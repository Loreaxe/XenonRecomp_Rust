pub fn sub_82208288(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208288 size=20
    let mut pc: u32 = 0x82208288;
    'dispatch: loop {
        match pc {
            0x82208288 => {
    //   block [0x82208288..0x8220829C)
	// 82208288: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220828C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208290: 409A000C  bne cr6, 0x8220829c
	if !ctx.cr[6].eq {
		sub_8220829C(ctx, base);
		return;
	}
	// 82208294: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208298: 4800002C  b 0x822082c4
	sub_822082B4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220829C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220829C size=24
    let mut pc: u32 = 0x8220829C;
    'dispatch: loop {
        match pc {
            0x8220829C => {
    //   block [0x8220829C..0x822082B4)
	// 8220829C: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 822082A0: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 822082A4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822082A8: 419A000C  beq cr6, 0x822082b4
	if ctx.cr[6].eq {
		sub_822082B4(ctx, base);
		return;
	}
	// 822082AC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822082B0: 48000014  b 0x822082c4
	sub_822082B4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822082B4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822082B4 size=40
    let mut pc: u32 = 0x822082B4;
    'dispatch: loop {
        match pc {
            0x822082B4 => {
    //   block [0x822082B4..0x822082DC)
	// 822082B4: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822082B8: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 822082BC: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 822082C0: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 822082C4: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 822082C8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822082CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822082D0: 419A0008  beq cr6, 0x822082d8
	if ctx.cr[6].eq {
	pc = 0x822082D8; continue 'dispatch;
	}
	// 822082D4: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822082D8: 48173130  b 0x8237b408
	sub_8237B408(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822082E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822082E0 size=144
    let mut pc: u32 = 0x822082E0;
    'dispatch: loop {
        match pc {
            0x822082E0 => {
    //   block [0x822082E0..0x82208370)
	// 822082E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822082E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822082E8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822082EC: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822082F0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822082F4: 409A000C  bne cr6, 0x82208300
	if !ctx.cr[6].eq {
	pc = 0x82208300; continue 'dispatch;
	}
	// 822082F8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822082FC: 4800002C  b 0x82208328
	pc = 0x82208328; continue 'dispatch;
	// 82208300: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208304: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208308: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220830C: 419A000C  beq cr6, 0x82208318
	if ctx.cr[6].eq {
	pc = 0x82208318; continue 'dispatch;
	}
	// 82208310: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208314: 48000014  b 0x82208328
	pc = 0x82208328; continue 'dispatch;
	// 82208318: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220831C: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82208320: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82208324: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82208328: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8220832C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208330: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208334: 419A0008  beq cr6, 0x8220833c
	if ctx.cr[6].eq {
	pc = 0x8220833C; continue 'dispatch;
	}
	// 82208338: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220833C: 481735AD  bl 0x8237b8e8
	ctx.lr = 0x82208340;
	sub_8237B8E8(ctx, base);
	// 82208340: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82208344: 419A0018  beq cr6, 0x8220835c
	if ctx.cr[6].eq {
	pc = 0x8220835C; continue 'dispatch;
	}
	// 82208348: A063000A  lhz r3, 0xa(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(10 as u32) ) } as u64;
	// 8220834C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208350: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208354: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208358: 4E800020  blr
	return;
	// 8220835C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208360: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208364: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208368: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220836C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208370(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208370 size=208
    let mut pc: u32 = 0x82208370;
    'dispatch: loop {
        match pc {
            0x82208370 => {
    //   block [0x82208370..0x82208440)
	// 82208370: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208374: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82208378: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220837C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208380: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208384: 409A000C  bne cr6, 0x82208390
	if !ctx.cr[6].eq {
	pc = 0x82208390; continue 'dispatch;
	}
	// 82208388: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220838C: 4800002C  b 0x822083b8
	pc = 0x822083B8; continue 'dispatch;
	// 82208390: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208394: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208398: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220839C: 419A000C  beq cr6, 0x822083a8
	if ctx.cr[6].eq {
	pc = 0x822083A8; continue 'dispatch;
	}
	// 822083A0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822083A4: 48000014  b 0x822083b8
	pc = 0x822083B8; continue 'dispatch;
	// 822083A8: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822083AC: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 822083B0: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 822083B4: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 822083B8: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 822083BC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822083C0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822083C4: 419A0008  beq cr6, 0x822083cc
	if ctx.cr[6].eq {
	pc = 0x822083CC; continue 'dispatch;
	}
	// 822083C8: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822083CC: 4817351D  bl 0x8237b8e8
	ctx.lr = 0x822083D0;
	sub_8237B8E8(ctx, base);
	// 822083D0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 822083D4: 419A0058  beq cr6, 0x8220842c
	if ctx.cr[6].eq {
	pc = 0x8220842C; continue 'dispatch;
	}
	// 822083D8: 89630007  lbz r11, 7(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(7 as u32) ) } as u64;
	// 822083DC: 2B0B0009  cmplwi cr6, r11, 9
	ctx.cr[6].compare_u32(ctx.r[11].u32, 9 as u32, &mut ctx.xer);
	// 822083E0: 40980020  bge cr6, 0x82208400
	if !ctx.cr[6].lt {
	pc = 0x82208400; continue 'dispatch;
	}
	// 822083E4: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822083E8: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 822083EC: 806B0008  lwz r3, 8(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 822083F0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 822083F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 822083F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 822083FC: 4E800020  blr
	return;
	// 82208400: 89630009  lbz r11, 9(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(9 as u32) ) } as u64;
	// 82208404: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82208408: 41980024  blt cr6, 0x8220842c
	if ctx.cr[6].lt {
	pc = 0x8220842C; continue 'dispatch;
	}
	// 8220840C: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208410: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82208414: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208418: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220841C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208420: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208424: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208428: 4E800020  blr
	return;
	// 8220842C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208430: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208434: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208438: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220843C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208440(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208440 size=20
    let mut pc: u32 = 0x82208440;
    'dispatch: loop {
        match pc {
            0x82208440 => {
    //   block [0x82208440..0x82208454)
	// 82208440: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208444: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208448: 409A000C  bne cr6, 0x82208454
	if !ctx.cr[6].eq {
		sub_82208454(ctx, base);
		return;
	}
	// 8220844C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208450: 4800002C  b 0x8220847c
	sub_8220846C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208454(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208454 size=24
    let mut pc: u32 = 0x82208454;
    'dispatch: loop {
        match pc {
            0x82208454 => {
    //   block [0x82208454..0x8220846C)
	// 82208454: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208458: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220845C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82208460: 419A000C  beq cr6, 0x8220846c
	if ctx.cr[6].eq {
		sub_8220846C(ctx, base);
		return;
	}
	// 82208464: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208468: 48000014  b 0x8220847c
	sub_8220846C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220846C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220846C size=48
    let mut pc: u32 = 0x8220846C;
    'dispatch: loop {
        match pc {
            0x8220846C => {
    //   block [0x8220846C..0x8220849C)
	// 8220846C: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208470: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82208474: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82208478: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 8220847C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82208480: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208484: 419A0010  beq cr6, 0x82208494
	if ctx.cr[6].eq {
	pc = 0x82208494; continue 'dispatch;
	}
	// 82208488: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220848C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208490: 409A000C  bne cr6, 0x8220849c
	if !ctx.cr[6].eq {
		sub_8220849C(ctx, base);
		return;
	}
	// 82208494: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208498: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220849C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220849C size=32
    let mut pc: u32 = 0x8220849C;
    'dispatch: loop {
        match pc {
            0x8220849C => {
    //   block [0x8220849C..0x822084BC)
	// 8220849C: 3D204754  lis r9, 0x4754
	ctx.r[9].s64 = 1196687360;
	// 822084A0: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822084A4: 61294D57  ori r9, r9, 0x4d57
	ctx.r[9].u64 = ctx.r[9].u64 | 19799;
	// 822084A8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822084AC: 409AFFE8  bne cr6, 0x82208494
	if !ctx.cr[6].eq {
		sub_8220846C(ctx, base);
		return;
	}
	// 822084B0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 822084B4: D02B0018  stfs f1, 0x18(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822084B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822084C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822084C0 size=20
    let mut pc: u32 = 0x822084C0;
    'dispatch: loop {
        match pc {
            0x822084C0 => {
    //   block [0x822084C0..0x822084D4)
	// 822084C0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822084C4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822084C8: 409A000C  bne cr6, 0x822084d4
	if !ctx.cr[6].eq {
		sub_822084D4(ctx, base);
		return;
	}
	// 822084CC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 822084D0: 4800002C  b 0x822084fc
	sub_822084EC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822084D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822084D4 size=24
    let mut pc: u32 = 0x822084D4;
    'dispatch: loop {
        match pc {
            0x822084D4 => {
    //   block [0x822084D4..0x822084EC)
	// 822084D4: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 822084D8: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 822084DC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822084E0: 419A000C  beq cr6, 0x822084ec
	if ctx.cr[6].eq {
		sub_822084EC(ctx, base);
		return;
	}
	// 822084E4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 822084E8: 48000014  b 0x822084fc
	sub_822084EC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822084EC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822084EC size=40
    let mut pc: u32 = 0x822084EC;
    'dispatch: loop {
        match pc {
            0x822084EC => {
    //   block [0x822084EC..0x82208514)
	// 822084EC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822084F0: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 822084F4: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 822084F8: 694A0001  xori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 ^ 1;
	// 822084FC: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 82208500: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208504: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208508: 419A0008  beq cr6, 0x82208510
	if ctx.cr[6].eq {
	pc = 0x82208510; continue 'dispatch;
	}
	// 8220850C: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208510: 48173000  b 0x8237b510
	sub_8237B510(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208518(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208518 size=20
    let mut pc: u32 = 0x82208518;
    'dispatch: loop {
        match pc {
            0x82208518 => {
    //   block [0x82208518..0x8220852C)
	// 82208518: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220851C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208520: 409A000C  bne cr6, 0x8220852c
	if !ctx.cr[6].eq {
		sub_8220852C(ctx, base);
		return;
	}
	// 82208524: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82208528: 4800002C  b 0x82208554
	sub_82208544(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220852C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220852C size=24
    let mut pc: u32 = 0x8220852C;
    'dispatch: loop {
        match pc {
            0x8220852C => {
    //   block [0x8220852C..0x82208544)
	// 8220852C: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208530: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208534: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82208538: 419A000C  beq cr6, 0x82208544
	if ctx.cr[6].eq {
		sub_82208544(ctx, base);
		return;
	}
	// 8220853C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82208540: 48000014  b 0x82208554
	sub_82208544(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208544(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208544 size=40
    let mut pc: u32 = 0x82208544;
    'dispatch: loop {
        match pc {
            0x82208544 => {
    //   block [0x82208544..0x8220856C)
	// 82208544: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208548: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 8220854C: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 82208550: 694A0001  xori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 ^ 1;
	// 82208554: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 82208558: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220855C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208560: 419A0008  beq cr6, 0x82208568
	if ctx.cr[6].eq {
	pc = 0x82208568; continue 'dispatch;
	}
	// 82208564: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208568: 48173060  b 0x8237b5c8
	sub_8237B5C8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208570(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208570 size=20
    let mut pc: u32 = 0x82208570;
    'dispatch: loop {
        match pc {
            0x82208570 => {
    //   block [0x82208570..0x82208584)
	// 82208570: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208574: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208578: 409A000C  bne cr6, 0x82208584
	if !ctx.cr[6].eq {
		sub_82208584(ctx, base);
		return;
	}
	// 8220857C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208580: 4800002C  b 0x822085ac
	sub_8220859C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208584(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208584 size=24
    let mut pc: u32 = 0x82208584;
    'dispatch: loop {
        match pc {
            0x82208584 => {
    //   block [0x82208584..0x8220859C)
	// 82208584: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208588: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220858C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82208590: 419A000C  beq cr6, 0x8220859c
	if ctx.cr[6].eq {
		sub_8220859C(ctx, base);
		return;
	}
	// 82208594: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208598: 48000014  b 0x822085ac
	sub_8220859C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220859C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220859C size=40
    let mut pc: u32 = 0x8220859C;
    'dispatch: loop {
        match pc {
            0x8220859C => {
    //   block [0x8220859C..0x822085C4)
	// 8220859C: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822085A0: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 822085A4: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 822085A8: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 822085AC: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 822085B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822085B4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822085B8: 419A0008  beq cr6, 0x822085c0
	if ctx.cr[6].eq {
	pc = 0x822085C0; continue 'dispatch;
	}
	// 822085BC: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822085C0: 481730F0  b 0x8237b6b0
	sub_8237B6B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822085C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822085C8 size=20
    let mut pc: u32 = 0x822085C8;
    'dispatch: loop {
        match pc {
            0x822085C8 => {
    //   block [0x822085C8..0x822085DC)
	// 822085C8: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 822085CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822085D0: 409A000C  bne cr6, 0x822085dc
	if !ctx.cr[6].eq {
		sub_822085DC(ctx, base);
		return;
	}
	// 822085D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 822085D8: 4800002C  b 0x82208604
	sub_822085F4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822085DC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822085DC size=24
    let mut pc: u32 = 0x822085DC;
    'dispatch: loop {
        match pc {
            0x822085DC => {
    //   block [0x822085DC..0x822085F4)
	// 822085DC: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 822085E0: 8124000C  lwz r9, 0xc(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 822085E4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822085E8: 419A000C  beq cr6, 0x822085f4
	if ctx.cr[6].eq {
		sub_822085F4(ctx, base);
		return;
	}
	// 822085EC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 822085F0: 48000014  b 0x82208604
	sub_822085F4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822085F4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822085F4 size=56
    let mut pc: u32 = 0x822085F4;
    'dispatch: loop {
        match pc {
            0x822085F4 => {
    //   block [0x822085F4..0x8220862C)
	// 822085F4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822085F8: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 822085FC: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 82208600: 694A0001  xori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 ^ 1;
	// 82208604: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 82208608: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8220860C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208610: 419A0008  beq cr6, 0x82208618
	if ctx.cr[6].eq {
	pc = 0x82208618; continue 'dispatch;
	}
	// 82208614: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208618: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220861C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82208620: 409A000C  bne cr6, 0x8220862c
	if !ctx.cr[6].eq {
		sub_8220862C(ctx, base);
		return;
	}
	// 82208624: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208628: 4800002C  b 0x82208654
	sub_82208644(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220862C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220862C size=24
    let mut pc: u32 = 0x8220862C;
    'dispatch: loop {
        match pc {
            0x8220862C => {
    //   block [0x8220862C..0x82208644)
	// 8220862C: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208630: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208634: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82208638: 419A000C  beq cr6, 0x82208644
	if ctx.cr[6].eq {
		sub_82208644(ctx, base);
		return;
	}
	// 8220863C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208640: 48000014  b 0x82208654
	sub_82208644(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208644(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208644 size=40
    let mut pc: u32 = 0x82208644;
    'dispatch: loop {
        match pc {
            0x82208644 => {
    //   block [0x82208644..0x8220866C)
	// 82208644: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208648: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220864C: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82208650: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82208654: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82208658: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220865C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208660: 419A0008  beq cr6, 0x82208668
	if ctx.cr[6].eq {
	pc = 0x82208668; continue 'dispatch;
	}
	// 82208664: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208668: 48173100  b 0x8237b768
	sub_8237B768(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208670(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208670 size=604
    let mut pc: u32 = 0x82208670;
    'dispatch: loop {
        match pc {
            0x82208670 => {
    //   block [0x82208670..0x822088CC)
	// 82208670: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208674: 4832CA31  bl 0x825350a4
	ctx.lr = 0x82208678;
	sub_82535080(ctx, base);
	// 82208678: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220867C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208680: 7C972378  mr r23, r4
	ctx.r[23].u64 = ctx.r[4].u64;
	// 82208684: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 82208688: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220868C: 409A000C  bne cr6, 0x82208698
	if !ctx.cr[6].eq {
	pc = 0x82208698; continue 'dispatch;
	}
	// 82208690: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82208694: 4800002C  b 0x822086c0
	pc = 0x822086C0; continue 'dispatch;
	// 82208698: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220869C: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 822086A0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822086A4: 419A000C  beq cr6, 0x822086b0
	if ctx.cr[6].eq {
	pc = 0x822086B0; continue 'dispatch;
	}
	// 822086A8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 822086AC: 48000014  b 0x822086c0
	pc = 0x822086C0; continue 'dispatch;
	// 822086B0: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822086B4: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 822086B8: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 822086BC: 694A0001  xori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 ^ 1;
	// 822086C0: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 822086C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822086C8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822086CC: 419A0008  beq cr6, 0x822086d4
	if ctx.cr[6].eq {
	pc = 0x822086D4; continue 'dispatch;
	}
	// 822086D0: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822086D4: 48173215  bl 0x8237b8e8
	ctx.lr = 0x822086D8;
	sub_8237B8E8(ctx, base);
	// 822086D8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 822086DC: 419A01E4  beq cr6, 0x822088c0
	if ctx.cr[6].eq {
	pc = 0x822088C0; continue 'dispatch;
	}
	// 822086E0: 89430007  lbz r10, 7(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(7 as u32) ) } as u64;
	// 822086E4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822086E8: 2B0A000F  cmplwi cr6, r10, 0xf
	ctx.cr[6].compare_u32(ctx.r[10].u32, 15 as u32, &mut ctx.xer);
	// 822086EC: 41980008  blt cr6, 0x822086f4
	if ctx.cr[6].lt {
	pc = 0x822086F4; continue 'dispatch;
	}
	// 822086F0: A163000E  lhz r11, 0xe(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 822086F4: 557E043E  clrlwi r30, r11, 0x10
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 822086F8: 2B0A000F  cmplwi cr6, r10, 0xf
	ctx.cr[6].compare_u32(ctx.r[10].u32, 15 as u32, &mut ctx.xer);
	// 822086FC: 4098000C  bge cr6, 0x82208708
	if !ctx.cr[6].lt {
	pc = 0x82208708; continue 'dispatch;
	}
	// 82208700: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82208704: 48000010  b 0x82208714
	pc = 0x82208714; continue 'dispatch;
	// 82208708: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220870C: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82208710: 83AB0020  lwz r29, 0x20(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 82208714: 2B0A000F  cmplwi cr6, r10, 0xf
	ctx.cr[6].compare_u32(ctx.r[10].u32, 15 as u32, &mut ctx.xer);
	// 82208718: 4098000C  bge cr6, 0x82208724
	if !ctx.cr[6].lt {
	pc = 0x82208724; continue 'dispatch;
	}
	// 8220871C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82208720: 48000034  b 0x82208754
	pc = 0x82208754; continue 'dispatch;
	// 82208724: A143000E  lhz r10, 0xe(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 82208728: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220872C: 409A000C  bne cr6, 0x82208738
	if !ctx.cr[6].eq {
	pc = 0x82208738; continue 'dispatch;
	}
	// 82208730: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82208734: 48000020  b 0x82208754
	pc = 0x82208754; continue 'dispatch;
	// 82208738: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220873C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82208740: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82208744: 816B0020  lwz r11, 0x20(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 82208748: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220874C: 396B000F  addi r11, r11, 0xf
	ctx.r[11].s64 = ctx.r[11].s64 + 15;
	// 82208750: 557F0036  rlwinm r31, r11, 0, 0, 0x1b
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82208754: 2B170000  cmplwi cr6, r23, 0
	ctx.cr[6].compare_u32(ctx.r[23].u32, 0 as u32, &mut ctx.xer);
	// 82208758: 419A0114  beq cr6, 0x8220886c
	if ctx.cr[6].eq {
	pc = 0x8220886C; continue 'dispatch;
	}
	// 8220875C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82208760: 419A0154  beq cr6, 0x822088b4
	if ctx.cr[6].eq {
	pc = 0x822088B4; continue 'dispatch;
	}
	// 82208764: 3D6082B6  lis r11, -0x7d4a
	ctx.r[11].s64 = -2102001664;
	// 82208768: 7FD9F378  mr r25, r30
	ctx.r[25].u64 = ctx.r[30].u64;
	// 8220876C: 3BCBB620  addi r30, r11, -0x49e0
	ctx.r[30].s64 = ctx.r[11].s64 + -18912;
	// 82208770: 3B400030  li r26, 0x30
	ctx.r[26].s64 = 48;
	// 82208774: 3B600010  li r27, 0x10
	ctx.r[27].s64 = 16;
	// 82208778: 3B800020  li r28, 0x20
	ctx.r[28].s64 = 32;
	// 8220877C: A17D0000  lhz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208780: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208784: 409A00A8  bne cr6, 0x8220882c
	if !ctx.cr[6].eq {
	pc = 0x8220882C; continue 'dispatch;
	}
	// 82208788: A17D0002  lhz r11, 2(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(2 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822088D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822088D0 size=140
    let mut pc: u32 = 0x822088D0;
    'dispatch: loop {
        match pc {
            0x822088D0 => {
    //   block [0x822088D0..0x8220895C)
	// 822088D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822088D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822088D8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822088DC: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822088E0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822088E4: 409A000C  bne cr6, 0x822088f0
	if !ctx.cr[6].eq {
	pc = 0x822088F0; continue 'dispatch;
	}
	// 822088E8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822088EC: 4800002C  b 0x82208918
	pc = 0x82208918; continue 'dispatch;
	// 822088F0: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 822088F4: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 822088F8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822088FC: 419A000C  beq cr6, 0x82208908
	if ctx.cr[6].eq {
	pc = 0x82208908; continue 'dispatch;
	}
	// 82208900: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208904: 48000014  b 0x82208918
	pc = 0x82208918; continue 'dispatch;
	// 82208908: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220890C: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82208910: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82208914: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82208918: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8220891C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208920: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208924: 419A0008  beq cr6, 0x8220892c
	if ctx.cr[6].eq {
	pc = 0x8220892C; continue 'dispatch;
	}
	// 82208928: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220892C: 4817303D  bl 0x8237b968
	ctx.lr = 0x82208930;
	sub_8237B968(ctx, base);
	// 82208930: 3CE00410  lis r7, 0x410
	ctx.r[7].s64 = 68157440;
	// 82208934: 3CC00410  lis r6, 0x410
	ctx.r[6].s64 = 68157440;
	// 82208938: 60E70011  ori r7, r7, 0x11
	ctx.r[7].u64 = ctx.r[7].u64 | 17;
	// 8220893C: 60C60012  ori r6, r6, 0x12
	ctx.r[6].u64 = ctx.r[6].u64 | 18;
	// 82208940: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 82208944: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 82208948: 48173251  bl 0x8237bb98
	ctx.lr = 0x8220894C;
	sub_8237BB98(ctx, base);
	// 8220894C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208950: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208954: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208958: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208960(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208960 size=20
    let mut pc: u32 = 0x82208960;
    'dispatch: loop {
        match pc {
            0x82208960 => {
    //   block [0x82208960..0x82208974)
	// 82208960: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208964: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208968: 409A000C  bne cr6, 0x82208974
	if !ctx.cr[6].eq {
		sub_82208974(ctx, base);
		return;
	}
	// 8220896C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82208970: 4800002C  b 0x8220899c
	sub_8220898C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208974(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208974 size=24
    let mut pc: u32 = 0x82208974;
    'dispatch: loop {
        match pc {
            0x82208974 => {
    //   block [0x82208974..0x8220898C)
	// 82208974: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208978: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220897C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82208980: 419A000C  beq cr6, 0x8220898c
	if ctx.cr[6].eq {
		sub_8220898C(ctx, base);
		return;
	}
	// 82208984: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82208988: 48000014  b 0x8220899c
	sub_8220898C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220898C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220898C size=40
    let mut pc: u32 = 0x8220898C;
    'dispatch: loop {
        match pc {
            0x8220898C => {
    //   block [0x8220898C..0x822089B4)
	// 8220898C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208990: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 82208994: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 82208998: 694A0001  xori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 ^ 1;
	// 8220899C: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 822089A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822089A4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822089A8: 419A0008  beq cr6, 0x822089b0
	if ctx.cr[6].eq {
	pc = 0x822089B0; continue 'dispatch;
	}
	// 822089AC: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822089B0: 4BFFB6F0  b 0x822040a0
	sub_822040A0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822089B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822089B8 size=208
    let mut pc: u32 = 0x822089B8;
    'dispatch: loop {
        match pc {
            0x822089B8 => {
    //   block [0x822089B8..0x82208A88)
	// 822089B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822089BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822089C0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822089C4: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822089C8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822089CC: 409A000C  bne cr6, 0x822089d8
	if !ctx.cr[6].eq {
	pc = 0x822089D8; continue 'dispatch;
	}
	// 822089D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822089D4: 4800002C  b 0x82208a00
	pc = 0x82208A00; continue 'dispatch;
	// 822089D8: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 822089DC: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 822089E0: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 822089E4: 419A000C  beq cr6, 0x822089f0
	if ctx.cr[6].eq {
	pc = 0x822089F0; continue 'dispatch;
	}
	// 822089E8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822089EC: 48000014  b 0x82208a00
	pc = 0x82208A00; continue 'dispatch;
	// 822089F0: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822089F4: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 822089F8: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 822089FC: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82208A00: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82208A04: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208A08: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208A0C: 419A0008  beq cr6, 0x82208a14
	if ctx.cr[6].eq {
	pc = 0x82208A14; continue 'dispatch;
	}
	// 82208A10: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208A14: 48172F55  bl 0x8237b968
	ctx.lr = 0x82208A18;
	sub_8237B968(ctx, base);
	// 82208A18: F8610050  std r3, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u64 ) };
	// 82208A1C: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82208A20: 2B0A01FF  cmplwi cr6, r10, 0x1ff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 511 as u32, &mut ctx.xer);
	// 82208A24: 4098003C  bge cr6, 0x82208a60
	if !ctx.cr[6].lt {
	pc = 0x82208A60; continue 'dispatch;
	}
	// 82208A28: 5549083C  slwi r9, r10, 1
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82208A2C: 3D608310  lis r11, -0x7cf0
	ctx.r[11].s64 = -2096103424;
	// 82208A30: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82208A34: 396B86B8  addi r11, r11, -0x7948
	ctx.r[11].s64 = ctx.r[11].s64 + -31048;
	// 82208A38: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82208A3C: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82208A40: 89090000  lbz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208A44: 2B080001  cmplwi cr6, r8, 1
	ctx.cr[6].compare_u32(ctx.r[8].u32, 1 as u32, &mut ctx.xer);
	// 82208A48: 409A0018  bne cr6, 0x82208a60
	if !ctx.cr[6].eq {
	pc = 0x82208A60; continue 'dispatch;
	}
	// 82208A4C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82208A50: 7D6A582E  lwzx r11, r10, r11
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82208A54: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82208A58: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82208A5C: 419A0018  beq cr6, 0x82208a74
	if ctx.cr[6].eq {
	pc = 0x82208A74; continue 'dispatch;
	}
	// 82208A60: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208A64: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208A68: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208A6C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208A70: 4E800020  blr
	return;
	// 82208A74: 80690010  lwz r3, 0x10(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) } as u64;
	// 82208A78: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208A7C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208A80: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208A84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208A88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208A88 size=272
    let mut pc: u32 = 0x82208A88;
    'dispatch: loop {
        match pc {
            0x82208A88 => {
    //   block [0x82208A88..0x82208B98)
	// 82208A88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208A8C: 4832C61D  bl 0x825350a8
	ctx.lr = 0x82208A90;
	sub_82535080(ctx, base);
	// 82208A90: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82208A94: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82208A98: 7C992378  mr r25, r4
	ctx.r[25].u64 = ctx.r[4].u64;
	// 82208A9C: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 82208AA0: 817C000C  lwz r11, 0xc(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208AA4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82208AA8: 409A0010  bne cr6, 0x82208ab8
	if !ctx.cr[6].eq {
	pc = 0x82208AB8; continue 'dispatch;
	}
	// 82208AAC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208AB0: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 82208AB4: 4832C644  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
	// 82208AB8: 83FC0008  lwz r31, 8(r28)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208ABC: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 82208AC0: 837C0000  lwz r27, 0(r28)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208AC4: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 82208AC8: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82208ACC: 4098FFE0  bge cr6, 0x82208aac
	if !ctx.cr[6].lt {
	pc = 0x82208AAC; continue 'dispatch;
	}
	// 82208AD0: 3D608310  lis r11, -0x7cf0
	ctx.r[11].s64 = -2096103424;
	// 82208AD4: 396B86B8  addi r11, r11, -0x7948
	ctx.r[11].s64 = ctx.r[11].s64 + -31048;
	// 82208AD8: 394B0010  addi r10, r11, 0x10
	ctx.r[10].s64 = ctx.r[11].s64 + 16;
	// 82208ADC: 57EB083C  slwi r11, r31, 1
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82208AE0: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 82208AE4: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82208AE8: 7FAB5214  add r29, r11, r10
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82208AEC: 2B1F01FF  cmplwi cr6, r31, 0x1ff
	ctx.cr[6].compare_u32(ctx.r[31].u32, 511 as u32, &mut ctx.xer);
	// 82208AF0: 40980050  bge cr6, 0x82208b40
	if !ctx.cr[6].lt {
	pc = 0x82208B40; continue 'dispatch;
	}
	// 82208AF4: 357DFFF0  addic. r11, r29, -0x10
	ctx.xer.ca = (ctx.r[29].u32 > (!(-16 as u32)));
	ctx.r[11].s64 = ctx.r[29].s64 + -16;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82208AF8: 41820048  beq 0x82208b40
	if ctx.cr[0].eq {
	pc = 0x82208B40; continue 'dispatch;
	}
	// 82208AFC: 897DFFF0  lbz r11, -0x10(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82208B00: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82208B04: 409A003C  bne cr6, 0x82208b40
	if !ctx.cr[6].eq {
	pc = 0x82208B40; continue 'dispatch;
	}
	// 82208B08: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208B0C: 83DDFFFC  lwz r30, -4(r29)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82208B10: 48191E81  bl 0x8239a990
	ctx.lr = 0x82208B14;
	sub_8239A990(ctx, base);
	// 82208B14: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208B18: 7F0B1840  cmplw cr6, r11, r3
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[3].u32, &mut ctx.xer);
	// 82208B1C: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82208B20: 41990008  bgt cr6, 0x82208b28
	if ctx.cr[6].gt {
	pc = 0x82208B28; continue 'dispatch;
	}
	// 82208B24: 7D63F214  add r11, r3, r30
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[30].u64;
	// 82208B28: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82208B2C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82208B30: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82208B34: 40980018  bge cr6, 0x82208b4c
	if !ctx.cr[6].lt {
	pc = 0x82208B4C; continue 'dispatch;
	}
	// 82208B38: 7D7B5B78  mr r27, r11
	ctx.r[27].u64 = ctx.r[11].u64;
	// 82208B3C: 48000010  b 0x82208b4c
	pc = 0x82208B4C; continue 'dispatch;
	// 82208B40: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 82208B44: 409A0008  bne cr6, 0x82208b4c
	if !ctx.cr[6].eq {
	pc = 0x82208B4C; continue 'dispatch;
	}
	// 82208B48: 7FFAFB78  mr r26, r31
	ctx.r[26].u64 = ctx.r[31].u64;
	// 82208B4C: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208B50: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82208B54: 815C000C  lwz r10, 0xc(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208B58: 3BBD0018  addi r29, r29, 0x18
	ctx.r[29].s64 = ctx.r[29].s64 + 24;
	// 82208B5C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82208B60: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82208B64: 4198FF88  blt cr6, 0x82208aec
	if ctx.cr[6].lt {
	pc = 0x82208AEC; continue 'dispatch;
	}
	// 82208B68: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 82208B6C: 419AFF40  beq cr6, 0x82208aac
	if ctx.cr[6].eq {
	pc = 0x82208AAC; continue 'dispatch;
	}
	// 82208B70: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82208B74: 815C0000  lwz r10, 0(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208B78: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82208B7C: 7F1B5840  cmplw cr6, r27, r11
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82208B80: 4098FF2C  bge cr6, 0x82208aac
	if !ctx.cr[6].lt {
	pc = 0x82208AAC; continue 'dispatch;
	}
	// 82208B84: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82208B88: 93590000  stw r26, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 82208B8C: 93780000  stw r27, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82208B90: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 82208B94: 4832C564  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208B98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208B98 size=120
    let mut pc: u32 = 0x82208B98;
    'dispatch: loop {
        match pc {
            0x82208B98 => {
    //   block [0x82208B98..0x82208C10)
	// 82208B98: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82208B9C: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82208BA0: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82208BA4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82208BA8: 40980060  bge cr6, 0x82208c08
	if !ctx.cr[6].lt {
	pc = 0x82208C08; continue 'dispatch;
	}
	// 82208BAC: 5569083C  slwi r9, r11, 1
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82208BB0: 3D408310  lis r10, -0x7cf0
	ctx.r[10].s64 = -2096103424;
	// 82208BB4: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82208BB8: 394A86B8  addi r10, r10, -0x7948
	ctx.r[10].s64 = ctx.r[10].s64 + -31048;
	// 82208BBC: 55291838  slwi r9, r9, 3
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82208BC0: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82208BC4: 2B0B01FF  cmplwi cr6, r11, 0x1ff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 511 as u32, &mut ctx.xer);
	// 82208BC8: 40980048  bge cr6, 0x82208c10
	if !ctx.cr[6].lt {
		sub_82208C10(ctx, base);
		return;
	}
	// 82208BCC: 892A0000  lbz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82208BD0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82208BD4: 419A0024  beq cr6, 0x82208bf8
	if ctx.cr[6].eq {
	pc = 0x82208BF8; continue 'dispatch;
	}
	// 82208BD8: 2B090001  cmplwi cr6, r9, 1
	ctx.cr[6].compare_u32(ctx.r[9].u32, 1 as u32, &mut ctx.xer);
	// 82208BDC: 409A0034  bne cr6, 0x82208c10
	if !ctx.cr[6].eq {
		sub_82208C10(ctx, base);
		return;
	}
	// 82208BE0: A12A0002  lhz r9, 2(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 82208BE4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82208BE8: 409A0028  bne cr6, 0x82208c10
	if !ctx.cr[6].eq {
		sub_82208C10(ctx, base);
		return;
	}
	// 82208BEC: 892A0001  lbz r9, 1(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 82208BF0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82208BF4: 409A001C  bne cr6, 0x82208c10
	if !ctx.cr[6].eq {
		sub_82208C10(ctx, base);
		return;
	}
	// 82208BF8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82208BFC: 394A0018  addi r10, r10, 0x18
	ctx.r[10].s64 = ctx.r[10].s64 + 24;
	// 82208C00: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82208C04: 4198FFC0  blt cr6, 0x82208bc4
	if ctx.cr[6].lt {
	pc = 0x82208BC4; continue 'dispatch;
	}
	// 82208C08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82208C0C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208C10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82208C10 size=8
    let mut pc: u32 = 0x82208C10;
    'dispatch: loop {
        match pc {
            0x82208C10 => {
    //   block [0x82208C10..0x82208C18)
	// 82208C10: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82208C14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208C18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208C18 size=276
    let mut pc: u32 = 0x82208C18;
    'dispatch: loop {
        match pc {
            0x82208C18 => {
    //   block [0x82208C18..0x82208D2C)
	// 82208C18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208C1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82208C20: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82208C24: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82208C28: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 82208C2C: 3BEBE630  addi r31, r11, -0x19d0
	ctx.r[31].s64 = ctx.r[11].s64 + -6608;
	// 82208C30: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208C34: 48000A2D  bl 0x82209660
	ctx.lr = 0x82208C38;
	sub_82209660(ctx, base);
	// 82208C38: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82208C3C: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 82208C40: 388B43D8  addi r4, r11, 0x43d8
	ctx.r[4].s64 = ctx.r[11].s64 + 17368;
	// 82208C44: 387F0100  addi r3, r31, 0x100
	ctx.r[3].s64 = ctx.r[31].s64 + 256;
	// 82208C48: 48329F79  bl 0x82532bc0
	ctx.lr = 0x82208C4C;
	sub_82532BC0(ctx, base);
	// 82208C4C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208C50: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208C54: 38C0003D  li r6, 0x3d
	ctx.r[6].s64 = 61;
	// 82208C58: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208C5C: 3C800204  lis r4, 0x204
	ctx.r[4].s64 = 33816576;
	// 82208C60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208C64: 997F010F  stb r11, 0x10f(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(271 as u32), ctx.r[11].u8 ) };
	// 82208C68: 48000AA9  bl 0x82209710
	ctx.lr = 0x82208C6C;
	sub_82209710(ctx, base);
	// 82208C6C: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208C70: 38C0005D  li r6, 0x5d
	ctx.r[6].s64 = 93;
	// 82208C74: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208C78: 3C800224  lis r4, 0x224
	ctx.r[4].s64 = 35913728;
	// 82208C7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208C80: 48000A91  bl 0x82209710
	ctx.lr = 0x82208C84;
	sub_82209710(ctx, base);
	// 82208C84: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208C88: 38C0007D  li r6, 0x7d
	ctx.r[6].s64 = 125;
	// 82208C8C: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208C90: 3C800244  lis r4, 0x244
	ctx.r[4].s64 = 38010880;
	// 82208C94: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208C98: 48000A79  bl 0x82209710
	ctx.lr = 0x82208C9C;
	sub_82209710(ctx, base);
	// 82208C9C: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208CA0: 38C0009D  li r6, 0x9d
	ctx.r[6].s64 = 157;
	// 82208CA4: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208CA8: 3C800264  lis r4, 0x264
	ctx.r[4].s64 = 40108032;
	// 82208CAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208CB0: 48000A61  bl 0x82209710
	ctx.lr = 0x82208CB4;
	sub_82209710(ctx, base);
	// 82208CB4: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208CB8: 38C000BD  li r6, 0xbd
	ctx.r[6].s64 = 189;
	// 82208CBC: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208CC0: 3C800284  lis r4, 0x284
	ctx.r[4].s64 = 42205184;
	// 82208CC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208CC8: 48000A49  bl 0x82209710
	ctx.lr = 0x82208CCC;
	sub_82209710(ctx, base);
	// 82208CCC: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208CD0: 38C000DD  li r6, 0xdd
	ctx.r[6].s64 = 221;
	// 82208CD4: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208CD8: 3C8002A4  lis r4, 0x2a4
	ctx.r[4].s64 = 44302336;
	// 82208CDC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208CE0: 48000A31  bl 0x82209710
	ctx.lr = 0x82208CE4;
	sub_82209710(ctx, base);
	// 82208CE4: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208CE8: 38C000FD  li r6, 0xfd
	ctx.r[6].s64 = 253;
	// 82208CEC: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208CF0: 3C8002C4  lis r4, 0x2c4
	ctx.r[4].s64 = 46399488;
	// 82208CF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208CF8: 48000A19  bl 0x82209710
	ctx.lr = 0x82208CFC;
	sub_82209710(ctx, base);
	// 82208CFC: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 82208D00: 38C0011D  li r6, 0x11d
	ctx.r[6].s64 = 285;
	// 82208D04: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208D08: 3C8002E4  lis r4, 0x2e4
	ctx.r[4].s64 = 48496640;
	// 82208D0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208D10: 48000A01  bl 0x82209710
	ctx.lr = 0x82208D14;
	sub_82209710(ctx, base);
	// 82208D14: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208D18: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208D1C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208D20: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208D24: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82208D28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208D30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208D30 size=276
    let mut pc: u32 = 0x82208D30;
    'dispatch: loop {
        match pc {
            0x82208D30 => {
    //   block [0x82208D30..0x82208E44)
	// 82208D30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208D34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82208D38: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82208D3C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82208D40: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 82208D44: 3BEBEB50  addi r31, r11, -0x14b0
	ctx.r[31].s64 = ctx.r[11].s64 + -5296;
	// 82208D48: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208D4C: 48000915  bl 0x82209660
	ctx.lr = 0x82208D50;
	sub_82209660(ctx, base);
	// 82208D50: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82208D54: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 82208D58: 388B43E8  addi r4, r11, 0x43e8
	ctx.r[4].s64 = ctx.r[11].s64 + 17384;
	// 82208D5C: 387F0100  addi r3, r31, 0x100
	ctx.r[3].s64 = ctx.r[31].s64 + 256;
	// 82208D60: 48329E61  bl 0x82532bc0
	ctx.lr = 0x82208D64;
	sub_82532BC0(ctx, base);
	// 82208D64: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82208D68: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208D6C: 38C0013D  li r6, 0x13d
	ctx.r[6].s64 = 317;
	// 82208D70: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208D74: 3C800304  lis r4, 0x304
	ctx.r[4].s64 = 50593792;
	// 82208D78: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208D7C: 997F010F  stb r11, 0x10f(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(271 as u32), ctx.r[11].u8 ) };
	// 82208D80: 48000991  bl 0x82209710
	ctx.lr = 0x82208D84;
	sub_82209710(ctx, base);
	// 82208D84: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208D88: 38C0013E  li r6, 0x13e
	ctx.r[6].s64 = 318;
	// 82208D8C: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208D90: 3C800324  lis r4, 0x324
	ctx.r[4].s64 = 52690944;
	// 82208D94: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208D98: 48000979  bl 0x82209710
	ctx.lr = 0x82208D9C;
	sub_82209710(ctx, base);
	// 82208D9C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208DA0: 38C0013F  li r6, 0x13f
	ctx.r[6].s64 = 319;
	// 82208DA4: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208DA8: 3C800344  lis r4, 0x344
	ctx.r[4].s64 = 54788096;
	// 82208DAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208DB0: 48000961  bl 0x82209710
	ctx.lr = 0x82208DB4;
	sub_82209710(ctx, base);
	// 82208DB4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208DB8: 38C00140  li r6, 0x140
	ctx.r[6].s64 = 320;
	// 82208DBC: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208DC0: 3C800364  lis r4, 0x364
	ctx.r[4].s64 = 56885248;
	// 82208DC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208DC8: 48000949  bl 0x82209710
	ctx.lr = 0x82208DCC;
	sub_82209710(ctx, base);
	// 82208DCC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208DD0: 38C00141  li r6, 0x141
	ctx.r[6].s64 = 321;
	// 82208DD4: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208DD8: 3C800384  lis r4, 0x384
	ctx.r[4].s64 = 58982400;
	// 82208DDC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208DE0: 48000931  bl 0x82209710
	ctx.lr = 0x82208DE4;
	sub_82209710(ctx, base);
	// 82208DE4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208DE8: 38C00142  li r6, 0x142
	ctx.r[6].s64 = 322;
	// 82208DEC: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208DF0: 3C8003A4  lis r4, 0x3a4
	ctx.r[4].s64 = 61079552;
	// 82208DF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208DF8: 48000919  bl 0x82209710
	ctx.lr = 0x82208DFC;
	sub_82209710(ctx, base);
	// 82208DFC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208E00: 38C00143  li r6, 0x143
	ctx.r[6].s64 = 323;
	// 82208E04: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208E08: 3C8003C4  lis r4, 0x3c4
	ctx.r[4].s64 = 63176704;
	// 82208E0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208E10: 48000901  bl 0x82209710
	ctx.lr = 0x82208E14;
	sub_82209710(ctx, base);
	// 82208E14: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208E18: 38C00144  li r6, 0x144
	ctx.r[6].s64 = 324;
	// 82208E1C: 3CA00020  lis r5, 0x20
	ctx.r[5].s64 = 2097152;
	// 82208E20: 3C8003E4  lis r4, 0x3e4
	ctx.r[4].s64 = 65273856;
	// 82208E24: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208E28: 480008E9  bl 0x82209710
	ctx.lr = 0x82208E2C;
	sub_82209710(ctx, base);
	// 82208E2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208E30: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82208E34: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82208E38: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82208E3C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82208E40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82208E48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82208E48 size=580
    let mut pc: u32 = 0x82208E48;
    'dispatch: loop {
        match pc {
            0x82208E48 => {
    //   block [0x82208E48..0x8220908C)
	// 82208E48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82208E4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82208E50: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82208E54: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82208E58: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82208E5C: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 82208E60: 3940000F  li r10, 0xf
	ctx.r[10].s64 = 15;
	// 82208E64: 3BEBECB0  addi r31, r11, -0x1350
	ctx.r[31].s64 = ctx.r[11].s64 + -4944;
	// 82208E68: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82208E6C: 397F0008  addi r11, r31, 8
	ctx.r[11].s64 = ctx.r[31].s64 + 8;
	// 82208E70: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82208E74: 93CBFFF8  stw r30, -8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), ctx.r[30].u32 ) };
	// 82208E78: 93CBFFFC  stw r30, -4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), ctx.r[30].u32 ) };
	// 82208E7C: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 82208E80: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82208E84: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82208E88: 9BCB0008  stb r30, 8(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u8 ) };
	// 82208E8C: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 82208E90: 4098FFE0  bge cr6, 0x82208e70
	if !ctx.cr[6].lt {
	pc = 0x82208E70; continue 'dispatch;
	}
	// 82208E94: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82208E98: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 82208E9C: 388B43F4  addi r4, r11, 0x43f4
	ctx.r[4].s64 = ctx.r[11].s64 + 17396;
	// 82208EA0: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82208EA4: 387F0200  addi r3, r31, 0x200
	ctx.r[3].s64 = ctx.r[31].s64 + 512;
	// 82208EA8: 997F0200  stb r11, 0x200(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(512 as u32), ctx.r[11].u8 ) };
	// 82208EAC: 48329D15  bl 0x82532bc0
	ctx.lr = 0x82208EB0;
	sub_82532BC0(ctx, base);
	// 82208EB0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208EB4: 9BDF020F  stb r30, 0x20f(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(527 as u32), ctx.r[30].u8 ) };
	// 82208EB8: 38C00145  li r6, 0x145
	ctx.r[6].s64 = 325;
	// 82208EBC: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208EC0: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208EC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208EC8: 48000901  bl 0x822097c8
	ctx.lr = 0x82208ECC;
	sub_822097C8(ctx, base);
	// 82208ECC: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208ED0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208ED4: 38C00146  li r6, 0x146
	ctx.r[6].s64 = 326;
	// 82208ED8: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208EDC: 60840400  ori r4, r4, 0x400
	ctx.r[4].u64 = ctx.r[4].u64 | 1024;
	// 82208EE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208EE4: 480008E5  bl 0x822097c8
	ctx.lr = 0x82208EE8;
	sub_822097C8(ctx, base);
	// 82208EE8: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208EEC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208EF0: 38C00147  li r6, 0x147
	ctx.r[6].s64 = 327;
	// 82208EF4: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208EF8: 60840800  ori r4, r4, 0x800
	ctx.r[4].u64 = ctx.r[4].u64 | 2048;
	// 82208EFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F00: 480008C9  bl 0x822097c8
	ctx.lr = 0x82208F04;
	sub_822097C8(ctx, base);
	// 82208F04: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F08: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F0C: 38C00148  li r6, 0x148
	ctx.r[6].s64 = 328;
	// 82208F10: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208F14: 60840C00  ori r4, r4, 0xc00
	ctx.r[4].u64 = ctx.r[4].u64 | 3072;
	// 82208F18: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F1C: 480008AD  bl 0x822097c8
	ctx.lr = 0x82208F20;
	sub_822097C8(ctx, base);
	// 82208F20: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F24: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F28: 38C00149  li r6, 0x149
	ctx.r[6].s64 = 329;
	// 82208F2C: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208F30: 60841000  ori r4, r4, 0x1000
	ctx.r[4].u64 = ctx.r[4].u64 | 4096;
	// 82208F34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F38: 48000891  bl 0x822097c8
	ctx.lr = 0x82208F3C;
	sub_822097C8(ctx, base);
	// 82208F3C: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F40: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F44: 38C0014A  li r6, 0x14a
	ctx.r[6].s64 = 330;
	// 82208F48: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208F4C: 60841400  ori r4, r4, 0x1400
	ctx.r[4].u64 = ctx.r[4].u64 | 5120;
	// 82208F50: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F54: 48000875  bl 0x822097c8
	ctx.lr = 0x82208F58;
	sub_822097C8(ctx, base);
	// 82208F58: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F5C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F60: 38C0014B  li r6, 0x14b
	ctx.r[6].s64 = 331;
	// 82208F64: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208F68: 60841800  ori r4, r4, 0x1800
	ctx.r[4].u64 = ctx.r[4].u64 | 6144;
	// 82208F6C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F70: 48000859  bl 0x822097c8
	ctx.lr = 0x82208F74;
	sub_822097C8(ctx, base);
	// 82208F74: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F78: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F7C: 38C0014C  li r6, 0x14c
	ctx.r[6].s64 = 332;
	// 82208F80: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208F84: 60841C00  ori r4, r4, 0x1c00
	ctx.r[4].u64 = ctx.r[4].u64 | 7168;
	// 82208F88: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208F8C: 4800083D  bl 0x822097c8
	ctx.lr = 0x82208F90;
	sub_822097C8(ctx, base);
	// 82208F90: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208F94: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208F98: 38C0014D  li r6, 0x14d
	ctx.r[6].s64 = 333;
	// 82208F9C: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208FA0: 60842000  ori r4, r4, 0x2000
	ctx.r[4].u64 = ctx.r[4].u64 | 8192;
	// 82208FA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208FA8: 48000821  bl 0x822097c8
	ctx.lr = 0x82208FAC;
	sub_822097C8(ctx, base);
	// 82208FAC: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208FB0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208FB4: 38C0014E  li r6, 0x14e
	ctx.r[6].s64 = 334;
	// 82208FB8: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208FBC: 60842400  ori r4, r4, 0x2400
	ctx.r[4].u64 = ctx.r[4].u64 | 9216;
	// 82208FC0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208FC4: 48000805  bl 0x822097c8
	ctx.lr = 0x82208FC8;
	sub_822097C8(ctx, base);
	// 82208FC8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208FCC: 38C0014F  li r6, 0x14f
	ctx.r[6].s64 = 335;
	// 82208FD0: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208FD4: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208FD8: 60842800  ori r4, r4, 0x2800
	ctx.r[4].u64 = ctx.r[4].u64 | 10240;
	// 82208FDC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208FE0: 480007E9  bl 0x822097c8
	ctx.lr = 0x82208FE4;
	sub_822097C8(ctx, base);
	// 82208FE4: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82208FE8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82208FEC: 38C00150  li r6, 0x150
	ctx.r[6].s64 = 336;
	// 82208FF0: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82208FF4: 60842C00  ori r4, r4, 0x2c00
	ctx.r[4].u64 = ctx.r[4].u64 | 11264;
	// 82208FF8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82208FFC: 480007CD  bl 0x822097c8
	ctx.lr = 0x82209000;
	sub_822097C8(ctx, base);
	// 82209000: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82209004: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209008: 38C00151  li r6, 0x151
	ctx.r[6].s64 = 337;
	// 8220900C: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82209010: 60843000  ori r4, r4, 0x3000
	ctx.r[4].u64 = ctx.r[4].u64 | 12288;
	// 82209014: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209018: 480007B1  bl 0x822097c8
	ctx.lr = 0x8220901C;
	sub_822097C8(ctx, base);
	// 8220901C: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82209020: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209024: 38C00152  li r6, 0x152
	ctx.r[6].s64 = 338;
	// 82209028: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 8220902C: 60843400  ori r4, r4, 0x3400
	ctx.r[4].u64 = ctx.r[4].u64 | 13312;
	// 82209030: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209034: 48000795  bl 0x822097c8
	ctx.lr = 0x82209038;
	sub_822097C8(ctx, base);
	// 82209038: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 8220903C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209040: 38C00153  li r6, 0x153
	ctx.r[6].s64 = 339;
	// 82209044: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82209048: 60843800  ori r4, r4, 0x3800
	ctx.r[4].u64 = ctx.r[4].u64 | 14336;
	// 8220904C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209050: 48000779  bl 0x822097c8
	ctx.lr = 0x82209054;
	sub_822097C8(ctx, base);
	// 82209054: 3C800404  lis r4, 0x404
	ctx.r[4].s64 = 67371008;
	// 82209058: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220905C: 38C00154  li r6, 0x154
	ctx.r[6].s64 = 340;
	// 82209060: 38A00400  li r5, 0x400
	ctx.r[5].s64 = 1024;
	// 82209064: 60843C00  ori r4, r4, 0x3c00
	ctx.r[4].u64 = ctx.r[4].u64 | 15360;
	// 82209068: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220906C: 4800075D  bl 0x822097c8
	ctx.lr = 0x82209070;
	sub_822097C8(ctx, base);
	// 82209070: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209074: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82209078: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220907C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209080: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82209084: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82209088: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209090(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209090 size=1024
    let mut pc: u32 = 0x82209090;
    'dispatch: loop {
        match pc {
            0x82209090 => {
    //   block [0x82209090..0x82209490)
	// 82209090: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209094: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209098: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220909C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 822090A0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822090A4: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 822090A8: 3940001F  li r10, 0x1f
	ctx.r[10].s64 = 31;
	// 822090AC: 3BEBE740  addi r31, r11, -0x18c0
	ctx.r[31].s64 = ctx.r[11].s64 + -6336;
	// 822090B0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 822090B4: 397F0008  addi r11, r31, 8
	ctx.r[11].s64 = ctx.r[31].s64 + 8;
	// 822090B8: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 822090BC: 93CBFFF8  stw r30, -8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), ctx.r[30].u32 ) };
	// 822090C0: 93CBFFFC  stw r30, -4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), ctx.r[30].u32 ) };
	// 822090C4: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 822090C8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 822090CC: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 822090D0: 9BCB0008  stb r30, 8(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u8 ) };
	// 822090D4: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 822090D8: 4098FFE0  bge cr6, 0x822090b8
	if !ctx.cr[6].lt {
	pc = 0x822090B8; continue 'dispatch;
	}
	// 822090DC: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 822090E0: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 822090E4: 388B4400  addi r4, r11, 0x4400
	ctx.r[4].s64 = ctx.r[11].s64 + 17408;
	// 822090E8: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 822090EC: 387F0400  addi r3, r31, 0x400
	ctx.r[3].s64 = ctx.r[31].s64 + 1024;
	// 822090F0: 997F0400  stb r11, 0x400(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(1024 as u32), ctx.r[11].u8 ) };
	// 822090F4: 48329ACD  bl 0x82532bc0
	ctx.lr = 0x822090F8;
	sub_82532BC0(ctx, base);
	// 822090F8: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 822090FC: 9BDF040F  stb r30, 0x40f(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(1039 as u32), ctx.r[30].u8 ) };
	// 82209100: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209104: 38C00155  li r6, 0x155
	ctx.r[6].s64 = 341;
	// 82209108: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 8220910C: 60844000  ori r4, r4, 0x4000
	ctx.r[4].u64 = ctx.r[4].u64 | 16384;
	// 82209110: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209114: 4800076D  bl 0x82209880
	ctx.lr = 0x82209118;
	sub_82209880(ctx, base);
	// 82209118: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 8220911C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209120: 38C00156  li r6, 0x156
	ctx.r[6].s64 = 342;
	// 82209124: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209128: 60845000  ori r4, r4, 0x5000
	ctx.r[4].u64 = ctx.r[4].u64 | 20480;
	// 8220912C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209130: 48000751  bl 0x82209880
	ctx.lr = 0x82209134;
	sub_82209880(ctx, base);
	// 82209134: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 82209138: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220913C: 38C00157  li r6, 0x157
	ctx.r[6].s64 = 343;
	// 82209140: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209144: 60846000  ori r4, r4, 0x6000
	ctx.r[4].u64 = ctx.r[4].u64 | 24576;
	// 82209148: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220914C: 48000735  bl 0x82209880
	ctx.lr = 0x82209150;
	sub_82209880(ctx, base);
	// 82209150: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 82209154: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209158: 38C00158  li r6, 0x158
	ctx.r[6].s64 = 344;
	// 8220915C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209160: 60847000  ori r4, r4, 0x7000
	ctx.r[4].u64 = ctx.r[4].u64 | 28672;
	// 82209164: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209168: 48000719  bl 0x82209880
	ctx.lr = 0x8220916C;
	sub_82209880(ctx, base);
	// 8220916C: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 82209170: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209174: 38C00159  li r6, 0x159
	ctx.r[6].s64 = 345;
	// 82209178: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 8220917C: 60848000  ori r4, r4, 0x8000
	ctx.r[4].u64 = ctx.r[4].u64 | 32768;
	// 82209180: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209184: 480006FD  bl 0x82209880
	ctx.lr = 0x82209188;
	sub_82209880(ctx, base);
	// 82209188: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 8220918C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209190: 38C0015A  li r6, 0x15a
	ctx.r[6].s64 = 346;
	// 82209194: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209198: 60849000  ori r4, r4, 0x9000
	ctx.r[4].u64 = ctx.r[4].u64 | 36864;
	// 8220919C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822091A0: 480006E1  bl 0x82209880
	ctx.lr = 0x822091A4;
	sub_82209880(ctx, base);
	// 822091A4: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 822091A8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822091AC: 38C0015B  li r6, 0x15b
	ctx.r[6].s64 = 347;
	// 822091B0: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822091B4: 6084A000  ori r4, r4, 0xa000
	ctx.r[4].u64 = ctx.r[4].u64 | 40960;
	// 822091B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822091BC: 480006C5  bl 0x82209880
	ctx.lr = 0x822091C0;
	sub_82209880(ctx, base);
	// 822091C0: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 822091C4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822091C8: 38C0015C  li r6, 0x15c
	ctx.r[6].s64 = 348;
	// 822091CC: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822091D0: 6084B000  ori r4, r4, 0xb000
	ctx.r[4].u64 = ctx.r[4].u64 | 45056;
	// 822091D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822091D8: 480006A9  bl 0x82209880
	ctx.lr = 0x822091DC;
	sub_82209880(ctx, base);
	// 822091DC: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 822091E0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822091E4: 38C0015D  li r6, 0x15d
	ctx.r[6].s64 = 349;
	// 822091E8: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822091EC: 6084C000  ori r4, r4, 0xc000
	ctx.r[4].u64 = ctx.r[4].u64 | 49152;
	// 822091F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822091F4: 4800068D  bl 0x82209880
	ctx.lr = 0x822091F8;
	sub_82209880(ctx, base);
	// 822091F8: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 822091FC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209200: 38C0015E  li r6, 0x15e
	ctx.r[6].s64 = 350;
	// 82209204: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209208: 6084D000  ori r4, r4, 0xd000
	ctx.r[4].u64 = ctx.r[4].u64 | 53248;
	// 8220920C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209210: 48000671  bl 0x82209880
	ctx.lr = 0x82209214;
	sub_82209880(ctx, base);
	// 82209214: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209218: 38C0015F  li r6, 0x15f
	ctx.r[6].s64 = 351;
	// 8220921C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209220: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 82209224: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209228: 6084E000  ori r4, r4, 0xe000
	ctx.r[4].u64 = ctx.r[4].u64 | 57344;
	// 8220922C: 48000655  bl 0x82209880
	ctx.lr = 0x82209230;
	sub_82209880(ctx, base);
	// 82209230: 3C800604  lis r4, 0x604
	ctx.r[4].s64 = 100925440;
	// 82209234: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209238: 38C00160  li r6, 0x160
	ctx.r[6].s64 = 352;
	// 8220923C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209240: 6084F000  ori r4, r4, 0xf000
	ctx.r[4].u64 = ctx.r[4].u64 | 61440;
	// 82209244: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209248: 48000639  bl 0x82209880
	ctx.lr = 0x8220924C;
	sub_82209880(ctx, base);
	// 8220924C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209250: 38C00161  li r6, 0x161
	ctx.r[6].s64 = 353;
	// 82209254: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209258: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 8220925C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209260: 48000621  bl 0x82209880
	ctx.lr = 0x82209264;
	sub_82209880(ctx, base);
	// 82209264: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209268: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220926C: 38C00162  li r6, 0x162
	ctx.r[6].s64 = 354;
	// 82209270: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209274: 60841000  ori r4, r4, 0x1000
	ctx.r[4].u64 = ctx.r[4].u64 | 4096;
	// 82209278: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220927C: 48000605  bl 0x82209880
	ctx.lr = 0x82209280;
	sub_82209880(ctx, base);
	// 82209280: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209284: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209288: 38C00163  li r6, 0x163
	ctx.r[6].s64 = 355;
	// 8220928C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209290: 60842000  ori r4, r4, 0x2000
	ctx.r[4].u64 = ctx.r[4].u64 | 8192;
	// 82209294: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209298: 480005E9  bl 0x82209880
	ctx.lr = 0x8220929C;
	sub_82209880(ctx, base);
	// 8220929C: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822092A0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822092A4: 38C00164  li r6, 0x164
	ctx.r[6].s64 = 356;
	// 822092A8: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822092AC: 60843000  ori r4, r4, 0x3000
	ctx.r[4].u64 = ctx.r[4].u64 | 12288;
	// 822092B0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822092B4: 480005CD  bl 0x82209880
	ctx.lr = 0x822092B8;
	sub_82209880(ctx, base);
	// 822092B8: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822092BC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822092C0: 38C00165  li r6, 0x165
	ctx.r[6].s64 = 357;
	// 822092C4: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822092C8: 60844000  ori r4, r4, 0x4000
	ctx.r[4].u64 = ctx.r[4].u64 | 16384;
	// 822092CC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822092D0: 480005B1  bl 0x82209880
	ctx.lr = 0x822092D4;
	sub_82209880(ctx, base);
	// 822092D4: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822092D8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822092DC: 38C00166  li r6, 0x166
	ctx.r[6].s64 = 358;
	// 822092E0: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822092E4: 60845000  ori r4, r4, 0x5000
	ctx.r[4].u64 = ctx.r[4].u64 | 20480;
	// 822092E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822092EC: 48000595  bl 0x82209880
	ctx.lr = 0x822092F0;
	sub_82209880(ctx, base);
	// 822092F0: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822092F4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822092F8: 38C00167  li r6, 0x167
	ctx.r[6].s64 = 359;
	// 822092FC: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209300: 60846000  ori r4, r4, 0x6000
	ctx.r[4].u64 = ctx.r[4].u64 | 24576;
	// 82209304: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209308: 48000579  bl 0x82209880
	ctx.lr = 0x8220930C;
	sub_82209880(ctx, base);
	// 8220930C: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209310: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209314: 38C00168  li r6, 0x168
	ctx.r[6].s64 = 360;
	// 82209318: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 8220931C: 60847000  ori r4, r4, 0x7000
	ctx.r[4].u64 = ctx.r[4].u64 | 28672;
	// 82209320: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209324: 4800055D  bl 0x82209880
	ctx.lr = 0x82209328;
	sub_82209880(ctx, base);
	// 82209328: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 8220932C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209330: 38C00169  li r6, 0x169
	ctx.r[6].s64 = 361;
	// 82209334: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209338: 60848000  ori r4, r4, 0x8000
	ctx.r[4].u64 = ctx.r[4].u64 | 32768;
	// 8220933C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209340: 48000541  bl 0x82209880
	ctx.lr = 0x82209344;
	sub_82209880(ctx, base);
	// 82209344: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209348: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220934C: 38C0016A  li r6, 0x16a
	ctx.r[6].s64 = 362;
	// 82209350: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209354: 60849000  ori r4, r4, 0x9000
	ctx.r[4].u64 = ctx.r[4].u64 | 36864;
	// 82209358: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220935C: 48000525  bl 0x82209880
	ctx.lr = 0x82209360;
	sub_82209880(ctx, base);
	// 82209360: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209364: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209368: 38C0016B  li r6, 0x16b
	ctx.r[6].s64 = 363;
	// 8220936C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209370: 6084A000  ori r4, r4, 0xa000
	ctx.r[4].u64 = ctx.r[4].u64 | 40960;
	// 82209374: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209378: 48000509  bl 0x82209880
	ctx.lr = 0x8220937C;
	sub_82209880(ctx, base);
	// 8220937C: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 82209380: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209384: 38C0016C  li r6, 0x16c
	ctx.r[6].s64 = 364;
	// 82209388: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 8220938C: 6084B000  ori r4, r4, 0xb000
	ctx.r[4].u64 = ctx.r[4].u64 | 45056;
	// 82209390: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209394: 480004ED  bl 0x82209880
	ctx.lr = 0x82209398;
	sub_82209880(ctx, base);
	// 82209398: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 8220939C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822093A0: 38C0016D  li r6, 0x16d
	ctx.r[6].s64 = 365;
	// 822093A4: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822093A8: 6084C000  ori r4, r4, 0xc000
	ctx.r[4].u64 = ctx.r[4].u64 | 49152;
	// 822093AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822093B0: 480004D1  bl 0x82209880
	ctx.lr = 0x822093B4;
	sub_82209880(ctx, base);
	// 822093B4: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822093B8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822093BC: 38C0016E  li r6, 0x16e
	ctx.r[6].s64 = 366;
	// 822093C0: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822093C4: 6084D000  ori r4, r4, 0xd000
	ctx.r[4].u64 = ctx.r[4].u64 | 53248;
	// 822093C8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822093CC: 480004B5  bl 0x82209880
	ctx.lr = 0x822093D0;
	sub_82209880(ctx, base);
	// 822093D0: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822093D4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822093D8: 38C0016F  li r6, 0x16f
	ctx.r[6].s64 = 367;
	// 822093DC: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822093E0: 6084E000  ori r4, r4, 0xe000
	ctx.r[4].u64 = ctx.r[4].u64 | 57344;
	// 822093E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822093E8: 48000499  bl 0x82209880
	ctx.lr = 0x822093EC;
	sub_82209880(ctx, base);
	// 822093EC: 3C800605  lis r4, 0x605
	ctx.r[4].s64 = 100990976;
	// 822093F0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 822093F4: 38C00170  li r6, 0x170
	ctx.r[6].s64 = 368;
	// 822093F8: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 822093FC: 6084F000  ori r4, r4, 0xf000
	ctx.r[4].u64 = ctx.r[4].u64 | 61440;
	// 82209400: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209404: 4800047D  bl 0x82209880
	ctx.lr = 0x82209408;
	sub_82209880(ctx, base);
	// 82209408: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220940C: 38C00171  li r6, 0x171
	ctx.r[6].s64 = 369;
	// 82209410: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209414: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 82209418: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220941C: 48000465  bl 0x82209880
	ctx.lr = 0x82209420;
	sub_82209880(ctx, base);
	// 82209420: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 82209424: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209428: 38C00172  li r6, 0x172
	ctx.r[6].s64 = 370;
	// 8220942C: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209430: 60841000  ori r4, r4, 0x1000
	ctx.r[4].u64 = ctx.r[4].u64 | 4096;
	// 82209434: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209438: 48000449  bl 0x82209880
	ctx.lr = 0x8220943C;
	sub_82209880(ctx, base);
	// 8220943C: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 82209440: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209444: 38C00173  li r6, 0x173
	ctx.r[6].s64 = 371;
	// 82209448: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 8220944C: 60842000  ori r4, r4, 0x2000
	ctx.r[4].u64 = ctx.r[4].u64 | 8192;
	// 82209450: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209454: 4800042D  bl 0x82209880
	ctx.lr = 0x82209458;
	sub_82209880(ctx, base);
	// 82209458: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 8220945C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209460: 38C00174  li r6, 0x174
	ctx.r[6].s64 = 372;
	// 82209464: 38A01000  li r5, 0x1000
	ctx.r[5].s64 = 4096;
	// 82209468: 60843000  ori r4, r4, 0x3000
	ctx.r[4].u64 = ctx.r[4].u64 | 12288;
	// 8220946C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209470: 48000411  bl 0x82209880
	ctx.lr = 0x82209474;
	sub_82209880(ctx, base);
	// 82209474: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209478: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220947C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209480: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209484: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82209488: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220948C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209490(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209490 size=276
    let mut pc: u32 = 0x82209490;
    'dispatch: loop {
        match pc {
            0x82209490 => {
    //   block [0x82209490..0x822095A4)
	// 82209490: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209494: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209498: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220949C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822094A0: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 822094A4: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 822094A8: 3BEBE550  addi r31, r11, -0x1ab0
	ctx.r[31].s64 = ctx.r[11].s64 + -6832;
	// 822094AC: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 822094B0: 387F0080  addi r3, r31, 0x80
	ctx.r[3].s64 = ctx.r[31].s64 + 128;
	// 822094B4: 388B4410  addi r4, r11, 0x4410
	ctx.r[4].s64 = ctx.r[11].s64 + 17424;
	// 822094B8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822094BC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 822094C0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 822094C4: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 822094C8: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 822094CC: 997F0010  stb r11, 0x10(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u8 ) };
	// 822094D0: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 822094D4: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 822094D8: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 822094DC: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 822094E0: 997F0030  stb r11, 0x30(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[11].u8 ) };
	// 822094E4: 917F0040  stw r11, 0x40(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[11].u32 ) };
	// 822094E8: 917F0044  stw r11, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 822094EC: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 822094F0: 917F004C  stw r11, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 822094F4: 997F0050  stb r11, 0x50(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u8 ) };
	// 822094F8: 917F0060  stw r11, 0x60(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 822094FC: 917F0064  stw r11, 0x64(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 82209500: 917F0068  stw r11, 0x68(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 82209504: 917F006C  stw r11, 0x6c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 82209508: 997F0070  stb r11, 0x70(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), ctx.r[11].u8 ) };
	// 8220950C: 997F0080  stb r11, 0x80(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[11].u8 ) };
	// 82209510: 483296B1  bl 0x82532bc0
	ctx.lr = 0x82209514;
	sub_82532BC0(ctx, base);
	// 82209514: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209518: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 8220951C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209520: 38C00177  li r6, 0x177
	ctx.r[6].s64 = 375;
	// 82209524: 38A00040  li r5, 0x40
	ctx.r[5].s64 = 64;
	// 82209528: 60844010  ori r4, r4, 0x4010
	ctx.r[4].u64 = ctx.r[4].u64 | 16400;
	// 8220952C: 997F008F  stb r11, 0x8f(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(143 as u32), ctx.r[11].u8 ) };
	// 82209530: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209534: 48000405  bl 0x82209938
	ctx.lr = 0x82209538;
	sub_82209938(ctx, base);
	// 82209538: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 8220953C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209540: 38C00178  li r6, 0x178
	ctx.r[6].s64 = 376;
	// 82209544: 38A00040  li r5, 0x40
	ctx.r[5].s64 = 64;
	// 82209548: 60844050  ori r4, r4, 0x4050
	ctx.r[4].u64 = ctx.r[4].u64 | 16464;
	// 8220954C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209550: 480003E9  bl 0x82209938
	ctx.lr = 0x82209554;
	sub_82209938(ctx, base);
	// 82209554: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 82209558: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8220955C: 38C00179  li r6, 0x179
	ctx.r[6].s64 = 377;
	// 82209560: 38A00040  li r5, 0x40
	ctx.r[5].s64 = 64;
	// 82209564: 60844090  ori r4, r4, 0x4090
	ctx.r[4].u64 = ctx.r[4].u64 | 16528;
	// 82209568: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220956C: 480003CD  bl 0x82209938
	ctx.lr = 0x82209570;
	sub_82209938(ctx, base);
	// 82209570: 3C800606  lis r4, 0x606
	ctx.r[4].s64 = 101056512;
	// 82209574: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82209578: 38C0017A  li r6, 0x17a
	ctx.r[6].s64 = 378;
	// 8220957C: 38A00040  li r5, 0x40
	ctx.r[5].s64 = 64;
	// 82209580: 608440D0  ori r4, r4, 0x40d0
	ctx.r[4].u64 = ctx.r[4].u64 | 16592;
	// 82209584: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209588: 480003B1  bl 0x82209938
	ctx.lr = 0x8220958C;
	sub_82209938(ctx, base);
	// 8220958C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209590: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82209594: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209598: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220959C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822095A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822095A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822095A8 size=180
    let mut pc: u32 = 0x822095A8;
    'dispatch: loop {
        match pc {
            0x822095A8 => {
    //   block [0x822095A8..0x8220965C)
	// 822095A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822095AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822095B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 822095B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 822095B8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822095BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822095C0: 90810050  stw r4, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[4].u32 ) };
	// 822095C4: 90A10054  stw r5, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[5].u32 ) };
	// 822095C8: 3BFE0040  addi r31, r30, 0x40
	ctx.r[31].s64 = ctx.r[30].s64 + 64;
	// 822095CC: 90C10058  stw r6, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[6].u32 ) };
	// 822095D0: 90E1005C  stw r7, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[7].u32 ) };
	// 822095D4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 822095D8: 419A001C  beq cr6, 0x822095f4
	if ctx.cr[6].eq {
	pc = 0x822095F4; continue 'dispatch;
	}
	// 822095DC: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 822095E0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822095E4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 822095E8: 483295D9  bl 0x82532bc0
	ctx.lr = 0x822095EC;
	sub_82532BC0(ctx, base);
	// 822095EC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822095F0: 9961006F  stb r11, 0x6f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(111 as u32), ctx.r[11].u8 ) };
	// 822095F4: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 822095F8: 7F1EF840  cmplw cr6, r30, r31
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[31].u32, &mut ctx.xer);
	// 822095FC: 419A001C  beq cr6, 0x82209618
	if ctx.cr[6].eq {
	pc = 0x82209618; continue 'dispatch;
	}
	// 82209600: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209604: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82209608: 419A002C  beq cr6, 0x82209634
	if ctx.cr[6].eq {
	pc = 0x82209634; continue 'dispatch;
	}
	// 8220960C: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 82209610: 7F0BF840  cmplw cr6, r11, r31
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[31].u32, &mut ctx.xer);
	// 82209614: 409AFFEC  bne cr6, 0x82209600
	if !ctx.cr[6].eq {
	pc = 0x82209600; continue 'dispatch;
	}
	// 82209618: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220961C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82209620: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209624: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209628: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220962C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82209630: 4E800020  blr
	return;
	// 82209634: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 82209638: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 8220963C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 82209640: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209644: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82209648: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8220964C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82209650: 4200FFF0  bdnz 0x82209640
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82209640; continue 'dispatch;
	}
	// 82209654: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82209658: 4BFFFFC4  b 0x8220961c
	pc = 0x8220961C; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82209660 size=172
    let mut pc: u32 = 0x82209660;
    'dispatch: loop {
        match pc {
            0x82209660 => {
    //   block [0x82209660..0x8220970C)
	// 82209660: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209664: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82209668: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220966C: 91630008  stw r11, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82209670: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82209674: 99630010  stb r11, 0x10(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u8 ) };
	// 82209678: 91630020  stw r11, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 8220967C: 91630024  stw r11, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 82209680: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 82209684: 9163002C  stw r11, 0x2c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 82209688: 99630030  stb r11, 0x30(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), ctx.r[11].u8 ) };
	// 8220968C: 91630040  stw r11, 0x40(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(64 as u32), ctx.r[11].u32 ) };
	// 82209690: 91630044  stw r11, 0x44(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 82209694: 91630048  stw r11, 0x48(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 82209698: 9163004C  stw r11, 0x4c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8220969C: 99630050  stb r11, 0x50(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(80 as u32), ctx.r[11].u8 ) };
	// 822096A0: 91630060  stw r11, 0x60(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 822096A4: 91630064  stw r11, 0x64(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 822096A8: 91630068  stw r11, 0x68(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 822096AC: 9163006C  stw r11, 0x6c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 822096B0: 99630070  stb r11, 0x70(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(112 as u32), ctx.r[11].u8 ) };
	// 822096B4: 91630080  stw r11, 0x80(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 822096B8: 91630084  stw r11, 0x84(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 822096BC: 91630088  stw r11, 0x88(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), ctx.r[11].u32 ) };
	// 822096C0: 9163008C  stw r11, 0x8c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 822096C4: 99630090  stb r11, 0x90(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(144 as u32), ctx.r[11].u8 ) };
	// 822096C8: 916300A0  stw r11, 0xa0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 822096CC: 916300A4  stw r11, 0xa4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 822096D0: 916300A8  stw r11, 0xa8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(168 as u32), ctx.r[11].u32 ) };
	// 822096D4: 916300AC  stw r11, 0xac(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 822096D8: 996300B0  stb r11, 0xb0(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(176 as u32), ctx.r[11].u8 ) };
	// 822096DC: 916300C0  stw r11, 0xc0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 822096E0: 916300C4  stw r11, 0xc4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 822096E4: 916300C8  stw r11, 0xc8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 822096E8: 916300CC  stw r11, 0xcc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 822096EC: 996300D0  stb r11, 0xd0(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(208 as u32), ctx.r[11].u8 ) };
	// 822096F0: 916300E0  stw r11, 0xe0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(224 as u32), ctx.r[11].u32 ) };
	// 822096F4: 916300E4  stw r11, 0xe4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 822096F8: 916300E8  stw r11, 0xe8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 822096FC: 916300EC  stw r11, 0xec(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 82209700: 996300F0  stb r11, 0xf0(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(240 as u32), ctx.r[11].u8 ) };
	// 82209704: 99630100  stb r11, 0x100(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(256 as u32), ctx.r[11].u8 ) };
	// 82209708: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209710(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209710 size=184
    let mut pc: u32 = 0x82209710;
    'dispatch: loop {
        match pc {
            0x82209710 => {
    //   block [0x82209710..0x822097C8)
	// 82209710: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209714: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209718: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220971C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82209720: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209724: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82209728: 90810050  stw r4, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[4].u32 ) };
	// 8220972C: 3D600020  lis r11, 0x20
	ctx.r[11].s64 = 2097152;
	// 82209730: 90C10058  stw r6, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[6].u32 ) };
	// 82209734: 3BFE0100  addi r31, r30, 0x100
	ctx.r[31].s64 = ctx.r[30].s64 + 256;
	// 82209738: 90E1005C  stw r7, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[7].u32 ) };
	// 8220973C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82209740: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82209744: 419A001C  beq cr6, 0x82209760
	if ctx.cr[6].eq {
	pc = 0x82209760; continue 'dispatch;
	}
	// 82209748: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 8220974C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82209750: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82209754: 4832946D  bl 0x82532bc0
	ctx.lr = 0x82209758;
	sub_82532BC0(ctx, base);
	// 82209758: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220975C: 9961006F  stb r11, 0x6f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(111 as u32), ctx.r[11].u8 ) };
	// 82209760: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82209764: 7F1EF840  cmplw cr6, r30, r31
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[31].u32, &mut ctx.xer);
	// 82209768: 419A001C  beq cr6, 0x82209784
	if ctx.cr[6].eq {
	pc = 0x82209784; continue 'dispatch;
	}
	// 8220976C: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209770: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82209774: 419A002C  beq cr6, 0x822097a0
	if ctx.cr[6].eq {
	pc = 0x822097A0; continue 'dispatch;
	}
	// 82209778: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 8220977C: 7F0BF840  cmplw cr6, r11, r31
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[31].u32, &mut ctx.xer);
	// 82209780: 409AFFEC  bne cr6, 0x8220976c
	if !ctx.cr[6].eq {
	pc = 0x8220976C; continue 'dispatch;
	}
	// 82209784: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209788: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8220978C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209790: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209794: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82209798: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220979C: 4E800020  blr
	return;
	// 822097A0: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 822097A4: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 822097A8: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 822097AC: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822097B0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 822097B4: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 822097B8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 822097BC: 4200FFF0  bdnz 0x822097ac
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822097AC; continue 'dispatch;
	}
	// 822097C0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 822097C4: 4BFFFFC4  b 0x82209788
	pc = 0x82209788; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822097C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822097C8 size=184
    let mut pc: u32 = 0x822097C8;
    'dispatch: loop {
        match pc {
            0x822097C8 => {
    //   block [0x822097C8..0x82209880)
	// 822097C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822097CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822097D0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 822097D4: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822097D8: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 822097DC: 90C10058  stw r6, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[6].u32 ) };
	// 822097E0: 3D4082CF  lis r10, -0x7d31
	ctx.r[10].s64 = -2100363264;
	// 822097E4: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 822097E8: 3BEAECB0  addi r31, r10, -0x1350
	ctx.r[31].s64 = ctx.r[10].s64 + -4944;
	// 822097EC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 822097F0: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 822097F4: 39600400  li r11, 0x400
	ctx.r[11].s64 = 1024;
	// 822097F8: 389F0200  addi r4, r31, 0x200
	ctx.r[4].s64 = ctx.r[31].s64 + 512;
	// 822097FC: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82209800: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82209804: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 82209808: 483293B9  bl 0x82532bc0
	ctx.lr = 0x8220980C;
	sub_82532BC0(ctx, base);
	// 8220980C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209810: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 82209814: 9861006F  stb r3, 0x6f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(111 as u32), ctx.r[3].u8 ) };
	// 82209818: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220981C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82209820: 419A0028  beq cr6, 0x82209848
	if ctx.cr[6].eq {
	pc = 0x82209848; continue 'dispatch;
	}
	// 82209824: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 82209828: 395F0200  addi r10, r31, 0x200
	ctx.r[10].s64 = ctx.r[31].s64 + 512;
	// 8220982C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82209830: 409AFFE8  bne cr6, 0x82209818
	if !ctx.cr[6].eq {
	pc = 0x82209818; continue 'dispatch;
	}
	// 82209834: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82209838: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220983C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209840: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82209844: 4E800020  blr
	return;
	// 82209848: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 8220984C: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82209850: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 82209854: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209858: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8220985C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82209860: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82209864: 4200FFF0  bdnz 0x82209854
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82209854; continue 'dispatch;
	}
	// 82209868: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220986C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82209870: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209874: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209878: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220987C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209880(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209880 size=184
    let mut pc: u32 = 0x82209880;
    'dispatch: loop {
        match pc {
            0x82209880 => {
    //   block [0x82209880..0x82209938)
	// 82209880: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209884: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209888: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220988C: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209890: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 82209894: 90C10058  stw r6, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[6].u32 ) };
	// 82209898: 3D4082CF  lis r10, -0x7d31
	ctx.r[10].s64 = -2100363264;
	// 8220989C: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 822098A0: 3BEAE740  addi r31, r10, -0x18c0
	ctx.r[31].s64 = ctx.r[10].s64 + -6336;
	// 822098A4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 822098A8: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 822098AC: 39601000  li r11, 0x1000
	ctx.r[11].s64 = 4096;
	// 822098B0: 389F0400  addi r4, r31, 0x400
	ctx.r[4].s64 = ctx.r[31].s64 + 1024;
	// 822098B4: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 822098B8: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 822098BC: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 822098C0: 48329301  bl 0x82532bc0
	ctx.lr = 0x822098C4;
	sub_82532BC0(ctx, base);
	// 822098C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822098C8: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 822098CC: 9861006F  stb r3, 0x6f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(111 as u32), ctx.r[3].u8 ) };
	// 822098D0: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 822098D4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822098D8: 419A0028  beq cr6, 0x82209900
	if ctx.cr[6].eq {
	pc = 0x82209900; continue 'dispatch;
	}
	// 822098DC: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 822098E0: 395F0400  addi r10, r31, 0x400
	ctx.r[10].s64 = ctx.r[31].s64 + 1024;
	// 822098E4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 822098E8: 409AFFE8  bne cr6, 0x822098d0
	if !ctx.cr[6].eq {
	pc = 0x822098D0; continue 'dispatch;
	}
	// 822098EC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 822098F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 822098F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 822098F8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822098FC: 4E800020  blr
	return;
	// 82209900: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 82209904: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82209908: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8220990C: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209910: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82209914: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82209918: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8220991C: 4200FFF0  bdnz 0x8220990c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8220990C; continue 'dispatch;
	}
	// 82209920: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82209924: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82209928: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220992C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209930: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82209934: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209938(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209938 size=184
    let mut pc: u32 = 0x82209938;
    'dispatch: loop {
        match pc {
            0x82209938 => {
    //   block [0x82209938..0x822099F0)
	// 82209938: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220993C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209940: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82209944: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209948: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8220994C: 90C10058  stw r6, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[6].u32 ) };
	// 82209950: 3D4082CF  lis r10, -0x7d31
	ctx.r[10].s64 = -2100363264;
	// 82209954: 38A0000F  li r5, 0xf
	ctx.r[5].s64 = 15;
	// 82209958: 3BEAE550  addi r31, r10, -0x1ab0
	ctx.r[31].s64 = ctx.r[10].s64 + -6832;
	// 8220995C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82209960: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82209964: 39600040  li r11, 0x40
	ctx.r[11].s64 = 64;
	// 82209968: 389F0080  addi r4, r31, 0x80
	ctx.r[4].s64 = ctx.r[31].s64 + 128;
	// 8220996C: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82209970: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82209974: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 82209978: 48329249  bl 0x82532bc0
	ctx.lr = 0x8220997C;
	sub_82532BC0(ctx, base);
	// 8220997C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209980: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 82209984: 9861006F  stb r3, 0x6f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(111 as u32), ctx.r[3].u8 ) };
	// 82209988: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220998C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82209990: 419A0028  beq cr6, 0x822099b8
	if ctx.cr[6].eq {
	pc = 0x822099B8; continue 'dispatch;
	}
	// 82209994: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 82209998: 395F0080  addi r10, r31, 0x80
	ctx.r[10].s64 = ctx.r[31].s64 + 128;
	// 8220999C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 822099A0: 409AFFE8  bne cr6, 0x82209988
	if !ctx.cr[6].eq {
	pc = 0x82209988; continue 'dispatch;
	}
	// 822099A4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 822099A8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 822099AC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 822099B0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822099B4: 4E800020  blr
	return;
	// 822099B8: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 822099BC: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 822099C0: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 822099C4: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822099C8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 822099CC: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 822099D0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 822099D4: 4200FFF0  bdnz 0x822099c4
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822099C4; continue 'dispatch;
	}
	// 822099D8: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 822099DC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 822099E0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 822099E4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 822099E8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822099EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822099F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822099F0 size=240
    let mut pc: u32 = 0x822099F0;
    'dispatch: loop {
        match pc {
            0x822099F0 => {
    //   block [0x822099F0..0x82209AE0)
	// 822099F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822099F4: 4832B6C5  bl 0x825350b8
	ctx.lr = 0x822099F8;
	sub_82535080(ctx, base);
	// 822099F8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822099FC: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 82209A00: 3C80820C  lis r4, -0x7df4
	ctx.r[4].s64 = -2113142784;
	// 82209A04: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 82209A08: 3BC43B80  addi r30, r4, 0x3b80
	ctx.r[30].s64 = ctx.r[4].s64 + 15232;
	// 82209A0C: 3C808288  lis r4, -0x7d78
	ctx.r[4].s64 = -2105016320;
	// 82209A10: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82209A14: 3BA48E38  addi r29, r4, -0x71c8
	ctx.r[29].s64 = ctx.r[4].s64 + -29128;
	// 82209A18: C00BBA38  lfs f0, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82209A1C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209A20: 395F0090  addi r10, r31, 0x90
	ctx.r[10].s64 = ctx.r[31].s64 + 144;
	// 82209A24: 3D208288  lis r9, -0x7d78
	ctx.r[9].s64 = -2105016320;
	// 82209A28: 3B800003  li r28, 3
	ctx.r[28].s64 = 3;
	// 82209A2C: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 82209A30: 3BA00004  li r29, 4
	ctx.r[29].s64 = 4;
	// 82209A34: 38E98E40  addi r7, r9, -0x71c0
	ctx.r[7].s64 = ctx.r[9].s64 + -29120;
	// 82209A38: B1610056  sth r11, 0x56(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(86 as u32), ctx.r[11].u16 ) };
	// 82209A3C: F96A0000  std r11, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 82209A40: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 82209A44: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 82209A48: 387F00E0  addi r3, r31, 0xe0
	ctx.r[3].s64 = ctx.r[31].s64 + 224;
	// 82209A4C: F96A0010  std r11, 0x10(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 82209A50: 38C9441C  addi r6, r9, 0x441c
	ctx.r[6].s64 = ctx.r[9].s64 + 17436;
	// 82209A54: F96A0018  std r11, 0x18(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(24 as u32), ctx.r[11].u64 ) };
	// 82209A58: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82209A5C: F96A0020  std r11, 0x20(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(32 as u32), ctx.r[11].u64 ) };
	// 82209A60: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82209A64: F96A0028  std r11, 0x28(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), ctx.r[11].u64 ) };
	// 82209A68: F96A0030  std r11, 0x30(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(48 as u32), ctx.r[11].u64 ) };
	// 82209A6C: F96A0038  std r11, 0x38(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(56 as u32), ctx.r[11].u64 ) };
	// 82209A70: 916A0040  stw r11, 0x40(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(64 as u32), ctx.r[11].u32 ) };
	// 82209A74: B16A0044  sth r11, 0x44(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(68 as u32), ctx.r[11].u16 ) };
	// 82209A78: B16A0046  sth r11, 0x46(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(70 as u32), ctx.r[11].u16 ) };
	// 82209A7C: D01F008C  stfs f0, 0x8c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82209A80: B3A10054  sth r29, 0x54(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[29].u16 ) };
	// 82209A84: A3BF0014  lhz r29, 0x14(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 82209A88: 911F0080  stw r8, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[8].u32 ) };
	// 82209A8C: 539D1EDE  rlwimi r29, r28, 3, 0x1b, 0xf
	ctx.r[29].u64 = (((ctx.r[28].u32).rotate_left(3) as u64) & 0xFFFFFFFFFFFF001F) | (ctx.r[29].u64 & 0x000000000000FFE0);
	// 82209A90: 913F0084  stw r9, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[9].u32 ) };
	// 82209A94: 993F001D  stb r9, 0x1d(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(29 as u32), ctx.r[9].u8 ) };
	// 82209A98: 993F001E  stb r9, 0x1e(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(30 as u32), ctx.r[9].u8 ) };
	// 82209A9C: 90FF00D0  stw r7, 0xd0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[7].u32 ) };
	// 82209AA0: B3BF0014  sth r29, 0x14(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u16 ) };
	// 82209AA4: 916A0048  stw r11, 0x48(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 82209AA8: 916A004C  stw r11, 0x4c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 82209AAC: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82209AB0: 93C30000  stw r30, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 82209AB4: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82209AB8: B1630008  sth r11, 8(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u16 ) };
	// 82209ABC: B163000A  sth r11, 0xa(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(10 as u32), ctx.r[11].u16 ) };
	// 82209AC0: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82209AC4: B1630010  sth r11, 0x10(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u16 ) };
	// 82209AC8: B1630012  sth r11, 0x12(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(18 as u32), ctx.r[11].u16 ) };
	// 82209ACC: 90BF0088  stw r5, 0x88(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(136 as u32), ctx.r[5].u32 ) };
	// 82209AD0: 48000129  bl 0x82209bf8
	ctx.lr = 0x82209AD4;
	sub_82209BF8(ctx, base);
	// 82209AD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82209AD8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82209ADC: 4832B62C  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209AE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209AE0 size=188
    let mut pc: u32 = 0x82209AE0;
    'dispatch: loop {
        match pc {
            0x82209AE0 => {
    //   block [0x82209AE0..0x82209B9C)
	// 82209AE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209AE4: 4832B5D9  bl 0x825350bc
	ctx.lr = 0x82209AE8;
	sub_82535080(ctx, base);
	// 82209AE8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209AEC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82209AF0: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82209AF4: 997F001C  stb r11, 0x1c(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u8 ) };
	// 82209AF8: 4BFFA889  bl 0x82204380
	ctx.lr = 0x82209AFC;
	sub_82204380(ctx, base);
	// 82209AFC: 817F00F4  lwz r11, 0xf4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(244 as u32) ) } as u64;
	// 82209B00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209B04: 419A0090  beq cr6, 0x82209b94
	if ctx.cr[6].eq {
	pc = 0x82209B94; continue 'dispatch;
	}
	// 82209B08: 807F0080  lwz r3, 0x80(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) } as u64;
	// 82209B0C: 83DF00FC  lwz r30, 0xfc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(252 as u32) ) } as u64;
	// 82209B10: 83BF00F8  lwz r29, 0xf8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(248 as u32) ) } as u64;
	// 82209B14: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82209B18: 419A007C  beq cr6, 0x82209b94
	if ctx.cr[6].eq {
	pc = 0x82209B94; continue 'dispatch;
	}
	// 82209B1C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209B20: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82209B24: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209B28: 4E800421  bctrl
	ctx.lr = 0x82209B2C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209B2C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82209B30: 419A0064  beq cr6, 0x82209b94
	if ctx.cr[6].eq {
	pc = 0x82209B94; continue 'dispatch;
	}
	// 82209B34: 817F0080  lwz r11, 0x80(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) } as u64;
	// 82209B38: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209B3C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82209B40: 409A000C  bne cr6, 0x82209b4c
	if !ctx.cr[6].eq {
	pc = 0x82209B4C; continue 'dispatch;
	}
	// 82209B44: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209B48: 4800002C  b 0x82209b74
	pc = 0x82209B74; continue 'dispatch;
	// 82209B4C: 812A0008  lwz r9, 8(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82209B50: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209B54: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82209B58: 419A000C  beq cr6, 0x82209b64
	if ctx.cr[6].eq {
	pc = 0x82209B64; continue 'dispatch;
	}
	// 82209B5C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209B60: 48000014  b 0x82209b74
	pc = 0x82209B74; continue 'dispatch;
	// 82209B64: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209B68: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82209B6C: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82209B70: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82209B74: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82209B78: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209B7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209B80: 419A0008  beq cr6, 0x82209b88
	if ctx.cr[6].eq {
	pc = 0x82209B88; continue 'dispatch;
	}
	// 82209B84: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209B88: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82209B8C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82209B90: 48172A31  bl 0x8237c5c0
	ctx.lr = 0x82209B94;
	sub_8237C5C0(ctx, base);
	// 82209B94: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82209B98: 4832B574  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209BA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82209BA0 size=16
    let mut pc: u32 = 0x82209BA0;
    'dispatch: loop {
        match pc {
            0x82209BA0 => {
    //   block [0x82209BA0..0x82209BB0)
	// 82209BA0: 3D6082C0  lis r11, -0x7d40
	ctx.r[11].s64 = -2101346304;
	// 82209BA4: 896BBFF0  lbz r11, -0x4010(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(-16400 as u32) ) } as u64;
	// 82209BA8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209BAC: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209BB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82209BB0 size=24
    let mut pc: u32 = 0x82209BB0;
    'dispatch: loop {
        match pc {
            0x82209BB0 => {
    //   block [0x82209BB0..0x82209BC8)
	// 82209BB0: A1630014  lhz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82209BB4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82209BB8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82209BBC: 514B552A  rlwimi r11, r10, 0xa, 0x14, 0x15
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(10) as u64) & 0x0000000000000C00) | (ctx.r[11].u64 & 0xFFFFFFFFFFFFF3FF);
	// 82209BC0: B1630014  sth r11, 0x14(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[11].u16 ) };
	// 82209BC4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209BC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209BC8 size=44
    let mut pc: u32 = 0x82209BC8;
    'dispatch: loop {
        match pc {
            0x82209BC8 => {
    //   block [0x82209BC8..0x82209BF4)
	// 82209BC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209BCC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82209BD0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209BD4: 4815C68D  bl 0x82366260
	ctx.lr = 0x82209BD8;
	sub_82366260(ctx, base);
	// 82209BD8: 3D4082A2  lis r10, -0x7d5e
	ctx.r[10].s64 = -2103312384;
	// 82209BDC: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 82209BE0: 916A01B8  stw r11, 0x1b8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(440 as u32), ctx.r[11].u32 ) };
	// 82209BE4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82209BE8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82209BEC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82209BF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209BF8 size=284
    let mut pc: u32 = 0x82209BF8;
    'dispatch: loop {
        match pc {
            0x82209BF8 => {
    //   block [0x82209BF8..0x82209D14)
	// 82209BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209BFC: 4832B4C1  bl 0x825350bc
	ctx.lr = 0x82209C00;
	sub_82535080(ctx, base);
	// 82209C00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209C04: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82209C08: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82209C0C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C10: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C14: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209C18: 4E800421  bctrl
	ctx.lr = 0x82209C1C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209C1C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C20: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82209C24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82209C28: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209C2C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209C30: 4E800421  bctrl
	ctx.lr = 0x82209C34;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209C34: 7F1F1840  cmplw cr6, r31, r3
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[3].u32, &mut ctx.xer);
	// 82209C38: 40980054  bge cr6, 0x82209c8c
	if !ctx.cr[6].lt {
	pc = 0x82209C8C; continue 'dispatch;
	}
	// 82209C3C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C40: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C44: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82209C48: 409A0024  bne cr6, 0x82209c6c
	if !ctx.cr[6].eq {
	pc = 0x82209C6C; continue 'dispatch;
	}
	// 82209C4C: A17F0004  lhz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209C50: A15D0004  lhz r10, 4(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209C54: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82209C58: 409A0014  bne cr6, 0x82209c6c
	if !ctx.cr[6].eq {
	pc = 0x82209C6C; continue 'dispatch;
	}
	// 82209C5C: A17F0006  lhz r11, 6(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(6 as u32) ) } as u64;
	// 82209C60: A15D0006  lhz r10, 6(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(6 as u32) ) } as u64;
	// 82209C64: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82209C68: 419A0084  beq cr6, 0x82209cec
	if ctx.cr[6].eq {
	pc = 0x82209CEC; continue 'dispatch;
	}
	// 82209C6C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C70: 3BFF0008  addi r31, r31, 8
	ctx.r[31].s64 = ctx.r[31].s64 + 8;
	// 82209C74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82209C78: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209C7C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209C80: 4E800421  bctrl
	ctx.lr = 0x82209C84;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209C84: 7F1F1840  cmplw cr6, r31, r3
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[3].u32, &mut ctx.xer);
	// 82209C88: 4198FFB4  blt cr6, 0x82209c3c
	if ctx.cr[6].lt {
	pc = 0x82209C3C; continue 'dispatch;
	}
	// 82209C8C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C90: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82209C94: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209C98: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209C9C: 4E800421  bctrl
	ctx.lr = 0x82209CA0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209CA0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209CA4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82209CA8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82209CAC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209CB0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209CB4: 4E800421  bctrl
	ctx.lr = 0x82209CB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209CB8: 7F1F1840  cmplw cr6, r31, r3
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[3].u32, &mut ctx.xer);
	// 82209CBC: 40980030  bge cr6, 0x82209cec
	if !ctx.cr[6].lt {
	pc = 0x82209CEC; continue 'dispatch;
	}
	// 82209CC0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209CC4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82209CC8: 419A0030  beq cr6, 0x82209cf8
	if ctx.cr[6].eq {
	pc = 0x82209CF8; continue 'dispatch;
	}
	// 82209CCC: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209CD0: 3BFF0008  addi r31, r31, 8
	ctx.r[31].s64 = ctx.r[31].s64 + 8;
	// 82209CD4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82209CD8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209CDC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82209CE0: 4E800421  bctrl
	ctx.lr = 0x82209CE4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82209CE4: 7F1F1840  cmplw cr6, r31, r3
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[3].u32, &mut ctx.xer);
	// 82209CE8: 4198FFD8  blt cr6, 0x82209cc0
	if ctx.cr[6].lt {
	pc = 0x82209CC0; continue 'dispatch;
	}
	// 82209CEC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209CF0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82209CF4: 4832B418  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 82209CF8: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209CFC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82209D00: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82209D04: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209D08: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82209D0C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82209D10: 4832B3FC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209D18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209D18 size=252
    let mut pc: u32 = 0x82209D18;
    'dispatch: loop {
        match pc {
            0x82209D18 => {
    //   block [0x82209D18..0x82209E14)
	// 82209D18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209D1C: 4832B391  bl 0x825350ac
	ctx.lr = 0x82209D20;
	sub_82535080(ctx, base);
	// 82209D20: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209D24: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209D28: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82209D2C: A3230004  lhz r25, 4(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209D30: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82209D34: A3430006  lhz r26, 6(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(6 as u32) ) } as u64;
	// 82209D38: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 82209D3C: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 82209D40: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209D44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209D48: 419A0014  beq cr6, 0x82209d5c
	if ctx.cr[6].eq {
	pc = 0x82209D5C; continue 'dispatch;
	}
	// 82209D4C: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209D50: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209D54: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209D58: 419A000C  beq cr6, 0x82209d64
	if ctx.cr[6].eq {
	pc = 0x82209D64; continue 'dispatch;
	}
	// 82209D5C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209D60: 48000008  b 0x82209d68
	pc = 0x82209D68; continue 'dispatch;
	// 82209D64: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209D68: 38A00020  li r5, 0x20
	ctx.r[5].s64 = 32;
	// 82209D6C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82209D70: 48173BD1  bl 0x8237d940
	ctx.lr = 0x82209D74;
	sub_8237D940(ctx, base);
	// 82209D74: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82209D78: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 82209D7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209D80: 419A0024  beq cr6, 0x82209da4
	if ctx.cr[6].eq {
	pc = 0x82209DA4; continue 'dispatch;
	}
	// 82209D84: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 82209D88: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82209D8C: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82209D90: 394A4450  addi r10, r10, 0x4450
	ctx.r[10].s64 = ctx.r[10].s64 + 17488;
	// 82209D94: 938B000C  stw r28, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 82209D98: 936B0010  stw r27, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[27].u32 ) };
	// 82209D9C: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82209DA0: 48000008  b 0x82209da8
	pc = 0x82209DA8; continue 'dispatch;
	// 82209DA4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209DA8: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82209DAC: B3450002  sth r26, 2(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(2 as u32), ctx.r[26].u16 ) };
	// 82209DB0: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82209DB4: B3C50000  sth r30, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[30].u16 ) };
	// 82209DB8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209DBC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209DC0: 419A0020  beq cr6, 0x82209de0
	if ctx.cr[6].eq {
	pc = 0x82209DE0; continue 'dispatch;
	}
	// 82209DC4: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209DC8: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209DCC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209DD0: 409A0010  bne cr6, 0x82209de0
	if !ctx.cr[6].eq {
	pc = 0x82209DE0; continue 'dispatch;
	}
	// 82209DD4: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 82209DD8: 386B0050  addi r3, r11, 0x50
	ctx.r[3].s64 = ctx.r[11].s64 + 80;
	// 82209DDC: 4817A3F5  bl 0x823841d0
	ctx.lr = 0x82209DE0;
	sub_823841D0(ctx, base);
	// 82209DE0: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 82209DE4: 419A0014  beq cr6, 0x82209df8
	if ctx.cr[6].eq {
	pc = 0x82209DF8; continue 'dispatch;
	}
	// 82209DE8: 7F6B0034  cntlzw r11, r27
	ctx.r[11].u64 = if ctx.r[27].u32 == 0 { 32 } else { ctx.r[27].u32.leading_zeros() as u64 };
	// 82209DEC: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 82209DF0: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 82209DF4: 41980008  blt cr6, 0x82209dfc
	if ctx.cr[6].lt {
	pc = 0x82209DFC; continue 'dispatch;
	}
	// 82209DF8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209DFC: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 82209E00: 394A4A00  addi r10, r10, 0x4a00
	ctx.r[10].s64 = ctx.r[10].s64 + 18944;
	// 82209E04: 394A00A0  addi r10, r10, 0xa0
	ctx.r[10].s64 = ctx.r[10].s64 + 160;
	// 82209E08: 7FCB51AE  stbx r30, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[30].u8) };
	// 82209E0C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 82209E10: 4832B2EC  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209E18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209E18 size=236
    let mut pc: u32 = 0x82209E18;
    'dispatch: loop {
        match pc {
            0x82209E18 => {
    //   block [0x82209E18..0x82209F04)
	// 82209E18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209E1C: 4832B299  bl 0x825350b4
	ctx.lr = 0x82209E20;
	sub_82535080(ctx, base);
	// 82209E20: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209E24: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209E28: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82209E2C: A3630004  lhz r27, 4(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209E30: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82209E34: A3A30006  lhz r29, 6(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(6 as u32) ) } as u64;
	// 82209E38: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209E3C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209E40: 419A0014  beq cr6, 0x82209e54
	if ctx.cr[6].eq {
	pc = 0x82209E54; continue 'dispatch;
	}
	// 82209E44: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209E48: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209E4C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209E50: 419A000C  beq cr6, 0x82209e5c
	if ctx.cr[6].eq {
	pc = 0x82209E5C; continue 'dispatch;
	}
	// 82209E54: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209E58: 48000008  b 0x82209e60
	pc = 0x82209E60; continue 'dispatch;
	// 82209E5C: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209E60: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82209E64: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82209E68: 48173AD9  bl 0x8237d940
	ctx.lr = 0x82209E6C;
	sub_8237D940(ctx, base);
	// 82209E6C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82209E70: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 82209E74: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209E78: 419A001C  beq cr6, 0x82209e94
	if ctx.cr[6].eq {
	pc = 0x82209E94; continue 'dispatch;
	}
	// 82209E7C: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 82209E80: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82209E84: 938B0008  stw r28, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 82209E88: 394A4454  addi r10, r10, 0x4454
	ctx.r[10].s64 = ctx.r[10].s64 + 17492;
	// 82209E8C: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82209E90: 48000008  b 0x82209e98
	pc = 0x82209E98; continue 'dispatch;
	// 82209E94: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209E98: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82209E9C: B3A50002  sth r29, 2(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(2 as u32), ctx.r[29].u16 ) };
	// 82209EA0: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82209EA4: B3C50000  sth r30, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[30].u16 ) };
	// 82209EA8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209EAC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209EB0: 419A0020  beq cr6, 0x82209ed0
	if ctx.cr[6].eq {
	pc = 0x82209ED0; continue 'dispatch;
	}
	// 82209EB4: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209EB8: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209EBC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209EC0: 409A0010  bne cr6, 0x82209ed0
	if !ctx.cr[6].eq {
	pc = 0x82209ED0; continue 'dispatch;
	}
	// 82209EC4: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82209EC8: 386B0050  addi r3, r11, 0x50
	ctx.r[3].s64 = ctx.r[11].s64 + 80;
	// 82209ECC: 4817A305  bl 0x823841d0
	ctx.lr = 0x82209ED0;
	sub_823841D0(ctx, base);
	// 82209ED0: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 82209ED4: 419A0014  beq cr6, 0x82209ee8
	if ctx.cr[6].eq {
	pc = 0x82209EE8; continue 'dispatch;
	}
	// 82209ED8: 7F8B0034  cntlzw r11, r28
	ctx.r[11].u64 = if ctx.r[28].u32 == 0 { 32 } else { ctx.r[28].u32.leading_zeros() as u64 };
	// 82209EDC: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 82209EE0: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 82209EE4: 41980008  blt cr6, 0x82209eec
	if ctx.cr[6].lt {
	pc = 0x82209EEC; continue 'dispatch;
	}
	// 82209EE8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209EEC: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 82209EF0: 394A4A00  addi r10, r10, 0x4a00
	ctx.r[10].s64 = ctx.r[10].s64 + 18944;
	// 82209EF4: 394A00A0  addi r10, r10, 0xa0
	ctx.r[10].s64 = ctx.r[10].s64 + 160;
	// 82209EF8: 7FCB51AE  stbx r30, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[30].u8) };
	// 82209EFC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82209F00: 4832B204  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82209F08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82209F08 size=260
    let mut pc: u32 = 0x82209F08;
    'dispatch: loop {
        match pc {
            0x82209F08 => {
    //   block [0x82209F08..0x8220A00C)
	// 82209F08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82209F0C: 4832B19D  bl 0x825350a8
	ctx.lr = 0x82209F10;
	sub_82535080(ctx, base);
	// 82209F10: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82209F14: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209F18: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82209F1C: A3030004  lhz r24, 4(r3)
	ctx.r[24].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209F20: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82209F24: A3230006  lhz r25, 6(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(6 as u32) ) } as u64;
	// 82209F28: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 82209F2C: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 82209F30: 7D1A4378  mr r26, r8
	ctx.r[26].u64 = ctx.r[8].u64;
	// 82209F34: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209F38: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209F3C: 419A0014  beq cr6, 0x82209f50
	if ctx.cr[6].eq {
	pc = 0x82209F50; continue 'dispatch;
	}
	// 82209F40: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209F44: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209F48: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209F4C: 419A000C  beq cr6, 0x82209f58
	if ctx.cr[6].eq {
	pc = 0x82209F58; continue 'dispatch;
	}
	// 82209F50: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82209F54: 48000008  b 0x82209f5c
	pc = 0x82209F5C; continue 'dispatch;
	// 82209F58: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82209F5C: 38A00020  li r5, 0x20
	ctx.r[5].s64 = 32;
	// 82209F60: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82209F64: 481739DD  bl 0x8237d940
	ctx.lr = 0x82209F68;
	sub_8237D940(ctx, base);
	// 82209F68: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82209F6C: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 82209F70: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209F74: 419A0028  beq cr6, 0x82209f9c
	if ctx.cr[6].eq {
	pc = 0x82209F9C; continue 'dispatch;
	}
	// 82209F78: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 82209F7C: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82209F80: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82209F84: 394A4458  addi r10, r10, 0x4458
	ctx.r[10].s64 = ctx.r[10].s64 + 17496;
	// 82209F88: 938B000C  stw r28, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 82209F8C: 936B0010  stw r27, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[27].u32 ) };
	// 82209F90: 934B0014  stw r26, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[26].u32 ) };
	// 82209F94: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82209F98: 48000008  b 0x82209fa0
	pc = 0x82209FA0; continue 'dispatch;
	// 82209F9C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209FA0: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82209FA4: B3250002  sth r25, 2(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(2 as u32), ctx.r[25].u16 ) };
	// 82209FA8: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82209FAC: B3C50000  sth r30, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[30].u16 ) };
	// 82209FB0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82209FB4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82209FB8: 419A0020  beq cr6, 0x82209fd8
	if ctx.cr[6].eq {
	pc = 0x82209FD8; continue 'dispatch;
	}
	// 82209FBC: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 82209FC0: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82209FC4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82209FC8: 409A0010  bne cr6, 0x82209fd8
	if !ctx.cr[6].eq {
	pc = 0x82209FD8; continue 'dispatch;
	}
	// 82209FCC: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 82209FD0: 386B0050  addi r3, r11, 0x50
	ctx.r[3].s64 = ctx.r[11].s64 + 80;
	// 82209FD4: 4817A1FD  bl 0x823841d0
	ctx.lr = 0x82209FD8;
	sub_823841D0(ctx, base);
	// 82209FD8: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 82209FDC: 419A0014  beq cr6, 0x82209ff0
	if ctx.cr[6].eq {
	pc = 0x82209FF0; continue 'dispatch;
	}
	// 82209FE0: 7F4B0034  cntlzw r11, r26
	ctx.r[11].u64 = if ctx.r[26].u32 == 0 { 32 } else { ctx.r[26].u32.leading_zeros() as u64 };
	// 82209FE4: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 82209FE8: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 82209FEC: 41980008  blt cr6, 0x82209ff4
	if ctx.cr[6].lt {
	pc = 0x82209FF4; continue 'dispatch;
	}
	// 82209FF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82209FF4: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 82209FF8: 394A4A00  addi r10, r10, 0x4a00
	ctx.r[10].s64 = ctx.r[10].s64 + 18944;
	// 82209FFC: 394A00A0  addi r10, r10, 0xa0
	ctx.r[10].s64 = ctx.r[10].s64 + 160;
	// 8220A000: 7FCB51AE  stbx r30, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[30].u8) };
	// 8220A004: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8220A008: 4832B0F0  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A010(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220A010 size=348
    let mut pc: u32 = 0x8220A010;
    'dispatch: loop {
        match pc {
            0x8220A010 => {
    //   block [0x8220A010..0x8220A16C)
	// 8220A010: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A014: 4832B099  bl 0x825350ac
	ctx.lr = 0x8220A018;
	sub_82535080(ctx, base);
	// 8220A018: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A01C: 83C30000  lwz r30, 0(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A020: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220A024: A3230004  lhz r25, 4(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A028: 7D3B4B78  mr r27, r9
	ctx.r[27].u64 = ctx.r[9].u64;
	// 8220A02C: A3430006  lhz r26, 6(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(6 as u32) ) } as u64;
	// 8220A030: 7D5C5378  mr r28, r10
	ctx.r[28].u64 = ctx.r[10].u64;
	// 8220A034: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A038: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A03C: 419A0014  beq cr6, 0x8220a050
	if ctx.cr[6].eq {
	pc = 0x8220A050; continue 'dispatch;
	}
	// 8220A040: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A044: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A048: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A04C: 419A000C  beq cr6, 0x8220a058
	if ctx.cr[6].eq {
	pc = 0x8220A058; continue 'dispatch;
	}
	// 8220A050: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A054: 48000008  b 0x8220a05c
	pc = 0x8220A05C; continue 'dispatch;
	// 8220A058: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A05C: 38A00070  li r5, 0x70
	ctx.r[5].s64 = 112;
	// 8220A060: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220A064: 481738DD  bl 0x8237d940
	ctx.lr = 0x8220A068;
	sub_8237D940(ctx, base);
	// 8220A068: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A06C: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8220A070: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8220A074: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A078: 419A0088  beq cr6, 0x8220a100
	if ctx.cr[6].eq {
	pc = 0x8220A100; continue 'dispatch;
	}
	// 8220A07C: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 8220A080: 93EB0004  stw r31, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[31].u32 ) };
	// 8220A084: 3D2082A1  lis r9, -0x7d5f
	ctx.r[9].s64 = -2103377920;
	// 8220A088: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 8220A08C: 394A445C  addi r10, r10, 0x445c
	ctx.r[10].s64 = ctx.r[10].s64 + 17500;
	// 8220A090: 38E96180  addi r7, r9, 0x6180
	ctx.r[7].s64 = ctx.r[9].s64 + 24960;
	// 8220A094: 392B0010  addi r9, r11, 0x10
	ctx.r[9].s64 = ctx.r[11].s64 + 16;
	// 8220A098: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8220A09C: 3D408311  lis r10, -0x7cef
	ctx.r[10].s64 = -2096037888;
	// 8220A0A0: 810A3F18  lwz r8, 0x3f18(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16152 as u32) ) } as u64;
	// 8220A0A4: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 8220A0A8: 38E00008  li r7, 8
	ctx.r[7].s64 = 8;
	// 8220A0AC: 910B000C  stw r8, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 8220A0B0: 7CE903A6  mtctr r7
	ctx.ctr.u64 = ctx.r[7].u64;
	// 8220A0B4: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 8220A0B8: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8220A0BC: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 8220A0C0: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 8220A0C4: 4200FFF0  bdnz 0x8220a0b4
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8220A0B4; continue 'dispatch;
	}
	// 8220A0C8: 3D208311  lis r9, -0x7cef
	ctx.r[9].s64 = -2096037888;
	// 8220A0CC: 814100F4  lwz r10, 0xf4(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(244 as u32) ) } as u64;
	// 8220A0D0: 390B0060  addi r8, r11, 0x60
	ctx.r[8].s64 = ctx.r[11].s64 + 96;
	// 8220A0D4: C1BC0000  lfs f13, 0(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220A0D8: C0093F14  lfs f0, 0x3f14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16148 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A0DC: 7D094378  mr r9, r8
	ctx.r[9].u64 = ctx.r[8].u64;
	// 8220A0E0: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 8220A0E4: D00B0050  stfs f0, 0x50(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220A0E8: E94A0008  ld r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	// 8220A0EC: D1AB0058  stfs f13, 0x58(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220A0F0: 936B0054  stw r27, 0x54(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(84 as u32), ctx.r[27].u32 ) };
	// 8220A0F4: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 8220A0F8: F9490008  std r10, 8(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[10].u64 ) };
	// 8220A0FC: 48000008  b 0x8220a104
	pc = 0x8220A104; continue 'dispatch;
	// 8220A100: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A104: B3450002  sth r26, 2(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(2 as u32), ctx.r[26].u16 ) };
	// 8220A108: B3A50000  sth r29, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[29].u16 ) };
	// 8220A10C: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220A110: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A114: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A118: 419A0020  beq cr6, 0x8220a138
	if ctx.cr[6].eq {
	pc = 0x8220A138; continue 'dispatch;
	}
	// 8220A11C: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A120: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A124: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A128: 409A0010  bne cr6, 0x8220a138
	if !ctx.cr[6].eq {
	pc = 0x8220A138; continue 'dispatch;
	}
	// 8220A12C: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 8220A130: 386B0050  addi r3, r11, 0x50
	ctx.r[3].s64 = ctx.r[11].s64 + 80;
	// 8220A134: 4817A09D  bl 0x823841d0
	ctx.lr = 0x8220A138;
	sub_823841D0(ctx, base);
	// 8220A138: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 8220A13C: 419A0014  beq cr6, 0x8220a150
	if ctx.cr[6].eq {
	pc = 0x8220A150; continue 'dispatch;
	}
	// 8220A140: 7F6B0034  cntlzw r11, r27
	ctx.r[11].u64 = if ctx.r[27].u32 == 0 { 32 } else { ctx.r[27].u32.leading_zeros() as u64 };
	// 8220A144: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 8220A148: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 8220A14C: 41980008  blt cr6, 0x8220a154
	if ctx.cr[6].lt {
	pc = 0x8220A154; continue 'dispatch;
	}
	// 8220A150: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A154: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 8220A158: 394A4A00  addi r10, r10, 0x4a00
	ctx.r[10].s64 = ctx.r[10].s64 + 18944;
	// 8220A15C: 394A00A0  addi r10, r10, 0xa0
	ctx.r[10].s64 = ctx.r[10].s64 + 160;
	// 8220A160: 7FAB51AE  stbx r29, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[29].u8) };
	// 8220A164: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8220A168: 4832AF94  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A170(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A170 size=228
    let mut pc: u32 = 0x8220A170;
    'dispatch: loop {
        match pc {
            0x8220A170 => {
    //   block [0x8220A170..0x8220A254)
	// 8220A170: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A174: 4832AF35  bl 0x825350a8
	ctx.lr = 0x8220A178;
	sub_82535080(ctx, base);
	// 8220A178: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A17C: 83430000  lwz r26, 0(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A180: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 8220A184: A3030004  lhz r24, 4(r3)
	ctx.r[24].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A188: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8220A18C: A3230006  lhz r25, 6(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(6 as u32) ) } as u64;
	// 8220A190: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 8220A194: 7D1C4378  mr r28, r8
	ctx.r[28].u64 = ctx.r[8].u64;
	// 8220A198: 7D3B4B78  mr r27, r9
	ctx.r[27].u64 = ctx.r[9].u64;
	// 8220A19C: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A1A0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A1A4: 419A0014  beq cr6, 0x8220a1b8
	if ctx.cr[6].eq {
	pc = 0x8220A1B8; continue 'dispatch;
	}
	// 8220A1A8: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A1AC: 813A0004  lwz r9, 4(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A1B0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A1B4: 419A000C  beq cr6, 0x8220a1c0
	if ctx.cr[6].eq {
	pc = 0x8220A1C0; continue 'dispatch;
	}
	// 8220A1B8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A1BC: 48000008  b 0x8220a1c4
	pc = 0x8220A1C4; continue 'dispatch;
	// 8220A1C0: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A1C4: 38A00020  li r5, 0x20
	ctx.r[5].s64 = 32;
	// 8220A1C8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220A1CC: 48173775  bl 0x8237d940
	ctx.lr = 0x8220A1D0;
	sub_8237D940(ctx, base);
	// 8220A1D0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A1D4: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8220A1D8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A1DC: 419A0034  beq cr6, 0x8220a210
	if ctx.cr[6].eq {
	pc = 0x8220A210; continue 'dispatch;
	}
	// 8220A1E0: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 8220A1E4: 93EB0008  stw r31, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 8220A1E8: 3D208287  lis r9, -0x7d79
	ctx.r[9].s64 = -2105081856;
	// 8220A1EC: 93CB000C  stw r30, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[30].u32 ) };
	// 8220A1F0: 394A4460  addi r10, r10, 0x4460
	ctx.r[10].s64 = ctx.r[10].s64 + 17504;
	// 8220A1F4: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 8220A1F8: 39297864  addi r9, r9, 0x7864
	ctx.r[9].s64 = ctx.r[9].s64 + 30820;
	// 8220A1FC: 938B0014  stw r28, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[28].u32 ) };
	// 8220A200: 936B0018  stw r27, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[27].u32 ) };
	// 8220A204: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8220A208: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8220A20C: 48000008  b 0x8220a214
	pc = 0x8220A214; continue 'dispatch;
	// 8220A210: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A214: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8220A218: B3250002  sth r25, 2(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(2 as u32), ctx.r[25].u16 ) };
	// 8220A21C: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220A220: B1250000  sth r9, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8220A224: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A228: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A22C: 419A0020  beq cr6, 0x8220a24c
	if ctx.cr[6].eq {
	pc = 0x8220A24C; continue 'dispatch;
	}
	// 8220A230: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A234: 813A0004  lwz r9, 4(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A238: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A23C: 409A0010  bne cr6, 0x8220a24c
	if !ctx.cr[6].eq {
	pc = 0x8220A24C; continue 'dispatch;
	}
	// 8220A240: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 8220A244: 386B0050  addi r3, r11, 0x50
	ctx.r[3].s64 = ctx.r[11].s64 + 80;
	// 8220A248: 48179F89  bl 0x823841d0
	ctx.lr = 0x8220A24C;
	sub_823841D0(ctx, base);
	// 8220A24C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8220A250: 4832AEA8  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A258(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A258 size=224
    let mut pc: u32 = 0x8220A258;
    'dispatch: loop {
        match pc {
            0x8220A258 => {
    //   block [0x8220A258..0x8220A338)
	// 8220A258: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A25C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A260: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220A264: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220A268: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A26C: 3D6082B6  lis r11, -0x7d4a
	ctx.r[11].s64 = -2102001664;
	// 8220A270: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220A274: 3BCBB5B4  addi r30, r11, -0x4a4c
	ctx.r[30].s64 = ctx.r[11].s64 + -19020;
	// 8220A278: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A27C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220A280: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A284: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A288: 419A0014  beq cr6, 0x8220a29c
	if ctx.cr[6].eq {
	pc = 0x8220A29C; continue 'dispatch;
	}
	// 8220A28C: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A290: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 8220A294: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 8220A298: 41980008  blt cr6, 0x8220a2a0
	if ctx.cr[6].lt {
	pc = 0x8220A2A0; continue 'dispatch;
	}
	// 8220A29C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A2A0: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 8220A2A4: 556B482C  slwi r11, r11, 9
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(9);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220A2A8: 394AFE00  addi r10, r10, -0x200
	ctx.r[10].s64 = ctx.r[10].s64 + -512;
	// 8220A2AC: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220A2B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A2B4: 419A0020  beq cr6, 0x8220a2d4
	if ctx.cr[6].eq {
	pc = 0x8220A2D4; continue 'dispatch;
	}
	// 8220A2B8: 556A073E  clrlwi r10, r11, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8220A2BC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A2C0: 409A000C  bne cr6, 0x8220a2cc
	if !ctx.cr[6].eq {
	pc = 0x8220A2CC; continue 'dispatch;
	}
	// 8220A2C4: 3D4082C0  lis r10, -0x7d40
	ctx.r[10].s64 = -2101346304;
	// 8220A2C8: 916ABFD4  stw r11, -0x402c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-16428 as u32), ctx.r[11].u32 ) };
	// 8220A2CC: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8220A2D0: 48000008  b 0x8220a2d8
	pc = 0x8220A2D8; continue 'dispatch;
	// 8220A2D4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A2D8: 3D4082B6  lis r10, -0x7d4a
	ctx.r[10].s64 = -2102001664;
	// 8220A2DC: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A2E0: 80DF000C  lwz r6, 0xc(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A2E4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8220A2E8: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A2EC: 916AB65C  stw r11, -0x49a4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-18852 as u32), ctx.r[11].u32 ) };
	// 8220A2F0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A2F4: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8220A2F8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A2FC: 4E800421  bctrl
	ctx.lr = 0x8220A300;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A300: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A304: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8220A308: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A30C: 816B001C  lwz r11, 0x1c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A310: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A314: 4E800421  bctrl
	ctx.lr = 0x8220A318;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A318: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220A31C: 4817EE45  bl 0x82389160
	ctx.lr = 0x8220A320;
	sub_82389160(ctx, base);
	// 8220A320: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220A324: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A328: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A32C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220A330: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220A334: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A338(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A338 size=180
    let mut pc: u32 = 0x8220A338;
    'dispatch: loop {
        match pc {
            0x8220A338 => {
    //   block [0x8220A338..0x8220A3EC)
	// 8220A338: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A33C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A340: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220A344: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A348: 3D6082B6  lis r11, -0x7d4a
	ctx.r[11].s64 = -2102001664;
	// 8220A34C: 3BEBB5B4  addi r31, r11, -0x4a4c
	ctx.r[31].s64 = ctx.r[11].s64 + -19020;
	// 8220A350: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A354: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220A358: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A35C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A360: 419A0014  beq cr6, 0x8220a374
	if ctx.cr[6].eq {
	pc = 0x8220A374; continue 'dispatch;
	}
	// 8220A364: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A368: 216B001F  subfic r11, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[11].s64 = (31 as i64) - ctx.r[11].s64;
	// 8220A36C: 2B0B0010  cmplwi cr6, r11, 0x10
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16 as u32, &mut ctx.xer);
	// 8220A370: 41980008  blt cr6, 0x8220a378
	if ctx.cr[6].lt {
	pc = 0x8220A378; continue 'dispatch;
	}
	// 8220A374: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A378: 3D40830F  lis r10, -0x7cf1
	ctx.r[10].s64 = -2096168960;
	// 8220A37C: 556B482C  slwi r11, r11, 9
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(9);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220A380: 394AFE00  addi r10, r10, -0x200
	ctx.r[10].s64 = ctx.r[10].s64 + -512;
	// 8220A384: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220A388: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A38C: 419A0020  beq cr6, 0x8220a3ac
	if ctx.cr[6].eq {
	pc = 0x8220A3AC; continue 'dispatch;
	}
	// 8220A390: 556A073E  clrlwi r10, r11, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8220A394: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A398: 409A000C  bne cr6, 0x8220a3a4
	if !ctx.cr[6].eq {
	pc = 0x8220A3A4; continue 'dispatch;
	}
	// 8220A39C: 3D4082C0  lis r10, -0x7d40
	ctx.r[10].s64 = -2101346304;
	// 8220A3A0: 916ABFD4  stw r11, -0x402c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-16428 as u32), ctx.r[11].u32 ) };
	// 8220A3A4: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8220A3A8: 48000008  b 0x8220a3b0
	pc = 0x8220A3B0; continue 'dispatch;
	// 8220A3AC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A3B0: 3D4082B6  lis r10, -0x7d4a
	ctx.r[10].s64 = -2102001664;
	// 8220A3B4: 80630004  lwz r3, 4(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A3B8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220A3BC: 916AB65C  stw r11, -0x49a4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-18852 as u32), ctx.r[11].u32 ) };
	// 8220A3C0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A3C4: 816B001C  lwz r11, 0x1c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220A3C8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A3CC: 4E800421  bctrl
	ctx.lr = 0x8220A3D0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A3D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220A3D4: 4817ED8D  bl 0x82389160
	ctx.lr = 0x8220A3D8;
	sub_82389160(ctx, base);
	// 8220A3D8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220A3DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A3E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A3E4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220A3E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A3F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A3F0 size=112
    let mut pc: u32 = 0x8220A3F0;
    'dispatch: loop {
        match pc {
            0x8220A3F0 => {
    //   block [0x8220A3F0..0x8220A460)
	// 8220A3F0: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220A3F4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A3F8: 419A0014  beq cr6, 0x8220a40c
	if ctx.cr[6].eq {
	pc = 0x8220A40C; continue 'dispatch;
	}
	// 8220A3FC: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A400: 214B001F  subfic r10, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[10].s64 = (31 as i64) - ctx.r[11].s64;
	// 8220A404: 2B0A0010  cmplwi cr6, r10, 0x10
	ctx.cr[6].compare_u32(ctx.r[10].u32, 16 as u32, &mut ctx.xer);
	// 8220A408: 41980008  blt cr6, 0x8220a410
	if ctx.cr[6].lt {
	pc = 0x8220A410; continue 'dispatch;
	}
	// 8220A40C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220A410: 3D60830F  lis r11, -0x7cf1
	ctx.r[11].s64 = -2096168960;
	// 8220A414: 554A482C  slwi r10, r10, 9
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(9);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8220A418: 396BFE00  addi r11, r11, -0x200
	ctx.r[11].s64 = ctx.r[11].s64 + -512;
	// 8220A41C: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8220A420: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A424: 419A0018  beq cr6, 0x8220a43c
	if ctx.cr[6].eq {
	pc = 0x8220A43C; continue 'dispatch;
	}
	// 8220A428: 556A073E  clrlwi r10, r11, 0x1c
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8220A42C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A430: 409A000C  bne cr6, 0x8220a43c
	if !ctx.cr[6].eq {
	pc = 0x8220A43C; continue 'dispatch;
	}
	// 8220A434: 3D4082C0  lis r10, -0x7d40
	ctx.r[10].s64 = -2101346304;
	// 8220A438: 916ABFD4  stw r11, -0x402c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-16428 as u32), ctx.r[11].u32 ) };
	// 8220A43C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A440: 80C30010  lwz r6, 0x10(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A444: 80A3000C  lwz r5, 0xc(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A448: 80830008  lwz r4, 8(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A44C: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8220A450: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A454: 816A002C  lwz r11, 0x2c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(44 as u32) ) } as u64;
	// 8220A458: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A45C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A460(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220A460 size=204
    let mut pc: u32 = 0x8220A460;
    'dispatch: loop {
        match pc {
            0x8220A460 => {
    //   block [0x8220A460..0x8220A52C)
	// 8220A460: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A464: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A468: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220A46C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220A470: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A474: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220A478: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8220A47C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A480: 419A0014  beq cr6, 0x8220a494
	if ctx.cr[6].eq {
	pc = 0x8220A494; continue 'dispatch;
	}
	// 8220A484: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A488: 214B001F  subfic r10, r11, 0x1f
	ctx.xer.ca = ctx.r[11].u32 <= 31 as u32;
	ctx.r[10].s64 = (31 as i64) - ctx.r[11].s64;
	// 8220A48C: 2B0A0010  cmplwi cr6, r10, 0x10
	ctx.cr[6].compare_u32(ctx.r[10].u32, 16 as u32, &mut ctx.xer);
	// 8220A490: 41980008  blt cr6, 0x8220a498
	if ctx.cr[6].lt {
	pc = 0x8220A498; continue 'dispatch;
	}
	// 8220A494: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220A498: 3D60830F  lis r11, -0x7cf1
	ctx.r[11].s64 = -2096168960;
	// 8220A49C: C01F0060  lfs f0, 0x60(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A4A0: 554A482C  slwi r10, r10, 9
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(9);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8220A4A4: 396BFE00  addi r11, r11, -0x200
	ctx.r[11].s64 = ctx.r[11].s64 + -512;
	// 8220A4A8: 7FCA5A14  add r30, r10, r11
	ctx.r[30].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8220A4AC: 57CB073E  clrlwi r11, r30, 0x1c
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x0000000Fu64;
	// 8220A4B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A4B4: D01E0160  stfs f0, 0x160(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 8220A4B8: C01F0064  lfs f0, 0x64(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(100 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A4BC: D01E0164  stfs f0, 0x164(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(356 as u32), tmp.u32 ) };
	// 8220A4C0: C01F0068  lfs f0, 0x68(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(104 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A4C4: D01E0168  stfs f0, 0x168(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(360 as u32), tmp.u32 ) };
	// 8220A4C8: 409A000C  bne cr6, 0x8220a4d4
	if !ctx.cr[6].eq {
	pc = 0x8220A4D4; continue 'dispatch;
	}
	// 8220A4CC: 3D6082C0  lis r11, -0x7d40
	ctx.r[11].s64 = -2101346304;
	// 8220A4D0: 93CBBFD4  stw r30, -0x402c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-16428 as u32), ctx.r[30].u32 ) };
	// 8220A4D4: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A4D8: C03F0058  lfs f1, 0x58(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220A4DC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A4E0: 816B0034  lwz r11, 0x34(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220A4E4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A4E8: 4E800421  bctrl
	ctx.lr = 0x8220A4EC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A4EC: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A4F0: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8220A4F4: 38FF0050  addi r7, r31, 0x50
	ctx.r[7].s64 = ctx.r[31].s64 + 80;
	// 8220A4F8: 38DF0010  addi r6, r31, 0x10
	ctx.r[6].s64 = ctx.r[31].s64 + 16;
	// 8220A4FC: 38BF000C  addi r5, r31, 0xc
	ctx.r[5].s64 = ctx.r[31].s64 + 12;
	// 8220A500: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A504: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8220A508: 816B0028  lwz r11, 0x28(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 8220A50C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A510: 4E800421  bctrl
	ctx.lr = 0x8220A514;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A514: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220A518: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A51C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A520: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220A524: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220A528: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A530(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A530 size=72
    let mut pc: u32 = 0x8220A530;
    'dispatch: loop {
        match pc {
            0x8220A530 => {
    //   block [0x8220A530..0x8220A578)
	// 8220A530: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8220A534: 810B0018  lwz r8, 0x18(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 8220A538: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8220A53C: 419A0018  beq cr6, 0x8220a554
	if ctx.cr[6].eq {
	pc = 0x8220A554; continue 'dispatch;
	}
	// 8220A540: 550A073E  clrlwi r10, r8, 0x1c
	ctx.r[10].u64 = ctx.r[8].u32 as u64 & 0x0000000Fu64;
	// 8220A544: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A548: 409A000C  bne cr6, 0x8220a554
	if !ctx.cr[6].eq {
	pc = 0x8220A554; continue 'dispatch;
	}
	// 8220A54C: 3D4082C0  lis r10, -0x7d40
	ctx.r[10].s64 = -2101346304;
	// 8220A550: 910ABFD4  stw r8, -0x402c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-16428 as u32), ctx.r[8].u32 ) };
	// 8220A554: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A558: 80EB0014  lwz r7, 0x14(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220A55C: 80CB0010  lwz r6, 0x10(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A560: 80AB000C  lwz r5, 0xc(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A564: 808B0008  lwz r4, 8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A568: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A56C: 816B0028  lwz r11, 0x28(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 8220A570: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A574: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A578 size=168
    let mut pc: u32 = 0x8220A578;
    'dispatch: loop {
        match pc {
            0x8220A578 => {
    //   block [0x8220A578..0x8220A620)
	// 8220A578: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A57C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A580: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A584: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8220A588: F8810078  std r4, 0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[4].u64 ) };
	// 8220A58C: 2B240000  cmpldi cr6, r4, 0
	ctx.cr[6].compare_u64(ctx.r[4].u64, 0, &mut ctx.xer);
	// 8220A590: 419A007C  beq cr6, 0x8220a60c
	if ctx.cr[6].eq {
	pc = 0x8220A60C; continue 'dispatch;
	}
	// 8220A594: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8220A598: 481729D9  bl 0x8237cf70
	ctx.lr = 0x8220A59C;
	sub_8237CF70(ctx, base);
	// 8220A59C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A5A0: 419A006C  beq cr6, 0x8220a60c
	if ctx.cr[6].eq {
	pc = 0x8220A60C; continue 'dispatch;
	}
	// 8220A5A4: 8161007C  lwz r11, 0x7c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 8220A5A8: 2B0B01FF  cmplwi cr6, r11, 0x1ff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 511 as u32, &mut ctx.xer);
	// 8220A5AC: 40980048  bge cr6, 0x8220a5f4
	if !ctx.cr[6].lt {
	pc = 0x8220A5F4; continue 'dispatch;
	}
	// 8220A5B0: 5569083C  slwi r9, r11, 1
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8220A5B4: 3D408310  lis r10, -0x7cf0
	ctx.r[10].s64 = -2096103424;
	// 8220A5B8: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8220A5BC: 394A86B8  addi r10, r10, -0x7948
	ctx.r[10].s64 = ctx.r[10].s64 + -31048;
	// 8220A5C0: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220A5C4: 7D2B50AE  lbzx r9, r11, r10
	ctx.r[9].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 8220A5C8: 2B090001  cmplwi cr6, r9, 1
	ctx.cr[6].compare_u32(ctx.r[9].u32, 1 as u32, &mut ctx.xer);
	// 8220A5CC: 409A0028  bne cr6, 0x8220a5f4
	if !ctx.cr[6].eq {
	pc = 0x8220A5F4; continue 'dispatch;
	}
	// 8220A5D0: 392A0008  addi r9, r10, 8
	ctx.r[9].s64 = ctx.r[10].s64 + 8;
	// 8220A5D4: 81010078  lwz r8, 0x78(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 8220A5D8: 7D2B482E  lwzx r9, r11, r9
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8220A5DC: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8220A5E0: 409A0014  bne cr6, 0x8220a5f4
	if !ctx.cr[6].eq {
	pc = 0x8220A5F4; continue 'dispatch;
	}
	// 8220A5E4: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8220A5E8: 7D2B522E  lhzx r9, r11, r10
	ctx.r[9].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 8220A5EC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8220A5F0: 7D2B532E  sthx r9, r11, r10
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[9].u16) };
	// 8220A5F4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220A5F8: F8870000  std r4, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[4].u64 ) };
	// 8220A5FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220A600: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A604: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A608: 4E800020  blr
	return;
	// 8220A60C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A610: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220A614: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A618: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A61C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A620(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A620 size=20
    let mut pc: u32 = 0x8220A620;
    'dispatch: loop {
        match pc {
            0x8220A620 => {
    //   block [0x8220A620..0x8220A634)
	// 8220A620: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A624: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A628: 409A000C  bne cr6, 0x8220a634
	if !ctx.cr[6].eq {
		sub_8220A634(ctx, base);
		return;
	}
	// 8220A62C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A630: 4800002C  b 0x8220a65c
	sub_8220A64C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A634(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A634 size=24
    let mut pc: u32 = 0x8220A634;
    'dispatch: loop {
        match pc {
            0x8220A634 => {
    //   block [0x8220A634..0x8220A64C)
	// 8220A634: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A638: 81230010  lwz r9, 0x10(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A63C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A640: 419A000C  beq cr6, 0x8220a64c
	if ctx.cr[6].eq {
		sub_8220A64C(ctx, base);
		return;
	}
	// 8220A644: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A648: 48000014  b 0x8220a65c
	sub_8220A64C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A64C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A64C size=32
    let mut pc: u32 = 0x8220A64C;
    'dispatch: loop {
        match pc {
            0x8220A64C => {
    //   block [0x8220A64C..0x8220A66C)
	// 8220A64C: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A650: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A654: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8220A658: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 8220A65C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8220A660: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A664: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A668: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A66C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220A66C size=8
    let mut pc: u32 = 0x8220A66C;
    'dispatch: loop {
        match pc {
            0x8220A66C => {
    //   block [0x8220A66C..0x8220A674)
	// 8220A66C: 806A0000  lwz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A670: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A678(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A678 size=92
    let mut pc: u32 = 0x8220A678;
    'dispatch: loop {
        match pc {
            0x8220A678 => {
    //   block [0x8220A678..0x8220A6D4)
	// 8220A678: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A67C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A680: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220A684: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220A688: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A68C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220A690: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8220A694: 397F0008  addi r11, r31, 8
	ctx.r[11].s64 = ctx.r[31].s64 + 8;
	// 8220A698: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8220A69C: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A6A0: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8220A6A4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A6A8: 419A0008  beq cr6, 0x8220a6b0
	if ctx.cr[6].eq {
	pc = 0x8220A6B0; continue 'dispatch;
	}
	// 8220A6AC: 4BF129AD  bl 0x8211d058
	ctx.lr = 0x8220A6B0;
	sub_8211D058(ctx, base);
	// 8220A6B0: E87F0000  ld r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	// 8220A6B4: 48172805  bl 0x8237ceb8
	ctx.lr = 0x8220A6B8;
	sub_8237CEB8(ctx, base);
	// 8220A6B8: FBDF0000  std r30, 0(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 8220A6BC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220A6C0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A6C4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A6C8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220A6CC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220A6D0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A6D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220A6D8 size=120
    let mut pc: u32 = 0x8220A6D8;
    'dispatch: loop {
        match pc {
            0x8220A6D8 => {
    //   block [0x8220A6D8..0x8220A750)
	// 8220A6D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A6DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A6E0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A6E4: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8220A6E8: E8670000  ld r3, 0(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	// 8220A6EC: 48172885  bl 0x8237cf70
	ctx.lr = 0x8220A6F0;
	sub_8237CF70(ctx, base);
	// 8220A6F0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A6F4: 419A0048  beq cr6, 0x8220a73c
	if ctx.cr[6].eq {
	pc = 0x8220A73C; continue 'dispatch;
	}
	// 8220A6F8: 81670008  lwz r11, 8(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A6FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A700: 419A002C  beq cr6, 0x8220a72c
	if ctx.cr[6].eq {
	pc = 0x8220A72C; continue 'dispatch;
	}
	// 8220A704: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A708: 81270010  lwz r9, 0x10(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A70C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8220A710: 419A000C  beq cr6, 0x8220a71c
	if ctx.cr[6].eq {
	pc = 0x8220A71C; continue 'dispatch;
	}
	// 8220A714: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A718: 48000014  b 0x8220a72c
	pc = 0x8220A72C; continue 'dispatch;
	// 8220A71C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A720: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8220A724: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8220A728: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 8220A72C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8220A730: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220A734: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A738: 409A0008  bne cr6, 0x8220a740
	if !ctx.cr[6].eq {
	pc = 0x8220A740; continue 'dispatch;
	}
	// 8220A73C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A740: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220A744: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A748: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A74C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A750(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220A750 size=344
    let mut pc: u32 = 0x8220A750;
    'dispatch: loop {
        match pc {
            0x8220A750 => {
    //   block [0x8220A750..0x8220A8A8)
	// 8220A750: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A754: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220A758: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220A75C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220A760: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A764: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220A768: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220A76C: 4BFFFF6D  bl 0x8220a6d8
	ctx.lr = 0x8220A770;
	sub_8220A6D8(ctx, base);
	// 8220A770: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A774: 409A000C  bne cr6, 0x8220a780
	if !ctx.cr[6].eq {
	pc = 0x8220A780; continue 'dispatch;
	}
	// 8220A778: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A77C: 48000114  b 0x8220a890
	pc = 0x8220A890; continue 'dispatch;
	// 8220A780: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220A784: 4BFFFE9D  bl 0x8220a620
	ctx.lr = 0x8220A788;
	sub_8220A620(ctx, base);
	// 8220A788: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A78C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A790: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220A794: 4199000C  bgt cr6, 0x8220a7a0
	if ctx.cr[6].gt {
	pc = 0x8220A7A0; continue 'dispatch;
	}
	// 8220A798: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8220A79C: 48000020  b 0x8220a7bc
	pc = 0x8220A7BC; continue 'dispatch;
	// 8220A7A0: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A7A4: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A7A8: 7D2A4851  subf. r9, r10, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8220A7AC: 4082000C  bne 0x8220a7b8
	if !ctx.cr[0].eq {
	pc = 0x8220A7B8; continue 'dispatch;
	}
	// 8220A7B0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8220A7B4: 48000008  b 0x8220a7bc
	pc = 0x8220A7BC; continue 'dispatch;
	// 8220A7B8: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 8220A7BC: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A7C0: 7F0A2840  cmplw cr6, r10, r5
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220A7C4: 4099FFB4  ble cr6, 0x8220a778
	if !ctx.cr[6].gt {
	pc = 0x8220A778; continue 'dispatch;
	}
	// 8220A7C8: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A7CC: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8220A7D0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220A7D4: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8220A7D8: 512A07FE  rlwimi r10, r9, 0, 0x1f, 0x1f
	ctx.r[10].u64 = (((ctx.r[9].u32).rotate_left(0) as u64) & 0x0000000000000001) | (ctx.r[10].u64 & 0xFFFFFFFFFFFFFFFE);
	// 8220A7DC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220A7E0: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220A7E4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220A7E8: 512A0636  rlwimi r10, r9, 0, 0x18, 0x1b
	ctx.r[10].u64 = (((ctx.r[9].u32).rotate_left(0) as u64) & 0x00000000000000F0) | (ctx.r[10].u64 & 0xFFFFFFFFFFFFFF0F);
	// 8220A7EC: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 8220A7F0: 39200060  li r9, 0x60
	ctx.r[9].s64 = 96;
	// 8220A7F4: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8220A7F8: 913F000C  stw r9, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 8220A7FC: 4BFFFE25  bl 0x8220a620
	ctx.lr = 0x8220A800;
	sub_8220A620(ctx, base);
	// 8220A800: 480D5269  bl 0x822dfa68
	ctx.lr = 0x8220A804;
	sub_822DFA68(ctx, base);
	// 8220A804: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A808: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A80C: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220A810: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A814: 4E800421  bctrl
	ctx.lr = 0x8220A818;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A818: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8220A81C: E87E0000  ld r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	// 8220A820: 481727B1  bl 0x8237cfd0
	ctx.lr = 0x8220A824;
	sub_8237CFD0(ctx, base);
	// 8220A824: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8220A828: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A82C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220A830: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220A834: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A838: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A83C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A840: 4E800421  bctrl
	ctx.lr = 0x8220A844;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A844: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A848: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 8220A84C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8220A850: 409A0014  bne cr6, 0x8220a864
	if !ctx.cr[6].eq {
	pc = 0x8220A864; continue 'dispatch;
	}
	// 8220A854: C0010068  lfs f0, 0x68(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A858: C1A1006C  lfs f13, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220A85C: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220A860: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220A864: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A868: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A86C: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220A870: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A874: 4E800421  bctrl
	ctx.lr = 0x8220A878;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A878: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8220A87C: 2B0B000A  cmplwi cr6, r11, 0xa
	ctx.cr[6].compare_u32(ctx.r[11].u32, 10 as u32, &mut ctx.xer);
	// 8220A880: 41980008  blt cr6, 0x8220a888
	if ctx.cr[6].lt {
	pc = 0x8220A888; continue 'dispatch;
	}
	// 8220A884: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8220A888: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220A88C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220A890: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8220A894: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220A898: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220A89C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220A8A0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220A8A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220A8A8 size=292
    let mut pc: u32 = 0x8220A8A8;
    'dispatch: loop {
        match pc {
            0x8220A8A8 => {
    //   block [0x8220A8A8..0x8220A9CC)
	// 8220A8A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A8AC: 4832A811  bl 0x825350bc
	ctx.lr = 0x8220A8B0;
	sub_82535080(ctx, base);
	// 8220A8B0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A8B4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220A8B8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220A8BC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8220A8C0: 4BFFFE19  bl 0x8220a6d8
	ctx.lr = 0x8220A8C4;
	sub_8220A6D8(ctx, base);
	// 8220A8C4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A8C8: 409A0010  bne cr6, 0x8220a8d8
	if !ctx.cr[6].eq {
	pc = 0x8220A8D8; continue 'dispatch;
	}
	// 8220A8CC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A8D0: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220A8D4: 4832A838  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 8220A8D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220A8DC: 4BFFFD45  bl 0x8220a620
	ctx.lr = 0x8220A8E0;
	sub_8220A620(ctx, base);
	// 8220A8E0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A8E4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220A8E8: 4199000C  bgt cr6, 0x8220a8f4
	if ctx.cr[6].gt {
	pc = 0x8220A8F4; continue 'dispatch;
	}
	// 8220A8EC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A8F0: 48000020  b 0x8220a910
	pc = 0x8220A910; continue 'dispatch;
	// 8220A8F4: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A8F8: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A8FC: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220A900: 4082000C  bne 0x8220a90c
	if !ctx.cr[0].eq {
	pc = 0x8220A90C; continue 'dispatch;
	}
	// 8220A904: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A908: 48000008  b 0x8220a910
	pc = 0x8220A910; continue 'dispatch;
	// 8220A90C: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220A910: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A914: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8220A918: 4099FFB4  ble cr6, 0x8220a8cc
	if !ctx.cr[6].gt {
	pc = 0x8220A8CC; continue 'dispatch;
	}
	// 8220A91C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220A920: 4BF497A1  bl 0x821540c0
	ctx.lr = 0x8220A924;
	sub_821540C0(ctx, base);
	// 8220A924: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220A928: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220A92C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8220A930: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220A934: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220A938: 4BFFFCE9  bl 0x8220a620
	ctx.lr = 0x8220A93C;
	sub_8220A620(ctx, base);
	// 8220A93C: 480D512D  bl 0x822dfa68
	ctx.lr = 0x8220A940;
	sub_822DFA68(ctx, base);
	// 8220A940: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A944: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8220A948: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A94C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A950: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A954: 4E800421  bctrl
	ctx.lr = 0x8220A958;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A958: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A95C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220A960: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A964: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220A968: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A96C: 4E800421  bctrl
	ctx.lr = 0x8220A970;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A970: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220A974: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8220A978: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220A97C: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220A980: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220A984: 4E800421  bctrl
	ctx.lr = 0x8220A988;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220A988: 39610080  addi r11, r1, 0x80
	ctx.r[11].s64 = ctx.r[1].s64 + 128;
	// 8220A98C: 395F0010  addi r10, r31, 0x10
	ctx.r[10].s64 = ctx.r[31].s64 + 16;
	// 8220A990: C0010060  lfs f0, 0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A994: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220A998: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220A99C: C1A10064  lfs f13, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220A9A0: C0010070  lfs f0, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220A9A4: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 8220A9A8: C1810074  lfs f12, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220A9AC: E96B0008  ld r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	// 8220A9B0: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220A9B4: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220A9B8: D19F0054  stfs f12, 0x54(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220A9BC: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8220A9C0: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8220A9C4: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220A9C8: 4832A744  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220A9D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220A9D0 size=384
    let mut pc: u32 = 0x8220A9D0;
    'dispatch: loop {
        match pc {
            0x8220A9D0 => {
    //   block [0x8220A9D0..0x8220AB50)
	// 8220A9D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220A9D4: 4832A6E5  bl 0x825350b8
	ctx.lr = 0x8220A9D8;
	sub_82535080(ctx, base);
	// 8220A9D8: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220A9DC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220A9E0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220A9E4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8220A9E8: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 8220A9EC: 4BFFFCED  bl 0x8220a6d8
	ctx.lr = 0x8220A9F0;
	sub_8220A6D8(ctx, base);
	// 8220A9F0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220A9F4: 409A0010  bne cr6, 0x8220aa04
	if !ctx.cr[6].eq {
	pc = 0x8220AA04; continue 'dispatch;
	}
	// 8220A9F8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220A9FC: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 8220AA00: 4832A708  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 8220AA04: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220AA08: 4BFFFC19  bl 0x8220a620
	ctx.lr = 0x8220AA0C;
	sub_8220A620(ctx, base);
	// 8220AA0C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AA10: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220AA14: 4199000C  bgt cr6, 0x8220aa20
	if ctx.cr[6].gt {
	pc = 0x8220AA20; continue 'dispatch;
	}
	// 8220AA18: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AA1C: 48000020  b 0x8220aa3c
	pc = 0x8220AA3C; continue 'dispatch;
	// 8220AA20: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AA24: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AA28: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220AA2C: 4082000C  bne 0x8220aa38
	if !ctx.cr[0].eq {
	pc = 0x8220AA38; continue 'dispatch;
	}
	// 8220AA30: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AA34: 48000008  b 0x8220aa3c
	pc = 0x8220AA3C; continue 'dispatch;
	// 8220AA38: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220AA3C: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AA40: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8220AA44: 4099FFB4  ble cr6, 0x8220a9f8
	if !ctx.cr[6].gt {
	pc = 0x8220A9F8; continue 'dispatch;
	}
	// 8220AA48: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220AA4C: 4BFFFBD5  bl 0x8220a620
	ctx.lr = 0x8220AA50;
	sub_8220A620(ctx, base);
	// 8220AA50: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AA54: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220AA58: 4199000C  bgt cr6, 0x8220aa64
	if ctx.cr[6].gt {
	pc = 0x8220AA64; continue 'dispatch;
	}
	// 8220AA5C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AA60: 48000020  b 0x8220aa80
	pc = 0x8220AA80; continue 'dispatch;
	// 8220AA64: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AA68: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AA6C: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220AA70: 4082000C  bne 0x8220aa7c
	if !ctx.cr[0].eq {
	pc = 0x8220AA7C; continue 'dispatch;
	}
	// 8220AA74: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AA78: 48000008  b 0x8220aa80
	pc = 0x8220AA80; continue 'dispatch;
	// 8220AA7C: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220AA80: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AA84: 7F0BE040  cmplw cr6, r11, r28
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[28].u32, &mut ctx.xer);
	// 8220AA88: 4099FF70  ble cr6, 0x8220a9f8
	if !ctx.cr[6].gt {
	pc = 0x8220A9F8; continue 'dispatch;
	}
	// 8220AA8C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220AA90: 4BF49631  bl 0x821540c0
	ctx.lr = 0x8220AA94;
	sub_821540C0(ctx, base);
	// 8220AA94: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AA98: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220AA9C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8220AAA0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220AAA4: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220AAA8: 4BFFFB79  bl 0x8220a620
	ctx.lr = 0x8220AAAC;
	sub_8220A620(ctx, base);
	// 8220AAAC: 480D4FBD  bl 0x822dfa68
	ctx.lr = 0x8220AAB0;
	sub_822DFA68(ctx, base);
	// 8220AAB0: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AAB4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220AAB8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AABC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AAC0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AAC4: 4E800421  bctrl
	ctx.lr = 0x8220AAC8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AAC8: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AACC: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8220AAD0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AAD4: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AAD8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AADC: 4E800421  bctrl
	ctx.lr = 0x8220AAE0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AAE0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220AAE4: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8220AAE8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220AAEC: 4BFFFB35  bl 0x8220a620
	ctx.lr = 0x8220AAF0;
	sub_8220A620(ctx, base);
	// 8220AAF0: 480D4F79  bl 0x822dfa68
	ctx.lr = 0x8220AAF4;
	sub_822DFA68(ctx, base);
	// 8220AAF4: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AAF8: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8220AAFC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AB00: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AB04: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AB08: 4E800421  bctrl
	ctx.lr = 0x8220AB0C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AB0C: 39610080  addi r11, r1, 0x80
	ctx.r[11].s64 = ctx.r[1].s64 + 128;
	// 8220AB10: 395F0010  addi r10, r31, 0x10
	ctx.r[10].s64 = ctx.r[31].s64 + 16;
	// 8220AB14: C0010060  lfs f0, 0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220AB18: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220AB1C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220AB20: C1A10064  lfs f13, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220AB24: C0010070  lfs f0, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220AB28: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 8220AB2C: C1810074  lfs f12, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220AB30: E96B0008  ld r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	// 8220AB34: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220AB38: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220AB3C: D19F0054  stfs f12, 0x54(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220AB40: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8220AB44: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8220AB48: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 8220AB4C: 4832A5BC  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220AB50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220AB50 size=292
    let mut pc: u32 = 0x8220AB50;
    'dispatch: loop {
        match pc {
            0x8220AB50 => {
    //   block [0x8220AB50..0x8220AC74)
	// 8220AB50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220AB54: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220AB58: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220AB5C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220AB60: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220AB64: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220AB68: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220AB6C: 4BFFFB6D  bl 0x8220a6d8
	ctx.lr = 0x8220AB70;
	sub_8220A6D8(ctx, base);
	// 8220AB70: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220AB74: 409A000C  bne cr6, 0x8220ab80
	if !ctx.cr[6].eq {
	pc = 0x8220AB80; continue 'dispatch;
	}
	// 8220AB78: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220AB7C: 480000E0  b 0x8220ac5c
	pc = 0x8220AC5C; continue 'dispatch;
	// 8220AB80: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220AB84: 4BFFFA9D  bl 0x8220a620
	ctx.lr = 0x8220AB88;
	sub_8220A620(ctx, base);
	// 8220AB88: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AB8C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AB90: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220AB94: 4199000C  bgt cr6, 0x8220aba0
	if ctx.cr[6].gt {
	pc = 0x8220ABA0; continue 'dispatch;
	}
	// 8220AB98: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8220AB9C: 48000020  b 0x8220abbc
	pc = 0x8220ABBC; continue 'dispatch;
	// 8220ABA0: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220ABA4: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220ABA8: 7D2A4851  subf. r9, r10, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8220ABAC: 4082000C  bne 0x8220abb8
	if !ctx.cr[0].eq {
	pc = 0x8220ABB8; continue 'dispatch;
	}
	// 8220ABB0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8220ABB4: 48000008  b 0x8220abbc
	pc = 0x8220ABBC; continue 'dispatch;
	// 8220ABB8: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 8220ABBC: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220ABC0: 7F0A2840  cmplw cr6, r10, r5
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220ABC4: 4099FFB4  ble cr6, 0x8220ab78
	if !ctx.cr[6].gt {
	pc = 0x8220AB78; continue 'dispatch;
	}
	// 8220ABC8: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220ABCC: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8220ABD0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220ABD4: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8220ABD8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220ABDC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220ABE0: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220ABE4: C00A1FF8  lfs f0, 0x1ff8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ABE8: 39400030  li r10, 0x30
	ctx.r[10].s64 = 48;
	// 8220ABEC: D01F0020  stfs f0, 0x20(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220ABF0: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220ABF4: D01F0018  stfs f0, 0x18(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220ABF8: 915F000C  stw r10, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8220ABFC: 4BFFFA25  bl 0x8220a620
	ctx.lr = 0x8220AC00;
	sub_8220A620(ctx, base);
	// 8220AC00: 480D4E69  bl 0x822dfa68
	ctx.lr = 0x8220AC04;
	sub_822DFA68(ctx, base);
	// 8220AC04: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AC08: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AC0C: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220AC10: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AC14: 4E800421  bctrl
	ctx.lr = 0x8220AC18;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AC18: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8220AC1C: E87E0000  ld r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	// 8220AC20: 481723B1  bl 0x8237cfd0
	ctx.lr = 0x8220AC24;
	sub_8237CFD0(ctx, base);
	// 8220AC24: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AC28: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 8220AC2C: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8220AC30: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AC34: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8220AC38: 816A0010  lwz r11, 0x10(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220AC3C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AC40: 4E800421  bctrl
	ctx.lr = 0x8220AC44;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AC44: 2B03000A  cmplwi cr6, r3, 0xa
	ctx.cr[6].compare_u32(ctx.r[3].u32, 10 as u32, &mut ctx.xer);
	// 8220AC48: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8220AC4C: 40980008  bge cr6, 0x8220ac54
	if !ctx.cr[6].lt {
	pc = 0x8220AC54; continue 'dispatch;
	}
	// 8220AC50: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8220AC54: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220AC58: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220AC5C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8220AC60: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220AC64: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220AC68: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220AC6C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220AC70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220AC78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220AC78 size=552
    let mut pc: u32 = 0x8220AC78;
    'dispatch: loop {
        match pc {
            0x8220AC78 => {
    //   block [0x8220AC78..0x8220AEA0)
	// 8220AC78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220AC7C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220AC80: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220AC84: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220AC88: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8220AC8C: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220AC90: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8220AC94: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220AC98: 4BFFFA41  bl 0x8220a6d8
	ctx.lr = 0x8220AC9C;
	sub_8220A6D8(ctx, base);
	// 8220AC9C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220ACA0: 409A000C  bne cr6, 0x8220acac
	if !ctx.cr[6].eq {
	pc = 0x8220ACAC; continue 'dispatch;
	}
	// 8220ACA4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220ACA8: 480001DC  b 0x8220ae84
	pc = 0x8220AE84; continue 'dispatch;
	// 8220ACAC: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220ACB0: 4BFFF971  bl 0x8220a620
	ctx.lr = 0x8220ACB4;
	sub_8220A620(ctx, base);
	// 8220ACB4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220ACB8: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8220ACBC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220ACC0: 4199000C  bgt cr6, 0x8220accc
	if ctx.cr[6].gt {
	pc = 0x8220ACCC; continue 'dispatch;
	}
	// 8220ACC4: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 8220ACC8: 48000020  b 0x8220ace8
	pc = 0x8220ACE8; continue 'dispatch;
	// 8220ACCC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220ACD0: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220ACD4: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220ACD8: 4082000C  bne 0x8220ace4
	if !ctx.cr[0].eq {
	pc = 0x8220ACE4; continue 'dispatch;
	}
	// 8220ACDC: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 8220ACE0: 48000008  b 0x8220ace8
	pc = 0x8220ACE8; continue 'dispatch;
	// 8220ACE4: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220ACE8: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220ACEC: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220ACF0: 4099FFB4  ble cr6, 0x8220aca4
	if !ctx.cr[6].gt {
	pc = 0x8220ACA4; continue 'dispatch;
	}
	// 8220ACF4: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220ACF8: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 8220ACFC: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220AD00: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220AD04: C3EBBA38  lfs f31, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220AD08: D3E10060  stfs f31, 0x60(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220AD0C: D3E10064  stfs f31, 0x64(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220AD10: D3E10068  stfs f31, 0x68(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220AD14: D3E1006C  stfs f31, 0x6c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220AD18: 4BFFF909  bl 0x8220a620
	ctx.lr = 0x8220AD1C;
	sub_8220A620(ctx, base);
	// 8220AD1C: 480D4D4D  bl 0x822dfa68
	ctx.lr = 0x8220AD20;
	sub_822DFA68(ctx, base);
	// 8220AD20: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AD24: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8220AD28: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AD2C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AD30: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AD34: 4E800421  bctrl
	ctx.lr = 0x8220AD38;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AD38: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AD3C: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 8220AD40: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AD44: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AD48: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AD4C: 4E800421  bctrl
	ctx.lr = 0x8220AD50;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AD50: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AD54: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8220AD58: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AD5C: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AD60: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AD64: 4E800421  bctrl
	ctx.lr = 0x8220AD68;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AD68: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8220AD6C: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 8220AD70: C0010080  lfs f0, 0x80(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220AD74: 38FF0010  addi r7, r31, 0x10
	ctx.r[7].s64 = ctx.r[31].s64 + 16;
	// 8220AD78: C1010070  lfs f8, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220AD7C: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 8220AD80: C1810090  lfs f12, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220AD84: 38C10060  addi r6, r1, 0x60
	ctx.r[6].s64 = ctx.r[1].s64 + 96;
	// 8220AD88: C1610088  lfs f11, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220AD8C: E88A0000  ld r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 8220AD90: 397F0030  addi r11, r31, 0x30
	ctx.r[11].s64 = ctx.r[31].s64 + 48;
	// 8220AD94: E8690000  ld r3, 0(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	// 8220AD98: C1A10084  lfs f13, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220AD9C: E94A0008  ld r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	// 8220ADA0: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220ADA4: E9290008  ld r9, 8(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	// 8220ADA8: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220ADAC: D01F0020  stfs f0, 0x20(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220ADB0: 93DF0028  stw r30, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 8220ADB4: F8870000  std r4, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[4].u64 ) };
	// 8220ADB8: C1210074  lfs f9, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220ADBC: F8680000  std r3, 0(r8)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[3].u64 ) };
	// 8220ADC0: C1410078  lfs f10, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220ADC4: F9470008  std r10, 8(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[10].u64 ) };
	// 8220ADC8: 394B0010  addi r10, r11, 0x10
	ctx.r[10].s64 = ctx.r[11].s64 + 16;
	// 8220ADCC: F9280008  std r9, 8(r8)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[9].u64 ) };
	// 8220ADD0: ED8C402A  fadds f12, f12, f8
	ctx.f[12].f64 = ((ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64;
	// 8220ADD4: E9260000  ld r9, 0(r6)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	// 8220ADD8: ED6B002A  fadds f11, f11, f0
	ctx.f[11].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220ADDC: E9060008  ld r8, 8(r6)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) };
	// 8220ADE0: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220ADE4: D1AB0024  stfs f13, 0x24(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220ADE8: 93CB0028  stw r30, 0x28(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 8220ADEC: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220ADF0: E8E50000  ld r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	// 8220ADF4: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220ADF8: E8C50008  ld r6, 8(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	// 8220ADFC: D3EB000C  stfs f31, 0xc(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8220AE00: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8220AE04: D16B0020  stfs f11, 0x20(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220AE08: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8220AE0C: F90A0008  std r8, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[8].u64 ) };
	// 8220AE10: C0E10094  lfs f7, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220AE14: 394B0010  addi r10, r11, 0x10
	ctx.r[10].s64 = ctx.r[11].s64 + 16;
	// 8220AE18: ED27482A  fadds f9, f7, f9
	ctx.f[9].f64 = ((ctx.f[7].f64 + ctx.f[9].f64) as f32) as f64;
	// 8220AE1C: C0E1008C  lfs f7, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220AE20: EDA7682A  fadds f13, f7, f13
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220AE24: D10B0000  stfs f8, 0(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220AE28: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220AE2C: D3EB000C  stfs f31, 0xc(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8220AE30: F8EA0000  std r7, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u64 ) };
	// 8220AE34: F8CA0008  std r6, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[6].u64 ) };
	// 8220AE38: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8220AE3C: D00B0020  stfs f0, 0x20(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220AE40: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220AE44: 93CB0028  stw r30, 0x28(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 8220AE48: D1AB0024  stfs f13, 0x24(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220AE4C: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8220AE50: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220AE54: E92A0000  ld r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 8220AE58: E90A0008  ld r8, 8(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	// 8220AE5C: 394B0010  addi r10, r11, 0x10
	ctx.r[10].s64 = ctx.r[11].s64 + 16;
	// 8220AE60: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220AE64: 93CB0028  stw r30, 0x28(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 8220AE68: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220AE6C: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220AE70: D3EB000C  stfs f31, 0xc(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8220AE74: D16B0020  stfs f11, 0x20(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220AE78: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8220AE7C: D1AB0024  stfs f13, 0x24(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220AE80: F90A0008  std r8, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[8].u64 ) };
	// 8220AE84: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 8220AE88: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220AE8C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220AE90: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8220AE94: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220AE98: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220AE9C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220AEA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220AEA0 size=204
    let mut pc: u32 = 0x8220AEA0;
    'dispatch: loop {
        match pc {
            0x8220AEA0 => {
    //   block [0x8220AEA0..0x8220AF6C)
	// 8220AEA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220AEA4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220AEA8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220AEAC: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220AEB0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220AEB4: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 8220AEB8: 4BFFF821  bl 0x8220a6d8
	ctx.lr = 0x8220AEBC;
	sub_8220A6D8(ctx, base);
	// 8220AEBC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220AEC0: 409A001C  bne cr6, 0x8220aedc
	if !ctx.cr[6].eq {
	pc = 0x8220AEDC; continue 'dispatch;
	}
	// 8220AEC4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220AEC8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220AECC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220AED0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220AED4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220AED8: 4E800020  blr
	return;
	// 8220AEDC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220AEE0: 4BFFF741  bl 0x8220a620
	ctx.lr = 0x8220AEE4;
	sub_8220A620(ctx, base);
	// 8220AEE4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AEE8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220AEEC: 4199000C  bgt cr6, 0x8220aef8
	if ctx.cr[6].gt {
	pc = 0x8220AEF8; continue 'dispatch;
	}
	// 8220AEF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AEF4: 48000020  b 0x8220af14
	pc = 0x8220AF14; continue 'dispatch;
	// 8220AEF8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AEFC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AF00: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220AF04: 4082000C  bne 0x8220af10
	if !ctx.cr[0].eq {
	pc = 0x8220AF10; continue 'dispatch;
	}
	// 8220AF08: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AF0C: 48000008  b 0x8220af14
	pc = 0x8220AF14; continue 'dispatch;
	// 8220AF10: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220AF14: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AF18: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220AF1C: 4099FFA8  ble cr6, 0x8220aec4
	if !ctx.cr[6].gt {
	pc = 0x8220AEC4; continue 'dispatch;
	}
	// 8220AF20: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AF24: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220AF28: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220AF2C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220AF30: 4BFFF6F1  bl 0x8220a620
	ctx.lr = 0x8220AF34;
	sub_8220A620(ctx, base);
	// 8220AF34: 480D4B35  bl 0x822dfa68
	ctx.lr = 0x8220AF38;
	sub_822DFA68(ctx, base);
	// 8220AF38: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220AF3C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AF40: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220AF44: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220AF48: 4E800421  bctrl
	ctx.lr = 0x8220AF4C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220AF4C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8220AF50: E87F0000  ld r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	// 8220AF54: 4817207D  bl 0x8237cfd0
	ctx.lr = 0x8220AF58;
	sub_8237CFD0(ctx, base);
	// 8220AF58: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220AF5C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220AF60: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220AF64: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220AF68: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220AF70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220AF70 size=208
    let mut pc: u32 = 0x8220AF70;
    'dispatch: loop {
        match pc {
            0x8220AF70 => {
    //   block [0x8220AF70..0x8220B040)
	// 8220AF70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220AF74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220AF78: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220AF7C: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220AF80: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8220AF84: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220AF88: 4BFFF751  bl 0x8220a6d8
	ctx.lr = 0x8220AF8C;
	sub_8220A6D8(ctx, base);
	// 8220AF8C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220AF90: 409A001C  bne cr6, 0x8220afac
	if !ctx.cr[6].eq {
	pc = 0x8220AFAC; continue 'dispatch;
	}
	// 8220AF94: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220AF98: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220AF9C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220AFA0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220AFA4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220AFA8: 4E800020  blr
	return;
	// 8220AFAC: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220AFB0: 4BFFF671  bl 0x8220a620
	ctx.lr = 0x8220AFB4;
	sub_8220A620(ctx, base);
	// 8220AFB4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220AFB8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220AFBC: 4199000C  bgt cr6, 0x8220afc8
	if ctx.cr[6].gt {
	pc = 0x8220AFC8; continue 'dispatch;
	}
	// 8220AFC0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AFC4: 48000020  b 0x8220afe4
	pc = 0x8220AFE4; continue 'dispatch;
	// 8220AFC8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220AFCC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AFD0: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220AFD4: 4082000C  bne 0x8220afe0
	if !ctx.cr[0].eq {
	pc = 0x8220AFE0; continue 'dispatch;
	}
	// 8220AFD8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AFDC: 48000008  b 0x8220afe4
	pc = 0x8220AFE4; continue 'dispatch;
	// 8220AFE0: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220AFE4: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220AFE8: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220AFEC: 4099FFA8  ble cr6, 0x8220af94
	if !ctx.cr[6].gt {
	pc = 0x8220AF94; continue 'dispatch;
	}
	// 8220AFF0: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8220AFF4: 419AFFA0  beq cr6, 0x8220af94
	if ctx.cr[6].eq {
	pc = 0x8220AF94; continue 'dispatch;
	}
	// 8220AFF8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220AFFC: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220B000: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220B004: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220B008: 4BFFF619  bl 0x8220a620
	ctx.lr = 0x8220B00C;
	sub_8220A620(ctx, base);
	// 8220B00C: 480D4A5D  bl 0x822dfa68
	ctx.lr = 0x8220B010;
	sub_822DFA68(ctx, base);
	// 8220B010: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220B014: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220B018: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B01C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B020: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220B024: 4E800421  bctrl
	ctx.lr = 0x8220B028;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220B028: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220B02C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220B030: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220B034: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220B038: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220B03C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B040(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220B040 size=208
    let mut pc: u32 = 0x8220B040;
    'dispatch: loop {
        match pc {
            0x8220B040 => {
    //   block [0x8220B040..0x8220B110)
	// 8220B040: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220B044: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220B048: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220B04C: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220B050: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8220B054: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220B058: 4BFFF681  bl 0x8220a6d8
	ctx.lr = 0x8220B05C;
	sub_8220A6D8(ctx, base);
	// 8220B05C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220B060: 409A001C  bne cr6, 0x8220b07c
	if !ctx.cr[6].eq {
	pc = 0x8220B07C; continue 'dispatch;
	}
	// 8220B064: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8220B068: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220B06C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220B070: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220B074: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220B078: 4E800020  blr
	return;
	// 8220B07C: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220B080: 4BFFF5A1  bl 0x8220a620
	ctx.lr = 0x8220B084;
	sub_8220A620(ctx, base);
	// 8220B084: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B088: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B08C: 4199000C  bgt cr6, 0x8220b098
	if ctx.cr[6].gt {
	pc = 0x8220B098; continue 'dispatch;
	}
	// 8220B090: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220B094: 48000020  b 0x8220b0b4
	pc = 0x8220B0B4; continue 'dispatch;
	// 8220B098: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220B09C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220B0A0: 7D4B5051  subf. r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8220B0A4: 4082000C  bne 0x8220b0b0
	if !ctx.cr[0].eq {
	pc = 0x8220B0B0; continue 'dispatch;
	}
	// 8220B0A8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220B0AC: 48000008  b 0x8220b0b4
	pc = 0x8220B0B4; continue 'dispatch;
	// 8220B0B0: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8220B0B4: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220B0B8: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 8220B0BC: 4099FFA8  ble cr6, 0x8220b064
	if !ctx.cr[6].gt {
	pc = 0x8220B064; continue 'dispatch;
	}
	// 8220B0C0: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8220B0C4: 419AFFA0  beq cr6, 0x8220b064
	if ctx.cr[6].eq {
	pc = 0x8220B064; continue 'dispatch;
	}
	// 8220B0C8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220B0CC: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8220B0D0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220B0D4: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220B0D8: 4BFFF549  bl 0x8220a620
	ctx.lr = 0x8220B0DC;
	sub_8220A620(ctx, base);
	// 8220B0DC: 480D498D  bl 0x822dfa68
	ctx.lr = 0x8220B0E0;
	sub_822DFA68(ctx, base);
	// 8220B0E0: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220B0E4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220B0E8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B0EC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220B0F0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220B0F4: 4E800421  bctrl
	ctx.lr = 0x8220B0F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220B0F8: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8220B0FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8220B100: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220B104: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220B108: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220B10C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B110(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B110 size=8
    let mut pc: u32 = 0x8220B110;
    'dispatch: loop {
        match pc {
            0x8220B110 => {
    //   block [0x8220B110..0x8220B118)
	// 8220B110: 80630114  lwz r3, 0x114(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(276 as u32) ) } as u64;
	// 8220B114: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B118(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B118 size=8
    let mut pc: u32 = 0x8220B118;
    'dispatch: loop {
        match pc {
            0x8220B118 => {
    //   block [0x8220B118..0x8220B120)
	// 8220B118: 386300E0  addi r3, r3, 0xe0
	ctx.r[3].s64 = ctx.r[3].s64 + 224;
	// 8220B11C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220B120 size=380
    let mut pc: u32 = 0x8220B120;
    'dispatch: loop {
        match pc {
            0x8220B120 => {
    //   block [0x8220B120..0x8220B29C)
	// 8220B120: 3D208288  lis r9, -0x7d78
	ctx.r[9].s64 = -2105016320;
	// 8220B124: 9081001C  stw r4, 0x1c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(28 as u32), ctx.r[4].u32 ) };
	// 8220B128: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220B12C: 90610014  stw r3, 0x14(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 8220B130: 39298E40  addi r9, r9, -0x71c0
	ctx.r[9].s64 = ctx.r[9].s64 + -29120;
	// 8220B134: 90A10024  stw r5, 0x24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(36 as u32), ctx.r[5].u32 ) };
	// 8220B138: 90C1002C  stw r6, 0x2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(44 as u32), ctx.r[6].u32 ) };
	// 8220B13C: 39430090  addi r10, r3, 0x90
	ctx.r[10].s64 = ctx.r[3].s64 + 144;
	// 8220B140: 39000003  li r8, 3
	ctx.r[8].s64 = 3;
	// 8220B144: C00BBA38  lfs f0, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220B148: 396300E0  addi r11, r3, 0xe0
	ctx.r[11].s64 = ctx.r[3].s64 + 224;
	// 8220B14C: 9121FFD0  stw r9, -0x30(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u32 ) };
	// 8220B150: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 8220B154: 39294464  addi r9, r9, 0x4464
	ctx.r[9].s64 = ctx.r[9].s64 + 17508;
	// 8220B158: 9161FFDC  stw r11, -0x24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-36 as u32), ctx.r[11].u32 ) };
	// 8220B15C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220B160: 9121FFD4  stw r9, -0x2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), ctx.r[9].u32 ) };
	// 8220B164: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 8220B168: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 8220B16C: 39293A7C  addi r9, r9, 0x3a7c
	ctx.r[9].s64 = ctx.r[9].s64 + 14972;
	// 8220B170: F961FFE8  std r11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[11].u64 ) };
	// 8220B174: F96A0000  std r11, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 8220B178: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8220B17C: F96A0010  std r11, 0x10(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8220B180: 9121FFD8  stw r9, -0x28(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[9].u32 ) };
	// 8220B184: F96A0018  std r11, 0x18(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(24 as u32), ctx.r[11].u64 ) };
	// 8220B188: F96A0020  std r11, 0x20(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(32 as u32), ctx.r[11].u64 ) };
	// 8220B18C: F96A0028  std r11, 0x28(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), ctx.r[11].u64 ) };
	// 8220B190: F96A0030  std r11, 0x30(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(48 as u32), ctx.r[11].u64 ) };
	// 8220B194: F96A0038  std r11, 0x38(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(56 as u32), ctx.r[11].u64 ) };
	// 8220B198: 916A0040  stw r11, 0x40(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(64 as u32), ctx.r[11].u32 ) };
	// 8220B19C: B16A0044  sth r11, 0x44(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(68 as u32), ctx.r[11].u16 ) };
	// 8220B1A0: B16A0046  sth r11, 0x46(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(70 as u32), ctx.r[11].u16 ) };
	// 8220B1A4: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8220B1A8: 80610014  lwz r3, 0x14(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220B1AC: 81210024  lwz r9, 0x24(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(36 as u32) ) } as u64;
	// 8220B1B0: A0E30014  lhz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220B1B4: D003008C  stfs f0, 0x8c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 8220B1B8: 91230080  stw r9, 0x80(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 8220B1BC: 51071EDE  rlwimi r7, r8, 3, 0x1b, 0xf
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(3) as u64) & 0xFFFFFFFFFFFF001F) | (ctx.r[7].u64 & 0x000000000000FFE0);
	// 8220B1C0: 8101FFD0  lwz r8, -0x30(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8220B1C4: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8220B1C8: B0E30014  sth r7, 0x14(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[7].u16 ) };
	// 8220B1CC: 3CE08287  lis r7, -0x7d79
	ctx.r[7].s64 = -2105081856;
	// 8220B1D0: 910300D0  stw r8, 0xd0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(208 as u32), ctx.r[8].u32 ) };
	// 8220B1D4: 91230084  stw r9, 0x84(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(132 as u32), ctx.r[9].u32 ) };
	// 8220B1D8: 38E77790  addi r7, r7, 0x7790
	ctx.r[7].s64 = ctx.r[7].s64 + 30608;
	// 8220B1DC: 9923001D  stb r9, 0x1d(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(29 as u32), ctx.r[9].u8 ) };
	// 8220B1E0: 9923001E  stb r9, 0x1e(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(30 as u32), ctx.r[9].u8 ) };
	// 8220B1E4: 916A0048  stw r11, 0x48(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 8220B1E8: 916A004C  stw r11, 0x4c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8220B1EC: 8141FFD4  lwz r10, -0x2c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-44 as u32) ) } as u64;
	// 8220B1F0: 8101FFD8  lwz r8, -0x28(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) } as u64;
	// 8220B1F4: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8220B1F8: 8141FFDC  lwz r10, -0x24(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-36 as u32) ) } as u64;
	// 8220B1FC: 910A0000  stw r8, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8220B200: 3D008288  lis r8, -0x7d78
	ctx.r[8].s64 = -2105016320;
	// 8220B204: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220B208: B16A0008  sth r11, 8(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u16 ) };
	// 8220B20C: 39088E38  addi r8, r8, -0x71c8
	ctx.r[8].s64 = ctx.r[8].s64 + -29128;
	// 8220B210: B16A000A  sth r11, 0xa(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(10 as u32), ctx.r[11].u16 ) };
	// 8220B214: 916A000C  stw r11, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8220B218: B16A0010  sth r11, 0x10(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u16 ) };
	// 8220B21C: B16A0012  sth r11, 0x12(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(18 as u32), ctx.r[11].u16 ) };
	// 8220B220: 916A0014  stw r11, 0x14(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8220B224: B16A0018  sth r11, 0x18(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(24 as u32), ctx.r[11].u16 ) };
	// 8220B228: B16A001A  sth r11, 0x1a(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(26 as u32), ctx.r[11].u16 ) };
	// 8220B22C: 916A001C  stw r11, 0x1c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8220B230: B16A0020  sth r11, 0x20(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220B234: B16A0022  sth r11, 0x22(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220B238: 916A0024  stw r11, 0x24(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8220B23C: B16A0028  sth r11, 0x28(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(40 as u32), ctx.r[11].u16 ) };
	// 8220B240: B16A002A  sth r11, 0x2a(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(42 as u32), ctx.r[11].u16 ) };
	// 8220B244: 8141001C  lwz r10, 0x1c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220B248: 91630114  stw r11, 0x114(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(276 as u32), ctx.r[11].u32 ) };
	// 8220B24C: 9143010C  stw r10, 0x10c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(268 as u32), ctx.r[10].u32 ) };
	// 8220B250: 8141002C  lwz r10, 0x2c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(44 as u32) ) } as u64;
	// 8220B254: 91430088  stw r10, 0x88(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), ctx.r[10].u32 ) };
	// 8220B258: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 8220B25C: 910300E4  stw r8, 0xe4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(228 as u32), ctx.r[8].u32 ) };
	// 8220B260: B12300E8  sth r9, 0xe8(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), ctx.r[9].u16 ) };
	// 8220B264: B16300EA  sth r11, 0xea(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(234 as u32), ctx.r[11].u16 ) };
	// 8220B268: 910300EC  stw r8, 0xec(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(236 as u32), ctx.r[8].u32 ) };
	// 8220B26C: B14300F0  sth r10, 0xf0(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(240 as u32), ctx.r[10].u16 ) };
	// 8220B270: B16300F2  sth r11, 0xf2(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(242 as u32), ctx.r[11].u16 ) };
	// 8220B274: 90E300F4  stw r7, 0xf4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(244 as u32), ctx.r[7].u32 ) };
	// 8220B278: B12300F8  sth r9, 0xf8(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(248 as u32), ctx.r[9].u16 ) };
	// 8220B27C: B16300FA  sth r11, 0xfa(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(250 as u32), ctx.r[11].u16 ) };
	// 8220B280: 916300FC  stw r11, 0xfc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(252 as u32), ctx.r[11].u32 ) };
	// 8220B284: B1230100  sth r9, 0x100(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(256 as u32), ctx.r[9].u16 ) };
	// 8220B288: B1630102  sth r11, 0x102(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(258 as u32), ctx.r[11].u16 ) };
	// 8220B28C: 91630104  stw r11, 0x104(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(260 as u32), ctx.r[11].u32 ) };
	// 8220B290: B1430108  sth r10, 0x108(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(264 as u32), ctx.r[10].u16 ) };
	// 8220B294: B163010A  sth r11, 0x10a(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(266 as u32), ctx.r[11].u16 ) };
	// 8220B298: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B2A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220B2A0 size=84
    let mut pc: u32 = 0x8220B2A0;
    'dispatch: loop {
        match pc {
            0x8220B2A0 => {
    //   block [0x8220B2A0..0x8220B2F4)
	// 8220B2A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220B2A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220B2A8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220B2AC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220B2B0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220B2B4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B2B8: 816B0020  lwz r11, 0x20(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220B2BC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220B2C0: 4E800421  bctrl
	ctx.lr = 0x8220B2C4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220B2C4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220B2C8: 419A0018  beq cr6, 0x8220b2e0
	if ctx.cr[6].eq {
	pc = 0x8220B2E0; continue 'dispatch;
	}
	// 8220B2CC: 817F0110  lwz r11, 0x110(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(272 as u32) ) } as u64;
	// 8220B2D0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B2D4: 419A000C  beq cr6, 0x8220b2e0
	if ctx.cr[6].eq {
	pc = 0x8220B2E0; continue 'dispatch;
	}
	// 8220B2D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220B2DC: 4BFF9125  bl 0x82204400
	ctx.lr = 0x8220B2E0;
	sub_82204400(ctx, base);
	// 8220B2E0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220B2E4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220B2E8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220B2EC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220B2F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B2F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B2F8 size=24
    let mut pc: u32 = 0x8220B2F8;
    'dispatch: loop {
        match pc {
            0x8220B2F8 => {
    //   block [0x8220B2F8..0x8220B310)
	// 8220B2F8: 81630110  lwz r11, 0x110(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(272 as u32) ) } as u64;
	// 8220B2FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B300: 409A0010  bne cr6, 0x8220b310
	if !ctx.cr[6].eq {
		sub_8220B310(ctx, base);
		return;
	}
	// 8220B304: B16300F8  sth r11, 0xf8(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(248 as u32), ctx.r[11].u16 ) };
	// 8220B308: B16300FA  sth r11, 0xfa(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(250 as u32), ctx.r[11].u16 ) };
	// 8220B30C: 4800001C  b 0x8220b328
	sub_8220B310(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B310(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B310 size=32
    let mut pc: u32 = 0x8220B310;
    'dispatch: loop {
        match pc {
            0x8220B310 => {
    //   block [0x8220B310..0x8220B330)
	// 8220B310: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8220B314: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8220B318: 3D608287  lis r11, -0x7d79
	ctx.r[11].s64 = -2105081856;
	// 8220B31C: 396B7790  addi r11, r11, 0x7790
	ctx.r[11].s64 = ctx.r[11].s64 + 30608;
	// 8220B320: B14300F8  sth r10, 0xf8(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(248 as u32), ctx.r[10].u16 ) };
	// 8220B324: B12300FA  sth r9, 0xfa(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(250 as u32), ctx.r[9].u16 ) };
	// 8220B328: 916300F4  stw r11, 0xf4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(244 as u32), ctx.r[11].u32 ) };
	// 8220B32C: 4BFF8F44  b 0x82204270
	sub_82204270(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220B330 size=836
    let mut pc: u32 = 0x8220B330;
    'dispatch: loop {
        match pc {
            0x8220B330 => {
    //   block [0x8220B330..0x8220B674)
	// 8220B330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220B334: 48329D59  bl 0x8253508c
	ctx.lr = 0x8220B338;
	sub_82535080(ctx, base);
	// 8220B338: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220B33C: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B340: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8220B344: 7CDF3378  mr r31, r6
	ctx.r[31].u64 = ctx.r[6].u64;
	// 8220B348: 7CF73B78  mr r23, r7
	ctx.r[23].u64 = ctx.r[7].u64;
	// 8220B34C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8220B350: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B354: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B358: 419A0014  beq cr6, 0x8220b36c
	if ctx.cr[6].eq {
	pc = 0x8220B36C; continue 'dispatch;
	}
	// 8220B35C: 812B001C  lwz r9, 0x1c(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8220B360: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220B364: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8220B368: 419A000C  beq cr6, 0x8220b374
	if ctx.cr[6].eq {
	pc = 0x8220B374; continue 'dispatch;
	}
	// 8220B36C: 7FD6F378  mr r22, r30
	ctx.r[22].u64 = ctx.r[30].u64;
	// 8220B370: 48000008  b 0x8220b378
	pc = 0x8220B378; continue 'dispatch;
	// 8220B374: 7D765B78  mr r22, r11
	ctx.r[22].u64 = ctx.r[11].u64;
	// 8220B378: A3050006  lhz r24, 6(r5)
	ctx.r[24].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[5].u32.wrapping_add(6 as u32) ) } as u64;
	// 8220B37C: 2B160000  cmplwi cr6, r22, 0
	ctx.cr[6].compare_u32(ctx.r[22].u32, 0 as u32, &mut ctx.xer);
	// 8220B380: A2A50004  lhz r21, 4(r5)
	ctx.r[21].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220B384: 419A02E8  beq cr6, 0x8220b66c
	if ctx.cr[6].eq {
	pc = 0x8220B66C; continue 'dispatch;
	}
	// 8220B388: 38A000C0  li r5, 0xc0
	ctx.r[5].s64 = 192;
	// 8220B38C: 8076000C  lwz r3, 0xc(r22)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220B390: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 8220B394: 481725AD  bl 0x8237d940
	ctx.lr = 0x8220B398;
	sub_8237D940(ctx, base);
	// 8220B398: 3D608311  lis r11, -0x7cef
	ctx.r[11].s64 = -2096037888;
	// 8220B39C: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 8220B3A0: 396B9000  addi r11, r11, -0x7000
	ctx.r[11].s64 = ctx.r[11].s64 + -28672;
	// 8220B3A4: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220B3A8: 38800180  li r4, 0x180
	ctx.r[4].s64 = 384;
	// 8220B3AC: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8220B3B0: 48198871  bl 0x823a3c20
	ctx.lr = 0x8220B3B4;
	sub_823A3C20(ctx, base);
	// 8220B3B4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8220B3B8: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8220B3BC: 419A02B0  beq cr6, 0x8220b66c
	if ctx.cr[6].eq {
	pc = 0x8220B66C; continue 'dispatch;
	}
	// 8220B3C0: 839F0000  lwz r28, 0(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B3C4: 38A10054  addi r5, r1, 0x54
	ctx.r[5].s64 = ctx.r[1].s64 + 84;
	// 8220B3C8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220B3CC: 835F0018  lwz r26, 0x18(r31)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 8220B3D0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8220B3D4: 4818F615  bl 0x8239a9e8
	ctx.lr = 0x8220B3D8;
	sub_8239A9E8(ctx, base);
	// 8220B3D8: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 8220B3DC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220B3E0: 409A0014  bne cr6, 0x8220b3f4
	if !ctx.cr[6].eq {
	pc = 0x8220B3F4; continue 'dispatch;
	}
	// 8220B3E4: 3F801000  lis r28, 0x1000
	ctx.r[28].s64 = 268435456;
	// 8220B3E8: 90E10050  stw r7, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u32 ) };
	// 8220B3EC: 90E10054  stw r7, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[7].u32 ) };
	// 8220B3F0: 639C0007  ori r28, r28, 7
	ctx.r[28].u64 = ctx.r[28].u64 | 7;
	// 8220B3F4: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 8220B3F8: 409A0008  bne cr6, 0x8220b400
	if !ctx.cr[6].eq {
	pc = 0x8220B400; continue 'dispatch;
	}
	// 8220B3FC: 3F404020  lis r26, 0x4020
	ctx.r[26].s64 = 1075838976;
	// 8220B400: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220B404: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220B408: 65640001  oris r4, r11, 1
	ctx.r[4].u64 = ctx.r[11].u64 | 65536;
	// 8220B40C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8220B410: 60842000  ori r4, r4, 0x2000
	ctx.r[4].u64 = ctx.r[4].u64 | 8192;
	// 8220B414: 419A0008  beq cr6, 0x8220b41c
	if ctx.cr[6].eq {
	pc = 0x8220B41C; continue 'dispatch;
	}
	// 8220B418: 7D242378  or r4, r9, r4
	ctx.r[4].u64 = ctx.r[9].u64 | ctx.r[4].u64;
	// 8220B41C: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8220B420: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B424: 419A002C  beq cr6, 0x8220b450
	if ctx.cr[6].eq {
	pc = 0x8220B450; continue 'dispatch;
	}
	// 8220B428: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 8220B42C: E9010060  ld r8, 0x60(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8220B430: 93CB001C  stw r30, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[30].u32 ) };
	// 8220B434: 394A44B4  addi r10, r10, 0x44b4
	ctx.r[10].s64 = ctx.r[10].s64 + 17588;
	// 8220B438: 93AB0050  stw r29, 0x50(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 8220B43C: 936B00B0  stw r27, 0xb0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(176 as u32), ctx.r[27].u32 ) };
	// 8220B440: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8220B444: F90B0058  std r8, 0x58(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 8220B448: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8220B44C: 48000008  b 0x8220b454
	pc = 0x8220B454; continue 'dispatch;
	// 8220B450: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 8220B454: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 8220B458: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 8220B45C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8220B460: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220B464: 3B6B00A0  addi r27, r11, 0xa0
	ctx.r[27].s64 = ctx.r[11].s64 + 160;
	// 8220B468: 390B0060  addi r8, r11, 0x60
	ctx.r[8].s64 = ctx.r[11].s64 + 96;
	// 8220B46C: 90CB0054  stw r6, 0x54(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(84 as u32), ctx.r[6].u32 ) };
	// 8220B470: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 8220B474: B3190002  sth r24, 2(r25)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[25].u32.wrapping_add(2 as u32), ctx.r[24].u16 ) };
	// 8220B478: 3B0B0058  addi r24, r11, 0x58
	ctx.r[24].s64 = ctx.r[11].s64 + 88;
	// 8220B47C: B1390000  sth r9, 0(r25)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8220B480: C00A1FF8  lfs f0, 0x1ff8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220B484: 91790004  stw r11, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8220B488: 3D403F80  lis r10, 0x3f80
	ctx.r[10].s64 = 1065353216;
	// 8220B48C: 807F000C  lwz r3, 0xc(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220B490: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 8220B494: 93CB0024  stw r30, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 8220B498: 7D545378  mr r20, r10
	ctx.r[20].u64 = ctx.r[10].u64;
	// 8220B49C: 908B0028  stw r4, 0x28(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), ctx.r[4].u32 ) };
	// 8220B4A0: 7D535378  mr r19, r10
	ctx.r[19].u64 = ctx.r[10].u64;
	// 8220B4A4: 934B002C  stw r26, 0x2c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(44 as u32), ctx.r[26].u32 ) };
	// 8220B4A8: 7D525378  mr r18, r10
	ctx.r[18].u64 = ctx.r[10].u64;
	// 8220B4AC: 938B0030  stw r28, 0x30(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), ctx.r[28].u32 ) };
	// 8220B4B0: 7D515378  mr r17, r10
	ctx.r[17].u64 = ctx.r[10].u64;
	// 8220B4B4: 906B0020  stw r3, 0x20(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 8220B4B8: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 8220B4BC: 809F0004  lwz r4, 4(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220B4C0: 7FA9EB78  mr r9, r29
	ctx.r[9].u64 = ctx.r[29].u64;
	// 8220B4C4: 908B0034  stw r4, 0x34(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(52 as u32), ctx.r[4].u32 ) };
	// 8220B4C8: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220B4CC: FDA06850  fneg f13, f13
	ctx.f[13].u64 = ctx.f[13].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220B4D0: D00B003C  stfs f0, 0x3c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220B4D4: D1AB0038  stfs f13, 0x38(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220B4D8: 93CB0040  stw r30, 0x40(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(64 as u32), ctx.r[30].u32 ) };
	// 8220B4DC: 930B0044  stw r24, 0x44(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(68 as u32), ctx.r[24].u32 ) };
	// 8220B4E0: 93CB0048  stw r30, 0x48(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(72 as u32), ctx.r[30].u32 ) };
	// 8220B4E4: 936B004C  stw r27, 0x4c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(76 as u32), ctx.r[27].u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B678(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B678 size=24
    let mut pc: u32 = 0x8220B678;
    'dispatch: loop {
        match pc {
            0x8220B678 => {
    //   block [0x8220B678..0x8220B690)
	// 8220B678: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 8220B67C: 3D40829E  lis r10, -0x7d62
	ctx.r[10].s64 = -2103574528;
	// 8220B680: E96B6410  ld r11, 0x6410(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(25616 as u32) ) };
	// 8220B684: E94A6418  ld r10, 0x6418(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(25624 as u32) ) };
	// 8220B688: 7F2B5040  cmpld cr6, r11, r10
	ctx.cr[6].compare_u64(ctx.r[11].u64, ctx.r[10].u64, &mut ctx.xer);
	// 8220B68C: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B690(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220B690 size=8
    let mut pc: u32 = 0x8220B690;
    'dispatch: loop {
        match pc {
            0x8220B690 => {
    //   block [0x8220B690..0x8220B698)
	// 8220B690: 48165190  b 0x82370820
	sub_82370820(ctx, base);
	return;
	// 8220B694: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B698(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220B698 size=400
    let mut pc: u32 = 0x8220B698;
    'dispatch: loop {
        match pc {
            0x8220B698 => {
    //   block [0x8220B698..0x8220B828)
	// 8220B698: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220B69C: 48329A15  bl 0x825350b0
	ctx.lr = 0x8220B6A0;
	sub_82535080(ctx, base);
	// 8220B6A0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220B6A4: 3D204020  lis r9, 0x4020
	ctx.r[9].s64 = 1075838976;
	// 8220B6A8: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220B6AC: 7D254B78  mr r5, r9
	ctx.r[5].u64 = ctx.r[9].u64;
	// 8220B6B0: 7D3D4B78  mr r29, r9
	ctx.r[29].u64 = ctx.r[9].u64;
	// 8220B6B4: C00B1FF8  lfs f0, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220B6B8: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 8220B6BC: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8220B6C0: C1AA2074  lfs f13, 0x2074(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8308 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220B6C4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220B6C8: 38C00022  li r6, 0x22
	ctx.r[6].s64 = 34;
	// 8220B6CC: 38E00120  li r7, 0x120
	ctx.r[7].s64 = 288;
	// 8220B6D0: 9163004C  stw r11, 0x4c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8220B6D4: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 8220B6D8: 9163007C  stw r11, 0x7c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220B6DC: 3D600080  lis r11, 0x80
	ctx.r[11].s64 = 8388608;
	// 8220B6E0: C189BFFC  lfs f12, -0x4004(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220B6E4: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8220B6E8: 61640760  ori r4, r11, 0x760
	ctx.r[4].u64 = ctx.r[11].u64 | 1888;
	// 8220B6EC: D0030000  stfs f0, 0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220B6F0: 3D600606  lis r11, 0x606
	ctx.r[11].s64 = 101056512;
	// 8220B6F4: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220B6F8: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 8220B6FC: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220B700: 616B8195  ori r11, r11, 0x8195
	ctx.r[11].u64 = ctx.r[11].u64 | 33173;
	// 8220B704: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220B708: C1692530  lfs f11, 0x2530(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(9520 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220B70C: 3D20829E  lis r9, -0x7d62
	ctx.r[9].s64 = -2103574528;
	// 8220B710: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 8220B714: D0030010  stfs f0, 0x10(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220B718: 7D7B5B78  mr r27, r11
	ctx.r[27].u64 = ctx.r[11].u64;
	// 8220B71C: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220B720: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8220B724: D003001C  stfs f0, 0x1c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220B728: D1A30024  stfs f13, 0x24(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220B72C: 3B800760  li r28, 0x760
	ctx.r[28].s64 = 1888;
	// 8220B730: D0030020  stfs f0, 0x20(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220B734: 3B400002  li r26, 2
	ctx.r[26].s64 = 2;
	// 8220B738: D0030028  stfs f0, 0x28(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220B73C: D003002C  stfs f0, 0x2c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 8220B740: 90A30048  stw r5, 0x48(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), ctx.r[5].u32 ) };
	// 8220B744: 916920B8  stw r11, 0x20b8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8376 as u32), ctx.r[11].u32 ) };
	// 8220B748: 3D20829E  lis r9, -0x7d62
	ctx.r[9].s64 = -2103574528;
	// 8220B74C: 90C30034  stw r6, 0x34(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[6].u32 ) };
	// 8220B750: D0030058  stfs f0, 0x58(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220B754: 90E30044  stw r7, 0x44(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), ctx.r[7].u32 ) };
	// 8220B758: 91030040  stw r8, 0x40(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(64 as u32), ctx.r[8].u32 ) };
	// 8220B75C: 9143003C  stw r10, 0x3c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), ctx.r[10].u32 ) };
	// 8220B760: F9696410  std r11, 0x6410(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(25616 as u32), ctx.r[11].u64 ) };
	// 8220B764: 3D20829E  lis r9, -0x7d62
	ctx.r[9].s64 = -2103574528;
	// 8220B768: 91430038  stw r10, 0x38(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), ctx.r[10].u32 ) };
	// 8220B76C: D1830058  stfs f12, 0x58(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220B770: 90830044  stw r4, 0x44(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), ctx.r[4].u32 ) };
	// 8220B774: 93E30030  stw r31, 0x30(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), ctx.r[31].u32 ) };
	// 8220B778: 93C30038  stw r30, 0x38(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), ctx.r[30].u32 ) };
	// 8220B77C: D0030088  stfs f0, 0x88(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8220B780: 90C30064  stw r6, 0x64(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(100 as u32), ctx.r[6].u32 ) };
	// 8220B784: 3CC0820A  lis r6, -0x7df6
	ctx.r[6].s64 = -2113273856;
	// 8220B788: F9696418  std r11, 0x6418(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(25624 as u32), ctx.r[11].u64 ) };
	// 8220B78C: 3D208288  lis r9, -0x7d78
	ctx.r[9].s64 = -2105016320;
	// 8220B790: 90E30074  stw r7, 0x74(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(116 as u32), ctx.r[7].u32 ) };
	// 8220B794: 3CE08288  lis r7, -0x7d78
	ctx.r[7].s64 = -2105016320;
	// 8220B798: 3929D0B0  addi r9, r9, -0x2f50
	ctx.r[9].s64 = ctx.r[9].s64 + -12112;
	// 8220B79C: 91030070  stw r8, 0x70(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(112 as u32), ctx.r[8].u32 ) };
	// 8220B7A0: 93A30078  stw r29, 0x78(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(120 as u32), ctx.r[29].u32 ) };
	// 8220B7A4: 39630090  addi r11, r3, 0x90
	ctx.r[11].s64 = ctx.r[3].s64 + 144;
	// 8220B7A8: 9143006C  stw r10, 0x6c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(108 as u32), ctx.r[10].u32 ) };
	// 8220B7AC: C1A6BA38  lfs f13, -0x45c8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220B7B0: 91430068  stw r10, 0x68(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(104 as u32), ctx.r[10].u32 ) };
	// 8220B7B4: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 8220B7B8: D1630088  stfs f11, 0x88(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8220B7BC: 93830074  stw r28, 0x74(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(116 as u32), ctx.r[28].u32 ) };
	// 8220B7C0: 93630060  stw r27, 0x60(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(96 as u32), ctx.r[27].u32 ) };
	// 8220B7C4: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8220B7C8: 93430068  stw r26, 0x68(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(104 as u32), ctx.r[26].u32 ) };
	// 8220B7CC: 38A78C60  addi r5, r7, -0x73a0
	ctx.r[5].s64 = ctx.r[7].s64 + -29600;
	// 8220B7D0: 38C50100  addi r6, r5, 0x100
	ctx.r[6].s64 = ctx.r[5].s64 + 256;
	// 8220B7D4: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220B7D8: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220B7DC: 38EB0010  addi r7, r11, 0x10
	ctx.r[7].s64 = ctx.r[11].s64 + 16;
	// 8220B7E0: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220B7E4: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8220B7E8: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8220B7EC: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8220B7F0: E8860000  ld r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	// 8220B7F4: F8870000  std r4, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[4].u64 ) };
	// 8220B7F8: E8C60008  ld r6, 8(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) };
	// 8220B7FC: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220B800: 914B002C  stw r10, 0x2c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(44 as u32), ctx.r[10].u32 ) };
	// 8220B804: F8C70008  std r6, 8(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[6].u64 ) };
	// 8220B808: C189FFFC  lfs f12, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220B80C: D18B0020  stfs f12, 0x20(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220B810: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220B814: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 8220B818: D18B0024  stfs f12, 0x24(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220B81C: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8220B820: 409AFFB0  bne cr6, 0x8220b7d0
	if !ctx.cr[6].eq {
	pc = 0x8220B7D0; continue 'dispatch;
	}
	// 8220B824: 483298DC  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220B828(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220B828 size=3544
    let mut pc: u32 = 0x8220B828;
    'dispatch: loop {
        match pc {
            0x8220B828 => {
    //   block [0x8220B828..0x8220C600)
	// 8220B828: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220B82C: 48329855  bl 0x82535080
	ctx.lr = 0x8220B830;
	sub_82535080(ctx, base);
	// 8220B830: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 8220B834: 4832A77D  bl 0x82535fb0
	ctx.lr = 0x8220B838;
	sub_82535FB0(ctx, base);
	// 8220B838: 9421FD30  stwu r1, -0x2d0(r1)
	ea = ctx.r[1].u32.wrapping_add(-720 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220B83C: 3D40829E  lis r10, -0x7d62
	ctx.r[10].s64 = -2103574528;
	// 8220B840: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 8220B844: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 8220B848: 7C952378  mr r21, r4
	ctx.r[21].u64 = ctx.r[4].u64;
	// 8220B84C: 816A20B8  lwz r11, 0x20b8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8376 as u32) ) } as u64;
	// 8220B850: 93610090  stw r27, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[27].u32 ) };
	// 8220B854: 2B0B0040  cmplwi cr6, r11, 0x40
	ctx.cr[6].compare_u32(ctx.r[11].u32, 64 as u32, &mut ctx.xer);
	// 8220B858: 40980018  bge cr6, 0x8220b870
	if !ctx.cr[6].lt {
	pc = 0x8220B870; continue 'dispatch;
	}
	// 8220B85C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8220B860: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8220B864: 913A000C  stw r9, 0xc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 8220B868: 916A20B8  stw r11, 0x20b8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8376 as u32), ctx.r[11].u32 ) };
	// 8220B86C: 4800000C  b 0x8220b878
	pc = 0x8220B878; continue 'dispatch;
	// 8220B870: 3960003F  li r11, 0x3f
	ctx.r[11].s64 = 63;
	// 8220B874: 917A000C  stw r11, 0xc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8220B878: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 8220B87C: 816BF388  lwz r11, -0xc78(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3192 as u32) ) } as u64;
	// 8220B880: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220B884: 419A0D4C  beq cr6, 0x8220c5d0
	if ctx.cr[6].eq {
	pc = 0x8220C5D0; continue 'dispatch;
	}
	// 8220B888: 3D608288  lis r11, -0x7d78
	ctx.r[11].s64 = -2105016320;
	// 8220B88C: 7F7CDB78  mr r28, r27
	ctx.r[28].u64 = ctx.r[27].u64;
	// 8220B890: 3BCBD0E0  addi r30, r11, -0x2f20
	ctx.r[30].s64 = ctx.r[11].s64 + -12064;
	// 8220B894: 39C00020  li r14, 0x20
	ctx.r[14].s64 = 32;
	// 8220B898: 39E00010  li r15, 0x10
	ctx.r[15].s64 = 16;
	// 8220B89C: 3A000030  li r16, 0x30
	ctx.r[16].s64 = 48;
	// 8220B8A0: 897E0000  lbz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220B8A4: 5569303E  rotlwi r9, r11, 6
	ctx.r[9].u64 = ((ctx.r[11].u32).rotate_left(6)) as u64;
	// 8220B8A8: 897E0002  lbz r11, 2(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(2 as u32) ) } as u64;
	// 8220B8AC: 556A303E  rotlwi r10, r11, 6
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(6)) as u64;
	// 8220B8B0: 7D69AA14  add r11, r9, r21
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[21].u64;
	// 8220B8B4: 3D2082C0  lis r9, -0x7d40
	ctx.r[9].s64 = -2101346304;
	// 8220B8B8: 7D4AAA14  add r10, r10, r21
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[21].u64;
	// 8220B8BC: C0EB0030  lfs f7, 0x30(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220B8C0: C0CB0034  lfs f6, 0x34(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220B8C4: 8129BF90  lwz r9, -0x4070(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16496 as u32) ) } as u64;
	// 8220B8C8: C0AB0038  lfs f5, 0x38(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220B8CC: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220B8D0: C3CA0030  lfs f30, 0x30(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(48 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8220B8D4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8220B8D8: 3B2BBA44  addi r25, r11, -0x45bc
	ctx.r[25].s64 = ctx.r[11].s64 + -17852;
	// 8220B8DC: C38A0034  lfs f28, 0x34(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8220B8E0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220B8E4: C36A0038  lfs f27, 0x38(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(56 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8220B8E8: 912100E0  stw r9, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[9].u32 ) };
	// 8220B8EC: C3F9FFF4  lfs f31, -0xc(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(-12 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220B8F0: C3AB1FF8  lfs f29, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8220B8F4: 419A00C0  beq cr6, 0x8220b9b4
	if ctx.cr[6].eq {
	pc = 0x8220B9B4; continue 'dispatch;
	}
	// 8220B8F8: D3A100B0  stfs f29, 0xb0(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 8220B8FC: 39690180  addi r11, r9, 0x180
	ctx.r[11].s64 = ctx.r[9].s64 + 384;
	// 8220B900: D3A100B4  stfs f29, 0xb4(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), tmp.u32 ) };
	// 8220B904: D3E100B8  stfs f31, 0xb8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), tmp.u32 ) };
	// 8220B908: D3A100BC  stfs f29, 0xbc(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), tmp.u32 ) };
	// 8220B90C: 394100B0  addi r10, r1, 0xb0
	ctx.r[10].s64 = ctx.r[1].s64 + 176;
	// 8220B910: D3A100D0  stfs f29, 0xd0(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 8220B914: D3A100D4  stfs f29, 0xd4(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 8220B918: D3A100D8  stfs f29, 0xd8(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 8220B91C: D3A100DC  stfs f29, 0xdc(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), tmp.u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C600(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220C600 size=60
    let mut pc: u32 = 0x8220C600;
    'dispatch: loop {
        match pc {
            0x8220C600 => {
    //   block [0x8220C600..0x8220C63C)
	// 8220C600: A1630020  lhz r11, 0x20(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220C604: C1A30010  lfs f13, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220C608: C1830014  lfs f12, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220C60C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220C610: C1630018  lfs f11, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220C614: 7D6B28AE  lbzx r11, r11, r5
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8220C618: 556B103E  rotlwi r11, r11, 2
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220C61C: 7C0B242E  lfsx f0, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C620: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220C624: D1A30010  stfs f13, 0x10(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220C628: EDA00332  fmuls f13, f0, f12
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220C62C: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220C630: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8220C634: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220C638: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220C640 size=40
    let mut pc: u32 = 0x8220C640;
    'dispatch: loop {
        match pc {
            0x8220C640 => {
    //   block [0x8220C640..0x8220C668)
	// 8220C640: C0030010  lfs f0, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C644: C1A30014  lfs f13, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220C648: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8220C64C: C1830018  lfs f12, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220C650: EDA10372  fmuls f13, f1, f13
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220C654: ED810332  fmuls f12, f1, f12
	ctx.f[12].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220C658: D0030010  stfs f0, 0x10(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220C65C: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220C660: D1830018  stfs f12, 0x18(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220C664: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C668(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220C668 size=72
    let mut pc: u32 = 0x8220C668;
    'dispatch: loop {
        match pc {
            0x8220C668 => {
    //   block [0x8220C668..0x8220C6B0)
	// 8220C668: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220C66C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220C670: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220C674: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220C678: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8220C67C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220C680: 396B6DD0  addi r11, r11, 0x6dd0
	ctx.r[11].s64 = ctx.r[11].s64 + 28112;
	// 8220C684: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 8220C688: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220C68C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220C690: 419A000C  beq cr6, 0x8220c69c
	if ctx.cr[6].eq {
	pc = 0x8220C69C; continue 'dispatch;
	}
	// 8220C694: 48326525  bl 0x82532bb8
	ctx.lr = 0x8220C698;
	sub_82532BB8(ctx, base);
	// 8220C698: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220C69C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220C6A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220C6A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220C6A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C6AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C6B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220C6B0 size=96
    let mut pc: u32 = 0x8220C6B0;
    'dispatch: loop {
        match pc {
            0x8220C6B0 => {
    //   block [0x8220C6B0..0x8220C710)
	// 8220C6B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220C6B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220C6B8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220C6BC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220C6C0: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8220C6C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220C6C8: 396B6DD0  addi r11, r11, 0x6dd0
	ctx.r[11].s64 = ctx.r[11].s64 + 28112;
	// 8220C6CC: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 8220C6D0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220C6D4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220C6D8: 419A0020  beq cr6, 0x8220c6f8
	if ctx.cr[6].eq {
	pc = 0x8220C6F8; continue 'dispatch;
	}
	// 8220C6DC: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220C6E0: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 8220C6E4: 38C00015  li r6, 0x15
	ctx.r[6].s64 = 21;
	// 8220C6E8: A0BF0004  lhz r5, 4(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220C6EC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220C6F0: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8220C6F4: 482579C5  bl 0x824640b8
	ctx.lr = 0x8220C6F8;
	sub_824640B8(ctx, base);
	// 8220C6F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220C6FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220C700: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220C704: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220C708: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C70C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C710(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220C710 size=72
    let mut pc: u32 = 0x8220C710;
    'dispatch: loop {
        match pc {
            0x8220C710 => {
    //   block [0x8220C710..0x8220C758)
	// 8220C710: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220C714: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220C718: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220C71C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220C720: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220C724: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220C728: 396B45C8  addi r11, r11, 0x45c8
	ctx.r[11].s64 = ctx.r[11].s64 + 17864;
	// 8220C72C: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 8220C730: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220C734: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220C738: 419A000C  beq cr6, 0x8220c744
	if ctx.cr[6].eq {
	pc = 0x8220C744; continue 'dispatch;
	}
	// 8220C73C: 4832647D  bl 0x82532bb8
	ctx.lr = 0x8220C740;
	sub_82532BB8(ctx, base);
	// 8220C740: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220C744: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220C748: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220C74C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220C750: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C754: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C758(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220C758 size=8
    let mut pc: u32 = 0x8220C758;
    'dispatch: loop {
        match pc {
            0x8220C758 => {
    //   block [0x8220C758..0x8220C760)
	// 8220C758: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8220C75C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C760(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220C760 size=24
    let mut pc: u32 = 0x8220C760;
    'dispatch: loop {
        match pc {
            0x8220C760 => {
    //   block [0x8220C760..0x8220C778)
	// 8220C760: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8220C764: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8220C768: 556B6026  slwi r11, r11, 0xc
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(12);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220C76C: 7D6B5378  or r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 8220C770: 5563402E  slwi r3, r11, 8
	ctx.r[3].u32 = ctx.r[11].u32.wrapping_shl(8);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 8220C774: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C778(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8220C778 size=8
    let mut pc: u32 = 0x8220C778;
    'dispatch: loop {
        match pc {
            0x8220C778 => {
    //   block [0x8220C778..0x8220C780)
	// 8220C778: 38600009  li r3, 9
	ctx.r[3].s64 = 9;
	// 8220C77C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C780(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220C780 size=260
    let mut pc: u32 = 0x8220C780;
    'dispatch: loop {
        match pc {
            0x8220C780 => {
    //   block [0x8220C780..0x8220C884)
	// 8220C780: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220C784: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220C788: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220C78C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8220C790: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8220C794: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220C798: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220C79C: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7A0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220C7A4: C00B0014  lfs f0, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7A8: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220C7AC: C00B0028  lfs f0, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7B0: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8220C7B4: C00B003C  lfs f0, 0x3c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7B8: D001008C  stfs f0, 0x8c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 8220C7BC: C00B0004  lfs f0, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7C0: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220C7C4: C00B0010  lfs f0, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7C8: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220C7CC: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7D0: D0010070  stfs f0, 0x70(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8220C7D4: C00B0020  lfs f0, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7D8: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220C7DC: C00B0018  lfs f0, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7E0: D0010074  stfs f0, 0x74(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 8220C7E4: C00B0024  lfs f0, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7E8: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220C7EC: C00B0030  lfs f0, 0x30(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7F0: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8220C7F4: C00B0034  lfs f0, 0x34(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C7F8: D0010084  stfs f0, 0x84(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8220C7FC: C00B0038  lfs f0, 0x38(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C800: D0010088  stfs f0, 0x88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8220C804: C00B000C  lfs f0, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C808: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220C80C: C00B001C  lfs f0, 0x1c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C810: D001006C  stfs f0, 0x6c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220C814: C00B002C  lfs f0, 0x2c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C818: D001007C  stfs f0, 0x7c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 8220C81C: 4815B5D5  bl 0x82367df0
	ctx.lr = 0x8220C820;
	sub_82367DF0(ctx, base);
	// 8220C820: C0010050  lfs f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C824: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220C828: FDA00210  fabs f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8220C82C: C00B2150  lfs f0, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C830: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220C834: 40980024  bge cr6, 0x8220c858
	if !ctx.cr[6].lt {
	pc = 0x8220C858; continue 'dispatch;
	}
	// 8220C838: C1A10054  lfs f13, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220C83C: FDA06A10  fabs f13, f13
	ctx.f[13].u64 = ctx.f[13].u64 & !0x8000_0000_0000_0000u64;
	// 8220C840: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220C844: 40980014  bge cr6, 0x8220c858
	if !ctx.cr[6].lt {
	pc = 0x8220C858; continue 'dispatch;
	}
	// 8220C848: C0010074  lfs f0, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C84C: C0410064  lfs f2, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220C850: FC200050  fneg f1, f0
	ctx.f[1].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220C854: 4800000C  b 0x8220c860
	pc = 0x8220C860; continue 'dispatch;
	// 8220C858: C0410078  lfs f2, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220C85C: C0210068  lfs f1, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220C860: 48326649  bl 0x82532ea8
	ctx.lr = 0x8220C864;
	sub_82532EA8(ctx, base);
	// 8220C864: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220C868: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220C86C: C00B2254  lfs f0, 0x2254(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8788 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C870: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220C874: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8220C878: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220C87C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220C880: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C888(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220C888 size=72
    let mut pc: u32 = 0x8220C888;
    'dispatch: loop {
        match pc {
            0x8220C888 => {
    //   block [0x8220C888..0x8220C8D0)
	// 8220C888: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220C88C: C00B1FF8  lfs f0, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C890: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220C894: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8220C898: C00BBFFC  lfs f0, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C89C: 40990034  ble cr6, 0x8220c8d0
	if !ctx.cr[6].gt {
		sub_8220C8D0(ctx, base);
		return;
	}
	// 8220C8A0: EC01002A  fadds f0, f1, f0
	ctx.f[0].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220C8A4: 3961FFF0  addi r11, r1, -0x10
	ctx.r[11].s64 = ctx.r[1].s64 + -16;
	// 8220C8A8: FC00001E  fctiwz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 8220C8AC: 7C005FAE  stfiwx f0, 0, r11
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8220C8B0: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8220C8B4: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8220C8B8: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8220C8BC: C801FFF0  lfd f0, -0x10(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C8C0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8220C8C4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8220C8C8: EC210028  fsubs f1, f1, f0
	ctx.f[1].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220C8CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C8D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220C8D0 size=48
    let mut pc: u32 = 0x8220C8D0;
    'dispatch: loop {
        match pc {
            0x8220C8D0 => {
    //   block [0x8220C8D0..0x8220C900)
	// 8220C8D0: EC010028  fsubs f0, f1, f0
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220C8D4: 3961FFF0  addi r11, r1, -0x10
	ctx.r[11].s64 = ctx.r[1].s64 + -16;
	// 8220C8D8: FC00001E  fctiwz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 8220C8DC: 7C005FAE  stfiwx f0, 0, r11
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8220C8E0: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8220C8E4: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8220C8E8: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8220C8EC: C801FFF0  lfd f0, -0x10(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C8F0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8220C8F4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8220C8F8: EC210028  fsubs f1, f1, f0
	ctx.f[1].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220C8FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C900(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220C900 size=208
    let mut pc: u32 = 0x8220C900;
    'dispatch: loop {
        match pc {
            0x8220C900 => {
    //   block [0x8220C900..0x8220C9D0)
	// 8220C900: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220C904: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220C908: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220C90C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220C910: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8220C914: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220C918: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220C91C: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220C920: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220C924: 396B44B8  addi r11, r11, 0x44b8
	ctx.r[11].s64 = ctx.r[11].s64 + 17592;
	// 8220C928: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220C92C: C3EABA38  lfs f31, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220C930: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220C934: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220C938: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220C93C: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220C940: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220C944: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220C948: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220C94C: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220C950: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220C954: C01E0010  lfs f0, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C958: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220C95C: C01E0014  lfs f0, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C960: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220C964: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C968: D01F0018  stfs f0, 0x18(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220C96C: D3FF001C  stfs f31, 0x1c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220C970: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220C974: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220C978: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220C97C: 4815B89D  bl 0x82368218
	ctx.lr = 0x8220C980;
	sub_82368218(ctx, base);
	// 8220C980: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220C984: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220C988: 48167A19  bl 0x823743a0
	ctx.lr = 0x8220C98C;
	sub_823743A0(ctx, base);
	// 8220C98C: C01E0000  lfs f0, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C990: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220C994: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220C998: C01E0004  lfs f0, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C99C: D01F0034  stfs f0, 0x34(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220C9A0: C01E0008  lfs f0, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C9A4: D01F0038  stfs f0, 0x38(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220C9A8: D3FF003C  stfs f31, 0x3c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220C9AC: A17E0030  lhz r11, 0x30(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) } as u64;
	// 8220C9B0: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220C9B4: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220C9B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220C9BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220C9C0: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8220C9C4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220C9C8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220C9CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220C9D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220C9D0 size=116
    let mut pc: u32 = 0x8220C9D0;
    'dispatch: loop {
        match pc {
            0x8220C9D0 => {
    //   block [0x8220C9D0..0x8220CA44)
	// 8220C9D0: A1430020  lhz r10, 0x20(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220C9D4: C1A30010  lfs f13, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220C9D8: C1830014  lfs f12, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220C9DC: 39630030  addi r11, r3, 0x30
	ctx.r[11].s64 = ctx.r[3].s64 + 48;
	// 8220C9E0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8220C9E4: C1630018  lfs f11, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220C9E8: 7D4A28AE  lbzx r10, r10, r5
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8220C9EC: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8220C9F0: 7C0A242E  lfsx f0, r10, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220C9F4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220C9F8: D1A30010  stfs f13, 0x10(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220C9FC: EDA00332  fmuls f13, f0, f12
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220CA00: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220CA04: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8220CA08: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220CA0C: 81430050  lwz r10, 0x50(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220CA10: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220CA14: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220CA18: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220CA1C: 7D4A28AE  lbzx r10, r10, r5
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8220CA20: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8220CA24: 7C0A242E  lfsx f0, r10, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CA28: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CA2C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220CA30: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CA34: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220CA38: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CA3C: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220CA40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220CA48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220CA48 size=624
    let mut pc: u32 = 0x8220CA48;
    'dispatch: loop {
        match pc {
            0x8220CA48 => {
    //   block [0x8220CA48..0x8220CCB8)
	// 8220CA48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220CA4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220CA50: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220CA54: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 8220CA58: 1181038C  vspltisw v12, 1
	for i in 0..4 {
		ctx.v[12].u32[i] = 1;
	}
	// 8220CA5C: 39200030  li r9, 0x30
	ctx.r[9].s64 = 48;
	// 8220CA60: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 8220CA64: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 8220CA68: 1041634A  vcfsx v2, v12, 1
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (1 as u32)) << 23));
	for i in 0..4 {
		ctx.v[2].f32[i] = (ctx.v[12].s32[i] as f32) * scale;
	}
	// 8220CA6C: 38880040  addi r4, r8, 0x40
	ctx.r[4].s64 = ctx.r[8].s64 + 64;
	// 8220CA70: A1680022  lhz r11, 0x22(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220CA74: 1020634A  vcfsx v1, v12, 0
	let scale = f32::from_bits(((127u32 - (0 as u32)) << 23));
	for i in 0..4 {
		ctx.v[1].f32[i] = (ctx.v[12].s32[i] as f32) * scale;
	}
	// 8220CA78: 80A80050  lwz r5, 0x50(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(80 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220CCB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220CCB8 size=260
    let mut pc: u32 = 0x8220CCB8;
    'dispatch: loop {
        match pc {
            0x8220CCB8 => {
    //   block [0x8220CCB8..0x8220CDBC)
	// 8220CCB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220CCBC: 48328401  bl 0x825350bc
	ctx.lr = 0x8220CCC0;
	sub_82535080(ctx, base);
	// 8220CCC0: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8220CCC4: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220CCC8: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220CCCC: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220CCD0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220CCD4: 396B44C8  addi r11, r11, 0x44c8
	ctx.r[11].s64 = ctx.r[11].s64 + 17608;
	// 8220CCD8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220CCDC: C3EABA38  lfs f31, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220CCE0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220CCE4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220CCE8: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220CCEC: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220CCF0: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220CCF4: A15E004E  lhz r10, 0x4e(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220CCF8: A17E0034  lhz r11, 0x34(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220CCFC: B15F0020  sth r10, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[10].u16 ) };
	// 8220CD00: A15E004C  lhz r10, 0x4c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220CD04: B15F0022  sth r10, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[10].u16 ) };
	// 8220CD08: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220CD0C: C01E0010  lfs f0, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD10: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220CD14: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220CD18: C01E0014  lfs f0, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD1C: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220CD20: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220CD24: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD28: D01F0018  stfs f0, 0x18(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220CD2C: 7FAB2A14  add r29, r11, r5
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8220CD30: D3FF001C  stfs f31, 0x1c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220CD34: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220CD38: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220CD3C: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220CD40: 4815B4D9  bl 0x82368218
	ctx.lr = 0x8220CD44;
	sub_82368218(ctx, base);
	// 8220CD44: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220CD48: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220CD4C: 48167655  bl 0x823743a0
	ctx.lr = 0x8220CD50;
	sub_823743A0(ctx, base);
	// 8220CD50: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220CD54: C07D0028  lfs f3, 0x28(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220CD58: C05D0024  lfs f2, 0x24(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220CD5C: C03D0020  lfs f1, 0x20(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220CD60: 4815B4B9  bl 0x82368218
	ctx.lr = 0x8220CD64;
	sub_82368218(ctx, base);
	// 8220CD64: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220CD68: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 8220CD6C: 48167635  bl 0x823743a0
	ctx.lr = 0x8220CD70;
	sub_823743A0(ctx, base);
	// 8220CD70: C01E0000  lfs f0, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD74: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220CD78: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220CD7C: C01E0004  lfs f0, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD80: D01F0034  stfs f0, 0x34(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220CD84: C01E0008  lfs f0, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CD88: D01F0038  stfs f0, 0x38(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220CD8C: D3FF003C  stfs f31, 0x3c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220CD90: A17E0036  lhz r11, 0x36(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220CD94: 917F0060  stw r11, 0x60(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8220CD98: A17E0034  lhz r11, 0x34(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220CD9C: 917F0064  stw r11, 0x64(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220CDA0: A17D004C  lhz r11, 0x4c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220CDA4: 917F0068  stw r11, 0x68(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 8220CDA8: C01E0030  lfs f0, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CDAC: D01F006C  stfs f0, 0x6c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220CDB0: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 8220CDB4: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8220CDB8: 48328354  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220CDC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220CDC0 size=116
    let mut pc: u32 = 0x8220CDC0;
    'dispatch: loop {
        match pc {
            0x8220CDC0 => {
    //   block [0x8220CDC0..0x8220CE34)
	// 8220CDC0: A1430020  lhz r10, 0x20(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220CDC4: C1A30010  lfs f13, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220CDC8: C1830014  lfs f12, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220CDCC: 39630030  addi r11, r3, 0x30
	ctx.r[11].s64 = ctx.r[3].s64 + 48;
	// 8220CDD0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8220CDD4: C1630018  lfs f11, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220CDD8: 7D4A28AE  lbzx r10, r10, r5
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8220CDDC: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8220CDE0: 7C0A242E  lfsx f0, r10, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CDE4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CDE8: D1A30010  stfs f13, 0x10(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220CDEC: EDA00332  fmuls f13, f0, f12
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220CDF0: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220CDF4: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8220CDF8: D0030018  stfs f0, 0x18(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220CDFC: 81430060  lwz r10, 0x60(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(96 as u32) ) } as u64;
	// 8220CE00: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220CE04: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220CE08: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220CE0C: 7D4A28AE  lbzx r10, r10, r5
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8220CE10: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8220CE14: 7C0A242E  lfsx f0, r10, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CE18: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CE1C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220CE20: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CE24: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220CE28: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220CE2C: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220CE30: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220CE38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220CE38 size=80
    let mut pc: u32 = 0x8220CE38;
    'dispatch: loop {
        match pc {
            0x8220CE38 => {
    //   block [0x8220CE38..0x8220CE88)
	// 8220CE38: 39630030  addi r11, r3, 0x30
	ctx.r[11].s64 = ctx.r[3].s64 + 48;
	// 8220CE3C: C0030010  lfs f0, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CE40: C1A30014  lfs f13, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220CE44: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8220CE48: C1830018  lfs f12, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220CE4C: EDA10372  fmuls f13, f1, f13
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220CE50: ED810332  fmuls f12, f1, f12
	ctx.f[12].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220CE54: D0030010  stfs f0, 0x10(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220CE58: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220CE5C: D1830018  stfs f12, 0x18(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220CE60: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220CE64: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220CE68: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8220CE6C: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220CE70: EDAD0072  fmuls f13, f13, f1
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 8220CE74: ED8C0072  fmuls f12, f12, f1
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[1].f64) as f32) as f64);
	// 8220CE78: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220CE7C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220CE80: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220CE84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220CE88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8220CE88 size=708
    let mut pc: u32 = 0x8220CE88;
    'dispatch: loop {
        match pc {
            0x8220CE88 => {
    //   block [0x8220CE88..0x8220D14C)
	// 8220CE88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220CE8C: 4832822D  bl 0x825350b8
	ctx.lr = 0x8220CE90;
	sub_82535080(ctx, base);
	// 8220CE90: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 8220CE94: 48329155  bl 0x82535fe8
	ctx.lr = 0x8220CE98;
	sub_82535FB0(ctx, base);
	// 8220CE98: 9421FEC0  stwu r1, -0x140(r1)
	ea = ctx.r[1].u32.wrapping_add(-320 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220CE9C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220CEA0: 1181038C  vspltisw v12, 1
	for i in 0..4 {
		ctx.v[12].u32[i] = 1;
	}
	// 8220CEA4: 39200030  li r9, 0x30
	ctx.r[9].s64 = 48;
	// 8220CEA8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220CEAC: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 8220CEB0: 1161634A  vcfsx v11, v12, 1
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (1 as u32)) << 23));
	for i in 0..4 {
		ctx.v[11].f32[i] = (ctx.v[12].s32[i] as f32) * scale;
	}
	// 8220CEB4: 3B9F0040  addi r28, r31, 0x40
	ctx.r[28].s64 = ctx.r[31].s64 + 64;
	// 8220CEB8: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220CEBC: 1140634A  vcfsx v10, v12, 0
	let scale = f32::from_bits(((127u32 - (0 as u32)) << 23));
	for i in 0..4 {
		ctx.v[10].f32[i] = (ctx.v[12].s32[i] as f32) * scale;
	}
	// 8220CEC0: 80FF0060  lwz r7, 0x60(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(96 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D150(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D150 size=288
    let mut pc: u32 = 0x8220D150;
    'dispatch: loop {
        match pc {
            0x8220D150 => {
    //   block [0x8220D150..0x8220D270)
	// 8220D150: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D154: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D158: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220D15C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220D160: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D164: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220D168: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D16C: 396B44D8  addi r11, r11, 0x44d8
	ctx.r[11].s64 = ctx.r[11].s64 + 17624;
	// 8220D170: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220D174: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220D178: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220D17C: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220D180: A1640034  lhz r11, 0x34(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220D184: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220D188: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8220D18C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220D190: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D194: 7FCB2A14  add r30, r11, r5
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8220D198: 897E004B  lbz r11, 0x4b(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(75 as u32) ) } as u64;
	// 8220D19C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8220D1A0: 409A000C  bne cr6, 0x8220d1ac
	if !ctx.cr[6].eq {
	pc = 0x8220D1AC; continue 'dispatch;
	}
	// 8220D1A4: 552B043E  clrlwi r11, r9, 0x10
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0x0000FFFFu64;
	// 8220D1A8: 392B0015  addi r9, r11, 0x15
	ctx.r[9].s64 = ctx.r[11].s64 + 21;
	// 8220D1AC: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220D1B0: A144004E  lhz r10, 0x4e(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220D1B4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D1B8: C1ABBA38  lfs f13, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D1BC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D1C0: B15F0020  sth r10, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[10].u16 ) };
	// 8220D1C4: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D1C8: A164004C  lhz r11, 0x4c(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D1CC: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220D1D0: C1840010  lfs f12, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D1D4: D19F0010  stfs f12, 0x10(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220D1D8: C1840014  lfs f12, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D1DC: D19F0014  stfs f12, 0x14(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220D1E0: C1840018  lfs f12, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D1E4: B13F005C  sth r9, 0x5c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(92 as u32), ctx.r[9].u16 ) };
	// 8220D1E8: D19F0018  stfs f12, 0x18(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220D1EC: D1BF001C  stfs f13, 0x1c(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220D1F0: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D1F4: D01F0058  stfs f0, 0x58(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220D1F8: D01F0054  stfs f0, 0x54(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220D1FC: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220D200: B17F005E  sth r11, 0x5e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(94 as u32), ctx.r[11].u16 ) };
	// 8220D204: C0040030  lfs f0, 0x30(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D208: 89640036  lbz r11, 0x36(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220D20C: 396B0014  addi r11, r11, 0x14
	ctx.r[11].s64 = ctx.r[11].s64 + 20;
	// 8220D210: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D214: 7C0BFD2E  stfsx f0, r11, r31
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32), tmp.u32) };
	// 8220D218: C0640028  lfs f3, 0x28(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D21C: C0440024  lfs f2, 0x24(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D220: C0240020  lfs f1, 0x20(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D224: 4815AFF5  bl 0x82368218
	ctx.lr = 0x8220D228;
	sub_82368218(ctx, base);
	// 8220D228: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D22C: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220D230: 48167171  bl 0x823743a0
	ctx.lr = 0x8220D234;
	sub_823743A0(ctx, base);
	// 8220D234: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D238: C07E0028  lfs f3, 0x28(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D23C: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D240: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D244: 4815AFD5  bl 0x82368218
	ctx.lr = 0x8220D248;
	sub_82368218(ctx, base);
	// 8220D248: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D24C: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220D250: 48167151  bl 0x823743a0
	ctx.lr = 0x8220D254;
	sub_823743A0(ctx, base);
	// 8220D254: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220D258: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220D25C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220D260: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220D264: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220D268: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220D26C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D270(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D270 size=308
    let mut pc: u32 = 0x8220D270;
    'dispatch: loop {
        match pc {
            0x8220D270 => {
    //   block [0x8220D270..0x8220D3A4)
	// 8220D270: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D274: 48327E49  bl 0x825350bc
	ctx.lr = 0x8220D278;
	sub_82535080(ctx, base);
	// 8220D278: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D27C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D280: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220D284: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 8220D288: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D28C: 4815B2AD  bl 0x82368538
	ctx.lr = 0x8220D290;
	sub_82368538(ctx, base);
	// 8220D290: A17F005E  lhz r11, 0x5e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(94 as u32) ) } as u64;
	// 8220D294: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220D298: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D29C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D2A0: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D2A4: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220D2A8: 4815AB49  bl 0x82367df0
	ctx.lr = 0x8220D2AC;
	sub_82367DF0(ctx, base);
	// 8220D2AC: A17F005C  lhz r11, 0x5c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(92 as u32) ) } as u64;
	// 8220D2B0: C0010070  lfs f0, 0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D2B4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220D2B8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D2BC: C1A10064  lfs f13, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D2C0: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8220D2C4: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 8220D2C8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D2CC: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220D2D0: C0010080  lfs f0, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D2D4: C1A10068  lfs f13, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D2D8: 7CABEA14  add r5, r11, r29
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220D2DC: D1A10080  stfs f13, 0x80(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8220D2E0: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220D2E4: C0010084  lfs f0, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D2E8: C1A10078  lfs f13, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D2EC: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8220D2F0: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8220D2F4: 4815AAFD  bl 0x82367df0
	ctx.lr = 0x8220D2F8;
	sub_82367DF0(ctx, base);
	// 8220D2F8: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 8220D2FC: 38A10054  addi r5, r1, 0x54
	ctx.r[5].s64 = ctx.r[1].s64 + 84;
	// 8220D300: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D304: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 8220D308: 4815B309  bl 0x82368610
	ctx.lr = 0x8220D30C;
	sub_82368610(ctx, base);
	// 8220D30C: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220D310: C01F0050  lfs f0, 0x50(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D314: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D318: C1610050  lfs f11, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220D31C: EC2002F2  fmuls f1, f0, f11
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8220D320: C1BF0054  lfs f13, 0x54(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D324: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D328: C0010054  lfs f0, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D32C: EC4D0032  fmuls f2, f13, f0
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D330: C19F0058  lfs f12, 0x58(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D334: 7FCBEA14  add r30, r11, r29
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220D338: C0010058  lfs f0, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D33C: EC6C0032  fmuls f3, f12, f0
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D340: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220D344: 4815AED5  bl 0x82368218
	ctx.lr = 0x8220D348;
	sub_82368218(ctx, base);
	// 8220D348: 389F0030  addi r4, r31, 0x30
	ctx.r[4].s64 = ctx.r[31].s64 + 48;
	// 8220D34C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D350: 4815B1E9  bl 0x82368538
	ctx.lr = 0x8220D354;
	sub_82368538(ctx, base);
	// 8220D354: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8220D358: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220D35C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220D360: 4815AA91  bl 0x82367df0
	ctx.lr = 0x8220D364;
	sub_82367DF0(ctx, base);
	// 8220D364: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220D368: C1BF0010  lfs f13, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D36C: D1BE0030  stfs f13, 0x30(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220D370: C1BF0014  lfs f13, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D374: D1BE0034  stfs f13, 0x34(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220D378: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D37C: C1BF0018  lfs f13, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D380: D1BE0038  stfs f13, 0x38(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220D384: D01E003C  stfs f0, 0x3c(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220D388: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220D38C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D390: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D394: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220D398: 4815A999  bl 0x82367d30
	ctx.lr = 0x8220D39C;
	sub_82367D30(ctx, base);
	// 8220D39C: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 8220D3A0: 48327D6C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D3A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D3A8 size=224
    let mut pc: u32 = 0x8220D3A8;
    'dispatch: loop {
        match pc {
            0x8220D3A8 => {
    //   block [0x8220D3A8..0x8220D488)
	// 8220D3A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D3AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D3B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220D3B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220D3B8: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D3BC: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220D3C0: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220D3C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D3C8: 396B44E8  addi r11, r11, 0x44e8
	ctx.r[11].s64 = ctx.r[11].s64 + 17640;
	// 8220D3CC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220D3D0: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D3D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220D3D8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D3DC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220D3E0: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220D3E4: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220D3E8: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220D3EC: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220D3F0: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D3F4: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220D3F8: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D3FC: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220D400: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D404: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220D408: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D40C: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220D410: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220D414: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D418: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D41C: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D420: 4815ADF9  bl 0x82368218
	ctx.lr = 0x8220D424;
	sub_82368218(ctx, base);
	// 8220D424: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220D428: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D42C: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D430: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D434: 4815ADE5  bl 0x82368218
	ctx.lr = 0x8220D438;
	sub_82368218(ctx, base);
	// 8220D438: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220D43C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D440: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D444: 4815A9AD  bl 0x82367df0
	ctx.lr = 0x8220D448;
	sub_82367DF0(ctx, base);
	// 8220D448: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D44C: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220D450: 48166F51  bl 0x823743a0
	ctx.lr = 0x8220D454;
	sub_823743A0(ctx, base);
	// 8220D454: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D458: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220D45C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220D460: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D464: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220D468: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D46C: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220D470: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220D474: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220D478: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220D47C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220D480: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220D484: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D488(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D488 size=240
    let mut pc: u32 = 0x8220D488;
    'dispatch: loop {
        match pc {
            0x8220D488 => {
    //   block [0x8220D488..0x8220D578)
	// 8220D488: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D48C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D490: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D494: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 8220D498: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8220D49C: 38880030  addi r4, r8, 0x30
	ctx.r[4].s64 = ctx.r[8].s64 + 48;
	// 8220D4A0: A1680020  lhz r11, 0x20(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220D4A4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D4A8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D4AC: 7C6B5214  add r3, r11, r10
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220D4B0: 4815B089  bl 0x82368538
	ctx.lr = 0x8220D4B4;
	sub_82368538(ctx, base);
	// 8220D4B4: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220D4B8: C1A80010  lfs f13, 0x10(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D4BC: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8220D4C0: D1A30030  stfs f13, 0x30(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220D4C4: C1A80014  lfs f13, 0x14(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D4C8: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220D4CC: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D4D0: C1A80018  lfs f13, 0x18(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D4D4: D1A30038  stfs f13, 0x38(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220D4D8: D003003C  stfs f0, 0x3c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220D4DC: A1680022  lhz r11, 0x22(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220D4E0: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D4E4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D4E8: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220D4EC: 4815A845  bl 0x82367d30
	ctx.lr = 0x8220D4F0;
	sub_82367D30(ctx, base);
	// 8220D4F0: C1880040  lfs f12, 0x40(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(64 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D4F4: C1630000  lfs f11, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220D4F8: C0080048  lfs f0, 0x48(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(72 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D4FC: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220D500: C1A80044  lfs f13, 0x44(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D504: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220D508: C1230008  lfs f9, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220D50C: D1630000  stfs f11, 0(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220D510: ED6A0332  fmuls f11, f10, f12
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220D514: C1030010  lfs f8, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220D518: ED890332  fmuls f12, f9, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220D51C: C0E30014  lfs f7, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220D520: ED080372  fmuls f8, f8, f13
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220D524: C0C30018  lfs f6, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220D528: D1830008  stfs f12, 8(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220D52C: ED870372  fmuls f12, f7, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220D530: C0A30020  lfs f5, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220D534: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220D538: C0830024  lfs f4, 0x24(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220D53C: ECA50032  fmuls f5, f5, f0
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D540: C0630028  lfs f3, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D544: D1A30018  stfs f13, 0x18(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220D548: EDA40032  fmuls f13, f4, f0
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D54C: EC030032  fmuls f0, f3, f0
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D550: D0A30020  stfs f5, 0x20(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220D554: D1030010  stfs f8, 0x10(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220D558: D1630004  stfs f11, 4(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220D55C: D1830014  stfs f12, 0x14(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220D560: D1A30024  stfs f13, 0x24(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220D564: D0030028  stfs f0, 0x28(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220D568: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220D56C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220D570: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220D574: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D578 size=228
    let mut pc: u32 = 0x8220D578;
    'dispatch: loop {
        match pc {
            0x8220D578 => {
    //   block [0x8220D578..0x8220D65C)
	// 8220D578: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D57C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D580: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220D584: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220D588: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D58C: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220D590: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220D594: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D598: 396B44F8  addi r11, r11, 0x44f8
	ctx.r[11].s64 = ctx.r[11].s64 + 17656;
	// 8220D59C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D5A0: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D5A4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220D5A8: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220D5AC: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220D5B0: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220D5B4: A144004E  lhz r10, 0x4e(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220D5B8: A164004C  lhz r11, 0x4c(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D5BC: B15F0020  sth r10, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[10].u16 ) };
	// 8220D5C0: A144004C  lhz r10, 0x4c(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D5C4: B15F0022  sth r10, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[10].u16 ) };
	// 8220D5C8: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220D5CC: C1A40010  lfs f13, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D5D0: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220D5D4: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220D5D8: C1A40014  lfs f13, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D5DC: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D5E0: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220D5E4: C1A40018  lfs f13, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D5E8: 7FCB2A14  add r30, r11, r5
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8220D5EC: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220D5F0: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220D5F4: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D5F8: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8220D5FC: C0040030  lfs f0, 0x30(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D600: D01F0054  stfs f0, 0x54(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220D604: C0640028  lfs f3, 0x28(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D608: C0440024  lfs f2, 0x24(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D60C: C0240020  lfs f1, 0x20(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D610: 4815AC09  bl 0x82368218
	ctx.lr = 0x8220D614;
	sub_82368218(ctx, base);
	// 8220D614: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D618: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220D61C: 48166D85  bl 0x823743a0
	ctx.lr = 0x8220D620;
	sub_823743A0(ctx, base);
	// 8220D620: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D624: C07E0028  lfs f3, 0x28(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D628: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D62C: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D630: 4815ABE9  bl 0x82368218
	ctx.lr = 0x8220D634;
	sub_82368218(ctx, base);
	// 8220D634: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D638: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220D63C: 48166D65  bl 0x823743a0
	ctx.lr = 0x8220D640;
	sub_823743A0(ctx, base);
	// 8220D640: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220D644: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220D648: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220D64C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220D650: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220D654: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220D658: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D660 size=612
    let mut pc: u32 = 0x8220D660;
    'dispatch: loop {
        match pc {
            0x8220D660 => {
    //   block [0x8220D660..0x8220D8C4)
	// 8220D660: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D664: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D668: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220D66C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220D670: DBC1FFD8  stfd f30, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[30].u64 ) };
	// 8220D674: DBE1FFE0  stfd f31, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8220D678: 9421FEB0  stwu r1, -0x150(r1)
	ea = ctx.r[1].u32.wrapping_add(-336 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D67C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D680: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220D684: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 8220D688: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D68C: 4815AEAD  bl 0x82368538
	ctx.lr = 0x8220D690;
	sub_82368538(ctx, base);
	// 8220D690: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8220D694: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220D698: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D69C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D6A0: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D6A4: 4815A74D  bl 0x82367df0
	ctx.lr = 0x8220D6A8;
	sub_82367DF0(ctx, base);
	// 8220D6A8: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220D6AC: C0010070  lfs f0, 0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D6B0: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220D6B4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D6B8: C1A10064  lfs f13, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D6BC: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8220D6C0: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 8220D6C4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D6C8: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220D6CC: C0010080  lfs f0, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D6D0: C1A10068  lfs f13, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D6D4: 7CABF214  add r5, r11, r30
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D6D8: D1A10080  stfs f13, 0x80(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8220D6DC: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220D6E0: C0010084  lfs f0, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D6E4: C1A10078  lfs f13, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D6E8: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8220D6EC: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8220D6F0: 4815A701  bl 0x82367df0
	ctx.lr = 0x8220D6F4;
	sub_82367DF0(ctx, base);
	// 8220D6F4: C18100A4  lfs f12, 0xa4(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220D6F8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D6FC: FDA06210  fabs f13, f12
	ctx.f[13].u64 = ctx.f[12].u64 & !0x8000_0000_0000_0000u64;
	// 8220D700: C16100A8  lfs f11, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220D704: C00B2150  lfs f0, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D708: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220D70C: C3CBBA38  lfs f30, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8220D710: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220D714: 4098004C  bge cr6, 0x8220d760
	if !ctx.cr[6].lt {
	pc = 0x8220D760; continue 'dispatch;
	}
	// 8220D718: FDA05A10  fabs f13, f11
	ctx.f[13].u64 = ctx.f[11].u64 & !0x8000_0000_0000_0000u64;
	// 8220D71C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220D720: 40980040  bge cr6, 0x8220d760
	if !ctx.cr[6].lt {
	pc = 0x8220D760; continue 'dispatch;
	}
	// 8220D724: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D728: C00100A0  lfs f0, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D72C: 396B1FF8  addi r11, r11, 0x1ff8
	ctx.r[11].s64 = ctx.r[11].s64 + 8184;
	// 8220D730: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220D734: D3E10054  stfs f31, 0x54(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220D738: FF00F800  fcmpu cr6, f0, f31
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[31].f64);
	// 8220D73C: D3E10050  stfs f31, 0x50(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220D740: 40990010  ble cr6, 0x8220d750
	if !ctx.cr[6].gt {
	pc = 0x8220D750; continue 'dispatch;
	}
	// 8220D744: D3C1005C  stfs f30, 0x5c(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220D748: D3E10058  stfs f31, 0x58(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220D74C: 48000080  b 0x8220d7cc
	pc = 0x8220D7CC; continue 'dispatch;
	// 8220D750: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D754: D3E1005C  stfs f31, 0x5c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220D758: C00B2074  lfs f0, 0x2074(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8308 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D75C: 4800006C  b 0x8220d7c8
	pc = 0x8220D7C8; continue 'dispatch;
	// 8220D760: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D764: C00100A0  lfs f0, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D768: C1ABBFFC  lfs f13, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D76C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D770: EC000372  fmuls f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220D774: 396B1FF8  addi r11, r11, 0x1ff8
	ctx.r[11].s64 = ctx.r[11].s64 + 8184;
	// 8220D778: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220D77C: FD400210  fabs f10, f0
	ctx.f[10].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8220D780: FF0A6800  fcmpu cr6, f10, f13
	ctx.cr[6].compare_f64(ctx.f[10].f64, ctx.f[13].f64);
	// 8220D784: 4099001C  ble cr6, 0x8220d7a0
	if !ctx.cr[6].gt {
	pc = 0x8220D7A0; continue 'dispatch;
	}
	// 8220D788: FF00F800  fcmpu cr6, f0, f31
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[31].f64);
	// 8220D78C: 4099000C  ble cr6, 0x8220d798
	if !ctx.cr[6].gt {
	pc = 0x8220D798; continue 'dispatch;
	}
	// 8220D790: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 8220D794: 4800000C  b 0x8220d7a0
	pc = 0x8220D7A0; continue 'dispatch;
	// 8220D798: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D79C: C00B2048  lfs f0, 0x2048(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8264 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D7A0: ED4D0028  fsubs f10, f13, f0
	ctx.f[10].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220D7A4: D3E10050  stfs f31, 0x50(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220D7A8: EDA0682A  fadds f13, f0, f13
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220D7AC: EC00502C  fsqrts f0, f10
	ctx.f[0].f64 = ((ctx.f[10].f64).sqrt() as f32) as f64;
	// 8220D7B0: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D7B4: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D7B8: EDA0682C  fsqrts f13, f13
	ctx.f[13].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 8220D7BC: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220D7C0: FC006050  fneg f0, f12
	ctx.f[0].u64 = ctx.f[12].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220D7C4: D1A1005C  stfs f13, 0x5c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220D7C8: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220D7CC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D7D0: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 8220D7D4: 4815AD65  bl 0x82368538
	ctx.lr = 0x8220D7D8;
	sub_82368538(ctx, base);
	// 8220D7D8: 38A100A0  addi r5, r1, 0xa0
	ctx.r[5].s64 = ctx.r[1].s64 + 160;
	// 8220D7DC: 388100E0  addi r4, r1, 0xe0
	ctx.r[4].s64 = ctx.r[1].s64 + 224;
	// 8220D7E0: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 8220D7E4: 4815A60D  bl 0x82367df0
	ctx.lr = 0x8220D7E8;
	sub_82367DF0(ctx, base);
	// 8220D7E8: C0410108  lfs f2, 0x108(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D7EC: C02100F8  lfs f1, 0xf8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D7F0: 483256B9  bl 0x82532ea8
	ctx.lr = 0x8220D7F4;
	sub_82532EA8(ctx, base);
	// 8220D7F4: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220D7F8: FD800818  frsp f12, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220D7FC: C01F0054  lfs f0, 0x54(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D800: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D804: EDBE0028  fsubs f13, f30, f0
	ctx.f[13].f64 = (((ctx.f[30].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220D808: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D80C: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D810: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220D814: C00B2254  lfs f0, 0x2254(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8788 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D818: EC0C0032  fmuls f0, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D81C: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220D820: FC200050  fneg f1, f0
	ctx.f[1].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220D824: 4815A66D  bl 0x82367e90
	ctx.lr = 0x8220D828;
	sub_82367E90(ctx, base);
	// 8220D828: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220D82C: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D830: 389F0030  addi r4, r31, 0x30
	ctx.r[4].s64 = ctx.r[31].s64 + 48;
	// 8220D834: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D838: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D83C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D840: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D844: D00B0030  stfs f0, 0x30(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220D848: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D84C: D00B0034  stfs f0, 0x34(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220D850: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D854: D00B0038  stfs f0, 0x38(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220D858: D3CB003C  stfs f30, 0x3c(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220D85C: 4815ACDD  bl 0x82368538
	ctx.lr = 0x8220D860;
	sub_82368538(ctx, base);
	// 8220D860: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220D864: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220D868: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D86C: D3E10098  stfs f31, 0x98(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 8220D870: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D874: D3E10094  stfs f31, 0x94(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 8220D878: D3E10090  stfs f31, 0x90(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 8220D87C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D880: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D884: 4815A4AD  bl 0x82367d30
	ctx.lr = 0x8220D888;
	sub_82367D30(ctx, base);
	// 8220D888: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220D88C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220D890: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220D894: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D898: 7CABF214  add r5, r11, r30
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D89C: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8220D8A0: 4815A491  bl 0x82367d30
	ctx.lr = 0x8220D8A4;
	sub_82367D30(ctx, base);
	// 8220D8A4: 38210150  addi r1, r1, 0x150
	ctx.r[1].s64 = ctx.r[1].s64 + 336;
	// 8220D8A8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220D8AC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220D8B0: CBC1FFD8  lfd f30, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8220D8B4: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8220D8B8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220D8BC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220D8C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D8C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D8C8 size=216
    let mut pc: u32 = 0x8220D8C8;
    'dispatch: loop {
        match pc {
            0x8220D8C8 => {
    //   block [0x8220D8C8..0x8220D9A0)
	// 8220D8C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D8CC: 483277F1  bl 0x825350bc
	ctx.lr = 0x8220D8D0;
	sub_82535080(ctx, base);
	// 8220D8D0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D8D4: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220D8D8: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220D8DC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D8E0: 396B4508  addi r11, r11, 0x4508
	ctx.r[11].s64 = ctx.r[11].s64 + 17672;
	// 8220D8E4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220D8E8: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D8EC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220D8F0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D8F4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220D8F8: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220D8FC: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220D900: A15E004E  lhz r10, 0x4e(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220D904: A17E0036  lhz r11, 0x36(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220D908: B15F0020  sth r10, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[10].u16 ) };
	// 8220D90C: A15E004C  lhz r10, 0x4c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220D910: B15F0022  sth r10, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[10].u16 ) };
	// 8220D914: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220D918: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D91C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220D920: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220D924: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D928: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220D92C: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D930: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D934: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220D938: 7FAB2A14  add r29, r11, r5
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8220D93C: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220D940: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D944: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D948: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D94C: 4815A8CD  bl 0x82368218
	ctx.lr = 0x8220D950;
	sub_82368218(ctx, base);
	// 8220D950: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D954: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220D958: 48166A49  bl 0x823743a0
	ctx.lr = 0x8220D95C;
	sub_823743A0(ctx, base);
	// 8220D95C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220D960: C07D0028  lfs f3, 0x28(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220D964: C05D0024  lfs f2, 0x24(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220D968: C03D0020  lfs f1, 0x20(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220D96C: 4815A8AD  bl 0x82368218
	ctx.lr = 0x8220D970;
	sub_82368218(ctx, base);
	// 8220D970: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220D974: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220D978: 48166A29  bl 0x823743a0
	ctx.lr = 0x8220D97C;
	sub_823743A0(ctx, base);
	// 8220D97C: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D980: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220D984: A17E0034  lhz r11, 0x34(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220D988: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220D98C: 917F0054  stw r11, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220D990: A17E0036  lhz r11, 0x36(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220D994: 917F0058  stw r11, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8220D998: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220D99C: 48327770  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220D9A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220D9A0 size=332
    let mut pc: u32 = 0x8220D9A0;
    'dispatch: loop {
        match pc {
            0x8220D9A0 => {
    //   block [0x8220D9A0..0x8220DAEC)
	// 8220D9A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220D9A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220D9A8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220D9AC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220D9B0: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8220D9B4: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220D9B8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220D9BC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220D9C0: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 8220D9C4: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 8220D9C8: 4815AB71  bl 0x82368538
	ctx.lr = 0x8220D9CC;
	sub_82368538(ctx, base);
	// 8220D9CC: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8220D9D0: 38A100B0  addi r5, r1, 0xb0
	ctx.r[5].s64 = ctx.r[1].s64 + 176;
	// 8220D9D4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D9D8: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220D9DC: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220D9E0: 4815A411  bl 0x82367df0
	ctx.lr = 0x8220D9E4;
	sub_82367DF0(ctx, base);
	// 8220D9E4: 817F0058  lwz r11, 0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 8220D9E8: C0010070  lfs f0, 0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220D9EC: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220D9F0: C1A10064  lfs f13, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220D9F4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220D9F8: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8220D9FC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220DA00: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220DA04: 7CABF214  add r5, r11, r30
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220DA08: C0010080  lfs f0, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DA0C: C1A10068  lfs f13, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DA10: D1A10080  stfs f13, 0x80(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8220DA14: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220DA18: C0010084  lfs f0, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DA1C: C1A10078  lfs f13, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DA20: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8220DA24: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8220DA28: 4815A3C9  bl 0x82367df0
	ctx.lr = 0x8220DA2C;
	sub_82367DF0(ctx, base);
	// 8220DA2C: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220DA30: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220DA34: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 8220DA38: C3EBBA38  lfs f31, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220DA3C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DA40: D3E1005C  stfs f31, 0x5c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220DA44: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DA48: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220DA4C: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220DA50: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220DA54: 4816694D  bl 0x823743a0
	ctx.lr = 0x8220DA58;
	sub_823743A0(ctx, base);
	// 8220DA58: 38A100A0  addi r5, r1, 0xa0
	ctx.r[5].s64 = ctx.r[1].s64 + 160;
	// 8220DA5C: C03F0050  lfs f1, 0x50(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DA60: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DA64: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DA68: 48166D39  bl 0x823747a0
	ctx.lr = 0x8220DA6C;
	sub_823747A0(ctx, base);
	// 8220DA6C: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220DA70: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DA74: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DA78: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DA7C: 7CABF214  add r5, r11, r30
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220DA80: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8220DA84: 4815AAB5  bl 0x82368538
	ctx.lr = 0x8220DA88;
	sub_82368538(ctx, base);
	// 8220DA88: 389F0030  addi r4, r31, 0x30
	ctx.r[4].s64 = ctx.r[31].s64 + 48;
	// 8220DA8C: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 8220DA90: 4815AAA9  bl 0x82368538
	ctx.lr = 0x8220DA94;
	sub_82368538(ctx, base);
	// 8220DA94: 388100B0  addi r4, r1, 0xb0
	ctx.r[4].s64 = ctx.r[1].s64 + 176;
	// 8220DA98: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8220DA9C: 4815A355  bl 0x82367df0
	ctx.lr = 0x8220DAA0;
	sub_82367DF0(ctx, base);
	// 8220DAA0: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DAA4: D0050030  stfs f0, 0x30(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220DAA8: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DAAC: D0050034  stfs f0, 0x34(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220DAB0: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DAB4: D0050038  stfs f0, 0x38(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220DAB8: D3E5003C  stfs f31, 0x3c(r5)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220DABC: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220DAC0: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DAC4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DAC8: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8220DACC: 4815A265  bl 0x82367d30
	ctx.lr = 0x8220DAD0;
	sub_82367D30(ctx, base);
	// 8220DAD0: 38210110  addi r1, r1, 0x110
	ctx.r[1].s64 = ctx.r[1].s64 + 272;
	// 8220DAD4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220DAD8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220DADC: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8220DAE0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220DAE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220DAE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220DAF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220DAF0 size=296
    let mut pc: u32 = 0x8220DAF0;
    'dispatch: loop {
        match pc {
            0x8220DAF0 => {
    //   block [0x8220DAF0..0x8220DC18)
	// 8220DAF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220DAF4: 483275C9  bl 0x825350bc
	ctx.lr = 0x8220DAF8;
	sub_82535080(ctx, base);
	// 8220DAF8: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220DAFC: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220DB00: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220DB04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220DB08: 396B4518  addi r11, r11, 0x4518
	ctx.r[11].s64 = ctx.r[11].s64 + 17688;
	// 8220DB0C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220DB10: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DB14: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220DB18: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DB1C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8220DB20: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220DB24: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220DB28: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220DB2C: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220DB30: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220DB34: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220DB38: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220DB3C: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DB40: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220DB44: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DB48: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220DB4C: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DB50: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220DB54: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220DB58: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DB5C: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DB60: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DB64: 4815A6B5  bl 0x82368218
	ctx.lr = 0x8220DB68;
	sub_82368218(ctx, base);
	// 8220DB68: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DB6C: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220DB70: 48166831  bl 0x823743a0
	ctx.lr = 0x8220DB74;
	sub_823743A0(ctx, base);
	// 8220DB74: A17E0036  lhz r11, 0x36(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220DB78: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DB7C: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220DB80: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220DB84: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DB88: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DB8C: C06B0028  lfs f3, 0x28(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DB90: C04B0024  lfs f2, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DB94: C02B0020  lfs f1, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DB98: 4815A681  bl 0x82368218
	ctx.lr = 0x8220DB9C;
	sub_82368218(ctx, base);
	// 8220DB9C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DBA0: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 8220DBA4: 481667FD  bl 0x823743a0
	ctx.lr = 0x8220DBA8;
	sub_823743A0(ctx, base);
	// 8220DBA8: A17E003C  lhz r11, 0x3c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(60 as u32) ) } as u64;
	// 8220DBAC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DBB0: 556A103E  rotlwi r10, r11, 2
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8220DBB4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8220DBB8: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DBBC: 7FABEA14  add r29, r11, r29
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DBC0: C07D0028  lfs f3, 0x28(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DBC4: C05D0024  lfs f2, 0x24(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DBC8: C03D0020  lfs f1, 0x20(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DBCC: 4815A64D  bl 0x82368218
	ctx.lr = 0x8220DBD0;
	sub_82368218(ctx, base);
	// 8220DBD0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DBD4: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 8220DBD8: 481667C9  bl 0x823743a0
	ctx.lr = 0x8220DBDC;
	sub_823743A0(ctx, base);
	// 8220DBDC: A17D004C  lhz r11, 0x4c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220DBE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220DBE4: B17F006E  sth r11, 0x6e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(110 as u32), ctx.r[11].u16 ) };
	// 8220DBE8: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DBEC: D01F0060  stfs f0, 0x60(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220DBF0: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DBF4: D01F0064  stfs f0, 0x64(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220DBF8: A17E0034  lhz r11, 0x34(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) } as u64;
	// 8220DBFC: B17F0068  sth r11, 0x68(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), ctx.r[11].u16 ) };
	// 8220DC00: A17E0036  lhz r11, 0x36(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(54 as u32) ) } as u64;
	// 8220DC04: B17F006A  sth r11, 0x6a(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(106 as u32), ctx.r[11].u16 ) };
	// 8220DC08: A17E003C  lhz r11, 0x3c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(60 as u32) ) } as u64;
	// 8220DC0C: B17F006C  sth r11, 0x6c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[11].u16 ) };
	// 8220DC10: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220DC14: 483274F8  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220DC18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220DC18 size=432
    let mut pc: u32 = 0x8220DC18;
    'dispatch: loop {
        match pc {
            0x8220DC18 => {
    //   block [0x8220DC18..0x8220DDC8)
	// 8220DC18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220DC1C: 483274A1  bl 0x825350bc
	ctx.lr = 0x8220DC20;
	sub_82535080(ctx, base);
	// 8220DC20: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8220DC24: 9421FEC0  stwu r1, -0x140(r1)
	ea = ctx.r[1].u32.wrapping_add(-320 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220DC28: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220DC2C: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220DC30: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 8220DC34: 386100D0  addi r3, r1, 0xd0
	ctx.r[3].s64 = ctx.r[1].s64 + 208;
	// 8220DC38: 4815A901  bl 0x82368538
	ctx.lr = 0x8220DC3C;
	sub_82368538(ctx, base);
	// 8220DC3C: A17F0068  lhz r11, 0x68(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(104 as u32) ) } as u64;
	// 8220DC40: 38A100D0  addi r5, r1, 0xd0
	ctx.r[5].s64 = ctx.r[1].s64 + 208;
	// 8220DC44: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DC48: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8220DC4C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DC50: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DC54: 4815A19D  bl 0x82367df0
	ctx.lr = 0x8220DC58;
	sub_82367DF0(ctx, base);
	// 8220DC58: A17F006A  lhz r11, 0x6a(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(106 as u32) ) } as u64;
	// 8220DC5C: C0010080  lfs f0, 0x80(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DC60: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8220DC64: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DC68: C1A10074  lfs f13, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DC6C: D1A10080  stfs f13, 0x80(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8220DC70: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8220DC74: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DC78: D0010074  stfs f0, 0x74(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 8220DC7C: C0010090  lfs f0, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DC80: C1A10078  lfs f13, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DC84: 7CABEA14  add r5, r11, r29
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DC88: D1A10090  stfs f13, 0x90(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 8220DC8C: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8220DC90: C0010094  lfs f0, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DC94: C1A10088  lfs f13, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DC98: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 8220DC9C: D0010088  stfs f0, 0x88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8220DCA0: 4815A151  bl 0x82367df0
	ctx.lr = 0x8220DCA4;
	sub_82367DF0(ctx, base);
	// 8220DCA4: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220DCA8: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8220DCAC: 386100C0  addi r3, r1, 0xc0
	ctx.r[3].s64 = ctx.r[1].s64 + 192;
	// 8220DCB0: C3EBBA38  lfs f31, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220DCB4: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DCB8: D3E1006C  stfs f31, 0x6c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220DCBC: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DCC0: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220DCC4: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220DCC8: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220DCCC: 481666D5  bl 0x823743a0
	ctx.lr = 0x8220DCD0;
	sub_823743A0(ctx, base);
	// 8220DCD0: 38A100C0  addi r5, r1, 0xc0
	ctx.r[5].s64 = ctx.r[1].s64 + 192;
	// 8220DCD4: C03F0060  lfs f1, 0x60(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(96 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DCD8: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220DCDC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220DCE0: 48166AC1  bl 0x823747a0
	ctx.lr = 0x8220DCE4;
	sub_823747A0(ctx, base);
	// 8220DCE4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220DCE8: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8220DCEC: 4815A84D  bl 0x82368538
	ctx.lr = 0x8220DCF0;
	sub_82368538(ctx, base);
	// 8220DCF0: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 8220DCF4: 38A10054  addi r5, r1, 0x54
	ctx.r[5].s64 = ctx.r[1].s64 + 84;
	// 8220DCF8: 388100B0  addi r4, r1, 0xb0
	ctx.r[4].s64 = ctx.r[1].s64 + 176;
	// 8220DCFC: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8220DD00: 4815A911  bl 0x82368610
	ctx.lr = 0x8220DD04;
	sub_82368610(ctx, base);
	// 8220DD04: 389F0050  addi r4, r31, 0x50
	ctx.r[4].s64 = ctx.r[31].s64 + 80;
	// 8220DD08: 386100D0  addi r3, r1, 0xd0
	ctx.r[3].s64 = ctx.r[1].s64 + 208;
	// 8220DD0C: 4815A82D  bl 0x82368538
	ctx.lr = 0x8220DD10;
	sub_82368538(ctx, base);
	// 8220DD10: A17F006E  lhz r11, 0x6e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(110 as u32) ) } as u64;
	// 8220DD14: 38A100D0  addi r5, r1, 0xd0
	ctx.r[5].s64 = ctx.r[1].s64 + 208;
	// 8220DD18: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DD1C: 386100D0  addi r3, r1, 0xd0
	ctx.r[3].s64 = ctx.r[1].s64 + 208;
	// 8220DD20: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DD24: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DD28: 4815A0C9  bl 0x82367df0
	ctx.lr = 0x8220DD2C;
	sub_82367DF0(ctx, base);
	// 8220DD2C: A17F006C  lhz r11, 0x6c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(108 as u32) ) } as u64;
	// 8220DD30: 388100D0  addi r4, r1, 0xd0
	ctx.r[4].s64 = ctx.r[1].s64 + 208;
	// 8220DD34: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DD38: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DD3C: 7C6BEA14  add r3, r11, r29
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DD40: 4BFFEA41  bl 0x8220c780
	ctx.lr = 0x8220DD44;
	sub_8220C780(ctx, base);
	// 8220DD44: C01F0064  lfs f0, 0x64(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(100 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DD48: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220DD4C: EC010032  fmuls f0, f1, f0
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220DD50: C0610050  lfs f3, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DD54: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DD58: C0410054  lfs f2, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DD5C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DD60: 7FCBEA14  add r30, r11, r29
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DD64: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220DD68: FC200050  fneg f1, f0
	ctx.f[1].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220DD6C: 4815A4AD  bl 0x82368218
	ctx.lr = 0x8220DD70;
	sub_82368218(ctx, base);
	// 8220DD70: 389F0030  addi r4, r31, 0x30
	ctx.r[4].s64 = ctx.r[31].s64 + 48;
	// 8220DD74: 386100D0  addi r3, r1, 0xd0
	ctx.r[3].s64 = ctx.r[1].s64 + 208;
	// 8220DD78: 4815A7C1  bl 0x82368538
	ctx.lr = 0x8220DD7C;
	sub_82368538(ctx, base);
	// 8220DD7C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8220DD80: 388100D0  addi r4, r1, 0xd0
	ctx.r[4].s64 = ctx.r[1].s64 + 208;
	// 8220DD84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220DD88: 4815A069  bl 0x82367df0
	ctx.lr = 0x8220DD8C;
	sub_82367DF0(ctx, base);
	// 8220DD8C: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DD90: D01E0030  stfs f0, 0x30(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220DD94: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DD98: D01E0034  stfs f0, 0x34(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220DD9C: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DDA0: D01E0038  stfs f0, 0x38(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220DDA4: D3FE003C  stfs f31, 0x3c(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220DDA8: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220DDAC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DDB0: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DDB4: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220DDB8: 48159F79  bl 0x82367d30
	ctx.lr = 0x8220DDBC;
	sub_82367D30(ctx, base);
	// 8220DDBC: 38210140  addi r1, r1, 0x140
	ctx.r[1].s64 = ctx.r[1].s64 + 320;
	// 8220DDC0: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8220DDC4: 48327348  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220DDC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220DDC8 size=212
    let mut pc: u32 = 0x8220DDC8;
    'dispatch: loop {
        match pc {
            0x8220DDC8 => {
    //   block [0x8220DDC8..0x8220DE9C)
	// 8220DDC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220DDCC: 483272F1  bl 0x825350bc
	ctx.lr = 0x8220DDD0;
	sub_82535080(ctx, base);
	// 8220DDD0: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220DDD4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220DDD8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220DDDC: 396B4538  addi r11, r11, 0x4538
	ctx.r[11].s64 = ctx.r[11].s64 + 17720;
	// 8220DDE0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8220DDE4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220DDE8: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220DDEC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DDF0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220DDF4: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8220DDF8: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8220DDFC: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220DE00: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DE04: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220DE08: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220DE0C: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220DE10: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DE14: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220DE18: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DE1C: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220DE20: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DE24: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220DE28: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220DE2C: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DE30: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DE34: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DE38: 4815A3E1  bl 0x82368218
	ctx.lr = 0x8220DE3C;
	sub_82368218(ctx, base);
	// 8220DE3C: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220DE40: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220DE44: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DE48: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DE4C: 4815A3CD  bl 0x82368218
	ctx.lr = 0x8220DE50;
	sub_82368218(ctx, base);
	// 8220DE50: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220DE54: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DE58: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220DE5C: 48159F95  bl 0x82367df0
	ctx.lr = 0x8220DE60;
	sub_82367DF0(ctx, base);
	// 8220DE60: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220DE64: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220DE68: 48166539  bl 0x823743a0
	ctx.lr = 0x8220DE6C;
	sub_823743A0(ctx, base);
	// 8220DE6C: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DE70: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220DE74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220DE78: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DE7C: D01F004C  stfs f0, 0x4c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 8220DE80: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DE84: 93BF0040  stw r29, 0x40(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[29].u32 ) };
	// 8220DE88: D01F0050  stfs f0, 0x50(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220DE8C: B3BF0044  sth r29, 0x44(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[29].u16 ) };
	// 8220DE90: B3BF0046  sth r29, 0x46(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(70 as u32), ctx.r[29].u16 ) };
	// 8220DE94: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220DE98: 48327274  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220DEA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220DEA0 size=744
    let mut pc: u32 = 0x8220DEA0;
    'dispatch: loop {
        match pc {
            0x8220DEA0 => {
    //   block [0x8220DEA0..0x8220E188)
	// 8220DEA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220DEA4: 48327215  bl 0x825350b8
	ctx.lr = 0x8220DEA8;
	sub_82535080(ctx, base);
	// 8220DEA8: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 8220DEAC: 4832813D  bl 0x82535fe8
	ctx.lr = 0x8220DEB0;
	sub_82535FB0(ctx, base);
	// 8220DEB0: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220DEB4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220DEB8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8220DEBC: 389E0030  addi r4, r30, 0x30
	ctx.r[4].s64 = ctx.r[30].s64 + 48;
	// 8220DEC0: A17E0020  lhz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220DEC4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DEC8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DECC: 7FEBE214  add r31, r11, r28
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220DED0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220DED4: 4815A665  bl 0x82368538
	ctx.lr = 0x8220DED8;
	sub_82368538(ctx, base);
	// 8220DED8: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220DEDC: C1BE0010  lfs f13, 0x10(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DEE0: D1BF0030  stfs f13, 0x30(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220DEE4: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DEE8: D1BF0034  stfs f13, 0x34(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220DEEC: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DEF0: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DEF4: D1BF0038  stfs f13, 0x38(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220DEF8: D01F003C  stfs f0, 0x3c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220DEFC: A17E0044  lhz r11, 0x44(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(68 as u32) ) } as u64;
	// 8220DF00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220DF04: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DF08: C38B1FF8  lfs f28, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8220DF0C: 419A0190  beq cr6, 0x8220e09c
	if ctx.cr[6].eq {
	pc = 0x8220E09C; continue 'dispatch;
	}
	// 8220DF10: 817E0040  lwz r11, 0x40(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(64 as u32) ) } as u64;
	// 8220DF14: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220DF18: 419A0184  beq cr6, 0x8220e09c
	if ctx.cr[6].eq {
	pc = 0x8220E09C; continue 'dispatch;
	}
	// 8220DF1C: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220DF20: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8220DF24: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DF28: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DF2C: 7C8BE214  add r4, r11, r28
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220DF30: 48159E01  bl 0x82367d30
	ctx.lr = 0x8220DF34;
	sub_82367D30(ctx, base);
	// 8220DF34: 83BE0040  lwz r29, 0x40(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(64 as u32) ) } as u64;
	// 8220DF38: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DF3C: C01D0004  lfs f0, 4(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DF40: EC000032  fmuls f0, f0, f0
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220DF44: C03D0008  lfs f1, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DF48: C05D0000  lfs f2, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DF4C: EC01007A  fmadds f0, f1, f1, f0
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64);
	// 8220DF50: EDA200BA  fmadds f13, f2, f2, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[2].f64 + ctx.f[0].f64) as f32) as f64);
	// 8220DF54: C00B252C  lfs f0, 0x252c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9516 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DF58: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220DF5C: 40990118  ble cr6, 0x8220e074
	if !ctx.cr[6].gt {
	pc = 0x8220E074; continue 'dispatch;
	}
	// 8220DF60: 48324F49  bl 0x82532ea8
	ctx.lr = 0x8220DF64;
	sub_82532EA8(ctx, base);
	// 8220DF64: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220DF68: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220DF6C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220DF70: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DF74: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DF78: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220DF7C: C3EA2254  lfs f31, 0x2254(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8788 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220DF80: C04B0000  lfs f2, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220DF84: EFC007F2  fmuls f30, f0, f31
	ctx.f[30].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 8220DF88: C02B0008  lfs f1, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DF8C: 48324F1D  bl 0x82532ea8
	ctx.lr = 0x8220DF90;
	sub_82532EA8(ctx, base);
	// 8220DF90: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220DF94: EC20F7FC  fnmsubs f1, f0, f31, f30
	ctx.f[1].f64 = -(((ctx.f[0].f64 * ctx.f[31].f64 - ctx.f[30].f64) as f32) as f64);
	// 8220DF98: 4BFFE8F1  bl 0x8220c888
	ctx.lr = 0x8220DF9C;
	sub_8220C888(ctx, base);
	// 8220DF9C: FFA00890  fmr f29, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[29].f64 = ctx.f[1].f64;
	// 8220DFA0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DFA4: C00B2370  lfs f0, 0x2370(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9072 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DFA8: FF1D0000  fcmpu cr6, f29, f0
	ctx.cr[6].compare_f64(ctx.f[29].f64, ctx.f[0].f64);
	// 8220DFAC: 41980014  blt cr6, 0x8220dfc0
	if ctx.cr[6].lt {
	pc = 0x8220DFC0; continue 'dispatch;
	}
	// 8220DFB0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220DFB4: C00B223C  lfs f0, 0x223c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8764 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DFB8: FF1D0000  fcmpu cr6, f29, f0
	ctx.cr[6].compare_f64(ctx.f[29].f64, ctx.f[0].f64);
	// 8220DFBC: 40990008  ble cr6, 0x8220dfc4
	if !ctx.cr[6].gt {
	pc = 0x8220DFC4; continue 'dispatch;
	}
	// 8220DFC0: FFA00090  fmr f29, f0
	ctx.f[29].f64 = ctx.f[0].f64;
	// 8220DFC4: C1BD0000  lfs f13, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220DFC8: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220DFCC: C01D0008  lfs f0, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220DFD0: C03D0004  lfs f1, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220DFD4: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 8220DFD8: EC40002C  fsqrts f2, f0
	ctx.f[2].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8220DFDC: 48324ECD  bl 0x82532ea8
	ctx.lr = 0x8220DFE0;
	sub_82532EA8(ctx, base);
	// 8220DFE0: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220DFE4: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220DFE8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8220DFEC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220DFF0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8220DFF4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220DFF8: 554A3032  slwi r10, r10, 6
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8220DFFC: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220E000: 7D4AE214  add r10, r10, r28
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[28].u64;
	// 8220E004: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E008: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220E00C: C02A0004  lfs f1, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E010: EFC007F2  fmuls f30, f0, f31
	ctx.f[30].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 8220E014: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E018: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 8220E01C: EC40002C  fsqrts f2, f0
	ctx.f[2].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8220E020: 48324E89  bl 0x82532ea8
	ctx.lr = 0x8220E024;
	sub_82532EA8(ctx, base);
	// 8220E024: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8220E028: EC20F7FC  fnmsubs f1, f0, f31, f30
	ctx.f[1].f64 = -(((ctx.f[0].f64 * ctx.f[31].f64 - ctx.f[30].f64) as f32) as f64);
	// 8220E02C: 4BFFE85D  bl 0x8220c888
	ctx.lr = 0x8220E030;
	sub_8220C888(ctx, base);
	// 8220E030: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E034: C00B24FC  lfs f0, 0x24fc(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9468 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E038: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8220E03C: 41980014  blt cr6, 0x8220e050
	if ctx.cr[6].lt {
	pc = 0x8220E050; continue 'dispatch;
	}
	// 8220E040: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E044: C00B209C  lfs f0, 0x209c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8348 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E048: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8220E04C: 40990008  ble cr6, 0x8220e054
	if !ctx.cr[6].gt {
	pc = 0x8220E054; continue 'dispatch;
	}
	// 8220E050: FC200090  fmr f1, f0
	ctx.f[1].f64 = ctx.f[0].f64;
	// 8220E054: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E058: FC60E090  fmr f3, f28
	ctx.f[3].f64 = ctx.f[28].f64;
	// 8220E05C: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 8220E060: 4815A1B9  bl 0x82368218
	ctx.lr = 0x8220E064;
	sub_82368218(ctx, base);
	// 8220E064: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8220E068: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220E06C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E070: 48159D81  bl 0x82367df0
	ctx.lr = 0x8220E074;
	sub_82367DF0(ctx, base);
	// 8220E074: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E078: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E07C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E080: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E084: 7C8BE214  add r4, r11, r28
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220E088: 48159C01  bl 0x82367c88
	ctx.lr = 0x8220E08C;
	sub_82367C88(ctx, base);
	// 8220E08C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8220E090: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E094: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E098: 48159C99  bl 0x82367d30
	ctx.lr = 0x8220E09C;
	sub_82367D30(ctx, base);
	// 8220E09C: A17E0046  lhz r11, 0x46(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(70 as u32) ) } as u64;
	// 8220E0A0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220E0A4: 419A005C  beq cr6, 0x8220e100
	if ctx.cr[6].eq {
	pc = 0x8220E100; continue 'dispatch;
	}
	// 8220E0A8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E0AC: C1BF0000  lfs f13, 0(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E0B0: C19F0004  lfs f12, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E0B4: C17F0008  lfs f11, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E0B8: D39F000C  stfs f28, 0xc(r31)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8220E0BC: D39F002C  stfs f28, 0x2c(r31)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 8220E0C0: C00B2074  lfs f0, 0x2074(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8308 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E0C4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0C8: D1BF0000  stfs f13, 0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220E0CC: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0D0: D19F0004  stfs f12, 4(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220E0D4: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0D8: C1BF0020  lfs f13, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E0DC: C19F0024  lfs f12, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E0E0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0E4: D17F0008  stfs f11, 8(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220E0E8: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0EC: C17F0028  lfs f11, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E0F0: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E0F4: D1BF0020  stfs f13, 0x20(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220E0F8: D19F0024  stfs f12, 0x24(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220E0FC: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220E100: C19E0048  lfs f12, 0x48(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E104: C17F0000  lfs f11, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E108: C01E0050  lfs f0, 0x50(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E10C: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220E110: C1BE004C  lfs f13, 0x4c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E114: C15F0004  lfs f10, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220E118: C13F0008  lfs f9, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220E11C: D17F0000  stfs f11, 0(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220E120: ED6A0332  fmuls f11, f10, f12
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220E124: C11F0010  lfs f8, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220E128: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8220E12C: C0FF0014  lfs f7, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220E130: ED080372  fmuls f8, f8, f13
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220E134: C0DF0018  lfs f6, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220E138: D19F0008  stfs f12, 8(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220E13C: ED870372  fmuls f12, f7, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220E140: C0BF0020  lfs f5, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220E144: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220E148: C09F0024  lfs f4, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220E14C: ECA00172  fmuls f5, f0, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[5].f64) as f32) as f64);
	// 8220E150: C07F0028  lfs f3, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E154: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E158: EDA40032  fmuls f13, f4, f0
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E15C: EC030032  fmuls f0, f3, f0
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E160: D0BF0020  stfs f5, 0x20(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220E164: D11F0010  stfs f8, 0x10(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E168: D17F0004  stfs f11, 4(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220E16C: D19F0014  stfs f12, 0x14(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E170: D1BF0024  stfs f13, 0x24(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220E174: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220E178: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 8220E17C: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 8220E180: 48327EB5  bl 0x82536034
	ctx.lr = 0x8220E184;
	sub_82535FFC(ctx, base);
	// 8220E184: 48326F84  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E188(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E188 size=224
    let mut pc: u32 = 0x8220E188;
    'dispatch: loop {
        match pc {
            0x8220E188 => {
    //   block [0x8220E188..0x8220E268)
	// 8220E188: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E18C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E190: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220E194: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220E198: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E19C: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220E1A0: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220E1A4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220E1A8: 396B4528  addi r11, r11, 0x4528
	ctx.r[11].s64 = ctx.r[11].s64 + 17704;
	// 8220E1AC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220E1B0: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E1B4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220E1B8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E1BC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220E1C0: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220E1C4: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220E1C8: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220E1CC: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220E1D0: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220E1D4: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220E1D8: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E1DC: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E1E0: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E1E4: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E1E8: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E1EC: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E1F0: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220E1F4: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E1F8: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E1FC: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E200: 4815A019  bl 0x82368218
	ctx.lr = 0x8220E204;
	sub_82368218(ctx, base);
	// 8220E204: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220E208: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E20C: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E210: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E214: 4815A005  bl 0x82368218
	ctx.lr = 0x8220E218;
	sub_82368218(ctx, base);
	// 8220E218: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220E21C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E220: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E224: 48159BCD  bl 0x82367df0
	ctx.lr = 0x8220E228;
	sub_82367DF0(ctx, base);
	// 8220E228: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E22C: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220E230: 48166171  bl 0x823743a0
	ctx.lr = 0x8220E234;
	sub_823743A0(ctx, base);
	// 8220E234: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E238: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E23C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E240: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E244: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220E248: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E24C: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220E250: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220E254: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E258: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E25C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220E260: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220E264: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E268(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E268 size=216
    let mut pc: u32 = 0x8220E268;
    'dispatch: loop {
        match pc {
            0x8220E268 => {
    //   block [0x8220E268..0x8220E340)
	// 8220E268: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E26C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E270: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E274: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8220E278: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8220E27C: 388A0030  addi r4, r10, 0x30
	ctx.r[4].s64 = ctx.r[10].s64 + 48;
	// 8220E280: A12A0020  lhz r9, 0x20(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220E284: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8220E288: 55293032  slwi r9, r9, 6
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(6);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8220E28C: 7C695A14  add r3, r9, r11
	ctx.r[3].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 8220E290: 4815A2A9  bl 0x82368538
	ctx.lr = 0x8220E294;
	sub_82368538(ctx, base);
	// 8220E294: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220E298: C1AA0010  lfs f13, 0x10(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E29C: D1A30030  stfs f13, 0x30(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E2A0: C1AA0014  lfs f13, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E2A4: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E2A8: C1AA0018  lfs f13, 0x18(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E2AC: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E2B0: D1A30038  stfs f13, 0x38(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E2B4: D003003C  stfs f0, 0x3c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220E2B8: C18A0040  lfs f12, 0x40(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E2BC: C1630000  lfs f11, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E2C0: C00A0048  lfs f0, 0x48(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(72 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E2C4: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220E2C8: C1AA0044  lfs f13, 0x44(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E2CC: C1430004  lfs f10, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220E2D0: C1230008  lfs f9, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220E2D4: D1630000  stfs f11, 0(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220E2D8: ED6C02B2  fmuls f11, f12, f10
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 8220E2DC: C1030010  lfs f8, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220E2E0: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8220E2E4: C0E30014  lfs f7, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220E2E8: ED0D0232  fmuls f8, f13, f8
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8220E2EC: C0C30018  lfs f6, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220E2F0: D1830008  stfs f12, 8(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220E2F4: ED8D01F2  fmuls f12, f13, f7
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[7].f64) as f32) as f64);
	// 8220E2F8: C0A30020  lfs f5, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220E2FC: EDAD01B2  fmuls f13, f13, f6
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[6].f64) as f32) as f64);
	// 8220E300: C0830024  lfs f4, 0x24(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220E304: ECA00172  fmuls f5, f0, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[5].f64) as f32) as f64);
	// 8220E308: C0630028  lfs f3, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E30C: D1A30018  stfs f13, 0x18(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E310: EDA00132  fmuls f13, f0, f4
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[4].f64) as f32) as f64);
	// 8220E314: EC0000F2  fmuls f0, f0, f3
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[3].f64) as f32) as f64);
	// 8220E318: D0A30020  stfs f5, 0x20(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220E31C: D1030010  stfs f8, 0x10(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E320: D1630004  stfs f11, 4(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220E324: D1830014  stfs f12, 0x14(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E328: D1A30024  stfs f13, 0x24(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220E32C: D0030028  stfs f0, 0x28(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220E330: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220E334: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E338: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E33C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E340(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E340 size=216
    let mut pc: u32 = 0x8220E340;
    'dispatch: loop {
        match pc {
            0x8220E340 => {
    //   block [0x8220E340..0x8220E418)
	// 8220E340: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E344: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E348: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220E34C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220E350: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E354: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220E358: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220E35C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220E360: 396B4548  addi r11, r11, 0x4548
	ctx.r[11].s64 = ctx.r[11].s64 + 17736;
	// 8220E364: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220E368: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E36C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220E370: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E374: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220E378: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220E37C: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220E380: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220E384: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220E388: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220E38C: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220E390: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E394: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E398: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E39C: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E3A0: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E3A4: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E3A8: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220E3AC: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E3B0: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E3B4: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E3B8: 48159E61  bl 0x82368218
	ctx.lr = 0x8220E3BC;
	sub_82368218(ctx, base);
	// 8220E3BC: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220E3C0: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E3C4: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E3C8: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E3CC: 48159E4D  bl 0x82368218
	ctx.lr = 0x8220E3D0;
	sub_82368218(ctx, base);
	// 8220E3D0: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220E3D4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E3D8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E3DC: 48159A15  bl 0x82367df0
	ctx.lr = 0x8220E3E0;
	sub_82367DF0(ctx, base);
	// 8220E3E0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E3E4: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220E3E8: 48165FB9  bl 0x823743a0
	ctx.lr = 0x8220E3EC;
	sub_823743A0(ctx, base);
	// 8220E3EC: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E3F0: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E3F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E3F8: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E3FC: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220E400: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220E404: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E408: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E40C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220E410: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220E414: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E418(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E418 size=304
    let mut pc: u32 = 0x8220E418;
    'dispatch: loop {
        match pc {
            0x8220E418 => {
    //   block [0x8220E418..0x8220E548)
	// 8220E418: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E41C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E420: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E424: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 8220E428: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 8220E42C: 38890030  addi r4, r9, 0x30
	ctx.r[4].s64 = ctx.r[9].s64 + 48;
	// 8220E430: A1690020  lhz r11, 0x20(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220E434: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E438: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E43C: 7CAB4214  add r5, r11, r8
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8220E440: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8220E444: 4815A0F5  bl 0x82368538
	ctx.lr = 0x8220E448;
	sub_82368538(ctx, base);
	// 8220E448: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220E44C: C1A90010  lfs f13, 0x10(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E450: D1A50030  stfs f13, 0x30(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E454: C1A90014  lfs f13, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E458: D1A50034  stfs f13, 0x34(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E45C: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E460: C1A90018  lfs f13, 0x18(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E464: D1A50038  stfs f13, 0x38(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E468: D005003C  stfs f0, 0x3c(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220E46C: A1690022  lhz r11, 0x22(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E470: 7D630734  extsh r3, r11
	ctx.r[3].s64 = ctx.r[11].s16 as i64;
	// 8220E474: 48003AB5  bl 0x82211f28
	ctx.lr = 0x8220E478;
	sub_82211F28(ctx, base);
	// 8220E478: C0030000  lfs f0, 0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E47C: C1A50000  lfs f13, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E480: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E484: C1850010  lfs f12, 0x10(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E488: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220E48C: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E490: C1650020  lfs f11, 0x20(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(32 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E494: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E498: D0050020  stfs f0, 0x20(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220E49C: D1A50010  stfs f13, 0x10(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E4A0: C0030004  lfs f0, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E4A4: C1450004  lfs f10, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220E4A8: EDAA0032  fmuls f13, f10, f0
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E4AC: C1250014  lfs f9, 0x14(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220E4B0: D1A50004  stfs f13, 4(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220E4B4: EDA90032  fmuls f13, f9, f0
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E4B8: C1050024  lfs f8, 0x24(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(36 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220E4BC: EC080032  fmuls f0, f8, f0
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E4C0: D0050024  stfs f0, 0x24(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220E4C4: D1A50014  stfs f13, 0x14(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E4C8: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E4CC: C0E50008  lfs f7, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220E4D0: EDA001F2  fmuls f13, f0, f7
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 8220E4D4: C0C50018  lfs f6, 0x18(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220E4D8: C0A50028  lfs f5, 0x28(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(40 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220E4DC: D1A50008  stfs f13, 8(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220E4E0: EDA001B2  fmuls f13, f0, f6
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[6].f64) as f32) as f64);
	// 8220E4E4: EC000172  fmuls f0, f0, f5
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[5].f64) as f32) as f64);
	// 8220E4E8: D0050028  stfs f0, 0x28(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220E4EC: D1A50018  stfs f13, 0x18(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E4F0: C0030000  lfs f0, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E4F4: C0850030  lfs f4, 0x30(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(48 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220E4F8: EC000132  fmuls f0, f0, f4
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[4].f64) as f32) as f64);
	// 8220E4FC: D0050030  stfs f0, 0x30(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E500: C0030004  lfs f0, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E504: C0650034  lfs f3, 0x34(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(52 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E508: EC0000F2  fmuls f0, f0, f3
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[3].f64) as f32) as f64);
	// 8220E50C: D0050034  stfs f0, 0x34(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E510: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E514: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8220E518: C0450038  lfs f2, 0x38(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(56 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E51C: EC020032  fmuls f0, f2, f0
	ctx.f[0].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E520: D0050038  stfs f0, 0x38(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E524: A1690022  lhz r11, 0x22(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E528: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E52C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E530: 7C8B4214  add r4, r11, r8
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8220E534: 481597FD  bl 0x82367d30
	ctx.lr = 0x8220E538;
	sub_82367D30(ctx, base);
	// 8220E538: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220E53C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E540: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E544: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E548(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E548 size=188
    let mut pc: u32 = 0x8220E548;
    'dispatch: loop {
        match pc {
            0x8220E548 => {
    //   block [0x8220E548..0x8220E604)
	// 8220E548: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E54C: 48326B71  bl 0x825350bc
	ctx.lr = 0x8220E550;
	sub_82535080(ctx, base);
	// 8220E550: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E554: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220E558: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220E55C: 396B4558  addi r11, r11, 0x4558
	ctx.r[11].s64 = ctx.r[11].s64 + 17752;
	// 8220E560: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8220E564: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220E568: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220E56C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E570: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220E574: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8220E578: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8220E57C: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220E580: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E584: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220E588: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220E58C: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220E590: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E594: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E598: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E59C: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E5A0: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E5A4: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E5A8: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220E5AC: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E5B0: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E5B4: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E5B8: 48159C61  bl 0x82368218
	ctx.lr = 0x8220E5BC;
	sub_82368218(ctx, base);
	// 8220E5BC: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220E5C0: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E5C4: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E5C8: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E5CC: 48159C4D  bl 0x82368218
	ctx.lr = 0x8220E5D0;
	sub_82368218(ctx, base);
	// 8220E5D0: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220E5D4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E5D8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E5DC: 48159815  bl 0x82367df0
	ctx.lr = 0x8220E5E0;
	sub_82367DF0(ctx, base);
	// 8220E5E0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E5E4: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220E5E8: 48165DB9  bl 0x823743a0
	ctx.lr = 0x8220E5EC;
	sub_823743A0(ctx, base);
	// 8220E5EC: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E5F0: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E5F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E5F8: 93BF0044  stw r29, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[29].u32 ) };
	// 8220E5FC: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220E600: 48326B0C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E608 size=448
    let mut pc: u32 = 0x8220E608;
    'dispatch: loop {
        match pc {
            0x8220E608 => {
    //   block [0x8220E608..0x8220E7C8)
	// 8220E608: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E60C: 48326AAD  bl 0x825350b8
	ctx.lr = 0x8220E610;
	sub_82535080(ctx, base);
	// 8220E610: DBC1FFC8  stfd f30, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[30].u64 ) };
	// 8220E614: DBE1FFD0  stfd f31, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 8220E618: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E61C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220E620: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8220E624: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220E628: 817E0044  lwz r11, 0x44(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(68 as u32) ) } as u64;
	// 8220E62C: C3DE0040  lfs f30, 0x40(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(64 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8220E630: A15E0020  lhz r10, 0x20(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220E634: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 8220E638: 3BAB0001  addi r29, r11, 1
	ctx.r[29].s64 = ctx.r[11].s64 + 1;
	// 8220E63C: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 8220E640: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E644: 7FEBE214  add r31, r11, r28
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220E648: 93BE0044  stw r29, 0x44(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(68 as u32), ctx.r[29].u32 ) };
	// 8220E64C: 4815996D  bl 0x82367fb8
	ctx.lr = 0x8220E650;
	sub_82367FB8(ctx, base);
	// 8220E650: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220E654: 2F1D0010  cmpwi cr6, r29, 0x10
	ctx.cr[6].compare_i32(ctx.r[29].s32, 16, &mut ctx.xer);
	// 8220E658: C3EBBA38  lfs f31, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220E65C: 41990048  bgt cr6, 0x8220e6a4
	if ctx.cr[6].gt {
	pc = 0x8220E6A4; continue 'dispatch;
	}
	// 8220E660: 57AB073E  clrlwi r11, r29, 0x1c
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x0000000Fu64;
	// 8220E664: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8220E668: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E66C: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8220E670: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8220E674: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8220E678: C00B2748  lfs f0, 0x2748(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10056 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E67C: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E680: 4BF44C39  bl 0x821532b8
	ctx.lr = 0x8220E684;
	sub_821532B8(ctx, base);
	// 8220E684: EC01F82A  fadds f0, f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = ((ctx.f[1].f64 + ctx.f[31].f64) as f32) as f64;
	// 8220E688: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E68C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220E690: EDA007B2  fmuls f13, f0, f30
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[30].f64) as f32) as f64);
	// 8220E694: C00BBFFC  lfs f0, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E698: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E69C: 4815991D  bl 0x82367fb8
	ctx.lr = 0x8220E6A0;
	sub_82367FB8(ctx, base);
	// 8220E6A0: 48000014  b 0x8220e6b4
	pc = 0x8220E6B4; continue 'dispatch;
	// 8220E6A4: 2F1D012C  cmpwi cr6, r29, 0x12c
	ctx.cr[6].compare_i32(ctx.r[29].s32, 300, &mut ctx.xer);
	// 8220E6A8: 4198000C  blt cr6, 0x8220e6b4
	if ctx.cr[6].lt {
	pc = 0x8220E6B4; continue 'dispatch;
	}
	// 8220E6AC: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 8220E6B0: 917E0044  stw r11, 0x44(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 8220E6B4: 389E0030  addi r4, r30, 0x30
	ctx.r[4].s64 = ctx.r[30].s64 + 48;
	// 8220E6B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E6BC: 48159E7D  bl 0x82368538
	ctx.lr = 0x8220E6C0;
	sub_82368538(ctx, base);
	// 8220E6C0: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220E6C4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8220E6C8: 48159729  bl 0x82367df0
	ctx.lr = 0x8220E6CC;
	sub_82367DF0(ctx, base);
	// 8220E6CC: C01E0010  lfs f0, 0x10(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E6D0: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E6D4: C01E0014  lfs f0, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E6D8: D01F0034  stfs f0, 0x34(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E6DC: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E6E0: D01F0038  stfs f0, 0x38(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E6E4: D3FF003C  stfs f31, 0x3c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220E6E8: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E6EC: 7D630734  extsh r3, r11
	ctx.r[3].s64 = ctx.r[11].s16 as i64;
	// 8220E6F0: 48003839  bl 0x82211f28
	ctx.lr = 0x8220E6F4;
	sub_82211F28(ctx, base);
	// 8220E6F4: FC400090  fmr f2, f0
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[0].f64;
	// 8220E6F8: C0030000  lfs f0, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E6FC: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8220E700: C1BF0000  lfs f13, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E704: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E708: C19F0010  lfs f12, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220E70C: D1BF0000  stfs f13, 0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220E710: EDA00332  fmuls f13, f0, f12
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220E714: C17F0020  lfs f11, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220E718: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8220E71C: D01F0020  stfs f0, 0x20(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220E720: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E724: C0030004  lfs f0, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E728: C15F0004  lfs f10, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220E72C: EDAA0032  fmuls f13, f10, f0
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E730: C13F0014  lfs f9, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220E734: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220E738: EDA90032  fmuls f13, f9, f0
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E73C: C11F0024  lfs f8, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220E740: EC080032  fmuls f0, f8, f0
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E744: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220E748: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E74C: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E750: C0FF0008  lfs f7, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220E754: EDA70032  fmuls f13, f7, f0
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E758: C0DF0018  lfs f6, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220E75C: C0BF0028  lfs f5, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220E760: D1BF0008  stfs f13, 8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220E764: EDA60032  fmuls f13, f6, f0
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E768: EC050032  fmuls f0, f5, f0
	ctx.f[0].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E76C: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220E770: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E774: C0030000  lfs f0, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E778: C09F0030  lfs f4, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220E77C: EC000132  fmuls f0, f0, f4
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[4].f64) as f32) as f64);
	// 8220E780: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E784: C0030004  lfs f0, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E788: C07F0034  lfs f3, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E78C: EC030032  fmuls f0, f3, f0
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E790: D01F0034  stfs f0, 0x34(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E794: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E798: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E79C: EC0000B2  fmuls f0, f0, f2
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[2].f64) as f32) as f64);
	// 8220E7A0: D01F0038  stfs f0, 0x38(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E7A4: A17E0022  lhz r11, 0x22(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E7A8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E7AC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E7B0: 7C8BE214  add r4, r11, r28
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8220E7B4: 4815957D  bl 0x82367d30
	ctx.lr = 0x8220E7B8;
	sub_82367D30(ctx, base);
	// 8220E7B8: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 8220E7BC: CBC1FFC8  lfd f30, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 8220E7C0: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8220E7C4: 48326944  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E7C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E7C8 size=272
    let mut pc: u32 = 0x8220E7C8;
    'dispatch: loop {
        match pc {
            0x8220E7C8 => {
    //   block [0x8220E7C8..0x8220E8D8)
	// 8220E7C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E7CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E7D0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8220E7D4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8220E7D8: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E7DC: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220E7E0: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220E7E4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220E7E8: 396B4568  addi r11, r11, 0x4568
	ctx.r[11].s64 = ctx.r[11].s64 + 17768;
	// 8220E7EC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220E7F0: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E7F4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8220E7F8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E7FC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220E800: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8220E804: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8220E808: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220E80C: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220E810: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220E814: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220E818: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E81C: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E820: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E824: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E828: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E82C: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E830: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220E834: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E838: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E83C: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E840: 481599D9  bl 0x82368218
	ctx.lr = 0x8220E844;
	sub_82368218(ctx, base);
	// 8220E844: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220E848: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E84C: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E850: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E854: 481599C5  bl 0x82368218
	ctx.lr = 0x8220E858;
	sub_82368218(ctx, base);
	// 8220E858: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220E85C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E860: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E864: 4815958D  bl 0x82367df0
	ctx.lr = 0x8220E868;
	sub_82367DF0(ctx, base);
	// 8220E868: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E86C: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220E870: 48165B31  bl 0x823743a0
	ctx.lr = 0x8220E874;
	sub_823743A0(ctx, base);
	// 8220E874: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E878: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E87C: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E880: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E884: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220E888: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220E88C: 40990008  ble cr6, 0x8220e894
	if !ctx.cr[6].gt {
	pc = 0x8220E894; continue 'dispatch;
	}
	// 8220E890: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E894: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E898: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E89C: C00B207C  lfs f0, 0x207c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8316 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E8A0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E8A4: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220E8A8: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220E8AC: C1AB2490  lfs f13, 0x2490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9360 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E8B0: EC200372  fmuls f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220E8B4: 4BF44A05  bl 0x821532b8
	ctx.lr = 0x8220E8B8;
	sub_821532B8(ctx, base);
	// 8220E8B8: D03F0044  stfs f1, 0x44(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220E8BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E8C0: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220E8C4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E8C8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E8CC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8220E8D0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8220E8D4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E8D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E8D8 size=120
    let mut pc: u32 = 0x8220E8D8;
    'dispatch: loop {
        match pc {
            0x8220E8D8 => {
    //   block [0x8220E8D8..0x8220E950)
	// 8220E8D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E8DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8220E8E0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E8E4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8220E8E8: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 8220E8EC: 388A0030  addi r4, r10, 0x30
	ctx.r[4].s64 = ctx.r[10].s64 + 48;
	// 8220E8F0: A16A0020  lhz r11, 0x20(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220E8F4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E8F8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E8FC: 7C6B4A14  add r3, r11, r9
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8220E900: 48159C39  bl 0x82368538
	ctx.lr = 0x8220E904;
	sub_82368538(ctx, base);
	// 8220E904: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220E908: C1AA0010  lfs f13, 0x10(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E90C: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8220E910: D1A30030  stfs f13, 0x30(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220E914: C1AA0014  lfs f13, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E918: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220E91C: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E920: C1AA0018  lfs f13, 0x18(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E924: D1A30038  stfs f13, 0x38(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220E928: D003003C  stfs f0, 0x3c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220E92C: A16A0022  lhz r11, 0x22(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220E930: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220E934: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220E938: 7C8B4A14  add r4, r11, r9
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8220E93C: 481593F5  bl 0x82367d30
	ctx.lr = 0x8220E940;
	sub_82367D30(ctx, base);
	// 8220E940: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8220E944: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8220E948: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8220E94C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220E950(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220E950 size=196
    let mut pc: u32 = 0x8220E950;
    'dispatch: loop {
        match pc {
            0x8220E950 => {
    //   block [0x8220E950..0x8220EA14)
	// 8220E950: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220E954: 48326769  bl 0x825350bc
	ctx.lr = 0x8220E958;
	sub_82535080(ctx, base);
	// 8220E958: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220E95C: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220E960: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220E964: 396B4578  addi r11, r11, 0x4578
	ctx.r[11].s64 = ctx.r[11].s64 + 17784;
	// 8220E968: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8220E96C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220E970: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220E974: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E978: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220E97C: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8220E980: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8220E984: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220E988: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220E98C: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220E990: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220E994: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220E998: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E99C: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220E9A0: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E9A4: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220E9A8: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220E9AC: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220E9B0: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220E9B4: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E9B8: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E9BC: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E9C0: 48159859  bl 0x82368218
	ctx.lr = 0x8220E9C4;
	sub_82368218(ctx, base);
	// 8220E9C4: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220E9C8: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220E9CC: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220E9D0: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220E9D4: 48159845  bl 0x82368218
	ctx.lr = 0x8220E9D8;
	sub_82368218(ctx, base);
	// 8220E9D8: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220E9DC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E9E0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220E9E4: 4815940D  bl 0x82367df0
	ctx.lr = 0x8220E9E8;
	sub_82367DF0(ctx, base);
	// 8220E9E8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220E9EC: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220E9F0: 481659B1  bl 0x823743a0
	ctx.lr = 0x8220E9F4;
	sub_823743A0(ctx, base);
	// 8220E9F4: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220E9F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220E9FC: 93BF0048  stw r29, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[29].u32 ) };
	// 8220EA00: C00B1FF8  lfs f0, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EA04: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EA08: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EA0C: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220EA10: 483266FC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220EA18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220EA18 size=716
    let mut pc: u32 = 0x8220EA18;
    'dispatch: loop {
        match pc {
            0x8220EA18 => {
    //   block [0x8220EA18..0x8220EA88)
	// 8220EA18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220EA1C: 483266A1  bl 0x825350bc
	ctx.lr = 0x8220EA20;
	sub_82535080(ctx, base);
	// 8220EA20: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8220EA24: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220EA28: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220EA2C: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220EA30: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8220EA34: A15F0020  lhz r10, 0x20(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220EA38: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 8220EA3C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8220EA40: C3E9BA38  lfs f31, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220EA44: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 8220EA48: 554A3032  slwi r10, r10, 6
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8220EA4C: 7FCAEA14  add r30, r10, r29
	ctx.r[30].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 8220EA50: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220EA54: C16A1FF8  lfs f11, 0x1ff8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220EA58: 41990068  bgt cr6, 0x8220eac0
	if ctx.cr[6].gt {
	pc = 0x8220EAC0; continue 'dispatch;
	}
	// 8220EA5C: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 8220EA60: 398CEA74  addi r12, r12, -0x158c
	ctx.r[12].s64 = ctx.r[12].s64 + -5516;
	// 8220EA64: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8220EA68: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8220EA6C: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8220EA70: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8220EB0C; continue 'dispatch;
		},
		1 => {
	pc = 0x8220EB94; continue 'dispatch;
		},
		2 => {
	pc = 0x8220EB60; continue 'dispatch;
		},
		3 => {
	pc = 0x8220EAC0; continue 'dispatch;
		},
		4 => {
	pc = 0x8220EA88; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8220EA74: 8220EB0C  lwz r17, -0x14f4(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -5364u32 ) } as u64;
	// 8220EA78: 8220EB94  lwz r17, -0x146c(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -5228u32 ) } as u64;
	// 8220EA7C: 8220EB60  lwz r17, -0x14a0(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -5280u32 ) } as u64;
	// 8220EA80: 8220EAC0  lwz r17, -0x1540(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -5440u32 ) } as u64;
	// 8220EA84: 8220EA88  lwz r17, -0x1578(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -5496u32 ) } as u64;
            }
            0x8220EA88 => {
    //   block [0x8220EA88..0x8220EAC0)
	// 8220EA88: C1BF0044  lfs f13, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EA8C: FF0D5800  fcmpu cr6, f13, f11
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[11].f64);
	// 8220EA90: 40990040  ble cr6, 0x8220ead0
	if !ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EA94: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EA98: C00B22EC  lfs f0, 0x22ec(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8940 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EA9C: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220EAA0: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EAA4: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EAA8: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220EAAC: FF0DF800  fcmpu cr6, f13, f31
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[31].f64);
	// 8220EAB0: 41980020  blt cr6, 0x8220ead0
	if ctx.cr[6].lt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EAB4: EC00F82A  fadds f0, f0, f31
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[31].f64) as f32) as f64;
	// 8220EAB8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220EABC: 41990014  bgt cr6, 0x8220ead0
	if ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	pc = 0x8220EAC0; continue 'dispatch;
            }
            0x8220EAC0 => {
    //   block [0x8220EAC0..0x8220EB0C)
	// 8220EAC0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220EAC4: D17F0044  stfs f11, 0x44(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EAC8: D17F0040  stfs f11, 0x40(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EACC: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 8220EAD0: C01F0040  lfs f0, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EAD4: C1BF0044  lfs f13, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EAD8: EC20682A  fadds f1, f0, f13
	ctx.f[1].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220EADC: D03F0040  stfs f1, 0x40(r31)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EAE0: FF015800  fcmpu cr6, f1, f11
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[11].f64);
	// 8220EAE4: 4098010C  bge cr6, 0x8220ebf0
	if !ctx.cr[6].lt {
	pc = 0x8220EBF0; continue 'dispatch;
	}
	// 8220EAE8: FC000850  fneg f0, f1
	ctx.f[0].u64 = ctx.f[1].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220EAEC: FF00F800  fcmpu cr6, f0, f31
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[31].f64);
	// 8220EAF0: 41980014  blt cr6, 0x8220eb04
	if ctx.cr[6].lt {
	pc = 0x8220EB04; continue 'dispatch;
	}
	// 8220EAF4: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 8220EAF8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8220EAFC: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8220EB00: EC006828  fsubs f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8220EB04: EC3F0028  fsubs f1, f31, f0
	ctx.f[1].f64 = (((ctx.f[31].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EB08: 48000100  b 0x8220ec08
	pc = 0x8220EC08; continue 'dispatch;
            }
            0x8220EB0C => {
    //   block [0x8220EB0C..0x8220EB60)
	// 8220EB0C: C01F0044  lfs f0, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EB10: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 8220EB14: 4099FFBC  ble cr6, 0x8220ead0
	if !ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EB18: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB1C: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EB20: C18B2744  lfs f12, 0x2744(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10052 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EB24: ED806B3A  fmadds f12, f0, f12, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8220EB28: FF0CF800  fcmpu cr6, f12, f31
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[31].f64);
	// 8220EB2C: 4098FFA4  bge cr6, 0x8220ead0
	if !ctx.cr[6].lt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EB30: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB34: C18B2740  lfs f12, 0x2740(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10048 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EB38: EDA06B3A  fmadds f13, f0, f12, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8220EB3C: FF0DF800  fcmpu cr6, f13, f31
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[31].f64);
	// 8220EB40: 4198FF90  blt cr6, 0x8220ead0
	if ctx.cr[6].lt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EB44: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB48: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 8220EB4C: C1AB22EC  lfs f13, 0x22ec(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8940 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EB50: EC000372  fmuls f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220EB54: 915F0048  stw r10, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[10].u32 ) };
	// 8220EB58: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EB5C: 4BFFFF74  b 0x8220ead0
	pc = 0x8220EAD0; continue 'dispatch;
            }
            0x8220EB60 => {
    //   block [0x8220EB60..0x8220EB94)
	// 8220EB60: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB64: C19F0044  lfs f12, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EB68: C1AB273C  lfs f13, 0x273c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10044 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EB6C: FF0C6800  fcmpu cr6, f12, f13
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[13].f64);
	// 8220EB70: 4098FF60  bge cr6, 0x8220ead0
	if !ctx.cr[6].lt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EB74: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB78: C00B2738  lfs f0, 0x2738(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10040 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EB7C: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220EB80: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EB84: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8220EB88: 4099FF48  ble cr6, 0x8220ead0
	if !ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EB8C: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EB90: 4BFFFF40  b 0x8220ead0
	pc = 0x8220EAD0; continue 'dispatch;
            }
            0x8220EB94 => {
    //   block [0x8220EB94..0x8220ECE4)
	// 8220EB94: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EB98: C1BF0044  lfs f13, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EB9C: C00B2734  lfs f0, 0x2734(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10036 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EBA0: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220EBA4: 40980024  bge cr6, 0x8220ebc8
	if !ctx.cr[6].lt {
	pc = 0x8220EBC8; continue 'dispatch;
	}
	// 8220EBA8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EBAC: C18B2730  lfs f12, 0x2730(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10032 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EBB0: EDAD602A  fadds f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8220EBB4: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EBB8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220EBBC: 4099FF14  ble cr6, 0x8220ead0
	if !ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EBC0: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EBC4: 4BFFFF0C  b 0x8220ead0
	pc = 0x8220EAD0; continue 'dispatch;
	// 8220EBC8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220EBCC: 4099FF04  ble cr6, 0x8220ead0
	if !ctx.cr[6].gt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EBD0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EBD4: C18B2730  lfs f12, 0x2730(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10032 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EBD8: EDAD6028  fsubs f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 8220EBDC: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EBE0: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220EBE4: 4098FEEC  bge cr6, 0x8220ead0
	if !ctx.cr[6].lt {
	pc = 0x8220EAD0; continue 'dispatch;
	}
	// 8220EBE8: D01F0044  stfs f0, 0x44(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EBEC: 4BFFFEE4  b 0x8220ead0
	pc = 0x8220EAD0; continue 'dispatch;
	// 8220EBF0: FF01F800  fcmpu cr6, f1, f31
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[31].f64);
	// 8220EBF4: 41980014  blt cr6, 0x8220ec08
	if ctx.cr[6].lt {
	pc = 0x8220EC08; continue 'dispatch;
	}
	// 8220EBF8: FC000E5E  fctidz f0, f1
	ctx.f[0].s64 = if ctx.f[1].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[1].f64.trunc() as i64 };
	// 8220EBFC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8220EC00: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8220EC04: EC210028  fsubs f1, f1, f0
	ctx.f[1].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EC08: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8220EC0C: D03F0040  stfs f1, 0x40(r31)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EC10: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220EC14: D3E10060  stfs f31, 0x60(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220EC18: D1610064  stfs f11, 0x64(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220EC1C: D1610068  stfs f11, 0x68(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220EC20: D3E1006C  stfs f31, 0x6c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220EC24: 48165675  bl 0x82374298
	ctx.lr = 0x8220EC28;
	sub_82374298(ctx, base);
	// 8220EC28: C0E10054  lfs f7, 0x54(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220EC2C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220EC30: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EC34: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220EC38: EC8C01F2  fmuls f4, f12, f7
	ctx.f[4].f64 = (((ctx.f[12].f64 * ctx.f[7].f64) as f32) as f64);
	// 8220EC3C: C1BF003C  lfs f13, 0x3c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EC40: C141005C  lfs f10, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220EC44: ECAD01F2  fmuls f5, f13, f7
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[7].f64) as f32) as f64);
	// 8220EC48: C17F0038  lfs f11, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220EC4C: C1210050  lfs f9, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220EC50: C1010058  lfs f8, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220EC54: EC6C0272  fmuls f3, f12, f9
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8220EC58: C01F0034  lfs f0, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EC5C: ECC00232  fmuls f6, f0, f8
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[8].f64) as f32) as f64);
	// 8220EC60: EC8B22BA  fmadds f4, f11, f10, f4
	ctx.f[4].f64 = (((ctx.f[11].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 8220EC64: ECAB2A7A  fmadds f5, f11, f9, f5
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[9].f64 + ctx.f[5].f64) as f32) as f64);
	// 8220EC68: EC6D1AB8  fmsubs f3, f13, f10, f3
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[10].f64 - ctx.f[3].f64) as f32) as f64);
	// 8220EC6C: ECCC32BA  fmadds f6, f12, f10, f6
	ctx.f[6].f64 = (((ctx.f[12].f64 * ctx.f[10].f64 + ctx.f[6].f64) as f32) as f64);
	// 8220EC70: EC8D223A  fmadds f4, f13, f8, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8220EC74: ECA02ABA  fmadds f5, f0, f10, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[5].f64) as f32) as f64);
	// 8220EC78: ECCD327A  fmadds f6, f13, f9, f6
	ctx.f[6].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[6].f64) as f32) as f64);
	// 8220EC7C: ED40227C  fnmsubs f10, f0, f9, f4
	ctx.f[10].f64 = -(((ctx.f[0].f64 * ctx.f[9].f64 - ctx.f[4].f64) as f32) as f64);
	// 8220EC80: D1410058  stfs f10, 0x58(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220EC84: EC0019FC  fnmsubs f0, f0, f7, f3
	ctx.f[0].f64 = -(((ctx.f[0].f64 * ctx.f[7].f64 - ctx.f[3].f64) as f32) as f64);
	// 8220EC88: ED8C2A3C  fnmsubs f12, f12, f8, f5
	ctx.f[12].f64 = -(((ctx.f[12].f64 * ctx.f[8].f64 - ctx.f[5].f64) as f32) as f64);
	// 8220EC8C: D1810054  stfs f12, 0x54(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220EC90: EDAB31FC  fnmsubs f13, f11, f7, f6
	ctx.f[13].f64 = -(((ctx.f[11].f64 * ctx.f[7].f64 - ctx.f[6].f64) as f32) as f64);
	// 8220EC94: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220EC98: EC0B023C  fnmsubs f0, f11, f8, f0
	ctx.f[0].f64 = -(((ctx.f[11].f64 * ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EC9C: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220ECA0: 48159899  bl 0x82368538
	ctx.lr = 0x8220ECA4;
	sub_82368538(ctx, base);
	// 8220ECA4: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ECA8: D01E0030  stfs f0, 0x30(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220ECAC: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8220ECB0: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ECB4: D01E0034  stfs f0, 0x34(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220ECB8: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ECBC: D01E0038  stfs f0, 0x38(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220ECC0: D3FE003C  stfs f31, 0x3c(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220ECC4: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220ECC8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220ECCC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220ECD0: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220ECD4: 4815905D  bl 0x82367d30
	ctx.lr = 0x8220ECD8;
	sub_82367D30(ctx, base);
	// 8220ECD8: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8220ECDC: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8220ECE0: 4832642C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220ECE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220ECE8 size=216
    let mut pc: u32 = 0x8220ECE8;
    'dispatch: loop {
        match pc {
            0x8220ECE8 => {
    //   block [0x8220ECE8..0x8220EDC0)
	// 8220ECE8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220ECEC: 483263D1  bl 0x825350bc
	ctx.lr = 0x8220ECF0;
	sub_82535080(ctx, base);
	// 8220ECF0: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220ECF4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220ECF8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220ECFC: 396B4588  addi r11, r11, 0x4588
	ctx.r[11].s64 = ctx.r[11].s64 + 17800;
	// 8220ED00: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8220ED04: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8220ED08: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220ED0C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220ED10: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220ED14: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8220ED18: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8220ED1C: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220ED20: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ED24: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220ED28: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220ED2C: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220ED30: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220ED34: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220ED38: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220ED3C: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220ED40: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220ED44: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220ED48: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220ED4C: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220ED50: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220ED54: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220ED58: 481594C1  bl 0x82368218
	ctx.lr = 0x8220ED5C;
	sub_82368218(ctx, base);
	// 8220ED5C: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220ED60: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220ED64: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220ED68: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220ED6C: 481594AD  bl 0x82368218
	ctx.lr = 0x8220ED70;
	sub_82368218(ctx, base);
	// 8220ED70: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220ED74: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220ED78: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220ED7C: 48159075  bl 0x82367df0
	ctx.lr = 0x8220ED80;
	sub_82367DF0(ctx, base);
	// 8220ED80: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220ED84: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 8220ED88: 48165619  bl 0x823743a0
	ctx.lr = 0x8220ED8C;
	sub_823743A0(ctx, base);
	// 8220ED8C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220ED90: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8220ED94: C00B1FF8  lfs f0, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220ED98: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 8220ED9C: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EDA0: C1BE0030  lfs f13, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EDA4: B3BF004E  sth r29, 0x4e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(78 as u32), ctx.r[29].u16 ) };
	// 8220EDA8: D1BF0044  stfs f13, 0x44(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220EDAC: B3BF004C  sth r29, 0x4c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[29].u16 ) };
	// 8220EDB0: C00BD468  lfs f0, -0x2b98(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-11160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EDB4: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EDB8: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8220EDBC: 48326350  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220EDC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220EDC0 size=1000
    let mut pc: u32 = 0x8220EDC0;
    'dispatch: loop {
        match pc {
            0x8220EDC0 => {
    //   block [0x8220EDC0..0x8220EE38)
	// 8220EDC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220EDC4: 483262F5  bl 0x825350b8
	ctx.lr = 0x8220EDC8;
	sub_82535080(ctx, base);
	// 8220EDC8: DBC1FFC8  stfd f30, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[30].u64 ) };
	// 8220EDCC: DBE1FFD0  stfd f31, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 8220EDD0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220EDD4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220EDD8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220EDDC: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8220EDE0: A15F0020  lhz r10, 0x20(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220EDE4: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220EDE8: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8220EDEC: C3E9BA38  lfs f31, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220EDF0: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220EDF4: 554A3032  slwi r10, r10, 6
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8220EDF8: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 8220EDFC: 7FCAEA14  add r30, r10, r29
	ctx.r[30].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 8220EE00: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220EE04: C3CA1FF8  lfs f30, 0x1ff8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8220EE08: 41990288  bgt cr6, 0x8220f090
	if ctx.cr[6].gt {
	pc = 0x8220F090; continue 'dispatch;
	}
	// 8220EE0C: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 8220EE10: 398CEE24  addi r12, r12, -0x11dc
	ctx.r[12].s64 = ctx.r[12].s64 + -4572;
	// 8220EE14: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8220EE18: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8220EE1C: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8220EE20: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8220F094; continue 'dispatch;
		},
		1 => {
	pc = 0x8220F020; continue 'dispatch;
		},
		2 => {
	pc = 0x8220EEE8; continue 'dispatch;
		},
		3 => {
	pc = 0x8220EE38; continue 'dispatch;
		},
		4 => {
	pc = 0x8220EF8C; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8220EE24: 8220F094  lwz r17, -0xf6c(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -3948u32 ) } as u64;
	// 8220EE28: 8220F020  lwz r17, -0xfe0(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -4064u32 ) } as u64;
	// 8220EE2C: 8220EEE8  lwz r17, -0x1118(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -4376u32 ) } as u64;
	// 8220EE30: 8220EE38  lwz r17, -0x11c8(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -4552u32 ) } as u64;
	// 8220EE34: 8220EF8C  lwz r17, -0x1074(0)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, -4212u32 ) } as u64;
            }
            0x8220EE38 => {
    //   block [0x8220EE38..0x8220EEE8)
	// 8220EE38: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220EE3C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220EE40: 409A007C  bne cr6, 0x8220eebc
	if !ctx.cr[6].eq {
	pc = 0x8220EEBC; continue 'dispatch;
	}
	// 8220EE44: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EE48: C01F0040  lfs f0, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EE4C: C1ABBFFC  lfs f13, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EE50: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8220EE54: 419A0038  beq cr6, 0x8220ee8c
	if ctx.cr[6].eq {
	pc = 0x8220EE8C; continue 'dispatch;
	}
	// 8220EE58: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EE5C: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8220EE60: C18B272C  lfs f12, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EE64: 40980018  bge cr6, 0x8220ee7c
	if !ctx.cr[6].lt {
	pc = 0x8220EE7C; continue 'dispatch;
	}
	// 8220EE68: ED60602A  fadds f11, f0, f12
	ctx.f[11].f64 = ((ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64;
	// 8220EE6C: FF0B6800  fcmpu cr6, f11, f13
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[13].f64);
	// 8220EE70: 4198000C  blt cr6, 0x8220ee7c
	if ctx.cr[6].lt {
	pc = 0x8220EE7C; continue 'dispatch;
	}
	// 8220EE74: D1BF0040  stfs f13, 0x40(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EE78: 48000014  b 0x8220ee8c
	pc = 0x8220EE8C; continue 'dispatch;
	// 8220EE7C: FC40F890  fmr f2, f31
	ctx.f[2].f64 = ctx.f[31].f64;
	// 8220EE80: EC20602A  fadds f1, f0, f12
	ctx.f[1].f64 = ((ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64;
	// 8220EE84: 4BF14E85  bl 0x82123d08
	ctx.lr = 0x8220EE88;
	sub_82123D08(ctx, base);
	// 8220EE88: D03F0040  stfs f1, 0x40(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EE8C: C1BF0048  lfs f13, 0x48(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EE90: FF0DF800  fcmpu cr6, f13, f31
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[31].f64);
	// 8220EE94: 40980020  bge cr6, 0x8220eeb4
	if !ctx.cr[6].lt {
	pc = 0x8220EEB4; continue 'dispatch;
	}
	// 8220EE98: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EE9C: C00B20CC  lfs f0, 0x20cc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8396 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EEA0: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220EEA4: EDBF0028  fsubs f13, f31, f0
	ctx.f[13].f64 = (((ctx.f[31].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EEA8: FC0DF82E  fsel f0, f13, f0, f31
	ctx.f[0].f64 = if ctx.f[13].f64 >= 0.0 { ctx.f[0].f64 } else { ctx.f[31].f64 };
	// 8220EEAC: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EEB0: 480001E4  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220EEB4: D3FF0048  stfs f31, 0x48(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EEB8: 480001DC  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220EEBC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EEC0: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EEC4: D3FF0048  stfs f31, 0x48(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EEC8: C00B272C  lfs f0, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EECC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EED0: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220EED4: C1AB2038  lfs f13, 0x2038(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8248 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EED8: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EEDC: FC0C682E  fsel f0, f12, f0, f13
	ctx.f[0].f64 = if ctx.f[12].f64 >= 0.0 { ctx.f[0].f64 } else { ctx.f[13].f64 };
	// 8220EEE0: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EEE4: 480001B0  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
            }
            0x8220EEE8 => {
    //   block [0x8220EEE8..0x8220EF8C)
	// 8220EEE8: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220EEEC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220EEF0: 409A006C  bne cr6, 0x8220ef5c
	if !ctx.cr[6].eq {
	pc = 0x8220EF5C; continue 'dispatch;
	}
	// 8220EEF4: C01F0040  lfs f0, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EEF8: FF00F000  fcmpu cr6, f0, f30
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[30].f64);
	// 8220EEFC: 419A0038  beq cr6, 0x8220ef34
	if ctx.cr[6].eq {
	pc = 0x8220EF34; continue 'dispatch;
	}
	// 8220EF00: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EF04: FF00F000  fcmpu cr6, f0, f30
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[30].f64);
	// 8220EF08: C1AB272C  lfs f13, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EF0C: 40980018  bge cr6, 0x8220ef24
	if !ctx.cr[6].lt {
	pc = 0x8220EF24; continue 'dispatch;
	}
	// 8220EF10: ED80682A  fadds f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220EF14: FF0CF000  fcmpu cr6, f12, f30
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[30].f64);
	// 8220EF18: 4198000C  blt cr6, 0x8220ef24
	if ctx.cr[6].lt {
	pc = 0x8220EF24; continue 'dispatch;
	}
	// 8220EF1C: D3DF0040  stfs f30, 0x40(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EF20: 48000014  b 0x8220ef34
	pc = 0x8220EF34; continue 'dispatch;
	// 8220EF24: FC40F890  fmr f2, f31
	ctx.f[2].f64 = ctx.f[31].f64;
	// 8220EF28: EC20682A  fadds f1, f0, f13
	ctx.f[1].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220EF2C: 4BF14DDD  bl 0x82123d08
	ctx.lr = 0x8220EF30;
	sub_82123D08(ctx, base);
	// 8220EF30: D03F0040  stfs f1, 0x40(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EF34: C1BF0048  lfs f13, 0x48(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EF38: FF0DF800  fcmpu cr6, f13, f31
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[31].f64);
	// 8220EF3C: 4098FF78  bge cr6, 0x8220eeb4
	if !ctx.cr[6].lt {
	pc = 0x8220EEB4; continue 'dispatch;
	}
	// 8220EF40: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EF44: C00B20CC  lfs f0, 0x20cc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8396 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EF48: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220EF4C: EDBF0028  fsubs f13, f31, f0
	ctx.f[13].f64 = (((ctx.f[31].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EF50: FC0DF82E  fsel f0, f13, f0, f31
	ctx.f[0].f64 = if ctx.f[13].f64 >= 0.0 { ctx.f[0].f64 } else { ctx.f[31].f64 };
	// 8220EF54: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EF58: 4800013C  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220EF5C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EF60: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EF64: D3FF0048  stfs f31, 0x48(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220EF68: C00B272C  lfs f0, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EF6C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EF70: EC0D0028  fsubs f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220EF74: C9AB2008  lfd f13, 0x2008(r11)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8200 as u32) ) };
	// 8220EF78: FD800050  fneg f12, f0
	ctx.f[12].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8220EF7C: FC0C036E  fsel f0, f12, f13, f0
	ctx.f[0].f64 = if ctx.f[12].f64 >= 0.0 { ctx.f[13].f64 } else { ctx.f[0].f64 };
	// 8220EF80: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8220EF84: D01F0040  stfs f0, 0x40(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EF88: 4800010C  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
            }
            0x8220EF8C => {
    //   block [0x8220EF8C..0x8220F020)
	// 8220EF8C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EF90: C01F0040  lfs f0, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220EF94: C18B2038  lfs f12, 0x2038(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8248 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220EF98: FF006000  fcmpu cr6, f0, f12
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[12].f64);
	// 8220EF9C: 419A0078  beq cr6, 0x8220f014
	if ctx.cr[6].eq {
	pc = 0x8220F014; continue 'dispatch;
	}
	// 8220EFA0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EFA4: C16B203C  lfs f11, 0x203c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8252 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220EFA8: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 8220EFAC: 419A0068  beq cr6, 0x8220f014
	if ctx.cr[6].eq {
	pc = 0x8220F014; continue 'dispatch;
	}
	// 8220EFB0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220EFB4: FF006000  fcmpu cr6, f0, f12
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[12].f64);
	// 8220EFB8: C1AB272C  lfs f13, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220EFBC: 40980020  bge cr6, 0x8220efdc
	if !ctx.cr[6].lt {
	pc = 0x8220EFDC; continue 'dispatch;
	}
	// 8220EFC0: ED40682A  fadds f10, f0, f13
	ctx.f[10].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220EFC4: FF0A6000  fcmpu cr6, f10, f12
	ctx.cr[6].compare_f64(ctx.f[10].f64, ctx.f[12].f64);
	// 8220EFC8: 41980014  blt cr6, 0x8220efdc
	if ctx.cr[6].lt {
	pc = 0x8220EFDC; continue 'dispatch;
	}
	// 8220EFCC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220EFD0: D19F0040  stfs f12, 0x40(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EFD4: B17F004E  sth r11, 0x4e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(78 as u32), ctx.r[11].u16 ) };
	// 8220EFD8: 480000BC  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220EFDC: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 8220EFE0: 40980020  bge cr6, 0x8220f000
	if !ctx.cr[6].lt {
	pc = 0x8220F000; continue 'dispatch;
	}
	// 8220EFE4: ED80682A  fadds f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220EFE8: FF0C5800  fcmpu cr6, f12, f11
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[11].f64);
	// 8220EFEC: 41980014  blt cr6, 0x8220f000
	if ctx.cr[6].lt {
	pc = 0x8220F000; continue 'dispatch;
	}
	// 8220EFF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220EFF4: D17F0040  stfs f11, 0x40(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220EFF8: B17F004E  sth r11, 0x4e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(78 as u32), ctx.r[11].u16 ) };
	// 8220EFFC: 48000098  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220F000: FC40F890  fmr f2, f31
	ctx.f[2].f64 = ctx.f[31].f64;
	// 8220F004: EC20682A  fadds f1, f0, f13
	ctx.f[1].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220F008: 4BF14D01  bl 0x82123d08
	ctx.lr = 0x8220F00C;
	sub_82123D08(ctx, base);
	// 8220F00C: D03F0040  stfs f1, 0x40(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220F010: 48000084  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220F014: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220F018: B17F004E  sth r11, 0x4e(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(78 as u32), ctx.r[11].u16 ) };
	// 8220F01C: 48000078  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
            }
            0x8220F020 => {
    //   block [0x8220F020..0x8220F094)
	// 8220F020: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220F024: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F028: FC40F890  fmr f2, f31
	ctx.f[2].f64 = ctx.f[31].f64;
	// 8220F02C: C00B272C  lfs f0, 0x272c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10028 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F030: EC2D002A  fadds f1, f13, f0
	ctx.f[1].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220F034: 4BF14CD5  bl 0x82123d08
	ctx.lr = 0x8220F038;
	sub_82123D08(ctx, base);
	// 8220F038: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 8220F03C: C1BF0048  lfs f13, 0x48(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F040: D03F0040  stfs f1, 0x40(r31)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220F044: C00BD468  lfs f0, -0x2b98(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-11160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F048: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220F04C: 40990020  ble cr6, 0x8220f06c
	if !ctx.cr[6].gt {
	pc = 0x8220F06C; continue 'dispatch;
	}
	// 8220F050: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220F054: C18B20CC  lfs f12, 0x20cc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8396 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F058: EDAD6028  fsubs f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 8220F05C: ED806828  fsubs f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8220F060: FC0C682E  fsel f0, f12, f0, f13
	ctx.f[0].f64 = if ctx.f[12].f64 >= 0.0 { ctx.f[0].f64 } else { ctx.f[13].f64 };
	// 8220F064: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220F068: 4800002C  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220F06C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8220F070: 40980024  bge cr6, 0x8220f094
	if !ctx.cr[6].lt {
	pc = 0x8220F094; continue 'dispatch;
	}
	// 8220F074: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220F078: C18B20CC  lfs f12, 0x20cc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8396 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F07C: EDAD602A  fadds f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8220F080: ED806828  fsubs f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8220F084: FC0C036E  fsel f0, f12, f13, f0
	ctx.f[0].f64 = if ctx.f[12].f64 >= 0.0 { ctx.f[13].f64 } else { ctx.f[0].f64 };
	// 8220F088: D01F0048  stfs f0, 0x48(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220F08C: 48000008  b 0x8220f094
	pc = 0x8220F094; continue 'dispatch;
	// 8220F090: D3DF0040  stfs f30, 0x40(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), tmp.u32 ) };
            }
            0x8220F094 => {
    //   block [0x8220F094..0x8220F1A8)
	// 8220F094: C1BF0040  lfs f13, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F098: D3C10060  stfs f30, 0x60(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220F09C: FF0DF000  fcmpu cr6, f13, f30
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[30].f64);
	// 8220F0A0: D3E10064  stfs f31, 0x64(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220F0A4: D3C10068  stfs f30, 0x68(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220F0A8: D3E1006C  stfs f31, 0x6c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8220F0AC: 419A00AC  beq cr6, 0x8220f158
	if ctx.cr[6].eq {
	pc = 0x8220F158; continue 'dispatch;
	}
	// 8220F0B0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220F0B4: 3B810060  addi r28, r1, 0x60
	ctx.r[28].s64 = ctx.r[1].s64 + 96;
	// 8220F0B8: C00B2490  lfs f0, 0x2490(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9360 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F0BC: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220F0C0: 4BF0E409  bl 0x8211d4c8
	ctx.lr = 0x8220F0C4;
	sub_8211D4C8(ctx, base);
	// 8220F0C4: C01F0048  lfs f0, 0x48(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F0C8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220F0CC: EC010032  fmuls f0, f1, f0
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220F0D0: C1BF0044  lfs f13, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F0D4: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8220F0D8: EC200372  fmuls f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220F0DC: 481651BD  bl 0x82374298
	ctx.lr = 0x8220F0E0;
	sub_82374298(ctx, base);
	// 8220F0E0: C141005C  lfs f10, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220F0E4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220F0E8: C17F0038  lfs f11, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220F0EC: EC8B02B2  fmuls f4, f11, f10
	ctx.f[4].f64 = (((ctx.f[11].f64 * ctx.f[10].f64) as f32) as f64);
	// 8220F0F0: C1010050  lfs f8, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220F0F4: C1210054  lfs f9, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220F0F8: ECAB0232  fmuls f5, f11, f8
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[8].f64) as f32) as f64);
	// 8220F0FC: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F100: C0E10058  lfs f7, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220F104: EC6C0232  fmuls f3, f12, f8
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 8220F108: C01F0034  lfs f0, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F10C: ECC001F2  fmuls f6, f0, f7
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 8220F110: C1BF003C  lfs f13, 0x3c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F114: EC8C227A  fmadds f4, f12, f9, f4
	ctx.f[4].f64 = (((ctx.f[12].f64 * ctx.f[9].f64 + ctx.f[4].f64) as f32) as f64);
	// 8220F118: ECAD2A7A  fmadds f5, f13, f9, f5
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[5].f64) as f32) as f64);
	// 8220F11C: EC6D1AB8  fmsubs f3, f13, f10, f3
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[10].f64 - ctx.f[3].f64) as f32) as f64);
	// 8220F120: ECCC32BA  fmadds f6, f12, f10, f6
	ctx.f[6].f64 = (((ctx.f[12].f64 * ctx.f[10].f64 + ctx.f[6].f64) as f32) as f64);
	// 8220F124: EC8D21FA  fmadds f4, f13, f7, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[4].f64) as f32) as f64);
	// 8220F128: ECA02ABA  fmadds f5, f0, f10, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[5].f64) as f32) as f64);
	// 8220F12C: ECCD323A  fmadds f6, f13, f8, f6
	ctx.f[6].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[6].f64) as f32) as f64);
	// 8220F130: ED40223C  fnmsubs f10, f0, f8, f4
	ctx.f[10].f64 = -(((ctx.f[0].f64 * ctx.f[8].f64 - ctx.f[4].f64) as f32) as f64);
	// 8220F134: D1410058  stfs f10, 0x58(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8220F138: EC001A7C  fnmsubs f0, f0, f9, f3
	ctx.f[0].f64 = -(((ctx.f[0].f64 * ctx.f[9].f64 - ctx.f[3].f64) as f32) as f64);
	// 8220F13C: ED8C29FC  fnmsubs f12, f12, f7, f5
	ctx.f[12].f64 = -(((ctx.f[12].f64 * ctx.f[7].f64 - ctx.f[5].f64) as f32) as f64);
	// 8220F140: D1810054  stfs f12, 0x54(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8220F144: EDAB327C  fnmsubs f13, f11, f9, f6
	ctx.f[13].f64 = -(((ctx.f[11].f64 * ctx.f[9].f64 - ctx.f[6].f64) as f32) as f64);
	// 8220F148: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8220F14C: EC0B01FC  fnmsubs f0, f11, f7, f0
	ctx.f[0].f64 = -(((ctx.f[11].f64 * ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 8220F150: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8220F154: 48000008  b 0x8220f15c
	pc = 0x8220F15C; continue 'dispatch;
	// 8220F158: 389F0030  addi r4, r31, 0x30
	ctx.r[4].s64 = ctx.r[31].s64 + 48;
	// 8220F15C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220F160: 481593D9  bl 0x82368538
	ctx.lr = 0x8220F164;
	sub_82368538(ctx, base);
	// 8220F164: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F168: D01E0030  stfs f0, 0x30(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220F16C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8220F170: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F174: D01E0034  stfs f0, 0x34(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220F178: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F17C: D01E0038  stfs f0, 0x38(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220F180: D3FE003C  stfs f31, 0x3c(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220F184: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220F188: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220F18C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220F190: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220F194: 48158B9D  bl 0x82367d30
	ctx.lr = 0x8220F198;
	sub_82367D30(ctx, base);
	// 8220F198: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8220F19C: CBC1FFC8  lfd f30, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 8220F1A0: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8220F1A4: 48325F64  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F1A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220F1A8 size=340
    let mut pc: u32 = 0x8220F1A8;
    'dispatch: loop {
        match pc {
            0x8220F1A8 => {
    //   block [0x8220F1A8..0x8220F2FC)
	// 8220F1A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220F1AC: 48325F11  bl 0x825350bc
	ctx.lr = 0x8220F1B0;
	sub_82535080(ctx, base);
	// 8220F1B0: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8220F1B4: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220F1B8: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8220F1BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220F1C0: 396B4598  addi r11, r11, 0x4598
	ctx.r[11].s64 = ctx.r[11].s64 + 17816;
	// 8220F1C4: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8220F1C8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8220F1CC: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 8220F1D0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220F1D4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8220F1D8: 93BE0024  stw r29, 0x24(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8220F1DC: 93BE0028  stw r29, 0x28(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8220F1E0: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 8220F1E4: C3EABA38  lfs f31, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8220F1E8: B17E0020  sth r11, 0x20(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8220F1EC: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8220F1F0: B17E0022  sth r11, 0x22(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8220F1F4: C01F0010  lfs f0, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F1F8: D01E0010  stfs f0, 0x10(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220F1FC: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F200: D01E0014  stfs f0, 0x14(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220F204: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F208: D01E0018  stfs f0, 0x18(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220F20C: D3FE001C  stfs f31, 0x1c(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8220F210: C07F0028  lfs f3, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220F214: C05F0024  lfs f2, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220F218: C03F0020  lfs f1, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220F21C: 48158FFD  bl 0x82368218
	ctx.lr = 0x8220F220;
	sub_82368218(ctx, base);
	// 8220F220: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8220F224: C07F0008  lfs f3, 8(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220F228: C05F0004  lfs f2, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220F22C: C03F0000  lfs f1, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220F230: 48158FE9  bl 0x82368218
	ctx.lr = 0x8220F234;
	sub_82368218(ctx, base);
	// 8220F234: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8220F238: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220F23C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220F240: 48158BB1  bl 0x82367df0
	ctx.lr = 0x8220F244;
	sub_82367DF0(ctx, base);
	// 8220F244: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220F248: 387E0070  addi r3, r30, 0x70
	ctx.r[3].s64 = ctx.r[30].s64 + 112;
	// 8220F24C: 48165155  bl 0x823743a0
	ctx.lr = 0x8220F250;
	sub_823743A0(ctx, base);
	// 8220F250: C01F0020  lfs f0, 0x20(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F254: D01E0030  stfs f0, 0x30(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220F258: 395E0080  addi r10, r30, 0x80
	ctx.r[10].s64 = ctx.r[30].s64 + 128;
	// 8220F25C: C01F0024  lfs f0, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F260: 7FA9EB78  mr r9, r29
	ctx.r[9].u64 = ctx.r[29].u64;
	// 8220F264: D01E0034  stfs f0, 0x34(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220F268: 39600007  li r11, 7
	ctx.r[11].s64 = 7;
	// 8220F26C: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F270: D01E0038  stfs f0, 0x38(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220F274: C01F0000  lfs f0, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F278: D01E0040  stfs f0, 0x40(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8220F27C: C01F0004  lfs f0, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F280: D01E0044  stfs f0, 0x44(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8220F284: C01F0008  lfs f0, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F288: D01E0048  stfs f0, 0x48(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8220F28C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220F290: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8220F294: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8220F298: 4200FFF8  bdnz 0x8220f290
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8220F290; continue 'dispatch;
	}
	// 8220F29C: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8220F2A0: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8220F2A4: 397E0084  addi r11, r30, 0x84
	ctx.r[11].s64 = ctx.r[30].s64 + 132;
	// 8220F2A8: 39000003  li r8, 3
	ctx.r[8].s64 = 3;
	// 8220F2AC: C00A2074  lfs f0, 0x2074(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8308 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F2B0: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8220F2B4: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8220F2B8: D3EB0000  stfs f31, 0(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220F2BC: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220F2C0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8220F2C4: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220F2C8: 396B0014  addi r11, r11, 0x14
	ctx.r[11].s64 = ctx.r[11].s64 + 20;
	// 8220F2CC: 409AFFE4  bne cr6, 0x8220f2b0
	if !ctx.cr[6].eq {
	pc = 0x8220F2B0; continue 'dispatch;
	}
	// 8220F2D0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8220F2D4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8220F2D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220F2DC: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F2E0: D01E0060  stfs f0, 0x60(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8220F2E4: 915E00BC  stw r10, 0xbc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(188 as u32), ctx.r[10].u32 ) };
	// 8220F2E8: D01E0064  stfs f0, 0x64(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8220F2EC: D01E0068  stfs f0, 0x68(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8220F2F0: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 8220F2F4: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8220F2F8: 48325E14  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F300(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220F300 size=452
    let mut pc: u32 = 0x8220F300;
    'dispatch: loop {
        match pc {
            0x8220F300 => {
    //   block [0x8220F300..0x8220F4C4)
	// 8220F300: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220F304: 48325DB9  bl 0x825350bc
	ctx.lr = 0x8220F308;
	sub_82535080(ctx, base);
	// 8220F308: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220F30C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220F310: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8220F314: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220F318: A17F0020  lhz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8220F31C: C07F0038  lfs f3, 0x38(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220F320: C05F0034  lfs f2, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8220F324: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220F328: C03F0030  lfs f1, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8220F32C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220F330: 7FCBEA14  add r30, r11, r29
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220F334: 48158EE5  bl 0x82368218
	ctx.lr = 0x8220F338;
	sub_82368218(ctx, base);
	// 8220F338: C01F0068  lfs f0, 0x68(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(104 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F33C: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 8220F340: C1BF0048  lfs f13, 0x48(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F344: EC60682A  fadds f3, f0, f13
	ctx.f[3].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8220F348: C19F0064  lfs f12, 0x64(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(100 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F34C: C01F0044  lfs f0, 0x44(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F350: EC4C002A  fadds f2, f12, f0
	ctx.f[2].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220F354: C1BF0060  lfs f13, 0x60(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(96 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F358: C01F0040  lfs f0, 0x40(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F35C: EC2D002A  fadds f1, f13, f0
	ctx.f[1].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8220F360: 48158EB9  bl 0x82368218
	ctx.lr = 0x8220F364;
	sub_82368218(ctx, base);
	// 8220F364: 38A100A0  addi r5, r1, 0xa0
	ctx.r[5].s64 = ctx.r[1].s64 + 160;
	// 8220F368: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220F36C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8220F370: 48158A81  bl 0x82367df0
	ctx.lr = 0x8220F374;
	sub_82367DF0(ctx, base);
	// 8220F374: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8220F378: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8220F37C: 48165025  bl 0x823743a0
	ctx.lr = 0x8220F380;
	sub_823743A0(ctx, base);
	// 8220F380: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8220F384: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220F388: 481591B1  bl 0x82368538
	ctx.lr = 0x8220F38C;
	sub_82368538(ctx, base);
	// 8220F38C: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8220F390: C1BF0010  lfs f13, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F394: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8220F398: D1BE0030  stfs f13, 0x30(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8220F39C: C1BF0014  lfs f13, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F3A0: D1BE0034  stfs f13, 0x34(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8220F3A4: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F3A8: C1BF0018  lfs f13, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F3AC: D1BE0038  stfs f13, 0x38(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8220F3B0: D01E003C  stfs f0, 0x3c(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8220F3B4: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 8220F3B8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8220F3BC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8220F3C0: 7C8BEA14  add r4, r11, r29
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8220F3C4: 4815896D  bl 0x82367d30
	ctx.lr = 0x8220F3C8;
	sub_82367D30(ctx, base);
	// 8220F3C8: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8220F3CC: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8220F3D0: 3D208286  lis r9, -0x7d7a
	ctx.r[9].s64 = -2105147392;
	// 8220F3D4: 397F008C  addi r11, r31, 0x8c
	ctx.r[11].s64 = ctx.r[31].s64 + 140;
	// 8220F3D8: 39400003  li r10, 3
	ctx.r[10].s64 = 3;
	// 8220F3DC: C1072074  lfs f8, 0x2074(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8308 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220F3E0: C1481FF8  lfs f10, 0x1ff8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8184 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220F3E4: C129F384  lfs f9, -0xc7c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-3196 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220F3E8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F3EC: C16BFFF8  lfs f11, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220F3F0: FF0D5000  fcmpu cr6, f13, f10
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[10].f64);
	// 8220F3F4: D16BFFF4  stfs f11, -0xc(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 8220F3F8: 4198003C  blt cr6, 0x8220f434
	if ctx.cr[6].lt {
	pc = 0x8220F434; continue 'dispatch;
	}
	// 8220F3FC: C00B0004  lfs f0, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F400: EC00482A  fadds f0, f0, f9
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64;
	// 8220F404: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220F408: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8220F40C: 41980014  blt cr6, 0x8220f420
	if ctx.cr[6].lt {
	pc = 0x8220F420; continue 'dispatch;
	}
	// 8220F410: D16BFFF4  stfs f11, -0xc(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 8220F414: D10B0000  stfs f8, 0(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220F418: D14B0004  stfs f10, 4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220F41C: 48000018  b 0x8220f434
	pc = 0x8220F434; continue 'dispatch;
	// 8220F420: C18BFFFC  lfs f12, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F424: ED6B6028  fsubs f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8220F428: EDAB6824  fdivs f13, f11, f13
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[13].f64) as f32) as f64;
	// 8220F42C: EC0D603A  fmadds f0, f13, f0, f12
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64);
	// 8220F430: D00BFFF4  stfs f0, -0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 8220F434: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8220F438: 396B0014  addi r11, r11, 0x14
	ctx.r[11].s64 = ctx.r[11].s64 + 20;
	// 8220F43C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8220F440: 409AFFA8  bne cr6, 0x8220f3e8
	if !ctx.cr[6].eq {
	pc = 0x8220F3E8; continue 'dispatch;
	}
	// 8220F444: C19F0080  lfs f12, 0x80(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8220F448: C17E0000  lfs f11, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8220F44C: C01F00A8  lfs f0, 0xa8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(168 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8220F450: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220F454: C1BF0094  lfs f13, 0x94(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(148 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8220F458: C15E0004  lfs f10, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8220F45C: C13E0008  lfs f9, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8220F460: D17E0000  stfs f11, 0(r30)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8220F464: ED6A0332  fmuls f11, f10, f12
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220F468: C11E0010  lfs f8, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8220F46C: ED890332  fmuls f12, f9, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8220F470: C0FE0014  lfs f7, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8220F474: ED080372  fmuls f8, f8, f13
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220F478: C0DE0018  lfs f6, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8220F47C: D19E0008  stfs f12, 8(r30)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8220F480: ED870372  fmuls f12, f7, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220F484: C0BE0020  lfs f5, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8220F488: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8220F48C: C09E0024  lfs f4, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8220F490: ECA50032  fmuls f5, f5, f0
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220F494: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8220F498: D1BE0018  stfs f13, 0x18(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8220F49C: EDA40032  fmuls f13, f4, f0
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220F4A0: EC030032  fmuls f0, f3, f0
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8220F4A4: D0BE0020  stfs f5, 0x20(r30)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8220F4A8: D11E0010  stfs f8, 0x10(r30)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8220F4AC: D17E0004  stfs f11, 4(r30)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8220F4B0: D19E0014  stfs f12, 0x14(r30)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8220F4B4: D1BE0024  stfs f13, 0x24(r30)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8220F4B8: D01E0028  stfs f0, 0x28(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8220F4BC: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 8220F4C0: 48325C4C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F4C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F4C8 size=28
    let mut pc: u32 = 0x8220F4C8;
    'dispatch: loop {
        match pc {
            0x8220F4C8 => {
    //   block [0x8220F4C8..0x8220F4E4)
	// 8220F4C8: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F4CC: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F4D0: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F4D4: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F4D8: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F4DC: 386B0125  addi r3, r11, 0x125
	ctx.r[3].s64 = ctx.r[11].s64 + 293;
	// 8220F4E0: 48153478  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F4E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F4E8 size=28
    let mut pc: u32 = 0x8220F4E8;
    'dispatch: loop {
        match pc {
            0x8220F4E8 => {
    //   block [0x8220F4E8..0x8220F504)
	// 8220F4E8: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F4EC: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F4F0: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F4F4: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F4F8: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F4FC: 386B0126  addi r3, r11, 0x126
	ctx.r[3].s64 = ctx.r[11].s64 + 294;
	// 8220F500: 48153458  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F508(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F508 size=28
    let mut pc: u32 = 0x8220F508;
    'dispatch: loop {
        match pc {
            0x8220F508 => {
    //   block [0x8220F508..0x8220F524)
	// 8220F508: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F50C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F510: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F514: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F518: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F51C: 386B0128  addi r3, r11, 0x128
	ctx.r[3].s64 = ctx.r[11].s64 + 296;
	// 8220F520: 48153438  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F528(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F528 size=28
    let mut pc: u32 = 0x8220F528;
    'dispatch: loop {
        match pc {
            0x8220F528 => {
    //   block [0x8220F528..0x8220F544)
	// 8220F528: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F52C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F530: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F534: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F538: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F53C: 386B0127  addi r3, r11, 0x127
	ctx.r[3].s64 = ctx.r[11].s64 + 295;
	// 8220F540: 48153418  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F548(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F548 size=28
    let mut pc: u32 = 0x8220F548;
    'dispatch: loop {
        match pc {
            0x8220F548 => {
    //   block [0x8220F548..0x8220F564)
	// 8220F548: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F54C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F550: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F554: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F558: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F55C: 386B0129  addi r3, r11, 0x129
	ctx.r[3].s64 = ctx.r[11].s64 + 297;
	// 8220F560: 481533F8  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F568(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F568 size=28
    let mut pc: u32 = 0x8220F568;
    'dispatch: loop {
        match pc {
            0x8220F568 => {
    //   block [0x8220F568..0x8220F584)
	// 8220F568: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F56C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F570: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F574: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F578: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F57C: 386B012A  addi r3, r11, 0x12a
	ctx.r[3].s64 = ctx.r[11].s64 + 298;
	// 8220F580: 481533D8  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F588 size=28
    let mut pc: u32 = 0x8220F588;
    'dispatch: loop {
        match pc {
            0x8220F588 => {
    //   block [0x8220F588..0x8220F5A4)
	// 8220F588: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F58C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F590: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F594: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F598: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F59C: 386B012B  addi r3, r11, 0x12b
	ctx.r[3].s64 = ctx.r[11].s64 + 299;
	// 8220F5A0: 481533B8  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F5A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F5A8 size=28
    let mut pc: u32 = 0x8220F5A8;
    'dispatch: loop {
        match pc {
            0x8220F5A8 => {
    //   block [0x8220F5A8..0x8220F5C4)
	// 8220F5A8: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F5AC: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F5B0: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F5B4: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F5B8: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F5BC: 386B012C  addi r3, r11, 0x12c
	ctx.r[3].s64 = ctx.r[11].s64 + 300;
	// 8220F5C0: 48153398  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F5C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F5C8 size=28
    let mut pc: u32 = 0x8220F5C8;
    'dispatch: loop {
        match pc {
            0x8220F5C8 => {
    //   block [0x8220F5C8..0x8220F5E4)
	// 8220F5C8: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F5CC: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F5D0: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F5D4: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F5D8: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F5DC: 386B012D  addi r3, r11, 0x12d
	ctx.r[3].s64 = ctx.r[11].s64 + 301;
	// 8220F5E0: 48153378  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F5E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F5E8 size=28
    let mut pc: u32 = 0x8220F5E8;
    'dispatch: loop {
        match pc {
            0x8220F5E8 => {
    //   block [0x8220F5E8..0x8220F604)
	// 8220F5E8: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F5EC: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F5F0: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F5F4: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F5F8: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F5FC: 386B012F  addi r3, r11, 0x12f
	ctx.r[3].s64 = ctx.r[11].s64 + 303;
	// 8220F600: 48153358  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F608 size=28
    let mut pc: u32 = 0x8220F608;
    'dispatch: loop {
        match pc {
            0x8220F608 => {
    //   block [0x8220F608..0x8220F624)
	// 8220F608: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F60C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F610: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F614: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F618: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F61C: 386B012E  addi r3, r11, 0x12e
	ctx.r[3].s64 = ctx.r[11].s64 + 302;
	// 8220F620: 48153338  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F628(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F628 size=28
    let mut pc: u32 = 0x8220F628;
    'dispatch: loop {
        match pc {
            0x8220F628 => {
    //   block [0x8220F628..0x8220F644)
	// 8220F628: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F62C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F630: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F634: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F638: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F63C: 386B0131  addi r3, r11, 0x131
	ctx.r[3].s64 = ctx.r[11].s64 + 305;
	// 8220F640: 48153318  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8220F648 size=28
    let mut pc: u32 = 0x8220F648;
    'dispatch: loop {
        match pc {
            0x8220F648 => {
    //   block [0x8220F648..0x8220F664)
	// 8220F648: 21650000  subfic r11, r5, 0
	ctx.xer.ca = ctx.r[5].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[5].s64;
	// 8220F64C: 80830010  lwz r4, 0x10(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8220F650: 38A30014  addi r5, r3, 0x14
	ctx.r[5].s64 = ctx.r[3].s64 + 20;
	// 8220F654: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8220F658: 556B073C  rlwinm r11, r11, 0, 0x1c, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8220F65C: 386B0132  addi r3, r11, 0x132
	ctx.r[3].s64 = ctx.r[11].s64 + 306;
	// 8220F660: 481532F8  b 0x82362958
	sub_82362958(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8220F668(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8220F668 size=3648
    let mut pc: u32 = 0x8220F668;
    'dispatch: loop {
        match pc {
            0x8220F668 => {
    //   block [0x8220F668..0x822104A8)
	// 8220F668: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8220F66C: 48325A19  bl 0x82535084
	ctx.lr = 0x8220F670;
	sub_82535080(ctx, base);
	// 8220F670: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 8220F674: 9421EEF0  stwu r1, -0x1110(r1)
	ea = ctx.r[1].u32.wrapping_add(-4368 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8220F678: 7C721B78  mr r18, r3
	ctx.r[18].u64 = ctx.r[3].u64;
	// 8220F67C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8220F680: 8172000C  lwz r11, 0xc(r18)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(12 as u32) ) } as u64;
	// 8220F684: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8220F688: 419A0E18  beq cr6, 0x822104a0
	if ctx.cr[6].eq {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F68C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8220F690: 419A0E10  beq cr6, 0x822104a0
	if ctx.cr[6].eq {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F694: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8220F698: 419A0E08  beq cr6, 0x822104a0
	if ctx.cr[6].eq {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F69C: 81720018  lwz r11, 0x18(r18)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(24 as u32) ) } as u64;
	// 8220F6A0: 394B0014  addi r10, r11, 0x14
	ctx.r[10].s64 = ctx.r[11].s64 + 20;
	// 8220F6A4: 3D6082B5  lis r11, -0x7d4b
	ctx.r[11].s64 = -2102067200;
	// 8220F6A8: 39EB0C40  addi r15, r11, 0xc40
	ctx.r[15].s64 = ctx.r[11].s64 + 3136;
	// 8220F6AC: 816F0688  lwz r11, 0x688(r15)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(1672 as u32) ) } as u64;
	// 8220F6B0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8220F6B4: 41980DEC  blt cr6, 0x822104a0
	if ctx.cr[6].lt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F6B8: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220F6BC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8220F6C0: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220F6C4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220F6C8: 4E800421  bctrl
	ctx.lr = 0x8220F6CC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220F6CC: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8220F6D0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8220F6D4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8220F6D8: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220F6DC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8220F6E0: 4E800421  bctrl
	ctx.lr = 0x8220F6E4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8220F6E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8220F6E8: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8220F6EC: 41980DB4  blt cr6, 0x822104a0
	if ctx.cr[6].lt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F6F0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8220F6F4: 41980DAC  blt cr6, 0x822104a0
	if ctx.cr[6].lt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F6F8: 80720014  lwz r3, 0x14(r18)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(20 as u32) ) } as u64;
	// 8220F6FC: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 8220F700: 419A0018  beq cr6, 0x8220f718
	if ctx.cr[6].eq {
	pc = 0x8220F718; continue 'dispatch;
	}
	// 8220F704: 481F609D  bl 0x824057a0
	ctx.lr = 0x8220F708;
	sub_824057A0(ctx, base);
	// 8220F708: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8220F70C: 409A000C  bne cr6, 0x8220f718
	if !ctx.cr[6].eq {
	pc = 0x8220F718; continue 'dispatch;
	}
	// 8220F710: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 8220F714: 91720014  stw r11, 0x14(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8220F718: 7D7EFA14  add r11, r30, r31
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[31].u64;
	// 8220F71C: 5571C73E  rlwinm r17, r11, 0x18, 0x1c, 0x1f
	ctx.r[17].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8220F720: 2B110007  cmplwi cr6, r17, 7
	ctx.cr[6].compare_u32(ctx.r[17].u32, 7 as u32, &mut ctx.xer);
	// 8220F724: 41990D7C  bgt cr6, 0x822104a0
	if ctx.cr[6].gt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F728: 5570073E  clrlwi r16, r11, 0x1c
	ctx.r[16].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8220F72C: 2B100010  cmplwi cr6, r16, 0x10
	ctx.cr[6].compare_u32(ctx.r[16].u32, 16 as u32, &mut ctx.xer);
	// 8220F730: 41990D70  bgt cr6, 0x822104a0
	if ctx.cr[6].gt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 8220F734: 3D60822B  lis r11, -0x7dd5
	ctx.r[11].s64 = -2111111168;
	// 8220F738: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8220F73C: 396B2F80  addi r11, r11, 0x2f80
	ctx.r[11].s64 = ctx.r[11].s64 + 12160;
	// 8220F740: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 8220F744: 3EE08221  lis r23, -0x7ddf
	ctx.r[23].s64 = -2111766528;
	// 8220F748: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 8220F74C: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 8220F750: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 8220F754: 916100E8  stw r11, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 8220F758: 3F608221  lis r27, -0x7ddf
	ctx.r[27].s64 = -2111766528;
	// 8220F75C: 3F80822B  lis r28, -0x7dd5
	ctx.r[28].s64 = -2111111168;
	// 8220F760: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 8220F764: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8220F768: 3FE08221  lis r31, -0x7ddf
	ctx.r[31].s64 = -2111766528;
	// 8220F76C: 3C608221  lis r3, -0x7ddf
	ctx.r[3].s64 = -2111766528;
	// 8220F770: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 8220F774: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 8220F778: 3CC08221  lis r6, -0x7ddf
	ctx.r[6].s64 = -2111766528;
	// 8220F77C: 3CE0822B  lis r7, -0x7dd5
	ctx.r[7].s64 = -2111111168;
	// 8220F780: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 8220F784: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 8220F788: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 8220F78C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8220F790: 3AB5F4C8  addi r21, r21, -0xb38
	ctx.r[21].s64 = ctx.r[21].s64 + -2872;
	// 8220F794: 3AD6F4E8  addi r22, r22, -0xb18
	ctx.r[22].s64 = ctx.r[22].s64 + -2840;
	// 8220F798: 3AF7F508  addi r23, r23, -0xaf8
	ctx.r[23].s64 = ctx.r[23].s64 + -2808;
	// 8220F79C: 3B18F528  addi r24, r24, -0xad8
	ctx.r[24].s64 = ctx.r[24].s64 + -2776;
	// 8220F7A0: 3B39F548  addi r25, r25, -0xab8
	ctx.r[25].s64 = ctx.r[25].s64 + -2744;
	// 8220F7A4: 916100EC  stw r11, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 8220F7A8: 3B5AF568  addi r26, r26, -0xa98
	ctx.r[26].s64 = ctx.r[26].s64 + -2712;
	// 8220F7AC: 92A100C0  stw r21, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[21].u32 ) };
	// 8220F7B0: 3B7BF588  addi r27, r27, -0xa78
	ctx.r[27].s64 = ctx.r[27].s64 + -2680;
	// 8220F7B4: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8220F7B8: 3B9C2F80  addi r28, r28, 0x2f80
	ctx.r[28].s64 = ctx.r[28].s64 + 12160;
	// 8220F7BC: 92C100E0  stw r22, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[22].u32 ) };
	// 8220F7C0: 3BBDF4C8  addi r29, r29, -0xb38
	ctx.r[29].s64 = ctx.r[29].s64 + -2872;
	// 8220F7C4: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8220F7C8: 3BDEF4E8  addi r30, r30, -0xb18
	ctx.r[30].s64 = ctx.r[30].s64 + -2840;
	// 8220F7CC: 92E100D8  stw r23, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[23].u32 ) };
	// 8220F7D0: 3BFFF508  addi r31, r31, -0xaf8
	ctx.r[31].s64 = ctx.r[31].s64 + -2808;
	// 8220F7D4: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 8220F7D8: 3863F528  addi r3, r3, -0xad8
	ctx.r[3].s64 = ctx.r[3].s64 + -2776;
	// 8220F7DC: 930100D0  stw r24, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[24].u32 ) };
	// 8220F7E0: 3884F548  addi r4, r4, -0xab8
	ctx.r[4].s64 = ctx.r[4].s64 + -2744;
	// 8220F7E4: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 8220F7E8: 38A5F568  addi r5, r5, -0xa98
	ctx.r[5].s64 = ctx.r[5].s64 + -2712;
	// 8220F7EC: 932100C8  stw r25, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[25].u32 ) };
	// 8220F7F0: 38C6F588  addi r6, r6, -0xa78
	ctx.r[6].s64 = ctx.r[6].s64 + -2680;
	// 8220F7F4: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8220F7F8: 38E72F80  addi r7, r7, 0x2f80
	ctx.r[7].s64 = ctx.r[7].s64 + 12160;
	// 8220F7FC: 93410070  stw r26, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[26].u32 ) };
	// 8220F800: 3908F4C8  addi r8, r8, -0xb38
	ctx.r[8].s64 = ctx.r[8].s64 + -2872;
	// 8220F804: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8220F808: 3929F4E8  addi r9, r9, -0xb18
	ctx.r[9].s64 = ctx.r[9].s64 + -2840;
	// 8220F80C: 936100B0  stw r27, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[27].u32 ) };
	// 8220F810: 394AF508  addi r10, r10, -0xaf8
	ctx.r[10].s64 = ctx.r[10].s64 + -2808;
	// 8220F814: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8220F818: 93810080  stw r28, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[28].u32 ) };
	// 8220F81C: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8220F820: 93A100A0  stw r29, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[29].u32 ) };
	// 8220F824: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8220F828: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 8220F82C: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220F830: 93E10058  stw r31, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[31].u32 ) };
	// 8220F834: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8220F838: 90610060  stw r3, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[3].u32 ) };
	// 8220F83C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220F840: 90810068  stw r4, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[4].u32 ) };
	// 8220F844: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8220F848: 90A10078  stw r5, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[5].u32 ) };
	// 8220F84C: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220F850: 90C10088  stw r6, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[6].u32 ) };
	// 8220F854: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 8220F858: 90E10098  stw r7, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[7].u32 ) };
	// 8220F85C: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8220F860: 910100A8  stw r8, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[8].u32 ) };
	// 8220F864: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8220F868: 912100B8  stw r9, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[9].u32 ) };
	// 8220F86C: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8220F870: 91410090  stw r10, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[10].u32 ) };
	// 8220F874: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8220F878: E94100E8  ld r10, 0xe8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8220F87C: 3E808221  lis r20, -0x7ddf
	ctx.r[20].s64 = -2111766528;
	// 8220F880: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8220F884: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 8220F888: 3EE08221  lis r23, -0x7ddf
	ctx.r[23].s64 = -2111766528;
	// 8220F88C: 3F00822B  lis r24, -0x7dd5
	ctx.r[24].s64 = -2111111168;
	// 8220F890: F9410100  std r10, 0x100(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), ctx.r[10].u64 ) };
	// 8220F894: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 8220F898: E94100C0  ld r10, 0xc0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 8220F89C: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 8220F8A0: 3A94F528  addi r20, r20, -0xad8
	ctx.r[20].s64 = ctx.r[20].s64 + -2776;
	// 8220F8A4: 3AB5F548  addi r21, r21, -0xab8
	ctx.r[21].s64 = ctx.r[21].s64 + -2744;
	// 8220F8A8: 3AD6F568  addi r22, r22, -0xa98
	ctx.r[22].s64 = ctx.r[22].s64 + -2712;
	// 8220F8AC: 3AF7F588  addi r23, r23, -0xa78
	ctx.r[23].s64 = ctx.r[23].s64 + -2680;
	// 8220F8B0: F9410108  std r10, 0x108(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), ctx.r[10].u64 ) };
	// 8220F8B4: 3B182F80  addi r24, r24, 0x2f80
	ctx.r[24].s64 = ctx.r[24].s64 + 12160;
	// 8220F8B8: E94100E0  ld r10, 0xe0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8220F8BC: 3B39F4C8  addi r25, r25, -0xb38
	ctx.r[25].s64 = ctx.r[25].s64 + -2872;
	// 8220F8C0: 3B5AF4E8  addi r26, r26, -0xb18
	ctx.r[26].s64 = ctx.r[26].s64 + -2840;
	// 8220F8C4: 3F608221  lis r27, -0x7ddf
	ctx.r[27].s64 = -2111766528;
	// 8220F8C8: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 8220F8CC: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 8220F8D0: F9410110  std r10, 0x110(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[10].u64 ) };
	// 8220F8D4: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8220F8D8: E94100D8  ld r10, 0xd8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 8220F8DC: 3FE08221  lis r31, -0x7ddf
	ctx.r[31].s64 = -2111766528;
	// 8220F8E0: 3C60822B  lis r3, -0x7dd5
	ctx.r[3].s64 = -2111111168;
	// 8220F8E4: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 8220F8E8: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 8220F8EC: 3CC08221  lis r6, -0x7ddf
	ctx.r[6].s64 = -2111766528;
	// 8220F8F0: F9410118  std r10, 0x118(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[10].u64 ) };
	// 8220F8F4: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 8220F8F8: E94100D0  ld r10, 0xd0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8220F8FC: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 8220F900: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 8220F904: F9410120  std r10, 0x120(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[10].u64 ) };
	// 8220F908: E94100C8  ld r10, 0xc8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 8220F90C: F9410128  std r10, 0x128(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), ctx.r[10].u64 ) };
	// 8220F910: E9410070  ld r10, 0x70(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8220F914: F9410130  std r10, 0x130(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[10].u64 ) };
	// 8220F918: E94100B0  ld r10, 0xb0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 8220F91C: F9410138  std r10, 0x138(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), ctx.r[10].u64 ) };
	// 8220F920: E9410080  ld r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8220F924: F9410140  std r10, 0x140(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[10].u64 ) };
	// 8220F928: E94100A0  ld r10, 0xa0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 8220F92C: F9410148  std r10, 0x148(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), ctx.r[10].u64 ) };
	// 8220F930: E9410050  ld r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8220F934: F9410150  std r10, 0x150(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[10].u64 ) };
	// 8220F938: E9410058  ld r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8220F93C: F9410158  std r10, 0x158(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), ctx.r[10].u64 ) };
	// 8220F940: E9410060  ld r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8220F944: F9410160  std r10, 0x160(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), ctx.r[10].u64 ) };
	// 8220F948: E9410068  ld r10, 0x68(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 8220F94C: 93410068  stw r26, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[26].u32 ) };
	// 8220F950: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8220F954: F9410168  std r10, 0x168(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), ctx.r[10].u64 ) };
	// 8220F958: E9410078  ld r10, 0x78(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8220F95C: 93210078  stw r25, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[25].u32 ) };
	// 8220F960: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220F964: F9410170  std r10, 0x170(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), ctx.r[10].u64 ) };
	// 8220F968: E9410088  ld r10, 0x88(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 8220F96C: 93010088  stw r24, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[24].u32 ) };
	// 8220F970: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 8220F974: F9410178  std r10, 0x178(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), ctx.r[10].u64 ) };
	// 8220F978: E9410098  ld r10, 0x98(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8220F97C: 92E10098  stw r23, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[23].u32 ) };
	// 8220F980: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8220F984: F9410180  std r10, 0x180(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[10].u64 ) };
	// 8220F988: E94100A8  ld r10, 0xa8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8220F98C: 92C100A8  stw r22, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[22].u32 ) };
	// 8220F990: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8220F994: F9410188  std r10, 0x188(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), ctx.r[10].u64 ) };
	// 8220F998: E94100B8  ld r10, 0xb8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8220F99C: 92A100B8  stw r21, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[21].u32 ) };
	// 8220F9A0: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8220F9A4: F9410190  std r10, 0x190(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), ctx.r[10].u64 ) };
	// 8220F9A8: E9410090  ld r10, 0x90(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8220F9AC: 92810090  stw r20, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[20].u32 ) };
	// 8220F9B0: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8220F9B4: F9410198  std r10, 0x198(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), ctx.r[10].u64 ) };
	// 8220F9B8: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 8220F9BC: 394AF588  addi r10, r10, -0xa78
	ctx.r[10].s64 = ctx.r[10].s64 + -2680;
	// 8220F9C0: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220F9C4: 3B7BF508  addi r27, r27, -0xaf8
	ctx.r[27].s64 = ctx.r[27].s64 + -2808;
	// 8220F9C8: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8220F9CC: 3B9CF528  addi r28, r28, -0xad8
	ctx.r[28].s64 = ctx.r[28].s64 + -2776;
	// 8220F9D0: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220F9D4: 3BBDF548  addi r29, r29, -0xab8
	ctx.r[29].s64 = ctx.r[29].s64 + -2744;
	// 8220F9D8: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8220F9DC: 3BDEF568  addi r30, r30, -0xa98
	ctx.r[30].s64 = ctx.r[30].s64 + -2712;
	// 8220F9E0: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8220F9E4: 914100E8  stw r10, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[10].u32 ) };
	// 8220F9E8: 3BFFF588  addi r31, r31, -0xa78
	ctx.r[31].s64 = ctx.r[31].s64 + -2680;
	// 8220F9EC: E9410090  ld r10, 0x90(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8220F9F0: 38632F80  addi r3, r3, 0x2f80
	ctx.r[3].s64 = ctx.r[3].s64 + 12160;
	// 8220F9F4: 93610060  stw r27, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[27].u32 ) };
	// 8220F9F8: 3884F4C8  addi r4, r4, -0xb38
	ctx.r[4].s64 = ctx.r[4].s64 + -2872;
	// 8220F9FC: 93810058  stw r28, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[28].u32 ) };
	// 8220FA00: 38A5F4E8  addi r5, r5, -0xb18
	ctx.r[5].s64 = ctx.r[5].s64 + -2840;
	// 8220FA04: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 8220FA08: 38C6F508  addi r6, r6, -0xaf8
	ctx.r[6].s64 = ctx.r[6].s64 + -2808;
	// 8220FA0C: 93C100A0  stw r30, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[30].u32 ) };
	// 8220FA10: 38E7F528  addi r7, r7, -0xad8
	ctx.r[7].s64 = ctx.r[7].s64 + -2776;
	// 8220FA14: F94101A0  std r10, 0x1a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(416 as u32), ctx.r[10].u64 ) };
	// 8220FA18: 3908F548  addi r8, r8, -0xab8
	ctx.r[8].s64 = ctx.r[8].s64 + -2744;
	// 8220FA1C: E94100B8  ld r10, 0xb8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8220FA20: 3929F568  addi r9, r9, -0xa98
	ctx.r[9].s64 = ctx.r[9].s64 + -2712;
	// 8220FA24: 93E10080  stw r31, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[31].u32 ) };
	// 8220FA28: 3E60822B  lis r19, -0x7dd5
	ctx.r[19].s64 = -2111111168;
	// 8220FA2C: 906100B0  stw r3, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[3].u32 ) };
	// 8220FA30: 3E808221  lis r20, -0x7ddf
	ctx.r[20].s64 = -2111766528;
	// 8220FA34: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8220FA38: 90810070  stw r4, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[4].u32 ) };
	// 8220FA3C: F94101A8  std r10, 0x1a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(424 as u32), ctx.r[10].u64 ) };
	// 8220FA40: E94100A8  ld r10, 0xa8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8220FA44: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8220FA48: 90A100C8  stw r5, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[5].u32 ) };
	// 8220FA4C: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8220FA50: 90C100D0  stw r6, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[6].u32 ) };
	// 8220FA54: F94101B0  std r10, 0x1b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), ctx.r[10].u64 ) };
	// 8220FA58: E9410098  ld r10, 0x98(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8220FA5C: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 8220FA60: 90E100D8  stw r7, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[7].u32 ) };
	// 8220FA64: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 8220FA68: 910100E0  stw r8, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[8].u32 ) };
	// 8220FA6C: F94101B8  std r10, 0x1b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), ctx.r[10].u64 ) };
	// 8220FA70: E9410088  ld r10, 0x88(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 8220FA74: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8220FA78: 912100C0  stw r9, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[9].u32 ) };
	// 8220FA7C: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8220FA80: 916100EC  stw r11, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 8220FA84: F94101C0  std r10, 0x1c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), ctx.r[10].u64 ) };
	// 8220FA88: E9410078  ld r10, 0x78(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8220FA8C: F94101C8  std r10, 0x1c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), ctx.r[10].u64 ) };
	// 8220FA90: E9410068  ld r10, 0x68(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 8220FA94: F94101D0  std r10, 0x1d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(464 as u32), ctx.r[10].u64 ) };
	// 8220FA98: E9410060  ld r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8220FA9C: F94101D8  std r10, 0x1d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(472 as u32), ctx.r[10].u64 ) };
	// 8220FAA0: E9410058  ld r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8220FAA4: F94101E0  std r10, 0x1e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(480 as u32), ctx.r[10].u64 ) };
	// 8220FAA8: E9410050  ld r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8220FAAC: F94101E8  std r10, 0x1e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), ctx.r[10].u64 ) };
	// 8220FAB0: E94100A0  ld r10, 0xa0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 8220FAB4: F94101F0  std r10, 0x1f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), ctx.r[10].u64 ) };
	// 8220FAB8: E9410080  ld r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8220FABC: F94101F8  std r10, 0x1f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(504 as u32), ctx.r[10].u64 ) };
	// 8220FAC0: E94100B0  ld r10, 0xb0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 8220FAC4: F9410200  std r10, 0x200(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(512 as u32), ctx.r[10].u64 ) };
	// 8220FAC8: E9410070  ld r10, 0x70(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8220FACC: F9410208  std r10, 0x208(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(520 as u32), ctx.r[10].u64 ) };
	// 8220FAD0: E94100C8  ld r10, 0xc8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 8220FAD4: F9410210  std r10, 0x210(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(528 as u32), ctx.r[10].u64 ) };
	// 8220FAD8: E94100D0  ld r10, 0xd0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8220FADC: F9410218  std r10, 0x218(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(536 as u32), ctx.r[10].u64 ) };
	// 8220FAE0: E94100D8  ld r10, 0xd8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 8220FAE4: F9410220  std r10, 0x220(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(544 as u32), ctx.r[10].u64 ) };
	// 8220FAE8: E94100E0  ld r10, 0xe0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8220FAEC: F9410228  std r10, 0x228(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(552 as u32), ctx.r[10].u64 ) };
	// 8220FAF0: E94100C0  ld r10, 0xc0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 8220FAF4: F9410230  std r10, 0x230(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(560 as u32), ctx.r[10].u64 ) };
	// 8220FAF8: E94100E8  ld r10, 0xe8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8220FAFC: F9410238  std r10, 0x238(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(568 as u32), ctx.r[10].u64 ) };
	// 8220FB00: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 8220FB04: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8220FB08: 3A732F80  addi r19, r19, 0x2f80
	ctx.r[19].s64 = ctx.r[19].s64 + 12160;
	// 8220FB0C: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8220FB10: 3929F508  addi r9, r9, -0xaf8
	ctx.r[9].s64 = ctx.r[9].s64 + -2808;
	// 8220FB14: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8220FB18: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8220FB1C: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8220FB20: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 8220FB24: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 8220FB28: 3EE08221  lis r23, -0x7ddf
	ctx.r[23].s64 = -2111766528;
	// 8220FB2C: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220FB30: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 8220FB34: 92610090  stw r19, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[19].u32 ) };
	// 8220FB38: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 8220FB3C: 912100E8  stw r9, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[9].u32 ) };
	// 8220FB40: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 8220FB44: E9210090  ld r9, 0x90(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8220FB48: 3F60822B  lis r27, -0x7dd5
	ctx.r[27].s64 = -2111111168;
	// 8220FB4C: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8220FB50: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 8220FB54: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220FB58: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 8220FB5C: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8220FB60: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8220FB64: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220FB68: 3FE08221  lis r31, -0x7ddf
	ctx.r[31].s64 = -2111766528;
	// 8220FB6C: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8220FB70: 3C608221  lis r3, -0x7ddf
	ctx.r[3].s64 = -2111766528;
	// 8220FB74: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8220FB78: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 8220FB7C: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8220FB80: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 8220FB84: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8220FB88: 3CC0822B  lis r6, -0x7dd5
	ctx.r[6].s64 = -2111111168;
	// 8220FB8C: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8220FB90: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 8220FB94: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 8220FB98: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 8220FB9C: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 8220FBA0: 3A94F5A8  addi r20, r20, -0xa58
	ctx.r[20].s64 = ctx.r[20].s64 + -2648;
	// 8220FBA4: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8220FBA8: 3AB5F5C8  addi r21, r21, -0xa38
	ctx.r[21].s64 = ctx.r[21].s64 + -2616;
	// 8220FBAC: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8220FBB0: 3AD6F5E8  addi r22, r22, -0xa18
	ctx.r[22].s64 = ctx.r[22].s64 + -2584;
	// 8220FBB4: 916100EC  stw r11, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 8220FBB8: 3AF7F608  addi r23, r23, -0x9f8
	ctx.r[23].s64 = ctx.r[23].s64 + -2552;
	// 8220FBBC: F9210240  std r9, 0x240(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(576 as u32), ctx.r[9].u64 ) };
	// 8220FBC0: 3B18F548  addi r24, r24, -0xab8
	ctx.r[24].s64 = ctx.r[24].s64 + -2744;
	// 8220FBC4: 3B39F628  addi r25, r25, -0x9d8
	ctx.r[25].s64 = ctx.r[25].s64 + -2520;
	// 8220FBC8: 928100B8  stw r20, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[20].u32 ) };
	// 8220FBCC: 3B5AF648  addi r26, r26, -0x9b8
	ctx.r[26].s64 = ctx.r[26].s64 + -2488;
	// 8220FBD0: 92A100A8  stw r21, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[21].u32 ) };
	// 8220FBD4: 3B7B2F80  addi r27, r27, 0x2f80
	ctx.r[27].s64 = ctx.r[27].s64 + 12160;
	// 8220FBD8: 92C10098  stw r22, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[22].u32 ) };
	// 8220FBDC: 3B9CF4C8  addi r28, r28, -0xb38
	ctx.r[28].s64 = ctx.r[28].s64 + -2872;
	// 8220FBE0: 92E10088  stw r23, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[23].u32 ) };
	// 8220FBE4: 3BBDF4E8  addi r29, r29, -0xb18
	ctx.r[29].s64 = ctx.r[29].s64 + -2840;
	// 8220FBE8: 93010078  stw r24, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[24].u32 ) };
	// 8220FBEC: 3BDEF508  addi r30, r30, -0xaf8
	ctx.r[30].s64 = ctx.r[30].s64 + -2808;
	// 8220FBF0: 93210068  stw r25, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[25].u32 ) };
	// 8220FBF4: 3BFFF528  addi r31, r31, -0xad8
	ctx.r[31].s64 = ctx.r[31].s64 + -2776;
	// 8220FBF8: 93410060  stw r26, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[26].u32 ) };
	// 8220FBFC: 3863F548  addi r3, r3, -0xab8
	ctx.r[3].s64 = ctx.r[3].s64 + -2744;
	// 8220FC00: 93610058  stw r27, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[27].u32 ) };
	// 8220FC04: 3884F568  addi r4, r4, -0xa98
	ctx.r[4].s64 = ctx.r[4].s64 + -2712;
	// 8220FC08: 93810050  stw r28, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[28].u32 ) };
	// 8220FC0C: 38A5F588  addi r5, r5, -0xa78
	ctx.r[5].s64 = ctx.r[5].s64 + -2680;
	// 8220FC10: 93A100A0  stw r29, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[29].u32 ) };
	// 8220FC14: 38C62F80  addi r6, r6, 0x2f80
	ctx.r[6].s64 = ctx.r[6].s64 + 12160;
	// 8220FC18: 93C10080  stw r30, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[30].u32 ) };
	// 8220FC1C: 38E7F4C8  addi r7, r7, -0xb38
	ctx.r[7].s64 = ctx.r[7].s64 + -2872;
	// 8220FC20: 93E100B0  stw r31, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[31].u32 ) };
	// 8220FC24: 3908F4E8  addi r8, r8, -0xb18
	ctx.r[8].s64 = ctx.r[8].s64 + -2840;
	// 8220FC28: 90610070  stw r3, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[3].u32 ) };
	// 8220FC2C: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 8220FC30: 908100C8  stw r4, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[4].u32 ) };
	// 8220FC34: 90A100D0  stw r5, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[5].u32 ) };
	// 8220FC38: 90C100D8  stw r6, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[6].u32 ) };
	// 8220FC3C: 90E100E0  stw r7, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[7].u32 ) };
	// 8220FC40: 910100C0  stw r8, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[8].u32 ) };
	// 8220FC44: E92100B8  ld r9, 0xb8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8220FC48: 3E808221  lis r20, -0x7ddf
	ctx.r[20].s64 = -2111766528;
	// 8220FC4C: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8220FC50: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8220FC54: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 8220FC58: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8220FC5C: 3EE0822B  lis r23, -0x7dd5
	ctx.r[23].s64 = -2111111168;
	// 8220FC60: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 8220FC64: F9210248  std r9, 0x248(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(584 as u32), ctx.r[9].u64 ) };
	// 8220FC68: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 8220FC6C: E92100A8  ld r9, 0xa8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8220FC70: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 8220FC74: 394AF528  addi r10, r10, -0xad8
	ctx.r[10].s64 = ctx.r[10].s64 + -2776;
	// 8220FC78: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8220FC7C: 3A94F548  addi r20, r20, -0xab8
	ctx.r[20].s64 = ctx.r[20].s64 + -2744;
	// 8220FC80: 3AB5F568  addi r21, r21, -0xa98
	ctx.r[21].s64 = ctx.r[21].s64 + -2712;
	// 8220FC84: 3AD6F588  addi r22, r22, -0xa78
	ctx.r[22].s64 = ctx.r[22].s64 + -2680;
	// 8220FC88: F9210250  std r9, 0x250(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(592 as u32), ctx.r[9].u64 ) };
	// 8220FC8C: 3AF72F80  addi r23, r23, 0x2f80
	ctx.r[23].s64 = ctx.r[23].s64 + 12160;
	// 8220FC90: E9210098  ld r9, 0x98(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8220FC94: 3B18F5A8  addi r24, r24, -0xa58
	ctx.r[24].s64 = ctx.r[24].s64 + -2648;
	// 8220FC98: 3B39F5C8  addi r25, r25, -0xa38
	ctx.r[25].s64 = ctx.r[25].s64 + -2616;
	// 8220FC9C: 91410090  stw r10, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[10].u32 ) };
	// 8220FCA0: 3B5AF5E8  addi r26, r26, -0xa18
	ctx.r[26].s64 = ctx.r[26].s64 + -2584;
	// 8220FCA4: 928100B8  stw r20, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[20].u32 ) };
	// 8220FCA8: 3F608221  lis r27, -0x7ddf
	ctx.r[27].s64 = -2111766528;
	// 8220FCAC: 92A100A8  stw r21, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[21].u32 ) };
	// 8220FCB0: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 8220FCB4: 92C10098  stw r22, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[22].u32 ) };
	// 8220FCB8: F9210258  std r9, 0x258(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(600 as u32), ctx.r[9].u64 ) };
	// 8220FCBC: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 8220FCC0: E9210088  ld r9, 0x88(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 8220FCC4: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8220FCC8: 3FE0822B  lis r31, -0x7dd5
	ctx.r[31].s64 = -2111111168;
	// 8220FCCC: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8220FCD0: 3C608221  lis r3, -0x7ddf
	ctx.r[3].s64 = -2111766528;
	// 8220FCD4: 92E10088  stw r23, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[23].u32 ) };
	// 8220FCD8: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 8220FCDC: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 8220FCE0: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 8220FCE4: F9210260  std r9, 0x260(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(608 as u32), ctx.r[9].u64 ) };
	// 8220FCE8: 3CC08221  lis r6, -0x7ddf
	ctx.r[6].s64 = -2111766528;
	// 8220FCEC: E9210078  ld r9, 0x78(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8220FCF0: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 8220FCF4: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 8220FCF8: 93010078  stw r24, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[24].u32 ) };
	// 8220FCFC: 3D40822B  lis r10, -0x7dd5
	ctx.r[10].s64 = -2111111168;
	// 8220FD00: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220FD04: F9210268  std r9, 0x268(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(616 as u32), ctx.r[9].u64 ) };
	// 8220FD08: E9210068  ld r9, 0x68(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 8220FD0C: 93210068  stw r25, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[25].u32 ) };
	// 8220FD10: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8220FD14: F9210270  std r9, 0x270(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(624 as u32), ctx.r[9].u64 ) };
	// 8220FD18: E9210060  ld r9, 0x60(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8220FD1C: 93410060  stw r26, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[26].u32 ) };
	// 8220FD20: F9210278  std r9, 0x278(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(632 as u32), ctx.r[9].u64 ) };
	// 8220FD24: E9210058  ld r9, 0x58(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8220FD28: F9210280  std r9, 0x280(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(640 as u32), ctx.r[9].u64 ) };
	// 8220FD2C: E9210050  ld r9, 0x50(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8220FD30: F9210288  std r9, 0x288(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(648 as u32), ctx.r[9].u64 ) };
	// 8220FD34: E92100A0  ld r9, 0xa0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 8220FD38: F9210290  std r9, 0x290(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(656 as u32), ctx.r[9].u64 ) };
	// 8220FD3C: E9210080  ld r9, 0x80(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8220FD40: F9210298  std r9, 0x298(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(664 as u32), ctx.r[9].u64 ) };
	// 8220FD44: E92100B0  ld r9, 0xb0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 8220FD48: F92102A0  std r9, 0x2a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(672 as u32), ctx.r[9].u64 ) };
	// 8220FD4C: E9210070  ld r9, 0x70(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8220FD50: F92102A8  std r9, 0x2a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(680 as u32), ctx.r[9].u64 ) };
	// 8220FD54: E92100C8  ld r9, 0xc8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 8220FD58: F92102B0  std r9, 0x2b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(688 as u32), ctx.r[9].u64 ) };
	// 8220FD5C: E92100D0  ld r9, 0xd0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8220FD60: F92102B8  std r9, 0x2b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(696 as u32), ctx.r[9].u64 ) };
	// 8220FD64: E92100D8  ld r9, 0xd8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 8220FD68: F92102C0  std r9, 0x2c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(704 as u32), ctx.r[9].u64 ) };
	// 8220FD6C: E92100E0  ld r9, 0xe0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8220FD70: F92102C8  std r9, 0x2c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(712 as u32), ctx.r[9].u64 ) };
	// 8220FD74: E92100C0  ld r9, 0xc0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 8220FD78: F92102D0  std r9, 0x2d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(720 as u32), ctx.r[9].u64 ) };
	// 8220FD7C: E92100E8  ld r9, 0xe8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8220FD80: F92102D8  std r9, 0x2d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(728 as u32), ctx.r[9].u64 ) };
	// 8220FD84: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 8220FD88: 3929F588  addi r9, r9, -0xa78
	ctx.r[9].s64 = ctx.r[9].s64 + -2680;
	// 8220FD8C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220FD90: 3B7BF608  addi r27, r27, -0x9f8
	ctx.r[27].s64 = ctx.r[27].s64 + -2552;
	// 8220FD94: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8220FD98: 3B9CF548  addi r28, r28, -0xab8
	ctx.r[28].s64 = ctx.r[28].s64 + -2744;
	// 8220FD9C: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220FDA0: 3BBDF628  addi r29, r29, -0x9d8
	ctx.r[29].s64 = ctx.r[29].s64 + -2520;
	// 8220FDA4: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8220FDA8: 3BDEF648  addi r30, r30, -0x9b8
	ctx.r[30].s64 = ctx.r[30].s64 + -2488;
	// 8220FDAC: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8220FDB0: 912100E8  stw r9, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[9].u32 ) };
	// 8220FDB4: 3BFF2F80  addi r31, r31, 0x2f80
	ctx.r[31].s64 = ctx.r[31].s64 + 12160;
	// 8220FDB8: E9210090  ld r9, 0x90(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8220FDBC: 3863F4C8  addi r3, r3, -0xb38
	ctx.r[3].s64 = ctx.r[3].s64 + -2872;
	// 8220FDC0: 93610058  stw r27, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[27].u32 ) };
	// 8220FDC4: 3884F4E8  addi r4, r4, -0xb18
	ctx.r[4].s64 = ctx.r[4].s64 + -2840;
	// 8220FDC8: 93810050  stw r28, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[28].u32 ) };
	// 8220FDCC: 38A5F508  addi r5, r5, -0xaf8
	ctx.r[5].s64 = ctx.r[5].s64 + -2808;
	// 8220FDD0: 93A100A0  stw r29, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[29].u32 ) };
	// 8220FDD4: 38C6F528  addi r6, r6, -0xad8
	ctx.r[6].s64 = ctx.r[6].s64 + -2776;
	// 8220FDD8: 93C10080  stw r30, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[30].u32 ) };
	// 8220FDDC: 38E7F548  addi r7, r7, -0xab8
	ctx.r[7].s64 = ctx.r[7].s64 + -2744;
	// 8220FDE0: F92102E0  std r9, 0x2e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(736 as u32), ctx.r[9].u64 ) };
	// 8220FDE4: 3908F568  addi r8, r8, -0xa98
	ctx.r[8].s64 = ctx.r[8].s64 + -2712;
	// 8220FDE8: E92100B8  ld r9, 0xb8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8220FDEC: 394A2F80  addi r10, r10, 0x2f80
	ctx.r[10].s64 = ctx.r[10].s64 + 12160;
	// 8220FDF0: 93E100B0  stw r31, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[31].u32 ) };
	// 8220FDF4: 3E808221  lis r20, -0x7ddf
	ctx.r[20].s64 = -2111766528;
	// 8220FDF8: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8220FDFC: 90610070  stw r3, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[3].u32 ) };
	// 8220FE00: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8220FE04: F92102E8  std r9, 0x2e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(744 as u32), ctx.r[9].u64 ) };
	// 8220FE08: E92100A8  ld r9, 0xa8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8220FE0C: 908100C8  stw r4, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[4].u32 ) };
	// 8220FE10: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8220FE14: 90A100D0  stw r5, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[5].u32 ) };
	// 8220FE18: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 8220FE1C: F92102F0  std r9, 0x2f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(752 as u32), ctx.r[9].u64 ) };
	// 8220FE20: E9210098  ld r9, 0x98(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8220FE24: 90C100D8  stw r6, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[6].u32 ) };
	// 8220FE28: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 8220FE2C: 90E100E0  stw r7, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[7].u32 ) };
	// 8220FE30: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8220FE34: F92102F8  std r9, 0x2f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(760 as u32), ctx.r[9].u64 ) };
	// 8220FE38: E9210088  ld r9, 0x88(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 8220FE3C: 910100C0  stw r8, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[8].u32 ) };
	// 8220FE40: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8220FE44: 916100EC  stw r11, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 8220FE48: 91410090  stw r10, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[10].u32 ) };
	// 8220FE4C: F9210300  std r9, 0x300(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(768 as u32), ctx.r[9].u64 ) };
	// 8220FE50: E9210078  ld r9, 0x78(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8220FE54: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8220FE58: F9210308  std r9, 0x308(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(776 as u32), ctx.r[9].u64 ) };
	// 8220FE5C: E9210068  ld r9, 0x68(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 8220FE60: F9210310  std r9, 0x310(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(784 as u32), ctx.r[9].u64 ) };
	// 8220FE64: E9210060  ld r9, 0x60(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8220FE68: F9210318  std r9, 0x318(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(792 as u32), ctx.r[9].u64 ) };
	// 8220FE6C: E9210058  ld r9, 0x58(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8220FE70: F9210320  std r9, 0x320(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(800 as u32), ctx.r[9].u64 ) };
	// 8220FE74: E9210050  ld r9, 0x50(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8220FE78: F9210328  std r9, 0x328(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(808 as u32), ctx.r[9].u64 ) };
	// 8220FE7C: E92100A0  ld r9, 0xa0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 8220FE80: F9210330  std r9, 0x330(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(816 as u32), ctx.r[9].u64 ) };
	// 8220FE84: E9210080  ld r9, 0x80(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8220FE88: F9210338  std r9, 0x338(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(824 as u32), ctx.r[9].u64 ) };
	// 8220FE8C: E92100B0  ld r9, 0xb0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 8220FE90: F9210340  std r9, 0x340(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(832 as u32), ctx.r[9].u64 ) };
	// 8220FE94: E9210070  ld r9, 0x70(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8220FE98: F9210348  std r9, 0x348(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(840 as u32), ctx.r[9].u64 ) };
	// 8220FE9C: E92100C8  ld r9, 0xc8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 8220FEA0: F9210350  std r9, 0x350(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(848 as u32), ctx.r[9].u64 ) };
	// 8220FEA4: E92100D0  ld r9, 0xd0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8220FEA8: F9210358  std r9, 0x358(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(856 as u32), ctx.r[9].u64 ) };
	// 8220FEAC: E92100D8  ld r9, 0xd8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 8220FEB0: F9210360  std r9, 0x360(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(864 as u32), ctx.r[9].u64 ) };
	// 8220FEB4: E92100E0  ld r9, 0xe0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8220FEB8: F9210368  std r9, 0x368(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(872 as u32), ctx.r[9].u64 ) };
	// 8220FEBC: E92100C0  ld r9, 0xc0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 8220FEC0: F9210370  std r9, 0x370(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(880 as u32), ctx.r[9].u64 ) };
	// 8220FEC4: E92100E8  ld r9, 0xe8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8220FEC8: F9210378  std r9, 0x378(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(888 as u32), ctx.r[9].u64 ) };
	// 8220FECC: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 8220FED0: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8220FED4: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8220FED8: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8220FEDC: 394AF528  addi r10, r10, -0xad8
	ctx.r[10].s64 = ctx.r[10].s64 + -2776;
	// 8220FEE0: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8220FEE4: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 8220FEE8: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 8220FEEC: 3EE08221  lis r23, -0x7ddf
	ctx.r[23].s64 = -2111766528;
	// 8220FEF0: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8220FEF4: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 8220FEF8: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8220FEFC: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 8220FF00: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8220FF04: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 8220FF08: 914100F0  stw r10, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[10].u32 ) };
	// 8220FF0C: 3F60822B  lis r27, -0x7dd5
	ctx.r[27].s64 = -2111111168;
	// 8220FF10: E9410090  ld r10, 0x90(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8220FF14: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 8220FF18: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8220FF1C: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 8220FF20: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8220FF24: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8220FF28: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8220FF2C: 3FE08221  lis r31, -0x7ddf
	ctx.r[31].s64 = -2111766528;
	// 8220FF30: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8220FF34: 3C608221  lis r3, -0x7ddf
	ctx.r[3].s64 = -2111766528;
	// 8220FF38: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8220FF3C: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 8220FF40: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8220FF44: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 8220FF48: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8220FF4C: 3CC0822B  lis r6, -0x7dd5
	ctx.r[6].s64 = -2111111168;
	// 8220FF50: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 8220FF54: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 8220FF58: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 8220FF5C: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 8220FF60: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8220FF64: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 8220FF68: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8220FF6C: 3A94F4C8  addi r20, r20, -0xb38
	ctx.r[20].s64 = ctx.r[20].s64 + -2872;
	// 8220FF70: 916100EC  stw r11, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[11].u32 ) };
	// 8220FF74: 3AB5F4E8  addi r21, r21, -0xb18
	ctx.r[21].s64 = ctx.r[21].s64 + -2840;
	// 8220FF78: 916100F4  stw r11, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[11].u32 ) };
	// 8220FF7C: 3AD6F508  addi r22, r22, -0xaf8
	ctx.r[22].s64 = ctx.r[22].s64 + -2808;
	// 8220FF80: F9410380  std r10, 0x380(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(896 as u32), ctx.r[10].u64 ) };
	// 8220FF84: 3AF7F528  addi r23, r23, -0xad8
	ctx.r[23].s64 = ctx.r[23].s64 + -2776;
	// 8220FF88: 3B18F548  addi r24, r24, -0xab8
	ctx.r[24].s64 = ctx.r[24].s64 + -2744;
	// 8220FF8C: 3B39F568  addi r25, r25, -0xa98
	ctx.r[25].s64 = ctx.r[25].s64 + -2712;
	// 8220FF90: 928100B8  stw r20, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[20].u32 ) };
	// 8220FF94: 3B5AF588  addi r26, r26, -0xa78
	ctx.r[26].s64 = ctx.r[26].s64 + -2680;
	// 8220FF98: 92A100A8  stw r21, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[21].u32 ) };
	// 8220FF9C: 3B7B2F80  addi r27, r27, 0x2f80
	ctx.r[27].s64 = ctx.r[27].s64 + 12160;
	// 8220FFA0: 92C10098  stw r22, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[22].u32 ) };
	// 8220FFA4: 3B9CF4C8  addi r28, r28, -0xb38
	ctx.r[28].s64 = ctx.r[28].s64 + -2872;
	// 8220FFA8: 92E10088  stw r23, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[23].u32 ) };
	// 8220FFAC: 3BBDF4E8  addi r29, r29, -0xb18
	ctx.r[29].s64 = ctx.r[29].s64 + -2840;
	// 8220FFB0: 93010078  stw r24, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[24].u32 ) };
	// 8220FFB4: 3BDEF508  addi r30, r30, -0xaf8
	ctx.r[30].s64 = ctx.r[30].s64 + -2808;
	// 8220FFB8: 93210068  stw r25, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[25].u32 ) };
	// 8220FFBC: 3BFFF528  addi r31, r31, -0xad8
	ctx.r[31].s64 = ctx.r[31].s64 + -2776;
	// 8220FFC0: 93410060  stw r26, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[26].u32 ) };
	// 8220FFC4: 3863F548  addi r3, r3, -0xab8
	ctx.r[3].s64 = ctx.r[3].s64 + -2744;
	// 8220FFC8: 93610058  stw r27, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[27].u32 ) };
	// 8220FFCC: 3884F568  addi r4, r4, -0xa98
	ctx.r[4].s64 = ctx.r[4].s64 + -2712;
	// 8220FFD0: 93810050  stw r28, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[28].u32 ) };
	// 8220FFD4: 38A5F588  addi r5, r5, -0xa78
	ctx.r[5].s64 = ctx.r[5].s64 + -2680;
	// 8220FFD8: 93A100A0  stw r29, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[29].u32 ) };
	// 8220FFDC: 38C62F80  addi r6, r6, 0x2f80
	ctx.r[6].s64 = ctx.r[6].s64 + 12160;
	// 8220FFE0: 93C10080  stw r30, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[30].u32 ) };
	// 8220FFE4: 38E7F4C8  addi r7, r7, -0xb38
	ctx.r[7].s64 = ctx.r[7].s64 + -2872;
	// 8220FFE8: 93E100B0  stw r31, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[31].u32 ) };
	// 8220FFEC: 3908F4E8  addi r8, r8, -0xb18
	ctx.r[8].s64 = ctx.r[8].s64 + -2840;
	// 8220FFF0: 90610070  stw r3, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[3].u32 ) };
	// 8220FFF4: 3929F508  addi r9, r9, -0xaf8
	ctx.r[9].s64 = ctx.r[9].s64 + -2808;
	// 8220FFF8: 908100C8  stw r4, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[4].u32 ) };
	// 8220FFFC: 90A100D0  stw r5, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[5].u32 ) };
	// 82210000: 90C100D8  stw r6, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[6].u32 ) };
	// 82210004: 90E100E0  stw r7, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[7].u32 ) };
	// 82210008: 910100C0  stw r8, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[8].u32 ) };
	// 8221000C: 912100E8  stw r9, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[9].u32 ) };
	// 82210010: E94100B8  ld r10, 0xb8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 82210014: 3E808221  lis r20, -0x7ddf
	ctx.r[20].s64 = -2111766528;
	// 82210018: 3EA08221  lis r21, -0x7ddf
	ctx.r[21].s64 = -2111766528;
	// 8221001C: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 82210020: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 82210024: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 82210028: 3EE0822B  lis r23, -0x7dd5
	ctx.r[23].s64 = -2111111168;
	// 8221002C: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 82210030: F9410388  std r10, 0x388(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(904 as u32), ctx.r[10].u64 ) };
	// 82210034: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 82210038: E94100A8  ld r10, 0xa8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8221003C: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 82210040: 3A94F548  addi r20, r20, -0xab8
	ctx.r[20].s64 = ctx.r[20].s64 + -2744;
	// 82210044: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 82210048: 3AB5F568  addi r21, r21, -0xa98
	ctx.r[21].s64 = ctx.r[21].s64 + -2712;
	// 8221004C: 3AD6F588  addi r22, r22, -0xa78
	ctx.r[22].s64 = ctx.r[22].s64 + -2680;
	// 82210050: 3AF72F80  addi r23, r23, 0x2f80
	ctx.r[23].s64 = ctx.r[23].s64 + 12160;
	// 82210054: F9410390  std r10, 0x390(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(912 as u32), ctx.r[10].u64 ) };
	// 82210058: 3B18F4C8  addi r24, r24, -0xb38
	ctx.r[24].s64 = ctx.r[24].s64 + -2872;
	// 8221005C: E9410098  ld r10, 0x98(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 82210060: 3B39F4E8  addi r25, r25, -0xb18
	ctx.r[25].s64 = ctx.r[25].s64 + -2840;
	// 82210064: 3B5AF508  addi r26, r26, -0xaf8
	ctx.r[26].s64 = ctx.r[26].s64 + -2808;
	// 82210068: 92A10090  stw r21, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[21].u32 ) };
	// 8221006C: 3F608221  lis r27, -0x7ddf
	ctx.r[27].s64 = -2111766528;
	// 82210070: 92C100B8  stw r22, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[22].u32 ) };
	// 82210074: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 82210078: 92E100A8  stw r23, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[23].u32 ) };
	// 8221007C: 3FA08221  lis r29, -0x7ddf
	ctx.r[29].s64 = -2111766528;
	// 82210080: 93010098  stw r24, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[24].u32 ) };
	// 82210084: F9410398  std r10, 0x398(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(920 as u32), ctx.r[10].u64 ) };
	// 82210088: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 8221008C: E9410088  ld r10, 0x88(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 82210090: 3FE0822B  lis r31, -0x7dd5
	ctx.r[31].s64 = -2111111168;
	// 82210094: 3C608221  lis r3, -0x7ddf
	ctx.r[3].s64 = -2111766528;
	// 82210098: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 8221009C: 3C808221  lis r4, -0x7ddf
	ctx.r[4].s64 = -2111766528;
	// 822100A0: 93210088  stw r25, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[25].u32 ) };
	// 822100A4: 3CA08221  lis r5, -0x7ddf
	ctx.r[5].s64 = -2111766528;
	// 822100A8: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 822100AC: 3CC08221  lis r6, -0x7ddf
	ctx.r[6].s64 = -2111766528;
	// 822100B0: F94103A0  std r10, 0x3a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(928 as u32), ctx.r[10].u64 ) };
	// 822100B4: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 822100B8: E9410078  ld r10, 0x78(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 822100BC: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 822100C0: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 822100C4: 93410078  stw r26, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[26].u32 ) };
	// 822100C8: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 822100CC: F94103A8  std r10, 0x3a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(936 as u32), ctx.r[10].u64 ) };
	// 822100D0: E9410068  ld r10, 0x68(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 822100D4: F94103B0  std r10, 0x3b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(944 as u32), ctx.r[10].u64 ) };
	// 822100D8: E9410060  ld r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 822100DC: F94103B8  std r10, 0x3b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(952 as u32), ctx.r[10].u64 ) };
	// 822100E0: E9410058  ld r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 822100E4: F94103C0  std r10, 0x3c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(960 as u32), ctx.r[10].u64 ) };
	// 822100E8: E9410050  ld r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 822100EC: F94103C8  std r10, 0x3c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(968 as u32), ctx.r[10].u64 ) };
	// 822100F0: E94100A0  ld r10, 0xa0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 822100F4: F94103D0  std r10, 0x3d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(976 as u32), ctx.r[10].u64 ) };
	// 822100F8: E9410080  ld r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 822100FC: F94103D8  std r10, 0x3d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(984 as u32), ctx.r[10].u64 ) };
	// 82210100: E94100B0  ld r10, 0xb0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 82210104: F94103E0  std r10, 0x3e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(992 as u32), ctx.r[10].u64 ) };
	// 82210108: E9410070  ld r10, 0x70(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8221010C: F94103E8  std r10, 0x3e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1000 as u32), ctx.r[10].u64 ) };
	// 82210110: E94100C8  ld r10, 0xc8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 82210114: F94103F0  std r10, 0x3f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1008 as u32), ctx.r[10].u64 ) };
	// 82210118: E94100D0  ld r10, 0xd0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8221011C: F94103F8  std r10, 0x3f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1016 as u32), ctx.r[10].u64 ) };
	// 82210120: E94100D8  ld r10, 0xd8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 82210124: F9410400  std r10, 0x400(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1024 as u32), ctx.r[10].u64 ) };
	// 82210128: E94100E0  ld r10, 0xe0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8221012C: F9410408  std r10, 0x408(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1032 as u32), ctx.r[10].u64 ) };
	// 82210130: E94100C0  ld r10, 0xc0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 82210134: F9410410  std r10, 0x410(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1040 as u32), ctx.r[10].u64 ) };
	// 82210138: E94100E8  ld r10, 0xe8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8221013C: F9410418  std r10, 0x418(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1048 as u32), ctx.r[10].u64 ) };
	// 82210140: E94100F0  ld r10, 0xf0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	// 82210144: 928100F0  stw r20, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[20].u32 ) };
	// 82210148: 916100F4  stw r11, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[11].u32 ) };
	// 8221014C: F9410420  std r10, 0x420(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1056 as u32), ctx.r[10].u64 ) };
	// 82210150: 3D40822B  lis r10, -0x7dd5
	ctx.r[10].s64 = -2111111168;
	// 82210154: 394A2F80  addi r10, r10, 0x2f80
	ctx.r[10].s64 = ctx.r[10].s64 + 12160;
	// 82210158: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8221015C: 3B7BF528  addi r27, r27, -0xad8
	ctx.r[27].s64 = ctx.r[27].s64 + -2776;
	// 82210160: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 82210164: 3B9CF548  addi r28, r28, -0xab8
	ctx.r[28].s64 = ctx.r[28].s64 + -2744;
	// 82210168: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8221016C: 3BBDF568  addi r29, r29, -0xa98
	ctx.r[29].s64 = ctx.r[29].s64 + -2712;
	// 82210170: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82210174: 3BDEF588  addi r30, r30, -0xa78
	ctx.r[30].s64 = ctx.r[30].s64 + -2680;
	// 82210178: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8221017C: 914100C0  stw r10, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[10].u32 ) };
	// 82210180: 3BFF2F80  addi r31, r31, 0x2f80
	ctx.r[31].s64 = ctx.r[31].s64 + 12160;
	// 82210184: E94100F0  ld r10, 0xf0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	// 82210188: 3863F4C8  addi r3, r3, -0xb38
	ctx.r[3].s64 = ctx.r[3].s64 + -2872;
	// 8221018C: 93610068  stw r27, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[27].u32 ) };
	// 82210190: 3884F4E8  addi r4, r4, -0xb18
	ctx.r[4].s64 = ctx.r[4].s64 + -2840;
	// 82210194: 93810060  stw r28, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[28].u32 ) };
	// 82210198: 38A5F508  addi r5, r5, -0xaf8
	ctx.r[5].s64 = ctx.r[5].s64 + -2808;
	// 8221019C: 93A10058  stw r29, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[29].u32 ) };
	// 822101A0: 38C6F528  addi r6, r6, -0xad8
	ctx.r[6].s64 = ctx.r[6].s64 + -2776;
	// 822101A4: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 822101A8: 38E7F548  addi r7, r7, -0xab8
	ctx.r[7].s64 = ctx.r[7].s64 + -2744;
	// 822101AC: F9410428  std r10, 0x428(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1064 as u32), ctx.r[10].u64 ) };
	// 822101B0: 3908F568  addi r8, r8, -0xa98
	ctx.r[8].s64 = ctx.r[8].s64 + -2712;
	// 822101B4: E9410090  ld r10, 0x90(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 822101B8: 3929F588  addi r9, r9, -0xa78
	ctx.r[9].s64 = ctx.r[9].s64 + -2680;
	// 822101BC: 93E100A0  stw r31, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[31].u32 ) };
	// 822101C0: 3EC08221  lis r22, -0x7ddf
	ctx.r[22].s64 = -2111766528;
	// 822101C4: 90610080  stw r3, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[3].u32 ) };
	// 822101C8: 3EE08221  lis r23, -0x7ddf
	ctx.r[23].s64 = -2111766528;
	// 822101CC: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 822101D0: 908100B0  stw r4, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[4].u32 ) };
	// 822101D4: F9410430  std r10, 0x430(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1072 as u32), ctx.r[10].u64 ) };
	// 822101D8: E94100B8  ld r10, 0xb8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 822101DC: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 822101E0: 90A10070  stw r5, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[5].u32 ) };
	// 822101E4: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 822101E8: 90C100C8  stw r6, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[6].u32 ) };
	// 822101EC: F9410438  std r10, 0x438(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1080 as u32), ctx.r[10].u64 ) };
	// 822101F0: E94100A8  ld r10, 0xa8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 822101F4: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 822101F8: 90E100D0  stw r7, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[7].u32 ) };
	// 822101FC: 916100D4  stw r11, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[11].u32 ) };
	// 82210200: 910100D8  stw r8, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[8].u32 ) };
	// 82210204: F9410440  std r10, 0x440(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1088 as u32), ctx.r[10].u64 ) };
	// 82210208: E9410098  ld r10, 0x98(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8221020C: 916100DC  stw r11, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[11].u32 ) };
	// 82210210: 912100E0  stw r9, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[9].u32 ) };
	// 82210214: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 82210218: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8221021C: F9410448  std r10, 0x448(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1096 as u32), ctx.r[10].u64 ) };
	// 82210220: E9410088  ld r10, 0x88(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 82210224: F9410450  std r10, 0x450(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1104 as u32), ctx.r[10].u64 ) };
	// 82210228: E9410078  ld r10, 0x78(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8221022C: F9410458  std r10, 0x458(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1112 as u32), ctx.r[10].u64 ) };
	// 82210230: E9410068  ld r10, 0x68(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 82210234: F9410460  std r10, 0x460(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1120 as u32), ctx.r[10].u64 ) };
	// 82210238: E9410060  ld r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 8221023C: F9410468  std r10, 0x468(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1128 as u32), ctx.r[10].u64 ) };
	// 82210240: E9410058  ld r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82210244: F9410470  std r10, 0x470(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1136 as u32), ctx.r[10].u64 ) };
	// 82210248: E9410050  ld r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8221024C: F9410478  std r10, 0x478(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1144 as u32), ctx.r[10].u64 ) };
	// 82210250: E94100A0  ld r10, 0xa0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 82210254: F9410480  std r10, 0x480(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1152 as u32), ctx.r[10].u64 ) };
	// 82210258: E9410080  ld r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8221025C: F9410488  std r10, 0x488(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1160 as u32), ctx.r[10].u64 ) };
	// 82210260: E94100B0  ld r10, 0xb0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 82210264: F9410490  std r10, 0x490(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1168 as u32), ctx.r[10].u64 ) };
	// 82210268: E9410070  ld r10, 0x70(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8221026C: F9410498  std r10, 0x498(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1176 as u32), ctx.r[10].u64 ) };
	// 82210270: E94100C8  ld r10, 0xc8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 82210274: F94104A0  std r10, 0x4a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1184 as u32), ctx.r[10].u64 ) };
	// 82210278: E94100D0  ld r10, 0xd0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8221027C: F94104A8  std r10, 0x4a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1192 as u32), ctx.r[10].u64 ) };
	// 82210280: E94100D8  ld r10, 0xd8(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 82210284: F94104B0  std r10, 0x4b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1200 as u32), ctx.r[10].u64 ) };
	// 82210288: E94100E0  ld r10, 0xe0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8221028C: F94104B8  std r10, 0x4b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1208 as u32), ctx.r[10].u64 ) };
	// 82210290: E94100C0  ld r10, 0xc0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 82210294: F94104C0  std r10, 0x4c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1216 as u32), ctx.r[10].u64 ) };
	// 82210298: 3AD6F4C8  addi r22, r22, -0xb38
	ctx.r[22].s64 = ctx.r[22].s64 + -2872;
	// 8221029C: 916100F4  stw r11, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[11].u32 ) };
	// 822102A0: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 822102A4: 3AF7F4E8  addi r23, r23, -0xb18
	ctx.r[23].s64 = ctx.r[23].s64 + -2840;
	// 822102A8: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 822102AC: 3F008221  lis r24, -0x7ddf
	ctx.r[24].s64 = -2111766528;
	// 822102B0: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 822102B4: 3F208221  lis r25, -0x7ddf
	ctx.r[25].s64 = -2111766528;
	// 822102B8: 9161009C  stw r11, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[11].u32 ) };
	// 822102BC: 3B18F508  addi r24, r24, -0xaf8
	ctx.r[24].s64 = ctx.r[24].s64 + -2808;
	// 822102C0: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 822102C4: 3B39F528  addi r25, r25, -0xad8
	ctx.r[25].s64 = ctx.r[25].s64 + -2776;
	// 822102C8: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 822102CC: 3F408221  lis r26, -0x7ddf
	ctx.r[26].s64 = -2111766528;
	// 822102D0: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 822102D4: 3F608221  lis r27, -0x7ddf
	ctx.r[27].s64 = -2111766528;
	// 822102D8: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 822102DC: 3B5AF548  addi r26, r26, -0xab8
	ctx.r[26].s64 = ctx.r[26].s64 + -2744;
	// 822102E0: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 822102E4: 3B7BF568  addi r27, r27, -0xa98
	ctx.r[27].s64 = ctx.r[27].s64 + -2712;
	// 822102E8: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 822102EC: 3F808221  lis r28, -0x7ddf
	ctx.r[28].s64 = -2111766528;
	// 822102F0: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 822102F4: 3FA0822B  lis r29, -0x7dd5
	ctx.r[29].s64 = -2111111168;
	// 822102F8: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 822102FC: 3B9CF588  addi r28, r28, -0xa78
	ctx.r[28].s64 = ctx.r[28].s64 + -2680;
	// 82210300: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 82210304: 3BBD2F80  addi r29, r29, 0x2f80
	ctx.r[29].s64 = ctx.r[29].s64 + 12160;
	// 82210308: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8221030C: 3FC08221  lis r30, -0x7ddf
	ctx.r[30].s64 = -2111766528;
	// 82210310: 92C100F0  stw r22, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[22].u32 ) };
	// 82210314: 3FE08221  lis r31, -0x7ddf
	ctx.r[31].s64 = -2111766528;
	// 82210318: E96100F0  ld r11, 0xf0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	// 8221031C: 3BDEF4C8  addi r30, r30, -0xb38
	ctx.r[30].s64 = ctx.r[30].s64 + -2872;
	// 82210320: 92E10090  stw r23, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[23].u32 ) };
	// 82210324: 3BFFF4E8  addi r31, r31, -0xb18
	ctx.r[31].s64 = ctx.r[31].s64 + -2840;
	// 82210328: 930100B8  stw r24, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[24].u32 ) };
	// 8221032C: 3CC08221  lis r6, -0x7ddf
	ctx.r[6].s64 = -2111766528;
	// 82210330: 932100A8  stw r25, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[25].u32 ) };
	// 82210334: 3CE08221  lis r7, -0x7ddf
	ctx.r[7].s64 = -2111766528;
	// 82210338: 93410098  stw r26, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[26].u32 ) };
	// 8221033C: 3D008221  lis r8, -0x7ddf
	ctx.r[8].s64 = -2111766528;
	// 82210340: F96104C8  std r11, 0x4c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1224 as u32), ctx.r[11].u64 ) };
	// 82210344: 3D208221  lis r9, -0x7ddf
	ctx.r[9].s64 = -2111766528;
	// 82210348: E9610090  ld r11, 0x90(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8221034C: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 82210350: 93610088  stw r27, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[27].u32 ) };
	// 82210354: 38C6F508  addi r6, r6, -0xaf8
	ctx.r[6].s64 = ctx.r[6].s64 + -2808;
	// 82210358: 93810078  stw r28, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[28].u32 ) };
	// 8221035C: 38E7F528  addi r7, r7, -0xad8
	ctx.r[7].s64 = ctx.r[7].s64 + -2776;
	// 82210360: 93A10068  stw r29, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[29].u32 ) };
	// 82210364: 3908F548  addi r8, r8, -0xab8
	ctx.r[8].s64 = ctx.r[8].s64 + -2744;
	// 82210368: 93C10060  stw r30, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u32 ) };
	// 8221036C: 3929F568  addi r9, r9, -0xa98
	ctx.r[9].s64 = ctx.r[9].s64 + -2712;
	// 82210370: F96104D0  std r11, 0x4d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1232 as u32), ctx.r[11].u64 ) };
	// 82210374: 394AF588  addi r10, r10, -0xa78
	ctx.r[10].s64 = ctx.r[10].s64 + -2680;
	// 82210378: E96100B8  ld r11, 0xb8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8221037C: 38A00B40  li r5, 0xb40
	ctx.r[5].s64 = 2880;
	// 82210380: 93E10058  stw r31, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[31].u32 ) };
	// 82210384: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82210388: 38610540  addi r3, r1, 0x540
	ctx.r[3].s64 = ctx.r[1].s64 + 1344;
	// 8221038C: 90C10050  stw r6, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[6].u32 ) };
	// 82210390: 90E100A0  stw r7, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[7].u32 ) };
	// 82210394: 91010080  stw r8, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[8].u32 ) };
	// 82210398: F96104D8  std r11, 0x4d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1240 as u32), ctx.r[11].u64 ) };
	// 8221039C: E96100A8  ld r11, 0xa8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 822103A0: 912100B0  stw r9, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[9].u32 ) };
	// 822103A4: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 822103A8: F96104E0  std r11, 0x4e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1248 as u32), ctx.r[11].u64 ) };
	// 822103AC: E9610098  ld r11, 0x98(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 822103B0: F96104E8  std r11, 0x4e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1256 as u32), ctx.r[11].u64 ) };
	// 822103B4: E9610088  ld r11, 0x88(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 822103B8: F96104F0  std r11, 0x4f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1264 as u32), ctx.r[11].u64 ) };
	// 822103BC: E9610078  ld r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 822103C0: F96104F8  std r11, 0x4f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1272 as u32), ctx.r[11].u64 ) };
	// 822103C4: E9610068  ld r11, 0x68(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 822103C8: F9610500  std r11, 0x500(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1280 as u32), ctx.r[11].u64 ) };
	// 822103CC: E9610060  ld r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 822103D0: F9610508  std r11, 0x508(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1288 as u32), ctx.r[11].u64 ) };
	// 822103D4: E9610058  ld r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 822103D8: F9610510  std r11, 0x510(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1296 as u32), ctx.r[11].u64 ) };
	// 822103DC: E9610050  ld r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 822103E0: F9610518  std r11, 0x518(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1304 as u32), ctx.r[11].u64 ) };
	// 822103E4: E96100A0  ld r11, 0xa0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 822103E8: F9610520  std r11, 0x520(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1312 as u32), ctx.r[11].u64 ) };
	// 822103EC: E9610080  ld r11, 0x80(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 822103F0: F9610528  std r11, 0x528(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1320 as u32), ctx.r[11].u64 ) };
	// 822103F4: E96100B0  ld r11, 0xb0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 822103F8: F9610530  std r11, 0x530(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1328 as u32), ctx.r[11].u64 ) };
	// 822103FC: E9610070  ld r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 82210400: F9610538  std r11, 0x538(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(1336 as u32), ctx.r[11].u64 ) };
	// 82210404: 48324DCD  bl 0x825351d0
	ctx.lr = 0x82210408;
	sub_825351D0(ctx, base);
	// 82210408: 8172000C  lwz r11, 0xc(r18)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(12 as u32) ) } as u64;
	// 8221040C: 3D408288  lis r10, -0x7d78
	ctx.r[10].s64 = -2105016320;
	// 82210410: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82210414: C1AB01A4  lfs f13, 0x1a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(420 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210418: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221041C: C00B01A8  lfs f0, 0x1a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(424 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210420: C18B01A0  lfs f12, 0x1a0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(416 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82210424: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82210428: EDAC033A  fmadds f13, f12, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221042C: C00AD564  lfs f0, -0x2a9c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-10908 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210430: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82210434: 4099000C  ble cr6, 0x82210440
	if !ctx.cr[6].gt {
	pc = 0x82210440; continue 'dispatch;
	}
	// 82210438: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8221043C: 48000030  b 0x8221046c
	pc = 0x8221046C; continue 'dispatch;
	// 82210440: C1AB01B4  lfs f13, 0x1b4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(436 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210444: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82210448: C00B01B8  lfs f0, 0x1b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(440 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221044C: C18B01B0  lfs f12, 0x1b0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(432 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82210450: 3D608288  lis r11, -0x7d78
	ctx.r[11].s64 = -2105016320;
	// 82210454: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82210458: EDAC033A  fmadds f13, f12, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221045C: C00BD330  lfs f0, -0x2cd0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-11472 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210460: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82210464: 4099003C  ble cr6, 0x822104a0
	if !ctx.cr[6].gt {
	pc = 0x822104A0; continue 'dispatch;
	}
	// 82210468: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8221046C: 560B1838  slwi r11, r16, 3
	ctx.r[11].u32 = ctx.r[16].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210470: 80920010  lwz r4, 0x10(r18)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(16 as u32) ) } as u64;
	// 82210474: 39410104  addi r10, r1, 0x104
	ctx.r[10].s64 = ctx.r[1].s64 + 260;
	// 82210478: 7D6B8A14  add r11, r11, r17
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[17].u64;
	// 8221047C: 39210100  addi r9, r1, 0x100
	ctx.r[9].s64 = ctx.r[1].s64 + 256;
	// 82210480: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210484: 7D4B502E  lwzx r10, r11, r10
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82210488: 7D6B482E  lwzx r11, r11, r9
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8221048C: 7C6A9214  add r3, r10, r18
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[18].u64;
	// 82210490: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82210494: 4E800421  bctrl
	ctx.lr = 0x82210498;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82210498: 816F0688  lwz r11, 0x688(r15)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(1672 as u32) ) } as u64;
	// 8221049C: 91720018  stw r11, 0x18(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 822104A0: 38211110  addi r1, r1, 0x1110
	ctx.r[1].s64 = ctx.r[1].s64 + 4368;
	// 822104A4: 48324C30  b 0x825350d4
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822104A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822104A8 size=304
    let mut pc: u32 = 0x822104A8;
    'dispatch: loop {
        match pc {
            0x822104A8 => {
    //   block [0x822104A8..0x822105D8)
	// 822104A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822104AC: 48324C11  bl 0x825350bc
	ctx.lr = 0x822104B0;
	sub_82535080(ctx, base);
	// 822104B0: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822104B4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 822104B8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 822104BC: 396B45A8  addi r11, r11, 0x45a8
	ctx.r[11].s64 = ctx.r[11].s64 + 17832;
	// 822104C0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 822104C4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 822104C8: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 822104CC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 822104D0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 822104D4: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 822104D8: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 822104DC: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 822104E0: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822104E4: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 822104E8: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 822104EC: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 822104F0: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822104F4: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822104F8: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822104FC: D1BF0014  stfs f13, 0x14(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82210500: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210504: D1BF0018  stfs f13, 0x18(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82210508: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8221050C: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82210510: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82210514: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82210518: 48157D01  bl 0x82368218
	ctx.lr = 0x8221051C;
	sub_82368218(ctx, base);
	// 8221051C: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 82210520: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82210524: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82210528: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221052C: 48157CED  bl 0x82368218
	ctx.lr = 0x82210530;
	sub_82368218(ctx, base);
	// 82210530: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 82210534: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82210538: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221053C: 481578B5  bl 0x82367df0
	ctx.lr = 0x82210540;
	sub_82367DF0(ctx, base);
	// 82210540: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82210544: 387F0030  addi r3, r31, 0x30
	ctx.r[3].s64 = ctx.r[31].s64 + 48;
	// 82210548: 48163E59  bl 0x823743a0
	ctx.lr = 0x8221054C;
	sub_823743A0(ctx, base);
	// 8221054C: 3D40DEAD  lis r10, -0x2153
	ctx.r[10].s64 = -559087616;
	// 82210550: 397F00D4  addi r11, r31, 0xd4
	ctx.r[11].s64 = ctx.r[31].s64 + 212;
	// 82210554: 93BF00C4  stw r29, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[29].u32 ) };
	// 82210558: 614ADEAD  ori r10, r10, 0xdead
	ctx.r[10].u64 = ctx.r[10].u64 | 57005;
	// 8221055C: 93BF00CC  stw r29, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[29].u32 ) };
	// 82210560: 93BF00C8  stw r29, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[29].u32 ) };
	// 82210564: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82210568: 93DF00C0  stw r30, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[30].u32 ) };
	// 8221056C: 915F00F4  stw r10, 0xf4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(244 as u32), ctx.r[10].u32 ) };
	// 82210570: 419A0054  beq cr6, 0x822105c4
	if ctx.cr[6].eq {
	pc = 0x822105C4; continue 'dispatch;
	}
	// 82210574: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82210578: 3D40820C  lis r10, -0x7df4
	ctx.r[10].s64 = -2113142784;
	// 8221057C: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 82210580: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 82210584: 394A45C8  addi r10, r10, 0x45c8
	ctx.r[10].s64 = ctx.r[10].s64 + 17864;
	// 82210588: B0EB0006  sth r7, 6(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(6 as u32), ctx.r[7].u16 ) };
	// 8221058C: 392945B8  addi r9, r9, 0x45b8
	ctx.r[9].s64 = ctx.r[9].s64 + 17848;
	// 82210590: 3908C798  addi r8, r8, -0x3868
	ctx.r[8].s64 = ctx.r[8].s64 + -14440;
	// 82210594: 38E0FFFF  li r7, -1
	ctx.r[7].s64 = -1;
	// 82210598: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221059C: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 822105A0: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 822105A4: 910B0008  stw r8, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 822105A8: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 822105AC: 93AB0010  stw r29, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 822105B0: 90EB0014  stw r7, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[7].u32 ) };
	// 822105B4: 93AB0018  stw r29, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[29].u32 ) };
	// 822105B8: 917F00D0  stw r11, 0xd0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[11].u32 ) };
	// 822105BC: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 822105C0: 48324B4C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 822105C4: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 822105C8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822105CC: 917F00D0  stw r11, 0xd0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[11].u32 ) };
	// 822105D0: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 822105D4: 48324B38  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822105D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822105D8 size=504
    let mut pc: u32 = 0x822105D8;
    'dispatch: loop {
        match pc {
            0x822105D8 => {
    //   block [0x822105D8..0x822107D0)
	// 822105D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822105DC: 48324AE1  bl 0x825350bc
	ctx.lr = 0x822105E0;
	sub_82535080(ctx, base);
	// 822105E0: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822105E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822105E8: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 822105EC: A17E0020  lhz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 822105F0: 813E00C4  lwz r9, 0xc4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(196 as u32) ) } as u64;
	// 822105F4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 822105F8: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 822105FC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210600: 7FEB5214  add r31, r11, r10
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82210604: 419A015C  beq cr6, 0x82210760
	if ctx.cr[6].eq {
	pc = 0x82210760; continue 'dispatch;
	}
	// 82210608: 807E00CC  lwz r3, 0xcc(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(204 as u32) ) } as u64;
	// 8221060C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82210610: 419A0118  beq cr6, 0x82210728
	if ctx.cr[6].eq {
	pc = 0x82210728; continue 'dispatch;
	}
	// 82210614: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 82210618: 4817D679  bl 0x8238dc90
	ctx.lr = 0x8221061C;
	sub_8238DC90(ctx, base);
	// 8221061C: 38BE0040  addi r5, r30, 0x40
	ctx.r[5].s64 = ctx.r[30].s64 + 64;
	// 82210620: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 82210624: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82210628: 48157709  bl 0x82367d30
	ctx.lr = 0x8221062C;
	sub_82367D30(ctx, base);
	// 8221062C: C01F0030  lfs f0, 0x30(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210630: 817E00C8  lwz r11, 0xc8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(200 as u32) ) } as u64;
	// 82210634: D0010070  stfs f0, 0x70(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82210638: C01F0034  lfs f0, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221063C: C1BF0038  lfs f13, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210640: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82210644: D0010074  stfs f0, 0x74(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82210648: D1A10078  stfs f13, 0x78(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8221064C: 409A015C  bne cr6, 0x822107a8
	if !ctx.cr[6].eq {
	pc = 0x822107A8; continue 'dispatch;
	}
	// 82210650: 4BFA72B9  bl 0x821b7908
	ctx.lr = 0x82210654;
	sub_821B7908(ctx, base);
	// 82210654: FF000800  fcmpu cr6, f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[1].f64);
	// 82210658: 40980150  bge cr6, 0x822107a8
	if !ctx.cr[6].lt {
	pc = 0x822107A8; continue 'dispatch;
	}
	// 8221065C: 817E00C0  lwz r11, 0xc0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(192 as u32) ) } as u64;
	// 82210660: 896B0030  lbz r11, 0x30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 82210664: 557D073E  clrlwi r29, r11, 0x1c
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 82210668: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8221066C: 4198000C  blt cr6, 0x82210678
	if ctx.cr[6].lt {
	pc = 0x82210678; continue 'dispatch;
	}
	// 82210670: 2F1D0003  cmpwi cr6, r29, 3
	ctx.cr[6].compare_i32(ctx.r[29].s32, 3, &mut ctx.xer);
	// 82210674: 40990008  ble cr6, 0x8221067c
	if !ctx.cr[6].gt {
	pc = 0x8221067C; continue 'dispatch;
	}
	// 82210678: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8221067C: 39600036  li r11, 0x36
	ctx.r[11].s64 = 54;
	// 82210680: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82210684: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82210688: 39600009  li r11, 9
	ctx.r[11].s64 = 9;
	// 8221068C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 82210690: 3960000A  li r11, 0xa
	ctx.r[11].s64 = 10;
	// 82210694: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 82210698: 3960000B  li r11, 0xb
	ctx.r[11].s64 = 11;
	// 8221069C: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 822106A0: 419A007C  beq cr6, 0x8221071c
	if ctx.cr[6].eq {
	pc = 0x8221071C; continue 'dispatch;
	}
	// 822106A4: 48322B6D  bl 0x82533210
	ctx.lr = 0x822106A8;
	sub_82533210(ctx, base);
	// 822106A8: 3D60829F  lis r11, -0x7d61
	ctx.r[11].s64 = -2103508992;
	// 822106AC: 546A047E  clrlwi r10, r3, 0x11
	ctx.r[10].u64 = ctx.r[3].u32 as u64 & 0x00007FFFu64;
	// 822106B0: 806BB514  lwz r3, -0x4aec(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-19180 as u32) ) } as u64;
	// 822106B4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 822106B8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 822106BC: F9610058  std r11, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u64 ) };
	// 822106C0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 822106C4: C8010058  lfd f0, 0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 822106C8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822106CC: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822106D0: C00B206C  lfs f0, 0x206c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8300 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822106D4: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822106D8: 419A002C  beq cr6, 0x82210704
	if ctx.cr[6].eq {
	pc = 0x82210704; continue 'dispatch;
	}
	// 822106DC: 3D408288  lis r10, -0x7d78
	ctx.r[10].s64 = -2105016320;
	// 822106E0: 3D208288  lis r9, -0x7d78
	ctx.r[9].s64 = -2105016320;
	// 822106E4: 57AB103A  slwi r11, r29, 2
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822106E8: 394AD344  addi r10, r10, -0x2cbc
	ctx.r[10].s64 = ctx.r[10].s64 + -11452;
	// 822106EC: 3929D334  addi r9, r9, -0x2ccc
	ctx.r[9].s64 = ctx.r[9].s64 + -11468;
	// 822106F0: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 822106F4: 7DAB542E  lfsx f13, r11, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822106F8: 7D8B4C2E  lfsx f12, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822106FC: EC2D603A  fmadds f1, f13, f0, f12
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64);
	// 82210700: 48110859  bl 0x82320f58
	ctx.lr = 0x82210704;
	sub_82320F58(ctx, base);
	// 82210704: 57AB103A  slwi r11, r29, 2
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210708: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8221070C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82210710: 389E00B0  addi r4, r30, 0xb0
	ctx.r[4].s64 = ctx.r[30].s64 + 176;
	// 82210714: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82210718: 48151F69  bl 0x82362680
	ctx.lr = 0x8221071C;
	sub_82362680(ctx, base);
	// 8221071C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82210720: 917E00C8  stw r11, 0xc8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 82210724: 48000084  b 0x822107a8
	pc = 0x822107A8; continue 'dispatch;
	// 82210728: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 8221072C: 39400030  li r10, 0x30
	ctx.r[10].s64 = 48;
	// 82210730: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 82210734: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 82210738: 3D603F80  lis r11, 0x3f80
	ctx.r[11].s64 = 1065353216;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822107D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822107D0 size=324
    let mut pc: u32 = 0x822107D0;
    'dispatch: loop {
        match pc {
            0x822107D0 => {
    //   block [0x822107D0..0x82210914)
	// 822107D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822107D4: 483248DD  bl 0x825350b0
	ctx.lr = 0x822107D8;
	sub_82535080(ctx, base);
	// 822107D8: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822107DC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 822107E0: 817F00C4  lwz r11, 0xc4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 822107E4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822107E8: 409A0124  bne cr6, 0x8221090c
	if !ctx.cr[6].eq {
	pc = 0x8221090C; continue 'dispatch;
	}
	// 822107EC: 817F00C0  lwz r11, 0xc0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 822107F0: 2F05FFFF  cmpwi cr6, r5, -1
	ctx.cr[6].compare_i32(ctx.r[5].s32, -1, &mut ctx.xer);
	// 822107F4: 3B400001  li r26, 1
	ctx.r[26].s64 = 1;
	// 822107F8: 816B0030  lwz r11, 0x30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 822107FC: 557DE53E  rlwinm r29, r11, 0x1c, 0x14, 0x1f
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 82210800: 557C073E  clrlwi r28, r11, 0x1c
	ctx.r[28].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 82210804: 419A001C  beq cr6, 0x82210820
	if ctx.cr[6].eq {
	pc = 0x82210820; continue 'dispatch;
	}
	// 82210808: 556B843E  srwi r11, r11, 0x10
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(16);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221080C: 7F4A2830  slw r10, r26, r5
	if (ctx.r[5].u8 & 0x20) != 0 {
		ctx.r[10].u64 = 0;
	} else {
		ctx.r[10].u64 = ((ctx.r[26].u32) << ((ctx.r[5].u8 & 0x1F) as u32)) as u64;
	}
	// 82210810: 7D6B5038  and r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[10].u64;
	// 82210814: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 82210818: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221081C: 419A00F0  beq cr6, 0x8221090c
	if ctx.cr[6].eq {
	pc = 0x8221090C; continue 'dispatch;
	}
	// 82210820: 3B7F0080  addi r27, r31, 0x80
	ctx.r[27].s64 = ctx.r[31].s64 + 128;
	// 82210824: 480DC90D  bl 0x822ed130
	ctx.lr = 0x82210828;
	sub_822ED130(ctx, base);
	// 82210828: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8221082C: 93A10054  stw r29, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[29].u32 ) };
	// 82210830: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82210834: 93810058  stw r28, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[28].u32 ) };
	// 82210838: 396B45DC  addi r11, r11, 0x45dc
	ctx.r[11].s64 = ctx.r[11].s64 + 17884;
	// 8221083C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82210840: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82210844: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 82210848: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8221084C: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82210850: 480DCC01  bl 0x822ed450
	ctx.lr = 0x82210854;
	sub_822ED450(ctx, base);
	// 82210854: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82210858: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8221085C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82210860: 480DCA09  bl 0x822ed268
	ctx.lr = 0x82210864;
	sub_822ED268(ctx, base);
	// 82210864: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82210868: 419A00A4  beq cr6, 0x8221090c
	if ctx.cr[6].eq {
	pc = 0x8221090C; continue 'dispatch;
	}
	// 8221086C: 4817C755  bl 0x8238cfc0
	ctx.lr = 0x82210870;
	sub_8238CFC0(ctx, base);
	// 82210870: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 82210874: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 82210878: 911F00CC  stw r8, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[8].u32 ) };
	// 8221087C: 419A0090  beq cr6, 0x8221090c
	if ctx.cr[6].eq {
	pc = 0x8221090C; continue 'dispatch;
	}
	// 82210880: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 82210884: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82210888: 48158309  bl 0x82368b90
	ctx.lr = 0x8221088C;
	sub_82368B90(ctx, base);
	// 8221088C: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 82210890: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82210894: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82210898: 48157499  bl 0x82367d30
	ctx.lr = 0x8221089C;
	sub_82367D30(ctx, base);
	// 8221089C: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 822108A0: 7D034378  mr r3, r8
	ctx.r[3].u64 = ctx.r[8].u64;
	// 822108A4: 4817D1AD  bl 0x8238da50
	ctx.lr = 0x822108A8;
	sub_8238DA50(ctx, base);
	// 822108A8: 815F00CC  lwz r10, 0xcc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 822108AC: 816A0004  lwz r11, 4(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 822108B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822108B4: 419A0008  beq cr6, 0x822108bc
	if ctx.cr[6].eq {
	pc = 0x822108BC; continue 'dispatch;
	}
	// 822108B8: 93AB000C  stw r29, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 822108BC: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 822108C0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822108C4: 419A0008  beq cr6, 0x822108cc
	if ctx.cr[6].eq {
	pc = 0x822108CC; continue 'dispatch;
	}
	// 822108C8: 93AB0008  stw r29, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 822108CC: 817F00D0  lwz r11, 0xd0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 822108D0: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 822108D4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822108D8: 409A0018  bne cr6, 0x822108f0
	if !ctx.cr[6].eq {
	pc = 0x822108F0; continue 'dispatch;
	}
	// 822108DC: 815F00CC  lwz r10, 0xcc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 822108E0: 388B0008  addi r4, r11, 8
	ctx.r[4].s64 = ctx.r[11].s64 + 8;
	// 822108E4: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 822108E8: 806A0004  lwz r3, 4(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 822108EC: 4827DDCD  bl 0x8248e6b8
	ctx.lr = 0x822108F0;
	sub_8248E6B8(ctx, base);
	// 822108F0: 817F00D0  lwz r11, 0xd0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 822108F4: 395F00B0  addi r10, r31, 0xb0
	ctx.r[10].s64 = ctx.r[31].s64 + 176;
	// 822108F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 822108FC: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 82210900: 809F00CC  lwz r4, 0xcc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82210904: 480DD435  bl 0x822edd38
	ctx.lr = 0x82210908;
	sub_822EDD38(ctx, base);
	// 82210908: 935F00C4  stw r26, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[26].u32 ) };
	// 8221090C: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 82210910: 483247F0  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82210918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82210918 size=400
    let mut pc: u32 = 0x82210918;
    'dispatch: loop {
        match pc {
            0x82210918 => {
    //   block [0x82210918..0x82210AA8)
	// 82210918: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221091C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82210920: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82210924: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82210928: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221092C: 7C8B0734  extsh r11, r4
	ctx.r[11].s64 = ctx.r[4].s16 as i64;
	// 82210930: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 82210934: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82210938: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 8221093C: 409A0054  bne cr6, 0x82210990
	if !ctx.cr[6].eq {
	pc = 0x82210990; continue 'dispatch;
	}
	// 82210940: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82210AA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82210AA8 size=144
    let mut pc: u32 = 0x82210AA8;
    'dispatch: loop {
        match pc {
            0x82210AA8 => {
    //   block [0x82210AA8..0x82210B38)
	// 82210AA8: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 82210AAC: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82210AB0: 39200030  li r9, 0x30
	ctx.r[9].s64 = 48;
	// 82210AB4: FC000A10  fabs f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = ctx.f[1].u64 & !0x8000_0000_0000_0000u64;
	// 82210AB8: 38E80020  addi r7, r8, 0x20
	ctx.r[7].s64 = ctx.r[8].s64 + 32;
	// 82210ABC: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 82210AC0: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82210AC4: 39400030  li r10, 0x30
	ctx.r[10].s64 = 48;
	// 82210AC8: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82210ACC: C1682150  lfs f11, 0x2150(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8528 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82210AD0: E9030000  ld r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	// 82210AD4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82210AD8: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 82210ADC: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 82210AE0: E9030008  ld r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	// 82210AE4: F9090008  std r8, 8(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[8].u64 ) };
	// 82210AE8: E9240000  ld r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	// 82210AEC: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82210AF0: E9240008  ld r9, 8(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	// 82210AF4: F92A0008  std r9, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[9].u64 ) };
	// 82210AF8: 7C2B3D2E  stfsx f1, r11, r7
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82210AFC: 41980028  blt cr6, 0x82210b24
	if ctx.cr[6].lt {
	pc = 0x82210B24; continue 'dispatch;
	}
	// 82210B00: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210B04: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82210B08: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82210B0C: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210B10: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82210B14: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82210B18: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82210B1C: FF005800  fcmpu cr6, f0, f11
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[11].f64);
	// 82210B20: 40980008  bge cr6, 0x82210b28
	if !ctx.cr[6].lt {
	pc = 0x82210B28; continue 'dispatch;
	}
	// 82210B24: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82210B28: 39400030  li r10, 0x30
	ctx.r[10].s64 = 48;
	// 82210B2C: 394A0024  addi r10, r10, 0x24
	ctx.r[10].s64 = ctx.r[10].s64 + 36;
	// 82210B30: 7D2B51AE  stbx r9, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[9].u8) };
	// 82210B34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82210B38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82210B38 size=344
    let mut pc: u32 = 0x82210B38;
    'dispatch: loop {
        match pc {
            0x82210B38 => {
    //   block [0x82210B38..0x82210C90)
	// 82210B38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82210B3C: 48324581  bl 0x825350bc
	ctx.lr = 0x82210B40;
	sub_82535080(ctx, base);
	// 82210B40: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82210B44: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82210B48: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82210B4C: 83FE0044  lwz r31, 0x44(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(68 as u32) ) } as u64;
	// 82210B50: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82210B54: 419A00F0  beq cr6, 0x82210c44
	if ctx.cr[6].eq {
	pc = 0x82210C44; continue 'dispatch;
	}
	// 82210B58: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 82210B5C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82210B60: 419A00E4  beq cr6, 0x82210c44
	if ctx.cr[6].eq {
	pc = 0x82210C44; continue 'dispatch;
	}
	// 82210B64: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82210B68: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82210B6C: 48157095  bl 0x82367c00
	ctx.lr = 0x82210B70;
	sub_82367C00(ctx, base);
	// 82210B70: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 82210B74: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 82210B78: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82210B7C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82210B80: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210B84: 7D0BEA14  add r8, r11, r29
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82210B88: 7D044378  mr r4, r8
	ctx.r[4].u64 = ctx.r[8].u64;
	// 82210B8C: 48157265  bl 0x82367df0
	ctx.lr = 0x82210B90;
	sub_82367DF0(ctx, base);
	// 82210B90: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 82210B94: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82210B98: 48163809  bl 0x823743a0
	ctx.lr = 0x82210B9C;
	sub_823743A0(ctx, base);
	// 82210B9C: C0010050  lfs f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BA0: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 82210BA4: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 82210BA8: C0010054  lfs f0, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BAC: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82210BB0: C0010058  lfs f0, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BB4: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82210BB8: C041005C  lfs f2, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82210BBC: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BC0: EC0200BC  fnmsubs f0, f2, f2, f0
	ctx.f[0].f64 = -(((ctx.f[2].f64 * ctx.f[2].f64 - ctx.f[0].f64) as f32) as f64);
	// 82210BC4: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 82210BC8: EC20002C  fsqrts f1, f0
	ctx.f[1].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82210BCC: C0080030  lfs f0, 0x30(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BD0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82210BD4: C0080034  lfs f0, 0x34(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BD8: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82210BDC: C0080038  lfs f0, 0x38(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BE0: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82210BE4: 483222C5  bl 0x82532ea8
	ctx.lr = 0x82210BE8;
	sub_82532EA8(ctx, base);
	// 82210BE8: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82210BEC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82210BF0: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82210BF4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82210BF8: C00B2254  lfs f0, 0x2254(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8788 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82210BFC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82210C00: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82210C04: C1AB2068  lfs f13, 0x2068(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82210C08: EC000372  fmuls f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82210C0C: FC200210  fabs f1, f0
	ctx.f[1].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 82210C10: 4BFFFE99  bl 0x82210aa8
	ctx.lr = 0x82210C14;
	sub_82210AA8(ctx, base);
	// 82210C14: A17F0022  lhz r11, 0x22(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(34 as u32) ) } as u64;
	// 82210C18: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 82210C1C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82210C20: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210C24: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82210C28: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 82210C2C: E94B0000  ld r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 82210C30: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82210C34: F95E0000  std r10, 0(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 82210C38: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 82210C3C: 4200FFF0  bdnz 0x82210c2c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82210C2C; continue 'dispatch;
	}
	// 82210C40: 48000018  b 0x82210c58
	pc = 0x82210C58; continue 'dispatch;
	// 82210C44: 39600030  li r11, 0x30
	ctx.r[11].s64 = 48;
	// 82210C48: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82210C4C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82210C50: 396B0024  addi r11, r11, 0x24
	ctx.r[11].s64 = ctx.r[11].s64 + 36;
	// 82210C54: 7D2B51AE  stbx r9, r11, r10
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[9].u8) };
	// 82210C58: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82210C5C: 419A002C  beq cr6, 0x82210c88
	if ctx.cr[6].eq {
	pc = 0x82210C88; continue 'dispatch;
	}
	// 82210C60: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82210C64: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82210C68: 83DF0024  lwz r30, 0x24(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 82210C6C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82210C70: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82210C74: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82210C78: 4E800421  bctrl
	ctx.lr = 0x82210C7C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82210C7C: 7FDFF378  mr r31, r30
	ctx.r[31].u64 = ctx.r[30].u64;
	// 82210C80: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82210C84: 409AFFDC  bne cr6, 0x82210c60
	if !ctx.cr[6].eq {
	pc = 0x82210C60; continue 'dispatch;
	}
	// 82210C88: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82210C8C: 48324480  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82210C90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82210C90 size=3876
    let mut pc: u32 = 0x82210C90;
    'dispatch: loop {
        match pc {
            0x82210C90 => {
    //   block [0x82210C90..0x82210E1C)
	// 82210C90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82210C94: 483243ED  bl 0x82535080
	ctx.lr = 0x82210C98;
	sub_82535080(ctx, base);
	// 82210C98: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 82210C9C: E981E000  ld r12, -0x2000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8192 as u32) ) };
	// 82210CA0: 9421DED0  stwu r1, -0x2130(r1)
	ea = ctx.r[1].u32.wrapping_add(-8496 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82210CA4: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 82210CA8: 90A12154  stw r5, 0x2154(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(8532 as u32), ctx.r[5].u32 ) };
	// 82210CAC: 3A200000  li r17, 0
	ctx.r[17].s64 = 0;
	// 82210CB0: 7C701B78  mr r16, r3
	ctx.r[16].u64 = ctx.r[3].u64;
	// 82210CB4: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 82210CB8: 7C8F2378  mr r15, r4
	ctx.r[15].u64 = ctx.r[4].u64;
	// 82210CBC: 93A12164  stw r29, 0x2164(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(8548 as u32), ctx.r[29].u32 ) };
	// 82210CC0: 7E3F8B78  mr r31, r17
	ctx.r[31].u64 = ctx.r[17].u64;
	// 82210CC4: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 82210CC8: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 82210CCC: 7E268B78  mr r6, r17
	ctx.r[6].u64 = ctx.r[17].u64;
	// 82210CD0: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 82210CD4: 38E0FFFF  li r7, -1
	ctx.r[7].s64 = -1;
	// 82210CD8: 556A1838  slwi r10, r11, 3
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82210CDC: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 82210CE0: 3B810092  addi r28, r1, 0x92
	ctx.r[28].s64 = ctx.r[1].s64 + 146;
	// 82210CE4: 3B610094  addi r27, r1, 0x94
	ctx.r[27].s64 = ctx.r[1].s64 + 148;
	// 82210CE8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82210CEC: 7E2A232E  sthx r17, r10, r4
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32), ctx.r[17].u16) };
	// 82210CF0: 2B2B0200  cmpldi cr6, r11, 0x200
	ctx.cr[6].compare_u64(ctx.r[11].u64, 512, &mut ctx.xer);
	// 82210CF4: 7CEAE32E  sthx r7, r10, r28
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[28].u32), ctx.r[7].u16) };
	// 82210CF8: 7E2AD92E  stwx r17, r10, r27
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[27].u32), ctx.r[17].u32) };
	// 82210CFC: 4198FFDC  blt cr6, 0x82210cd8
	if ctx.cr[6].lt {
	pc = 0x82210CD8; continue 'dispatch;
	}
	// 82210D00: 7CB307B4  extsw r19, r5
	ctx.r[19].s64 = ctx.r[5].s32 as i64;
	// 82210D04: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82210D08: 7E258B78  mr r5, r17
	ctx.r[5].u64 = ctx.r[17].u64;
	// 82210D0C: 2F330000  cmpdi cr6, r19, 0
	ctx.cr[6].compare_i64(ctx.r[19].s64, 0, &mut ctx.xer);
	// 82210D10: 40990140  ble cr6, 0x82210e50
	if !ctx.cr[6].gt {
	pc = 0x82210E50; continue 'dispatch;
	}
	// 82210D14: 7CAB07B4  extsw r11, r5
	ctx.r[11].s64 = ctx.r[5].s32 as i64;
	// 82210D18: 3B811090  addi r28, r1, 0x1090
	ctx.r[28].s64 = ctx.r[1].s64 + 4240;
	// 82210D1C: 5567103A  slwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82210D20: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82210D24: 7CEB3A14  add r7, r11, r7
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82210D28: 3B611092  addi r27, r1, 0x1092
	ctx.r[27].s64 = ctx.r[1].s64 + 4242;
	// 82210D2C: 54E72036  slwi r7, r7, 4
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82210D30: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82210D34: 7CE77A14  add r7, r7, r15
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[15].u64;
	// 82210D38: A0C7004E  lhz r6, 0x4e(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(78 as u32) ) } as u64;
	// 82210D3C: A347004C  lhz r26, 0x4c(r7)
	ctx.r[26].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(76 as u32) ) } as u64;
	// 82210D40: 7CCAE32E  sthx r6, r10, r28
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[28].u32), ctx.r[6].u16) };
	// 82210D44: 7F4ADB2E  sthx r26, r10, r27
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[27].u32), ctx.r[26].u16) };
	// 82210D48: 40980018  bge cr6, 0x82210d60
	if !ctx.cr[6].lt {
	pc = 0x82210D60; continue 'dispatch;
	}
	// 82210D4C: 39611890  addi r11, r1, 0x1890
	ctx.r[11].s64 = ctx.r[1].s64 + 6288;
	// 82210D50: 54C6043E  clrlwi r6, r6, 0x10
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x0000FFFFu64;
	// 82210D54: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82210D58: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82210D5C: 48000034  b 0x82210d90
	pc = 0x82210D90; continue 'dispatch;
	// 82210D60: 8B87004B  lbz r28, 0x4b(r7)
	ctx.r[28].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(75 as u32) ) } as u64;
	// 82210D64: 2B1C0001  cmplwi cr6, r28, 1
	ctx.cr[6].compare_u32(ctx.r[28].u32, 1 as u32, &mut ctx.xer);
	// 82210D68: 409A0018  bne cr6, 0x82210d80
	if !ctx.cr[6].eq {
	pc = 0x82210D80; continue 'dispatch;
	}
	// 82210D6C: 39611890  addi r11, r1, 0x1890
	ctx.r[11].s64 = ctx.r[1].s64 + 6288;
	// 82210D70: 54C6043E  clrlwi r6, r6, 0x10
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x0000FFFFu64;
	// 82210D74: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82210D78: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82210D7C: 48000014  b 0x82210d90
	pc = 0x82210D90; continue 'dispatch;
	// 82210D80: 38C11890  addi r6, r1, 0x1890
	ctx.r[6].s64 = ctx.r[1].s64 + 6288;
	// 82210D84: 7F8B2214  add r28, r11, r4
	ctx.r[28].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 82210D88: 7D6A3214  add r11, r10, r6
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 82210D8C: 938B0000  stw r28, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[28].u32 ) };
	// 82210D90: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82210D94: 8947004B  lbz r10, 0x4b(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(75 as u32) ) } as u64;
	// 82210D98: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 82210D9C: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82210DA0: 2B0A0015  cmplwi cr6, r10, 0x15
	ctx.cr[6].compare_u32(ctx.r[10].u32, 21 as u32, &mut ctx.xer);
	// 82210DA4: B167004E  sth r11, 0x4e(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(78 as u32), ctx.r[11].u16 ) };
	// 82210DA8: 4199009C  bgt cr6, 0x82210e44
	if ctx.cr[6].gt {
	pc = 0x82210E44; continue 'dispatch;
	}
	// 82210DAC: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82210DB0: 398C0DC4  addi r12, r12, 0xdc4
	ctx.r[12].s64 = ctx.r[12].s64 + 3524;
	// 82210DB4: 5540103A  slwi r0, r10, 2
	ctx.r[0].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82210DB8: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82210DBC: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82210DC0: 4E800420  bctr
	match ctx.r[10].u64 {
		0 => {
	pc = 0x82210E1C; continue 'dispatch;
		},
		1 => {
	pc = 0x82210E44; continue 'dispatch;
		},
		2 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		3 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		4 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		5 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		6 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		7 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		8 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		9 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		10 => {
	pc = 0x82210E40; continue 'dispatch;
		},
		11 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		12 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		13 => {
	pc = 0x82210E44; continue 'dispatch;
		},
		14 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		15 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		16 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		17 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		18 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		19 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		20 => {
	pc = 0x82210E44; continue 'dispatch;
		},
		21 => {
	pc = 0x82210E38; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82210DC4: 82210E1C  lwz r17, 0xe1c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3612 as u32) ) } as u64;
	// 82210DC8: 82210E44  lwz r17, 0xe44(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3652 as u32) ) } as u64;
	// 82210DCC: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DD0: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DD4: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DD8: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DDC: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DE0: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DE4: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DE8: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DEC: 82210E40  lwz r17, 0xe40(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3648 as u32) ) } as u64;
	// 82210DF0: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DF4: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210DF8: 82210E44  lwz r17, 0xe44(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3652 as u32) ) } as u64;
	// 82210DFC: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E00: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E04: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E08: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E0C: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E10: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
	// 82210E14: 82210E44  lwz r17, 0xe44(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3652 as u32) ) } as u64;
	// 82210E18: 82210E38  lwz r17, 0xe38(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(3640 as u32) ) } as u64;
            }
            0x82210E1C => {
    //   block [0x82210E1C..0x82210E38)
	// 82210E1C: 2F1D0004  cmpwi cr6, r29, 4
	ctx.cr[6].compare_i32(ctx.r[29].s32, 4, &mut ctx.xer);
	// 82210E20: 419A000C  beq cr6, 0x82210e2c
	if ctx.cr[6].eq {
	pc = 0x82210E2C; continue 'dispatch;
	}
	// 82210E24: 2F1D000B  cmpwi cr6, r29, 0xb
	ctx.cr[6].compare_i32(ctx.r[29].s32, 11, &mut ctx.xer);
	// 82210E28: 409A0008  bne cr6, 0x82210e30
	if !ctx.cr[6].eq {
	pc = 0x82210E30; continue 'dispatch;
	}
	// 82210E2C: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82210E30: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 82210E34: 48000010  b 0x82210e44
	pc = 0x82210E44; continue 'dispatch;
            }
            0x82210E38 => {
    //   block [0x82210E38..0x82210E40)
	// 82210E38: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82210E3C: 48000008  b 0x82210e44
	pc = 0x82210E44; continue 'dispatch;
            }
            0x82210E40 => {
    //   block [0x82210E40..0x82210E44)
	// 82210E40: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	pc = 0x82210E44; continue 'dispatch;
            }
            0x82210E44 => {
    //   block [0x82210E44..0x82211020)
	// 82210E44: 38A50001  addi r5, r5, 1
	ctx.r[5].s64 = ctx.r[5].s64 + 1;
	// 82210E48: 7F259800  cmpd cr6, r5, r19
	ctx.cr[6].compare_i64(ctx.r[5].s64, ctx.r[19].s64, &mut ctx.xer);
	// 82210E4C: 4198FEC8  blt cr6, 0x82210d14
	if ctx.cr[6].lt {
	pc = 0x82210D14; continue 'dispatch;
	}
	// 82210E50: 39660001  addi r11, r6, 1
	ctx.r[11].s64 = ctx.r[6].s64 + 1;
	// 82210E54: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82210E58: 91680000  stw r11, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82210E5C: 419A0008  beq cr6, 0x82210e64
	if ctx.cr[6].eq {
	pc = 0x82210E64; continue 'dispatch;
	}
	// 82210E60: 90690000  stw r3, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 82210E64: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82210E68: 7FEB0734  extsh r11, r31
	ctx.r[11].s64 = ctx.r[31].s16 as i64;
	// 82210E6C: 4098009C  bge cr6, 0x82210f08
	if !ctx.cr[6].lt {
	pc = 0x82210F08; continue 'dispatch;
	}
	// 82210E70: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82210E74: B1700000  sth r11, 0(r16)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[16].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82210E78: 4199000C  bgt cr6, 0x82210e84
	if ctx.cr[6].gt {
	pc = 0x82210E84; continue 'dispatch;
	}
	// 82210E7C: 92300008  stw r17, 8(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(8 as u32), ctx.r[17].u32 ) };
	// 82210E80: 48000008  b 0x82210e88
	pc = 0x82210E88; continue 'dispatch;
	// 82210E84: 93300008  stw r25, 8(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 82210E88: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82210E8C: 41990008  bgt cr6, 0x82210e94
	if ctx.cr[6].gt {
	pc = 0x82210E94; continue 'dispatch;
	}
	// 82210E90: 9230000C  stw r17, 0xc(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(12 as u32), ctx.r[17].u32 ) };
	// 82210E94: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82210E98: 41990068  bgt cr6, 0x82210f00
	if ctx.cr[6].gt {
	pc = 0x82210F00; continue 'dispatch;
	}
	// 82210E9C: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82210EA0: 41990060  bgt cr6, 0x82210f00
	if ctx.cr[6].gt {
	pc = 0x82210F00; continue 'dispatch;
	}
	// 82210EA4: 39400061  li r10, 0x61
	ctx.r[10].s64 = 97;
	// 82210EA8: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 82210EAC: 2F330000  cmpdi cr6, r19, 0
	ctx.cr[6].compare_i64(ctx.r[19].s64, 0, &mut ctx.xer);
	// 82210EB0: 91480000  stw r10, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82210EB4: 40990CF4  ble cr6, 0x82211ba8
	if !ctx.cr[6].gt {
	pc = 0x82211BA8; continue 'dispatch;
	}
	// 82210EB8: 7D6A07B4  extsw r10, r11
	ctx.r[10].s64 = ctx.r[11].s32 as i64;
	// 82210EBC: 38E11090  addi r7, r1, 0x1090
	ctx.r[7].s64 = ctx.r[1].s64 + 4240;
	// 82210EC0: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82210EC4: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82210EC8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82210ECC: 38C11092  addi r6, r1, 0x1092
	ctx.r[6].s64 = ctx.r[1].s64 + 4242;
	// 82210ED0: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82210ED4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82210ED8: 7D093A2E  lhzx r8, r9, r7
	ctx.r[8].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 82210EDC: 7D4A7A14  add r10, r10, r15
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[15].u64;
	// 82210EE0: 7F2B9800  cmpd cr6, r11, r19
	ctx.cr[6].compare_i64(ctx.r[11].s64, ctx.r[19].s64, &mut ctx.xer);
	// 82210EE4: 7D29322E  lhzx r9, r9, r6
	ctx.r[9].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 82210EE8: B10A004E  sth r8, 0x4e(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(78 as u32), ctx.r[8].u16 ) };
	// 82210EEC: B12A004C  sth r9, 0x4c(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(76 as u32), ctx.r[9].u16 ) };
	// 82210EF0: 4198FFC8  blt cr6, 0x82210eb8
	if ctx.cr[6].lt {
	pc = 0x82210EB8; continue 'dispatch;
	}
	// 82210EF4: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82210EF8: 38212130  addi r1, r1, 0x2130
	ctx.r[1].s64 = ctx.r[1].s64 + 8496;
	// 82210EFC: 483241D4  b 0x825350d0
	sub_825350D0(ctx, base);
	return;
	// 82210F00: B2300002  sth r17, 2(r16)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[16].u32.wrapping_add(2 as u32), ctx.r[17].u16 ) };
	// 82210F04: 4800002C  b 0x82210f30
	pc = 0x82210F30; continue 'dispatch;
	// 82210F08: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82210F0C: B1700004  sth r11, 4(r16)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[16].u32.wrapping_add(4 as u32), ctx.r[11].u16 ) };
	// 82210F10: 4199000C  bgt cr6, 0x82210f1c
	if ctx.cr[6].gt {
	pc = 0x82210F1C; continue 'dispatch;
	}
	// 82210F14: 92300010  stw r17, 0x10(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(16 as u32), ctx.r[17].u32 ) };
	// 82210F18: 48000008  b 0x82210f20
	pc = 0x82210F20; continue 'dispatch;
	// 82210F1C: 93300010  stw r25, 0x10(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(16 as u32), ctx.r[25].u32 ) };
	// 82210F20: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82210F24: 41990008  bgt cr6, 0x82210f2c
	if ctx.cr[6].gt {
	pc = 0x82210F2C; continue 'dispatch;
	}
	// 82210F28: 92300014  stw r17, 0x14(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(20 as u32), ctx.r[17].u32 ) };
	// 82210F2C: B2300006  sth r17, 6(r16)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[16].u32.wrapping_add(6 as u32), ctx.r[17].u16 ) };
	// 82210F30: 7E3A8B78  mr r26, r17
	ctx.r[26].u64 = ctx.r[17].u64;
	// 82210F34: 7E328B78  mr r18, r17
	ctx.r[18].u64 = ctx.r[17].u64;
	// 82210F38: 7E3B8B78  mr r27, r17
	ctx.r[27].u64 = ctx.r[17].u64;
	// 82210F3C: 39C00001  li r14, 1
	ctx.r[14].s64 = 1;
	// 82210F40: 3A800030  li r20, 0x30
	ctx.r[20].s64 = 48;
	// 82210F44: 3AA00020  li r21, 0x20
	ctx.r[21].s64 = 32;
	// 82210F48: 3AC00010  li r22, 0x10
	ctx.r[22].s64 = 16;
	// 82210F4C: 3F803F80  lis r28, 0x3f80
	ctx.r[28].s64 = 1065353216;
	// 82210F50: 2F330000  cmpdi cr6, r19, 0
	ctx.cr[6].compare_i64(ctx.r[19].s64, 0, &mut ctx.xer);
	// 82210F54: 409907A8  ble cr6, 0x822116fc
	if !ctx.cr[6].gt {
	pc = 0x822116FC; continue 'dispatch;
	}
	// 82210F58: 3B00000B  li r24, 0xb
	ctx.r[24].s64 = 11;
	// 82210F5C: 3AE0000C  li r23, 0xc
	ctx.r[23].s64 = 12;
	// 82210F60: 7F7D07B4  extsw r29, r27
	ctx.r[29].s64 = ctx.r[27].s32 as i64;
	// 82210F64: 57AB103A  slwi r11, r29, 2
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210F68: 7D7D5A14  add r11, r29, r11
	ctx.r[11].u64 = ctx.r[29].u64 + ctx.r[11].u64;
	// 82210F6C: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210F70: 7FEB7A14  add r31, r11, r15
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[15].u64;
	// 82210F74: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 82210F78: 2B0BFFFF  cmplwi cr6, r11, 0xffff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65535 as u32, &mut ctx.xer);
	// 82210F7C: 409A0010  bne cr6, 0x82210f8c
	if !ctx.cr[6].eq {
	pc = 0x82210F8C; continue 'dispatch;
	}
	// 82210F80: 3D400000  lis r10, 0
	ctx.r[10].s64 = 0;
	// 82210F84: 614AFFFF  ori r10, r10, 0xffff
	ctx.r[10].u64 = ctx.r[10].u64 | 65535;
	// 82210F88: 48000010  b 0x82210f98
	pc = 0x82210F98; continue 'dispatch;
	// 82210F8C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82210F90: 39411890  addi r10, r1, 0x1890
	ctx.r[10].s64 = ctx.r[1].s64 + 6288;
	// 82210F94: 7D4B502E  lwzx r10, r11, r10
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82210F98: 897F004B  lbz r11, 0x4b(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(75 as u32) ) } as u64;
	// 82210F9C: B15F004C  sth r10, 0x4c(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[10].u16 ) };
	// 82210FA0: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82210FA4: 2B0B0016  cmplwi cr6, r11, 0x16
	ctx.cr[6].compare_u32(ctx.r[11].u32, 22 as u32, &mut ctx.xer);
	// 82210FA8: 41990744  bgt cr6, 0x822116ec
	if ctx.cr[6].gt {
	pc = 0x822116EC; continue 'dispatch;
	}
	// 82210FAC: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82210FB0: 398C0FC4  addi r12, r12, 0xfc4
	ctx.r[12].s64 = ctx.r[12].s64 + 4036;
	// 82210FB4: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82210FB8: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82210FBC: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82210FC0: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x82211020; continue 'dispatch;
		},
		1 => {
	pc = 0x822116EC; continue 'dispatch;
		},
		2 => {
	pc = 0x8221122C; continue 'dispatch;
		},
		3 => {
	pc = 0x82211078; continue 'dispatch;
		},
		4 => {
	pc = 0x822110FC; continue 'dispatch;
		},
		5 => {
	pc = 0x822110AC; continue 'dispatch;
		},
		6 => {
	pc = 0x822110CC; continue 'dispatch;
		},
		7 => {
	pc = 0x82211120; continue 'dispatch;
		},
		8 => {
	pc = 0x82211144; continue 'dispatch;
		},
		9 => {
	pc = 0x822112F8; continue 'dispatch;
		},
		10 => {
	pc = 0x82211168; continue 'dispatch;
		},
		11 => {
	pc = 0x82211324; continue 'dispatch;
		},
		12 => {
	pc = 0x82211324; continue 'dispatch;
		},
		13 => {
	pc = 0x822116EC; continue 'dispatch;
		},
		14 => {
	pc = 0x82211370; continue 'dispatch;
		},
		15 => {
	pc = 0x82211390; continue 'dispatch;
		},
		16 => {
	pc = 0x822113B0; continue 'dispatch;
		},
		17 => {
	pc = 0x82211324; continue 'dispatch;
		},
		18 => {
	pc = 0x822113D0; continue 'dispatch;
		},
		19 => {
	pc = 0x82211418; continue 'dispatch;
		},
		20 => {
	pc = 0x82211534; continue 'dispatch;
		},
		21 => {
	pc = 0x82211324; continue 'dispatch;
		},
		22 => {
	pc = 0x82211578; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82210FC4: 82211020  lwz r17, 0x1020(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4128 as u32) ) } as u64;
	// 82210FC8: 822116EC  lwz r17, 0x16ec(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5868 as u32) ) } as u64;
	// 82210FCC: 8221122C  lwz r17, 0x122c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4652 as u32) ) } as u64;
	// 82210FD0: 82211078  lwz r17, 0x1078(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4216 as u32) ) } as u64;
	// 82210FD4: 822110FC  lwz r17, 0x10fc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4348 as u32) ) } as u64;
	// 82210FD8: 822110AC  lwz r17, 0x10ac(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4268 as u32) ) } as u64;
	// 82210FDC: 822110CC  lwz r17, 0x10cc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4300 as u32) ) } as u64;
	// 82210FE0: 82211120  lwz r17, 0x1120(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4384 as u32) ) } as u64;
	// 82210FE4: 82211144  lwz r17, 0x1144(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4420 as u32) ) } as u64;
	// 82210FE8: 822112F8  lwz r17, 0x12f8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4856 as u32) ) } as u64;
	// 82210FEC: 82211168  lwz r17, 0x1168(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4456 as u32) ) } as u64;
	// 82210FF0: 82211324  lwz r17, 0x1324(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4900 as u32) ) } as u64;
	// 82210FF4: 82211324  lwz r17, 0x1324(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4900 as u32) ) } as u64;
	// 82210FF8: 822116EC  lwz r17, 0x16ec(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5868 as u32) ) } as u64;
	// 82210FFC: 82211370  lwz r17, 0x1370(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4976 as u32) ) } as u64;
	// 82211000: 82211390  lwz r17, 0x1390(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5008 as u32) ) } as u64;
	// 82211004: 822113B0  lwz r17, 0x13b0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5040 as u32) ) } as u64;
	// 82211008: 82211324  lwz r17, 0x1324(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4900 as u32) ) } as u64;
	// 8221100C: 822113D0  lwz r17, 0x13d0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5072 as u32) ) } as u64;
	// 82211010: 82211418  lwz r17, 0x1418(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5144 as u32) ) } as u64;
	// 82211014: 82211534  lwz r17, 0x1534(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5428 as u32) ) } as u64;
	// 82211018: 82211324  lwz r17, 0x1324(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4900 as u32) ) } as u64;
	// 8221101C: 82211578  lwz r17, 0x1578(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(5496 as u32) ) } as u64;
            }
            0x82211020 => {
    //   block [0x82211020..0x82211078)
	// 82211020: 80E12164  lwz r7, 0x2164(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(8548 as u32) ) } as u64;
	// 82211024: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 82211028: 419A000C  beq cr6, 0x82211034
	if ctx.cr[6].eq {
	pc = 0x82211034; continue 'dispatch;
	}
	// 8221102C: 2F07000B  cmpwi cr6, r7, 0xb
	ctx.cr[6].compare_i32(ctx.r[7].s32, 11, &mut ctx.xer);
	// 82211030: 409A06BC  bne cr6, 0x822116ec
	if !ctx.cr[6].eq {
	pc = 0x822116EC; continue 'dispatch;
	}
	// 82211034: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211038: 419A001C  beq cr6, 0x82211054
	if ctx.cr[6].eq {
	pc = 0x82211054; continue 'dispatch;
	}
	// 8221103C: 38D00028  addi r6, r16, 0x28
	ctx.r[6].s64 = ctx.r[16].s64 + 40;
	// 82211040: 38B0001C  addi r5, r16, 0x1c
	ctx.r[5].s64 = ctx.r[16].s64 + 28;
	// 82211044: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211048: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 8221104C: 4801155D  bl 0x822225a8
	ctx.lr = 0x82211050;
	sub_822225A8(ctx, base);
	// 82211050: 48000008  b 0x82211058
	pc = 0x82211058; continue 'dispatch;
	// 82211054: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 82211058: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 8221105C: 39410094  addi r10, r1, 0x94
	ctx.r[10].s64 = ctx.r[1].s64 + 148;
	// 82211060: 39210090  addi r9, r1, 0x90
	ctx.r[9].s64 = ctx.r[1].s64 + 144;
	// 82211064: 556B183E  rotlwi r11, r11, 3
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(3)) as u64;
	// 82211068: 3B390270  addi r25, r25, 0x270
	ctx.r[25].s64 = ctx.r[25].s64 + 624;
	// 8221106C: 7C6B512E  stwx r3, r11, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[3].u32) };
	// 82211070: 7F0B4B2E  sthx r24, r11, r9
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), ctx.r[24].u16) };
	// 82211074: 48000678  b 0x822116ec
	pc = 0x822116EC; continue 'dispatch;
            }
            0x82211078 => {
    //   block [0x82211078..0x822110AC)
	// 82211078: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 8221107C: 419A0024  beq cr6, 0x822110a0
	if ctx.cr[6].eq {
	pc = 0x822110A0; continue 'dispatch;
	}
	// 82211080: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82211084: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 82211088: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221108C: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211090: 4BFFC0C1  bl 0x8220d150
	ctx.lr = 0x82211094;
	sub_8220D150(ctx, base);
	// 82211094: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211098: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 8221109C: 480005EC  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822110A0: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 822110A4: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 822110A8: 480005E0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822110AC => {
    //   block [0x822110AC..0x822110CC)
	// 822110AC: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822110B0: 419AFFF0  beq cr6, 0x822110a0
	if ctx.cr[6].eq {
	pc = 0x822110A0; continue 'dispatch;
	}
	// 822110B4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822110B8: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822110BC: 4BFFB845  bl 0x8220c900
	ctx.lr = 0x822110C0;
	sub_8220C900(ctx, base);
	// 822110C0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822110C4: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 822110C8: 480005C0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822110CC => {
    //   block [0x822110CC..0x822110FC)
	// 822110CC: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822110D0: 419A0020  beq cr6, 0x822110f0
	if ctx.cr[6].eq {
	pc = 0x822110F0; continue 'dispatch;
	}
	// 822110D4: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 822110D8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822110DC: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822110E0: 4BFFBBD9  bl 0x8220ccb8
	ctx.lr = 0x822110E4;
	sub_8220CCB8(ctx, base);
	// 822110E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822110E8: 3B390070  addi r25, r25, 0x70
	ctx.r[25].s64 = ctx.r[25].s64 + 112;
	// 822110EC: 4800059C  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822110F0: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 822110F4: 3B390070  addi r25, r25, 0x70
	ctx.r[25].s64 = ctx.r[25].s64 + 112;
	// 822110F8: 48000590  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822110FC => {
    //   block [0x822110FC..0x82211120)
	// 822110FC: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211100: 419AFFA0  beq cr6, 0x822110a0
	if ctx.cr[6].eq {
	pc = 0x822110A0; continue 'dispatch;
	}
	// 82211104: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 82211108: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221110C: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211110: 4BFFC469  bl 0x8220d578
	ctx.lr = 0x82211114;
	sub_8220D578(ctx, base);
	// 82211114: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211118: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 8221111C: 4800056C  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211120 => {
    //   block [0x82211120..0x82211144)
	// 82211120: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211124: 419AFF7C  beq cr6, 0x822110a0
	if ctx.cr[6].eq {
	pc = 0x822110A0; continue 'dispatch;
	}
	// 82211128: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 8221112C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211130: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211134: 4BFFC795  bl 0x8220d8c8
	ctx.lr = 0x82211138;
	sub_8220D8C8(ctx, base);
	// 82211138: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8221113C: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 82211140: 48000548  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211144 => {
    //   block [0x82211144..0x82211168)
	// 82211144: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211148: 419AFFA8  beq cr6, 0x822110f0
	if ctx.cr[6].eq {
	pc = 0x822110F0; continue 'dispatch;
	}
	// 8221114C: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 82211150: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211154: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211158: 4BFFC999  bl 0x8220daf0
	ctx.lr = 0x8221115C;
	sub_8220DAF0(ctx, base);
	// 8221115C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211160: 3B390070  addi r25, r25, 0x70
	ctx.r[25].s64 = ctx.r[25].s64 + 112;
	// 82211164: 48000524  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211168 => {
    //   block [0x82211168..0x8221122C)
	// 82211168: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 8221116C: 419A0014  beq cr6, 0x82211180
	if ctx.cr[6].eq {
	pc = 0x82211180; continue 'dispatch;
	}
	// 82211170: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211174: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211178: 48010C51  bl 0x82221dc8
	ctx.lr = 0x8221117C;
	sub_82221DC8(ctx, base);
	// 8221117C: 48000008  b 0x82211184
	pc = 0x82211184; continue 'dispatch;
	// 82211180: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 82211184: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 82211188: 39210094  addi r9, r1, 0x94
	ctx.r[9].s64 = ctx.r[1].s64 + 148;
	// 8221118C: 39010090  addi r8, r1, 0x90
	ctx.r[8].s64 = ctx.r[1].s64 + 144;
	// 82211190: 556B183E  rotlwi r11, r11, 3
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(3)) as u64;
	// 82211194: 3B390260  addi r25, r25, 0x260
	ctx.r[25].s64 = ctx.r[25].s64 + 608;
	// 82211198: 7E2A8B78  mr r10, r17
	ctx.r[10].u64 = ctx.r[17].u64;
	// 8221119C: 7C6B492E  stwx r3, r11, r9
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), ctx.r[3].u32) };
	// 822111A0: 7F0B432E  sthx r24, r11, r8
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), ctx.r[24].u16) };
	// 822111A4: A16300A4  lhz r11, 0xa4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(164 as u32) ) } as u64;
	// 822111A8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 822111AC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 822111B0: 40990034  ble cr6, 0x822111e4
	if !ctx.cr[6].gt {
	pc = 0x822111E4; continue 'dispatch;
	}
	// 822111B4: 396300A8  addi r11, r3, 0xa8
	ctx.r[11].s64 = ctx.r[3].s64 + 168;
	// 822111B8: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822111BC: 39011890  addi r8, r1, 0x1890
	ctx.r[8].s64 = ctx.r[1].s64 + 6288;
	// 822111C0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 822111C4: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 822111C8: 7D29402E  lwzx r9, r9, r8
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 822111CC: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 822111D0: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 822111D4: A12300A4  lhz r9, 0xa4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(164 as u32) ) } as u64;
	// 822111D8: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 822111DC: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 822111E0: 4198FFD8  blt cr6, 0x822111b8
	if ctx.cr[6].lt {
	pc = 0x822111B8; continue 'dispatch;
	}
	// 822111E4: A16300A6  lhz r11, 0xa6(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(166 as u32) ) } as u64;
	// 822111E8: 7E2A8B78  mr r10, r17
	ctx.r[10].u64 = ctx.r[17].u64;
	// 822111EC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 822111F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 822111F4: 409904F8  ble cr6, 0x822116ec
	if !ctx.cr[6].gt {
	pc = 0x822116EC; continue 'dispatch;
	}
	// 822111F8: 39630120  addi r11, r3, 0x120
	ctx.r[11].s64 = ctx.r[3].s64 + 288;
	// 822111FC: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211200: 39011890  addi r8, r1, 0x1890
	ctx.r[8].s64 = ctx.r[1].s64 + 6288;
	// 82211204: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82211208: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221120C: 7D29402E  lwzx r9, r9, r8
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 82211210: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82211214: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 82211218: A12300A6  lhz r9, 0xa6(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(166 as u32) ) } as u64;
	// 8221121C: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82211220: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82211224: 4198FFD8  blt cr6, 0x822111fc
	if ctx.cr[6].lt {
	pc = 0x822111FC; continue 'dispatch;
	}
	// 82211228: 480004C4  b 0x822116ec
	pc = 0x822116EC; continue 'dispatch;
            }
            0x8221122C => {
    //   block [0x8221122C..0x822112F8)
	// 8221122C: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 82211230: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211234: 396BFFC4  addi r11, r11, -0x3c
	ctx.r[11].s64 = ctx.r[11].s64 + -60;
	// 82211238: 392B0010  addi r9, r11, 0x10
	ctx.r[9].s64 = ctx.r[11].s64 + 16;
	// 8221123C: 556A2036  slwi r10, r11, 4
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82211240: 55292036  slwi r9, r9, 4
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82211244: 7D4A8214  add r10, r10, r16
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[16].u64;
	// 82211248: 396B00CC  addi r11, r11, 0xcc
	ctx.r[11].s64 = ctx.r[11].s64 + 204;
	// 8221124C: 5568103A  slwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82211250: 7C09852E  stfsx f0, r9, r16
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[16].u32), tmp.u32) };
	// 82211254: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211258: D00A0104  stfs f0, 0x104(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 8221125C: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211260: D00A0108  stfs f0, 0x108(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 82211264: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 82211268: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8221126C: 7D68812E  stwx r11, r8, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[16].u32), ctx.r[11].u32) };
	// 82211270: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 82211274: 2F0B0041  cmpwi cr6, r11, 0x41
	ctx.cr[6].compare_i32(ctx.r[11].s32, 65, &mut ctx.xer);
	// 82211278: 419A002C  beq cr6, 0x822112a4
	if ctx.cr[6].eq {
	pc = 0x822112A4; continue 'dispatch;
	}
	// 8221127C: 2F0B004D  cmpwi cr6, r11, 0x4d
	ctx.cr[6].compare_i32(ctx.r[11].s32, 77, &mut ctx.xer);
	// 82211280: 419A0024  beq cr6, 0x822112a4
	if ctx.cr[6].eq {
	pc = 0x822112A4; continue 'dispatch;
	}
	// 82211284: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211288: 419A0090  beq cr6, 0x82211318
	if ctx.cr[6].eq {
	pc = 0x82211318; continue 'dispatch;
	}
	// 8221128C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211290: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211294: 4BFFCEF5  bl 0x8220e188
	ctx.lr = 0x82211298;
	sub_8220E188(ctx, base);
	// 82211298: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8221129C: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 822112A0: 480003E8  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822112A4: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822112A8: 419A0018  beq cr6, 0x822112c0
	if ctx.cr[6].eq {
	pc = 0x822112C0; continue 'dispatch;
	}
	// 822112AC: 7DE57B78  mr r5, r15
	ctx.r[5].u64 = ctx.r[15].u64;
	// 822112B0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822112B4: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822112B8: 4BFFCB11  bl 0x8220ddc8
	ctx.lr = 0x822112BC;
	sub_8220DDC8(ctx, base);
	// 822112BC: 48000008  b 0x822112c4
	pc = 0x822112C4; continue 'dispatch;
	// 822112C0: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 822112C4: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 822112C8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822112CC: 2B0B0041  cmplwi cr6, r11, 0x41
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65 as u32, &mut ctx.xer);
	// 822112D0: 39630040  addi r11, r3, 0x40
	ctx.r[11].s64 = ctx.r[3].s64 + 64;
	// 822112D4: 409A0014  bne cr6, 0x822112e8
	if !ctx.cr[6].eq {
	pc = 0x822112E8; continue 'dispatch;
	}
	// 822112D8: 91700448  stw r11, 0x448(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(1096 as u32), ctx.r[11].u32 ) };
	// 822112DC: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 822112E0: 90700450  stw r3, 0x450(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(1104 as u32), ctx.r[3].u32 ) };
	// 822112E4: 480003A4  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822112E8: 9170044C  stw r11, 0x44c(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(1100 as u32), ctx.r[11].u32 ) };
	// 822112EC: 3B390060  addi r25, r25, 0x60
	ctx.r[25].s64 = ctx.r[25].s64 + 96;
	// 822112F0: 90700454  stw r3, 0x454(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(1108 as u32), ctx.r[3].u32 ) };
	// 822112F4: 48000394  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822112F8 => {
    //   block [0x822112F8..0x82211324)
	// 822112F8: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822112FC: 419A001C  beq cr6, 0x82211318
	if ctx.cr[6].eq {
	pc = 0x82211318; continue 'dispatch;
	}
	// 82211300: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211304: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211308: 4BFFC0A1  bl 0x8220d3a8
	ctx.lr = 0x8221130C;
	sub_8220D3A8(ctx, base);
	// 8221130C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211310: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 82211314: 48000374  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 82211318: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 8221131C: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 82211320: 48000368  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211324 => {
    //   block [0x82211324..0x82211370)
	// 82211324: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211328: 419A0020  beq cr6, 0x82211348
	if ctx.cr[6].eq {
	pc = 0x82211348; continue 'dispatch;
	}
	// 8221132C: 7DE67B78  mr r6, r15
	ctx.r[6].u64 = ctx.r[15].u64;
	// 82211330: 7E459378  mr r5, r18
	ctx.r[5].u64 = ctx.r[18].u64;
	// 82211334: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211338: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 8221133C: 4800D5E5  bl 0x8221e920
	ctx.lr = 0x82211340;
	sub_8221E920(ctx, base);
	// 82211340: 3A520001  addi r18, r18, 1
	ctx.r[18].s64 = ctx.r[18].s64 + 1;
	// 82211344: 48000008  b 0x8221134c
	pc = 0x8221134C; continue 'dispatch;
	// 82211348: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 8221134C: A17F004E  lhz r11, 0x4e(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 82211350: 39410094  addi r10, r1, 0x94
	ctx.r[10].s64 = ctx.r[1].s64 + 148;
	// 82211354: 39210090  addi r9, r1, 0x90
	ctx.r[9].s64 = ctx.r[1].s64 + 144;
	// 82211358: 556B183E  rotlwi r11, r11, 3
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(3)) as u64;
	// 8221135C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211360: 3B3900E0  addi r25, r25, 0xe0
	ctx.r[25].s64 = ctx.r[25].s64 + 224;
	// 82211364: 7C6B512E  stwx r3, r11, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[3].u32) };
	// 82211368: 7EEB4B2E  sthx r23, r11, r9
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), ctx.r[23].u16) };
	// 8221136C: 4800031C  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211370 => {
    //   block [0x82211370..0x82211390)
	// 82211370: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211374: 419AFFA4  beq cr6, 0x82211318
	if ctx.cr[6].eq {
	pc = 0x82211318; continue 'dispatch;
	}
	// 82211378: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221137C: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211380: 4BFFCFC1  bl 0x8220e340
	ctx.lr = 0x82211384;
	sub_8220E340(ctx, base);
	// 82211384: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211388: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 8221138C: 480002FC  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211390 => {
    //   block [0x82211390..0x822113B0)
	// 82211390: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211394: 419AFF84  beq cr6, 0x82211318
	if ctx.cr[6].eq {
	pc = 0x82211318; continue 'dispatch;
	}
	// 82211398: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221139C: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822113A0: 4BFFD1A9  bl 0x8220e548
	ctx.lr = 0x822113A4;
	sub_8220E548(ctx, base);
	// 822113A4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822113A8: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 822113AC: 480002DC  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822113B0 => {
    //   block [0x822113B0..0x822113D0)
	// 822113B0: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822113B4: 419AFF64  beq cr6, 0x82211318
	if ctx.cr[6].eq {
	pc = 0x82211318; continue 'dispatch;
	}
	// 822113B8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822113BC: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822113C0: 4BFFD409  bl 0x8220e7c8
	ctx.lr = 0x822113C4;
	sub_8220E7C8(ctx, base);
	// 822113C4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822113C8: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 822113CC: 480002BC  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x822113D0 => {
    //   block [0x822113D0..0x82211418)
	// 822113D0: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822113D4: 419A0018  beq cr6, 0x822113ec
	if ctx.cr[6].eq {
	pc = 0x822113EC; continue 'dispatch;
	}
	// 822113D8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822113DC: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 822113E0: 4BFFD571  bl 0x8220e950
	ctx.lr = 0x822113E4;
	sub_8220E950(ctx, base);
	// 822113E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822113E8: 48000008  b 0x822113f0
	pc = 0x822113F0; continue 'dispatch;
	// 822113EC: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 822113F0: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 822113F4: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 822113F8: 2B0B0015  cmplwi cr6, r11, 0x15
	ctx.cr[6].compare_u32(ctx.r[11].u32, 21 as u32, &mut ctx.xer);
	// 822113FC: 409A000C  bne cr6, 0x82211408
	if !ctx.cr[6].eq {
	pc = 0x82211408; continue 'dispatch;
	}
	// 82211400: 93D0002C  stw r30, 0x2c(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(44 as u32), ctx.r[30].u32 ) };
	// 82211404: 48000284  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 82211408: 2B0B0016  cmplwi cr6, r11, 0x16
	ctx.cr[6].compare_u32(ctx.r[11].u32, 22 as u32, &mut ctx.xer);
	// 8221140C: 409A027C  bne cr6, 0x82211688
	if !ctx.cr[6].eq {
	pc = 0x82211688; continue 'dispatch;
	}
	// 82211410: 93D00030  stw r30, 0x30(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(48 as u32), ctx.r[30].u32 ) };
	// 82211414: 48000274  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211418 => {
    //   block [0x82211418..0x82211534)
	// 82211418: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 8221141C: 419A0018  beq cr6, 0x82211434
	if ctx.cr[6].eq {
	pc = 0x82211434; continue 'dispatch;
	}
	// 82211420: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211424: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211428: 4BFFD8C1  bl 0x8220ece8
	ctx.lr = 0x8221142C;
	sub_8220ECE8(ctx, base);
	// 8221142C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211430: 48000008  b 0x82211438
	pc = 0x82211438; continue 'dispatch;
	// 82211434: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 82211438: 57AB103A  slwi r11, r29, 2
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221143C: 39411092  addi r10, r1, 0x1092
	ctx.r[10].s64 = ctx.r[1].s64 + 4242;
	// 82211440: 39211092  addi r9, r1, 0x1092
	ctx.r[9].s64 = ctx.r[1].s64 + 4242;
	// 82211444: 39011090  addi r8, r1, 0x1090
	ctx.r[8].s64 = ctx.r[1].s64 + 4240;
	// 82211448: 3B390050  addi r25, r25, 0x50
	ctx.r[25].s64 = ctx.r[25].s64 + 80;
	// 8221144C: 7D6B522E  lhzx r11, r11, r10
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82211450: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82211454: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82211458: 7D6B4A2E  lhzx r11, r11, r9
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8221145C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82211460: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82211464: 7D6B422E  lhzx r11, r11, r8
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 82211468: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221146C: 2F0B0015  cmpwi cr6, r11, 0x15
	ctx.cr[6].compare_i32(ctx.r[11].s32, 21, &mut ctx.xer);
	// 82211470: 409A003C  bne cr6, 0x822114ac
	if !ctx.cr[6].eq {
	pc = 0x822114AC; continue 'dispatch;
	}
	// 82211474: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 82211478: 39500034  addi r10, r16, 0x34
	ctx.r[10].s64 = ctx.r[16].s64 + 52;
	// 8221147C: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211480: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82211484: 419A0018  beq cr6, 0x8221149c
	if ctx.cr[6].eq {
	pc = 0x8221149C; continue 'dispatch;
	}
	// 82211488: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8221148C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82211490: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 82211494: 4198FFE8  blt cr6, 0x8221147c
	if ctx.cr[6].lt {
	pc = 0x8221147C; continue 'dispatch;
	}
	// 82211498: 480001F0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 8221149C: 396B000D  addi r11, r11, 0xd
	ctx.r[11].s64 = ctx.r[11].s64 + 13;
	// 822114A0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822114A4: 7FCB812E  stwx r30, r11, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[16].u32), ctx.r[30].u32) };
	// 822114A8: 480001E0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822114AC: 2F0B0016  cmpwi cr6, r11, 0x16
	ctx.cr[6].compare_i32(ctx.r[11].s32, 22, &mut ctx.xer);
	// 822114B0: 409A003C  bne cr6, 0x822114ec
	if !ctx.cr[6].eq {
	pc = 0x822114EC; continue 'dispatch;
	}
	// 822114B4: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 822114B8: 39500054  addi r10, r16, 0x54
	ctx.r[10].s64 = ctx.r[16].s64 + 84;
	// 822114BC: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822114C0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 822114C4: 419A0018  beq cr6, 0x822114dc
	if ctx.cr[6].eq {
	pc = 0x822114DC; continue 'dispatch;
	}
	// 822114C8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 822114CC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 822114D0: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 822114D4: 4198FFE8  blt cr6, 0x822114bc
	if ctx.cr[6].lt {
	pc = 0x822114BC; continue 'dispatch;
	}
	// 822114D8: 480001B0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822114DC: 396B0015  addi r11, r11, 0x15
	ctx.r[11].s64 = ctx.r[11].s64 + 21;
	// 822114E0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822114E4: 7FCB812E  stwx r30, r11, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[16].u32), ctx.r[30].u32) };
	// 822114E8: 480001A0  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 822114EC: A17F004C  lhz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 822114F0: 2B0B0015  cmplwi cr6, r11, 0x15
	ctx.cr[6].compare_u32(ctx.r[11].u32, 21 as u32, &mut ctx.xer);
	// 822114F4: 409A0194  bne cr6, 0x82211688
	if !ctx.cr[6].eq {
	pc = 0x82211688; continue 'dispatch;
	}
	// 822114F8: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 822114FC: 39500034  addi r10, r16, 0x34
	ctx.r[10].s64 = ctx.r[16].s64 + 52;
	// 82211500: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211504: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82211508: 419A0018  beq cr6, 0x82211520
	if ctx.cr[6].eq {
	pc = 0x82211520; continue 'dispatch;
	}
	// 8221150C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82211510: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82211514: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 82211518: 4198FFE8  blt cr6, 0x82211500
	if ctx.cr[6].lt {
	pc = 0x82211500; continue 'dispatch;
	}
	// 8221151C: 4800016C  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
	// 82211520: 396B000D  addi r11, r11, 0xd
	ctx.r[11].s64 = ctx.r[11].s64 + 13;
	// 82211524: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82211528: 7FCB812E  stwx r30, r11, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[16].u32), ctx.r[30].u32) };
	// 8221152C: B1DE004C  sth r14, 0x4c(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(76 as u32), ctx.r[14].u16 ) };
	// 82211530: 48000158  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211534 => {
    //   block [0x82211534..0x82211578)
	// 82211534: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 82211538: 419A0018  beq cr6, 0x82211550
	if ctx.cr[6].eq {
	pc = 0x82211550; continue 'dispatch;
	}
	// 8221153C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211540: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211544: 4BFFDC65  bl 0x8220f1a8
	ctx.lr = 0x82211548;
	sub_8220F1A8(ctx, base);
	// 82211548: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8221154C: 48000008  b 0x82211554
	pc = 0x82211554; continue 'dispatch;
	// 82211550: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 82211554: 817F0030  lwz r11, 0x30(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 82211558: 3B3900C0  addi r25, r25, 0xc0
	ctx.r[25].s64 = ctx.r[25].s64 + 192;
	// 8221155C: 394BFFFF  addi r10, r11, -1
	ctx.r[10].s64 = ctx.r[11].s64 + -1;
	// 82211560: 2B0A0008  cmplwi cr6, r10, 8
	ctx.cr[6].compare_u32(ctx.r[10].u32, 8 as u32, &mut ctx.xer);
	// 82211564: 40980124  bge cr6, 0x82211688
	if !ctx.cr[6].lt {
	pc = 0x82211688; continue 'dispatch;
	}
	// 82211568: 396B001C  addi r11, r11, 0x1c
	ctx.r[11].s64 = ctx.r[11].s64 + 28;
	// 8221156C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82211570: 7FCB812E  stwx r30, r11, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[16].u32), ctx.r[30].u32) };
	// 82211574: 48000114  b 0x82211688
	pc = 0x82211688; continue 'dispatch;
            }
            0x82211578 => {
    //   block [0x82211578..0x822116EC)
	// 82211578: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 8221157C: 419A0018  beq cr6, 0x82211594
	if ctx.cr[6].eq {
	pc = 0x82211594; continue 'dispatch;
	}
	// 82211580: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82211584: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82211588: 4BFFEF21  bl 0x822104a8
	ctx.lr = 0x8221158C;
	sub_822104A8(ctx, base);
	// 8221158C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82211590: 48000008  b 0x82211598
	pc = 0x82211598; continue 'dispatch;
	// 82211594: 7E3E8B78  mr r30, r17
	ctx.r[30].u64 = ctx.r[17].u64;
	// 82211598: 817F0030  lwz r11, 0x30(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 8221159C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 822115A0: 7DE37B78  mr r3, r15
	ctx.r[3].u64 = ctx.r[15].u64;
	// 822115A4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 822115A8: 3B390100  addi r25, r25, 0x100
	ctx.r[25].s64 = ctx.r[25].s64 + 256;
	// 822115AC: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 822115B0: 396B0025  addi r11, r11, 0x25
	ctx.r[11].s64 = ctx.r[11].s64 + 37;
	// 822115B4: 557D103A  slwi r29, r11, 2
	ctx.r[29].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 822115B8: 7FDD812E  stwx r30, r29, r16
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[16].u32), ctx.r[30].u32) };
	// 822115BC: A09F004E  lhz r4, 0x4e(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(78 as u32) ) } as u64;
	// 822115C0: 4BFFF359  bl 0x82210918
	ctx.lr = 0x822115C4;
	sub_82210918(ctx, base);
	// 822115C4: 7D7D802E  lwzx r11, r29, r16
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[16].u32)) } as u64;
	// 822115C8: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 822115CC: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 822115D0: 394B0010  addi r10, r11, 0x10
	ctx.r[10].s64 = ctx.r[11].s64 + 16;
	// 822115D4: 392B0020  addi r9, r11, 0x20
	ctx.r[9].s64 = ctx.r[11].s64 + 32;
            }
            0x822116EC => {
    //   block [0x822116EC..0x82211BB4)
	// 822116EC: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 822116F0: 7F3B9800  cmpd cr6, r27, r19
	ctx.cr[6].compare_i64(ctx.r[27].s64, ctx.r[19].s64, &mut ctx.xer);
	// 822116F4: 4198F86C  blt cr6, 0x82210f60
	if ctx.cr[6].lt {
	pc = 0x82210F60; continue 'dispatch;
	}
	// 822116F8: 83A12164  lwz r29, 0x2164(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(8548 as u32) ) } as u64;
	// 822116FC: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82211700: 4098000C  bge cr6, 0x8221170c
	if !ctx.cr[6].lt {
	pc = 0x8221170C; continue 'dispatch;
	}
	// 82211704: 7E3D8B78  mr r29, r17
	ctx.r[29].u64 = ctx.r[17].u64;
	// 82211708: 4800000C  b 0x82211714
	pc = 0x82211714; continue 'dispatch;
	// 8221170C: A1700002  lhz r11, 2(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[16].u32.wrapping_add(2 as u32) ) } as u64;
	// 82211710: 7D7D0734  extsh r29, r11
	ctx.r[29].s64 = ctx.r[11].s16 as i64;
	// 82211714: 7FB7EB78  mr r23, r29
	ctx.r[23].u64 = ctx.r[29].u64;
	// 82211718: 3BE10094  addi r31, r1, 0x94
	ctx.r[31].s64 = ctx.r[1].s64 + 148;
	// 8221171C: 3BC00200  li r30, 0x200
	ctx.r[30].s64 = 512;
	// 82211720: A17FFFFC  lhz r11, -4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82211724: 2B0B000B  cmplwi cr6, r11, 0xb
	ctx.cr[6].compare_u32(ctx.r[11].u32, 11 as u32, &mut ctx.xer);
	// 82211728: 409A00E8  bne cr6, 0x82211810
	if !ctx.cr[6].eq {
	pc = 0x82211810; continue 'dispatch;
	}
	// 8221172C: A17FFFFE  lhz r11, -2(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(-2 as u32) ) } as u64;
	// 82211730: 7EE6BB78  mr r6, r23
	ctx.r[6].u64 = ctx.r[23].u64;
	// 82211734: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82211738: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221173C: 4198000C  blt cr6, 0x82211748
	if ctx.cr[6].lt {
	pc = 0x82211748; continue 'dispatch;
	}
	// 82211740: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 82211744: 48000084  b 0x822117c8
	pc = 0x822117C8; continue 'dispatch;
	// 82211748: 81612164  lwz r11, 0x2164(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(8548 as u32) ) } as u64;
	// 8221174C: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 82211750: 409A0150  bne cr6, 0x822118a0
	if !ctx.cr[6].eq {
	pc = 0x822118A0; continue 'dispatch;
	}
	// 82211754: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211758: A14B0022  lhz r10, 0x22(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(34 as u32) ) } as u64;
	// 8221175C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82211760: 2F0A001E  cmpwi cr6, r10, 0x1e
	ctx.cr[6].compare_i32(ctx.r[10].s32, 30, &mut ctx.xer);
	// 82211764: 4098013C  bge cr6, 0x822118a0
	if !ctx.cr[6].lt {
	pc = 0x822118A0; continue 'dispatch;
	}
	// 82211768: A12B00A4  lhz r9, 0xa4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(164 as u32) ) } as u64;
	// 8221176C: 7E2A8B78  mr r10, r17
	ctx.r[10].u64 = ctx.r[17].u64;
	// 82211770: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82211774: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82211778: 40990044  ble cr6, 0x822117bc
	if !ctx.cr[6].gt {
	pc = 0x822117BC; continue 'dispatch;
	}
	// 8221177C: 396B00A8  addi r11, r11, 0xa8
	ctx.r[11].s64 = ctx.r[11].s64 + 168;
	// 82211780: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211784: 2B0901FF  cmplwi cr6, r9, 0x1ff
	ctx.cr[6].compare_u32(ctx.r[9].u32, 511 as u32, &mut ctx.xer);
	// 82211788: 41990018  bgt cr6, 0x822117a0
	if ctx.cr[6].gt {
	pc = 0x822117A0; continue 'dispatch;
	}
	// 8221178C: 55281838  slwi r8, r9, 3
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82211790: 38E10092  addi r7, r1, 0x92
	ctx.r[7].s64 = ctx.r[1].s64 + 146;
	// 82211794: 7D083A2E  lhzx r8, r8, r7
	ctx.r[8].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 82211798: 2B088000  cmplwi cr6, r8, 0x8000
	ctx.cr[6].compare_u32(ctx.r[8].u32, 32768 as u32, &mut ctx.xer);
	// 8221179C: 419800EC  blt cr6, 0x82211888
	if ctx.cr[6].lt {
	pc = 0x82211888; continue 'dispatch;
	}
	// 822117A0: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822117A4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 822117A8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 822117AC: A12900A4  lhz r9, 0xa4(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(164 as u32) ) } as u64;
	// 822117B0: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 822117B4: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 822117B8: 4198FFC8  blt cr6, 0x82211780
	if ctx.cr[6].lt {
	pc = 0x82211780; continue 'dispatch;
	}
	// 822117BC: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 822117C0: 3AF70001  addi r23, r23, 1
	ctx.r[23].s64 = ctx.r[23].s64 + 1;
	// 822117C4: B17FFFFE  sth r11, -2(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(-2 as u32), ctx.r[11].u16 ) };
	// 822117C8: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822117CC: 38A00200  li r5, 0x200
	ctx.r[5].s64 = 512;
	// 822117D0: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 822117D4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 822117D8: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822117DC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 822117E0: 4E800421  bctrl
	ctx.lr = 0x822117E4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 822117E4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822117E8: 39210090  addi r9, r1, 0x90
	ctx.r[9].s64 = ctx.r[1].s64 + 144;
	// 822117EC: A14B0022  lhz r10, 0x22(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(34 as u32) ) } as u64;
	// 822117F0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 822117F4: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822117F8: 7D2A4A2E  lhzx r9, r10, r9
	ctx.r[9].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 822117FC: 2B09000B  cmplwi cr6, r9, 0xb
	ctx.cr[6].compare_u32(ctx.r[9].u32, 11 as u32, &mut ctx.xer);
	// 82211800: 409A0010  bne cr6, 0x82211810
	if !ctx.cr[6].eq {
	pc = 0x82211810; continue 'dispatch;
	}
	// 82211804: 39210094  addi r9, r1, 0x94
	ctx.r[9].s64 = ctx.r[1].s64 + 148;
	// 82211808: 7D4A482E  lwzx r10, r10, r9
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8221180C: 914B0040  stw r10, 0x40(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(64 as u32), ctx.r[10].u32 ) };
	// 82211810: 3BDEFFFF  addi r30, r30, -1
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	// 82211814: 3BFF0008  addi r31, r31, 8
	ctx.r[31].s64 = ctx.r[31].s64 + 8;
	// 82211818: 2B3E0000  cmpldi cr6, r30, 0
	ctx.cr[6].compare_u64(ctx.r[30].u64, 0, &mut ctx.xer);
	// 8221181C: 4199FF04  bgt cr6, 0x82211720
	if ctx.cr[6].gt {
	pc = 0x82211720; continue 'dispatch;
	}
	// 82211820: 7F1DB850  subf r24, r29, r23
	ctx.r[24].s64 = ctx.r[23].s64 - ctx.r[29].s64;
	// 82211824: 7F17E800  cmpw cr6, r23, r29
	ctx.cr[6].compare_i32(ctx.r[23].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82211828: 40990328  ble cr6, 0x82211b50
	if !ctx.cr[6].gt {
	pc = 0x82211B50; continue 'dispatch;
	}
	// 8221182C: 82612164  lwz r19, 0x2164(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(8548 as u32) ) } as u64;
	// 82211830: 2F130000  cmpwi cr6, r19, 0
	ctx.cr[6].compare_i32(ctx.r[19].s32, 0, &mut ctx.xer);
	// 82211834: 409800B8  bge cr6, 0x822118ec
	if !ctx.cr[6].lt {
	pc = 0x822118EC; continue 'dispatch;
	}
	// 82211838: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 8221183C: 419A00A4  beq cr6, 0x822118e0
	if ctx.cr[6].eq {
	pc = 0x822118E0; continue 'dispatch;
	}
	// 82211840: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 82211844: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 82211848: 92390040  stw r17, 0x40(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(64 as u32), ctx.r[17].u32 ) };
	// 8221184C: 92390044  stw r17, 0x44(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(68 as u32), ctx.r[17].u32 ) };
	// 82211850: 9A390048  stb r17, 0x48(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(72 as u32), ctx.r[17].u8 ) };
	// 82211854: 9A390049  stb r17, 0x49(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(73 as u32), ctx.r[17].u8 ) };
	// 82211858: 9A39004A  stb r17, 0x4a(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(74 as u32), ctx.r[17].u8 ) };
	// 8221185C: 9A39004B  stb r17, 0x4b(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(75 as u32), ctx.r[17].u8 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82211BB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82211BB8 size=880
    let mut pc: u32 = 0x82211BB8;
    'dispatch: loop {
        match pc {
            0x82211BB8 => {
    //   block [0x82211BB8..0x82211F28)
	// 82211BB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82211BBC: 483234FD  bl 0x825350b8
	ctx.lr = 0x82211BC0;
	sub_82535080(ctx, base);
	// 82211BC0: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 82211BC4: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82211BC8: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82211BCC: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82211BD0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82211BD4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82211BD8: C01C0000  lfs f0, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211BDC: C1BC0004  lfs f13, 4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211BE0: 83DF0008  lwz r30, 8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82211BE4: C19C0008  lfs f12, 8(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82211BE8: C17C000C  lfs f11, 0xc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82211BEC: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82211BF0: C15F00D8  lfs f10, 0xd8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(216 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82211BF4: EC0007F2  fmuls f0, f0, f31
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211BF8: C13F00DC  lfs f9, 0xdc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(220 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82211BFC: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211C00: C11F00E0  lfs f8, 0xe0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(224 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82211C04: ED8C07F2  fmuls f12, f12, f31
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211C08: C0FF00E4  lfs f7, 0xe4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(228 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82211C0C: ED6B07F2  fmuls f11, f11, f31
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211C10: EC005024  fdivs f0, f0, f10
	ctx.f[0].f64 = ((ctx.f[0].f64 / ctx.f[10].f64) as f32) as f64;
	// 82211C14: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82211C18: EC0D4824  fdivs f0, f13, f9
	ctx.f[0].f64 = ((ctx.f[13].f64 / ctx.f[9].f64) as f32) as f64;
	// 82211C1C: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82211C20: EC0C4024  fdivs f0, f12, f8
	ctx.f[0].f64 = ((ctx.f[12].f64 / ctx.f[8].f64) as f32) as f64;
	// 82211C24: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82211C28: EC0B3824  fdivs f0, f11, f7
	ctx.f[0].f64 = ((ctx.f[11].f64 / ctx.f[7].f64) as f32) as f64;
	// 82211C2C: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82211C30: 419A0030  beq cr6, 0x82211c60
	if ctx.cr[6].eq {
	pc = 0x82211C60; continue 'dispatch;
	}
	// 82211C34: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211C38: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 82211C3C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82211C40: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82211C44: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82211C48: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82211C4C: 4E800421  bctrl
	ctx.lr = 0x82211C50;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82211C50: 83DE0024  lwz r30, 0x24(r30)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 82211C54: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82211C58: 409AFFDC  bne cr6, 0x82211c34
	if !ctx.cr[6].eq {
	pc = 0x82211C34; continue 'dispatch;
	}
	// 82211C5C: C001005C  lfs f0, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211C60: 83DF0010  lwz r30, 0x10(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82211C64: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82211C68: 419A002C  beq cr6, 0x82211c94
	if ctx.cr[6].eq {
	pc = 0x82211C94; continue 'dispatch;
	}
	// 82211C6C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211C70: C0210054  lfs f1, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82211C74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82211C78: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82211C7C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82211C80: 4E800421  bctrl
	ctx.lr = 0x82211C84;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82211C84: 83DE0024  lwz r30, 0x24(r30)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 82211C88: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82211C8C: 409AFFE0  bne cr6, 0x82211c6c
	if !ctx.cr[6].eq {
	pc = 0x82211C6C; continue 'dispatch;
	}
	// 82211C90: C001005C  lfs f0, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211C94: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82211C98: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82211C9C: 419A008C  beq cr6, 0x82211d28
	if ctx.cr[6].eq {
	pc = 0x82211D28; continue 'dispatch;
	}
	// 82211CA0: 816A0044  lwz r11, 0x44(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(68 as u32) ) } as u64;
	// 82211CA4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82211CA8: 419A0070  beq cr6, 0x82211d18
	if ctx.cr[6].eq {
	pc = 0x82211D18; continue 'dispatch;
	}
	// 82211CAC: A12B0020  lhz r9, 0x20(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 82211CB0: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82211CB4: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211CB8: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82211CBC: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82211CC0: C18B0014  lfs f12, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82211CC4: C16B0018  lfs f11, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82211CC8: 7D29E8AE  lbzx r9, r9, r29
	ctx.r[9].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82211CCC: 5529103E  rotlwi r9, r9, 2
	ctx.r[9].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 82211CD0: 7C09442E  lfsx f0, r9, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211CD4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211CD8: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82211CDC: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211CE0: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82211CE4: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211CE8: D00B0018  stfs f0, 0x18(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82211CEC: A12B0020  lhz r9, 0x20(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 82211CF0: C00B00A0  lfs f0, 0xa0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211CF4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82211CF8: 7D29E8AE  lbzx r9, r9, r29
	ctx.r[9].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82211CFC: 5529103E  rotlwi r9, r9, 2
	ctx.r[9].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 82211D00: 7DA93C2E  lfsx f13, r9, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D04: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211D08: D00B00A0  stfs f0, 0xa0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 82211D0C: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 82211D10: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82211D14: 409AFF98  bne cr6, 0x82211cac
	if !ctx.cr[6].eq {
	pc = 0x82211CAC; continue 'dispatch;
	}
	// 82211D18: 814A0040  lwz r10, 0x40(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 82211D1C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82211D20: 409AFF80  bne cr6, 0x82211ca0
	if !ctx.cr[6].eq {
	pc = 0x82211CA0; continue 'dispatch;
	}
	// 82211D24: C001005C  lfs f0, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82211D28: C1BC0000  lfs f13, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D2C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82211D30: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211D34: D1BF00D8  stfs f13, 0xd8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 82211D38: C1BC0004  lfs f13, 4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D3C: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211D40: D1BF00DC  stfs f13, 0xdc(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 82211D44: C1BC0008  lfs f13, 8(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D48: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211D4C: D1BF00E0  stfs f13, 0xe0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 82211D50: C1BC000C  lfs f13, 0xc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D54: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211D58: D1BF00E4  stfs f13, 0xe4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 82211D5C: C1BC000C  lfs f13, 0xc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D60: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82211D64: D1BF2164  stfs f13, 0x2164(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8548 as u32), tmp.u32 ) };
	// 82211D68: 552A003E  slwi r10, r9, 0
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82211D6C: 39290007  addi r9, r9, 7
	ctx.r[9].s64 = ctx.r[9].s64 + 7;
	// 82211D70: 396A0010  addi r11, r10, 0x10
	ctx.r[11].s64 = ctx.r[10].s64 + 16;
	// 82211D74: 390A0011  addi r8, r10, 0x11
	ctx.r[8].s64 = ctx.r[10].s64 + 17;
	// 82211D78: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82211D7C: 55052036  slwi r5, r8, 4
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82211D80: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82211D84: 390A0012  addi r8, r10, 0x12
	ctx.r[8].s64 = ctx.r[10].s64 + 18;
	// 82211D88: 38EA0013  addi r7, r10, 0x13
	ctx.r[7].s64 = ctx.r[10].s64 + 19;
	// 82211D8C: 55062036  slwi r6, r8, 4
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82211D90: 54E72036  slwi r7, r7, 4
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82211D94: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211D98: 390A0014  addi r8, r10, 0x14
	ctx.r[8].s64 = ctx.r[10].s64 + 20;
	// 82211D9C: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82211DA0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DA4: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82211DA8: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DAC: C14B000C  lfs f10, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82211DB0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DB4: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211DB8: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DBC: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211DC0: 55082036  slwi r8, r8, 4
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82211DC4: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211DC8: D14B000C  stfs f10, 0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211DCC: 7D65FA14  add r11, r5, r31
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[31].u64;
	// 82211DD0: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211DD4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DD8: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211DDC: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211DE0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DE4: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211DE8: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211DEC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DF0: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211DF4: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211DF8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211DFC: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211E00: 7D66FA14  add r11, r6, r31
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[31].u64;
	// 82211E04: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E08: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E0C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211E10: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E14: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E18: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211E1C: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E20: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E24: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211E28: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E2C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E30: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211E34: 7D67FA14  add r11, r7, r31
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[31].u64;
	// 82211E38: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E3C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E40: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211E44: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E48: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E4C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211E50: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E54: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E58: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211E5C: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E60: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E64: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211E68: 7D68FA14  add r11, r8, r31
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 82211E6C: 390A0015  addi r8, r10, 0x15
	ctx.r[8].s64 = ctx.r[10].s64 + 21;
	// 82211E70: 394A0016  addi r10, r10, 0x16
	ctx.r[10].s64 = ctx.r[10].s64 + 22;
	// 82211E74: 55082036  slwi r8, r8, 4
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82211E78: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E7C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E80: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211E84: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E88: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E8C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211E90: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211E94: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211E98: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211E9C: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EA0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EA4: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211EA8: 7D68FA14  add r11, r8, r31
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 82211EAC: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EB0: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82211EB4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EB8: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211EBC: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EC0: 2B290023  cmpldi cr6, r9, 0x23
	ctx.cr[6].compare_u64(ctx.r[9].u64, 35, &mut ctx.xer);
	// 82211EC4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EC8: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211ECC: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211ED0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211ED4: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211ED8: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EDC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EE0: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211EE4: 7D6AFA14  add r11, r10, r31
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[31].u64;
	// 82211EE8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EEC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EF0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82211EF4: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211EF8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211EFC: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82211F00: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211F04: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211F08: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82211F0C: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82211F10: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82211F14: D1AB000C  stfs f13, 0xc(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82211F18: 4198FE50  blt cr6, 0x82211d68
	if ctx.cr[6].lt {
	pc = 0x82211D68; continue 'dispatch;
	}
	// 82211F1C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82211F20: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 82211F24: 483231E4  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82211F28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82211F28 size=36
    let mut pc: u32 = 0x82211F28;
    'dispatch: loop {
        match pc {
            0x82211F28 => {
    //   block [0x82211F28..0x82211F4C)
	// 82211F28: 3963FFE9  addi r11, r3, -0x17
	ctx.r[11].s64 = ctx.r[3].s64 + -23;
	// 82211F2C: 2B0B0008  cmplwi cr6, r11, 8
	ctx.cr[6].compare_u32(ctx.r[11].u32, 8 as u32, &mut ctx.xer);
	// 82211F30: 4199001C  bgt cr6, 0x82211f4c
	if ctx.cr[6].gt {
		sub_82211F4C(ctx, base);
		return;
	}
	// 82211F34: 3943FFE9  addi r10, r3, -0x17
	ctx.r[10].s64 = ctx.r[3].s64 + -23;
	// 82211F38: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 82211F3C: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82211F40: 396B6420  addi r11, r11, 0x6420
	ctx.r[11].s64 = ctx.r[11].s64 + 25632;
	// 82211F44: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82211F48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82211F4C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82211F4C size=52
    let mut pc: u32 = 0x82211F4C;
    'dispatch: loop {
        match pc {
            0x82211F4C => {
    //   block [0x82211F4C..0x82211F80)
	// 82211F4C: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 82211F50: 816B20BC  lwz r11, 0x20bc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8380 as u32) ) } as u64;
	// 82211F54: 7F035800  cmpw cr6, r3, r11
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82211F58: 41980028  blt cr6, 0x82211f80
	if ctx.cr[6].lt {
		sub_82211F80(ctx, base);
		return;
	}
	// 82211F5C: 394B0009  addi r10, r11, 9
	ctx.r[10].s64 = ctx.r[11].s64 + 9;
	// 82211F60: 7F035000  cmpw cr6, r3, r10
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82211F64: 4098001C  bge cr6, 0x82211f80
	if !ctx.cr[6].lt {
		sub_82211F80(ctx, base);
		return;
	}
	// 82211F68: 7D4B1850  subf r10, r11, r3
	ctx.r[10].s64 = ctx.r[3].s64 - ctx.r[11].s64;
	// 82211F6C: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 82211F70: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82211F74: 396B6420  addi r11, r11, 0x6420
	ctx.r[11].s64 = ctx.r[11].s64 + 25632;
	// 82211F78: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82211F7C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82211F80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82211F80 size=12
    let mut pc: u32 = 0x82211F80;
    'dispatch: loop {
        match pc {
            0x82211F80 => {
    //   block [0x82211F80..0x82211F8C)
	// 82211F80: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82211F84: 386B4600  addi r3, r11, 0x4600
	ctx.r[3].s64 = ctx.r[11].s64 + 17920;
	// 82211F88: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82211F90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82211F90 size=200
    let mut pc: u32 = 0x82211F90;
    'dispatch: loop {
        match pc {
            0x82211F90 => {
    //   block [0x82211F90..0x82212058)
	// 82211F90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82211F94: 48323115  bl 0x825350a8
	ctx.lr = 0x82211F98;
	sub_82535080(ctx, base);
	// 82211F98: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82211F9C: 7CB92B78  mr r25, r5
	ctx.r[25].u64 = ctx.r[5].u64;
	// 82211FA0: 3B630094  addi r27, r3, 0x94
	ctx.r[27].s64 = ctx.r[3].s64 + 148;
	// 82211FA4: 3B400010  li r26, 0x10
	ctx.r[26].s64 = 16;
	// 82211FA8: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 82211FAC: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 82211FB0: 83FB0000  lwz r31, 0(r27)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82211FB4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82211FB8: 419A0088  beq cr6, 0x82212040
	if ctx.cr[6].eq {
	pc = 0x82212040; continue 'dispatch;
	}
	// 82211FBC: 817F00C4  lwz r11, 0xc4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 82211FC0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82211FC4: 419A007C  beq cr6, 0x82212040
	if ctx.cr[6].eq {
	pc = 0x82212040; continue 'dispatch;
	}
	// 82211FC8: 817F00CC  lwz r11, 0xcc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82211FCC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82211FD0: 419A0070  beq cr6, 0x82212040
	if ctx.cr[6].eq {
	pc = 0x82212040; continue 'dispatch;
	}
	// 82211FD4: 2F19FFFF  cmpwi cr6, r25, -1
	ctx.cr[6].compare_i32(ctx.r[25].s32, -1, &mut ctx.xer);
	// 82211FD8: 419A0020  beq cr6, 0x82211ff8
	if ctx.cr[6].eq {
	pc = 0x82211FF8; continue 'dispatch;
	}
	// 82211FDC: 817F00C0  lwz r11, 0xc0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 82211FE0: 7F0AC830  slw r10, r24, r25
	if (ctx.r[25].u8 & 0x20) != 0 {
		ctx.r[10].u64 = 0;
	} else {
		ctx.r[10].u64 = ((ctx.r[24].u32) << ((ctx.r[25].u8 & 0x1F) as u32)) as u64;
	}
	// 82211FE4: A16B0030  lhz r11, 0x30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 82211FE8: 7D6B5038  and r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[10].u64;
	// 82211FEC: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 82211FF0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82211FF4: 419A004C  beq cr6, 0x82212040
	if ctx.cr[6].eq {
	pc = 0x82212040; continue 'dispatch;
	}
	// 82211FF8: 480DB139  bl 0x822ed130
	ctx.lr = 0x82211FFC;
	sub_822ED130(ctx, base);
	// 82211FFC: 83DF00D0  lwz r30, 0xd0(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 82212000: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82212004: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 82212008: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221200C: 419A0014  beq cr6, 0x82212020
	if ctx.cr[6].eq {
	pc = 0x82212020; continue 'dispatch;
	}
	// 82212010: 389E0008  addi r4, r30, 8
	ctx.r[4].s64 = ctx.r[30].s64 + 8;
	// 82212014: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82212018: 4827C151  bl 0x8248e168
	ctx.lr = 0x8221201C;
	sub_8248E168(ctx, base);
	// 8221201C: 939E000C  stw r28, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 82212020: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82212024: 809F00CC  lwz r4, 0xcc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82212028: 480DBDD1  bl 0x822eddf8
	ctx.lr = 0x8221202C;
	sub_822EDDF8(ctx, base);
	// 8221202C: 807F00CC  lwz r3, 0xcc(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82212030: 4817B131  bl 0x8238d160
	ctx.lr = 0x82212034;
	sub_8238D160(ctx, base);
	// 82212034: 939F00CC  stw r28, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[28].u32 ) };
	// 82212038: 939F00C4  stw r28, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[28].u32 ) };
	// 8221203C: 939F00C8  stw r28, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[28].u32 ) };
	// 82212040: 3B5AFFFF  addi r26, r26, -1
	ctx.r[26].s64 = ctx.r[26].s64 + -1;
	// 82212044: 3B7B0004  addi r27, r27, 4
	ctx.r[27].s64 = ctx.r[27].s64 + 4;
	// 82212048: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 8221204C: 409AFF64  bne cr6, 0x82211fb0
	if !ctx.cr[6].eq {
	pc = 0x82211FB0; continue 'dispatch;
	}
	// 82212050: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 82212054: 483230A4  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82212058(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82212058 size=176
    let mut pc: u32 = 0x82212058;
    'dispatch: loop {
        match pc {
            0x82212058 => {
    //   block [0x82212058..0x82212108)
	// 82212058: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221205C: 48323051  bl 0x825350ac
	ctx.lr = 0x82212060;
	sub_82535080(ctx, base);
	// 82212060: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82212064: 3B430094  addi r26, r3, 0x94
	ctx.r[26].s64 = ctx.r[3].s64 + 148;
	// 82212068: 3B200010  li r25, 0x10
	ctx.r[25].s64 = 16;
	// 8221206C: 3F608273  lis r27, -0x7d8d
	ctx.r[27].s64 = -2106392576;
	// 82212070: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 82212074: 83FA0000  lwz r31, 0(r26)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82212078: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8221207C: 419A0074  beq cr6, 0x822120f0
	if ctx.cr[6].eq {
	pc = 0x822120F0; continue 'dispatch;
	}
	// 82212080: 817F00CC  lwz r11, 0xcc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82212084: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212088: 419A0068  beq cr6, 0x822120f0
	if ctx.cr[6].eq {
	pc = 0x822120F0; continue 'dispatch;
	}
	// 8221208C: 480DB0A5  bl 0x822ed130
	ctx.lr = 0x82212090;
	sub_822ED130(ctx, base);
	// 82212090: 83DF00D0  lwz r30, 0xd0(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 82212094: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82212098: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 8221209C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822120A0: 419A0014  beq cr6, 0x822120b4
	if ctx.cr[6].eq {
	pc = 0x822120B4; continue 'dispatch;
	}
	// 822120A4: 389E0008  addi r4, r30, 8
	ctx.r[4].s64 = ctx.r[30].s64 + 8;
	// 822120A8: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 822120AC: 4827C0BD  bl 0x8248e168
	ctx.lr = 0x822120B0;
	sub_8248E168(ctx, base);
	// 822120B0: 939E000C  stw r28, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 822120B4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 822120B8: 809F00CC  lwz r4, 0xcc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 822120BC: 480DBD3D  bl 0x822eddf8
	ctx.lr = 0x822120C0;
	sub_822EDDF8(ctx, base);
	// 822120C0: 83DF00CC  lwz r30, 0xcc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 822120C4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 822120C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 822120CC: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822120D0: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822120D4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 822120D8: 4E800421  bctrl
	ctx.lr = 0x822120DC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 822120DC: 817B49B0  lwz r11, 0x49b0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(18864 as u32) ) } as u64;
	// 822120E0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 822120E4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 822120E8: 4E800421  bctrl
	ctx.lr = 0x822120EC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 822120EC: 939F00CC  stw r28, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[28].u32 ) };
	// 822120F0: 3B39FFFF  addi r25, r25, -1
	ctx.r[25].s64 = ctx.r[25].s64 + -1;
	// 822120F4: 3B5A0004  addi r26, r26, 4
	ctx.r[26].s64 = ctx.r[26].s64 + 4;
	// 822120F8: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 822120FC: 409AFF78  bne cr6, 0x82212074
	if !ctx.cr[6].eq {
	pc = 0x82212074; continue 'dispatch;
	}
	// 82212100: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82212104: 48322FF8  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82212108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82212108 size=2684
    //   switch @ 0x82212938: r10 with 7 label(s)
    //       case  0  0x822129A0
    //       case  1  0x82212994
    //       case  2  0x82212988
    //       case  3  0x8221297C
    //       case  4  0x82212970
    //       case  5  0x82212964
    //       case  6  0x82212958
    let mut pc: u32 = 0x82212108;
    'dispatch: loop {
        match pc {
            0x82212108 => {
    //   block [0x82212108..0x82212340)
	// 82212108: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221210C: 48322F99  bl 0x825350a4
	ctx.lr = 0x82212110;
	sub_82535080(ctx, base);
	// 82212110: 9421F650  stwu r1, -0x9b0(r1)
	ea = ctx.r[1].u32.wrapping_add(-2480 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82212114: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82212118: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8221211C: 7FFAFB78  mr r26, r31
	ctx.r[26].u64 = ctx.r[31].u64;
	// 82212120: 387D00F0  addi r3, r29, 0xf0
	ctx.r[3].s64 = ctx.r[29].s64 + 240;
	// 82212124: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 82212128: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8221212C: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 82212130: 93410058  stw r26, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[26].u32 ) };
	// 82212134: 4BF83D85  bl 0x82195eb8
	ctx.lr = 0x82212138;
	sub_82195EB8(ctx, base);
	// 82212138: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 8221213C: 813D00E8  lwz r9, 0xe8(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(232 as u32) ) } as u64;
	// 82212140: 3D4082C0  lis r10, -0x7d40
	ctx.r[10].s64 = -2101346304;
	// 82212144: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 82212148: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8221214C: 93CB64D8  stw r30, 0x64d8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(25816 as u32), ctx.r[30].u32 ) };
	// 82212150: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82212154: 916ABA0C  stw r11, -0x45f4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-17908 as u32), ctx.r[11].u32 ) };
	// 82212158: 419A0078  beq cr6, 0x822121d0
	if ctx.cr[6].eq {
	pc = 0x822121D0; continue 'dispatch;
	}
	// 8221215C: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 82212160: C05F0078  lfs f2, 0x78(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82212164: C03F0070  lfs f1, 0x70(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(112 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82212168: 396BDBD0  addi r11, r11, -0x2430
	ctx.r[11].s64 = ctx.r[11].s64 + -9264;
	// 8221216C: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 82212170: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 82212174: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82212178: 40990018  ble cr6, 0x82212190
	if !ctx.cr[6].gt {
	pc = 0x82212190; continue 'dispatch;
	}
	// 8221217C: 896B0002  lbz r11, 2(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 82212180: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82212184: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82212188: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8221218C: 41990008  bgt cr6, 0x82212194
	if ctx.cr[6].gt {
	pc = 0x82212194; continue 'dispatch;
	}
	// 82212190: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 82212194: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82212198: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221219C: 409A0018  bne cr6, 0x822121b4
	if !ctx.cr[6].eq {
	pc = 0x822121B4; continue 'dispatch;
	}
	// 822121A0: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 822121A4: 4BFA5325  bl 0x821b74c8
	ctx.lr = 0x822121A8;
	sub_821B74C8(ctx, base);
	// 822121A8: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 822121AC: D02B64DC  stfs f1, 0x64dc(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(25820 as u32), tmp.u32 ) };
	// 822121B0: 48000030  b 0x822121e0
	pc = 0x822121E0; continue 'dispatch;
	// 822121B4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 822121B8: 92E10080  stw r23, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[23].u32 ) };
	// 822121BC: 38A10080  addi r5, r1, 0x80
	ctx.r[5].s64 = ctx.r[1].s64 + 128;
	// 822121C0: 4BFA5371  bl 0x821b7530
	ctx.lr = 0x822121C4;
	sub_821B7530(ctx, base);
	// 822121C4: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 822121C8: D02B64DC  stfs f1, 0x64dc(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(25820 as u32), tmp.u32 ) };
	// 822121CC: 48000014  b 0x822121e0
	pc = 0x822121E0; continue 'dispatch;
	// 822121D0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 822121D4: C00B2294  lfs f0, 0x2294(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8852 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822121D8: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 822121DC: D00B64DC  stfs f0, 0x64dc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(25820 as u32), tmp.u32 ) };
	// 822121E0: 3D6082C0  lis r11, -0x7d40
	ctx.r[11].s64 = -2101346304;
	// 822121E4: 815D0018  lwz r10, 0x18(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(24 as u32) ) } as u64;
	// 822121E8: 3CE0829E  lis r7, -0x7d62
	ctx.r[7].s64 = -2103574528;
	// 822121EC: 813D0020  lwz r9, 0x20(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 822121F0: 3B6BBFF0  addi r27, r11, -0x4010
	ctx.r[27].s64 = ctx.r[11].s64 + -16400;
	// 822121F4: 3D600003  lis r11, 3
	ctx.r[11].s64 = 196608;
	// 822121F8: 55483032  slwi r8, r10, 6
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822121FC: 616B85D8  ori r11, r11, 0x85d8
	ctx.r[11].u64 = ctx.r[11].u64 | 34264;
	// 82212200: 914720BC  stw r10, 0x20bc(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8380 as u32), ctx.r[10].u32 ) };
	// 82212204: 7CE8FA14  add r7, r8, r31
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 82212208: 55293032  slwi r9, r9, 6
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(6);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221220C: 2B090100  cmplwi cr6, r9, 0x100
	ctx.cr[6].compare_u32(ctx.r[9].u32, 256 as u32, &mut ctx.xer);
	// 82212210: 7C1B5C2E  lfsx f0, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212214: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 82212218: 90E1005C  stw r7, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[7].u32 ) };
	// 8221221C: D00BF384  stfs f0, -0xc7c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-3196 as u32), tmp.u32 ) };
	// 82212220: 397F05C0  addi r11, r31, 0x5c0
	ctx.r[11].s64 = ctx.r[31].s64 + 1472;
	// 82212224: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 82212228: 4098000C  bge cr6, 0x82212234
	if !ctx.cr[6].lt {
	pc = 0x82212234; continue 'dispatch;
	}
	// 8221222C: 7C003A2C  dcbt 0, r7
	// 82212230: 4800016C  b 0x8221239c
	pc = 0x8221239C; continue 'dispatch;
	// 82212234: 3D400004  lis r10, 4
	ctx.r[10].s64 = 262144;
	// 82212238: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8221223C: 41980008  blt cr6, 0x82212244
	if ctx.cr[6].lt {
	pc = 0x82212244; continue 'dispatch;
	}
	// 82212240: 3D200004  lis r9, 4
	ctx.r[9].s64 = 262144;
	// 82212244: 3947007F  addi r10, r7, 0x7f
	ctx.r[10].s64 = ctx.r[7].s64 + 127;
	// 82212248: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8221224C: 55480030  rlwinm r8, r10, 0, 0, 0x18
	ctx.r[8].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 82212250: 552A0030  rlwinm r10, r9, 0, 0, 0x18
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 82212254: 7F083840  cmplw cr6, r8, r7
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[7].u32, &mut ctx.xer);
	// 82212258: 7D285050  subf r9, r8, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8221225C: 91210060  stw r9, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u32 ) };
	// 82212260: 419A0008  beq cr6, 0x82212268
	if ctx.cr[6].eq {
	pc = 0x82212268; continue 'dispatch;
	}
	// 82212264: 7C003A2C  dcbt 0, r7
	// 82212268: 91410054  stw r10, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 8221226C: 2B090400  cmplwi cr6, r9, 0x400
	ctx.cr[6].compare_u32(ctx.r[9].u32, 1024 as u32, &mut ctx.xer);
	// 82212270: 4198008C  blt cr6, 0x822122fc
	if ctx.cr[6].lt {
	pc = 0x822122FC; continue 'dispatch;
	}
	// 82212274: 3960FF80  li r11, -0x80
	ctx.r[11].s64 = -128;
	// 82212278: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221227C: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82212280: 3940FF00  li r10, -0x100
	ctx.r[10].s64 = -256;
	// 82212284: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212288: 3940FE80  li r10, -0x180
	ctx.r[10].s64 = -384;
	// 8221228C: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82212290: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212294: 3940FE00  li r10, -0x200
	ctx.r[10].s64 = -512;
	// 82212298: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8221229C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822122A0: 3940FD80  li r10, -0x280
	ctx.r[10].s64 = -640;
	// 822122A4: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 822122A8: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822122AC: 3940FD00  li r10, -0x300
	ctx.r[10].s64 = -768;
	// 822122B0: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 822122B4: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822122B8: 3940FC80  li r10, -0x380
	ctx.r[10].s64 = -896;
	// 822122BC: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 822122C0: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822122C4: 3940FC00  li r10, -0x400
	ctx.r[10].s64 = -1024;
	// 822122C8: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 822122CC: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822122D0: 81610060  lwz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 822122D4: 392BFC00  addi r9, r11, -0x400
	ctx.r[9].s64 = ctx.r[11].s64 + -1024;
	// 822122D8: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 822122DC: 394BFC00  addi r10, r11, -0x400
	ctx.r[10].s64 = ctx.r[11].s64 + -1024;
	// 822122E0: 2B090400  cmplwi cr6, r9, 0x400
	ctx.cr[6].compare_u32(ctx.r[9].u32, 1024 as u32, &mut ctx.xer);
	// 822122E4: 91210060  stw r9, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u32 ) };
	// 822122E8: 91410054  stw r10, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 822122EC: 4098FF88  bge cr6, 0x82212274
	if !ctx.cr[6].lt {
	pc = 0x82212274; continue 'dispatch;
	}
	// 822122F0: 83410058  lwz r26, 0x58(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 822122F4: 81610068  lwz r11, 0x68(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 822122F8: 80E1005C  lwz r7, 0x5c(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 822122FC: 5529CF7E  rlwinm r9, r9, 0x19, 0x1d, 0x1f
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x0000007Fu64;
	// 82212300: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 82212304: 2B090006  cmplwi cr6, r9, 6
	ctx.cr[6].compare_u32(ctx.r[9].u32, 6 as u32, &mut ctx.xer);
	// 82212308: 41990094  bgt cr6, 0x8221239c
	if ctx.cr[6].gt {
	pc = 0x8221239C; continue 'dispatch;
	}
	// 8221230C: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82212310: 398C2324  addi r12, r12, 0x2324
	ctx.r[12].s64 = ctx.r[12].s64 + 8996;
	// 82212314: 5520103A  slwi r0, r9, 2
	ctx.r[0].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82212318: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8221231C: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82212320: 4E800420  bctr
	match ctx.r[9].u64 {
		0 => {
	pc = 0x82212388; continue 'dispatch;
		},
		1 => {
	pc = 0x8221237C; continue 'dispatch;
		},
		2 => {
	pc = 0x82212370; continue 'dispatch;
		},
		3 => {
	pc = 0x82212364; continue 'dispatch;
		},
		4 => {
	pc = 0x82212358; continue 'dispatch;
		},
		5 => {
	pc = 0x8221234C; continue 'dispatch;
		},
		6 => {
	pc = 0x82212340; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82212324: 82212388  lwz r17, 0x2388(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9096 as u32) ) } as u64;
	// 82212328: 8221237C  lwz r17, 0x237c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9084 as u32) ) } as u64;
	// 8221232C: 82212370  lwz r17, 0x2370(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9072 as u32) ) } as u64;
	// 82212330: 82212364  lwz r17, 0x2364(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9060 as u32) ) } as u64;
	// 82212334: 82212358  lwz r17, 0x2358(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9048 as u32) ) } as u64;
	// 82212338: 8221234C  lwz r17, 0x234c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9036 as u32) ) } as u64;
	// 8221233C: 82212340  lwz r17, 0x2340(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(9024 as u32) ) } as u64;
            }
            0x82212340 => {
    //   block [0x82212340..0x8221234C)
	// 82212340: 3960FC80  li r11, -0x380
	ctx.r[11].s64 = -896;
	// 82212344: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212348: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x8221234C; continue 'dispatch;
            }
            0x8221234C => {
    //   block [0x8221234C..0x82212358)
	// 8221234C: 3960FD00  li r11, -0x300
	ctx.r[11].s64 = -768;
	// 82212350: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212354: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x82212358; continue 'dispatch;
            }
            0x82212358 => {
    //   block [0x82212358..0x82212364)
	// 82212358: 3960FD80  li r11, -0x280
	ctx.r[11].s64 = -640;
	// 8221235C: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212360: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x82212364; continue 'dispatch;
            }
            0x82212364 => {
    //   block [0x82212364..0x82212370)
	// 82212364: 3960FE00  li r11, -0x200
	ctx.r[11].s64 = -512;
	// 82212368: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221236C: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x82212370; continue 'dispatch;
            }
            0x82212370 => {
    //   block [0x82212370..0x8221237C)
	// 82212370: 3960FE80  li r11, -0x180
	ctx.r[11].s64 = -384;
	// 82212374: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212378: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x8221237C; continue 'dispatch;
            }
            0x8221237C => {
    //   block [0x8221237C..0x82212388)
	// 8221237C: 3960FF00  li r11, -0x100
	ctx.r[11].s64 = -256;
	// 82212380: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212384: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	pc = 0x82212388; continue 'dispatch;
            }
            0x82212388 => {
    //   block [0x82212388..0x82212958)
	// 82212388: 3960FF80  li r11, -0x80
	ctx.r[11].s64 = -128;
	// 8221238C: 7C0B57EC  dcbz r11, r10
	ea.u32 = ctx.r[11].u32.wrapping_add(ctx.r[10].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212390: 83410058  lwz r26, 0x58(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82212394: 81610068  lwz r11, 0x68(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82212398: 80E1005C  lwz r7, 0x5c(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8221239C: 815D0020  lwz r10, 0x20(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 822123A0: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 822123A4: 7EE8BB78  mr r8, r23
	ctx.r[8].u64 = ctx.r[23].u64;
	// 822123A8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 822123AC: 3D40829E  lis r10, -0x7d62
	ctx.r[10].s64 = -2103574528;
	// 822123B0: C169BA38  lfs f11, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822123B4: 3B8A6420  addi r28, r10, 0x6420
	ctx.r[28].s64 = ctx.r[10].s64 + 25632;
	// 822123B8: 40990138  ble cr6, 0x822124f0
	if !ctx.cr[6].gt {
	pc = 0x822124F0; continue 'dispatch;
	}
	// 822123BC: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822123C0: 55092036  slwi r9, r8, 4
	ctx.r[9].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 822123C4: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 822123C8: C00B0004  lfs f0, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822123CC: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822123D0: 7D49E214  add r10, r9, r28
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[28].u64;
	// 822123D4: 38DC0004  addi r6, r28, 4
	ctx.r[6].s64 = ctx.r[28].s64 + 4;
	// 822123D8: 38BC0008  addi r5, r28, 8
	ctx.r[5].s64 = ctx.r[28].s64 + 8;
	// 822123DC: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 822123E0: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 822123E4: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 822123E8: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822123EC: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822123F0: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 822123F4: C00B0014  lfs f0, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822123F8: C18B0010  lfs f12, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822123FC: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82212400: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82212404: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82212408: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221240C: C1AB0028  lfs f13, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212410: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212414: C00B0024  lfs f0, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212418: C18B0020  lfs f12, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221241C: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82212420: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82212424: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82212428: D00A0008  stfs f0, 8(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221242C: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212430: EDAB6824  fdivs f13, f11, f13
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[13].f64) as f32) as f64;
	// 82212434: 7C09342E  lfsx f0, r9, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212438: EC0B0024  fdivs f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221243C: 7D892C2E  lfsx f12, r9, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212440: ED8B6024  fdivs f12, f11, f12
	ctx.f[12].f64 = ((ctx.f[11].f64 / ctx.f[12].f64) as f32) as f64;
	// 82212444: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82212448: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8221244C: C12B0004  lfs f9, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82212450: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 82212454: C10B0008  lfs f8, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82212458: 38C00008  li r6, 8
	ctx.r[6].s64 = 8;
	// 8221245C: C0EB0010  lfs f7, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82212460: C0CB0014  lfs f6, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82212464: C0AB0018  lfs f5, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82212468: C08B0020  lfs f4, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221246C: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212470: D14B0000  stfs f10, 0(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212474: ED490372  fmuls f10, f9, f13
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212478: D14B0004  stfs f10, 4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221247C: EDA80372  fmuls f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212480: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82212484: EDA001B2  fmuls f13, f0, f6
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[6].f64) as f32) as f64);
	// 82212488: C14B0028  lfs f10, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221248C: ECE70032  fmuls f7, f7, f0
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212490: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82212494: EC050032  fmuls f0, f5, f0
	ctx.f[0].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212498: D00B0018  stfs f0, 0x18(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221249C: C00B0024  lfs f0, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822124A0: EDAC0132  fmuls f13, f12, f4
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[4].f64) as f32) as f64);
	// 822124A4: EC000332  fmuls f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 822124A8: D0EB0010  stfs f7, 0x10(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822124AC: ED8A0332  fmuls f12, f10, f12
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 822124B0: D1AB0020  stfs f13, 0x20(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 822124B4: D00B0024  stfs f0, 0x24(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 822124B8: D18B0028  stfs f12, 0x28(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 822124BC: 7CC903A6  mtctr r6
	ctx.ctr.u64 = ctx.r[6].u64;
	// 822124C0: E8CA0000  ld r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 822124C4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 822124C8: F8C90000  std r6, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[6].u64 ) };
	// 822124CC: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 822124D0: 4200FFF0  bdnz 0x822124c0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822124C0; continue 'dispatch;
	}
	// 822124D4: 815D0020  lwz r10, 0x20(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 822124D8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 822124DC: 38E70040  addi r7, r7, 0x40
	ctx.r[7].s64 = ctx.r[7].s64 + 64;
	// 822124E0: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 822124E4: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 822124E8: 7F285000  cmpd cr6, r8, r10
	ctx.cr[6].compare_i64(ctx.r[8].s64, ctx.r[10].s64, &mut ctx.xer);
	// 822124EC: 4198FED0  blt cr6, 0x822123bc
	if ctx.cr[6].lt {
	pc = 0x822123BC; continue 'dispatch;
	}
	// 822124F0: 817D0450  lwz r11, 0x450(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(1104 as u32) ) } as u64;
	// 822124F4: 7EE9BB78  mr r9, r23
	ctx.r[9].u64 = ctx.r[23].u64;
	// 822124F8: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 822124FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212500: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82212504: 38E00030  li r7, 0x30
	ctx.r[7].s64 = 48;
	// 82212508: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 8221250C: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212510: 419A0050  beq cr6, 0x82212560
	if ctx.cr[6].eq {
	pc = 0x82212560; continue 'dispatch;
	}
	// 82212514: 817D0450  lwz r11, 0x450(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(1104 as u32) ) } as u64;
	// 82212518: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8221251C: A0CB0022  lhz r6, 0x22(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(34 as u32) ) } as u64;
	pc = 0x82212958; continue 'dispatch;
            }
            0x82212958 => {
    //   block [0x82212958..0x82212964)
	// 82212958: 3940FC80  li r10, -0x380
	ctx.r[10].s64 = -896;
	// 8221295C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212960: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x82212964; continue 'dispatch;
            }
            0x82212964 => {
    //   block [0x82212964..0x82212970)
	// 82212964: 3940FD00  li r10, -0x300
	ctx.r[10].s64 = -768;
	// 82212968: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221296C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x82212970; continue 'dispatch;
            }
            0x82212970 => {
    //   block [0x82212970..0x8221297C)
	// 82212970: 3940FD80  li r10, -0x280
	ctx.r[10].s64 = -640;
	// 82212974: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212978: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x8221297C; continue 'dispatch;
            }
            0x8221297C => {
    //   block [0x8221297C..0x82212988)
	// 8221297C: 3940FE00  li r10, -0x200
	ctx.r[10].s64 = -512;
	// 82212980: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212984: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x82212988; continue 'dispatch;
            }
            0x82212988 => {
    //   block [0x82212988..0x82212994)
	// 82212988: 3940FE80  li r10, -0x180
	ctx.r[10].s64 = -384;
	// 8221298C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82212990: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x82212994; continue 'dispatch;
            }
            0x82212994 => {
    //   block [0x82212994..0x822129A0)
	// 82212994: 3940FF00  li r10, -0x100
	ctx.r[10].s64 = -256;
	// 82212998: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221299C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	pc = 0x822129A0; continue 'dispatch;
            }
            0x822129A0 => {
    //   block [0x822129A0..0x82212B84)
	// 822129A0: 3940FF80  li r10, -0x80
	ctx.r[10].s64 = -128;
	// 822129A4: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822129A8: 83410058  lwz r26, 0x58(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 822129AC: 81210084  lwz r9, 0x84(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 822129B0: 7C004A2C  dcbt 0, r9
	// 822129B4: 48000010  b 0x822129c4
	pc = 0x822129C4; continue 'dispatch;
	// 822129B8: 817D0018  lwz r11, 0x18(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(24 as u32) ) } as u64;
	// 822129BC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822129C0: 7D2BD214  add r9, r11, r26
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 822129C4: 815D0020  lwz r10, 0x20(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 822129C8: 397A05C0  addi r11, r26, 0x5c0
	ctx.r[11].s64 = ctx.r[26].s64 + 1472;
	// 822129CC: 7EE6BB78  mr r6, r23
	ctx.r[6].u64 = ctx.r[23].u64;
	// 822129D0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 822129D4: 409900C4  ble cr6, 0x82212a98
	if !ctx.cr[6].gt {
	pc = 0x82212A98; continue 'dispatch;
	}
	// 822129D8: 54CA2036  slwi r10, r6, 4
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822129DC: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822129E0: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 822129E4: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 822129E8: 7D4AE214  add r10, r10, r28
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[28].u64;
	// 822129EC: C12B0008  lfs f9, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 822129F0: C10B0010  lfs f8, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 822129F4: 7D274B78  mr r7, r9
	ctx.r[7].u64 = ctx.r[9].u64;
	// 822129F8: C0EB0014  lfs f7, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 822129FC: 38A00008  li r5, 8
	ctx.r[5].s64 = 8;
	// 82212A00: C0CB0018  lfs f6, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82212A04: C0AB0020  lfs f5, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82212A08: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212A0C: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212A10: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212A14: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212A18: ECA50032  fmuls f5, f5, f0
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212A1C: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212A20: ED6A0332  fmuls f11, f10, f12
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212A24: ED890332  fmuls f12, f9, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212A28: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82212A2C: ED080372  fmuls f8, f8, f13
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212A30: C08B0024  lfs f4, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82212A34: ED870372  fmuls f12, f7, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212A38: C06B0028  lfs f3, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82212A3C: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212A40: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82212A44: EDA40032  fmuls f13, f4, f0
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212A48: D0AB0020  stfs f5, 0x20(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82212A4C: EC030032  fmuls f0, f3, f0
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212A50: D10B0010  stfs f8, 0x10(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82212A54: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82212A58: D18B0014  stfs f12, 0x14(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82212A5C: D1AB0024  stfs f13, 0x24(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82212A60: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82212A64: 7CA903A6  mtctr r5
	ctx.ctr.u64 = ctx.r[5].u64;
	// 82212A68: E9480000  ld r10, 0(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	// 82212A6C: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 82212A70: F9470000  std r10, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 82212A74: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 82212A78: 4200FFF0  bdnz 0x82212a68
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82212A68; continue 'dispatch;
	}
	// 82212A7C: 815D0020  lwz r10, 0x20(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 82212A80: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 82212A84: 39290040  addi r9, r9, 0x40
	ctx.r[9].s64 = ctx.r[9].s64 + 64;
	// 82212A88: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 82212A8C: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82212A90: 7F265000  cmpd cr6, r6, r10
	ctx.cr[6].compare_i64(ctx.r[6].s64, ctx.r[10].s64, &mut ctx.xer);
	// 82212A94: 4198FF44  blt cr6, 0x822129d8
	if ctx.cr[6].lt {
	pc = 0x822129D8; continue 'dispatch;
	}
	// 82212A98: 817D0020  lwz r11, 0x20(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 82212A9C: 815D0018  lwz r10, 0x18(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(24 as u32) ) } as u64;
	// 82212AA0: 811D0024  lwz r8, 0x24(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) } as u64;
	// 82212AA4: 7D6507B4  extsw r5, r11
	ctx.r[5].s64 = ctx.r[11].s32 as i64;
	// 82212AA8: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82212AAC: 7D0807B4  extsw r8, r8
	ctx.r[8].s64 = ctx.r[8].s32 as i64;
	// 82212AB0: 554B3032  slwi r11, r10, 6
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82212AB4: 7F254000  cmpd cr6, r5, r8
	ctx.cr[6].compare_i64(ctx.r[5].s64, ctx.r[8].s64, &mut ctx.xer);
	// 82212AB8: 7CCBD214  add r6, r11, r26
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 82212ABC: 409800C0  bge cr6, 0x82212b7c
	if !ctx.cr[6].lt {
	pc = 0x82212B7C; continue 'dispatch;
	}
	// 82212AC0: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 82212AC4: C01C0008  lfs f0, 8(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212AC8: C1BC0004  lfs f13, 4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212ACC: 39290040  addi r9, r9, 0x40
	ctx.r[9].s64 = ctx.r[9].s64 + 64;
	// 82212AD0: C19C0000  lfs f12, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212AD4: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 82212AD8: 38E00008  li r7, 8
	ctx.r[7].s64 = 8;
	// 82212ADC: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 82212AE0: 7CE903A6  mtctr r7
	ctx.ctr.u64 = ctx.r[7].u64;
	// 82212AE4: E8EA0000  ld r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 82212AE8: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 82212AEC: F8E80000  std r7, 0(r8)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[7].u64 ) };
	// 82212AF0: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 82212AF4: 4200FFF0  bdnz 0x82212ae4
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82212AE4; continue 'dispatch;
	}
	// 82212AF8: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212AFC: 38A50001  addi r5, r5, 1
	ctx.r[5].s64 = ctx.r[5].s64 + 1;
	// 82212B00: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82212B04: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212B08: C12B0008  lfs f9, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82212B0C: ED4C02B2  fmuls f10, f12, f10
	ctx.f[10].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 82212B10: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82212B14: C10B0010  lfs f8, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82212B18: C12B0014  lfs f9, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82212B1C: ED0D0232  fmuls f8, f13, f8
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 82212B20: C0EB0018  lfs f7, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82212B24: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 82212B28: EDAD01F2  fmuls f13, f13, f7
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[7].f64) as f32) as f64);
	// 82212B2C: C0CB0020  lfs f6, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82212B30: C0EB0024  lfs f7, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82212B34: ECC001B2  fmuls f6, f0, f6
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[6].f64) as f32) as f64);
	// 82212B38: C0AB0028  lfs f5, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82212B3C: ECE001F2  fmuls f7, f0, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 82212B40: EC000172  fmuls f0, f0, f5
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[5].f64) as f32) as f64);
	// 82212B44: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212B48: D14B0004  stfs f10, 4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82212B4C: 38C60040  addi r6, r6, 0x40
	ctx.r[6].s64 = ctx.r[6].s64 + 64;
	// 82212B50: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82212B54: D10B0010  stfs f8, 0x10(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82212B58: D12B0014  stfs f9, 0x14(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82212B5C: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82212B60: D0CB0020  stfs f6, 0x20(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82212B64: D0EB0024  stfs f7, 0x24(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82212B68: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82212B6C: 817D0024  lwz r11, 0x24(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) } as u64;
	// 82212B70: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 82212B74: 7F255800  cmpd cr6, r5, r11
	ctx.cr[6].compare_i64(ctx.r[5].s64, ctx.r[11].s64, &mut ctx.xer);
	// 82212B78: 4198FF48  blt cr6, 0x82212ac0
	if ctx.cr[6].lt {
	pc = 0x82212AC0; continue 'dispatch;
	}
	// 82212B7C: 382109B0  addi r1, r1, 0x9b0
	ctx.r[1].s64 = ctx.r[1].s64 + 2480;
	// 82212B80: 48322574  b 0x825350f4
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82212B88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82212B88 size=204
    let mut pc: u32 = 0x82212B88;
    'dispatch: loop {
        match pc {
            0x82212B88 => {
    //   block [0x82212B88..0x82212C54)
	// 82212B88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82212B8C: 48322531  bl 0x825350bc
	ctx.lr = 0x82212B90;
	sub_82535080(ctx, base);
	// 82212B90: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82212B94: 3D208311  lis r9, -0x7cef
	ctx.r[9].s64 = -2096037888;
	// 82212B98: 8149426C  lwz r10, 0x426c(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(17004 as u32) ) } as u64;
	// 82212B9C: 554B07FE  clrlwi r11, r10, 0x1f
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 82212BA0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212BA4: 3D608311  lis r11, -0x7cef
	ctx.r[11].s64 = -2096037888;
	// 82212BA8: 3BCB4248  addi r30, r11, 0x4248
	ctx.r[30].s64 = ctx.r[11].s64 + 16968;
	// 82212BAC: 409A0034  bne cr6, 0x82212be0
	if !ctx.cr[6].eq {
	pc = 0x82212BE0; continue 'dispatch;
	}
	// 82212BB0: 614A0001  ori r10, r10, 1
	ctx.r[10].u64 = ctx.r[10].u64 | 1;
	// 82212BB4: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82212BB8: 396BFEE8  addi r11, r11, -0x118
	ctx.r[11].s64 = ctx.r[11].s64 + -280;
	// 82212BBC: 9149426C  stw r10, 0x426c(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(17004 as u32), ctx.r[10].u32 ) };
	// 82212BC0: 3940FFFF  li r10, -1
	ctx.r[10].s64 = -1;
	// 82212BC4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82212BC8: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82212BCC: 917E000C  stw r11, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82212BD0: 915E0014  stw r10, 0x14(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 82212BD4: 917E0018  stw r11, 0x18(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 82212BD8: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 82212BDC: 917E0020  stw r11, 0x20(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 82212BE0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82212BE4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82212BE8: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82212BEC: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 82212BF0: 917E0010  stw r11, 0x10(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 82212BF4: 39600003  li r11, 3
	ctx.r[11].s64 = 3;
	// 82212BF8: 917E001C  stw r11, 0x1c(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 82212BFC: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82212C00: 3BAB4610  addi r29, r11, 0x4610
	ctx.r[29].s64 = ctx.r[11].s64 + 17936;
	// 82212C04: 7FEB0034  cntlzw r11, r31
	ctx.r[11].u64 = if ctx.r[31].u32 == 0 { 32 } else { ctx.r[31].u32.leading_zeros() as u64 };
	// 82212C08: 3D408221  lis r10, -0x7ddf
	ctx.r[10].s64 = -2111766528;
	// 82212C0C: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82212C10: 3CE00000  lis r7, 0
	ctx.r[7].s64 = 0;
	// 82212C14: 696B0001  xori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 ^ 1;
	// 82212C18: 7FA8EB78  mr r8, r29
	ctx.r[8].u64 = ctx.r[29].u64;
	// 82212C1C: 38CB0002  addi r6, r11, 2
	ctx.r[6].s64 = ctx.r[11].s64 + 2;
	// 82212C20: 57EB083C  slwi r11, r31, 1
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82212C24: 60E78000  ori r7, r7, 0x8000
	ctx.r[7].u64 = ctx.r[7].u64 | 32768;
	// 82212C28: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 82212C2C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82212C30: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82212C34: 388A2C58  addi r4, r10, 0x2c58
	ctx.r[4].s64 = ctx.r[10].s64 + 11352;
	// 82212C38: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82212C3C: 48126D55  bl 0x82339990
	ctx.lr = 0x82212C40;
	sub_82339990(ctx, base);
	// 82212C40: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82212C44: 2B1F0003  cmplwi cr6, r31, 3
	ctx.cr[6].compare_u32(ctx.r[31].u32, 3 as u32, &mut ctx.xer);
	// 82212C48: 4198FFBC  blt cr6, 0x82212c04
	if ctx.cr[6].lt {
	pc = 0x82212C04; continue 'dispatch;
	}
	// 82212C4C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82212C50: 483224BC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82212C58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82212C58 size=252
    let mut pc: u32 = 0x82212C58;
    'dispatch: loop {
        match pc {
            0x82212C58 => {
    //   block [0x82212C58..0x82212D54)
	// 82212C58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82212C5C: 48322461  bl 0x825350bc
	ctx.lr = 0x82212C60;
	sub_82535080(ctx, base);
	// 82212C60: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82212C64: 3D608287  lis r11, -0x7d79
	ctx.r[11].s64 = -2105081856;
	// 82212C68: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82212C6C: 3BABE6A0  addi r29, r11, -0x1960
	ctx.r[29].s64 = ctx.r[11].s64 + -6496;
	// 82212C70: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82212C74: 48000FE5  bl 0x82213c58
	ctx.lr = 0x82212C78;
	sub_82213C58(ctx, base);
	// 82212C78: 83C10050  lwz r30, 0x50(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82212C7C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82212C80: 419A00C8  beq cr6, 0x82212d48
	if ctx.cr[6].eq {
	pc = 0x82212D48; continue 'dispatch;
	}
	// 82212C84: 897E004B  lbz r11, 0x4b(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(75 as u32) ) } as u64;
	// 82212C88: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212C8C: 419A006C  beq cr6, 0x82212cf8
	if ctx.cr[6].eq {
	pc = 0x82212CF8; continue 'dispatch;
	}
	// 82212C90: 817E0044  lwz r11, 0x44(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(68 as u32) ) } as u64;
	// 82212C94: 894B0068  lbz r10, 0x68(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(104 as u32) ) } as u64;
	// 82212C98: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82212C9C: 419A005C  beq cr6, 0x82212cf8
	if ctx.cr[6].eq {
	pc = 0x82212CF8; continue 'dispatch;
	}
	// 82212CA0: 81410058  lwz r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82212CA4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212CA8: 214A0000  subfic r10, r10, 0
	ctx.xer.ca = ctx.r[10].u32 <= 0 as u32;
	ctx.r[10].s64 = (0 as i64) - ctx.r[10].s64;
	// 82212CAC: 7D4A5110  subfe r10, r10, r10
	let x = (!ctx.r[10].u32);
	let y = ctx.r[10].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[10].u32 = res;
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 82212CB0: 554A07BC  rlwinm r10, r10, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 82212CB4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82212CB8: 419A0040  beq cr6, 0x82212cf8
	if ctx.cr[6].eq {
	pc = 0x82212CF8; continue 'dispatch;
	}
	// 82212CBC: 810B0024  lwz r8, 0x24(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 82212CC0: 39200068  li r9, 0x68
	ctx.r[9].s64 = 104;
	// 82212CC4: 7C09422C  dcbt r9, r8
	// 82212CC8: 892B0068  lbz r9, 0x68(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(104 as u32) ) } as u64;
	// 82212CCC: 7D290774  extsb r9, r9
	ctx.r[9].s64 = ctx.r[9].s8 as i64;
	// 82212CD0: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82212CD4: 419A0018  beq cr6, 0x82212cec
	if ctx.cr[6].eq {
	pc = 0x82212CEC; continue 'dispatch;
	}
	// 82212CD8: 7D490774  extsb r9, r10
	ctx.r[9].s64 = ctx.r[10].s8 as i64;
	// 82212CDC: 2F0A0003  cmpwi cr6, r10, 3
	ctx.cr[6].compare_i32(ctx.r[10].s32, 3, &mut ctx.xer);
	// 82212CE0: 992B0069  stb r9, 0x69(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(105 as u32), ctx.r[9].u8 ) };
	// 82212CE4: 992B0068  stb r9, 0x68(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(104 as u32), ctx.r[9].u8 ) };
	// 82212CE8: 419A0010  beq cr6, 0x82212cf8
	if ctx.cr[6].eq {
	pc = 0x82212CF8; continue 'dispatch;
	}
	// 82212CEC: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 82212CF0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 82212CF4: 409AFFC8  bne cr6, 0x82212cbc
	if !ctx.cr[6].eq {
	pc = 0x82212CBC; continue 'dispatch;
	}
	// 82212CF8: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82212CFC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82212D00: 3BEB0080  addi r31, r11, 0x80
	ctx.r[31].s64 = ctx.r[11].s64 + 128;
	// 82212D04: 8161005C  lwz r11, 0x5c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82212D08: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82212D0C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82212D10: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82212D14: 69650001  xori r5, r11, 1
	ctx.r[5].u64 = ctx.r[11].u64 ^ 1;
	// 82212D18: 4BFFDE21  bl 0x82210b38
	ctx.lr = 0x82212D1C;
	sub_82210B38(ctx, base);
	// 82212D1C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82212D20: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82212D24: 4800CD15  bl 0x8221fa38
	ctx.lr = 0x82212D28;
	sub_8221FA38(ctx, base);
	// 82212D28: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82212D2C: 4800105D  bl 0x82213d88
	ctx.lr = 0x82212D30;
	sub_82213D88(ctx, base);
	// 82212D30: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82212D34: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82212D38: 48000F21  bl 0x82213c58
	ctx.lr = 0x82212D3C;
	sub_82213C58(ctx, base);
	// 82212D3C: 83C10050  lwz r30, 0x50(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82212D40: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82212D44: 409AFF40  bne cr6, 0x82212c84
	if !ctx.cr[6].eq {
	pc = 0x82212C84; continue 'dispatch;
	}
	// 82212D48: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82212D4C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82212D50: 483223BC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82212D58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82212D58 size=2424
    let mut pc: u32 = 0x82212D58;
    'dispatch: loop {
        match pc {
            0x82212D58 => {
    //   block [0x82212D58..0x822136D0)
	// 82212D58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82212D5C: 48322345  bl 0x825350a0
	ctx.lr = 0x82212D60;
	sub_82535080(ctx, base);
	// 82212D60: 3981FFA8  addi r12, r1, -0x58
	ctx.r[12].s64 = ctx.r[1].s64 + -88;
	// 82212D64: 48323275  bl 0x82535fd8
	ctx.lr = 0x82212D68;
	sub_82535FB0(ctx, base);
	// 82212D68: 9421F1A0  stwu r1, -0xe60(r1)
	ea = ctx.r[1].u32.wrapping_add(-3680 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82212D6C: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 82212D70: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 82212D74: 7C962378  mr r22, r4
	ctx.r[22].u64 = ctx.r[4].u64;
	// 82212D78: 39400022  li r10, 0x22
	ctx.r[10].s64 = 34;
	// 82212D7C: 396100C8  addi r11, r1, 0xc8
	ctx.r[11].s64 = ctx.r[1].s64 + 200;
	// 82212D80: C3C9BA38  lfs f30, -0x45c8(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82212D84: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82212D88: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82212D8C: D3CB0000  stfs f30, 0(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212D90: D3CBFFFC  stfs f30, -4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82212D94: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82212D98: D3CBFFF8  stfs f30, -8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82212D9C: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 82212DA0: 4098FFE4  bge cr6, 0x82212d84
	if !ctx.cr[6].lt {
	pc = 0x82212D84; continue 'dispatch;
	}
	// 82212DA4: 39400022  li r10, 0x22
	ctx.r[10].s64 = 34;
	// 82212DA8: 39610758  addi r11, r1, 0x758
	ctx.r[11].s64 = ctx.r[1].s64 + 1880;
	// 82212DAC: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82212DB0: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82212DB4: D3CB0000  stfs f30, 0(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212DB8: D3CBFFFC  stfs f30, -4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82212DBC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82212DC0: D3CBFFF8  stfs f30, -8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82212DC4: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 82212DC8: 4098FFE4  bge cr6, 0x82212dac
	if !ctx.cr[6].lt {
	pc = 0x82212DAC; continue 'dispatch;
	}
	// 82212DCC: 3AF60F80  addi r23, r22, 0xf80
	ctx.r[23].s64 = ctx.r[22].s64 + 3968;
	// 82212DD0: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82212DD4: 38A00023  li r5, 0x23
	ctx.r[5].s64 = 35;
	// 82212DD8: 7EEABB78  mr r10, r23
	ctx.r[10].u64 = ctx.r[23].u64;
	// 82212DDC: C1AA0008  lfs f13, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212DE0: 396100B8  addi r11, r1, 0xb8
	ctx.r[11].s64 = ctx.r[1].s64 + 184;
	// 82212DE4: ED0D0372  fmuls f8, f13, f13
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212DE8: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212DEC: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82212DF0: C16A0030  lfs f11, 0x30(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(48 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212DF4: C18A0004  lfs f12, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212DF8: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82212DFC: C14A0034  lfs f10, 0x34(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82212E00: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 82212E04: C12A0038  lfs f9, 0x38(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(56 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82212E08: 38C00008  li r6, 8
	ctx.r[6].s64 = 8;
	// 82212E0C: C1AA0018  lfs f13, 0x18(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212E10: D16BFFF8  stfs f11, -8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82212E14: D14BFFFC  stfs f10, -4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82212E18: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82212E1C: ED60403A  fmadds f11, f0, f0, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[8].f64) as f32) as f64);
	// 82212E20: C00A0010  lfs f0, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212E24: ED6C5B3A  fmadds f11, f12, f12, f11
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 82212E28: C18A0014  lfs f12, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212E2C: ED60582C  fsqrts f11, f11
	ctx.f[11].f64 = ((ctx.f[11].f64).sqrt() as f32) as f64;
	// 82212E30: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82212E34: ED6D0372  fmuls f11, f13, f13
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212E38: C1AA0028  lfs f13, 0x28(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212E3C: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212E40: ED60583A  fmadds f11, f0, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[11].f64) as f32) as f64);
	// 82212E44: C00A0020  lfs f0, 0x20(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82212E48: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82212E4C: ED6C5B3A  fmadds f11, f12, f12, f11
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 82212E50: C18A0024  lfs f12, 0x24(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212E54: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82212E58: ED60582C  fsqrts f11, f11
	ctx.f[11].f64 = ((ctx.f[11].f64).sqrt() as f32) as f64;
	// 82212E5C: D16B000C  stfs f11, 0xc(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82212E60: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82212E64: FDA05890  fmr f13, f11
	ctx.f[13].f64 = ctx.f[11].f64;
	// 82212E68: D00B0010  stfs f0, 0x10(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82212E6C: EC1E0024  fdivs f0, f30, f0
	ctx.f[0].f64 = ((ctx.f[30].f64 / ctx.f[0].f64) as f32) as f64;
	// 82212E70: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212E74: ED9E6024  fdivs f12, f30, f12
	ctx.f[12].f64 = ((ctx.f[30].f64 / ctx.f[12].f64) as f32) as f64;
	// 82212E78: EDBE6824  fdivs f13, f30, f13
	ctx.f[13].f64 = ((ctx.f[30].f64 / ctx.f[13].f64) as f32) as f64;
	// 82212E7C: 7CC903A6  mtctr r6
	ctx.ctr.u64 = ctx.r[6].u64;
	// 82212E80: E9680000  ld r11, 0(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	// 82212E84: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 82212E88: F9670000  std r11, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 82212E8C: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 82212E90: 4200FFF0  bdnz 0x82212e80
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82212E80; continue 'dispatch;
	}
	// 82212E94: C1610050  lfs f11, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212E98: 396100A0  addi r11, r1, 0xa0
	ctx.r[11].s64 = ctx.r[1].s64 + 160;
	// 82212E9C: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212EA0: D1610050  stfs f11, 0x50(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82212EA4: C1610054  lfs f11, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212EA8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82212EAC: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212EB0: D1610054  stfs f11, 0x54(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82212EB4: C1610058  lfs f11, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212EB8: 7C695A14  add r3, r9, r11
	ctx.r[3].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82212EBC: ED8B0332  fmuls f12, f11, f12
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82212EC0: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82212EC4: C1810060  lfs f12, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212EC8: ED8C0372  fmuls f12, f12, f13
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212ECC: D1810060  stfs f12, 0x60(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 82212ED0: C1810064  lfs f12, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212ED4: ED8C0372  fmuls f12, f12, f13
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212ED8: D1810064  stfs f12, 0x64(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82212EDC: C1810068  lfs f12, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212EE0: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 82212EE4: D1A10068  stfs f13, 0x68(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82212EE8: C1A10070  lfs f13, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212EEC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212EF0: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82212EF4: C1A10074  lfs f13, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212EF8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212EFC: D1A10074  stfs f13, 0x74(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82212F00: C1A10078  lfs f13, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212F04: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82212F08: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82212F0C: 48161495  bl 0x823743a0
	ctx.lr = 0x82212F10;
	sub_823743A0(ctx, base);
	// 82212F10: 39610730  addi r11, r1, 0x730
	ctx.r[11].s64 = ctx.r[1].s64 + 1840;
	// 82212F14: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 82212F18: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82212F1C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 82212F20: E9030000  ld r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	// 82212F24: 38630008  addi r3, r3, 8
	ctx.r[3].s64 = ctx.r[3].s64 + 8;
	// 82212F28: F90B0000  std r8, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 82212F2C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82212F30: 4200FFF0  bdnz 0x82212f20
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82212F20; continue 'dispatch;
	}
	// 82212F34: 38A5FFFF  addi r5, r5, -1
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	// 82212F38: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82212F3C: 39290030  addi r9, r9, 0x30
	ctx.r[9].s64 = ctx.r[9].s64 + 48;
	// 82212F40: 2B250000  cmpldi cr6, r5, 0
	ctx.cr[6].compare_u64(ctx.r[5].u64, 0, &mut ctx.xer);
	// 82212F44: 4199FE98  bgt cr6, 0x82212ddc
	if ctx.cr[6].gt {
	pc = 0x82212DDC; continue 'dispatch;
	}
	// 82212F48: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 82212F4C: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 82212F50: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 82212F54: 3B2BAF50  addi r25, r11, -0x50b0
	ctx.r[25].s64 = ctx.r[11].s64 + -20656;
	// 82212F58: C3AA1FF8  lfs f29, 0x1ff8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82212F5C: 7F0B07B4  extsw r11, r24
	ctx.r[11].s64 = ctx.r[24].s32 as i64;
	// 82212F60: 1D6B00A8  mulli r11, r11, 0xa8
	ctx.r[11].s64 = ctx.r[11].s64 * 168;
	// 82212F64: 7D6BD214  add r11, r11, r26
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 82212F68: 3B8B1BC8  addi r28, r11, 0x1bc8
	ctx.r[28].s64 = ctx.r[11].s64 + 7112;
	// 82212F6C: E97C0010  ld r11, 0x10(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) };
	// 82212F70: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82212F74: 419A0134  beq cr6, 0x822130a8
	if ctx.cr[6].eq {
	pc = 0x822130A8; continue 'dispatch;
	}
	// 82212F78: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82212F7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82212F80: 419A0128  beq cr6, 0x822130a8
	if ctx.cr[6].eq {
	pc = 0x822130A8; continue 'dispatch;
	}
	// 82212F84: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 82212F88: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 82212F8C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82212F90: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 82212F94: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82212F98: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 82212F9C: 38810730  addi r4, r1, 0x730
	ctx.r[4].s64 = ctx.r[1].s64 + 1840;
	// 82212FA0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82212FA4: 480016BD  bl 0x82214660
	ctx.lr = 0x82212FA8;
	sub_82214660(ctx, base);
	// 82212FA8: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 82212FAC: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82212FB0: 3BE100B8  addi r31, r1, 0xb8
	ctx.r[31].s64 = ctx.r[1].s64 + 184;
	// 82212FB4: 3BC10748  addi r30, r1, 0x748
	ctx.r[30].s64 = ctx.r[1].s64 + 1864;
	// 82212FB8: E97C0010  ld r11, 0x10(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) };
	// 82212FBC: 7D6BD838  and r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[27].u64;
	// 82212FC0: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82212FC4: 419A00CC  beq cr6, 0x82213090
	if ctx.cr[6].eq {
	pc = 0x82213090; continue 'dispatch;
	}
	// 82212FC8: 57AB003E  slwi r11, r29, 0
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82212FCC: 389FFFE8  addi r4, r31, -0x18
	ctx.r[4].s64 = ctx.r[31].s64 + -24;
	// 82212FD0: 396B0006  addi r11, r11, 6
	ctx.r[11].s64 = ctx.r[11].s64 + 6;
	// 82212FD4: 38BEFFE8  addi r5, r30, -0x18
	ctx.r[5].s64 = ctx.r[30].s64 + -24;
	// 82212FD8: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82212FDC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82212FE0: 7FEBE42E  lfsx f31, r11, r28
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82212FE4: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82212FE8: 481617B9  bl 0x823747a0
	ctx.lr = 0x82212FEC;
	sub_823747A0(ctx, base);
	// 82212FEC: EC1EF828  fsubs f0, f30, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (((ctx.f[30].f64 - ctx.f[31].f64) as f32) as f64);
	// 82212FF0: C1BFFFF8  lfs f13, -8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82212FF4: C19FFFFC  lfs f12, -4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82212FF8: C17F0000  lfs f11, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82212FFC: C15F0004  lfs f10, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82213000: C13EFFF8  lfs f9, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82213004: C11EFFFC  lfs f8, -4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82213008: C0FE0000  lfs f7, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221300C: C0DE0004  lfs f6, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82213010: C0BE0008  lfs f5, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82213014: C09E000C  lfs f4, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82213018: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221301C: C07E0010  lfs f3, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82213020: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213024: C05E0014  lfs f2, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82213028: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221302C: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213030: EDA96FFA  fmadds f13, f9, f31, f13
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82213034: D1BFFFF8  stfs f13, -8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82213038: EDA867FA  fmadds f13, f8, f31, f12
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221303C: D1BFFFFC  stfs f13, -4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82213040: EDBF59FA  fmadds f13, f31, f7, f11
	ctx.f[13].f64 = (((ctx.f[31].f64 * ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64);
	// 82213044: D1BF0000  stfs f13, 0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213048: EDA657FA  fmadds f13, f6, f31, f10
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 8221304C: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82213050: C1BF0008  lfs f13, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213054: C19F000C  lfs f12, 0xc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213058: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221305C: C17F0010  lfs f11, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213060: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213064: C15F0014  lfs f10, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82213068: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221306C: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 82213070: EDA56FFA  fmadds f13, f5, f31, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82213074: D1BF0008  stfs f13, 8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82213078: EDA467FA  fmadds f13, f4, f31, f12
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221307C: D1BF000C  stfs f13, 0xc(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82213080: EDA35FFA  fmadds f13, f3, f31, f11
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82213084: D1BF0010  stfs f13, 0x10(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82213088: EC0207FA  fmadds f0, f2, f31, f0
	ctx.f[0].f64 = (((ctx.f[2].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221308C: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82213090: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82213094: 3BFF0030  addi r31, r31, 0x30
	ctx.r[31].s64 = ctx.r[31].s64 + 48;
	// 82213098: 3BDE0030  addi r30, r30, 0x30
	ctx.r[30].s64 = ctx.r[30].s64 + 48;
	// 8221309C: 7B7B0FA4  sldi r27, r27, 1
	ctx.r[27].u64 = ctx.r[27].u64.wrapping_shl(1);
	ctx.r[27].u32 = ctx.r[27].u64 as u32;
	// 822130A0: 2B3D0023  cmpldi cr6, r29, 0x23
	ctx.cr[6].compare_u64(ctx.r[29].u64, 35, &mut ctx.xer);
	// 822130A4: 4198FF14  blt cr6, 0x82212fb8
	if ctx.cr[6].lt {
	pc = 0x82212FB8; continue 'dispatch;
	}
	// 822130A8: 3B180001  addi r24, r24, 1
	ctx.r[24].s64 = ctx.r[24].s64 + 1;
	// 822130AC: 2F380007  cmpdi cr6, r24, 7
	ctx.cr[6].compare_i64(ctx.r[24].s64, 7, &mut ctx.xer);
	// 822130B0: 4198FEAC  blt cr6, 0x82212f5c
	if ctx.cr[6].lt {
	pc = 0x82212F5C; continue 'dispatch;
	}
	// 822130B4: 817A2060  lwz r11, 0x2060(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8288 as u32) ) } as u64;
	// 822130B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822130BC: 419A052C  beq cr6, 0x822135e8
	if ctx.cr[6].eq {
	pc = 0x822135E8; continue 'dispatch;
	}
	// 822130C0: 815A1BC0  lwz r10, 0x1bc0(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(7104 as u32) ) } as u64;
	// 822130C4: 3B0B0F80  addi r24, r11, 0xf80
	ctx.r[24].s64 = ctx.r[11].s64 + 3968;
	// 822130C8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822130CC: 419A0160  beq cr6, 0x8221322c
	if ctx.cr[6].eq {
	pc = 0x8221322C; continue 'dispatch;
	}
	// 822130D0: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 822130D4: C1BA1BC4  lfs f13, 0x1bc4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(7108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822130D8: C00B2934  lfs f0, 0x2934(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10548 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822130DC: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 822130E0: 41990054  bgt cr6, 0x82213134
	if ctx.cr[6].gt {
	pc = 0x82213134; continue 'dispatch;
	}
	// 822130E4: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 822130E8: 54EB003E  slwi r11, r7, 0
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822130EC: 811A2060  lwz r8, 0x2060(r26)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8288 as u32) ) } as u64;
	// 822130F0: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 822130F4: 38CB000E  addi r6, r11, 0xe
	ctx.r[6].s64 = ctx.r[11].s64 + 14;
	// 822130F8: 556A3032  slwi r10, r11, 6
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822130FC: 54CB3032  slwi r11, r6, 6
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82213100: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82213104: 7D0BD214  add r8, r11, r26
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 82213108: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8221310C: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 82213110: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 82213114: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 82213118: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8221311C: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82213120: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 82213124: 4200FFF0  bdnz 0x82213114
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82213114; continue 'dispatch;
	}
	// 82213128: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 8221312C: 2B270061  cmpldi cr6, r7, 0x61
	ctx.cr[6].compare_u64(ctx.r[7].u64, 97, &mut ctx.xer);
	// 82213130: 4198FFB8  blt cr6, 0x822130e8
	if ctx.cr[6].lt {
	pc = 0x822130E8; continue 'dispatch;
	}
	// 82213134: 397A02BC  addi r11, r26, 0x2bc
	ctx.r[11].s64 = ctx.r[26].s64 + 700;
	// 82213138: 3B1A1300  addi r24, r26, 0x1300
	ctx.r[24].s64 = ctx.r[26].s64 + 4864;
	// 8221313C: 3D203F80  lis r9, 0x3f80
	ctx.r[9].s64 = 1065353216;
	// 82213140: 39400023  li r10, 0x23
	ctx.r[10].s64 = 35;
	// 82213144: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 82213148: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8221314C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82213150: 4200FFF8  bdnz 0x82213148
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82213148; continue 'dispatch;
	}
	// 82213154: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82213158: C1BA1BC4  lfs f13, 0x1bc4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(7108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221315C: 393A14C0  addi r9, r26, 0x14c0
	ctx.r[9].s64 = ctx.r[26].s64 + 5312;
	// 82213160: 39000008  li r8, 8
	ctx.r[8].s64 = 8;
	// 82213164: C00B2198  lfs f0, 0x2198(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8600 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213168: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221316C: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213170: C1ABBFFC  lfs f13, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213174: ED80F028  fsubs f12, f0, f30
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[30].f64) as f32) as f64);
	// 82213178: FC0C07AE  fsel f0, f12, f30, f0
	ctx.f[0].f64 = if ctx.f[12].f64 >= 0.0 { ctx.f[30].f64 } else { ctx.f[0].f64 };
	// 8221317C: ED9E0028  fsubs f12, f30, f0
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[0].f64) as f32) as f64);
	// 82213180: EC00637A  fmadds f0, f0, f13, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 82213184: D01A02D8  stfs f0, 0x2d8(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(728 as u32), tmp.u32 ) };
	// 82213188: D01A02DC  stfs f0, 0x2dc(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(732 as u32), tmp.u32 ) };
	// 8221318C: D01A0308  stfs f0, 0x308(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(776 as u32), tmp.u32 ) };
	// 82213190: D01A030C  stfs f0, 0x30c(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(780 as u32), tmp.u32 ) };
	// 82213194: 817A2060  lwz r11, 0x2060(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8288 as u32) ) } as u64;
	// 82213198: 394B1140  addi r10, r11, 0x1140
	ctx.r[10].s64 = ctx.r[11].s64 + 4416;
	// 8221319C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 822131A0: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 822131A4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 822131A8: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 822131AC: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 822131B0: 4200FFF0  bdnz 0x822131a0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822131A0; continue 'dispatch;
	}
	// 822131B4: 394B1180  addi r10, r11, 0x1180
	ctx.r[10].s64 = ctx.r[11].s64 + 4480;
	// 822131B8: 393A1500  addi r9, r26, 0x1500
	ctx.r[9].s64 = ctx.r[26].s64 + 5376;
	// 822131BC: 39000008  li r8, 8
	ctx.r[8].s64 = 8;
	// 822131C0: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 822131C4: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 822131C8: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 822131CC: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 822131D0: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 822131D4: 4200FFF0  bdnz 0x822131c4
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822131C4; continue 'dispatch;
	}
	// 822131D8: 394B1440  addi r10, r11, 0x1440
	ctx.r[10].s64 = ctx.r[11].s64 + 5184;
	// 822131DC: 393A17C0  addi r9, r26, 0x17c0
	ctx.r[9].s64 = ctx.r[26].s64 + 6080;
	// 822131E0: 39000008  li r8, 8
	ctx.r[8].s64 = 8;
	// 822131E4: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 822131E8: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 822131EC: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 822131F0: F9090000  std r8, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u64 ) };
	// 822131F4: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 822131F8: 4200FFF0  bdnz 0x822131e8
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822131E8; continue 'dispatch;
	}
	// 822131FC: 396B1480  addi r11, r11, 0x1480
	ctx.r[11].s64 = ctx.r[11].s64 + 5248;
	// 82213200: 395A1800  addi r10, r26, 0x1800
	ctx.r[10].s64 = ctx.r[26].s64 + 6144;
	// 82213204: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82213208: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8221320C: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 82213210: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82213214: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82213218: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8221321C: 4200FFF0  bdnz 0x8221320c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8221320C; continue 'dispatch;
	}
	// 82213220: C01A1BC4  lfs f0, 0x1bc4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(7108 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213224: EC00F02A  fadds f0, f0, f30
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[30].f64) as f32) as f64;
	// 82213228: D01A1BC4  stfs f0, 0x1bc4(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(7108 as u32), tmp.u32 ) };
	// 8221322C: 397A0230  addi r11, r26, 0x230
	ctx.r[11].s64 = ctx.r[26].s64 + 560;
	// 82213230: C39A2064  lfs f28, 0x2064(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8292 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82213234: C341009C  lfs f26, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 82213238: 3B80003E  li r28, 0x3e
	ctx.r[28].s64 = 62;
	// 8221323C: 7D4BD050  subf r10, r11, r26
	ctx.r[10].s64 = ctx.r[26].s64 - ctx.r[11].s64;
	// 82213240: EF7EE024  fdivs f27, f30, f28
	ctx.f[27].f64 = ((ctx.f[30].f64 / ctx.f[28].f64) as f32) as f64;
	// 82213244: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 82213248: 3B2A02BC  addi r25, r10, 0x2bc
	ctx.r[25].s64 = ctx.r[10].s64 + 700;
	// 8221324C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 82213250: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82213254: 3BE10748  addi r31, r1, 0x748
	ctx.r[31].s64 = ctx.r[1].s64 + 1864;
	// 82213258: 3BC100B8  addi r30, r1, 0xb8
	ctx.r[30].s64 = ctx.r[1].s64 + 184;
	// 8221325C: 3B600023  li r27, 0x23
	ctx.r[27].s64 = 35;
	// 82213260: C3AA2074  lfs f29, 0x2074(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8308 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82213264: C32B2150  lfs f25, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 82213268: 7FFDCC2E  lfsx f31, r29, r25
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[25].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221326C: FF1FC800  fcmpu cr6, f31, f25
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[25].f64);
	// 82213270: 40990358  ble cr6, 0x822135c8
	if !ctx.cr[6].gt {
	pc = 0x822135C8; continue 'dispatch;
	}
	// 82213274: 817A1BC0  lwz r11, 0x1bc0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(7104 as u32) ) } as u64;
	// 82213278: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221327C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82213280: 813A2060  lwz r9, 0x2060(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8288 as u32) ) } as u64;
	// 82213284: 554B3032  slwi r11, r10, 6
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82213288: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8221328C: 419A0030  beq cr6, 0x822132bc
	if ctx.cr[6].eq {
	pc = 0x822132BC; continue 'dispatch;
	}
	// 82213290: 2B3C0045  cmpldi cr6, r28, 0x45
	ctx.cr[6].compare_u64(ctx.r[28].u64, 69, &mut ctx.xer);
	// 82213294: 419A0028  beq cr6, 0x822132bc
	if ctx.cr[6].eq {
	pc = 0x822132BC; continue 'dispatch;
	}
	// 82213298: 2B3C0046  cmpldi cr6, r28, 0x46
	ctx.cr[6].compare_u64(ctx.r[28].u64, 70, &mut ctx.xer);
	// 8221329C: 419A0020  beq cr6, 0x822132bc
	if ctx.cr[6].eq {
	pc = 0x822132BC; continue 'dispatch;
	}
	// 822132A0: 2B3C0051  cmpldi cr6, r28, 0x51
	ctx.cr[6].compare_u64(ctx.r[28].u64, 81, &mut ctx.xer);
	// 822132A4: 419A0018  beq cr6, 0x822132bc
	if ctx.cr[6].eq {
	pc = 0x822132BC; continue 'dispatch;
	}
	// 822132A8: 2B3C0052  cmpldi cr6, r28, 0x52
	ctx.cr[6].compare_u64(ctx.r[28].u64, 82, &mut ctx.xer);
	// 822132AC: 419A0010  beq cr6, 0x822132bc
	if ctx.cr[6].eq {
	pc = 0x822132BC; continue 'dispatch;
	}
	// 822132B0: 396A000E  addi r11, r10, 0xe
	ctx.r[11].s64 = ctx.r[10].s64 + 14;
	// 822132B4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822132B8: 7D6BD214  add r11, r11, r26
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 822132BC: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822132C0: 7F05C378  mr r5, r24
	ctx.r[5].u64 = ctx.r[24].u64;
	// 822132C4: EC0C0332  fmuls f0, f12, f12
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 822132C8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822132CC: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822132D0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 822132D4: D3C1008C  stfs f30, 0x8c(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 822132D8: EC0D037A  fmadds f0, f13, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 822132DC: EC0B02FA  fmadds f0, f11, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64);
	// 822132E0: EC1C0024  fdivs f0, f28, f0
	ctx.f[0].f64 = ((ctx.f[28].f64 / ctx.f[0].f64) as f32) as f64;
	// 822132E4: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 822132E8: D1810070  stfs f12, 0x70(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 822132EC: C18B0018  lfs f12, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822132F0: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822132F4: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 822132F8: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 822132FC: ED5A0032  fmuls f10, f26, f0
	ctx.f[10].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213300: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213304: EC0C0332  fmuls f0, f12, f12
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 82213308: D1610060  stfs f11, 0x60(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8221330C: C16B0014  lfs f11, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213310: EC0D037A  fmadds f0, f13, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 82213314: EC0B02FA  fmadds f0, f11, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64);
	// 82213318: EC1C0024  fdivs f0, f28, f0
	ctx.f[0].f64 = ((ctx.f[28].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221331C: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213320: D1810074  stfs f12, 0x74(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82213324: C18B0028  lfs f12, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213328: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221332C: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213330: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82213334: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213338: C1AB0020  lfs f13, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221333C: EC0C0332  fmuls f0, f12, f12
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 82213340: D1610064  stfs f11, 0x64(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82213344: C16B0024  lfs f11, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213348: EC0D037A  fmadds f0, f13, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221334C: EC0B02FA  fmadds f0, f11, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64);
	// 82213350: EC1C0024  fdivs f0, f28, f0
	ctx.f[0].f64 = ((ctx.f[28].f64 / ctx.f[0].f64) as f32) as f64;
	// 82213354: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213358: D1610068  stfs f11, 0x68(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8221335C: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82213360: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82213364: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213368: D1A10058  stfs f13, 0x58(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8221336C: D1810078  stfs f12, 0x78(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82213370: EC0A0032  fmuls f0, f10, f0
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82213374: D001009C  stfs f0, 0x9c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82213378: C00B0030  lfs f0, 0x30(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822136D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x822136D0 size=476
    let mut pc: u32 = 0x822136D0;
    'dispatch: loop {
        match pc {
            0x822136D0 => {
    //   block [0x822136D0..0x822138AC)
	// 822136D0: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 822136D4: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 822136D8: 90640004  stw r3, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 822136DC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 822136E0: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 822136E4: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 822136E8: 39240010  addi r9, r4, 0x10
	ctx.r[9].s64 = ctx.r[4].s64 + 16;
	// 822136EC: C0052150  lfs f0, 0x2150(r5)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822136F0: 3944000C  addi r10, r4, 0xc
	ctx.r[10].s64 = ctx.r[4].s64 + 12;
	// 822136F4: 39640008  addi r11, r4, 8
	ctx.r[11].s64 = ctx.r[4].s64 + 8;
	// 822136F8: 38630078  addi r3, r3, 0x78
	ctx.r[3].s64 = ctx.r[3].s64 + 120;
	// 822136FC: 3BE00002  li r31, 2
	ctx.r[31].s64 = 2;
	// 82213700: 80A3FFFC  lwz r5, -4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82213704: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82213708: 419A004C  beq cr6, 0x82213754
	if ctx.cr[6].eq {
	pc = 0x82213754; continue 'dispatch;
	}
	// 8221370C: 54A5003E  slwi r5, r5, 0
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82213710: C1A50080  lfs f13, 0x80(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213714: C1850094  lfs f12, 0x94(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(148 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213718: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8221371C: C16500A8  lfs f11, 0xa8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(168 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213720: 41990014  bgt cr6, 0x82213734
	if ctx.cr[6].gt {
	pc = 0x82213734; continue 'dispatch;
	}
	// 82213724: FF0C0000  fcmpu cr6, f12, f0
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[0].f64);
	// 82213728: 4199000C  bgt cr6, 0x82213734
	if ctx.cr[6].gt {
	pc = 0x82213734; continue 'dispatch;
	}
	// 8221372C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 82213730: 40990024  ble cr6, 0x82213754
	if !ctx.cr[6].gt {
	pc = 0x82213754; continue 'dispatch;
	}
	// 82213734: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213738: 7CC73B78  or r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 | ctx.r[7].u64;
	// 8221373C: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213740: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82213744: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213748: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8221374C: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 82213750: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 82213754: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213758: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221375C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82213760: 419A004C  beq cr6, 0x822137ac
	if ctx.cr[6].eq {
	pc = 0x822137AC; continue 'dispatch;
	}
	// 82213764: 54A5003E  slwi r5, r5, 0
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82213768: C1A50080  lfs f13, 0x80(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221376C: C1850094  lfs f12, 0x94(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(148 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213770: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82213774: C16500A8  lfs f11, 0xa8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(168 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213778: 41990014  bgt cr6, 0x8221378c
	if ctx.cr[6].gt {
	pc = 0x8221378C; continue 'dispatch;
	}
	// 8221377C: FF0C0000  fcmpu cr6, f12, f0
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[0].f64);
	// 82213780: 4199000C  bgt cr6, 0x8221378c
	if ctx.cr[6].gt {
	pc = 0x8221378C; continue 'dispatch;
	}
	// 82213784: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 82213788: 40990024  ble cr6, 0x822137ac
	if !ctx.cr[6].gt {
	pc = 0x822137AC; continue 'dispatch;
	}
	// 8221378C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213790: 7CC73B78  or r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 | ctx.r[7].u64;
	// 82213794: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213798: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8221379C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822137A0: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 822137A4: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 822137A8: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 822137AC: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822137B0: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 822137B4: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 822137B8: 419A004C  beq cr6, 0x82213804
	if ctx.cr[6].eq {
	pc = 0x82213804; continue 'dispatch;
	}
	// 822137BC: 54A5003E  slwi r5, r5, 0
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 822137C0: C1A50080  lfs f13, 0x80(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822137C4: C1850094  lfs f12, 0x94(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(148 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822137C8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 822137CC: C16500A8  lfs f11, 0xa8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(168 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822137D0: 41990014  bgt cr6, 0x822137e4
	if ctx.cr[6].gt {
	pc = 0x822137E4; continue 'dispatch;
	}
	// 822137D4: FF0C0000  fcmpu cr6, f12, f0
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[0].f64);
	// 822137D8: 4199000C  bgt cr6, 0x822137e4
	if ctx.cr[6].gt {
	pc = 0x822137E4; continue 'dispatch;
	}
	// 822137DC: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 822137E0: 40990024  ble cr6, 0x82213804
	if !ctx.cr[6].gt {
	pc = 0x82213804; continue 'dispatch;
	}
	// 822137E4: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822137E8: 7CC73B78  or r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 | ctx.r[7].u64;
	// 822137EC: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822137F0: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 822137F4: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822137F8: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 822137FC: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 82213800: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 82213804: 80A30008  lwz r5, 8(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213808: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221380C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82213810: 419A004C  beq cr6, 0x8221385c
	if ctx.cr[6].eq {
	pc = 0x8221385C; continue 'dispatch;
	}
	// 82213814: 54A5003E  slwi r5, r5, 0
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82213818: C1A50080  lfs f13, 0x80(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221381C: C1850094  lfs f12, 0x94(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(148 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213820: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82213824: C16500A8  lfs f11, 0xa8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(168 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213828: 41990014  bgt cr6, 0x8221383c
	if ctx.cr[6].gt {
	pc = 0x8221383C; continue 'dispatch;
	}
	// 8221382C: FF0C0000  fcmpu cr6, f12, f0
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[0].f64);
	// 82213830: 4199000C  bgt cr6, 0x8221383c
	if ctx.cr[6].gt {
	pc = 0x8221383C; continue 'dispatch;
	}
	// 82213834: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 82213838: 40990024  ble cr6, 0x8221385c
	if !ctx.cr[6].gt {
	pc = 0x8221385C; continue 'dispatch;
	}
	// 8221383C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213840: 7CC73B78  or r7, r6, r7
	ctx.r[7].u64 = ctx.r[6].u64 | ctx.r[7].u64;
	// 82213844: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213848: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8221384C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82213850: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 82213854: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 82213858: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 8221385C: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 82213860: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82213864: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 82213868: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8221386C: 409AFE94  bne cr6, 0x82213700
	if !ctx.cr[6].eq {
	pc = 0x82213700; continue 'dispatch;
	}
	// 82213870: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 82213874: 419A002C  beq cr6, 0x822138a0
	if ctx.cr[6].eq {
	pc = 0x822138A0; continue 'dispatch;
	}
	// 82213878: 550B083C  slwi r11, r8, 1
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221387C: B0E40002  sth r7, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[7].u16 ) };
	// 82213880: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 82213884: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82213888: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8221388C: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 82213890: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82213894: B1640000  sth r11, 0(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82213898: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8221389C: 4E800020  blr
	return;
	// 822138A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822138A4: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 822138A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822138B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822138B0 size=304
    let mut pc: u32 = 0x822138B0;
    'dispatch: loop {
        match pc {
            0x822138B0 => {
    //   block [0x822138B0..0x822139E0)
	// 822138B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822138B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822138B8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 822138BC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 822138C0: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822138C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 822138C8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 822138CC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 822138D0: 897F0000  lbz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822138D4: 895F0001  lbz r10, 1(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(1 as u32) ) } as u64;
	// 822138D8: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 822138DC: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 822138E0: 556B402E  slwi r11, r11, 8
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(8);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822138E4: 7D7E5378  or r30, r11, r10
	ctx.r[30].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 822138E8: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 822138EC: 48321265  bl 0x82534b50
	ctx.lr = 0x822138F0;
	sub_82534B50(ctx, base);
	// 822138F0: A1210052  lhz r9, 0x52(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[1].u32.wrapping_add(82 as u32) ) } as u64;
	// 822138F4: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 822138F8: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 822138FC: 419A00C8  beq cr6, 0x822139c4
	if ctx.cr[6].eq {
	pc = 0x822139C4; continue 'dispatch;
	}
	// 82213900: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82213904: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 82213908: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8221390C: 38AB0074  addi r5, r11, 0x74
	ctx.r[5].s64 = ctx.r[11].s64 + 116;
	// 82213910: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82213914: 3941005C  addi r10, r1, 0x5c
	ctx.r[10].s64 = ctx.r[1].s64 + 92;
	// 82213918: C1462074  lfs f10, 0x2074(r6)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8308 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221391C: C1671FF8  lfs f11, 0x1ff8(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8184 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213920: C18B2150  lfs f12, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213924: 7D0B4838  and r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 & ctx.r[9].u64;
	// 82213928: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221392C: 419A0088  beq cr6, 0x822139b4
	if ctx.cr[6].eq {
	pc = 0x822139B4; continue 'dispatch;
	}
	// 82213930: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213934: C1AAFFFC  lfs f13, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213938: FF0D6000  fcmpu cr6, f13, f12
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[12].f64);
	// 8221393C: C00B0080  lfs f0, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213940: D00B0088  stfs f0, 0x88(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82213944: 40980008  bge cr6, 0x8221394c
	if !ctx.cr[6].lt {
	pc = 0x8221394C; continue 'dispatch;
	}
	// 82213948: FDA06090  fmr f13, f12
	ctx.f[13].f64 = ctx.f[12].f64;
	// 8221394C: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213950: D1AB0080  stfs f13, 0x80(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82213954: FF006000  fcmpu cr6, f0, f12
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[12].f64);
	// 82213958: D1AB0084  stfs f13, 0x84(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8221395C: D16B0090  stfs f11, 0x90(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82213960: D14B008C  stfs f10, 0x8c(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82213964: C1AB0094  lfs f13, 0x94(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(148 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213968: D1AB009C  stfs f13, 0x9c(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 8221396C: 40980008  bge cr6, 0x82213974
	if !ctx.cr[6].lt {
	pc = 0x82213974; continue 'dispatch;
	}
	// 82213970: FC006090  fmr f0, f12
	ctx.f[0].f64 = ctx.f[12].f64;
	// 82213974: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213978: D00B0094  stfs f0, 0x94(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 8221397C: FF0D6000  fcmpu cr6, f13, f12
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[12].f64);
	// 82213980: D00B0098  stfs f0, 0x98(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82213984: D16B00A4  stfs f11, 0xa4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82213988: D14B00A0  stfs f10, 0xa0(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 8221398C: C00B00A8  lfs f0, 0xa8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(168 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213990: D00B00B0  stfs f0, 0xb0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 82213994: 40980008  bge cr6, 0x8221399c
	if !ctx.cr[6].lt {
	pc = 0x8221399C; continue 'dispatch;
	}
	// 82213998: FDA06090  fmr f13, f12
	ctx.f[13].f64 = ctx.f[12].f64;
	// 8221399C: D1AB00A8  stfs f13, 0xa8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 822139A0: 7D094A78  xor r9, r8, r9
	ctx.r[9].u64 = ctx.r[8].u64 ^ ctx.r[9].u64;
	// 822139A4: D1AB00AC  stfs f13, 0xac(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 822139A8: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 822139AC: D16B00B8  stfs f11, 0xb8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(184 as u32), tmp.u32 ) };
	// 822139B0: D14B00B4  stfs f10, 0xb4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(180 as u32), tmp.u32 ) };
	// 822139B4: 5508083C  slwi r8, r8, 1
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822139B8: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 822139BC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 822139C0: 409AFF64  bne cr6, 0x82213924
	if !ctx.cr[6].eq {
	pc = 0x82213924; continue 'dispatch;
	}
	// 822139C4: 7C7EFA14  add r3, r30, r31
	ctx.r[3].u64 = ctx.r[30].u64 + ctx.r[31].u64;
	// 822139C8: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 822139CC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 822139D0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 822139D4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 822139D8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822139DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822139E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822139E0 size=84
    let mut pc: u32 = 0x822139E0;
    'dispatch: loop {
        match pc {
            0x822139E0 => {
    //   block [0x822139E0..0x82213A34)
	// 822139E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822139E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 822139E8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 822139EC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822139F0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 822139F4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822139F8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 822139FC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82213A00: 807F0154  lwz r3, 0x154(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(340 as u32) ) } as u64;
	// 82213A04: 917F010C  stw r11, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 82213A08: 917F0150  stw r11, 0x150(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(336 as u32), ctx.r[11].u32 ) };
	// 82213A0C: 481ADA35  bl 0x823c1440
	ctx.lr = 0x82213A10;
	sub_823C1440(ctx, base);
	// 82213A10: 807F0158  lwz r3, 0x158(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(344 as u32) ) } as u64;
	// 82213A14: 481ADB0D  bl 0x823c1520
	ctx.lr = 0x82213A18;
	sub_823C1520(ctx, base);
	// 82213A18: 807F015C  lwz r3, 0x15c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(348 as u32) ) } as u64;
	// 82213A1C: 481ADA25  bl 0x823c1440
	ctx.lr = 0x82213A20;
	sub_823C1440(ctx, base);
	// 82213A20: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82213A24: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82213A28: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82213A2C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82213A30: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213A38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213A38 size=368
    let mut pc: u32 = 0x82213A38;
    'dispatch: loop {
        match pc {
            0x82213A38 => {
    //   block [0x82213A38..0x82213BA8)
	// 82213A38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213A3C: 48321679  bl 0x825350b4
	ctx.lr = 0x82213A40;
	sub_82535080(ctx, base);
	// 82213A40: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213A44: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82213A48: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82213A4C: 3BFD0004  addi r31, r29, 4
	ctx.r[31].s64 = ctx.r[29].s64 + 4;
	// 82213A50: 3B7D0110  addi r27, r29, 0x110
	ctx.r[27].s64 = ctx.r[29].s64 + 272;
	// 82213A54: 3B80FFFF  li r28, -1
	ctx.r[28].s64 = -1;
	// 82213A58: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82213A5C: 807D0158  lwz r3, 0x158(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(344 as u32) ) } as u64;
	// 82213A60: 481ADAB9  bl 0x823c1518
	ctx.lr = 0x82213A64;
	sub_823C1518(ctx, base);
	// 82213A64: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213A68: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82213A6C: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213A70: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213A74: 4E800421  bctrl
	ctx.lr = 0x82213A78;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213A78: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213A7C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213A80: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82213A84: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82213A88: 40980008  bge cr6, 0x82213a90
	if !ctx.cr[6].lt {
	pc = 0x82213A90; continue 'dispatch;
	}
	// 82213A8C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82213A90: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213A94: 2F0B0010  cmpwi cr6, r11, 0x10
	ctx.cr[6].compare_i32(ctx.r[11].s32, 16, &mut ctx.xer);
	// 82213A98: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82213A9C: 40980008  bge cr6, 0x82213aa4
	if !ctx.cr[6].lt {
	pc = 0x82213AA4; continue 'dispatch;
	}
	// 82213AA0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82213AA4: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82213AA8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82213AAC: 419A001C  beq cr6, 0x82213ac8
	if ctx.cr[6].eq {
	pc = 0x82213AC8; continue 'dispatch;
	}
	// 82213AB0: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213AB4: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82213AB8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213ABC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213AC0: 4E800421  bctrl
	ctx.lr = 0x82213AC4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213AC4: 4BFFFF94  b 0x82213a58
	pc = 0x82213A58; continue 'dispatch;
	// 82213AC8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213ACC: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213AD0: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82213AD4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82213AD8: 40980008  bge cr6, 0x82213ae0
	if !ctx.cr[6].lt {
	pc = 0x82213AE0; continue 'dispatch;
	}
	// 82213ADC: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82213AE0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82213AE4: 2F0A0010  cmpwi cr6, r10, 0x10
	ctx.cr[6].compare_i32(ctx.r[10].s32, 16, &mut ctx.xer);
	// 82213AE8: 4098004C  bge cr6, 0x82213b34
	if !ctx.cr[6].lt {
	pc = 0x82213B34; continue 'dispatch;
	}
	// 82213AEC: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82213AF0: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213AF4: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82213AF8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82213AFC: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82213B00: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213B04: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82213B08: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213B0C: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82213B10: 815E000C  lwz r10, 0xc(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 82213B14: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82213B18: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213B1C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213B20: 2F0B0010  cmpwi cr6, r11, 0x10
	ctx.cr[6].compare_i32(ctx.r[11].s32, 16, &mut ctx.xer);
	// 82213B24: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82213B28: 4198000C  blt cr6, 0x82213b34
	if ctx.cr[6].lt {
	pc = 0x82213B34; continue 'dispatch;
	}
	// 82213B2C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82213B30: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82213B34: 817D010C  lwz r11, 0x10c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(268 as u32) ) } as u64;
	// 82213B38: 807D0154  lwz r3, 0x154(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(340 as u32) ) } as u64;
	// 82213B3C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213B40: 917D010C  stw r11, 0x10c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 82213B44: 481AD9DD  bl 0x823c1520
	ctx.lr = 0x82213B48;
	sub_823C1520(ctx, base);
	// 82213B48: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213B4C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213B50: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82213B54: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82213B58: 40980008  bge cr6, 0x82213b60
	if !ctx.cr[6].lt {
	pc = 0x82213B60; continue 'dispatch;
	}
	// 82213B5C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82213B60: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213B64: 2F0B0010  cmpwi cr6, r11, 0x10
	ctx.cr[6].compare_i32(ctx.r[11].s32, 16, &mut ctx.xer);
	// 82213B68: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82213B6C: 40980008  bge cr6, 0x82213b74
	if !ctx.cr[6].lt {
	pc = 0x82213B74; continue 'dispatch;
	}
	// 82213B70: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82213B74: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82213B78: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82213B7C: 419A000C  beq cr6, 0x82213b88
	if ctx.cr[6].eq {
	pc = 0x82213B88; continue 'dispatch;
	}
	// 82213B80: 807D0158  lwz r3, 0x158(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(344 as u32) ) } as u64;
	// 82213B84: 481AD8BD  bl 0x823c1440
	ctx.lr = 0x82213B88;
	sub_823C1440(ctx, base);
	// 82213B88: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213B8C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82213B90: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213B94: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213B98: 4E800421  bctrl
	ctx.lr = 0x82213B9C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213B9C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82213BA0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82213BA4: 48321560  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213BA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213BA8 size=124
    let mut pc: u32 = 0x82213BA8;
    'dispatch: loop {
        match pc {
            0x82213BA8 => {
    //   block [0x82213BA8..0x82213C24)
	// 82213BA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213BAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213BB0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82213BB4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82213BB8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213BBC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82213BC0: 3BDF0130  addi r30, r31, 0x130
	ctx.r[30].s64 = ctx.r[31].s64 + 304;
	// 82213BC4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213BC8: 817F0130  lwz r11, 0x130(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 82213BCC: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213BD0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213BD4: 4E800421  bctrl
	ctx.lr = 0x82213BD8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213BD8: 817F0150  lwz r11, 0x150(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(336 as u32) ) } as u64;
	// 82213BDC: 815F010C  lwz r10, 0x10c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) } as u64;
	// 82213BE0: 807F015C  lwz r3, 0x15c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(348 as u32) ) } as u64;
	// 82213BE4: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213BE8: 4098000C  bge cr6, 0x82213bf4
	if !ctx.cr[6].lt {
	pc = 0x82213BF4; continue 'dispatch;
	}
	// 82213BEC: 481AD855  bl 0x823c1440
	ctx.lr = 0x82213BF0;
	sub_823C1440(ctx, base);
	// 82213BF0: 48000008  b 0x82213bf8
	pc = 0x82213BF8; continue 'dispatch;
	// 82213BF4: 481AD92D  bl 0x823c1520
	ctx.lr = 0x82213BF8;
	sub_823C1520(ctx, base);
	// 82213BF8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213BFC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213C00: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213C04: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213C08: 4E800421  bctrl
	ctx.lr = 0x82213C0C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213C0C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82213C10: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82213C14: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82213C18: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82213C1C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82213C20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213C28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213C28 size=44
    let mut pc: u32 = 0x82213C28;
    'dispatch: loop {
        match pc {
            0x82213C28 => {
    //   block [0x82213C28..0x82213C54)
	// 82213C28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213C2C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213C30: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213C34: 3880FFFF  li r4, -1
	ctx.r[4].s64 = -1;
	// 82213C38: 8063015C  lwz r3, 0x15c(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(348 as u32) ) } as u64;
	// 82213C3C: 481AD8DD  bl 0x823c1518
	ctx.lr = 0x82213C40;
	sub_823C1518(ctx, base);
	// 82213C40: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82213C44: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82213C48: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82213C4C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82213C50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213C58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213C58 size=300
    let mut pc: u32 = 0x82213C58;
    'dispatch: loop {
        match pc {
            0x82213C58 => {
    //   block [0x82213C58..0x82213D84)
	// 82213C58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213C5C: 48321459  bl 0x825350b4
	ctx.lr = 0x82213C60;
	sub_82535080(ctx, base);
	// 82213C60: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213C64: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82213C68: 3B60FFFF  li r27, -1
	ctx.r[27].s64 = -1;
	// 82213C6C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82213C70: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82213C74: 807D0154  lwz r3, 0x154(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(340 as u32) ) } as u64;
	// 82213C78: 481AD8A1  bl 0x823c1518
	ctx.lr = 0x82213C7C;
	sub_823C1518(ctx, base);
	// 82213C7C: 817D0110  lwz r11, 0x110(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(272 as u32) ) } as u64;
	// 82213C80: 3BDD0110  addi r30, r29, 0x110
	ctx.r[30].s64 = ctx.r[29].s64 + 272;
	// 82213C84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213C88: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213C8C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213C90: 4E800421  bctrl
	ctx.lr = 0x82213C94;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213C94: 3BFD0004  addi r31, r29, 4
	ctx.r[31].s64 = ctx.r[29].s64 + 4;
	// 82213C98: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213C9C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213CA0: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213CA4: 409A0048  bne cr6, 0x82213cec
	if !ctx.cr[6].eq {
	pc = 0x82213CEC; continue 'dispatch;
	}
	// 82213CA8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213CAC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213CB0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213CB4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213CB8: 4E800421  bctrl
	ctx.lr = 0x82213CBC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213CBC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82213CC0: 807D0154  lwz r3, 0x154(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(340 as u32) ) } as u64;
	// 82213CC4: 481AD855  bl 0x823c1518
	ctx.lr = 0x82213CC8;
	sub_823C1518(ctx, base);
	// 82213CC8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213CCC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213CD0: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213CD4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213CD8: 4E800421  bctrl
	ctx.lr = 0x82213CDC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213CDC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213CE0: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213CE4: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213CE8: 419AFFC0  beq cr6, 0x82213ca8
	if ctx.cr[6].eq {
	pc = 0x82213CA8; continue 'dispatch;
	}
	// 82213CEC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213CF0: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82213CF4: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82213CF8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82213CFC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213D00: 915C0000  stw r10, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82213D04: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213D08: 915C0004  stw r10, 4(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82213D0C: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213D10: 915C0008  stw r10, 8(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82213D14: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82213D18: 917C000C  stw r11, 0xc(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82213D1C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213D20: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213D24: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213D28: 419A001C  beq cr6, 0x82213d44
	if ctx.cr[6].eq {
	pc = 0x82213D44; continue 'dispatch;
	}
	// 82213D2C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213D30: 2F0B0010  cmpwi cr6, r11, 0x10
	ctx.cr[6].compare_i32(ctx.r[11].s32, 16, &mut ctx.xer);
	// 82213D34: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82213D38: 4198000C  blt cr6, 0x82213d44
	if ctx.cr[6].lt {
	pc = 0x82213D44; continue 'dispatch;
	}
	// 82213D3C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82213D40: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82213D44: 807D0158  lwz r3, 0x158(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(344 as u32) ) } as u64;
	// 82213D48: 481AD7D9  bl 0x823c1520
	ctx.lr = 0x82213D4C;
	sub_823C1520(ctx, base);
	// 82213D4C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213D50: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213D54: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213D58: 409A000C  bne cr6, 0x82213d64
	if !ctx.cr[6].eq {
	pc = 0x82213D64; continue 'dispatch;
	}
	// 82213D5C: 807D0154  lwz r3, 0x154(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(340 as u32) ) } as u64;
	// 82213D60: 481AD6E1  bl 0x823c1440
	ctx.lr = 0x82213D64;
	sub_823C1440(ctx, base);
	// 82213D64: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213D68: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213D6C: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213D70: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213D74: 4E800421  bctrl
	ctx.lr = 0x82213D78;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213D78: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82213D7C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82213D80: 48321384  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213D88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213D88 size=124
    let mut pc: u32 = 0x82213D88;
    'dispatch: loop {
        match pc {
            0x82213D88 => {
    //   block [0x82213D88..0x82213E04)
	// 82213D88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213D8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213D90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82213D94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82213D98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213D9C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82213DA0: 3BDF0130  addi r30, r31, 0x130
	ctx.r[30].s64 = ctx.r[31].s64 + 304;
	// 82213DA4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213DA8: 817F0130  lwz r11, 0x130(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 82213DAC: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82213DB0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213DB4: 4E800421  bctrl
	ctx.lr = 0x82213DB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213DB8: 817F0150  lwz r11, 0x150(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(336 as u32) ) } as u64;
	// 82213DBC: 815F010C  lwz r10, 0x10c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) } as u64;
	// 82213DC0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82213DC4: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82213DC8: 917F0150  stw r11, 0x150(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(336 as u32), ctx.r[11].u32 ) };
	// 82213DCC: 4198000C  blt cr6, 0x82213dd8
	if ctx.cr[6].lt {
	pc = 0x82213DD8; continue 'dispatch;
	}
	// 82213DD0: 807F015C  lwz r3, 0x15c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(348 as u32) ) } as u64;
	// 82213DD4: 481AD74D  bl 0x823c1520
	ctx.lr = 0x82213DD8;
	sub_823C1520(ctx, base);
	// 82213DD8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82213DDC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82213DE0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82213DE4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82213DE8: 4E800421  bctrl
	ctx.lr = 0x82213DEC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82213DEC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82213DF0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82213DF4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82213DF8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82213DFC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82213E00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213E08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82213E08 size=208
    let mut pc: u32 = 0x82213E08;
    'dispatch: loop {
        match pc {
            0x82213E08 => {
    //   block [0x82213E08..0x82213ED8)
	// 82213E08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213E0C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213E10: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213E14: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82213E18: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82213E1C: 39490008  addi r10, r9, 8
	ctx.r[10].s64 = ctx.r[9].s64 + 8;
	// 82213E20: 386900B8  addi r3, r9, 0xb8
	ctx.r[3].s64 = ctx.r[9].s64 + 184;
	// 82213E24: C1AB1FF8  lfs f13, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213E28: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82213E2C: 390B4634  addi r8, r11, 0x4634
	ctx.r[8].s64 = ctx.r[11].s64 + 17972;
	// 82213E30: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 82213E34: D1AA000C  stfs f13, 0xc(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82213E38: D1AA0064  stfs f13, 0x64(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82213E3C: D1AA00BC  stfs f13, 0xbc(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(188 as u32), tmp.u32 ) };
	// 82213E40: D1AA0114  stfs f13, 0x114(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(276 as u32), tmp.u32 ) };
	// 82213E44: 910A0000  stw r8, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82213E48: C18BBA38  lfs f12, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213E4C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82213E50: 910A0058  stw r8, 0x58(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(88 as u32), ctx.r[8].u32 ) };
	// 82213E54: FC206090  fmr f1, f12
	ctx.f[1].f64 = ctx.f[12].f64;
	// 82213E58: 910A00B0  stw r8, 0xb0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(176 as u32), ctx.r[8].u32 ) };
	// 82213E5C: 910A0108  stw r8, 0x108(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(264 as u32), ctx.r[8].u32 ) };
	// 82213E60: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82213E64: 916A0008  stw r11, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82213E68: F96A0010  std r11, 0x10(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 82213E6C: 916A005C  stw r11, 0x5c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 82213E70: 916A0060  stw r11, 0x60(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82213E74: F96A0068  std r11, 0x68(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(104 as u32), ctx.r[11].u64 ) };
	// 82213E78: 916A00B4  stw r11, 0xb4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 82213E7C: 916A00B8  stw r11, 0xb8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 82213E80: F96A00C0  std r11, 0xc0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(192 as u32), ctx.r[11].u64 ) };
	// 82213E84: 916A010C  stw r11, 0x10c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 82213E88: 916A0110  stw r11, 0x110(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 82213E8C: F96A0118  std r11, 0x118(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(280 as u32), ctx.r[11].u64 ) };
	// 82213E90: 916901E0  stw r11, 0x1e0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(480 as u32), ctx.r[11].u32 ) };
	// 82213E94: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82213E98: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82213E9C: 480096C5  bl 0x8221d560
	ctx.lr = 0x82213EA0;
	sub_8221D560(ctx, base);
	// 82213EA0: 38690110  addi r3, r9, 0x110
	ctx.r[3].s64 = ctx.r[9].s64 + 272;
	// 82213EA4: FC206890  fmr f1, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[13].f64;
	// 82213EA8: 480096B9  bl 0x8221d560
	ctx.lr = 0x82213EAC;
	sub_8221D560(ctx, base);
	// 82213EAC: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 82213EB0: FC206090  fmr f1, f12
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[12].f64;
	// 82213EB4: 480096AD  bl 0x8221d560
	ctx.lr = 0x82213EB8;
	sub_8221D560(ctx, base);
	// 82213EB8: 38690060  addi r3, r9, 0x60
	ctx.r[3].s64 = ctx.r[9].s64 + 96;
	// 82213EBC: FC206890  fmr f1, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[13].f64;
	// 82213EC0: 480096A1  bl 0x8221d560
	ctx.lr = 0x82213EC4;
	sub_8221D560(ctx, base);
	// 82213EC4: 7D234B78  mr r3, r9
	ctx.r[3].u64 = ctx.r[9].u64;
	// 82213EC8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82213ECC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82213ED0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82213ED4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213ED8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82213ED8 size=244
    let mut pc: u32 = 0x82213ED8;
    'dispatch: loop {
        match pc {
            0x82213ED8 => {
    //   block [0x82213ED8..0x82213FCC)
	// 82213ED8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213EDC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213EE0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213EE4: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 82213EE8: C1840000  lfs f12, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82213EEC: C1240004  lfs f9, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82213EF0: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 82213EF4: C004000C  lfs f0, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82213EF8: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 82213EFC: C0E40008  lfs f7, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82213F00: 38AB0010  addi r5, r11, 0x10
	ctx.r[5].s64 = ctx.r[11].s64 + 16;
	// 82213F04: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82213F08: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82213F0C: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82213F10: ECAB0332  fmuls f5, f11, f12
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 82213F14: C10B0004  lfs f8, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82213F18: ECCC0372  fmuls f6, f12, f13
	ctx.f[6].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 82213F1C: EC890372  fmuls f4, f9, f13
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82213F20: C14ABA38  lfs f10, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82213F24: EC680332  fmuls f3, f8, f12
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 82213F28: D141007C  stfs f10, 0x7c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82213F2C: D1410078  stfs f10, 0x78(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82213F30: D1410074  stfs f10, 0x74(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82213F34: D1410070  stfs f10, 0x70(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82213F38: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82213F3C: ECAD2838  fmsubs f5, f13, f0, f5
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 - ctx.f[5].f64) as f32) as f64);
	// 82213F40: ECCA327A  fmadds f6, f10, f9, f6
	ctx.f[6].f64 = (((ctx.f[10].f64 * ctx.f[9].f64 + ctx.f[6].f64) as f32) as f64);
	// 82213F44: EC8722FA  fmadds f4, f7, f11, f4
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64);
	// 82213F48: EDA71B7A  fmadds f13, f7, f13, f3
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[3].f64) as f32) as f64);
	// 82213F4C: ECA82A7C  fnmsubs f5, f8, f9, f5
	ctx.f[5].f64 = -(((ctx.f[8].f64 * ctx.f[9].f64 - ctx.f[5].f64) as f32) as f64);
	// 82213F50: ECCB303A  fmadds f6, f11, f0, f6
	ctx.f[6].f64 = (((ctx.f[11].f64 * ctx.f[0].f64 + ctx.f[6].f64) as f32) as f64);
	// 82213F54: EC88203A  fmadds f4, f8, f0, f4
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[0].f64 + ctx.f[4].f64) as f32) as f64);
	// 82213F58: EC0A683A  fmadds f0, f10, f0, f13
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82213F5C: EDAA29FC  fnmsubs f13, f10, f7, f5
	ctx.f[13].f64 = -(((ctx.f[10].f64 * ctx.f[7].f64 - ctx.f[5].f64) as f32) as f64);
	// 82213F60: D1A1005C  stfs f13, 0x5c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82213F64: EDA7323C  fnmsubs f13, f7, f8, f6
	ctx.f[13].f64 = -(((ctx.f[7].f64 * ctx.f[8].f64 - ctx.f[6].f64) as f32) as f64);
	// 82213F68: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82213F6C: EDAA233C  fnmsubs f13, f10, f12, f4
	ctx.f[13].f64 = -(((ctx.f[10].f64 * ctx.f[12].f64 - ctx.f[4].f64) as f32) as f64);
	// 82213F70: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82213F74: EC0902FC  fnmsubs f0, f9, f11, f0
	ctx.f[0].f64 = -(((ctx.f[9].f64 * ctx.f[11].f64 - ctx.f[0].f64) as f32) as f64);
	// 82213F78: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82213F7C: 48153855  bl 0x823677d0
	ctx.lr = 0x82213F80;
	sub_823677D0(ctx, base);
	// 82213F80: 38E00010  li r7, 0x10
	ctx.r[7].s64 = 16;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82213FD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82213FD0 size=212
    let mut pc: u32 = 0x82213FD0;
    'dispatch: loop {
        match pc {
            0x82213FD0 => {
    //   block [0x82213FD0..0x822140A4)
	// 82213FD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82213FD4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82213FD8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82213FDC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82213FE0: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 82213FE4: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 82213FE8: 55693032  slwi r9, r11, 6
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82213FEC: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82213FF0: 7CA94214  add r5, r9, r8
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82213FF4: 3920FFFF  li r9, -1
	ctx.r[9].s64 = -1;
	// 82213FF8: 7FEA2214  add r31, r10, r4
	ctx.r[31].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 82213FFC: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 82214000: 7F0B3000  cmpw cr6, r11, r6
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82214004: 4098008C  bge cr6, 0x82214090
	if !ctx.cr[6].lt {
	pc = 0x82214090; continue 'dispatch;
	}
	// 82214008: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 8221400C: 388B64F0  addi r4, r11, 0x64f0
	ctx.r[4].s64 = ctx.r[11].s64 + 25840;
	// 82214010: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214014: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 82214018: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221401C: 41980064  blt cr6, 0x82214080
	if ctx.cr[6].lt {
	pc = 0x82214080; continue 'dispatch;
	}
	// 82214020: 7F095800  cmpw cr6, r9, r11
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82214024: 419A002C  beq cr6, 0x82214050
	if ctx.cr[6].eq {
	pc = 0x82214050; continue 'dispatch;
	}
	// 82214028: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221402C: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 82214030: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82214034: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82214038: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8221403C: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 82214040: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82214044: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82214048: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8221404C: 4200FFF0  bdnz 0x8221403c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8221403C; continue 'dispatch;
	}
	// 82214050: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82214054: 48153CDD  bl 0x82367d30
	ctx.lr = 0x82214058;
	sub_82367D30(ctx, base);
	// 82214058: 7CAA2B78  mr r10, r5
	ctx.r[10].u64 = ctx.r[5].u64;
	// 8221405C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 82214060: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82214064: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 82214068: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 8221406C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82214070: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82214074: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 82214078: 4200FFF0  bdnz 0x82214068
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82214068; continue 'dispatch;
	}
	// 8221407C: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 82214080: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82214084: 38A50040  addi r5, r5, 0x40
	ctx.r[5].s64 = ctx.r[5].s64 + 64;
	// 82214088: 7F073000  cmpw cr6, r7, r6
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8221408C: 4198FF84  blt cr6, 0x82214010
	if ctx.cr[6].lt {
	pc = 0x82214010; continue 'dispatch;
	}
	// 82214090: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82214094: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82214098: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221409C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 822140A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822140A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822140A8 size=140
    let mut pc: u32 = 0x822140A8;
    'dispatch: loop {
        match pc {
            0x822140A8 => {
    //   block [0x822140A8..0x82214134)
	// 822140A8: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 822140AC: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 822140B0: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 822140B4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 822140B8: 20A40020  subfic r5, r4, 0x20
	ctx.xer.ca = ctx.r[4].u32 <= 32 as u32;
	ctx.r[5].s64 = (32 as i64) - ctx.r[4].s64;
	// 822140BC: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 822140C0: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822140C4: 40980030  bge cr6, 0x822140f4
	if !ctx.cr[6].lt {
	pc = 0x822140F4; continue 'dispatch;
	}
	// 822140C8: 212B0020  subfic r9, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[9].s64 = (32 as i64) - ctx.r[11].s64;
	// 822140CC: A4CA0002  lhzu r6, 2(r10)
	ea = (ctx.r[10].u32 as u32).wrapping_add(0x2);
	ctx.r[6].u32 = unsafe { crate::rt::load_u16(base as *mut u8, ea) } as u32;
	ctx.r[10].u32 = ea;
	// 822140D0: 7C8B2050  subf r4, r11, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 822140D4: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 822140D8: 2F040010  cmpwi cr6, r4, 0x10
	ctx.cr[6].compare_i32(ctx.r[4].s32, 16, &mut ctx.xer);
	// 822140DC: 7D1F4830  slw r31, r8, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[31].u64 = 0;
	} else {
		ctx.r[31].u64 = ((ctx.r[8].u32) << ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 822140E0: 7D244850  subf r9, r4, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[4].s64;
	// 822140E4: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 822140E8: 7FE94C30  srw r9, r31, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[31].u32) >> ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 822140EC: 7D273B78  or r7, r9, r7
	ctx.r[7].u64 = ctx.r[9].u64 | ctx.r[7].u64;
	// 822140F0: 4199FFD8  bgt cr6, 0x822140c8
	if ctx.cr[6].gt {
	pc = 0x822140C8; continue 'dispatch;
	}
	// 822140F4: 212B0020  subfic r9, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[9].s64 = (32 as i64) - ctx.r[11].s64;
	// 822140F8: 20C40020  subfic r6, r4, 0x20
	ctx.xer.ca = ctx.r[4].u32 <= 32 as u32;
	ctx.r[6].s64 = (32 as i64) - ctx.r[4].s64;
	// 822140FC: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 82214100: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82214104: 7D094830  slw r9, r8, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[8].u32) << ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 82214108: 7D293430  srw r9, r9, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[9].u32) >> ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 8221410C: 7D293B78  or r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 | ctx.r[7].u64;
	// 82214110: 4199000C  bgt cr6, 0x8221411c
	if ctx.cr[6].gt {
	pc = 0x8221411C; continue 'dispatch;
	}
	// 82214114: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82214118: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 8221411C: 7D292830  slw r9, r9, r5
	if (ctx.r[5].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[9].u32) << ((ctx.r[5].u8 & 0x1F) as u32)) as u64;
	}
	// 82214120: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82214124: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82214128: 7D232E30  sraw r3, r9, r5
	tmp.u32 = ctx.r[5].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[3].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8221412C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 82214130: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82214138(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82214138 size=124
    let mut pc: u32 = 0x82214138;
    'dispatch: loop {
        match pc {
            0x82214138 => {
    //   block [0x82214138..0x822141B4)
	// 82214138: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8221413C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82214140: 81450004  lwz r10, 4(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 82214144: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214148: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 8221414C: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214150: 40980030  bge cr6, 0x82214180
	if !ctx.cr[6].lt {
	pc = 0x82214180; continue 'dispatch;
	}
	// 82214154: 212B0020  subfic r9, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[9].s64 = (32 as i64) - ctx.r[11].s64;
	// 82214158: A4CA0002  lhzu r6, 2(r10)
	ea = (ctx.r[10].u32 as u32).wrapping_add(0x2);
	ctx.r[6].u32 = unsafe { crate::rt::load_u16(base as *mut u8, ea) } as u32;
	ctx.r[10].u32 = ea;
	// 8221415C: 7C8B2050  subf r4, r11, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82214160: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 82214164: 2F040010  cmpwi cr6, r4, 0x10
	ctx.cr[6].compare_i32(ctx.r[4].s32, 16, &mut ctx.xer);
	// 82214168: 7D034830  slw r3, r8, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[3].u64 = 0;
	} else {
		ctx.r[3].u64 = ((ctx.r[8].u32) << ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 8221416C: 7D244850  subf r9, r4, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[4].s64;
	// 82214170: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 82214174: 7C694C30  srw r9, r3, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[3].u32) >> ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 82214178: 7D273B78  or r7, r9, r7
	ctx.r[7].u64 = ctx.r[9].u64 | ctx.r[7].u64;
	// 8221417C: 4199FFD8  bgt cr6, 0x82214154
	if ctx.cr[6].gt {
	pc = 0x82214154; continue 'dispatch;
	}
	// 82214180: 212B0020  subfic r9, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[9].s64 = (32 as i64) - ctx.r[11].s64;
	// 82214184: 20C40020  subfic r6, r4, 0x20
	ctx.xer.ca = ctx.r[4].u32 <= 32 as u32;
	ctx.r[6].s64 = (32 as i64) - ctx.r[4].s64;
	// 82214188: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 8221418C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82214190: 7D094830  slw r9, r8, r9
	if (ctx.r[9].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[8].u32) << ((ctx.r[9].u8 & 0x1F) as u32)) as u64;
	}
	// 82214194: 7D293430  srw r9, r9, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[9].u64 = 0;
	} else {
		ctx.r[9].u64 = ((ctx.r[9].u32) >> ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 82214198: 7D233B78  or r3, r9, r7
	ctx.r[3].u64 = ctx.r[9].u64 | ctx.r[7].u64;
	// 8221419C: 4199000C  bgt cr6, 0x822141a8
	if ctx.cr[6].gt {
	pc = 0x822141A8; continue 'dispatch;
	}
	// 822141A0: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822141A4: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 822141A8: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 822141AC: 91450004  stw r10, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 822141B0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822141B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822141B8 size=416
    let mut pc: u32 = 0x822141B8;
    'dispatch: loop {
        match pc {
            0x822141B8 => {
    //   block [0x822141B8..0x82214358)
	// 822141B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822141BC: 48320EED  bl 0x825350a8
	ctx.lr = 0x822141C0;
	sub_82535080(ctx, base);
	// 822141C0: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 822141C4: 9421E150  stwu r1, -0x1eb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-7856 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822141C8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 822141CC: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 822141D0: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 822141D4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 822141D8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 822141DC: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 822141E0: 481AD381  bl 0x823c1560
	ctx.lr = 0x822141E4;
	sub_823C1560(ctx, base);
	// 822141E4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 822141E8: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 822141EC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 822141F0: 4BFFFF49  bl 0x82214138
	ctx.lr = 0x822141F4;
	sub_82214138(ctx, base);
	// 822141F4: 7F1D1800  cmpw cr6, r29, r3
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[3].s32, &mut ctx.xer);
	// 822141F8: 40980008  bge cr6, 0x82214200
	if !ctx.cr[6].lt {
	pc = 0x82214200; continue 'dispatch;
	}
	// 822141FC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82214200: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82214204: 40990034  ble cr6, 0x82214238
	if !ctx.cr[6].gt {
	pc = 0x82214238; continue 'dispatch;
	}
	// 82214208: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8221420C: 5468402E  slwi r8, r3, 8
	ctx.r[8].u32 = ctx.r[3].u32.wrapping_shl(8);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82214210: 7D635A14  add r11, r3, r11
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 82214214: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 82214218: 894BFFFF  lbz r10, -1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(-1 as u32) ) } as u64;
	// 8221421C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 82214220: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82214224: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82214228: 394AFF00  addi r10, r10, -0x100
	ctx.r[10].s64 = ctx.r[10].s64 + -256;
	// 8221422C: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82214230: 992BFFFF  stb r9, -1(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(-1 as u32), ctx.r[9].u8 ) };
	// 82214234: 7FEA2B2E  sthx r31, r10, r5
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[5].u32), ctx.r[31].u16) };
	// 82214238: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 8221423C: 2B3F0012  cmpldi cr6, r31, 0x12
	ctx.cr[6].compare_u64(ctx.r[31].u64, 18, &mut ctx.xer);
	// 82214240: 4198FFA8  blt cr6, 0x822141e8
	if ctx.cr[6].lt {
	pc = 0x822141E8; continue 'dispatch;
	}
	// 82214244: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 82214248: 93BE0000  stw r29, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8221424C: 57A9482C  slwi r9, r29, 9
	ctx.r[9].u32 = ctx.r[29].u32.wrapping_shl(9);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82214250: 397E004C  addi r11, r30, 0x4c
	ctx.r[11].s64 = ctx.r[30].s64 + 76;
	// 82214254: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 82214258: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 8221425C: 7D1D5214  add r8, r29, r10
	ctx.r[8].u64 = ctx.r[29].u64 + ctx.r[10].u64;
	// 82214260: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82214264: 3B800001  li r28, 1
	ctx.r[28].s64 = 1;
	// 82214268: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8221426C: 3B49FE00  addi r26, r9, -0x200
	ctx.r[26].s64 = ctx.r[9].s64 + -512;
	// 82214270: 917E0008  stw r11, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82214274: 3B28FFFF  addi r25, r8, -1
	ctx.r[25].s64 = ctx.r[8].s64 + -1;
	// 82214278: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 8221427C: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 82214280: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82214284: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82214288: 40990098  ble cr6, 0x82214320
	if !ctx.cr[6].gt {
	pc = 0x82214320; continue 'dispatch;
	}
	// 8221428C: 8B790000  lbz r27, 0(r25)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214290: 7F47D378  mr r7, r26
	ctx.r[7].u64 = ctx.r[26].u64;
	// 82214294: 3B5AFE00  addi r26, r26, -0x200
	ctx.r[26].s64 = ctx.r[26].s64 + -512;
	// 82214298: 3B39FFFF  addi r25, r25, -1
	ctx.r[25].s64 = ctx.r[25].s64 + -1;
	// 8221429C: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 822142A0: 40990068  ble cr6, 0x82214308
	if !ctx.cr[6].gt {
	pc = 0x82214308; continue 'dispatch;
	}
	// 822142A4: 39250001  addi r9, r5, 1
	ctx.r[9].s64 = ctx.r[5].s64 + 1;
	// 822142A8: 57E4063E  clrlwi r4, r31, 0x18
	ctx.r[4].u64 = ctx.r[31].u32 as u64 & 0x000000FFu64;
	// 822142AC: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822142B0: 5783043E  clrlwi r3, r28, 0x10
	ctx.r[3].u64 = ctx.r[28].u32 as u64 & 0x0000FFFFu64;
	// 822142B4: 5549043E  clrlwi r9, r10, 0x10
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x0000FFFFu64;
	// 822142B8: 7D08F214  add r8, r8, r30
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[30].u64;
	// 822142BC: 7D291A14  add r9, r9, r3
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[3].u64;
	// 822142C0: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 822142C4: A3070000  lhz r24, 0(r7)
	ctx.r[24].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 822142C8: 38E70002  addi r7, r7, 2
	ctx.r[7].s64 = ctx.r[7].s64 + 2;
	// 822142CC: 552A043E  clrlwi r10, r9, 0x10
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x0000FFFFu64;
	// 822142D0: 988B0002  stb r4, 2(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(2 as u32), ctx.r[4].u8 ) };
	// 822142D4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 822142D8: 9B0B0003  stb r24, 3(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(3 as u32), ctx.r[24].u8 ) };
	// 822142DC: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 822142E0: 40990018  ble cr6, 0x822142f8
	if !ctx.cr[6].gt {
	pc = 0x822142F8; continue 'dispatch;
	}
	// 822142E4: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 822142E8: 91680000  stw r11, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 822142EC: 38A50001  addi r5, r5, 1
	ctx.r[5].s64 = ctx.r[5].s64 + 1;
	// 822142F0: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 822142F4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 822142F8: 3B7BFFFF  addi r27, r27, -1
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	// 822142FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82214300: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 82214304: 4199FFB8  bgt cr6, 0x822142bc
	if ctx.cr[6].gt {
	pc = 0x822142BC; continue 'dispatch;
	}
	// 82214308: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8221430C: 57890BFC  rlwinm r9, r28, 1, 0xf, 0x1e
	ctx.r[9].u64 = ctx.r[28].u32 as u64 & 0x7FFFFFFFu64;
	// 82214310: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82214314: 553C043E  clrlwi r28, r9, 0x10
	ctx.r[28].u64 = ctx.r[9].u32 as u64 & 0x0000FFFFu64;
	// 82214318: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8221431C: 4199FF70  bgt cr6, 0x8221428c
	if ctx.cr[6].gt {
	pc = 0x8221428C; continue 'dispatch;
	}
	// 82214320: 39250001  addi r9, r5, 1
	ctx.r[9].s64 = ctx.r[5].s64 + 1;
	// 82214324: 7D5E5850  subf r10, r30, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 82214328: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 8221432C: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82214330: 394AFFB4  addi r10, r10, -0x4c
	ctx.r[10].s64 = ctx.r[10].s64 + -76;
	// 82214334: 554A003A  rlwinm r10, r10, 0, 0, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 82214338: 7D69F12E  stwx r11, r9, r30
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[30].u32), ctx.r[11].u32) };
	// 8221433C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82214340: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82214344: 41990008  bgt cr6, 0x8221434c
	if ctx.cr[6].gt {
	pc = 0x8221434C; continue 'dispatch;
	}
	// 82214348: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8221434C: 5563063E  clrlwi r3, r11, 0x18
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82214350: 38211EB0  addi r1, r1, 0x1eb0
	ctx.r[1].s64 = ctx.r[1].s64 + 7856;
	// 82214354: 48320DA4  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82214358(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82214358 size=184
    let mut pc: u32 = 0x82214358;
    'dispatch: loop {
        match pc {
            0x82214358 => {
    //   block [0x82214358..0x82214410)
	// 82214358: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221435C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82214360: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82214364: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82214368: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221436C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82214370: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82214374: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82214378: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221437C: 4BFFFDBD  bl 0x82214138
	ctx.lr = 0x82214380;
	sub_82214138(ctx, base);
	// 82214380: 7C6B0034  cntlzw r11, r3
	ctx.r[11].u64 = if ctx.r[3].u32 == 0 { 32 } else { ctx.r[3].u32.leading_zeros() as u64 };
	// 82214384: 216B0021  subfic r11, r11, 0x21
	ctx.xer.ca = ctx.r[11].u32 <= 33 as u32;
	ctx.r[11].s64 = (33 as i64) - ctx.r[11].s64;
	// 82214388: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221438C: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82214390: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214394: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82214398: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8221439C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 822143A0: 4098001C  bge cr6, 0x822143bc
	if !ctx.cr[6].lt {
	pc = 0x822143BC; continue 'dispatch;
	}
	// 822143A4: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822143A8: 7F091840  cmplw cr6, r9, r3
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[3].u32, &mut ctx.xer);
	// 822143AC: 40990010  ble cr6, 0x822143bc
	if !ctx.cr[6].gt {
	pc = 0x822143BC; continue 'dispatch;
	}
	// 822143B0: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 822143B4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 822143B8: 4198FFEC  blt cr6, 0x822143a4
	if ctx.cr[6].lt {
	pc = 0x822143A4; continue 'dispatch;
	}
	// 822143BC: 892B0002  lbz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 822143C0: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822143C4: 552A073E  clrlwi r10, r9, 0x1c
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x0000000Fu64;
	// 822143C8: 80FF0004  lwz r7, 4(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 822143CC: 7D292670  srawi r9, r9, 4
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 4) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 4) as i64;
	// 822143D0: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 822143D4: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 822143D8: 2F0A0010  cmpwi cr6, r10, 0x10
	ctx.cr[6].compare_i32(ctx.r[10].s32, 16, &mut ctx.xer);
	// 822143DC: 7D293850  subf r9, r9, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 822143E0: 4099000C  ble cr6, 0x822143ec
	if !ctx.cr[6].gt {
	pc = 0x822143EC; continue 'dispatch;
	}
	// 822143E4: 3929FFFE  addi r9, r9, -2
	ctx.r[9].s64 = ctx.r[9].s64 + -2;
	// 822143E8: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 822143EC: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 822143F0: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 822143F4: 886B0003  lbz r3, 3(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 822143F8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 822143FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82214400: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82214404: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82214408: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221440C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82214410(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82214410 size=592
    let mut pc: u32 = 0x82214410;
    'dispatch: loop {
        match pc {
            0x82214410 => {
    //   block [0x82214410..0x82214660)
	// 82214410: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82214414: 48320C79  bl 0x8253508c
	ctx.lr = 0x82214418;
	sub_82535080(ctx, base);
	// 82214418: 3BE1FAD0  addi r31, r1, -0x530
	ctx.r[31].s64 = ctx.r[1].s64 + -1328;
	// 8221441C: 9421FAD0  stwu r1, -0x530(r1)
	ea = ctx.r[1].u32.wrapping_add(-1328 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82214420: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 82214424: 7CD63378  mr r22, r6
	ctx.r[22].u64 = ctx.r[6].u64;
	// 82214428: 7C912378  mr r17, r4
	ctx.r[17].u64 = ctx.r[4].u64;
	// 8221442C: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82214430: 81570008  lwz r10, 8(r23)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(8 as u32) ) } as u64;
	// 82214434: 81770004  lwz r11, 4(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(4 as u32) ) } as u64;
	// 82214438: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8221443C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82214440: 7D4A582E  lwzx r10, r10, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82214444: 7CEA5A14  add r7, r10, r11
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82214448: 3947001C  addi r10, r7, 0x1c
	ctx.r[10].s64 = ctx.r[7].s64 + 28;
	// 8221444C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 82214450: 7C00522C  dcbt 0, r10
	// 82214454: 7C8B1E70  srawi r11, r4, 3
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[4].s32 >> 3) as i64;
	// 82214458: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8221445C: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 82214460: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 82214464: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82214468: 41980020  blt cr6, 0x82214488
	if ctx.cr[6].lt {
	pc = 0x82214488; continue 'dispatch;
	}
	// 8221446C: A0C90000  lhz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214470: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82214474: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82214478: 7CC60734  extsh r6, r6
	ctx.r[6].s64 = ctx.r[6].s16 as i64;
	// 8221447C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82214480: 7D064214  add r8, r6, r8
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 82214484: 4098FFE8  bge cr6, 0x8221446c
	if !ctx.cr[6].lt {
	pc = 0x8221446C; continue 'dispatch;
	}
	// 82214488: A1670002  lhz r11, 2(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(2 as u32) ) } as u64;
	// 8221448C: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82214490: 2B160000  cmplwi cr6, r22, 0
	ctx.cr[6].compare_u32(ctx.r[22].u32, 0 as u32, &mut ctx.xer);
	// 82214494: 5575F87E  srwi r21, r11, 1
	ctx.r[21].u32 = ctx.r[11].u32.wrapping_shr(1);
	ctx.r[21].u64 = ctx.r[21].u32 as u64;
	// 82214498: 7C8B1E70  srawi r11, r4, 3
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[4].s32 >> 3) as i64;
	// 8221449C: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 822144A0: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822144A4: 7F2B2050  subf r25, r11, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 822144A8: 419A000C  beq cr6, 0x822144b4
	if ctx.cr[6].eq {
	pc = 0x822144B4; continue 'dispatch;
	}
	// 822144AC: 7ED4B378  mr r20, r22
	ctx.r[20].u64 = ctx.r[22].u64;
	// 822144B0: 48000020  b 0x822144d0
	pc = 0x822144D0; continue 'dispatch;
	// 822144B4: 56AB083C  slwi r11, r21, 1
	ctx.r[11].u32 = ctx.r[21].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822144B8: 7D6B00D0  neg r11, r11
	ctx.r[11].s64 = -ctx.r[11].s64;
	// 822144BC: 556C0036  rlwinm r12, r11, 0, 0, 0x1b
	ctx.r[12].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 822144C0: 483CDE05  bl 0x825e22c4
	ctx.lr = 0x822144C4;
	sub_825E22C4(ctx, base);
	// 822144C4: 81610000  lwz r11, 0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(0 as u32) ) } as u64;
	// 822144C8: 7D61616E  stwux r11, r1, r12
	ea = ctx.r[1].u32.wrapping_add(ctx.r[12].u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[11].u32) };
	ctx.r[1].u32 = ea;
	// 822144CC: 3A810050  addi r20, r1, 0x50
	ctx.r[20].s64 = ctx.r[1].s64 + 80;
	// 822144D0: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 822144D4: 7EA903A6  mtctr r21
	ctx.ctr.u64 = ctx.r[21].u64;
	// 822144D8: 2F150000  cmpwi cr6, r21, 0
	ctx.cr[6].compare_i32(ctx.r[21].s32, 0, &mut ctx.xer);
	// 822144DC: 40990020  ble cr6, 0x822144fc
	if !ctx.cr[6].gt {
	pc = 0x822144FC; continue 'dispatch;
	}
	// 822144E0: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822144E4: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822144E8: B1250000  sth r9, 0(r5)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 822144EC: 38A50002  addi r5, r5, 2
	ctx.r[5].s64 = ctx.r[5].s64 + 2;
	// 822144F0: B06B0000  sth r3, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[3].u16 ) };
	// 822144F4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822144F8: 4200FFE8  bdnz 0x822144e0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x822144E0; continue 'dispatch;
	}
	// 822144FC: 2F190000  cmpwi cr6, r25, 0
	ctx.cr[6].compare_i32(ctx.r[25].s32, 0, &mut ctx.xer);
	// 82214500: 409A000C  bne cr6, 0x8221450c
	if !ctx.cr[6].eq {
	pc = 0x8221450C; continue 'dispatch;
	}
	// 82214504: 2B160000  cmplwi cr6, r22, 0
	ctx.cr[6].compare_u32(ctx.r[22].u32, 0 as u32, &mut ctx.xer);
	// 82214508: 419A0150  beq cr6, 0x82214658
	if ctx.cr[6].eq {
	pc = 0x82214658; continue 'dispatch;
	}
	// 8221450C: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 82214510: 915F0054  stw r10, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 82214514: 38C00012  li r6, 0x12
	ctx.r[6].s64 = 18;
	// 82214518: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 8221451C: 389F0050  addi r4, r31, 0x50
	ctx.r[4].s64 = ctx.r[31].s64 + 80;
	// 82214520: 387F0060  addi r3, r31, 0x60
	ctx.r[3].s64 = ctx.r[31].s64 + 96;
	// 82214524: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82214528: 4BFFFC91  bl 0x822141b8
	ctx.lr = 0x8221452C;
	sub_822141B8(ctx, base);
	// 8221452C: 7F33CB78  mr r19, r25
	ctx.r[19].u64 = ctx.r[25].u64;
	// 82214530: 3A40FFFF  li r18, -1
	ctx.r[18].s64 = -1;
	// 82214534: 2F190000  cmpwi cr6, r25, 0
	ctx.cr[6].compare_i32(ctx.r[25].s32, 0, &mut ctx.xer);
	// 82214538: 40990084  ble cr6, 0x822145bc
	if !ctx.cr[6].gt {
	pc = 0x822145BC; continue 'dispatch;
	}
	// 8221453C: 7EB807B4  extsw r24, r21
	ctx.r[24].s64 = ctx.r[21].s32 as i64;
	// 82214540: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 82214544: 3B39FFFF  addi r25, r25, -1
	ctx.r[25].s64 = ctx.r[25].s64 + -1;
	// 82214548: 7F5ED378  mr r30, r26
	ctx.r[30].u64 = ctx.r[26].u64;
	// 8221454C: 2B3D0000  cmpldi cr6, r29, 0
	ctx.cr[6].compare_u64(ctx.r[29].u64, 0, &mut ctx.xer);
	// 82214550: 40990064  ble cr6, 0x822145b4
	if !ctx.cr[6].gt {
	pc = 0x822145B4; continue 'dispatch;
	}
	// 82214554: 7F7AA050  subf r27, r26, r20
	ctx.r[27].s64 = ctx.r[20].s64 - ctx.r[26].s64;
	// 82214558: 389F0050  addi r4, r31, 0x50
	ctx.r[4].s64 = ctx.r[31].s64 + 80;
	// 8221455C: 387F0060  addi r3, r31, 0x60
	ctx.r[3].s64 = ctx.r[31].s64 + 96;
	// 82214560: 4BFFFDF9  bl 0x82214358
	ctx.lr = 0x82214564;
	sub_82214358(ctx, base);
	// 82214564: 3B83FFFE  addi r28, r3, -2
	ctx.r[28].s64 = ctx.r[3].s64 + -2;
	// 82214568: 2F1C0001  cmpwi cr6, r28, 1
	ctx.cr[6].compare_i32(ctx.r[28].s32, 1, &mut ctx.xer);
	// 8221456C: 40990018  ble cr6, 0x82214584
	if !ctx.cr[6].gt {
	pc = 0x82214584; continue 'dispatch;
	}
	// 82214570: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82214574: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 82214578: 4BFFFB31  bl 0x822140a8
	ctx.lr = 0x8221457C;
	sub_822140A8(ctx, base);
	// 8221457C: 7E4BE030  slw r11, r18, r28
	if (ctx.r[28].u8 & 0x20) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = ((ctx.r[18].u32) << ((ctx.r[28].u8 & 0x1F) as u32)) as u64;
	}
	// 82214580: 7C7C5A78  xor r28, r3, r11
	ctx.r[28].u64 = ctx.r[3].u64 ^ ctx.r[11].u64;
	// 82214584: 7D7BF22E  lhzx r11, r27, r30
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 82214588: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8221458C: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 82214590: 2B3D0000  cmpldi cr6, r29, 0
	ctx.cr[6].compare_u64(ctx.r[29].u64, 0, &mut ctx.xer);
	// 82214594: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82214598: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8221459C: 7D7BF32E  sthx r11, r27, r30
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[27].u32.wrapping_add(ctx.r[30].u32), ctx.r[11].u16) };
	// 822145A0: A17E0000  lhz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822145A4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 822145A8: B17E0000  sth r11, 0(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 822145AC: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	// 822145B0: 4199FFA8  bgt cr6, 0x82214558
	if ctx.cr[6].gt {
	pc = 0x82214558; continue 'dispatch;
	}
	// 822145B4: 2F190000  cmpwi cr6, r25, 0
	ctx.cr[6].compare_i32(ctx.r[25].s32, 0, &mut ctx.xer);
	// 822145B8: 4199FF88  bgt cr6, 0x82214540
	if ctx.cr[6].gt {
	pc = 0x82214540; continue 'dispatch;
	}
	// 822145BC: 2B160000  cmplwi cr6, r22, 0
	ctx.cr[6].compare_u32(ctx.r[22].u32, 0 as u32, &mut ctx.xer);
	// 822145C0: 419A0098  beq cr6, 0x82214658
	if ctx.cr[6].eq {
	pc = 0x82214658; continue 'dispatch;
	}
	// 822145C4: 39730001  addi r11, r19, 1
	ctx.r[11].s64 = ctx.r[19].s64 + 1;
	// 822145C8: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 822145CC: 409A0020  bne cr6, 0x822145ec
	if !ctx.cr[6].eq {
	pc = 0x822145EC; continue 'dispatch;
	}
	// 822145D0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 822145D4: 7EC5B378  mr r5, r22
	ctx.r[5].u64 = ctx.r[22].u64;
	// 822145D8: 38910001  addi r4, r17, 1
	ctx.r[4].s64 = ctx.r[17].s64 + 1;
	// 822145DC: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 822145E0: 4BFFFE31  bl 0x82214410
	ctx.lr = 0x822145E4;
	sub_82214410(ctx, base);
	// 822145E4: 383F0530  addi r1, r31, 0x530
	ctx.r[1].s64 = ctx.r[31].s64 + 1328;
	// 822145E8: 48320AF4  b 0x825350dc
	sub_825350D0(ctx, base);
	return;
	// 822145EC: 7EBD07B4  extsw r29, r21
	ctx.r[29].s64 = ctx.r[21].s32 as i64;
	// 822145F0: 7EDEB378  mr r30, r22
	ctx.r[30].u64 = ctx.r[22].u64;
	// 822145F4: 2B3D0000  cmpldi cr6, r29, 0
	ctx.cr[6].compare_u64(ctx.r[29].u64, 0, &mut ctx.xer);
	// 822145F8: 40990060  ble cr6, 0x82214658
	if !ctx.cr[6].gt {
	pc = 0x82214658; continue 'dispatch;
	}
	// 822145FC: 389F0050  addi r4, r31, 0x50
	ctx.r[4].s64 = ctx.r[31].s64 + 80;
	// 82214600: 387F0060  addi r3, r31, 0x60
	ctx.r[3].s64 = ctx.r[31].s64 + 96;
	// 82214604: 4BFFFD55  bl 0x82214358
	ctx.lr = 0x82214608;
	sub_82214358(ctx, base);
	// 82214608: 3B83FFFE  addi r28, r3, -2
	ctx.r[28].s64 = ctx.r[3].s64 + -2;
	// 8221460C: 2F1C0001  cmpwi cr6, r28, 1
	ctx.cr[6].compare_i32(ctx.r[28].s32, 1, &mut ctx.xer);
	// 82214610: 40990018  ble cr6, 0x82214628
	if !ctx.cr[6].gt {
	pc = 0x82214628; continue 'dispatch;
	}
	// 82214614: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82214618: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 8221461C: 4BFFFA8D  bl 0x822140a8
	ctx.lr = 0x82214620;
	sub_822140A8(ctx, base);
	// 82214620: 7E4BE030  slw r11, r18, r28
	if (ctx.r[28].u8 & 0x20) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = ((ctx.r[18].u32) << ((ctx.r[28].u8 & 0x1F) as u32)) as u64;
	}
	// 82214624: 7C7C5A78  xor r28, r3, r11
	ctx.r[28].u64 = ctx.r[3].u64 ^ ctx.r[11].u64;
	// 82214628: A17A0000  lhz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221462C: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 82214630: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214634: 3B5A0002  addi r26, r26, 2
	ctx.r[26].s64 = ctx.r[26].s64 + 2;
	// 82214638: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221463C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214640: 2B3D0000  cmpldi cr6, r29, 0
	ctx.cr[6].compare_u64(ctx.r[29].u64, 0, &mut ctx.xer);
	// 82214644: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82214648: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8221464C: B17E0000  sth r11, 0(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82214650: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	// 82214654: 4199FFA8  bgt cr6, 0x822145fc
	if ctx.cr[6].gt {
	pc = 0x822145FC; continue 'dispatch;
	}
	// 82214658: 383F0530  addi r1, r31, 0x530
	ctx.r[1].s64 = ctx.r[31].s64 + 1328;
	// 8221465C: 48320A80  b 0x825350dc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82214660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82214660 size=532
    let mut pc: u32 = 0x82214660;
    'dispatch: loop {
        match pc {
            0x82214660 => {
    //   block [0x82214660..0x82214874)
	// 82214660: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82214664: 48320A45  bl 0x825350a8
	ctx.lr = 0x82214668;
	sub_82535080(ctx, base);
	// 82214668: 3981FFB8  addi r12, r1, -0x48
	ctx.r[12].s64 = ctx.r[1].s64 + -72;
	// 8221466C: 48321971  bl 0x82535fdc
	ctx.lr = 0x82214670;
	sub_82535FB0(ctx, base);
	// 82214670: 9421FA60  stwu r1, -0x5a0(r1)
	ea = ctx.r[1].u32.wrapping_add(-1440 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82214674: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82214678: FF400890  fmr f26, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[26].f64 = ctx.f[1].f64;
	// 8221467C: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82214680: FF201090  fmr f25, f2
	ctx.f[25].f64 = ctx.f[2].f64;
	// 82214684: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82214688: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 8221468C: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 82214690: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82214694: C01F000C  lfs f0, 0xc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82214698: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8221469C: 7D184378  mr r24, r8
	ctx.r[24].u64 = ctx.r[8].u64;
	// 822146A0: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822146A4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822146A8: 7D4A582E  lwzx r10, r10, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 822146AC: 7FAA5A14  add r29, r10, r11
	ctx.r[29].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 822146B0: A15D0000  lhz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 822146B4: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 822146B8: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 822146BC: F9410070  std r10, 0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u64 ) };
	// 822146C0: 556A06F6  rlwinm r10, r11, 0, 0x1b, 0x1b
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 822146C4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822146C8: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 822146CC: C3AABA38  lfs f29, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 822146D0: C9A10070  lfd f13, 0x70(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 822146D4: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 822146D8: FFE06818  frsp f31, f13
	ctx.f[31].f64 = (ctx.f[13].f64 as f32) as f64;
	// 822146DC: 419A0008  beq cr6, 0x822146e4
	if ctx.cr[6].eq {
	pc = 0x822146E4; continue 'dispatch;
	}
	// 822146E0: EFFFE82A  fadds f31, f31, f29
	ctx.f[31].f64 = ((ctx.f[31].f64 + ctx.f[29].f64) as f32) as f64;
	// 822146E4: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 822146E8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 822146EC: 419A0014  beq cr6, 0x82214700
	if ctx.cr[6].eq {
	pc = 0x82214700; continue 'dispatch;
	}
	// 822146F0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 822146F4: ED9FE82A  fadds f12, f31, f29
	ctx.f[12].f64 = ((ctx.f[31].f64 + ctx.f[29].f64) as f32) as f64;
	// 822146F8: C1ABBFFC  lfs f13, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822146FC: 48000024  b 0x82214720
	pc = 0x82214720; continue 'dispatch;
	// 82214700: 556B0738  rlwinm r11, r11, 0, 0x1c, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82214704: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82214708: 419A0020  beq cr6, 0x82214728
	if ctx.cr[6].eq {
	pc = 0x82214728; continue 'dispatch;
	}
	// 8221470C: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 82214710: C1ABD5B0  lfs f13, -0x2a50(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10832 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82214714: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82214718: ED9F682A  fadds f12, f31, f13
	ctx.f[12].f64 = ((ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64;
	// 8221471C: C1AB2038  lfs f13, 0x2038(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8248 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82214720: EFEC0372  fmuls f31, f12, f13
	ctx.f[31].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 82214724: EC000372  fmuls f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82214728: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221472C: C36B1FF8  lfs f27, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 82214730: FF00D800  fcmpu cr6, f0, f27
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[27].f64);
	// 82214734: 4098000C  bge cr6, 0x82214740
	if !ctx.cr[6].lt {
	pc = 0x82214740; continue 'dispatch;
	}
	// 82214738: FC00D890  fmr f0, f27
	ctx.f[0].f64 = ctx.f[27].f64;
	// 8221473C: 48000014  b 0x82214750
	pc = 0x82214750; continue 'dispatch;
	// 82214740: EDBFE828  fsubs f13, f31, f29
	ctx.f[13].f64 = (((ctx.f[31].f64 - ctx.f[29].f64) as f32) as f64);
	// 82214744: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82214748: 40990008  ble cr6, 0x82214750
	if !ctx.cr[6].gt {
	pc = 0x82214750; continue 'dispatch;
	}
	// 8221474C: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82214750: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 82214754: FDA0001E  fctiwz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 82214758: 38A00250  li r5, 0x250
	ctx.r[5].s64 = 592;
	// 8221475C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82214760: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82214764: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 82214768: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 8221476C: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 82214770: F9610070  std r11, 0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u64 ) };
	// 82214774: C9A10070  lfd f13, 0x70(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 82214778: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221477C: FFC06818  frsp f30, f13
	ctx.f[30].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82214780: EF80F028  fsubs f28, f0, f30
	ctx.f[28].f64 = (((ctx.f[0].f64 - ctx.f[30].f64) as f32) as f64);
	// 82214784: 481ACDDD  bl 0x823c1560
	ctx.lr = 0x82214788;
	sub_823C1560(ctx, base);
	// 82214788: 38A00250  li r5, 0x250
	ctx.r[5].s64 = 592;
	// 8221478C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82214790: 386102D0  addi r3, r1, 0x2d0
	ctx.r[3].s64 = ctx.r[1].s64 + 720;
	// 82214794: 481ACDCD  bl 0x823c1560
	ctx.lr = 0x82214798;
	sub_823C1560(ctx, base);
	// 82214798: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8221479C: 409A0010  bne cr6, 0x822147ac
	if !ctx.cr[6].eq {
	pc = 0x822147AC; continue 'dispatch;
	}
	// 822147A0: 3BC10080  addi r30, r1, 0x80
	ctx.r[30].s64 = ctx.r[1].s64 + 128;
	// 822147A4: 3B8102D0  addi r28, r1, 0x2d0
	ctx.r[28].s64 = ctx.r[1].s64 + 720;
	// 822147A8: 48000008  b 0x822147b0
	pc = 0x822147B0; continue 'dispatch;
	// 822147AC: 3B9E0250  addi r28, r30, 0x250
	ctx.r[28].s64 = ctx.r[30].s64 + 592;
	// 822147B0: EC1EE82A  fadds f0, f30, f29
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = ((ctx.f[30].f64 + ctx.f[29].f64) as f32) as f64;
	// 822147B4: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 822147B8: EDBFE828  fsubs f13, f31, f29
	ctx.f[13].f64 = (((ctx.f[31].f64 - ctx.f[29].f64) as f32) as f64);
	// 822147BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 822147C0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 822147C4: FC00F01E  fctiwz f0, f30
	ctx.f[0].s64 = if ctx.f[30].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[30].f64.trunc() as i32 as i64 };
	// 822147C8: 40990058  ble cr6, 0x82214820
	if !ctx.cr[6].gt {
	pc = 0x82214820; continue 'dispatch;
	}
	// 822147CC: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 822147D0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 822147D4: 7C005FAE  stfiwx f0, 0, r11
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 822147D8: 80810070  lwz r4, 0x70(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 822147DC: 4BFFFC35  bl 0x82214410
	ctx.lr = 0x822147E0;
	sub_82214410(ctx, base);
	// 822147E0: 7F08C378  mr r8, r24
	ctx.r[8].u64 = ctx.r[24].u64;
	// 822147E4: E8FD0008  ld r7, 8(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	// 822147E8: 7F46D378  mr r6, r26
	ctx.r[6].u64 = ctx.r[26].u64;
	// 822147EC: 93210064  stw r25, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[25].u32 ) };
	// 822147F0: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 822147F4: FC60D890  fmr f3, f27
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[3].f64 = ctx.f[27].f64;
	// 822147F8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 822147FC: 93C10054  stw r30, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[30].u32 ) };
	// 82214800: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82214804: FC40C890  fmr f2, f25
	ctx.f[2].f64 = ctx.f[25].f64;
	// 82214808: FC20D090  fmr f1, f26
	ctx.f[1].f64 = ctx.f[26].f64;
	// 8221480C: 4800006D  bl 0x82214878
	ctx.lr = 0x82214810;
	sub_82214878(ctx, base);
	// 82214810: 382105A0  addi r1, r1, 0x5a0
	ctx.r[1].s64 = ctx.r[1].s64 + 1440;
	// 82214814: 3981FFB8  addi r12, r1, -0x48
	ctx.r[12].s64 = ctx.r[1].s64 + -72;
	// 82214818: 48321811  bl 0x82536028
	ctx.lr = 0x8221481C;
	sub_82535FFC(ctx, base);
	// 8221481C: 483208DC  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
	// 82214820: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 82214824: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 82214828: 7C005FAE  stfiwx f0, 0, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8221482C: 80810070  lwz r4, 0x70(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82214830: 4BFFFBE1  bl 0x82214410
	ctx.lr = 0x82214834;
	sub_82214410(ctx, base);
	// 82214834: 7F08C378  mr r8, r24
	ctx.r[8].u64 = ctx.r[24].u64;
	// 82214838: E8FD0008  ld r7, 8(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	// 8221483C: 7F46D378  mr r6, r26
	ctx.r[6].u64 = ctx.r[26].u64;
	// 82214840: 93210064  stw r25, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[25].u32 ) };
	// 82214844: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82214848: FC60E090  fmr f3, f28
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[3].f64 = ctx.f[28].f64;
	// 8221484C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82214850: 93810054  stw r28, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[28].u32 ) };
	// 82214854: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82214858: FC40C890  fmr f2, f25
	ctx.f[2].f64 = ctx.f[25].f64;
	// 8221485C: FC20D090  fmr f1, f26
	ctx.f[1].f64 = ctx.f[26].f64;
	// 82214860: 48000019  bl 0x82214878
	ctx.lr = 0x82214864;
	sub_82214878(ctx, base);
	// 82214864: 382105A0  addi r1, r1, 0x5a0
	ctx.r[1].s64 = ctx.r[1].s64 + 1440;
	// 82214868: 3981FFB8  addi r12, r1, -0x48
	ctx.r[12].s64 = ctx.r[1].s64 + -72;
	// 8221486C: 483217BD  bl 0x82536028
	ctx.lr = 0x82214870;
	sub_82535FFC(ctx, base);
	// 82214870: 48320888  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82214878(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82214878 size=6268
    let mut pc: u32 = 0x82214878;
    'dispatch: loop {
        match pc {
            0x82214878 => {
    //   block [0x82214878..0x822149F4)
	// 82214878: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221487C: 48320805  bl 0x82535080
	ctx.lr = 0x82214880;
	sub_82535080(ctx, base);
	// 82214880: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82214884: 48321735  bl 0x82535fb8
	ctx.lr = 0x82214888;
	sub_82535FB0(ctx, base);
	// 82214888: 9421FB50  stwu r1, -0x4b0(r1)
	ea = ctx.r[1].u32.wrapping_add(-1200 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221488C: 7C701B78  mr r16, r3
	ctx.r[16].u64 = ctx.r[3].u64;
	// 82214890: FFE01890  fmr f31, f3
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ctx.f[3].f64;
	// 82214894: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 82214898: FE600890  fmr f19, f1
	ctx.f[19].f64 = ctx.f[1].f64;
	// 8221489C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 822148A0: FE001090  fmr f16, f2
	ctx.f[16].f64 = ctx.f[2].f64;
	// 822148A4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 822148A8: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 822148AC: 81500008  lwz r10, 8(r16)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(8 as u32) ) } as u64;
	// 822148B0: 7CF73B78  mr r23, r7
	ctx.r[23].u64 = ctx.r[7].u64;
	// 822148B4: 81700004  lwz r11, 4(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) } as u64;
	// 822148B8: C0092150  lfs f0, 0x2150(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822148BC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822148C0: 7D134378  mr r19, r8
	ctx.r[19].u64 = ctx.r[8].u64;
	// 822148C4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822148C8: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 822148CC: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 822148D0: 3B400001  li r26, 1
	ctx.r[26].s64 = 1;
	// 822148D4: 39E00001  li r15, 1
	ctx.r[15].s64 = 1;
	// 822148D8: 7D4A582E  lwzx r10, r10, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 822148DC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 822148E0: 82CB0004  lwz r22, 4(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 822148E4: 40980008  bge cr6, 0x822148ec
	if !ctx.cr[6].lt {
	pc = 0x822148EC; continue 'dispatch;
	}
	// 822148E8: 39E00000  li r15, 0
	ctx.r[15].s64 = 0;
	// 822148EC: 3FC0820A  lis r30, -0x7df6
	ctx.r[30].s64 = -2113273856;
	// 822148F0: C301010C  lfs f24, 0x10c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(268 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 822148F4: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 822148F8: 82210514  lwz r17, 0x514(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(1300 as u32) ) } as u64;
	// 822148FC: 3C60820D  lis r3, -0x7df3
	ctx.r[3].s64 = -2113077248;
	// 82214900: C381005C  lfs f28, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82214904: 3C80820D  lis r4, -0x7df3
	ctx.r[4].s64 = -2113077248;
	// 82214908: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8221490C: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 82214910: C3BEBA38  lfs f29, -0x45c8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82214914: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 82214918: 83C10504  lwz r30, 0x504(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(1284 as u32) ) } as u64;
	// 8221491C: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 82214920: C2832728  lfs f20, 0x2728(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(10024 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 82214924: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 82214928: C2242048  lfs f17, 0x2048(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8264 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 8221492C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 82214930: C2E5BFFC  lfs f23, -0x4004(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 82214934: 3AAB64E0  addi r21, r11, 0x64e0
	ctx.r[21].s64 = ctx.r[11].s64 + 25824;
	// 82214938: C2461FF8  lfs f18, 0x1ff8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8184 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 8221493C: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 82214940: C2A72724  lfs f21, 0x2724(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(10020 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 82214944: C3482720  lfs f26, 0x2720(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(10016 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 82214948: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 8221494C: C3692238  lfs f27, 0x2238(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8760 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 82214950: 3B6B64B0  addi r27, r11, 0x64b0
	ctx.r[27].s64 = ctx.r[11].s64 + 25776;
	// 82214954: C2CA2154  lfs f22, 0x2154(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8532 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 82214958: 3DC0829E  lis r14, -0x7d62
	ctx.r[14].s64 = -2103574528;
	// 8221495C: 3E400001  lis r18, 1
	ctx.r[18].s64 = 65536;
	// 82214960: 2B370000  cmpldi cr6, r23, 0
	ctx.cr[6].compare_u64(ctx.r[23].u64, 0, &mut ctx.xer);
	// 82214964: 419A177C  beq cr6, 0x822160e0
	if ctx.cr[6].eq {
	pc = 0x822160E0; continue 'dispatch;
	}
	// 82214968: 7AEB07E0  clrldi r11, r23, 0x3f
	ctx.r[11].u64 = ctx.r[23].u64 & 0x0000000000000001u64;
	// 8221496C: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82214970: 409A0090  bne cr6, 0x82214a00
	if !ctx.cr[6].eq {
	pc = 0x82214A00; continue 'dispatch;
	}
	// 82214974: 89710000  lbz r11, 0(r17)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214978: 396BFFFD  addi r11, r11, -3
	ctx.r[11].s64 = ctx.r[11].s64 + -3;
	// 8221497C: 2B0B0015  cmplwi cr6, r11, 0x15
	ctx.cr[6].compare_u32(ctx.r[11].u32, 21 as u32, &mut ctx.xer);
	// 82214980: 4199173C  bgt cr6, 0x822160bc
	if ctx.cr[6].gt {
	pc = 0x822160BC; continue 'dispatch;
	}
	// 82214984: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82214988: 398C499C  addi r12, r12, 0x499c
	ctx.r[12].s64 = ctx.r[12].s64 + 18844;
	// 8221498C: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82214990: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82214994: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82214998: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x822149F4; continue 'dispatch;
		},
		1 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		2 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		3 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		4 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		5 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		6 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		7 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		8 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		9 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		10 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		11 => {
	pc = 0x822149F4; continue 'dispatch;
		},
		12 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		13 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		14 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		15 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		16 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		17 => {
	pc = 0x822149F4; continue 'dispatch;
		},
		18 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		19 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		20 => {
	pc = 0x822149F4; continue 'dispatch;
		},
		21 => {
	pc = 0x822149F4; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8221499C: 822149F4  lwz r17, 0x49f4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(18932 as u32) ) } as u64;
	// 822149A0: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149A4: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149A8: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149AC: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149B0: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149B4: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149B8: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149BC: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149C0: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149C4: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149C8: 822149F4  lwz r17, 0x49f4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(18932 as u32) ) } as u64;
	// 822149CC: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149D0: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149D4: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149D8: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149DC: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149E0: 822149F4  lwz r17, 0x49f4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(18932 as u32) ) } as u64;
	// 822149E4: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149E8: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 822149EC: 822149F4  lwz r17, 0x49f4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(18932 as u32) ) } as u64;
	// 822149F0: 822149F4  lwz r17, 0x49f4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(18932 as u32) ) } as u64;
            }
            0x822149F4 => {
    //   block [0x822149F4..0x82214A9C)
	// 822149F4: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 822149F8: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 822149FC: 480016C0  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82214A00: 7A6B07E0  clrldi r11, r19, 0x3f
	ctx.r[11].u64 = ctx.r[19].u64 & 0x0000000000000001u64;
	// 82214A04: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82214A08: 89710000  lbz r11, 0(r17)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214A0C: 409A0110  bne cr6, 0x82214b1c
	if !ctx.cr[6].eq {
	pc = 0x82214B1C; continue 'dispatch;
	}
	// 82214A10: 2B0B001A  cmplwi cr6, r11, 0x1a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 26 as u32, &mut ctx.xer);
	// 82214A14: 419916A8  bgt cr6, 0x822160bc
	if ctx.cr[6].gt {
	pc = 0x822160BC; continue 'dispatch;
	}
	// 82214A18: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82214A1C: 398C4A30  addi r12, r12, 0x4a30
	ctx.r[12].s64 = ctx.r[12].s64 + 18992;
	// 82214A20: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82214A24: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82214A28: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82214A2C: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x82214BB0; continue 'dispatch;
		},
		1 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		2 => {
	pc = 0x82214A9C; continue 'dispatch;
		},
		3 => {
	pc = 0x82214AA8; continue 'dispatch;
		},
		4 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		5 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		6 => {
	pc = 0x822160B4; continue 'dispatch;
		},
		7 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		8 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		9 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		10 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		11 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		12 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		13 => {
	pc = 0x82214A9C; continue 'dispatch;
		},
		14 => {
	pc = 0x82214B00; continue 'dispatch;
		},
		15 => {
	pc = 0x82214B10; continue 'dispatch;
		},
		16 => {
	pc = 0x822160B4; continue 'dispatch;
		},
		17 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		18 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		19 => {
	pc = 0x82214A9C; continue 'dispatch;
		},
		20 => {
	pc = 0x82214AA8; continue 'dispatch;
		},
		21 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		22 => {
	pc = 0x82214ADC; continue 'dispatch;
		},
		23 => {
	pc = 0x82214ABC; continue 'dispatch;
		},
		24 => {
	pc = 0x82214ABC; continue 'dispatch;
		},
		25 => {
	pc = 0x82214A9C; continue 'dispatch;
		},
		26 => {
	pc = 0x82214A9C; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82214A30: 82214BB0  lwz r17, 0x4bb0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19376 as u32) ) } as u64;
	// 82214A34: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A38: 82214A9C  lwz r17, 0x4a9c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19100 as u32) ) } as u64;
	// 82214A3C: 82214AA8  lwz r17, 0x4aa8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19112 as u32) ) } as u64;
	// 82214A40: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A44: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A48: 822160B4  lwz r17, 0x60b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24756 as u32) ) } as u64;
	// 82214A4C: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A50: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A54: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A58: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A5C: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A60: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A64: 82214A9C  lwz r17, 0x4a9c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19100 as u32) ) } as u64;
	// 82214A68: 82214B00  lwz r17, 0x4b00(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19200 as u32) ) } as u64;
	// 82214A6C: 82214B10  lwz r17, 0x4b10(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19216 as u32) ) } as u64;
	// 82214A70: 822160B4  lwz r17, 0x60b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24756 as u32) ) } as u64;
	// 82214A74: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A78: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A7C: 82214A9C  lwz r17, 0x4a9c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19100 as u32) ) } as u64;
	// 82214A80: 82214AA8  lwz r17, 0x4aa8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19112 as u32) ) } as u64;
	// 82214A84: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214A88: 82214ADC  lwz r17, 0x4adc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19164 as u32) ) } as u64;
	// 82214A8C: 82214ABC  lwz r17, 0x4abc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19132 as u32) ) } as u64;
	// 82214A90: 82214ABC  lwz r17, 0x4abc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19132 as u32) ) } as u64;
	// 82214A94: 82214A9C  lwz r17, 0x4a9c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19100 as u32) ) } as u64;
	// 82214A98: 82214A9C  lwz r17, 0x4a9c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19100 as u32) ) } as u64;
            }
            0x82214A9C => {
    //   block [0x82214A9C..0x82214AA8)
	// 82214A9C: 3BFF0006  addi r31, r31, 6
	ctx.r[31].s64 = ctx.r[31].s64 + 6;
	// 82214AA0: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82214AA4: 48001618  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214AA8 => {
    //   block [0x82214AA8..0x82214ABC)
	// 82214AA8: 3BFF0006  addi r31, r31, 6
	ctx.r[31].s64 = ctx.r[31].s64 + 6;
	// 82214AAC: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82214AB0: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82214AB4: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82214AB8: 48001604  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214ABC => {
    //   block [0x82214ABC..0x82214ADC)
	// 82214ABC: 56CB00C6  rlwinm r11, r22, 0, 3, 3
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82214AC0: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82214AC4: 419AFFE4  beq cr6, 0x82214aa8
	if ctx.cr[6].eq {
	pc = 0x82214AA8; continue 'dispatch;
	}
	// 82214AC8: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 82214ACC: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 82214AD0: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82214AD4: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82214AD8: 480015E4  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214ADC => {
    //   block [0x82214ADC..0x82214B00)
	// 82214ADC: 56CB00C6  rlwinm r11, r22, 0, 3, 3
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82214AE0: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82214AE4: 419A0010  beq cr6, 0x82214af4
	if ctx.cr[6].eq {
	pc = 0x82214AF4; continue 'dispatch;
	}
	// 82214AE8: 3BFF000E  addi r31, r31, 0xe
	ctx.r[31].s64 = ctx.r[31].s64 + 14;
	// 82214AEC: 3BDE000E  addi r30, r30, 0xe
	ctx.r[30].s64 = ctx.r[30].s64 + 14;
	// 82214AF0: 480015CC  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82214AF4: 3BFF0008  addi r31, r31, 8
	ctx.r[31].s64 = ctx.r[31].s64 + 8;
	// 82214AF8: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 82214AFC: 480015C0  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214B00 => {
    //   block [0x82214B00..0x82214B10)
	// 82214B00: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 82214B04: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 82214B08: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82214B0C: 480015B0  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214B10 => {
    //   block [0x82214B10..0x82214BB0)
	// 82214B10: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 82214B14: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 82214B18: 480015A4  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82214B1C: 2B0B001C  cmplwi cr6, r11, 0x1c
	ctx.cr[6].compare_u32(ctx.r[11].u32, 28 as u32, &mut ctx.xer);
	// 82214B20: 4199159C  bgt cr6, 0x822160bc
	if ctx.cr[6].gt {
	pc = 0x822160BC; continue 'dispatch;
	}
	// 82214B24: 3D808221  lis r12, -0x7ddf
	ctx.r[12].s64 = -2111766528;
	// 82214B28: 398C4B3C  addi r12, r12, 0x4b3c
	ctx.r[12].s64 = ctx.r[12].s64 + 19260;
	// 82214B2C: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 82214B30: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82214B34: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82214B38: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x82214BB0; continue 'dispatch;
		},
		1 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		2 => {
	pc = 0x82214BB8; continue 'dispatch;
		},
		3 => {
	pc = 0x82214D08; continue 'dispatch;
		},
		4 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		5 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		6 => {
	pc = 0x822154A0; continue 'dispatch;
		},
		7 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		8 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		9 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		10 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		11 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		12 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		13 => {
	pc = 0x82214EC8; continue 'dispatch;
		},
		14 => {
	pc = 0x822151C8; continue 'dispatch;
		},
		15 => {
	pc = 0x8221533C; continue 'dispatch;
		},
		16 => {
	pc = 0x82216070; continue 'dispatch;
		},
		17 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		18 => {
	pc = 0x822160BC; continue 'dispatch;
		},
		19 => {
	pc = 0x82215F54; continue 'dispatch;
		},
		20 => {
	pc = 0x82215C68; continue 'dispatch;
		},
		21 => {
	pc = 0x82215040; continue 'dispatch;
		},
		22 => {
	pc = 0x8221555C; continue 'dispatch;
		},
		23 => {
	pc = 0x82215860; continue 'dispatch;
		},
		24 => {
	pc = 0x82215A64; continue 'dispatch;
		},
		25 => {
	pc = 0x82215DB0; continue 'dispatch;
		},
		26 => {
	pc = 0x82215048; continue 'dispatch;
		},
		27 => {
	pc = 0x82215F24; continue 'dispatch;
		},
		28 => {
	pc = 0x82215F40; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82214B3C: 82214BB0  lwz r17, 0x4bb0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19376 as u32) ) } as u64;
	// 82214B40: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B44: 82214BB8  lwz r17, 0x4bb8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19384 as u32) ) } as u64;
	// 82214B48: 82214D08  lwz r17, 0x4d08(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(19720 as u32) ) } as u64;
	// 82214B4C: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B50: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B54: 822154A0  lwz r17, 0x54a0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(21664 as u32) ) } as u64;
	// 82214B58: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B5C: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B60: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B64: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B68: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B6C: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B70: 82214EC8  lwz r17, 0x4ec8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(20168 as u32) ) } as u64;
	// 82214B74: 822151C8  lwz r17, 0x51c8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(20936 as u32) ) } as u64;
	// 82214B78: 8221533C  lwz r17, 0x533c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(21308 as u32) ) } as u64;
	// 82214B7C: 82216070  lwz r17, 0x6070(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24688 as u32) ) } as u64;
	// 82214B80: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B84: 822160BC  lwz r17, 0x60bc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24764 as u32) ) } as u64;
	// 82214B88: 82215F54  lwz r17, 0x5f54(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24404 as u32) ) } as u64;
	// 82214B8C: 82215C68  lwz r17, 0x5c68(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(23656 as u32) ) } as u64;
	// 82214B90: 82215040  lwz r17, 0x5040(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(20544 as u32) ) } as u64;
	// 82214B94: 8221555C  lwz r17, 0x555c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(21852 as u32) ) } as u64;
	// 82214B98: 82215860  lwz r17, 0x5860(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(22624 as u32) ) } as u64;
	// 82214B9C: 82215A64  lwz r17, 0x5a64(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(23140 as u32) ) } as u64;
	// 82214BA0: 82215DB0  lwz r17, 0x5db0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(23984 as u32) ) } as u64;
	// 82214BA4: 82215048  lwz r17, 0x5048(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(20552 as u32) ) } as u64;
	// 82214BA8: 82215F24  lwz r17, 0x5f24(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24356 as u32) ) } as u64;
	// 82214BAC: 82215F40  lwz r17, 0x5f40(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(24384 as u32) ) } as u64;
            }
            0x82214BB0 => {
    //   block [0x82214BB0..0x82214BB8)
	// 82214BB0: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 82214BB4: 48001508  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214BB8 => {
    //   block [0x82214BB8..0x82214D08)
	// 82214BB8: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82214BBC: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214BC0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82214BC4: 7D5C0734  extsh r28, r10
	ctx.r[28].s64 = ctx.r[10].s16 as i64;
	// 82214BC8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214BCC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82214BD0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214BD4: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82214BD8: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214BDC: F94102A0  std r10, 0x2a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(672 as u32), ctx.r[10].u64 ) };
	// 82214BE0: 7D2B0734  extsh r11, r9
	ctx.r[11].s64 = ctx.r[9].s16 as i64;
	// 82214BE4: F9610368  std r11, 0x368(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(872 as u32), ctx.r[11].u64 ) };
	// 82214BE8: C80102A0  lfd f0, 0x2a0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(672 as u32) ) };
	// 82214BEC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214BF0: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214BF4: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214BF8: C8010368  lfd f0, 0x368(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(872 as u32) ) };
	// 82214BFC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214C00: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214C04: EC4005B2  fmuls f2, f0, f22
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214C08: 48152DA1  bl 0x823679a8
	ctx.lr = 0x82214C0C;
	sub_823679A8(ctx, base);
	// 82214C0C: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 82214C10: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82214C14: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82214C18: 7F8B07B4  extsw r11, r28
	ctx.r[11].s64 = ctx.r[28].s32 as i64;
	// 82214C1C: 419A00AC  beq cr6, 0x82214cc8
	if ctx.cr[6].eq {
	pc = 0x82214CC8; continue 'dispatch;
	}
	// 82214C20: F9610378  std r11, 0x378(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(888 as u32), ctx.r[11].u64 ) };
	// 82214C24: 386100F0  addi r3, r1, 0xf0
	ctx.r[3].s64 = ctx.r[1].s64 + 240;
	// 82214C28: C8010378  lfd f0, 0x378(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(888 as u32) ) };
	// 82214C2C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214C30: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214C34: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214C38: 4815F661  bl 0x82374298
	ctx.lr = 0x82214C3C;
	sub_82374298(ctx, base);
	// 82214C3C: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82214C40: A39E0000  lhz r28, 0(r30)
	ctx.r[28].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214C44: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82214C48: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214C4C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82214C50: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214C54: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82214C58: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214C5C: F9410388  std r10, 0x388(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(904 as u32), ctx.r[10].u64 ) };
	// 82214C60: 7D2B0734  extsh r11, r9
	ctx.r[11].s64 = ctx.r[9].s16 as i64;
	// 82214C64: F9610120  std r11, 0x120(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[11].u64 ) };
	// 82214C68: C8010388  lfd f0, 0x388(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(904 as u32) ) };
	// 82214C6C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214C70: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214C74: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214C78: C8010120  lfd f0, 0x120(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(288 as u32) ) };
	// 82214C7C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214C80: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214C84: EC4005B2  fmuls f2, f0, f22
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214C88: 48152D21  bl 0x823679a8
	ctx.lr = 0x82214C8C;
	sub_823679A8(ctx, base);
	// 82214C8C: 7F8B0734  extsh r11, r28
	ctx.r[11].s64 = ctx.r[28].s16 as i64;
	// 82214C90: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82214C94: 38610100  addi r3, r1, 0x100
	ctx.r[3].s64 = ctx.r[1].s64 + 256;
	// 82214C98: F96102F0  std r11, 0x2f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(752 as u32), ctx.r[11].u64 ) };
	// 82214C9C: C80102F0  lfd f0, 0x2f0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(752 as u32) ) };
	// 82214CA0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214CA4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214CA8: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214CAC: 4815F5ED  bl 0x82374298
	ctx.lr = 0x82214CB0;
	sub_82374298(ctx, base);
	// 82214CB0: 38A10100  addi r5, r1, 0x100
	ctx.r[5].s64 = ctx.r[1].s64 + 256;
	// 82214CB4: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82214CB8: 388100F0  addi r4, r1, 0xf0
	ctx.r[4].s64 = ctx.r[1].s64 + 240;
	// 82214CBC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82214CC0: 4815FAE1  bl 0x823747a0
	ctx.lr = 0x82214CC4;
	sub_823747A0(ctx, base);
	// 82214CC4: 48000024  b 0x82214ce8
	pc = 0x82214CE8; continue 'dispatch;
	// 82214CC8: F9610130  std r11, 0x130(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[11].u64 ) };
	// 82214CCC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82214CD0: C8010130  lfd f0, 0x130(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) };
	// 82214CD4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214CD8: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214CDC: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82214CE0: 4815F5B9  bl 0x82374298
	ctx.lr = 0x82214CE4;
	sub_82374298(ctx, base);
	// 82214CE4: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82214CE8: E9590000  ld r10, 0(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	// 82214CEC: 397D0010  addi r11, r29, 0x10
	ctx.r[11].s64 = ctx.r[29].s64 + 16;
	// 82214CF0: C381005C  lfs f28, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82214CF4: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82214CF8: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 82214CFC: E9590008  ld r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) };
	// 82214D00: F94B0008  std r10, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u64 ) };
	// 82214D04: 480013B8  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214D08 => {
    //   block [0x82214D08..0x82214EC8)
	// 82214D08: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 82214D0C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82214D10: 419A011C  beq cr6, 0x82214e2c
	if ctx.cr[6].eq {
	pc = 0x82214E2C; continue 'dispatch;
	}
	// 82214D14: A13F0000  lhz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D18: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82214D1C: A11E0000  lhz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D20: 395E0002  addi r10, r30, 2
	ctx.r[10].s64 = ctx.r[30].s64 + 2;
	// 82214D24: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82214D28: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82214D2C: 56C70462  rlwinm r7, r22, 0, 0x11, 0x11
	ctx.r[7].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82214D30: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 82214D34: F9210260  std r9, 0x260(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(608 as u32), ctx.r[9].u64 ) };
	// 82214D38: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D3C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82214D40: F9010140  std r8, 0x140(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[8].u64 ) };
	// 82214D44: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82214D48: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D4C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82214D50: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82214D54: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82214D58: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 82214D5C: F9210340  std r9, 0x340(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(832 as u32), ctx.r[9].u64 ) };
	// 82214D60: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D64: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214D68: 7D2A0734  extsh r10, r9
	ctx.r[10].s64 = ctx.r[9].s16 as i64;
	// 82214D6C: F9010150  std r8, 0x150(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[8].u64 ) };
	// 82214D70: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82214D74: F9410270  std r10, 0x270(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(624 as u32), ctx.r[10].u64 ) };
	// 82214D78: F9610160  std r11, 0x160(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), ctx.r[11].u64 ) };
	// 82214D7C: C8010260  lfd f0, 0x260(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(608 as u32) ) };
	// 82214D80: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214D84: C9A10140  lfd f13, 0x140(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(320 as u32) ) };
	// 82214D88: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 82214D8C: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214D90: C8010340  lfd f0, 0x340(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(832 as u32) ) };
	// 82214D94: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214D98: C9610150  lfd f11, 0x150(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(336 as u32) ) };
	// 82214D9C: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 82214DA0: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82214DA4: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82214DA8: C9210160  lfd f9, 0x160(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(352 as u32) ) };
	// 82214DAC: FD004E9C  fcfid f8, f9
	ctx.f[8].f64 = (ctx.f[9].s64 as f64);
	// 82214DB0: FD600018  frsp f11, f0
	ctx.f[11].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214DB4: C8010270  lfd f0, 0x270(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(624 as u32) ) };
	// 82214DB8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214DBC: D1610054  stfs f11, 0x54(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82214DC0: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 82214DC4: FD004018  frsp f8, f8
	ctx.f[8].f64 = (ctx.f[8].f64 as f32) as f64;
	// 82214DC8: FD200018  frsp f9, f0
	ctx.f[9].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214DCC: D1210058  stfs f9, 0x58(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82214DD0: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82214DD4: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82214DD8: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82214DDC: ED200272  fmuls f9, f0, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 82214DE0: EC1C0032  fmuls f0, f28, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 82214DE4: EDAC6FFA  fmadds f13, f12, f31, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82214DE8: ED8A5FFA  fmadds f12, f10, f31, f11
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82214DEC: EC1807FA  fmadds f0, f24, f31, f0
	ctx.f[0].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 82214DF0: D01D001C  stfs f0, 0x1c(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82214DF4: ED684FFA  fmadds f11, f8, f31, f9
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[9].f64) as f32) as f64);
	// 82214DF8: 409A001C  bne cr6, 0x82214e14
	if !ctx.cr[6].eq {
	pc = 0x82214E14; continue 'dispatch;
	}
	// 82214DFC: EC0D06F2  fmuls f0, f13, f27
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214E00: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82214E04: EC0C06F2  fmuls f0, f12, f27
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214E08: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82214E0C: EC0B06F2  fmuls f0, f11, f27
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214E10: 480000A0  b 0x82214eb0
	pc = 0x82214EB0; continue 'dispatch;
	// 82214E14: EC0D06B2  fmuls f0, f13, f26
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[26].f64) as f32) as f64);
	// 82214E18: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82214E1C: EC0C06B2  fmuls f0, f12, f26
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[26].f64) as f32) as f64);
	// 82214E20: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82214E24: EC0B06B2  fmuls f0, f11, f26
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[26].f64) as f32) as f64);
	// 82214E28: 48000088  b 0x82214eb0
	pc = 0x82214EB0; continue 'dispatch;
	// 82214E2C: 56CB0462  rlwinm r11, r22, 0, 0x11, 0x11
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82214E30: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82214E34: 419A000C  beq cr6, 0x82214e40
	if ctx.cr[6].eq {
	pc = 0x82214E40; continue 'dispatch;
	}
	// 82214E38: FC00D090  fmr f0, f26
	ctx.f[0].f64 = ctx.f[26].f64;
	// 82214E3C: 48000008  b 0x82214e44
	pc = 0x82214E44; continue 'dispatch;
	// 82214E40: FC00D890  fmr f0, f27
	ctx.f[0].f64 = ctx.f[27].f64;
	// 82214E44: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214E48: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82214E4C: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82214E50: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214E54: F9410300  std r10, 0x300(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(768 as u32), ctx.r[10].u64 ) };
	// 82214E58: C9A10300  lfd f13, 0x300(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(768 as u32) ) };
	// 82214E5C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82214E60: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82214E64: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82214E68: D1BD0010  stfs f13, 0x10(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82214E6C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214E70: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82214E74: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214E78: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82214E7C: F9410170  std r10, 0x170(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), ctx.r[10].u64 ) };
	// 82214E80: C9A10170  lfd f13, 0x170(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(368 as u32) ) };
	// 82214E84: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82214E88: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82214E8C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82214E90: D1BD0014  stfs f13, 0x14(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82214E94: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214E98: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82214E9C: F9610280  std r11, 0x280(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(640 as u32), ctx.r[11].u64 ) };
	// 82214EA0: C9A10280  lfd f13, 0x280(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(640 as u32) ) };
	// 82214EA4: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82214EA8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82214EAC: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82214EB0: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82214EB4: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82214EB8: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82214EBC: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82214EC0: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82214EC4: 480011F8  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82214EC8 => {
    //   block [0x82214EC8..0x82215040)
	// 82214EC8: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 82214ECC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82214ED0: 419A0100  beq cr6, 0x82214fd0
	if ctx.cr[6].eq {
	pc = 0x82214FD0; continue 'dispatch;
	}
	// 82214ED4: A13E0000  lhz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214ED8: 395F0002  addi r10, r31, 2
	ctx.r[10].s64 = ctx.r[31].s64 + 2;
	// 82214EDC: A11F0000  lhz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214EE0: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82214EE4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82214EE8: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82214EEC: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82214EF0: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82214EF4: F9210180  std r9, 0x180(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[9].u64 ) };
	// 82214EF8: F9010380  std r8, 0x380(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(896 as u32), ctx.r[8].u64 ) };
	// 82214EFC: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214F00: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82214F04: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214F08: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82214F0C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82214F10: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82214F14: EDBC0032  fmuls f13, f28, f0
	ctx.f[13].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 82214F18: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82214F1C: 3BEA0002  addi r31, r10, 2
	ctx.r[31].s64 = ctx.r[10].s64 + 2;
	// 82214F20: F9010290  std r8, 0x290(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(656 as u32), ctx.r[8].u64 ) };
	// 82214F24: F9210190  std r9, 0x190(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), ctx.r[9].u64 ) };
	// 82214F28: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214F2C: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214F30: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82214F34: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82214F38: ED586FFA  fmadds f10, f24, f31, f13
	ctx.f[10].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82214F3C: D15D001C  stfs f10, 0x1c(r29)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82214F40: F92101A0  std r9, 0x1a0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(416 as u32), ctx.r[9].u64 ) };
	// 82214F44: F9610310  std r11, 0x310(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(784 as u32), ctx.r[11].u64 ) };
	// 82214F48: C9810180  lfd f12, 0x180(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(384 as u32) ) };
	// 82214F4C: C9610380  lfd f11, 0x380(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(896 as u32) ) };
	// 82214F50: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82214F54: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 82214F58: FDA06018  frsp f13, f12
	ctx.f[13].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82214F5C: FD805818  frsp f12, f11
	ctx.f[12].f64 = (ctx.f[11].f64 as f32) as f64;
	// 82214F60: C9610290  lfd f11, 0x290(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(656 as u32) ) };
	// 82214F64: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 82214F68: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82214F6C: ED200332  fmuls f9, f0, f12
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82214F70: C9810190  lfd f12, 0x190(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(400 as u32) ) };
	// 82214F74: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 82214F78: D1610054  stfs f11, 0x54(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82214F7C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82214F80: EDAD4FFA  fmadds f13, f13, f31, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[9].f64) as f32) as f64);
	// 82214F84: ED4002F2  fmuls f10, f0, f11
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82214F88: C9610310  lfd f11, 0x310(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(784 as u32) ) };
	// 82214F8C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 82214F90: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82214F94: EDAD06F2  fmuls f13, f13, f27
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214F98: D1BD0010  stfs f13, 0x10(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82214F9C: C9A101A0  lfd f13, 0x1a0(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(416 as u32) ) };
	// 82214FA0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 82214FA4: D1610058  stfs f11, 0x58(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82214FA8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82214FAC: ED8C57FA  fmadds f12, f12, f31, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 82214FB0: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82214FB4: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82214FB8: ED8C06F2  fmuls f12, f12, f27
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214FBC: D19D0014  stfs f12, 0x14(r29)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82214FC0: EC0D07FA  fmadds f0, f13, f31, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 82214FC4: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214FC8: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82214FCC: 480010F0  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82214FD0: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214FD4: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82214FD8: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82214FDC: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82214FE0: F94101B0  std r10, 0x1b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), ctx.r[10].u64 ) };
	// 82214FE4: C80101B0  lfd f0, 0x1b0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(432 as u32) ) };
	// 82214FE8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82214FEC: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82214FF0: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82214FF4: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82214FF8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82214FFC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215000: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215004: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215008: F9410110  std r10, 0x110(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[10].u64 ) };
	// 8221500C: C8010110  lfd f0, 0x110(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(272 as u32) ) };
	// 82215010: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215014: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215018: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 8221501C: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215020: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215024: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215028: F96101C0  std r11, 0x1c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), ctx.r[11].u64 ) };
	// 8221502C: C80101C0  lfd f0, 0x1c0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(448 as u32) ) };
	// 82215030: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215034: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215038: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 8221503C: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
            }
            0x82215040 => {
    //   block [0x82215040..0x82215048)
	// 82215040: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215044: 48001078  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215048 => {
    //   block [0x82215048..0x822151C8)
	// 82215048: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 8221504C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82215050: 419A0100  beq cr6, 0x82215150
	if ctx.cr[6].eq {
	pc = 0x82215150; continue 'dispatch;
	}
	// 82215054: A13E0000  lhz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215058: 395F0002  addi r10, r31, 2
	ctx.r[10].s64 = ctx.r[31].s64 + 2;
	// 8221505C: A11F0000  lhz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215060: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215064: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215068: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221506C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82215070: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215074: F9210350  std r9, 0x350(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(848 as u32), ctx.r[9].u64 ) };
	// 82215078: F90101D0  std r8, 0x1d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(464 as u32), ctx.r[8].u64 ) };
	// 8221507C: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215080: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215084: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215088: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8221508C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82215090: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215094: EDBC0032  fmuls f13, f28, f0
	ctx.f[13].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 82215098: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 8221509C: 3BEA0002  addi r31, r10, 2
	ctx.r[31].s64 = ctx.r[10].s64 + 2;
	// 822150A0: F90101E0  std r8, 0x1e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(480 as u32), ctx.r[8].u64 ) };
	// 822150A4: F92102B0  std r9, 0x2b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(688 as u32), ctx.r[9].u64 ) };
	// 822150A8: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822150AC: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822150B0: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 822150B4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 822150B8: ED586FFA  fmadds f10, f24, f31, f13
	ctx.f[10].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 822150BC: D15D001C  stfs f10, 0x1c(r29)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 822150C0: F9210320  std r9, 0x320(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(800 as u32), ctx.r[9].u64 ) };
	// 822150C4: F96101F0  std r11, 0x1f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), ctx.r[11].u64 ) };
	// 822150C8: C9810350  lfd f12, 0x350(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(848 as u32) ) };
	// 822150CC: C96101D0  lfd f11, 0x1d0(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(464 as u32) ) };
	// 822150D0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 822150D4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 822150D8: FDA06018  frsp f13, f12
	ctx.f[13].f64 = (ctx.f[12].f64 as f32) as f64;
	// 822150DC: FD805818  frsp f12, f11
	ctx.f[12].f64 = (ctx.f[11].f64 as f32) as f64;
	// 822150E0: C96101E0  lfd f11, 0x1e0(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(480 as u32) ) };
	// 822150E4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 822150E8: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 822150EC: ED200332  fmuls f9, f0, f12
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 822150F0: C98102B0  lfd f12, 0x2b0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(688 as u32) ) };
	// 822150F4: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 822150F8: D1610054  stfs f11, 0x54(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 822150FC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82215100: EDAD4FFA  fmadds f13, f13, f31, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[9].f64) as f32) as f64);
	// 82215104: ED4002F2  fmuls f10, f0, f11
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82215108: C96101F0  lfd f11, 0x1f0(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(496 as u32) ) };
	// 8221510C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 82215110: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82215114: EDAD0572  fmuls f13, f13, f21
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[21].f64) as f32) as f64);
	// 82215118: D1BD0010  stfs f13, 0x10(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221511C: C9A10320  lfd f13, 0x320(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(800 as u32) ) };
	// 82215120: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 82215124: D1610058  stfs f11, 0x58(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215128: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221512C: ED8C57FA  fmadds f12, f12, f31, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 82215130: EC0002F2  fmuls f0, f0, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82215134: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82215138: ED8C0572  fmuls f12, f12, f21
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[21].f64) as f32) as f64);
	// 8221513C: D19D0014  stfs f12, 0x14(r29)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215140: EC0D07FA  fmadds f0, f13, f31, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 82215144: EC000572  fmuls f0, f0, f21
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[21].f64) as f32) as f64);
	// 82215148: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221514C: 48000F70  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215150: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215154: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215158: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 8221515C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215160: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215164: F94102C0  std r10, 0x2c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(704 as u32), ctx.r[10].u64 ) };
	// 82215168: C80102C0  lfd f0, 0x2c0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(704 as u32) ) };
	// 8221516C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215170: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215174: EC000572  fmuls f0, f0, f21
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[21].f64) as f32) as f64);
	// 82215178: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221517C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215180: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215184: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215188: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 8221518C: F9410200  std r10, 0x200(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(512 as u32), ctx.r[10].u64 ) };
	// 82215190: C8010200  lfd f0, 0x200(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(512 as u32) ) };
	// 82215194: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215198: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8221519C: EC000572  fmuls f0, f0, f21
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[21].f64) as f32) as f64);
	// 822151A0: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822151A4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822151A8: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 822151AC: F9610370  std r11, 0x370(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(880 as u32), ctx.r[11].u64 ) };
	// 822151B0: C8010370  lfd f0, 0x370(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(880 as u32) ) };
	// 822151B4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822151B8: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822151BC: EC000572  fmuls f0, f0, f21
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[21].f64) as f32) as f64);
	// 822151C0: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822151C4: 48000EF8  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x822151C8 => {
    //   block [0x822151C8..0x8221533C)
	// 822151C8: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 822151CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 822151D0: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 822151D4: 419A00F8  beq cr6, 0x822152cc
	if ctx.cr[6].eq {
	pc = 0x822152CC; continue 'dispatch;
	}
	// 822151D8: A13F0000  lhz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822151DC: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 822151E0: 395E0002  addi r10, r30, 2
	ctx.r[10].s64 = ctx.r[30].s64 + 2;
	// 822151E4: A11E0000  lhz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822151E8: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 822151EC: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 822151F0: B12100EE  sth r9, 0xee(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(238 as u32), ctx.r[9].u16 ) };
	// 822151F4: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822151F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822151FC: A0EA0000  lhz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215200: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215204: EDBC0032  fmuls f13, f28, f0
	ctx.f[13].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 82215208: B12100EC  sth r9, 0xec(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[9].u16 ) };
	// 8221520C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215210: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215214: A0CA0000  lhz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215218: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8221521C: A0AA0000  lhz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215220: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215224: ED986FFA  fmadds f12, f24, f31, f13
	ctx.f[12].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215228: A08A0000  lhz r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221522C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215230: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 82215234: C1A100EC  lfs f13, 0xec(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(236 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215238: B12100DA  sth r9, 0xda(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(218 as u32), ctx.r[9].u16 ) };
	// 8221523C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215240: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215244: ED600372  fmuls f11, f0, f13
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82215248: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8221524C: B12100D8  sth r9, 0xd8(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[9].u16 ) };
	// 82215250: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215254: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215258: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 8221525C: C1A100D8  lfs f13, 0xd8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215260: B121006A  sth r9, 0x6a(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(106 as u32), ctx.r[9].u16 ) };
	// 82215264: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215268: ED400372  fmuls f10, f0, f13
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221526C: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215270: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215274: D19D001C  stfs f12, 0x1c(r29)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82215278: B1210068  sth r9, 0x68(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[9].u16 ) };
	// 8221527C: C1A10068  lfs f13, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215280: B10100B2  sth r8, 0xb2(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(178 as u32), ctx.r[8].u16 ) };
	// 82215284: B0E100B0  sth r7, 0xb0(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[7].u16 ) };
	// 82215288: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221528C: D1A10058  stfs f13, 0x58(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215290: C00100B0  lfs f0, 0xb0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215294: B0C10072  sth r6, 0x72(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(114 as u32), ctx.r[6].u16 ) };
	// 82215298: B0A10070  sth r5, 0x70(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[5].u16 ) };
	// 8221529C: EC005FFA  fmadds f0, f0, f31, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 822152A0: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822152A4: C1A10070  lfs f13, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822152A8: B08100D2  sth r4, 0xd2(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(210 as u32), ctx.r[4].u16 ) };
	// 822152AC: B16100D0  sth r11, 0xd0(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[11].u16 ) };
	// 822152B0: EDAD57FA  fmadds f13, f13, f31, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 822152B4: D1BD0014  stfs f13, 0x14(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822152B8: C00100D0  lfs f0, 0xd0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822152BC: EC0067FA  fmadds f0, f0, f31, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 822152C0: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822152C4: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 822152C8: 48000DF4  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 822152CC: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822152D0: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 822152D4: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 822152D8: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 822152DC: B141007A  sth r10, 0x7a(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(122 as u32), ctx.r[10].u16 ) };
	// 822152E0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822152E4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822152E8: B1410078  sth r10, 0x78(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[10].u16 ) };
	// 822152EC: C0010078  lfs f0, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822152F0: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822152F4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822152F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822152FC: B14100BA  sth r10, 0xba(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(186 as u32), ctx.r[10].u16 ) };
	// 82215300: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215304: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215308: B14100B8  sth r10, 0xb8(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[10].u16 ) };
	// 8221530C: C00100B8  lfs f0, 0xb8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215310: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215314: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215318: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8221531C: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215320: B1410082  sth r10, 0x82(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(130 as u32), ctx.r[10].u16 ) };
	// 82215324: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215328: B1410080  sth r10, 0x80(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[10].u16 ) };
	// 8221532C: C0010080  lfs f0, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215330: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215334: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215338: 48000D84  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x8221533C => {
    //   block [0x8221533C..0x822154A0)
	// 8221533C: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 82215340: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82215344: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215348: 419A00F0  beq cr6, 0x82215438
	if ctx.cr[6].eq {
	pc = 0x82215438; continue 'dispatch;
	}
	// 8221534C: A13F0000  lhz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215350: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82215354: 395E0002  addi r10, r30, 2
	ctx.r[10].s64 = ctx.r[30].s64 + 2;
	// 82215358: A11E0000  lhz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221535C: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215360: B12100D6  sth r9, 0xd6(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(214 as u32), ctx.r[9].u16 ) };
	// 82215364: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215368: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8221536C: A0EA0000  lhz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215370: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215374: EDBC0032  fmuls f13, f28, f0
	ctx.f[13].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 82215378: B12100D4  sth r9, 0xd4(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[9].u16 ) };
	// 8221537C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215380: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215384: A0CA0000  lhz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215388: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8221538C: A0AA0000  lhz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215390: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215394: ED986FFA  fmadds f12, f24, f31, f13
	ctx.f[12].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215398: A08A0000  lhz r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221539C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822153A0: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 822153A4: C1A100D4  lfs f13, 0xd4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822153A8: B121008A  sth r9, 0x8a(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(138 as u32), ctx.r[9].u16 ) };
	// 822153AC: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822153B0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822153B4: ED600372  fmuls f11, f0, f13
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822153B8: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 822153BC: B1210088  sth r9, 0x88(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[9].u16 ) };
	// 822153C0: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822153C4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822153C8: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 822153CC: C1A10088  lfs f13, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822153D0: B12100C2  sth r9, 0xc2(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(194 as u32), ctx.r[9].u16 ) };
	// 822153D4: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822153D8: ED400372  fmuls f10, f0, f13
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822153DC: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 822153E0: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822153E4: D19D001C  stfs f12, 0x1c(r29)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 822153E8: B12100C0  sth r9, 0xc0(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[9].u16 ) };
	// 822153EC: C1A100C0  lfs f13, 0xc0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822153F0: B1010092  sth r8, 0x92(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(146 as u32), ctx.r[8].u16 ) };
	// 822153F4: B0E10090  sth r7, 0x90(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[7].u16 ) };
	// 822153F8: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822153FC: D1A10058  stfs f13, 0x58(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215400: C0010090  lfs f0, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215404: B0C100EA  sth r6, 0xea(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(234 as u32), ctx.r[6].u16 ) };
	// 82215408: B0A100E8  sth r5, 0xe8(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[5].u16 ) };
	// 8221540C: EC005FFA  fmadds f0, f0, f31, f11
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82215410: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82215414: C1A100E8  lfs f13, 0xe8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215418: B081009A  sth r4, 0x9a(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(154 as u32), ctx.r[4].u16 ) };
	// 8221541C: B1610098  sth r11, 0x98(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[11].u16 ) };
	// 82215420: EDAD57FA  fmadds f13, f13, f31, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 82215424: D1BD0014  stfs f13, 0x14(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215428: C0010098  lfs f0, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221542C: EC0067FA  fmadds f0, f0, f31, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82215430: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215434: 48000C88  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215438: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221543C: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 82215440: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215444: B14100CA  sth r10, 0xca(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(202 as u32), ctx.r[10].u16 ) };
	// 82215448: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221544C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215450: B14100C8  sth r10, 0xc8(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[10].u16 ) };
	// 82215454: C00100C8  lfs f0, 0xc8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215458: D01D0010  stfs f0, 0x10(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221545C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215460: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215464: B14100A2  sth r10, 0xa2(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(162 as u32), ctx.r[10].u16 ) };
	// 82215468: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221546C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215470: B14100A0  sth r10, 0xa0(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[10].u16 ) };
	// 82215474: C00100A0  lfs f0, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215478: D01D0014  stfs f0, 0x14(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8221547C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215480: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215484: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215488: B14100E2  sth r10, 0xe2(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(226 as u32), ctx.r[10].u16 ) };
	// 8221548C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215490: B14100E0  sth r10, 0xe0(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[10].u16 ) };
	// 82215494: C00100E0  lfs f0, 0xe0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215498: D01D0018  stfs f0, 0x18(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221549C: 48000C20  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x822154A0 => {
    //   block [0x822154A0..0x8221555C)
	// 822154A0: A17F0000  lhz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822154A4: 3BFF0002  addi r31, r31, 2
	ctx.r[31].s64 = ctx.r[31].s64 + 2;
	// 822154A8: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822154AC: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	// 822154B0: 7D690734  extsh r9, r11
	ctx.r[9].s64 = ctx.r[11].s16 as i64;
	// 822154B4: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 822154B8: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 822154BC: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 822154C0: 40990014  ble cr6, 0x822154d4
	if !ctx.cr[6].gt {
	pc = 0x822154D4; continue 'dispatch;
	}
	// 822154C4: 7D525050  subf r10, r18, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[18].s64;
	// 822154C8: 7D6B9214  add r11, r11, r18
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[18].u64;
	// 822154CC: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 822154D0: 4199FFF4  bgt cr6, 0x822154c4
	if ctx.cr[6].gt {
	pc = 0x822154C4; continue 'dispatch;
	}
	// 822154D4: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 822154D8: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 822154DC: 40980014  bge cr6, 0x822154f0
	if !ctx.cr[6].lt {
	pc = 0x822154F0; continue 'dispatch;
	}
	// 822154E0: 7D4A9214  add r10, r10, r18
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[18].u64;
	// 822154E4: 7D725850  subf r11, r18, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[18].s64;
	// 822154E8: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 822154EC: 4198FFF4  blt cr6, 0x822154e0
	if ctx.cr[6].lt {
	pc = 0x822154E0; continue 'dispatch;
	}
	// 822154F0: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 822154F4: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 822154F8: 7D2A07B4  extsw r10, r9
	ctx.r[10].s64 = ctx.r[9].s32 as i64;
	// 822154FC: D2410054  stfs f18, 0x54(r1)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215500: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215504: D2410050  stfs f18, 0x50(r1)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215508: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8221550C: D3A10058  stfs f29, 0x58(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215510: F9610210  std r11, 0x210(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(528 as u32), ctx.r[11].u64 ) };
	// 82215514: F94102D0  std r10, 0x2d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(720 as u32), ctx.r[10].u64 ) };
	// 82215518: C9A10210  lfd f13, 0x210(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(528 as u32) ) };
	// 8221551C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82215520: C98102D0  lfd f12, 0x2d0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(720 as u32) ) };
	// 82215524: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82215528: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8221552C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82215530: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 82215534: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215538: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 8221553C: 4815ED5D  bl 0x82374298
	ctx.lr = 0x82215540;
	sub_82374298(ctx, base);
	// 82215540: E9590000  ld r10, 0(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	// 82215544: 397D0010  addi r11, r29, 0x10
	ctx.r[11].s64 = ctx.r[29].s64 + 16;
	// 82215548: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 8221554C: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 82215550: E9590008  ld r10, 8(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) };
	// 82215554: F94B0008  std r10, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u64 ) };
	// 82215558: 48000B64  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x8221555C => {
    //   block [0x8221555C..0x82215860)
	// 8221555C: 81500008  lwz r10, 8(r16)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(8 as u32) ) } as u64;
	// 82215560: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215564: 81700004  lwz r11, 4(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) } as u64;
	// 82215568: 386100F0  addi r3, r1, 0xf0
	ctx.r[3].s64 = ctx.r[1].s64 + 240;
	// 8221556C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215570: D2410050  stfs f18, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215574: D3A10054  stfs f29, 0x54(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215578: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8221557C: D2410058  stfs f18, 0x58(r1)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215580: 7D4A582E  lwzx r10, r10, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82215584: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82215588: A16B0010  lhz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8221558C: 556B0026  rlwinm r11, r11, 0, 0, 0x13
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82215590: F9610220  std r11, 0x220(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(544 as u32), ctx.r[11].u64 ) };
	// 82215594: C8010220  lfd f0, 0x220(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(544 as u32) ) };
	// 82215598: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8221559C: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822155A0: EF2005B2  fmuls f25, f0, f22
	ctx.f[25].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 822155A4: EC39802A  fadds f1, f25, f16
	ctx.f[1].f64 = ((ctx.f[25].f64 + ctx.f[16].f64) as f32) as f64;
	// 822155A8: 4815ECF1  bl 0x82374298
	ctx.lr = 0x822155AC;
	sub_82374298(ctx, base);
	// 822155AC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 822155B0: EC39982A  fadds f1, f25, f19
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ((ctx.f[25].f64 + ctx.f[19].f64) as f32) as f64;
	// 822155B4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 822155B8: 4815ECE1  bl 0x82374298
	ctx.lr = 0x822155BC;
	sub_82374298(ctx, base);
	// 822155BC: 56CB00C6  rlwinm r11, r22, 0, 3, 3
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 822155C0: A13F0000  lhz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 822155C4: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 822155C8: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 822155CC: A11E0000  lhz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822155D0: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 822155D4: 395E0002  addi r10, r30, 2
	ctx.r[10].s64 = ctx.r[30].s64 + 2;
	// 822155D8: 419A009C  beq cr6, 0x82215674
	if ctx.cr[6].eq {
	pc = 0x82215674; continue 'dispatch;
	}
	// 822155DC: B12100AA  sth r9, 0xaa(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(170 as u32), ctx.r[9].u16 ) };
	// 822155E0: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822155E4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822155E8: A0EA0000  lhz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822155EC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 822155F0: B12100A8  sth r9, 0xa8(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[9].u16 ) };
	// 822155F4: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822155F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822155FC: A0CA0000  lhz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215600: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215604: A0AA0000  lhz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215608: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8221560C: A08A0000  lhz r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215610: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215614: C00100A8  lfs f0, 0xa8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82215618: B1210062  sth r9, 0x62(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(98 as u32), ctx.r[9].u16 ) };
	// 8221561C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215620: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215624: B1210060  sth r9, 0x60(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u16 ) };
	// 82215628: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221562C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215630: A06B0000  lhz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215634: C1810060  lfs f12, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82215638: B1210066  sth r9, 0x66(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(102 as u32), ctx.r[9].u16 ) };
	// 8221563C: B0610064  sth r3, 0x64(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[3].u16 ) };
	// 82215640: 392B0002  addi r9, r11, 2
	ctx.r[9].s64 = ctx.r[11].s64 + 2;
	// 82215644: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215648: C1410064  lfs f10, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221564C: B101006E  sth r8, 0x6e(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(110 as u32), ctx.r[8].u16 ) };
	// 82215650: B0E1006C  sth r7, 0x6c(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[7].u16 ) };
	// 82215654: C1A1006C  lfs f13, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215658: B0C10076  sth r6, 0x76(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(118 as u32), ctx.r[6].u16 ) };
	// 8221565C: B0A10074  sth r5, 0x74(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[5].u16 ) };
	// 82215660: C1610074  lfs f11, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82215664: B081007E  sth r4, 0x7e(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(126 as u32), ctx.r[4].u16 ) };
	// 82215668: B161007C  sth r11, 0x7c(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u16 ) };
	// 8221566C: C121007C  lfs f9, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82215670: 48000098  b 0x82215708
	pc = 0x82215708; continue 'dispatch;
	// 82215674: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 82215678: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8221567C: F9010230  std r8, 0x230(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(560 as u32), ctx.r[8].u64 ) };
	// 82215680: F9210330  std r9, 0x330(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(816 as u32), ctx.r[9].u64 ) };
	// 82215684: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215688: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8221568C: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215690: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215694: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215698: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8221569C: F92102E0  std r9, 0x2e0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(736 as u32), ctx.r[9].u64 ) };
	// 822156A0: 392B0002  addi r9, r11, 2
	ctx.r[9].s64 = ctx.r[11].s64 + 2;
	// 822156A4: F9010240  std r8, 0x240(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(576 as u32), ctx.r[8].u64 ) };
	// 822156A8: A10B0000  lhz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822156AC: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 822156B0: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 822156B4: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 822156B8: F9010360  std r8, 0x360(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(864 as u32), ctx.r[8].u64 ) };
	// 822156BC: F9610250  std r11, 0x250(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(592 as u32), ctx.r[11].u64 ) };
	// 822156C0: C9A10230  lfd f13, 0x230(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(560 as u32) ) };
	// 822156C4: C8010330  lfd f0, 0x330(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(816 as u32) ) };
	// 822156C8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 822156CC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822156D0: C98102E0  lfd f12, 0x2e0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(736 as u32) ) };
	// 822156D4: C9610240  lfd f11, 0x240(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(576 as u32) ) };
	// 822156D8: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 822156DC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 822156E0: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822156E4: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 822156E8: C9410360  lfd f10, 0x360(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(864 as u32) ) };
	// 822156EC: C9210250  lfd f9, 0x250(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(592 as u32) ) };
	// 822156F0: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 822156F4: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 822156F8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 822156FC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 82215700: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 82215704: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 82215708: EFDDF828  fsubs f30, f29, f31
	ctx.f[30].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221570C: 56CB0462  rlwinm r11, r22, 0, 0x11, 0x11
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82215710: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215714: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82215718: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221571C: ED9E0332  fmuls f12, f30, f12
	ctx.f[12].f64 = (((ctx.f[30].f64 * ctx.f[12].f64) as f32) as f64);
	// 82215720: ED1C07B2  fmuls f8, f28, f30
	ctx.f[8].f64 = (((ctx.f[28].f64 * ctx.f[30].f64) as f32) as f64);
	// 82215724: ED5E02B2  fmuls f10, f30, f10
	ctx.f[10].f64 = (((ctx.f[30].f64 * ctx.f[10].f64) as f32) as f64);
	// 82215728: EC0D07FA  fmadds f0, f13, f31, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221572C: EDAB67FA  fmadds f13, f11, f31, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82215730: EF9847FA  fmadds f28, f24, f31, f8
	ctx.f[28].f64 = (((ctx.f[24].f64 * ctx.f[31].f64 + ctx.f[8].f64) as f32) as f64);
	// 82215734: D381005C  stfs f28, 0x5c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82215738: ED8957FA  fmadds f12, f9, f31, f10
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 8221573C: 409A001C  bne cr6, 0x82215758
	if !ctx.cr[6].eq {
	pc = 0x82215758; continue 'dispatch;
	}
	// 82215740: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215744: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215748: EC0D06F2  fmuls f0, f13, f27
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 8221574C: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215750: EC0C06F2  fmuls f0, f12, f27
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215754: 48000018  b 0x8221576c
	pc = 0x8221576C; continue 'dispatch;
	// 82215758: EC0006B2  fmuls f0, f0, f26
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[26].f64) as f32) as f64);
	// 8221575C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215760: EC0D06B2  fmuls f0, f13, f26
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215764: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215768: EC0C06B2  fmuls f0, f12, f26
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[26].f64) as f32) as f64);
	// 8221576C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215770: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215774: 388100F0  addi r4, r1, 0xf0
	ctx.r[4].s64 = ctx.r[1].s64 + 240;
	// 82215778: 387D0010  addi r3, r29, 0x10
	ctx.r[3].s64 = ctx.r[29].s64 + 16;
	// 8221577C: 48152055  bl 0x823677d0
	ctx.lr = 0x82215780;
	sub_823677D0(ctx, base);
	// 82215780: A1690000  lhz r11, 0(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215784: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215788: 3BE90002  addi r31, r9, 2
	ctx.r[31].s64 = ctx.r[9].s64 + 2;
	// 8221578C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82215790: 7D090734  extsh r9, r8
	ctx.r[9].s64 = ctx.r[8].s16 as i64;
	// 82215794: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 82215798: F9610118  std r11, 0x118(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[11].u64 ) };
	// 8221579C: F9210128  std r9, 0x128(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), ctx.r[9].u64 ) };
	// 822157A0: C8010118  lfd f0, 0x118(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) };
	// 822157A4: C9A10128  lfd f13, 0x128(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(296 as u32) ) };
	// 822157A8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822157AC: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 822157B0: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822157B4: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 822157B8: EC0005B2  fmuls f0, f0, f22
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 822157BC: EDAD05B2  fmuls f13, f13, f22
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[22].f64) as f32) as f64);
	// 822157C0: ED806828  fsubs f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 822157C4: FF0CB800  fcmpu cr6, f12, f23
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[23].f64);
	// 822157C8: 4099000C  ble cr6, 0x822157d4
	if !ctx.cr[6].gt {
	pc = 0x822157D4; continue 'dispatch;
	}
	// 822157CC: EC00E828  fsubs f0, f0, f29
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[29].f64) as f32) as f64);
	// 822157D0: 48000010  b 0x822157e0
	pc = 0x822157E0; continue 'dispatch;
	// 822157D4: FF0C8800  fcmpu cr6, f12, f17
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[17].f64);
	// 822157D8: 40980008  bge cr6, 0x822157e0
	if !ctx.cr[6].lt {
	pc = 0x822157E0; continue 'dispatch;
	}
	// 822157DC: EC00E82A  fadds f0, f0, f29
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[29].f64) as f32) as f64;
	// 822157E0: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 822157E4: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 822157E8: EC1E683A  fmadds f0, f30, f0, f13
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 822157EC: EC00C82A  fadds f0, f0, f25
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[25].f64) as f32) as f64;
	// 822157F0: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 822157F4: ED970028  fsubs f12, f23, f0
	ctx.f[12].f64 = (((ctx.f[23].f64 - ctx.f[0].f64) as f32) as f64);
	// 822157F8: EDADB828  fsubs f13, f13, f23
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[23].f64) as f32) as f64);
	// 822157FC: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 82215800: FDA06E5E  fctidz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[13].f64.trunc() as i64 };
	// 82215804: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82215808: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221580C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82215810: FD606818  frsp f11, f13
	ctx.f[11].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82215814: EDAC002A  fadds f13, f12, f0
	ctx.f[13].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 82215818: ED8B002A  fadds f12, f11, f0
	ctx.f[12].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8221581C: FC006B2E  fsel f0, f0, f12, f13
	ctx.f[0].f64 = if ctx.f[0].f64 >= 0.0 { ctx.f[12].f64 } else { ctx.f[13].f64 };
	// 82215820: D00E64D0  stfs f0, 0x64d0(r14)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(25808 as u32), tmp.u32 ) };
	// 82215824: EC00982A  fadds f0, f0, f19
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[19].f64) as f32) as f64;
	// 82215828: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221582C: ED970028  fsubs f12, f23, f0
	ctx.f[12].f64 = (((ctx.f[23].f64 - ctx.f[0].f64) as f32) as f64);
	// 82215830: EDADB828  fsubs f13, f13, f23
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[23].f64) as f32) as f64);
	// 82215834: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 82215838: FDA06E5E  fctidz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[13].f64.trunc() as i64 };
	// 8221583C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 82215840: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82215844: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82215848: FD606818  frsp f11, f13
	ctx.f[11].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8221584C: EDAC002A  fadds f13, f12, f0
	ctx.f[13].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 82215850: ED8B002A  fadds f12, f11, f0
	ctx.f[12].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 82215854: FC006B2E  fsel f0, f0, f12, f13
	ctx.f[0].f64 = if ctx.f[0].f64 >= 0.0 { ctx.f[12].f64 } else { ctx.f[13].f64 };
	// 82215858: D00B64D4  stfs f0, 0x64d4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(25812 as u32), tmp.u32 ) };
	// 8221585C: 48000860  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215860 => {
    //   block [0x82215860..0x82215A64)
	// 82215860: 56CB00C6  rlwinm r11, r22, 0, 3, 3
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82215864: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215868: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221586C: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215870: 419A00B4  beq cr6, 0x82215924
	if ctx.cr[6].eq {
	pc = 0x82215924; continue 'dispatch;
	}
	// 82215874: B1410086  sth r10, 0x86(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(134 as u32), ctx.r[10].u16 ) };
	// 82215878: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221587C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215880: B1410084  sth r10, 0x84(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[10].u16 ) };
	// 82215884: C1A10084  lfs f13, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215888: D1BB0000  stfs f13, 0(r27)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221588C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215890: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215894: B141008E  sth r10, 0x8e(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(142 as u32), ctx.r[10].u16 ) };
	// 82215898: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221589C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822158A0: B141008C  sth r10, 0x8c(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[10].u16 ) };
	// 822158A4: C181008C  lfs f12, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822158A8: D19B0004  stfs f12, 4(r27)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822158AC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158B0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822158B4: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 822158B8: B1410096  sth r10, 0x96(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(150 as u32), ctx.r[10].u16 ) };
	// 822158BC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158C0: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 822158C4: B1410094  sth r10, 0x94(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[10].u16 ) };
	// 822158C8: C1610094  lfs f11, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822158CC: D17B0008  stfs f11, 8(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822158D0: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158D4: B141009E  sth r10, 0x9e(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(158 as u32), ctx.r[10].u16 ) };
	// 822158D8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158DC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822158E0: B141009C  sth r10, 0x9c(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[10].u16 ) };
	// 822158E4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158E8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822158EC: C141009C  lfs f10, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 822158F0: B14100A6  sth r10, 0xa6(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(166 as u32), ctx.r[10].u16 ) };
	// 822158F4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822158F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 822158FC: B14100A4  sth r10, 0xa4(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[10].u16 ) };
	// 82215900: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215904: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215908: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 8221590C: C12100A4  lfs f9, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82215910: B14100AE  sth r10, 0xae(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(174 as u32), ctx.r[10].u16 ) };
	// 82215914: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215918: B14100AC  sth r10, 0xac(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[10].u16 ) };
	// 8221591C: C10100AC  lfs f8, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82215920: 480000B0  b 0x822159d0
	pc = 0x822159D0; continue 'dispatch;
	// 82215924: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215928: F9410138  std r10, 0x138(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), ctx.r[10].u64 ) };
	// 8221592C: C8010138  lfd f0, 0x138(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) };
	// 82215930: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215934: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215938: D1BB0000  stfs f13, 0(r27)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221593C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215940: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215944: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215948: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 8221594C: F9410148  std r10, 0x148(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), ctx.r[10].u64 ) };
	// 82215950: C8010148  lfd f0, 0x148(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(328 as u32) ) };
	// 82215954: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215958: FD800018  frsp f12, f0
	ctx.f[12].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8221595C: D19B0004  stfs f12, 4(r27)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215960: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215964: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215968: F9610158  std r11, 0x158(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), ctx.r[11].u64 ) };
	// 8221596C: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215970: C8010158  lfd f0, 0x158(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(344 as u32) ) };
	// 82215974: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215978: FD600018  frsp f11, f0
	ctx.f[11].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8221597C: D17B0008  stfs f11, 8(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215980: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215984: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215988: F9410168  std r10, 0x168(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), ctx.r[10].u64 ) };
	// 8221598C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215990: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215994: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215998: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 8221599C: F9410178  std r10, 0x178(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), ctx.r[10].u64 ) };
	// 822159A0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822159A4: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 822159A8: F9610188  std r11, 0x188(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), ctx.r[11].u64 ) };
	// 822159AC: C8010168  lfd f0, 0x168(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(360 as u32) ) };
	// 822159B0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822159B4: FD400018  frsp f10, f0
	ctx.f[10].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822159B8: C8010178  lfd f0, 0x178(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(376 as u32) ) };
	// 822159BC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822159C0: FD200018  frsp f9, f0
	ctx.f[9].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822159C4: C8010188  lfd f0, 0x188(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(392 as u32) ) };
	// 822159C8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 822159CC: FD000018  frsp f8, f0
	ctx.f[8].f64 = (ctx.f[0].f64 as f32) as f64;
	// 822159D0: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 822159D4: C0FB000C  lfs f7, 0xc(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 822159D8: 56CB0462  rlwinm r11, r22, 0, 0x11, 0x11
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 822159DC: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 822159E0: D1210054  stfs f9, 0x54(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 822159E4: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 822159E8: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 822159EC: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822159F0: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 822159F4: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 822159F8: ECE001F2  fmuls f7, f0, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 822159FC: EC0A6FFA  fmadds f0, f10, f31, f13
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215A00: EDA967FA  fmadds f13, f9, f31, f12
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82215A04: ED885FFA  fmadds f12, f8, f31, f11
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82215A08: ED7C3FFA  fmadds f11, f28, f31, f7
	ctx.f[11].f64 = (((ctx.f[28].f64 * ctx.f[31].f64 + ctx.f[7].f64) as f32) as f64);
	// 82215A0C: D17B000C  stfs f11, 0xc(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82215A10: 409A002C  bne cr6, 0x82215a3c
	if !ctx.cr[6].eq {
	pc = 0x82215A3C; continue 'dispatch;
	}
	// 82215A14: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215A18: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82215A1C: EC0D06F2  fmuls f0, f13, f27
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215A20: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215A24: EC0C06F2  fmuls f0, f12, f27
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215A28: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215A2C: D01B0008  stfs f0, 8(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215A30: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215A34: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215A38: 48000684  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215A3C: EC0006B2  fmuls f0, f0, f26
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215A40: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82215A44: EC0D06B2  fmuls f0, f13, f26
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215A48: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215A4C: EC0C06B2  fmuls f0, f12, f26
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215A50: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215A54: D01B0008  stfs f0, 8(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215A58: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215A5C: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215A60: 4800065C  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215A64 => {
    //   block [0x82215A64..0x82215C68)
	// 82215A64: 56CB00C6  rlwinm r11, r22, 0, 3, 3
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82215A68: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215A6C: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82215A70: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215A74: 419A00B4  beq cr6, 0x82215b28
	if ctx.cr[6].eq {
	pc = 0x82215B28; continue 'dispatch;
	}
	// 82215A78: B14100B6  sth r10, 0xb6(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(182 as u32), ctx.r[10].u16 ) };
	// 82215A7C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215A80: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215A84: B14100B4  sth r10, 0xb4(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[10].u16 ) };
	// 82215A88: C1A100B4  lfs f13, 0xb4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215A8C: D1BB0010  stfs f13, 0x10(r27)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82215A90: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215A94: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215A98: B14100BE  sth r10, 0xbe(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(190 as u32), ctx.r[10].u16 ) };
	// 82215A9C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AA0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215AA4: B14100BC  sth r10, 0xbc(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[10].u16 ) };
	// 82215AA8: C18100BC  lfs f12, 0xbc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82215AAC: D19B0014  stfs f12, 0x14(r27)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215AB0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AB4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215AB8: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215ABC: B14100C6  sth r10, 0xc6(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(198 as u32), ctx.r[10].u16 ) };
	// 82215AC0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AC4: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215AC8: B14100C4  sth r10, 0xc4(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[10].u16 ) };
	// 82215ACC: C16100C4  lfs f11, 0xc4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82215AD0: D17B0018  stfs f11, 0x18(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215AD4: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AD8: B14100CE  sth r10, 0xce(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(206 as u32), ctx.r[10].u16 ) };
	// 82215ADC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AE0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215AE4: B14100CC  sth r10, 0xcc(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[10].u16 ) };
	// 82215AE8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AEC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215AF0: C14100CC  lfs f10, 0xcc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82215AF4: B14100DE  sth r10, 0xde(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(222 as u32), ctx.r[10].u16 ) };
	// 82215AF8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215AFC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215B00: B14100DC  sth r10, 0xdc(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[10].u16 ) };
	// 82215B04: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B08: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215B0C: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82215B10: C12100DC  lfs f9, 0xdc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82215B14: B14100E6  sth r10, 0xe6(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(230 as u32), ctx.r[10].u16 ) };
	// 82215B18: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B1C: B14100E4  sth r10, 0xe4(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[10].u16 ) };
	// 82215B20: C10100E4  lfs f8, 0xe4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82215B24: 480000B0  b 0x82215bd4
	pc = 0x82215BD4; continue 'dispatch;
	// 82215B28: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215B2C: F9410198  std r10, 0x198(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), ctx.r[10].u64 ) };
	// 82215B30: C8010198  lfd f0, 0x198(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(408 as u32) ) };
	// 82215B34: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215B38: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215B3C: D1BB0010  stfs f13, 0x10(r27)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82215B40: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B44: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215B48: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215B4C: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215B50: F94101A8  std r10, 0x1a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(424 as u32), ctx.r[10].u64 ) };
	// 82215B54: C80101A8  lfd f0, 0x1a8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(424 as u32) ) };
	// 82215B58: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215B5C: FD800018  frsp f12, f0
	ctx.f[12].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215B60: D19B0014  stfs f12, 0x14(r27)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215B64: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B68: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215B6C: F96101B8  std r11, 0x1b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), ctx.r[11].u64 ) };
	// 82215B70: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215B74: C80101B8  lfd f0, 0x1b8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(440 as u32) ) };
	// 82215B78: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215B7C: FD600018  frsp f11, f0
	ctx.f[11].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215B80: D17B0018  stfs f11, 0x18(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215B84: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B88: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215B8C: F94101C8  std r10, 0x1c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), ctx.r[10].u64 ) };
	// 82215B90: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215B94: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215B98: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215B9C: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82215BA0: F94101D8  std r10, 0x1d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(472 as u32), ctx.r[10].u64 ) };
	// 82215BA4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215BA8: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215BAC: F96101E8  std r11, 0x1e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), ctx.r[11].u64 ) };
	// 82215BB0: C80101C8  lfd f0, 0x1c8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(456 as u32) ) };
	// 82215BB4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215BB8: FD400018  frsp f10, f0
	ctx.f[10].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215BBC: C80101D8  lfd f0, 0x1d8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(472 as u32) ) };
	// 82215BC0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215BC4: FD200018  frsp f9, f0
	ctx.f[9].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215BC8: C80101E8  lfd f0, 0x1e8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(488 as u32) ) };
	// 82215BCC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215BD0: FD000018  frsp f8, f0
	ctx.f[8].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215BD4: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82215BD8: C0FB001C  lfs f7, 0x1c(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(28 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82215BDC: 56CB0462  rlwinm r11, r22, 0, 0x11, 0x11
	ctx.r[11].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82215BE0: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215BE4: D1210054  stfs f9, 0x54(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215BE8: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215BEC: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 82215BF0: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82215BF4: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82215BF8: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82215BFC: ECE001F2  fmuls f7, f0, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 82215C00: EC0A6FFA  fmadds f0, f10, f31, f13
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215C04: EDA967FA  fmadds f13, f9, f31, f12
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82215C08: ED885FFA  fmadds f12, f8, f31, f11
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82215C0C: ED7C3FFA  fmadds f11, f28, f31, f7
	ctx.f[11].f64 = (((ctx.f[28].f64 * ctx.f[31].f64 + ctx.f[7].f64) as f32) as f64);
	// 82215C10: D17B001C  stfs f11, 0x1c(r27)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82215C14: 409A002C  bne cr6, 0x82215c40
	if !ctx.cr[6].eq {
	pc = 0x82215C40; continue 'dispatch;
	}
	// 82215C18: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215C1C: D01B0010  stfs f0, 0x10(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82215C20: EC0D06F2  fmuls f0, f13, f27
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215C24: D01B0014  stfs f0, 0x14(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215C28: EC0C06F2  fmuls f0, f12, f27
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215C2C: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215C30: D01B0018  stfs f0, 0x18(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215C34: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215C38: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215C3C: 48000480  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215C40: EC0006B2  fmuls f0, f0, f26
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215C44: D01B0010  stfs f0, 0x10(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82215C48: EC0D06B2  fmuls f0, f13, f26
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215C4C: D01B0014  stfs f0, 0x14(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82215C50: EC0C06B2  fmuls f0, f12, f26
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215C54: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215C58: D01B0018  stfs f0, 0x18(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82215C5C: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215C60: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215C64: 48000458  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215C68 => {
    //   block [0x82215C68..0x82215DB0)
	// 82215C68: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215C6C: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215C70: 56C90462  rlwinm r9, r22, 0, 0x11, 0x11
	ctx.r[9].u64 = ctx.r[22].u32 as u64 & 0xFFFFFFFFu64;
	// 82215C74: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215C78: 2B290000  cmpldi cr6, r9, 0
	ctx.cr[6].compare_u64(ctx.r[9].u64, 0, &mut ctx.xer);
	// 82215C7C: F94101F8  std r10, 0x1f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(504 as u32), ctx.r[10].u64 ) };
	// 82215C80: C80101F8  lfd f0, 0x1f8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(504 as u32) ) };
	// 82215C84: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215C88: FDA00018  frsp f13, f0
	ctx.f[13].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215C8C: D1B50000  stfs f13, 0(r21)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82215C90: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215C94: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215C98: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215C9C: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215CA0: F9410208  std r10, 0x208(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(520 as u32), ctx.r[10].u64 ) };
	// 82215CA4: C8010208  lfd f0, 0x208(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(520 as u32) ) };
	// 82215CA8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215CAC: FD800018  frsp f12, f0
	ctx.f[12].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215CB0: D1950004  stfs f12, 4(r21)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215CB4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215CB8: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215CBC: F9610218  std r11, 0x218(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(536 as u32), ctx.r[11].u64 ) };
	// 82215CC0: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215CC4: C8010218  lfd f0, 0x218(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(536 as u32) ) };
	// 82215CC8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215CCC: FD600018  frsp f11, f0
	ctx.f[11].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215CD0: D1750008  stfs f11, 8(r21)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215CD4: A15E0000  lhz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215CD8: C0F5000C  lfs f7, 0xc(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82215CDC: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215CE0: F9410228  std r10, 0x228(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(552 as u32), ctx.r[10].u64 ) };
	// 82215CE4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215CE8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215CEC: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215CF0: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82215CF4: F9410238  std r10, 0x238(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(568 as u32), ctx.r[10].u64 ) };
	// 82215CF8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215CFC: 7D4B0734  extsh r11, r10
	ctx.r[11].s64 = ctx.r[10].s16 as i64;
	// 82215D00: F9610248  std r11, 0x248(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(584 as u32), ctx.r[11].u64 ) };
	// 82215D04: C8010228  lfd f0, 0x228(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(552 as u32) ) };
	// 82215D08: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215D0C: FD400018  frsp f10, f0
	ctx.f[10].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215D10: C8010238  lfd f0, 0x238(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(568 as u32) ) };
	// 82215D14: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215D18: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82215D1C: FD200018  frsp f9, f0
	ctx.f[9].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215D20: C8010248  lfd f0, 0x248(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(584 as u32) ) };
	// 82215D24: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215D28: D1210054  stfs f9, 0x54(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82215D2C: FD000018  frsp f8, f0
	ctx.f[8].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215D30: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82215D34: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82215D38: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82215D3C: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82215D40: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82215D44: ECE001F2  fmuls f7, f0, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[7].f64) as f32) as f64);
	// 82215D48: EC0A6FFA  fmadds f0, f10, f31, f13
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 82215D4C: EDA967FA  fmadds f13, f9, f31, f12
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82215D50: ED885FFA  fmadds f12, f8, f31, f11
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82215D54: ED7C3FFA  fmadds f11, f28, f31, f7
	ctx.f[11].f64 = (((ctx.f[28].f64 * ctx.f[31].f64 + ctx.f[7].f64) as f32) as f64);
	// 82215D58: D175000C  stfs f11, 0xc(r21)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82215D5C: 409A002C  bne cr6, 0x82215d88
	if !ctx.cr[6].eq {
	pc = 0x82215D88; continue 'dispatch;
	}
	// 82215D60: EC0006F2  fmuls f0, f0, f27
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215D64: D0150000  stfs f0, 0(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82215D68: EC0D06F2  fmuls f0, f13, f27
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215D6C: D0150004  stfs f0, 4(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215D70: EC0C06F2  fmuls f0, f12, f27
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[27].f64) as f32) as f64);
	// 82215D74: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215D78: D0150008  stfs f0, 8(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215D7C: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215D80: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215D84: 48000338  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215D88: EC0006B2  fmuls f0, f0, f26
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215D8C: D0150000  stfs f0, 0(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82215D90: EC0D06B2  fmuls f0, f13, f26
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215D94: D0150004  stfs f0, 4(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82215D98: EC0C06B2  fmuls f0, f12, f26
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[26].f64) as f32) as f64);
	// 82215D9C: 3BBDFFD0  addi r29, r29, -0x30
	ctx.r[29].s64 = ctx.r[29].s64 + -48;
	// 82215DA0: D0150008  stfs f0, 8(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82215DA4: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215DA8: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215DAC: 48000310  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215DB0 => {
    //   block [0x82215DB0..0x82215F24)
	// 82215DB0: 55EB063E  clrlwi r11, r15, 0x18
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0x000000FFu64;
	// 82215DB4: A39F0000  lhz r28, 0(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215DB8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82215DBC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82215DC0: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82215DC4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215DC8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215DCC: 3BEB0002  addi r31, r11, 2
	ctx.r[31].s64 = ctx.r[11].s64 + 2;
	// 82215DD0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215DD4: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215DD8: 7D2B0734  extsh r11, r9
	ctx.r[11].s64 = ctx.r[9].s16 as i64;
	// 82215DDC: 419A00E8  beq cr6, 0x82215ec4
	if ctx.cr[6].eq {
	pc = 0x82215EC4; continue 'dispatch;
	}
	// 82215DE0: F9410258  std r10, 0x258(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(600 as u32), ctx.r[10].u64 ) };
	// 82215DE4: F9610268  std r11, 0x268(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(616 as u32), ctx.r[11].u64 ) };
	// 82215DE8: C8010258  lfd f0, 0x258(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(600 as u32) ) };
	// 82215DEC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215DF0: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215DF4: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215DF8: C8010268  lfd f0, 0x268(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(616 as u32) ) };
	// 82215DFC: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215E00: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215E04: EC4005B2  fmuls f2, f0, f22
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215E08: 48151BA1  bl 0x823679a8
	ctx.lr = 0x82215E0C;
	sub_823679A8(ctx, base);
	// 82215E0C: 7F8B0734  extsh r11, r28
	ctx.r[11].s64 = ctx.r[28].s16 as i64;
	// 82215E10: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215E14: 386100F0  addi r3, r1, 0xf0
	ctx.r[3].s64 = ctx.r[1].s64 + 240;
	// 82215E18: F9610278  std r11, 0x278(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(632 as u32), ctx.r[11].u64 ) };
	// 82215E1C: C8010278  lfd f0, 0x278(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(632 as u32) ) };
	// 82215E20: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215E24: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215E28: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215E2C: 4815E46D  bl 0x82374298
	ctx.lr = 0x82215E30;
	sub_82374298(ctx, base);
	// 82215E30: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82215E34: A39E0000  lhz r28, 0(r30)
	ctx.r[28].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215E38: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82215E3C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215E40: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82215E44: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82215E48: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 82215E4C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215E50: F9410288  std r10, 0x288(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(648 as u32), ctx.r[10].u64 ) };
	// 82215E54: 7D2B0734  extsh r11, r9
	ctx.r[11].s64 = ctx.r[9].s16 as i64;
	// 82215E58: F9610298  std r11, 0x298(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(664 as u32), ctx.r[11].u64 ) };
	// 82215E5C: C8010288  lfd f0, 0x288(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(648 as u32) ) };
	// 82215E60: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215E64: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215E68: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215E6C: C8010298  lfd f0, 0x298(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(664 as u32) ) };
	// 82215E70: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215E74: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215E78: EC4005B2  fmuls f2, f0, f22
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215E7C: 48151B2D  bl 0x823679a8
	ctx.lr = 0x82215E80;
	sub_823679A8(ctx, base);
	// 82215E80: 7F8B0734  extsh r11, r28
	ctx.r[11].s64 = ctx.r[28].s16 as i64;
	// 82215E84: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215E88: 38610100  addi r3, r1, 0x100
	ctx.r[3].s64 = ctx.r[1].s64 + 256;
	// 82215E8C: F96102A8  std r11, 0x2a8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(680 as u32), ctx.r[11].u64 ) };
	// 82215E90: C80102A8  lfd f0, 0x2a8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(680 as u32) ) };
	// 82215E94: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215E98: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215E9C: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215EA0: 4815E3F9  bl 0x82374298
	ctx.lr = 0x82215EA4;
	sub_82374298(ctx, base);
	// 82215EA4: 38A10100  addi r5, r1, 0x100
	ctx.r[5].s64 = ctx.r[1].s64 + 256;
	// 82215EA8: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82215EAC: 388100F0  addi r4, r1, 0xf0
	ctx.r[4].s64 = ctx.r[1].s64 + 240;
	// 82215EB0: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82215EB4: 4815E8ED  bl 0x823747a0
	ctx.lr = 0x82215EB8;
	sub_823747A0(ctx, base);
	// 82215EB8: C381005C  lfs f28, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82215EBC: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215EC0: 480001FC  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
	// 82215EC4: F94102B8  std r10, 0x2b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(696 as u32), ctx.r[10].u64 ) };
	// 82215EC8: F96102C8  std r11, 0x2c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(712 as u32), ctx.r[11].u64 ) };
	// 82215ECC: C80102B8  lfd f0, 0x2b8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(696 as u32) ) };
	// 82215ED0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215ED4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215ED8: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215EDC: C80102C8  lfd f0, 0x2c8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(712 as u32) ) };
	// 82215EE0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215EE4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215EE8: EC4005B2  fmuls f2, f0, f22
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215EEC: 48151ABD  bl 0x823679a8
	ctx.lr = 0x82215EF0;
	sub_823679A8(ctx, base);
	// 82215EF0: 7F8B0734  extsh r11, r28
	ctx.r[11].s64 = ctx.r[28].s16 as i64;
	// 82215EF4: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82215EF8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82215EFC: F96102D8  std r11, 0x2d8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(728 as u32), ctx.r[11].u64 ) };
	// 82215F00: C80102D8  lfd f0, 0x2d8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(728 as u32) ) };
	// 82215F04: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82215F08: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82215F0C: EC2005B2  fmuls f1, f0, f22
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[22].f64) as f32) as f64);
	// 82215F10: 4815E389  bl 0x82374298
	ctx.lr = 0x82215F14;
	sub_82374298(ctx, base);
	// 82215F14: C381005C  lfs f28, 0x5c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82215F18: 3BDE0006  addi r30, r30, 6
	ctx.r[30].s64 = ctx.r[30].s64 + 6;
	// 82215F1C: 7F58C378  or r24, r26, r24
	ctx.r[24].u64 = ctx.r[26].u64 | ctx.r[24].u64;
	// 82215F20: 4800019C  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215F24 => {
    //   block [0x82215F24..0x82215F40)
	// 82215F24: 3BBDFFA0  addi r29, r29, -0x60
	ctx.r[29].s64 = ctx.r[29].s64 + -96;
	// 82215F28: 7B5AF082  rldicl r26, r26, 0x3e, 2
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000003u64;
	// 82215F2C: 3A94FFFE  addi r20, r20, -2
	ctx.r[20].s64 = ctx.r[20].s64 + -2;
	// 82215F30: 3B39FFE0  addi r25, r25, -0x20
	ctx.r[25].s64 = ctx.r[25].s64 + -32;
	// 82215F34: 7AF70FA4  sldi r23, r23, 1
	ctx.r[23].u64 = ctx.r[23].u64.wrapping_shl(1);
	ctx.r[23].u32 = ctx.r[23].u64 as u32;
	// 82215F38: 7A730FA4  sldi r19, r19, 1
	ctx.r[19].u64 = ctx.r[19].u64.wrapping_shl(1);
	ctx.r[19].u32 = ctx.r[19].u64 as u32;
	// 82215F3C: 48000180  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215F40 => {
    //   block [0x82215F40..0x82215F54)
	// 82215F40: 3B39FFF0  addi r25, r25, -0x10
	ctx.r[25].s64 = ctx.r[25].s64 + -16;
	// 82215F44: 7AF70FA4  sldi r23, r23, 1
	ctx.r[23].u64 = ctx.r[23].u64.wrapping_shl(1);
	ctx.r[23].u32 = ctx.r[23].u64 as u32;
	// 82215F48: 3A94FFFF  addi r20, r20, -1
	ctx.r[20].s64 = ctx.r[20].s64 + -1;
	// 82215F4C: 7B5AF842  rldicl r26, r26, 0x3f, 1
	ctx.r[26].u64 = ctx.r[26].u64 & 0x0000000000000001u64;
	// 82215F50: 4800016C  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82215F54 => {
    //   block [0x82215F54..0x82216070)
	// 82215F54: A13F0000  lhz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215F58: 395F0002  addi r10, r31, 2
	ctx.r[10].s64 = ctx.r[31].s64 + 2;
	// 82215F5C: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82215F60: 397D0020  addi r11, r29, 0x20
	ctx.r[11].s64 = ctx.r[29].s64 + 32;
	// 82215F64: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215F68: F92102E8  std r9, 0x2e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(744 as u32), ctx.r[9].u64 ) };
	// 82215F6C: C9A102E8  lfd f13, 0x2e8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(744 as u32) ) };
	// 82215F70: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82215F74: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82215F78: D1BD0020  stfs f13, 0x20(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82215F7C: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215F80: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215F84: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215F88: 3BEA0002  addi r31, r10, 2
	ctx.r[31].s64 = ctx.r[10].s64 + 2;
	// 82215F8C: F92102F8  std r9, 0x2f8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(760 as u32), ctx.r[9].u64 ) };
	// 82215F90: C9A102F8  lfd f13, 0x2f8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(760 as u32) ) };
	// 82215F94: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82215F98: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82215F9C: D1BD0024  stfs f13, 0x24(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82215FA0: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215FA4: 7D2A0734  extsh r10, r9
	ctx.r[10].s64 = ctx.r[9].s16 as i64;
	// 82215FA8: F9410308  std r10, 0x308(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(776 as u32), ctx.r[10].u64 ) };
	// 82215FAC: 395E0002  addi r10, r30, 2
	ctx.r[10].s64 = ctx.r[30].s64 + 2;
	// 82215FB0: C9A10308  lfd f13, 0x308(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(776 as u32) ) };
	// 82215FB4: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82215FB8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82215FBC: D1BD0028  stfs f13, 0x28(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82215FC0: A13E0000  lhz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215FC4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82215FC8: ED400372  fmuls f10, f0, f13
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82215FCC: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82215FD0: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215FD4: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82215FD8: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82215FDC: C12B000C  lfs f9, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82215FE0: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82215FE4: EC000272  fmuls f0, f0, f9
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 82215FE8: F9210318  std r9, 0x318(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(792 as u32), ctx.r[9].u64 ) };
	// 82215FEC: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82215FF0: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82215FF4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 82215FF8: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 82215FFC: F9210328  std r9, 0x328(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(808 as u32), ctx.r[9].u64 ) };
	// 82216000: EC1C07FA  fmadds f0, f28, f31, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 82216004: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82216008: 7D2A0734  extsh r10, r9
	ctx.r[10].s64 = ctx.r[9].s16 as i64;
	// 8221600C: F9410338  std r10, 0x338(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(824 as u32), ctx.r[10].u64 ) };
	// 82216010: EC000532  fmuls f0, f0, f20
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[20].f64) as f32) as f64);
	// 82216014: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216018: C9A10318  lfd f13, 0x318(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(792 as u32) ) };
	// 8221601C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82216020: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82216024: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82216028: EDAD57FA  fmadds f13, f13, f31, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 8221602C: EDAD0532  fmuls f13, f13, f20
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[20].f64) as f32) as f64);
	// 82216030: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216034: C9A10328  lfd f13, 0x328(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(808 as u32) ) };
	// 82216038: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221603C: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82216040: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82216044: EDAD67FA  fmadds f13, f13, f31, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 82216048: EDAD0532  fmuls f13, f13, f20
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[20].f64) as f32) as f64);
	// 8221604C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216050: C9A10338  lfd f13, 0x338(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(824 as u32) ) };
	// 82216054: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82216058: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8221605C: D1A10058  stfs f13, 0x58(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82216060: EDAD5FFA  fmadds f13, f13, f31, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 82216064: EDAD0532  fmuls f13, f13, f20
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[20].f64) as f32) as f64);
	// 82216068: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221606C: 48000050  b 0x822160bc
	pc = 0x822160BC; continue 'dispatch;
            }
            0x82216070 => {
    //   block [0x82216070..0x822160B4)
	// 82216070: A17E0000  lhz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82216074: EC1DF828  fsubs f0, f29, f31
	ctx.f[0].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 82216078: A15F0000  lhz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221607C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82216080: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 82216084: F9610348  std r11, 0x348(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(840 as u32), ctx.r[11].u64 ) };
	// 82216088: F9410358  std r10, 0x358(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(856 as u32), ctx.r[10].u64 ) };
	// 8221608C: C9A10348  lfd f13, 0x348(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(840 as u32) ) };
	// 82216090: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82216094: C9810358  lfd f12, 0x358(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(856 as u32) ) };
	// 82216098: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8221609C: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 822160A0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 822160A4: EDAD07F2  fmuls f13, f13, f31
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[31].f64) as f32) as f64);
	// 822160A8: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 822160AC: EC000532  fmuls f0, f0, f20
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[20].f64) as f32) as f64);
	// 822160B0: D01D0020  stfs f0, 0x20(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(32 as u32), tmp.u32 ) };
	pc = 0x822160B4; continue 'dispatch;
            }
            0x822160B4 => {
    //   block [0x822160B4..0x822160BC)
	// 822160B4: 3BFF0002  addi r31, r31, 2
	ctx.r[31].s64 = ctx.r[31].s64 + 2;
	// 822160B8: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	pc = 0x822160BC; continue 'dispatch;
            }
            0x822160BC => {
    //   block [0x822160BC..0x822160F4)
	// 822160BC: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 822160C0: 3BBD0030  addi r29, r29, 0x30
	ctx.r[29].s64 = ctx.r[29].s64 + 48;
	// 822160C4: 7AF7F842  rldicl r23, r23, 0x3f, 1
	ctx.r[23].u64 = ctx.r[23].u64 & 0x0000000000000001u64;
	// 822160C8: 7A73F842  rldicl r19, r19, 0x3f, 1
	ctx.r[19].u64 = ctx.r[19].u64 & 0x0000000000000001u64;
	// 822160CC: 3B390010  addi r25, r25, 0x10
	ctx.r[25].s64 = ctx.r[25].s64 + 16;
	// 822160D0: 3A310001  addi r17, r17, 1
	ctx.r[17].s64 = ctx.r[17].s64 + 1;
	// 822160D4: 7B5A0FA4  sldi r26, r26, 1
	ctx.r[26].u64 = ctx.r[26].u64.wrapping_shl(1);
	ctx.r[26].u32 = ctx.r[26].u64 as u32;
	// 822160D8: 2F140060  cmpwi cr6, r20, 0x60
	ctx.cr[6].compare_i32(ctx.r[20].s32, 96, &mut ctx.xer);
	// 822160DC: 4198E884  blt cr6, 0x82214960
	if ctx.cr[6].lt {
	pc = 0x82214960; continue 'dispatch;
	}
	// 822160E0: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 822160E4: 382104B0  addi r1, r1, 0x4b0
	ctx.r[1].s64 = ctx.r[1].s64 + 1200;
	// 822160E8: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 822160EC: 4831FF19  bl 0x82536004
	ctx.lr = 0x822160F0;
	sub_82535FFC(ctx, base);
	// 822160F0: 4831EFE0  b 0x825350d0
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822160F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x822160F8 size=864
    let mut pc: u32 = 0x822160F8;
    'dispatch: loop {
        match pc {
            0x822160F8 => {
    //   block [0x822160F8..0x82216458)
	// 822160F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822160FC: 4831EFB1  bl 0x825350ac
	ctx.lr = 0x82216100;
	sub_82535080(ctx, base);
	// 82216100: DBC1FFB0  stfd f30, -0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), ctx.f[30].u64 ) };
	// 82216104: DBE1FFB8  stfd f31, -0x48(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[31].u64 ) };
	// 82216108: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221610C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216110: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82216114: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 82216118: 3BDF07E0  addi r30, r31, 0x7e0
	ctx.r[30].s64 = ctx.r[31].s64 + 2016;
	// 8221611C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82216120: C3CB1FF8  lfs f30, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82216124: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 82216128: 387F0F48  addi r3, r31, 0xf48
	ctx.r[3].s64 = ctx.r[31].s64 + 3912;
	// 8221612C: 396B4634  addi r11, r11, 0x4634
	ctx.r[11].s64 = ctx.r[11].s64 + 17972;
	// 82216130: C3EABA38  lfs f31, -0x45c8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82216134: D3DE000C  stfs f30, 0xc(r30)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216138: D3FE00A8  stfs f31, 0xa8(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 8221613C: 93BE0004  stw r29, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82216140: D3FE00A4  stfs f31, 0xa4(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82216144: 93BE0008  stw r29, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82216148: D3FE00A0  stfs f31, 0xa0(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 8221614C: FBBE0010  std r29, 0x10(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), ctx.r[29].u64 ) };
	// 82216150: D3DE00BC  stfs f30, 0xbc(r30)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(188 as u32), tmp.u32 ) };
	// 82216154: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82216158: D3FE0158  stfs f31, 0x158(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(344 as u32), tmp.u32 ) };
	// 8221615C: 93BE00B4  stw r29, 0xb4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(180 as u32), ctx.r[29].u32 ) };
	// 82216160: D3FE0154  stfs f31, 0x154(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(340 as u32), tmp.u32 ) };
	// 82216164: 93BE00B8  stw r29, 0xb8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(184 as u32), ctx.r[29].u32 ) };
	// 82216168: D3FE0150  stfs f31, 0x150(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(336 as u32), tmp.u32 ) };
	// 8221616C: 917E00B0  stw r11, 0xb0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(176 as u32), ctx.r[11].u32 ) };
	// 82216170: D3DE016C  stfs f30, 0x16c(r30)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(364 as u32), tmp.u32 ) };
	// 82216174: FBBE00C0  std r29, 0xc0(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(192 as u32), ctx.r[29].u64 ) };
	// 82216178: D3FE0208  stfs f31, 0x208(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(520 as u32), tmp.u32 ) };
	// 8221617C: 93BE0164  stw r29, 0x164(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(356 as u32), ctx.r[29].u32 ) };
	// 82216180: D3FE0204  stfs f31, 0x204(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(516 as u32), tmp.u32 ) };
	// 82216184: 93BE0168  stw r29, 0x168(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(360 as u32), ctx.r[29].u32 ) };
	// 82216188: D3FE0200  stfs f31, 0x200(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(512 as u32), tmp.u32 ) };
	// 8221618C: 917E0160  stw r11, 0x160(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(352 as u32), ctx.r[11].u32 ) };
	// 82216190: D3DE021C  stfs f30, 0x21c(r30)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(540 as u32), tmp.u32 ) };
	// 82216194: FBBE0170  std r29, 0x170(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(368 as u32), ctx.r[29].u64 ) };
	// 82216198: D3FE02B8  stfs f31, 0x2b8(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(696 as u32), tmp.u32 ) };
	// 8221619C: 93BE0214  stw r29, 0x214(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(532 as u32), ctx.r[29].u32 ) };
	// 822161A0: D3FE02B4  stfs f31, 0x2b4(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(692 as u32), tmp.u32 ) };
	// 822161A4: 93BE0218  stw r29, 0x218(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(536 as u32), ctx.r[29].u32 ) };
	// 822161A8: D3FE02B0  stfs f31, 0x2b0(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(688 as u32), tmp.u32 ) };
	// 822161AC: 917E0210  stw r11, 0x210(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(528 as u32), ctx.r[11].u32 ) };
	// 822161B0: D3DE02CC  stfs f30, 0x2cc(r30)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(716 as u32), tmp.u32 ) };
	// 822161B4: FBBE0220  std r29, 0x220(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(544 as u32), ctx.r[29].u64 ) };
	// 822161B8: D3FE0368  stfs f31, 0x368(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(872 as u32), tmp.u32 ) };
	// 822161BC: 93BE02C4  stw r29, 0x2c4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(708 as u32), ctx.r[29].u32 ) };
	// 822161C0: D3FE0364  stfs f31, 0x364(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(868 as u32), tmp.u32 ) };
	// 822161C4: 93BE02C8  stw r29, 0x2c8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(712 as u32), ctx.r[29].u32 ) };
	// 822161C8: D3FE0360  stfs f31, 0x360(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(864 as u32), tmp.u32 ) };
	// 822161CC: 917E02C0  stw r11, 0x2c0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(704 as u32), ctx.r[11].u32 ) };
	// 822161D0: FBBE02D0  std r29, 0x2d0(r30)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[30].u32.wrapping_add(720 as u32), ctx.r[29].u64 ) };
	// 822161D4: D3DF0B5C  stfs f30, 0xb5c(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2908 as u32), tmp.u32 ) };
	// 822161D8: D3FF0BF8  stfs f31, 0xbf8(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3064 as u32), tmp.u32 ) };
	// 822161DC: 93BF0B54  stw r29, 0xb54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2900 as u32), ctx.r[29].u32 ) };
	// 822161E0: D3FF0BF4  stfs f31, 0xbf4(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3060 as u32), tmp.u32 ) };
	// 822161E4: 93BF0B58  stw r29, 0xb58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2904 as u32), ctx.r[29].u32 ) };
	// 822161E8: D3FF0BF0  stfs f31, 0xbf0(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3056 as u32), tmp.u32 ) };
	// 822161EC: 917F0B50  stw r11, 0xb50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2896 as u32), ctx.r[11].u32 ) };
	// 822161F0: FBBF0B60  std r29, 0xb60(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(2912 as u32), ctx.r[29].u64 ) };
	// 822161F4: D3DF0C38  stfs f30, 0xc38(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3128 as u32), tmp.u32 ) };
	// 822161F8: D3DF0C3C  stfs f30, 0xc3c(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3132 as u32), tmp.u32 ) };
	// 822161FC: B3BF0C32  sth r29, 0xc32(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(3122 as u32), ctx.r[29].u16 ) };
	// 82216200: D3DF0C40  stfs f30, 0xc40(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3136 as u32), tmp.u32 ) };
	// 82216204: B3BF0C30  sth r29, 0xc30(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(3120 as u32), ctx.r[29].u16 ) };
	// 82216208: D3DF0C44  stfs f30, 0xc44(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3140 as u32), tmp.u32 ) };
	// 8221620C: D3FF0C2C  stfs f31, 0xc2c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3116 as u32), tmp.u32 ) };
	// 82216210: 4BFFDBF9  bl 0x82213e08
	ctx.lr = 0x82216214;
	sub_82213E08(ctx, base);
	// 82216214: 3B200009  li r25, 9
	ctx.r[25].s64 = 9;
	// 82216218: 9BBF0C53  stb r29, 0xc53(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3155 as u32), ctx.r[29].u8 ) };
	// 8221621C: 3B600008  li r27, 8
	ctx.r[27].s64 = 8;
	// 82216220: 39600007  li r11, 7
	ctx.r[11].s64 = 7;
	// 82216224: 3B40000D  li r26, 0xd
	ctx.r[26].s64 = 13;
	// 82216228: 3860000C  li r3, 0xc
	ctx.r[3].s64 = 12;
	// 8221622C: 9B3F0C50  stb r25, 0xc50(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3152 as u32), ctx.r[25].u8 ) };
	// 82216230: 3880000B  li r4, 0xb
	ctx.r[4].s64 = 11;
	// 82216234: 9B7F0C51  stb r27, 0xc51(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3153 as u32), ctx.r[27].u8 ) };
	// 82216238: 38A00011  li r5, 0x11
	ctx.r[5].s64 = 17;
	// 8221623C: 997F0C52  stb r11, 0xc52(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3154 as u32), ctx.r[11].u8 ) };
	// 82216240: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 82216244: 9B5F0C80  stb r26, 0xc80(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3200 as u32), ctx.r[26].u8 ) };
	// 82216248: 38E0000F  li r7, 0xf
	ctx.r[7].s64 = 15;
	// 8221624C: 987F0C81  stb r3, 0xc81(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3201 as u32), ctx.r[3].u8 ) };
	// 82216250: 997F0D12  stb r11, 0xd12(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3346 as u32), ctx.r[11].u8 ) };
	// 82216254: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216258: 39000015  li r8, 0x15
	ctx.r[8].s64 = 21;
	// 8221625C: 9B7F0D11  stb r27, 0xd11(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3345 as u32), ctx.r[27].u8 ) };
	// 82216260: 3B800001  li r28, 1
	ctx.r[28].s64 = 1;
	// 82216264: 989F0C82  stb r4, 0xc82(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3202 as u32), ctx.r[4].u8 ) };
	// 82216268: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 8221626C: 98BF0CB0  stb r5, 0xcb0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3248 as u32), ctx.r[5].u8 ) };
	// 82216270: 39400013  li r10, 0x13
	ctx.r[10].s64 = 19;
	// 82216274: 987F0D41  stb r3, 0xd41(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3393 as u32), ctx.r[3].u8 ) };
	// 82216278: C00BD6C8  lfs f0, -0x2938(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221627C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216280: 991F0CE0  stb r8, 0xce0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3296 as u32), ctx.r[8].u8 ) };
	// 82216284: 3B7F03CC  addi r27, r31, 0x3cc
	ctx.r[27].s64 = ctx.r[31].s64 + 972;
	// 82216288: 991F0DA0  stb r8, 0xda0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3488 as u32), ctx.r[8].u8 ) };
	// 8221628C: 391F0F50  addi r8, r31, 0xf50
	ctx.r[8].s64 = ctx.r[31].s64 + 3920;
	// 82216290: 989F0D42  stb r4, 0xd42(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3394 as u32), ctx.r[4].u8 ) };
	// 82216294: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82216298: 98BF0D70  stb r5, 0xd70(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3440 as u32), ctx.r[5].u8 ) };
	// 8221629C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 822162A0: C1AB2450  lfs f13, 0x2450(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822162A4: 39600005  li r11, 5
	ctx.r[11].s64 = 5;
	// 822162A8: 38A003C0  li r5, 0x3c0
	ctx.r[5].s64 = 960;
	// 822162AC: 9BBF0C83  stb r29, 0xc83(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3203 as u32), ctx.r[29].u8 ) };
	// 822162B0: 98DF0CB1  stb r6, 0xcb1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3249 as u32), ctx.r[6].u8 ) };
	// 822162B4: 98FF0CB2  stb r7, 0xcb2(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3250 as u32), ctx.r[7].u8 ) };
	// 822162B8: 9B9F0CB3  stb r28, 0xcb3(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3251 as u32), ctx.r[28].u8 ) };
	// 822162BC: 993F0CE1  stb r9, 0xce1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3297 as u32), ctx.r[9].u8 ) };
	// 822162C0: 995F0CE2  stb r10, 0xce2(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3298 as u32), ctx.r[10].u8 ) };
	// 822162C4: 9B9F0CE3  stb r28, 0xce3(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3299 as u32), ctx.r[28].u8 ) };
	// 822162C8: 9B3F0D10  stb r25, 0xd10(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3344 as u32), ctx.r[25].u8 ) };
	// 822162CC: 9BBF0D13  stb r29, 0xd13(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3347 as u32), ctx.r[29].u8 ) };
	// 822162D0: 9B5F0D40  stb r26, 0xd40(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3392 as u32), ctx.r[26].u8 ) };
	// 822162D4: 9BBF0D43  stb r29, 0xd43(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3395 as u32), ctx.r[29].u8 ) };
	// 822162D8: 98DF0D71  stb r6, 0xd71(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3441 as u32), ctx.r[6].u8 ) };
	// 822162DC: 98FF0D72  stb r7, 0xd72(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3442 as u32), ctx.r[7].u8 ) };
	// 822162E0: 9B9F0D73  stb r28, 0xd73(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3443 as u32), ctx.r[28].u8 ) };
	// 822162E4: 993F0DA1  stb r9, 0xda1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3489 as u32), ctx.r[9].u8 ) };
	// 822162E8: 995F0DA2  stb r10, 0xda2(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3490 as u32), ctx.r[10].u8 ) };
	// 822162EC: 9B9F0DA3  stb r28, 0xda3(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(3491 as u32), ctx.r[28].u8 ) };
	// 822162F0: D01F0C24  stfs f0, 0xc24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3108 as u32), tmp.u32 ) };
	// 822162F4: D1BF0C28  stfs f13, 0xc28(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3112 as u32), tmp.u32 ) };
	// 822162F8: FBBF0F38  std r29, 0xf38(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(3896 as u32), ctx.r[29].u64 ) };
	// 822162FC: D3DF0C3C  stfs f30, 0xc3c(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3132 as u32), tmp.u32 ) };
	// 82216300: B17F0C30  sth r11, 0xc30(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(3120 as u32), ctx.r[11].u16 ) };
	// 82216304: D3DF0C44  stfs f30, 0xc44(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3140 as u32), tmp.u32 ) };
	// 82216308: 911F1130  stw r8, 0x1130(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4400 as u32), ctx.r[8].u32 ) };
	// 8221630C: 93FF0F48  stw r31, 0xf48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3912 as u32), ctx.r[31].u32 ) };
	// 82216310: 937F0F4C  stw r27, 0xf4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3916 as u32), ctx.r[27].u32 ) };
	// 82216314: 481AB24D  bl 0x823c1560
	ctx.lr = 0x82216318;
	sub_823C1560(ctx, base);
	// 82216318: 38A0000C  li r5, 0xc
	ctx.r[5].s64 = 12;
	// 8221631C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82216320: 387F03C0  addi r3, r31, 0x3c0
	ctx.r[3].s64 = ctx.r[31].s64 + 960;
	// 82216324: 481AB23D  bl 0x823c1560
	ctx.lr = 0x82216328;
	sub_823C1560(ctx, base);
	// 82216328: 38A000F8  li r5, 0xf8
	ctx.r[5].s64 = 248;
	// 8221632C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82216330: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82216334: 481AB22D  bl 0x823c1560
	ctx.lr = 0x82216338;
	sub_823C1560(ctx, base);
	// 82216338: D3DF04D0  stfs f30, 0x4d0(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1232 as u32), tmp.u32 ) };
	// 8221633C: D3DF04D4  stfs f30, 0x4d4(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1236 as u32), tmp.u32 ) };
	// 82216340: 38A00240  li r5, 0x240
	ctx.r[5].s64 = 576;
	// 82216344: D3DF04D8  stfs f30, 0x4d8(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1240 as u32), tmp.u32 ) };
	// 82216348: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8221634C: D3FF04DC  stfs f31, 0x4dc(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1244 as u32), tmp.u32 ) };
	// 82216350: 387F05A0  addi r3, r31, 0x5a0
	ctx.r[3].s64 = ctx.r[31].s64 + 1440;
	// 82216354: D3DF04E0  stfs f30, 0x4e0(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1248 as u32), tmp.u32 ) };
	// 82216358: D3DF04E4  stfs f30, 0x4e4(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1252 as u32), tmp.u32 ) };
	// 8221635C: D3DF04E8  stfs f30, 0x4e8(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1256 as u32), tmp.u32 ) };
	// 82216360: D3FF04EC  stfs f31, 0x4ec(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1260 as u32), tmp.u32 ) };
	// 82216364: D3DF0590  stfs f30, 0x590(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1424 as u32), tmp.u32 ) };
	// 82216368: D3DF0594  stfs f30, 0x594(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1428 as u32), tmp.u32 ) };
	// 8221636C: 481AB1F5  bl 0x823c1560
	ctx.lr = 0x82216370;
	sub_823C1560(ctx, base);
	// 82216370: 38A00009  li r5, 9
	ctx.r[5].s64 = 9;
	// 82216374: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82216378: 387F0C04  addi r3, r31, 0xc04
	ctx.r[3].s64 = ctx.r[31].s64 + 3076;
	// 8221637C: 481AB1E5  bl 0x823c1560
	ctx.lr = 0x82216380;
	sub_823C1560(ctx, base);
	// 82216380: 93BF0F44  stw r29, 0xf44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(3908 as u32), ctx.r[29].u32 ) };
	// 82216384: D3FF0500  stfs f31, 0x500(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1280 as u32), tmp.u32 ) };
	// 82216388: D3FF0504  stfs f31, 0x504(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1284 as u32), tmp.u32 ) };
	// 8221638C: D3FF0508  stfs f31, 0x508(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1288 as u32), tmp.u32 ) };
	// 82216390: D3FF050C  stfs f31, 0x50c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1292 as u32), tmp.u32 ) };
	// 82216394: D3FF0510  stfs f31, 0x510(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1296 as u32), tmp.u32 ) };
	// 82216398: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8221639C: D3FF0514  stfs f31, 0x514(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1300 as u32), tmp.u32 ) };
	// 822163A0: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 822163A4: D3FF0518  stfs f31, 0x518(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1304 as u32), tmp.u32 ) };
	// 822163A8: D3FF051C  stfs f31, 0x51c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1308 as u32), tmp.u32 ) };
	// 822163AC: D3FF0520  stfs f31, 0x520(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1312 as u32), tmp.u32 ) };
	// 822163B0: D3FF0524  stfs f31, 0x524(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1316 as u32), tmp.u32 ) };
	// 822163B4: D3FF0528  stfs f31, 0x528(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1320 as u32), tmp.u32 ) };
	// 822163B8: D3FF052C  stfs f31, 0x52c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1324 as u32), tmp.u32 ) };
	// 822163BC: D3FF0530  stfs f31, 0x530(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1328 as u32), tmp.u32 ) };
	// 822163C0: D3FF0534  stfs f31, 0x534(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1332 as u32), tmp.u32 ) };
	// 822163C4: D3FF0538  stfs f31, 0x538(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1336 as u32), tmp.u32 ) };
	// 822163C8: D3FF053C  stfs f31, 0x53c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1340 as u32), tmp.u32 ) };
	// 822163CC: D3FF0540  stfs f31, 0x540(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1344 as u32), tmp.u32 ) };
	// 822163D0: D3FF0544  stfs f31, 0x544(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1348 as u32), tmp.u32 ) };
	// 822163D4: D3FF0548  stfs f31, 0x548(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1352 as u32), tmp.u32 ) };
	// 822163D8: D3FF054C  stfs f31, 0x54c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1356 as u32), tmp.u32 ) };
	// 822163DC: D3FF0550  stfs f31, 0x550(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1360 as u32), tmp.u32 ) };
	// 822163E0: D3FF0554  stfs f31, 0x554(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1364 as u32), tmp.u32 ) };
	// 822163E4: D3FF0558  stfs f31, 0x558(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1368 as u32), tmp.u32 ) };
	// 822163E8: D3FF055C  stfs f31, 0x55c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1372 as u32), tmp.u32 ) };
	// 822163EC: D3FF0560  stfs f31, 0x560(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1376 as u32), tmp.u32 ) };
	// 822163F0: D3FF0564  stfs f31, 0x564(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1380 as u32), tmp.u32 ) };
	// 822163F4: D3FF0568  stfs f31, 0x568(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1384 as u32), tmp.u32 ) };
	// 822163F8: D3FF056C  stfs f31, 0x56c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1388 as u32), tmp.u32 ) };
	// 822163FC: D3FF0570  stfs f31, 0x570(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1392 as u32), tmp.u32 ) };
	// 82216400: D3FF0574  stfs f31, 0x574(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1396 as u32), tmp.u32 ) };
	// 82216404: D3FF0578  stfs f31, 0x578(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1400 as u32), tmp.u32 ) };
	// 82216408: D3FF057C  stfs f31, 0x57c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1404 as u32), tmp.u32 ) };
	// 8221640C: D3FF0580  stfs f31, 0x580(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1408 as u32), tmp.u32 ) };
	// 82216410: D3FF0584  stfs f31, 0x584(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1412 as u32), tmp.u32 ) };
	// 82216414: D3FF0588  stfs f31, 0x588(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1416 as u32), tmp.u32 ) };
	// 82216418: D3FF058C  stfs f31, 0x58c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1420 as u32), tmp.u32 ) };
	// 8221641C: 4800665D  bl 0x8221ca78
	ctx.lr = 0x82216420;
	sub_8221CA78(ctx, base);
	// 82216420: 578B003E  slwi r11, r28, 0
	ctx.r[11].u32 = ctx.r[28].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82216424: FC20F090  fmr f1, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82216428: 1D6B00B0  mulli r11, r11, 0xb0
	ctx.r[11].s64 = ctx.r[11].s64 * 176;
	// 8221642C: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82216430: 386B07E0  addi r3, r11, 0x7e0
	ctx.r[3].s64 = ctx.r[11].s64 + 2016;
	// 82216434: 48006645  bl 0x8221ca78
	ctx.lr = 0x82216438;
	sub_8221CA78(ctx, base);
	// 82216438: 3B9C0001  addi r28, r28, 1
	ctx.r[28].s64 = ctx.r[28].s64 + 1;
	// 8221643C: 2B3C0005  cmpldi cr6, r28, 5
	ctx.cr[6].compare_u64(ctx.r[28].u64, 5, &mut ctx.xer);
	// 82216440: 4198FFE0  blt cr6, 0x82216420
	if ctx.cr[6].lt {
	pc = 0x82216420; continue 'dispatch;
	}
	// 82216444: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82216448: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8221644C: CBC1FFB0  lfd f30, -0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-80 as u32) ) };
	// 82216450: CBE1FFB8  lfd f31, -0x48(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-72 as u32) ) };
	// 82216454: 4831ECA8  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216458(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216458 size=804
    let mut pc: u32 = 0x82216458;
    'dispatch: loop {
        match pc {
            0x82216458 => {
    //   block [0x82216458..0x8221677C)
	// 82216458: C00303C0  lfs f0, 0x3c0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(960 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221645C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82216460: EC010024  fdivs f0, f1, f0
	ctx.f[0].f64 = ((ctx.f[1].f64 / ctx.f[0].f64) as f32) as f64;
	// 82216464: 552A003E  slwi r10, r9, 0
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216468: 39290006  addi r9, r9, 6
	ctx.r[9].s64 = ctx.r[9].s64 + 6;
	// 8221646C: 554B2036  slwi r11, r10, 4
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82216470: 390A0002  addi r8, r10, 2
	ctx.r[8].s64 = ctx.r[10].s64 + 2;
	// 82216474: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82216478: 55062036  slwi r6, r8, 4
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221647C: 390A0003  addi r8, r10, 3
	ctx.r[8].s64 = ctx.r[10].s64 + 3;
	// 82216480: 38AA0004  addi r5, r10, 4
	ctx.r[5].s64 = ctx.r[10].s64 + 4;
	// 82216484: 55072036  slwi r7, r8, 4
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82216488: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221648C: 54A82036  slwi r8, r5, 4
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82216490: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216494: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82216498: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221649C: EDA002F2  fmuls f13, f0, f11
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 822164A0: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822164A4: 394A0005  addi r10, r10, 5
	ctx.r[10].s64 = ctx.r[10].s64 + 5;
	// 822164A8: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822164AC: 2B29000C  cmpldi cr6, r9, 0xc
	ctx.cr[6].compare_u64(ctx.r[9].u64, 12, &mut ctx.xer);
	// 822164B0: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822164B4: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822164B8: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822164BC: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 822164C0: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822164C4: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822164C8: C1AB0014  lfs f13, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822164CC: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822164D0: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822164D4: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822164D8: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822164DC: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822164E0: 7D661A14  add r11, r6, r3
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[3].u64;
	// 822164E4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822164E8: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822164EC: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822164F0: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822164F4: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822164F8: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822164FC: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216500: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216504: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216508: 7D671A14  add r11, r7, r3
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[3].u64;
	// 8221650C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216510: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216514: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216518: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221651C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216520: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216524: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216528: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221652C: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216530: 7D681A14  add r11, r8, r3
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[3].u64;
	// 82216534: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216538: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221653C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216540: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216544: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216548: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221654C: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216550: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216554: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216558: 7D6A1A14  add r11, r10, r3
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 8221655C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216560: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216564: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216568: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221656C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216570: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216574: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216578: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221657C: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216580: 4198FEE4  blt cr6, 0x82216464
	if ctx.cr[6].lt {
	pc = 0x82216464; continue 'dispatch;
	}
	// 82216584: C00303C4  lfs f0, 0x3c4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(964 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216588: 396300C0  addi r11, r3, 0xc0
	ctx.r[11].s64 = ctx.r[3].s64 + 192;
	// 8221658C: EC020024  fdivs f0, f2, f0
	ctx.f[0].f64 = ((ctx.f[2].f64 / ctx.f[0].f64) as f32) as f64;
	// 82216590: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216594: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82216598: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221659C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165A0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822165A4: EDAB0032  fmuls f13, f11, f0
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165A8: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822165AC: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165B0: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165B4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165B8: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822165BC: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822165C0: C1AB0014  lfs f13, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165C4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165C8: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822165CC: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165D0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165D4: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822165D8: C1A300E0  lfs f13, 0xe0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(224 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165DC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 822165E0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165E4: D1A300E0  stfs f13, 0xe0(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 822165E8: C1A300E4  lfs f13, 0xe4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(228 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165EC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165F0: D1A300E4  stfs f13, 0xe4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 822165F4: C1A300E8  lfs f13, 0xe8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(232 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822165F8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822165FC: D1A300E8  stfs f13, 0xe8(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 82216600: C1A300F0  lfs f13, 0xf0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(240 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216604: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216608: D1A300F0  stfs f13, 0xf0(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(240 as u32), tmp.u32 ) };
	// 8221660C: C1A300F4  lfs f13, 0xf4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(244 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216610: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216614: D1A300F4  stfs f13, 0xf4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(244 as u32), tmp.u32 ) };
	// 82216618: C1A300F8  lfs f13, 0xf8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(248 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221661C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216620: D1A300F8  stfs f13, 0xf8(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(248 as u32), tmp.u32 ) };
	// 82216624: C1A30100  lfs f13, 0x100(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(256 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216628: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221662C: D1A30100  stfs f13, 0x100(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 82216630: C1A30104  lfs f13, 0x104(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(260 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216634: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216638: D1A30104  stfs f13, 0x104(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 8221663C: C1A30108  lfs f13, 0x108(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(264 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216640: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216644: D1A30108  stfs f13, 0x108(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 82216648: C1A30110  lfs f13, 0x110(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(272 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221664C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216650: D1A30110  stfs f13, 0x110(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(272 as u32), tmp.u32 ) };
	// 82216654: C1A30114  lfs f13, 0x114(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(276 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216658: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221665C: D1A30114  stfs f13, 0x114(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(276 as u32), tmp.u32 ) };
	// 82216660: C1A30118  lfs f13, 0x118(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(280 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216664: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216668: D1A30118  stfs f13, 0x118(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(280 as u32), tmp.u32 ) };
	// 8221666C: C1A30120  lfs f13, 0x120(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(288 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216670: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216674: D1A30120  stfs f13, 0x120(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(288 as u32), tmp.u32 ) };
	// 82216678: C1A30124  lfs f13, 0x124(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(292 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221667C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216680: D1A30124  stfs f13, 0x124(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(292 as u32), tmp.u32 ) };
	// 82216684: C1A30128  lfs f13, 0x128(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216688: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221668C: D1A30128  stfs f13, 0x128(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 82216690: C1A30130  lfs f13, 0x130(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(304 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216694: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216698: D1A30130  stfs f13, 0x130(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 8221669C: C1A30134  lfs f13, 0x134(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(308 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822166A0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822166A4: D1A30134  stfs f13, 0x134(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(308 as u32), tmp.u32 ) };
	// 822166A8: C1A30138  lfs f13, 0x138(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(312 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822166AC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822166B0: D1A30138  stfs f13, 0x138(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(312 as u32), tmp.u32 ) };
	// 822166B4: C1A30140  lfs f13, 0x140(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(320 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822166B8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822166BC: D1A30140  stfs f13, 0x140(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(320 as u32), tmp.u32 ) };
	// 822166C0: C1A30144  lfs f13, 0x144(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(324 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822166C4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822166C8: D1A30144  stfs f13, 0x144(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(324 as u32), tmp.u32 ) };
	// 822166CC: 3D40820B  lis r10, -0x7df5
	ctx.r[10].s64 = -2113208320;
	// 822166D0: C1A30148  lfs f13, 0x148(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(328 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822166D4: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822166D8: 38EAAD50  addi r7, r10, -0x52b0
	ctx.r[7].s64 = ctx.r[10].s64 + -21168;
	// 822166DC: D0030148  stfs f0, 0x148(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(328 as u32), tmp.u32 ) };
	// 822166E0: 556A003E  slwi r10, r11, 0
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822166E4: 38C70001  addi r6, r7, 1
	ctx.r[6].s64 = ctx.r[7].s64 + 1;
	// 822166E8: 5548083C  slwi r8, r10, 1
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822166EC: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 822166F0: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 822166F4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 822166F8: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822166FC: 2B2B0008  cmpldi cr6, r11, 8
	ctx.cr[6].compare_u64(ctx.r[11].u64, 8, &mut ctx.xer);
	// 82216700: 7D0A1A14  add r8, r10, r3
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216704: 7D4938AE  lbzx r10, r9, r7
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 82216708: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 8221670C: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82216710: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216714: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216718: C1AA0008  lfs f13, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221671C: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216720: C00A0004  lfs f0, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216724: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82216728: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221672C: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82216730: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82216734: D0080C54  stfs f0, 0xc54(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(3156 as u32), tmp.u32 ) };
	// 82216738: 7D4930AE  lbzx r10, r9, r6
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 8221673C: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 82216740: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82216744: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216748: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 8221674C: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216750: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216754: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216758: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221675C: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82216760: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82216764: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82216768: D0080C58  stfs f0, 0xc58(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(3160 as u32), tmp.u32 ) };
	// 8221676C: 4198FF74  blt cr6, 0x822166e0
	if ctx.cr[6].lt {
	pc = 0x822166E0; continue 'dispatch;
	}
	// 82216770: D02303C0  stfs f1, 0x3c0(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(960 as u32), tmp.u32 ) };
	// 82216774: D04303C4  stfs f2, 0x3c4(r3)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(964 as u32), tmp.u32 ) };
	// 82216778: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216780(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216780 size=500
    let mut pc: u32 = 0x82216780;
    'dispatch: loop {
        match pc {
            0x82216780 => {
    //   block [0x82216780..0x82216974)
	// 82216780: C00303C8  lfs f0, 0x3c8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(968 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216784: 3920001E  li r9, 0x1e
	ctx.r[9].s64 = 30;
	// 82216788: EC010024  fdivs f0, f1, f0
	ctx.f[0].f64 = ((ctx.f[1].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221678C: 552A003E  slwi r10, r9, 0
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216790: 3929000A  addi r9, r9, 0xa
	ctx.r[9].s64 = ctx.r[9].s64 + 10;
	// 82216794: 554B2036  slwi r11, r10, 4
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82216798: 390A0002  addi r8, r10, 2
	ctx.r[8].s64 = ctx.r[10].s64 + 2;
	// 8221679C: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 822167A0: 55052036  slwi r5, r8, 4
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 822167A4: 390A0003  addi r8, r10, 3
	ctx.r[8].s64 = ctx.r[10].s64 + 3;
	// 822167A8: 38EA0004  addi r7, r10, 4
	ctx.r[7].s64 = ctx.r[10].s64 + 4;
	// 822167AC: 55062036  slwi r6, r8, 4
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 822167B0: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822167B4: 54E72036  slwi r7, r7, 4
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 822167B8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822167BC: C16B0008  lfs f11, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 822167C0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822167C4: EDA002F2  fmuls f13, f0, f11
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 822167C8: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822167CC: 390A0005  addi r8, r10, 5
	ctx.r[8].s64 = ctx.r[10].s64 + 5;
	// 822167D0: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822167D4: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 822167D8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822167DC: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822167E0: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 822167E4: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822167E8: 55082036  slwi r8, r8, 4
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822167EC: C1AB0014  lfs f13, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822167F0: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822167F4: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822167F8: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822167FC: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216800: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82216804: 7D651A14  add r11, r5, r3
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[3].u64;
	// 82216808: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221680C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216810: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216814: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216818: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221681C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216820: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216824: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216828: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221682C: 7D661A14  add r11, r6, r3
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[3].u64;
	// 82216830: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216834: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216838: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221683C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216840: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216844: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216848: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221684C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216850: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216854: 7D671A14  add r11, r7, r3
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[3].u64;
	// 82216858: 38EA0007  addi r7, r10, 7
	ctx.r[7].s64 = ctx.r[10].s64 + 7;
	// 8221685C: 54E72036  slwi r7, r7, 4
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82216860: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216864: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216868: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221686C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216870: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216874: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216878: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221687C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216880: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216884: 7D681A14  add r11, r8, r3
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[3].u64;
	// 82216888: 390A0006  addi r8, r10, 6
	ctx.r[8].s64 = ctx.r[10].s64 + 6;
	// 8221688C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216890: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216894: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216898: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221689C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822168A0: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822168A4: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822168A8: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822168AC: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822168B0: 550B2036  slwi r11, r8, 4
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822168B4: 390A0008  addi r8, r10, 8
	ctx.r[8].s64 = ctx.r[10].s64 + 8;
	// 822168B8: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 822168BC: 394A0009  addi r10, r10, 9
	ctx.r[10].s64 = ctx.r[10].s64 + 9;
	// 822168C0: 55082036  slwi r8, r8, 4
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 822168C4: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 822168C8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822168CC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822168D0: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822168D4: 2B29003B  cmpldi cr6, r9, 0x3b
	ctx.cr[6].compare_u64(ctx.r[9].u64, 59, &mut ctx.xer);
	// 822168D8: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822168DC: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822168E0: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822168E4: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822168E8: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 822168EC: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822168F0: 7D671A14  add r11, r7, r3
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[3].u64;
	// 822168F4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822168F8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822168FC: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216900: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216904: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216908: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221690C: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216910: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216914: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216918: 7D681A14  add r11, r8, r3
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[3].u64;
	// 8221691C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216920: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216924: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216928: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221692C: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216930: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216934: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216938: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221693C: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216940: 7D6A1A14  add r11, r10, r3
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216944: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216948: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221694C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216950: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216954: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216958: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221695C: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216960: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216964: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216968: 4099FE24  ble cr6, 0x8221678c
	if !ctx.cr[6].gt {
	pc = 0x8221678C; continue 'dispatch;
	}
	// 8221696C: D02303C8  stfs f1, 0x3c8(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(968 as u32), tmp.u32 ) };
	// 82216970: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216978 size=144
    let mut pc: u32 = 0x82216978;
    'dispatch: loop {
        match pc {
            0x82216978 => {
    //   block [0x82216978..0x82216A08)
	// 82216978: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8221697C: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 82216980: 40990268  ble cr6, 0x82216be8
	if !ctx.cr[6].gt {
		sub_82216BC8(ctx, base);
		return;
	}
	// 82216984: 3D40820A  lis r10, -0x7df6
	ctx.r[10].s64 = -2113273856;
	// 82216988: 7CA707B4  extsw r7, r5
	ctx.r[7].s64 = ctx.r[5].s32 as i64;
	// 8221698C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82216990: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 82216994: 2F270004  cmpdi cr6, r7, 4
	ctx.cr[6].compare_i64(ctx.r[7].s64, 4, &mut ctx.xer);
	// 82216998: C00ABA38  lfs f0, -0x45c8(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221699C: 419801C4  blt cr6, 0x82216b60
	if ctx.cr[6].lt {
		sub_82216B40(ctx, base);
		return;
	}
	// 822169A0: 3947FFFC  addi r10, r7, -4
	ctx.r[10].s64 = ctx.r[7].s64 + -4;
	// 822169A4: 794AF082  rldicl r10, r10, 0x3e, 2
	ctx.r[10].u64 = ctx.r[10].u64 & 0x0000000000000003u64;
	// 822169A8: 390A0001  addi r8, r10, 1
	ctx.r[8].s64 = ctx.r[10].s64 + 1;
	// 822169AC: 79061764  sldi r6, r8, 2
	ctx.r[6].u64 = ctx.r[8].u64.wrapping_shl(2);
	ctx.r[6].u32 = ctx.r[6].u64 as u32;
	// 822169B0: 894B004B  lbz r10, 0x4b(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(75 as u32) ) } as u64;
	// 822169B4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 822169B8: 419A000C  beq cr6, 0x822169c4
	if ctx.cr[6].eq {
	pc = 0x822169C4; continue 'dispatch;
	}
	// 822169BC: 2F0A0002  cmpwi cr6, r10, 2
	ctx.cr[6].compare_i32(ctx.r[10].s32, 2, &mut ctx.xer);
	// 822169C0: 409A0058  bne cr6, 0x82216a18
	if !ctx.cr[6].eq {
		sub_82216A08(ctx, base);
		return;
	}
	// 822169C4: A12B004E  lhz r9, 0x4e(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(78 as u32) ) } as u64;
	// 822169C8: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822169CC: 552A203E  rotlwi r10, r9, 4
	ctx.r[10].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 822169D0: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 822169D4: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822169D8: C1AB0014  lfs f13, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822169DC: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822169E0: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822169E4: D1AA0008  stfs f13, 8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822169E8: D00A000C  stfs f0, 0xc(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 822169EC: A14B004C  lhz r10, 0x4c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 822169F0: 2B0AFFFF  cmplwi cr6, r10, 0xffff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 65535 as u32, &mut ctx.xer);
	// 822169F4: 409A0014  bne cr6, 0x82216a08
	if !ctx.cr[6].eq {
		sub_82216A08(ctx, base);
		return;
	}
	// 822169F8: 394900F5  addi r10, r9, 0xf5
	ctx.r[10].s64 = ctx.r[9].s64 + 245;
	// 822169FC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216A00: 7CAA192E  stwx r5, r10, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), ctx.r[5].u32) };
	// 82216A04: 48000014  b 0x82216a18
	sub_82216A08(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216A08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216A08 size=104
    let mut pc: u32 = 0x82216A08;
    'dispatch: loop {
        match pc {
            0x82216A08 => {
    //   block [0x82216A08..0x82216A70)
	// 82216A08: 392900F5  addi r9, r9, 0xf5
	ctx.r[9].s64 = ctx.r[9].s64 + 245;
	// 82216A0C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82216A10: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216A14: 7D49192E  stwx r10, r9, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u32) };
	// 82216A18: 894B009B  lbz r10, 0x9b(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(155 as u32) ) } as u64;
	// 82216A1C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82216A20: 419A000C  beq cr6, 0x82216a2c
	if ctx.cr[6].eq {
	pc = 0x82216A2C; continue 'dispatch;
	}
	// 82216A24: 2F0A0002  cmpwi cr6, r10, 2
	ctx.cr[6].compare_i32(ctx.r[10].s32, 2, &mut ctx.xer);
	// 82216A28: 409A0058  bne cr6, 0x82216a80
	if !ctx.cr[6].eq {
		sub_82216A70(ctx, base);
		return;
	}
	// 82216A2C: A12B009E  lhz r9, 0x9e(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(158 as u32) ) } as u64;
	// 82216A30: C1AB0060  lfs f13, 0x60(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(96 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216A34: 552A203E  rotlwi r10, r9, 4
	ctx.r[10].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 82216A38: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216A3C: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216A40: C1AB0064  lfs f13, 0x64(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216A44: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216A48: C1AB0068  lfs f13, 0x68(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216A4C: D1AA0008  stfs f13, 8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216A50: D00A000C  stfs f0, 0xc(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216A54: A14B009C  lhz r10, 0x9c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(156 as u32) ) } as u64;
	// 82216A58: 2B0AFFFF  cmplwi cr6, r10, 0xffff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 65535 as u32, &mut ctx.xer);
	// 82216A5C: 409A0014  bne cr6, 0x82216a70
	if !ctx.cr[6].eq {
		sub_82216A70(ctx, base);
		return;
	}
	// 82216A60: 394900F5  addi r10, r9, 0xf5
	ctx.r[10].s64 = ctx.r[9].s64 + 245;
	// 82216A64: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216A68: 7CAA192E  stwx r5, r10, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), ctx.r[5].u32) };
	// 82216A6C: 48000014  b 0x82216a80
	sub_82216A70(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216A70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216A70 size=104
    let mut pc: u32 = 0x82216A70;
    'dispatch: loop {
        match pc {
            0x82216A70 => {
    //   block [0x82216A70..0x82216AD8)
	// 82216A70: 392900F5  addi r9, r9, 0xf5
	ctx.r[9].s64 = ctx.r[9].s64 + 245;
	// 82216A74: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82216A78: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216A7C: 7D49192E  stwx r10, r9, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u32) };
	// 82216A80: 894B00EB  lbz r10, 0xeb(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(235 as u32) ) } as u64;
	// 82216A84: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82216A88: 419A000C  beq cr6, 0x82216a94
	if ctx.cr[6].eq {
	pc = 0x82216A94; continue 'dispatch;
	}
	// 82216A8C: 2F0A0002  cmpwi cr6, r10, 2
	ctx.cr[6].compare_i32(ctx.r[10].s32, 2, &mut ctx.xer);
	// 82216A90: 409A0058  bne cr6, 0x82216ae8
	if !ctx.cr[6].eq {
		sub_82216AD8(ctx, base);
		return;
	}
	// 82216A94: A12B00EE  lhz r9, 0xee(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(238 as u32) ) } as u64;
	// 82216A98: C1AB00B0  lfs f13, 0xb0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(176 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216A9C: 552A203E  rotlwi r10, r9, 4
	ctx.r[10].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 82216AA0: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216AA4: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216AA8: C1AB00B4  lfs f13, 0xb4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(180 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216AAC: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216AB0: C1AB00B8  lfs f13, 0xb8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(184 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216AB4: D1AA0008  stfs f13, 8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216AB8: D00A000C  stfs f0, 0xc(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216ABC: A14B00EC  lhz r10, 0xec(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(236 as u32) ) } as u64;
	// 82216AC0: 2B0AFFFF  cmplwi cr6, r10, 0xffff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 65535 as u32, &mut ctx.xer);
	// 82216AC4: 409A0014  bne cr6, 0x82216ad8
	if !ctx.cr[6].eq {
		sub_82216AD8(ctx, base);
		return;
	}
	// 82216AC8: 394900F5  addi r10, r9, 0xf5
	ctx.r[10].s64 = ctx.r[9].s64 + 245;
	// 82216ACC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216AD0: 7CAA192E  stwx r5, r10, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), ctx.r[5].u32) };
	// 82216AD4: 48000014  b 0x82216ae8
	sub_82216AD8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216AD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216AD8 size=104
    let mut pc: u32 = 0x82216AD8;
    'dispatch: loop {
        match pc {
            0x82216AD8 => {
    //   block [0x82216AD8..0x82216B40)
	// 82216AD8: 392900F5  addi r9, r9, 0xf5
	ctx.r[9].s64 = ctx.r[9].s64 + 245;
	// 82216ADC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82216AE0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216AE4: 7D49192E  stwx r10, r9, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u32) };
	// 82216AE8: 894B013B  lbz r10, 0x13b(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(315 as u32) ) } as u64;
	// 82216AEC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82216AF0: 419A000C  beq cr6, 0x82216afc
	if ctx.cr[6].eq {
	pc = 0x82216AFC; continue 'dispatch;
	}
	// 82216AF4: 2F0A0002  cmpwi cr6, r10, 2
	ctx.cr[6].compare_i32(ctx.r[10].s32, 2, &mut ctx.xer);
	// 82216AF8: 409A0058  bne cr6, 0x82216b50
	if !ctx.cr[6].eq {
		sub_82216B40(ctx, base);
		return;
	}
	// 82216AFC: A12B013E  lhz r9, 0x13e(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(318 as u32) ) } as u64;
	// 82216B00: C1AB0100  lfs f13, 0x100(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(256 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216B04: 552A203E  rotlwi r10, r9, 4
	ctx.r[10].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 82216B08: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216B0C: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216B10: C1AB0104  lfs f13, 0x104(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(260 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216B14: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216B18: C1AB0108  lfs f13, 0x108(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(264 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216B1C: D1AA0008  stfs f13, 8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216B20: D00A000C  stfs f0, 0xc(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216B24: A14B013C  lhz r10, 0x13c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(316 as u32) ) } as u64;
	// 82216B28: 2B0AFFFF  cmplwi cr6, r10, 0xffff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 65535 as u32, &mut ctx.xer);
	// 82216B2C: 409A0014  bne cr6, 0x82216b40
	if !ctx.cr[6].eq {
		sub_82216B40(ctx, base);
		return;
	}
	// 82216B30: 394900F5  addi r10, r9, 0xf5
	ctx.r[10].s64 = ctx.r[9].s64 + 245;
	// 82216B34: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216B38: 7CAA192E  stwx r5, r10, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), ctx.r[5].u32) };
	// 82216B3C: 48000014  b 0x82216b50
	sub_82216B40(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216B40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216B40 size=136
    let mut pc: u32 = 0x82216B40;
    'dispatch: loop {
        match pc {
            0x82216B40 => {
    //   block [0x82216B40..0x82216BC8)
	// 82216B40: 392900F5  addi r9, r9, 0xf5
	ctx.r[9].s64 = ctx.r[9].s64 + 245;
	// 82216B44: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82216B48: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216B4C: 7D49192E  stwx r10, r9, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u32) };
	// 82216B50: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82216B54: 396B0140  addi r11, r11, 0x140
	ctx.r[11].s64 = ctx.r[11].s64 + 320;
	// 82216B58: 2B280000  cmpldi cr6, r8, 0
	ctx.cr[6].compare_u64(ctx.r[8].u64, 0, &mut ctx.xer);
	// 82216B5C: 4199FE54  bgt cr6, 0x822169b0
	if ctx.cr[6].gt {
		sub_82216978(ctx, base);
		return;
	}
	// 82216B60: 7F263840  cmpld cr6, r6, r7
	ctx.cr[6].compare_u64(ctx.r[6].u64, ctx.r[7].u64, &mut ctx.xer);
	// 82216B64: 40980084  bge cr6, 0x82216be8
	if !ctx.cr[6].lt {
		sub_82216BC8(ctx, base);
		return;
	}
	// 82216B68: 396B004E  addi r11, r11, 0x4e
	ctx.r[11].s64 = ctx.r[11].s64 + 78;
	// 82216B6C: 7D063850  subf r8, r6, r7
	ctx.r[8].s64 = ctx.r[7].s64 - ctx.r[6].s64;
	// 82216B70: 894BFFFD  lbz r10, -3(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(-3 as u32) ) } as u64;
	// 82216B74: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82216B78: 419A000C  beq cr6, 0x82216b84
	if ctx.cr[6].eq {
	pc = 0x82216B84; continue 'dispatch;
	}
	// 82216B7C: 2F0A0002  cmpwi cr6, r10, 2
	ctx.cr[6].compare_i32(ctx.r[10].s32, 2, &mut ctx.xer);
	// 82216B80: 409A0058  bne cr6, 0x82216bd8
	if !ctx.cr[6].eq {
		sub_82216BC8(ctx, base);
		return;
	}
	// 82216B84: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82216B88: C1ABFFC2  lfs f13, -0x3e(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-62 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216B8C: 552A203E  rotlwi r10, r9, 4
	ctx.r[10].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 82216B90: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216B94: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216B98: C1ABFFC6  lfs f13, -0x3a(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-58 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216B9C: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216BA0: C1ABFFCA  lfs f13, -0x36(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-54 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216BA4: D1AA0008  stfs f13, 8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216BA8: D00A000C  stfs f0, 0xc(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216BAC: A14BFFFE  lhz r10, -2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(-2 as u32) ) } as u64;
	// 82216BB0: 2B0AFFFF  cmplwi cr6, r10, 0xffff
	ctx.cr[6].compare_u32(ctx.r[10].u32, 65535 as u32, &mut ctx.xer);
	// 82216BB4: 409A0014  bne cr6, 0x82216bc8
	if !ctx.cr[6].eq {
		sub_82216BC8(ctx, base);
		return;
	}
	// 82216BB8: 394900F5  addi r10, r9, 0xf5
	ctx.r[10].s64 = ctx.r[9].s64 + 245;
	// 82216BBC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216BC0: 7CAA192E  stwx r5, r10, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), ctx.r[5].u32) };
	// 82216BC4: 48000014  b 0x82216bd8
	sub_82216BC8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216BC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82216BC8 size=268
    let mut pc: u32 = 0x82216BC8;
    'dispatch: loop {
        match pc {
            0x82216BC8 => {
    //   block [0x82216BC8..0x82216CD4)
	// 82216BC8: 392900F5  addi r9, r9, 0xf5
	ctx.r[9].s64 = ctx.r[9].s64 + 245;
	// 82216BCC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82216BD0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216BD4: 7D49192E  stwx r10, r9, r3
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u32) };
	// 82216BD8: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82216BDC: 396B0050  addi r11, r11, 0x50
	ctx.r[11].s64 = ctx.r[11].s64 + 80;
	// 82216BE0: 2B280000  cmpldi cr6, r8, 0
	ctx.cr[6].compare_u64(ctx.r[8].u64, 0, &mut ctx.xer);
	// 82216BE4: 4199FF8C  bgt cr6, 0x82216b70
	if ctx.cr[6].gt {
		sub_82216B40(ctx, base);
		return;
	}
	// 82216BE8: 3940FFFF  li r10, -1
	ctx.r[10].s64 = -1;
	// 82216BEC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82216BF0: 914303CC  stw r10, 0x3cc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(972 as u32), ctx.r[10].u32 ) };
	// 82216BF4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82216BF8: 914303D0  stw r10, 0x3d0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(976 as u32), ctx.r[10].u32 ) };
	// 82216BFC: 3D40820B  lis r10, -0x7df5
	ctx.r[10].s64 = -2113208320;
	// 82216C00: 38EAAD50  addi r7, r10, -0x52b0
	ctx.r[7].s64 = ctx.r[10].s64 + -21168;
	// 82216C04: 556A003E  slwi r10, r11, 0
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216C08: 38C70001  addi r6, r7, 1
	ctx.r[6].s64 = ctx.r[7].s64 + 1;
	// 82216C0C: 5548083C  slwi r8, r10, 1
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82216C10: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82216C14: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82216C18: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82216C1C: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216C20: 2B2B0008  cmpldi cr6, r11, 8
	ctx.cr[6].compare_u64(ctx.r[11].u64, 8, &mut ctx.xer);
	// 82216C24: 7D0A1A14  add r8, r10, r3
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216C28: 7D4938AE  lbzx r10, r9, r7
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 82216C2C: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 82216C30: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82216C34: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216C38: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216C3C: C1AA0004  lfs f13, 4(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216C40: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216C44: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216C48: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82216C4C: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82216C50: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82216C54: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82216C58: D0080C54  stfs f0, 0xc54(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(3156 as u32), tmp.u32 ) };
	// 82216C5C: 7D4930AE  lbzx r10, r9, r6
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 82216C60: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 82216C64: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82216C68: 554A2036  slwi r10, r10, 4
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82216C6C: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82216C70: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216C74: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82216C78: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216C7C: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82216C80: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82216C84: EC0C033A  fmadds f0, f12, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82216C88: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 82216C8C: D0080C58  stfs f0, 0xc58(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(3160 as u32), tmp.u32 ) };
	// 82216C90: 4198FF74  blt cr6, 0x82216c04
	if ctx.cr[6].lt {
	pc = 0x82216C04; continue 'dispatch;
	}
	// 82216C94: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216C98: C1A30010  lfs f13, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82216C9C: C18300D0  lfs f12, 0xd0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(208 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82216CA0: C16302D0  lfs f11, 0x2d0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(720 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82216CA4: C00B2394  lfs f0, 0x2394(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9108 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216CA8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216CAC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216CB0: D1A303C0  stfs f13, 0x3c0(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(960 as u32), tmp.u32 ) };
	// 82216CB4: C00B2390  lfs f0, 0x2390(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9104 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216CB8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216CBC: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216CC0: D18303C4  stfs f12, 0x3c4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(964 as u32), tmp.u32 ) };
	// 82216CC4: C00B238C  lfs f0, 0x238c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9100 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82216CC8: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82216CCC: D00303C8  stfs f0, 0x3c8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(968 as u32), tmp.u32 ) };
	// 82216CD0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216CD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82216CD8 size=204
    let mut pc: u32 = 0x82216CD8;
    'dispatch: loop {
        match pc {
            0x82216CD8 => {
    //   block [0x82216CD8..0x82216DA4)
	// 82216CD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82216CDC: 4831E3E1  bl 0x825350bc
	ctx.lr = 0x82216CE0;
	sub_82535080(ctx, base);
	// 82216CE0: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 82216CE4: 4831F305  bl 0x82535fe8
	ctx.lr = 0x82216CE8;
	sub_82535FB0(ctx, base);
	// 82216CE8: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82216CEC: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82216CF0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82216CF4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82216CF8: C05E0014  lfs f2, 0x14(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82216CFC: C03E0018  lfs f1, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82216D00: 4831C1A9  bl 0x82532ea8
	ctx.lr = 0x82216D04;
	sub_82532EA8(ctx, base);
	// 82216D04: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 82216D08: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82216D0C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82216D10: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82216D14: C3EBBA38  lfs f31, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82216D18: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216D1C: D3E10050  stfs f31, 0x50(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82216D20: D3E1005C  stfs f31, 0x5c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82216D24: C3CB1FF8  lfs f30, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82216D28: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82216D2C: D3C10054  stfs f30, 0x54(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82216D30: D3C10058  stfs f30, 0x58(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82216D34: C3AB2254  lfs f29, 0x2254(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8788 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82216D38: EF800772  fmuls f28, f0, f29
	ctx.f[28].f64 = (((ctx.f[0].f64 * ctx.f[29].f64) as f32) as f64);
	// 82216D3C: FC20E050  fneg f1, f28
	ctx.f[1].u64 = ctx.f[28].u64 ^ 0x8000_0000_0000_0000u64;
	// 82216D40: 4815D4D9  bl 0x82374218
	ctx.lr = 0x82216D44;
	sub_82374218(ctx, base);
	// 82216D44: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82216D48: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82216D4C: 481517ED  bl 0x82368538
	ctx.lr = 0x82216D50;
	sub_82368538(ctx, base);
	// 82216D50: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82216D54: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 82216D58: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82216D5C: 48151095  bl 0x82367df0
	ctx.lr = 0x82216D60;
	sub_82367DF0(ctx, base);
	// 82216D60: C0410084  lfs f2, 0x84(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82216D64: C0210080  lfs f1, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82216D68: 4831C141  bl 0x82532ea8
	ctx.lr = 0x82216D6C;
	sub_82532EA8(ctx, base);
	// 82216D6C: FC000890  fmr f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = ctx.f[1].f64;
	// 82216D70: D3DF0000  stfs f30, 0(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216D74: D3DF0004  stfs f30, 4(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82216D78: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 82216D7C: D3FF0008  stfs f31, 8(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82216D80: D3FF000C  stfs f31, 0xc(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82216D84: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82216D88: EC000772  fmuls f0, f0, f29
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[29].f64) as f32) as f64);
	// 82216D8C: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 82216D90: D01D0000  stfs f0, 0(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82216D94: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 82216D98: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 82216D9C: 4831F299  bl 0x82536034
	ctx.lr = 0x82216DA0;
	sub_82535FFC(ctx, base);
	// 82216DA0: 4831E36C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82216DA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82216DA8 size=3588
    let mut pc: u32 = 0x82216DA8;
    'dispatch: loop {
        match pc {
            0x82216DA8 => {
    //   block [0x82216DA8..0x82217BAC)
	// 82216DA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82216DAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82216DB0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82216DB4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82216DB8: 3981FFE8  addi r12, r1, -0x18
	ctx.r[12].s64 = ctx.r[1].s64 + -24;
	// 82216DBC: 4831F211  bl 0x82535fcc
	ctx.lr = 0x82216DC0;
	sub_82535FB0(ctx, base);
	// 82216DC0: 3980FF70  li r12, -0x90
	ctx.r[12].s64 = -144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82217BB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82217BB0 size=1904
    let mut pc: u32 = 0x82217BB0;
    'dispatch: loop {
        match pc {
            0x82217BB0 => {
    //   block [0x82217BB0..0x82218320)
	// 82217BB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82217BB4: 4831D4FD  bl 0x825350b0
	ctx.lr = 0x82217BB8;
	sub_82535080(ctx, base);
	// 82217BB8: 3981FFC8  addi r12, r1, -0x38
	ctx.r[12].s64 = ctx.r[1].s64 + -56;
	// 82217BBC: 4831E421  bl 0x82535fdc
	ctx.lr = 0x82217BC0;
	sub_82535FB0(ctx, base);
	// 82217BC0: 9421FE60  stwu r1, -0x1a0(r1)
	ea = ctx.r[1].u32.wrapping_add(-416 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82217BC4: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82217BC8: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 82217BCC: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 82217BD0: 390B0C50  addi r8, r11, 0xc50
	ctx.r[8].s64 = ctx.r[11].s64 + 3152;
	// 82217BD4: 481500B5  bl 0x82367c88
	ctx.lr = 0x82217BD8;
	sub_82367C88(ctx, base);
	// 82217BD8: 38610110  addi r3, r1, 0x110
	ctx.r[3].s64 = ctx.r[1].s64 + 272;
	// 82217BDC: 8361007C  lwz r27, 0x7c(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 82217BE0: 3C80820A  lis r4, -0x7df6
	ctx.r[4].s64 = -2113273856;
	// 82217BE4: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 82217BE8: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 82217BEC: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82218320(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82218320 size=404
    let mut pc: u32 = 0x82218320;
    'dispatch: loop {
        match pc {
            0x82218320 => {
    //   block [0x82218320..0x822184B4)
	// 82218320: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82218324: 4831CD85  bl 0x825350a8
	ctx.lr = 0x82218328;
	sub_82535080(ctx, base);
	// 82218328: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221832C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82218330: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82218334: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82218338: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 8221833C: 7D194378  mr r25, r8
	ctx.r[25].u64 = ctx.r[8].u64;
	// 82218340: 7D384B78  mr r24, r9
	ctx.r[24].u64 = ctx.r[9].u64;
	// 82218344: 2F060000  cmpwi cr6, r6, 0
	ctx.cr[6].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82218348: 419800AC  blt cr6, 0x822183f4
	if ctx.cr[6].lt {
	pc = 0x822183F4; continue 'dispatch;
	}
	// 8221834C: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 82218350: 419800A4  blt cr6, 0x822183f4
	if ctx.cr[6].lt {
	pc = 0x822183F4; continue 'dispatch;
	}
	// 82218354: 7F06D000  cmpw cr6, r6, r26
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[26].s32, &mut ctx.xer);
	// 82218358: 4099009C  ble cr6, 0x822183f4
	if !ctx.cr[6].gt {
	pc = 0x822183F4; continue 'dispatch;
	}
	// 8221835C: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 82218360: 3B8BADD0  addi r28, r11, -0x5230
	ctx.r[28].s64 = ctx.r[11].s64 + -21040;
	// 82218364: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 82218368: 3BCB64B0  addi r30, r11, 0x64b0
	ctx.r[30].s64 = ctx.r[11].s64 + 25776;
	// 8221836C: 54CB083C  slwi r11, r6, 1
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82218370: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82218374: 7D665A14  add r11, r6, r11
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 82218378: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221837C: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82218380: 7C8BDA14  add r4, r11, r27
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 82218384: 4BFFBB55  bl 0x82213ed8
	ctx.lr = 0x82218388;
	sub_82213ED8(ctx, base);
	// 82218388: 2F060007  cmpwi cr6, r6, 7
	ctx.cr[6].compare_i32(ctx.r[6].s32, 7, &mut ctx.xer);
	// 8221838C: 419A000C  beq cr6, 0x82218398
	if ctx.cr[6].eq {
	pc = 0x82218398; continue 'dispatch;
	}
	// 82218390: 2F06000B  cmpwi cr6, r6, 0xb
	ctx.cr[6].compare_i32(ctx.r[6].s32, 11, &mut ctx.xer);
	// 82218394: 409A0108  bne cr6, 0x8221849c
	if !ctx.cr[6].eq {
	pc = 0x8221849C; continue 'dispatch;
	}
	// 82218398: 817D0C00  lwz r11, 0xc00(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(3072 as u32) ) } as u64;
	// 8221839C: C01D03C0  lfs f0, 0x3c0(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(960 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822183A0: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 822183A4: 409A008C  bne cr6, 0x82218430
	if !ctx.cr[6].eq {
	pc = 0x82218430; continue 'dispatch;
	}
	// 822183A8: 2F060007  cmpwi cr6, r6, 7
	ctx.cr[6].compare_i32(ctx.r[6].s32, 7, &mut ctx.xer);
	// 822183AC: 409A0050  bne cr6, 0x822183fc
	if !ctx.cr[6].eq {
	pc = 0x822183FC; continue 'dispatch;
	}
	// 822183B0: C1BE0000  lfs f13, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822183B4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822183B8: C1BE0004  lfs f13, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822183BC: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822183C0: C1BE0008  lfs f13, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822183C4: ED4D0032  fmuls f10, f13, f0
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822183C8: C1BE000C  lfs f13, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 822183CC: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 822183D0: D19F0010  stfs f12, 0x10(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822183D4: D17F0014  stfs f11, 0x14(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822183D8: D15F0018  stfs f10, 0x18(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 822183DC: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 822183E0: 396600F3  addi r11, r6, 0xf3
	ctx.r[11].s64 = ctx.r[6].s64 + 243;
	// 822183E4: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822183E8: 7CCBE82E  lwzx r6, r11, r29
	ctx.r[6].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 822183EC: 7F06D000  cmpw cr6, r6, r26
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[26].s32, &mut ctx.xer);
	// 822183F0: 4199FF7C  bgt cr6, 0x8221836c
	if ctx.cr[6].gt {
	pc = 0x8221836C; continue 'dispatch;
	}
	// 822183F4: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 822183F8: 4831CD00  b 0x825350f8
	sub_825350D0(ctx, base);
	return;
	// 822183FC: C1BE0010  lfs f13, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82218400: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82218404: C1BE0014  lfs f13, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82218408: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221840C: C1BE0018  lfs f13, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82218410: ED4D0032  fmuls f10, f13, f0
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82218414: C1BE001C  lfs f13, 0x1c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82218418: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221841C: D19F0010  stfs f12, 0x10(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82218420: D17F0014  stfs f11, 0x14(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82218424: D15F0018  stfs f10, 0x18(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82218428: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8221842C: 48000070  b 0x8221849c
	pc = 0x8221849C; continue 'dispatch;
	// 82218430: 2F180000  cmpwi cr6, r24, 0
	ctx.cr[6].compare_i32(ctx.r[24].s32, 0, &mut ctx.xer);
	// 82218434: 419A0068  beq cr6, 0x8221849c
	if ctx.cr[6].eq {
	pc = 0x8221849C; continue 'dispatch;
	}
	// 82218438: 3966FFFE  addi r11, r6, -2
	ctx.r[11].s64 = ctx.r[6].s64 + -2;
	// 8221843C: 393F0010  addi r9, r31, 0x10
	ctx.r[9].s64 = ctx.r[31].s64 + 16;
	// 82218440: 556A2036  slwi r10, r11, 4
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82218444: 7D6AE214  add r11, r10, r28
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[28].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822184B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x822184B8 size=9388
    let mut pc: u32 = 0x822184B8;
    'dispatch: loop {
        match pc {
            0x822184B8 => {
    //   block [0x822184B8..0x8221A964)
	// 822184B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 822184BC: 4831CBC5  bl 0x82535080
	ctx.lr = 0x822184C0;
	sub_82535080(ctx, base);
	// 822184C0: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 822184C4: 4831DAED  bl 0x82535fb0
	ctx.lr = 0x822184C8;
	sub_82535FB0(ctx, base);
	// 822184C8: 3BE1FC20  addi r31, r1, -0x3e0
	ctx.r[31].s64 = ctx.r[1].s64 + -992;
	// 822184CC: 9421FC20  stwu r1, -0x3e0(r1)
	ea = ctx.r[1].u32.wrapping_add(-992 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 822184D0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 822184D4: 90BF0404  stw r5, 0x404(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1028 as u32), ctx.r[5].u32 ) };
	// 822184D8: 3980CAA0  li r12, -0x3560
	ctx.r[12].s64 = -13664;
	// 822184DC: 397D07E0  addi r11, r29, 0x7e0
	ctx.r[11].s64 = ctx.r[29].s64 + 2016;
	// 822184E0: 917F0100  stw r11, 0x100(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(256 as u32), ctx.r[11].u32 ) };
	// 822184E4: 483C9DE1  bl 0x825e22c4
	ctx.lr = 0x822184E8;
	sub_825E22C4(ctx, base);
	// 822184E8: 81610000  lwz r11, 0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(0 as u32) ) } as u64;
	// 822184EC: 548A067E  clrlwi r10, r4, 0x19
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x0000007Fu64;
	// 822184F0: 909F0054  stw r4, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[4].u32 ) };
	// 822184F4: 7D61616E  stwux r11, r1, r12
	ea = ctx.r[1].u32.wrapping_add(ctx.r[12].u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[11].u32) };
	ctx.r[1].u32 = ea;
	// 822184F8: 915F005C  stw r10, 0x5c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(92 as u32), ctx.r[10].u32 ) };
	// 822184FC: 39400006  li r10, 6
	ctx.r[10].s64 = 6;
	// 82218500: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 82218504: 396B007F  addi r11, r11, 0x7f
	ctx.r[11].s64 = ctx.r[11].s64 + 127;
	// 82218508: F95F00B8  std r10, 0xb8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), ctx.r[10].u64 ) };
	// 8221850C: 556A0030  rlwinm r10, r11, 0, 0, 0x18
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82218510: 915F0060  stw r10, 0x60(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 82218514: 915F0050  stw r10, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82218518: 7C0057EC  dcbz 0, r10
	ea.u32 = ctx.r[10].u32;
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221851C: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 82218520: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218524: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218528: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 8221852C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218530: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218534: 39400180  li r10, 0x180
	ctx.r[10].s64 = 384;
	// 82218538: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221853C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218540: 39400200  li r10, 0x200
	ctx.r[10].s64 = 512;
	// 82218544: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218548: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221854C: 39400280  li r10, 0x280
	ctx.r[10].s64 = 640;
	// 82218550: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218554: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218558: 39400300  li r10, 0x300
	ctx.r[10].s64 = 768;
	// 8221855C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218560: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218564: 39400380  li r10, 0x380
	ctx.r[10].s64 = 896;
	// 82218568: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221856C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218570: 39400400  li r10, 0x400
	ctx.r[10].s64 = 1024;
	// 82218574: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218578: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221857C: 39400480  li r10, 0x480
	ctx.r[10].s64 = 1152;
	// 82218580: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218584: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218588: 39400500  li r10, 0x500
	ctx.r[10].s64 = 1280;
	// 8221858C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218590: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218594: 39400580  li r10, 0x580
	ctx.r[10].s64 = 1408;
	// 82218598: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221859C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822185A0: 39400600  li r10, 0x600
	ctx.r[10].s64 = 1536;
	// 822185A4: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822185A8: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822185AC: 39400680  li r10, 0x680
	ctx.r[10].s64 = 1664;
	// 822185B0: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822185B4: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822185B8: 39400700  li r10, 0x700
	ctx.r[10].s64 = 1792;
	// 822185BC: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822185C0: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822185C4: 39400780  li r10, 0x780
	ctx.r[10].s64 = 1920;
	// 822185C8: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822185CC: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822185D0: E97F00B8  ld r11, 0xb8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(184 as u32) ) };
	// 822185D4: 815F0050  lwz r10, 0x50(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822185D8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 822185DC: 394A0800  addi r10, r10, 0x800
	ctx.r[10].s64 = ctx.r[10].s64 + 2048;
	// 822185E0: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 822185E4: F97F00B8  std r11, 0xb8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), ctx.r[11].u64 ) };
	// 822185E8: 915F0050  stw r10, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 822185EC: 409AFF2C  bne cr6, 0x82218518
	if !ctx.cr[6].eq {
	pc = 0x82218518; continue 'dispatch;
	}
	// 822185F0: 817F005C  lwz r11, 0x5c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(92 as u32) ) } as u64;
	// 822185F4: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 822185F8: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 822185FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82218600: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218604: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 82218608: 409A00C4  bne cr6, 0x822186cc
	if !ctx.cr[6].eq {
	pc = 0x822186CC; continue 'dispatch;
	}
	// 8221860C: 7C005FEC  dcbz 0, r11
	ea.u32 = ctx.r[11].u32;
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218610: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 82218614: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218618: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221861C: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 82218620: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218624: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218628: 39400180  li r10, 0x180
	ctx.r[10].s64 = 384;
	// 8221862C: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218630: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218634: 39400200  li r10, 0x200
	ctx.r[10].s64 = 512;
	// 82218638: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8221863C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218640: 39400280  li r10, 0x280
	ctx.r[10].s64 = 640;
	// 82218644: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218648: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221864C: 39400300  li r10, 0x300
	ctx.r[10].s64 = 768;
	// 82218650: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218654: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218658: 39400380  li r10, 0x380
	ctx.r[10].s64 = 896;
	// 8221865C: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218660: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218664: 39400400  li r10, 0x400
	ctx.r[10].s64 = 1024;
	// 82218668: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8221866C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218670: 39400480  li r10, 0x480
	ctx.r[10].s64 = 1152;
	// 82218674: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218678: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221867C: 39400500  li r10, 0x500
	ctx.r[10].s64 = 1280;
	// 82218680: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218684: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218688: 39400580  li r10, 0x580
	ctx.r[10].s64 = 1408;
	// 8221868C: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218690: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218694: 39400600  li r10, 0x600
	ctx.r[10].s64 = 1536;
	// 82218698: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8221869C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186A0: 39400680  li r10, 0x680
	ctx.r[10].s64 = 1664;
	// 822186A4: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 822186A8: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186AC: 39400700  li r10, 0x700
	ctx.r[10].s64 = 1792;
	// 822186B0: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 822186B4: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186B8: 39400780  li r10, 0x780
	ctx.r[10].s64 = 1920;
	// 822186BC: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 822186C0: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186C4: 829F0054  lwz r20, 0x54(r31)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 822186C8: 48000104  b 0x822187cc
	pc = 0x822187CC; continue 'dispatch;
	// 822186CC: 394007F0  li r10, 0x7f0
	ctx.r[10].s64 = 2032;
	// 822186D0: 7C0A5A2C  dcbt r10, r11
	// 822186D4: 396B007F  addi r11, r11, 0x7f
	ctx.r[11].s64 = ctx.r[11].s64 + 127;
	// 822186D8: 556B0030  rlwinm r11, r11, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 822186DC: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 822186E0: 7C005FEC  dcbz 0, r11
	ea.u32 = ctx.r[11].u32;
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186E4: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 822186E8: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822186EC: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186F0: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 822186F4: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 822186F8: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 822186FC: 39400180  li r10, 0x180
	ctx.r[10].s64 = 384;
	// 82218700: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218704: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218708: 39400200  li r10, 0x200
	ctx.r[10].s64 = 512;
	// 8221870C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218710: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218714: 39400280  li r10, 0x280
	ctx.r[10].s64 = 640;
	// 82218718: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221871C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218720: 39400300  li r10, 0x300
	ctx.r[10].s64 = 768;
	// 82218724: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218728: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221872C: 39400380  li r10, 0x380
	ctx.r[10].s64 = 896;
	// 82218730: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218734: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218738: 39400400  li r10, 0x400
	ctx.r[10].s64 = 1024;
	// 8221873C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218740: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218744: 39400480  li r10, 0x480
	ctx.r[10].s64 = 1152;
	// 82218748: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221874C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218750: 39400500  li r10, 0x500
	ctx.r[10].s64 = 1280;
	// 82218754: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218758: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221875C: 39400580  li r10, 0x580
	ctx.r[10].s64 = 1408;
	// 82218760: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218764: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218768: 39400600  li r10, 0x600
	ctx.r[10].s64 = 1536;
	// 8221876C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218770: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218774: 39400680  li r10, 0x680
	ctx.r[10].s64 = 1664;
	// 82218778: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221877C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 82218780: 39400700  li r10, 0x700
	ctx.r[10].s64 = 1792;
	// 82218784: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82218788: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221878C: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 82218790: 829F0054  lwz r20, 0x54(r31)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82218794: 815F005C  lwz r10, 0x5c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(92 as u32) ) } as u64;
	// 82218798: 397407C0  addi r11, r20, 0x7c0
	ctx.r[11].s64 = ctx.r[20].s64 + 1984;
	// 8221879C: 2B0A0040  cmplwi cr6, r10, 0x40
	ctx.cr[6].compare_u32(ctx.r[10].u32, 64 as u32, &mut ctx.xer);
	// 822187A0: 40990018  ble cr6, 0x822187b8
	if !ctx.cr[6].gt {
	pc = 0x822187B8; continue 'dispatch;
	}
	// 822187A4: 394BFFC0  addi r10, r11, -0x40
	ctx.r[10].s64 = ctx.r[11].s64 + -64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221A968(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221A968 size=1744
    let mut pc: u32 = 0x8221A968;
    'dispatch: loop {
        match pc {
            0x8221A968 => {
    //   block [0x8221A968..0x8221B038)
	// 8221A968: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221A96C: 4831A74D  bl 0x825350b8
	ctx.lr = 0x8221A970;
	sub_82535080(ctx, base);
	// 8221A970: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 8221A974: 4831B659  bl 0x82535fcc
	ctx.lr = 0x8221A978;
	sub_82535FB0(ctx, base);
	// 8221A978: 9421F710  stwu r1, -0x8f0(r1)
	ea = ctx.r[1].u32.wrapping_add(-2288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221A97C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8221A980: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8221A984: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8221A988: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8221A98C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8221A990: 419A01F0  beq cr6, 0x8221ab80
	if ctx.cr[6].eq {
	pc = 0x8221AB80; continue 'dispatch;
	}
	// 8221A994: EB9E0F38  ld r28, 0xf38(r30)
	ctx.r[28].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(3896 as u32) ) };
	// 8221A998: 2B3C0000  cmpldi cr6, r28, 0
	ctx.cr[6].compare_u64(ctx.r[28].u64, 0, &mut ctx.xer);
	// 8221A99C: 419A01E4  beq cr6, 0x8221ab80
	if ctx.cr[6].eq {
	pc = 0x8221AB80; continue 'dispatch;
	}
	// 8221A9A0: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8221A9A4: 38A00800  li r5, 0x800
	ctx.r[5].s64 = 2048;
	// 8221A9A8: 4831A1A9  bl 0x82534b50
	ctx.lr = 0x8221A9AC;
	sub_82534B50(ctx, base);
	// 8221A9AC: 39400017  li r10, 0x17
	ctx.r[10].s64 = 23;
	// 8221A9B0: 554B3032  slwi r11, r10, 6
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221A9B4: 7C8BFA14  add r4, r11, r31
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 8221A9B8: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8221A9BC: 4814E00D  bl 0x823689c8
	ctx.lr = 0x8221A9C0;
	sub_823689C8(ctx, base);
	// 8221A9C0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8221A9C4: 2B2A001F  cmpldi cr6, r10, 0x1f
	ctx.cr[6].compare_u64(ctx.r[10].u64, 31, &mut ctx.xer);
	// 8221A9C8: 4099FFE8  ble cr6, 0x8221a9b0
	if !ctx.cr[6].gt {
	pc = 0x8221A9B0; continue 'dispatch;
	}
	// 8221A9CC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8221A9D0: 554B3032  slwi r11, r10, 6
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221A9D4: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 8221A9D8: 7C8B4A14  add r4, r11, r9
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8221A9DC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8221A9E0: 4814DFE9  bl 0x823689c8
	ctx.lr = 0x8221A9E4;
	sub_823689C8(ctx, base);
	// 8221A9E4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8221A9E8: 2B2A0020  cmpldi cr6, r10, 0x20
	ctx.cr[6].compare_u64(ctx.r[10].u64, 32, &mut ctx.xer);
	// 8221A9EC: 4198FFE4  blt cr6, 0x8221a9d0
	if ctx.cr[6].lt {
	pc = 0x8221A9D0; continue 'dispatch;
	}
	// 8221A9F0: 7B8B07E0  clrldi r11, r28, 0x3f
	ctx.r[11].u64 = ctx.r[28].u64 & 0x0000000000000001u64;
	// 8221A9F4: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221A9F8: 419A0134  beq cr6, 0x8221ab2c
	if ctx.cr[6].eq {
	pc = 0x8221AB2C; continue 'dispatch;
	}
	// 8221A9FC: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8221AA00: C3FD0000  lfs f31, 0(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221AA04: C1BF0008  lfs f13, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AA08: C01F0004  lfs f0, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221AA0C: C1410078  lfs f10, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AA10: C1610074  lfs f11, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AA14: C3ABBA38  lfs f29, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221AA18: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221AA1C: EFDDF828  fsubs f30, f29, f31
	ctx.f[30].f64 = (((ctx.f[29].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221AA20: C19F0000  lfs f12, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AA24: C1210070  lfs f9, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221AA28: EDAD07B2  fmuls f13, f13, f30
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[30].f64) as f32) as f64);
	// 8221AA2C: EC0007B2  fmuls f0, f0, f30
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[30].f64) as f32) as f64);
	// 8221AA30: ED9E0332  fmuls f12, f30, f12
	ctx.f[12].f64 = (((ctx.f[30].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AA34: EDAA6FFA  fmadds f13, f10, f31, f13
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221AA38: EC0B07FA  fmadds f0, f11, f31, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221AA3C: ED8967FA  fmadds f12, f9, f31, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221AA40: EDAD0372  fmuls f13, f13, f13
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AA44: EC00683A  fmadds f0, f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221AA48: EDAC033A  fmadds f13, f12, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221AA4C: C00B2910  lfs f0, 0x2910(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10512 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221AA50: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8221AA54: 41980060  blt cr6, 0x8221aab4
	if ctx.cr[6].lt {
	pc = 0x8221AAB4; continue 'dispatch;
	}
	// 8221AA58: C19F0018  lfs f12, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AA5C: ED9E0332  fmuls f12, f30, f12
	ctx.f[12].f64 = (((ctx.f[30].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AA60: C1BF0014  lfs f13, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AA64: C1210088  lfs f9, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221AA68: EDAD07B2  fmuls f13, f13, f30
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[30].f64) as f32) as f64);
	// 8221AA6C: C17F0010  lfs f11, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AA70: C1410084  lfs f10, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AA74: ED7E02F2  fmuls f11, f30, f11
	ctx.f[11].f64 = (((ctx.f[30].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AA78: C1010080  lfs f8, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221AA7C: ED8967FA  fmadds f12, f9, f31, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221AA80: EDAA6FFA  fmadds f13, f10, f31, f13
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221AA84: ED685FFA  fmadds f11, f8, f31, f11
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 8221AA88: ED8C0332  fmuls f12, f12, f12
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AA8C: EDAD637A  fmadds f13, f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221AA90: EDAB6AFA  fmadds f13, f11, f11, f13
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221AA94: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8221AA98: 4198001C  blt cr6, 0x8221aab4
	if ctx.cr[6].lt {
	pc = 0x8221AAB4; continue 'dispatch;
	}
	// 8221AA9C: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 8221AAA0: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 8221AAA4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221AAA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221AAAC: 4814D84D  bl 0x823682f8
	ctx.lr = 0x8221AAB0;
	sub_823682F8(ctx, base);
	// 8221AAB0: 4800007C  b 0x8221ab2c
	pc = 0x8221AB2C; continue 'dispatch;
	// 8221AAB4: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 8221AAB8: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8221AABC: 481598E5  bl 0x823743a0
	ctx.lr = 0x8221AAC0;
	sub_823743A0(ctx, base);
	// 8221AAC0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8221AAC4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221AAC8: 481598D9  bl 0x823743a0
	ctx.lr = 0x8221AACC;
	sub_823743A0(ctx, base);
	// 8221AACC: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8221AAD0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221AAD4: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 8221AAD8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221AADC: 48159CC5  bl 0x823747a0
	ctx.lr = 0x8221AAE0;
	sub_823747A0(ctx, base);
	// 8221AAE0: C01F0030  lfs f0, 0x30(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221AAE4: C1BF0034  lfs f13, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AAE8: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AAEC: C19F0038  lfs f12, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AAF0: EDAD07B2  fmuls f13, f13, f30
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[30].f64) as f32) as f64);
	// 8221AAF4: ED9E0332  fmuls f12, f30, f12
	ctx.f[12].f64 = (((ctx.f[30].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AAF8: C16100A0  lfs f11, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AAFC: C14100A4  lfs f10, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AB00: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221AB04: C12100A8  lfs f9, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221AB08: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221AB0C: EFCB07FA  fmadds f30, f11, f31, f0
	ctx.f[30].f64 = (((ctx.f[11].f64 * ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221AB10: EF8A6FFA  fmadds f28, f10, f31, f13
	ctx.f[28].f64 = (((ctx.f[10].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221AB14: EFE967FA  fmadds f31, f9, f31, f12
	ctx.f[31].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221AB18: 4814DA21  bl 0x82368538
	ctx.lr = 0x8221AB1C;
	sub_82368538(ctx, base);
	// 8221AB1C: D3DF0030  stfs f30, 0x30(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221AB20: D39F0034  stfs f28, 0x34(r31)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221AB24: D3FF0038  stfs f31, 0x38(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221AB28: D3BF003C  stfs f29, 0x3c(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221AB2C: 389F0040  addi r4, r31, 0x40
	ctx.r[4].s64 = ctx.r[31].s64 + 64;
	// 8221AB30: 396100B0  addi r11, r1, 0xb0
	ctx.r[11].s64 = ctx.r[1].s64 + 176;
	// 8221AB34: 393D0004  addi r9, r29, 4
	ctx.r[9].s64 = ctx.r[29].s64 + 4;
	// 8221AB38: 7B87F842  rldicl r7, r28, 0x3f, 1
	ctx.r[7].u64 = ctx.r[28].u64 & 0x0000000000000001u64;
	// 8221AB3C: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 8221AB40: 7CC45850  subf r6, r4, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 8221AB44: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 8221AB48: 419A0038  beq cr6, 0x8221ab80
	if ctx.cr[6].eq {
	pc = 0x8221AB80; continue 'dispatch;
	}
	// 8221AB4C: 78EB07E0  clrldi r11, r7, 0x3f
	ctx.r[11].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221AB50: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221AB54: 419A0014  beq cr6, 0x8221ab68
	if ctx.cr[6].eq {
	pc = 0x8221AB68; continue 'dispatch;
	}
	// 8221AB58: 7CA62214  add r5, r6, r4
	ctx.r[5].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 8221AB5C: C0290000  lfs f1, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221AB60: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8221AB64: 4814D795  bl 0x823682f8
	ctx.lr = 0x8221AB68;
	sub_823682F8(ctx, base);
	// 8221AB68: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8221AB6C: 38840040  addi r4, r4, 0x40
	ctx.r[4].s64 = ctx.r[4].s64 + 64;
	// 8221AB70: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8221AB74: 78E7F842  rldicl r7, r7, 0x3f, 1
	ctx.r[7].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221AB78: 2B280020  cmpldi cr6, r8, 0x20
	ctx.cr[6].compare_u64(ctx.r[8].u64, 32, &mut ctx.xer);
	// 8221AB7C: 4198FFC8  blt cr6, 0x8221ab44
	if ctx.cr[6].lt {
	pc = 0x8221AB44; continue 'dispatch;
	}
	// 8221AB80: C01E03C4  lfs f0, 0x3c4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(964 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221AB84: C1BE0500  lfs f13, 0x500(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1280 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AB88: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AB8C: C19E0504  lfs f12, 0x504(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1284 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AB90: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AB94: C15F05C0  lfs f10, 0x5c0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1472 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AB98: C17E0508  lfs f11, 0x508(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1288 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AB9C: C13F05C4  lfs f9, 0x5c4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1476 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221ABA0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ABA4: C11F05C8  lfs f8, 0x5c8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1480 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221ABA8: C0FF05D0  lfs f7, 0x5d0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1488 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221ABAC: C0DF05D4  lfs f6, 0x5d4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1492 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221ABB0: C0BF05D8  lfs f5, 0x5d8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1496 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8221ABB4: C09F05E0  lfs f4, 0x5e0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1504 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221ABB8: C07F05E4  lfs f3, 0x5e4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1508 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221ABBC: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ABC0: D15F05C0  stfs f10, 0x5c0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1472 as u32), tmp.u32 ) };
	// 8221ABC4: ED490372  fmuls f10, f9, f13
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ABC8: C05F05E8  lfs f2, 0x5e8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1512 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221ABCC: EDA80372  fmuls f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ABD0: D1BF05C8  stfs f13, 0x5c8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1480 as u32), tmp.u32 ) };
	// 8221ABD4: EDA70332  fmuls f13, f7, f12
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ABD8: D1BF05D0  stfs f13, 0x5d0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1488 as u32), tmp.u32 ) };
	// 8221ABDC: EDA60332  fmuls f13, f6, f12
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ABE0: D1BF05D4  stfs f13, 0x5d4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1492 as u32), tmp.u32 ) };
	// 8221ABE4: EDA50332  fmuls f13, f5, f12
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ABE8: D1BF05D8  stfs f13, 0x5d8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1496 as u32), tmp.u32 ) };
	// 8221ABEC: EDA402F2  fmuls f13, f4, f11
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221ABF0: D1BF05E0  stfs f13, 0x5e0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1504 as u32), tmp.u32 ) };
	// 8221ABF4: EDA302F2  fmuls f13, f3, f11
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221ABF8: D1BF05E4  stfs f13, 0x5e4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1508 as u32), tmp.u32 ) };
	// 8221ABFC: C03E0510  lfs f1, 0x510(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1296 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221AC00: EDA202F2  fmuls f13, f2, f11
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AC04: D1BF05E8  stfs f13, 0x5e8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1512 as u32), tmp.u32 ) };
	// 8221AC08: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC0C: C3FE0514  lfs f31, 0x514(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1300 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221AC10: ED9F0032  fmuls f12, f31, f0
	ctx.f[12].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC14: C3DE0518  lfs f30, 0x518(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1304 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221AC18: C3BF0600  lfs f29, 0x600(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1536 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221AC1C: ED7E0032  fmuls f11, f30, f0
	ctx.f[11].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC20: D15F05C4  stfs f10, 0x5c4(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1476 as u32), tmp.u32 ) };
	// 8221AC24: C39F0604  lfs f28, 0x604(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1540 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8221AC28: C37F0608  lfs f27, 0x608(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1544 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8221AC2C: C35F0610  lfs f26, 0x610(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1552 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8221AC30: C33F0614  lfs f25, 0x614(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1556 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8221AC34: C31F0618  lfs f24, 0x618(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1560 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8221AC38: ED5D0372  fmuls f10, f29, f13
	ctx.f[10].f64 = (((ctx.f[29].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AC3C: D15F0600  stfs f10, 0x600(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1536 as u32), tmp.u32 ) };
	// 8221AC40: ED5C0372  fmuls f10, f28, f13
	ctx.f[10].f64 = (((ctx.f[28].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AC44: C2FF0620  lfs f23, 0x620(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1568 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8221AC48: EDBB0372  fmuls f13, f27, f13
	ctx.f[13].f64 = (((ctx.f[27].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AC4C: D1BF0608  stfs f13, 0x608(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1544 as u32), tmp.u32 ) };
	// 8221AC50: EDBA0332  fmuls f13, f26, f12
	ctx.f[13].f64 = (((ctx.f[26].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AC54: D1BF0610  stfs f13, 0x610(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1552 as u32), tmp.u32 ) };
	// 8221AC58: EDB90332  fmuls f13, f25, f12
	ctx.f[13].f64 = (((ctx.f[25].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AC5C: D1BF0614  stfs f13, 0x614(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1556 as u32), tmp.u32 ) };
	// 8221AC60: EDB80332  fmuls f13, f24, f12
	ctx.f[13].f64 = (((ctx.f[24].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AC64: D1BF0618  stfs f13, 0x618(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1560 as u32), tmp.u32 ) };
	// 8221AC68: EDB702F2  fmuls f13, f23, f11
	ctx.f[13].f64 = (((ctx.f[23].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AC6C: D1BF0620  stfs f13, 0x620(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1568 as u32), tmp.u32 ) };
	// 8221AC70: C1BF0628  lfs f13, 0x628(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1576 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AC74: C2DF0624  lfs f22, 0x624(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1572 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8221AC78: ED2D02F2  fmuls f9, f13, f11
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AC7C: D15F0604  stfs f10, 0x604(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1540 as u32), tmp.u32 ) };
	// 8221AC80: ED5602F2  fmuls f10, f22, f11
	ctx.f[10].f64 = (((ctx.f[22].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AC84: C19E0520  lfs f12, 0x520(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1312 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AC88: C17E0524  lfs f11, 0x524(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1316 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AC8C: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC90: C11E0528  lfs f8, 0x528(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1320 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221AC94: ED8B0032  fmuls f12, f11, f0
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC98: ED680032  fmuls f11, f8, f0
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AC9C: C0FF0644  lfs f7, 0x644(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1604 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221ACA0: C11F0640  lfs f8, 0x640(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1600 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221ACA4: C0DF0648  lfs f6, 0x648(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1608 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221ACA8: C0BF0650  lfs f5, 0x650(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1616 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8221ACAC: C09F0654  lfs f4, 0x654(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1620 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221ACB0: C07F0658  lfs f3, 0x658(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1624 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221ACB4: C05F0660  lfs f2, 0x660(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1632 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221ACB8: C03F0664  lfs f1, 0x664(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1636 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221ACBC: C3FF0668  lfs f31, 0x668(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1640 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221ACC0: C3DE0530  lfs f30, 0x530(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1328 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221ACC4: D15F0624  stfs f10, 0x624(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1572 as u32), tmp.u32 ) };
	// 8221ACC8: ED480372  fmuls f10, f8, f13
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ACCC: D15F0640  stfs f10, 0x640(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1600 as u32), tmp.u32 ) };
	// 8221ACD0: ED470372  fmuls f10, f7, f13
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ACD4: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ACD8: D1BF0648  stfs f13, 0x648(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1608 as u32), tmp.u32 ) };
	// 8221ACDC: EDA50332  fmuls f13, f5, f12
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ACE0: D1BF0650  stfs f13, 0x650(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1616 as u32), tmp.u32 ) };
	// 8221ACE4: EDA40332  fmuls f13, f4, f12
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ACE8: D1BF0654  stfs f13, 0x654(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1620 as u32), tmp.u32 ) };
	// 8221ACEC: EDA30332  fmuls f13, f3, f12
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ACF0: D1BF0658  stfs f13, 0x658(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1624 as u32), tmp.u32 ) };
	// 8221ACF4: EDA202F2  fmuls f13, f2, f11
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221ACF8: D1BF0660  stfs f13, 0x660(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1632 as u32), tmp.u32 ) };
	// 8221ACFC: EDA102F2  fmuls f13, f1, f11
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AD00: D1BF0664  stfs f13, 0x664(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1636 as u32), tmp.u32 ) };
	// 8221AD04: EDBF02F2  fmuls f13, f31, f11
	ctx.f[13].f64 = (((ctx.f[31].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AD08: D1BF0668  stfs f13, 0x668(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1640 as u32), tmp.u32 ) };
	// 8221AD0C: EDBE0032  fmuls f13, f30, f0
	ctx.f[13].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AD10: C3BE0534  lfs f29, 0x534(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1332 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221AD14: ED9D0032  fmuls f12, f29, f0
	ctx.f[12].f64 = (((ctx.f[29].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AD18: C37F0680  lfs f27, 0x680(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1664 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8221AD1C: C39E0538  lfs f28, 0x538(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1336 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8221AD20: D15F0644  stfs f10, 0x644(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1604 as u32), tmp.u32 ) };
	// 8221AD24: ED7C0032  fmuls f11, f28, f0
	ctx.f[11].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AD28: C35F0684  lfs f26, 0x684(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1668 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8221AD2C: C33F0688  lfs f25, 0x688(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1672 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8221AD30: C31F0690  lfs f24, 0x690(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1680 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8221AD34: C2FF0694  lfs f23, 0x694(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1684 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8221AD38: C2DF0698  lfs f22, 0x698(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1688 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8221AD3C: C2BF06A0  lfs f21, 0x6a0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1696 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 8221AD40: ED5B0372  fmuls f10, f27, f13
	ctx.f[10].f64 = (((ctx.f[27].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AD44: D15F0680  stfs f10, 0x680(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1664 as u32), tmp.u32 ) };
	// 8221AD48: ED5A0372  fmuls f10, f26, f13
	ctx.f[10].f64 = (((ctx.f[26].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AD4C: D15F0684  stfs f10, 0x684(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1668 as u32), tmp.u32 ) };
	// 8221AD50: EDB90372  fmuls f13, f25, f13
	ctx.f[13].f64 = (((ctx.f[25].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AD54: D1BF0688  stfs f13, 0x688(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1672 as u32), tmp.u32 ) };
	// 8221AD58: EDB80332  fmuls f13, f24, f12
	ctx.f[13].f64 = (((ctx.f[24].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AD5C: D1BF0690  stfs f13, 0x690(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1680 as u32), tmp.u32 ) };
	// 8221AD60: EDB70332  fmuls f13, f23, f12
	ctx.f[13].f64 = (((ctx.f[23].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AD64: D1BF0694  stfs f13, 0x694(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1684 as u32), tmp.u32 ) };
	// 8221AD68: EDB60332  fmuls f13, f22, f12
	ctx.f[13].f64 = (((ctx.f[22].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AD6C: D1BF0698  stfs f13, 0x698(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1688 as u32), tmp.u32 ) };
	// 8221AD70: EDB502F2  fmuls f13, f21, f11
	ctx.f[13].f64 = (((ctx.f[21].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AD74: D1BF06A0  stfs f13, 0x6a0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1696 as u32), tmp.u32 ) };
	// 8221AD78: C1BE0540  lfs f13, 0x540(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1344 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AD7C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AD80: C15F06A4  lfs f10, 0x6a4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1700 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AD84: D13F0628  stfs f9, 0x628(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1576 as u32), tmp.u32 ) };
	// 8221AD88: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AD8C: C13F06A8  lfs f9, 0x6a8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1704 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221AD90: C11F06C0  lfs f8, 0x6c0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1728 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221AD94: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AD98: D15F06A4  stfs f10, 0x6a4(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1700 as u32), tmp.u32 ) };
	// 8221AD9C: C0FF06C4  lfs f7, 0x6c4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1732 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221ADA0: C19E0544  lfs f12, 0x544(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1348 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221ADA4: C0DF06C8  lfs f6, 0x6c8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1736 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221ADA8: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ADAC: C17E0548  lfs f11, 0x548(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1352 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221ADB0: C0BF06D0  lfs f5, 0x6d0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1744 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8221ADB4: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ADB8: ED480372  fmuls f10, f8, f13
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ADBC: D15F06C0  stfs f10, 0x6c0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1728 as u32), tmp.u32 ) };
	// 8221ADC0: ED470372  fmuls f10, f7, f13
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ADC4: C09F06D4  lfs f4, 0x6d4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1748 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221ADC8: C07F06D8  lfs f3, 0x6d8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1752 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221ADCC: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ADD0: C05E0550  lfs f2, 0x550(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1360 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221ADD4: C03E0554  lfs f1, 0x554(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1364 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221ADD8: C3FF06E0  lfs f31, 0x6e0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1760 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221ADDC: C3DF06E4  lfs f30, 0x6e4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1764 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221ADE0: C3BF06E8  lfs f29, 0x6e8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1768 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221ADE4: C39F0700  lfs f28, 0x700(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1792 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8221ADE8: C37F0704  lfs f27, 0x704(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1796 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8221ADEC: C35F0708  lfs f26, 0x708(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1800 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8221ADF0: C33F0710  lfs f25, 0x710(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1808 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8221ADF4: C31F0714  lfs f24, 0x714(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1812 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8221ADF8: C2FF0718  lfs f23, 0x718(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1816 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8221ADFC: C2DE0558  lfs f22, 0x558(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1368 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8221AE00: D13F06A8  stfs f9, 0x6a8(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1704 as u32), tmp.u32 ) };
	// 8221AE04: D15F06C4  stfs f10, 0x6c4(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1732 as u32), tmp.u32 ) };
	// 8221AE08: D1BF06C8  stfs f13, 0x6c8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1736 as u32), tmp.u32 ) };
	// 8221AE0C: EDA50332  fmuls f13, f5, f12
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE10: D1BF06D0  stfs f13, 0x6d0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1744 as u32), tmp.u32 ) };
	// 8221AE14: EDA40332  fmuls f13, f4, f12
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE18: D1BF06D4  stfs f13, 0x6d4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1748 as u32), tmp.u32 ) };
	// 8221AE1C: EDA30332  fmuls f13, f3, f12
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE20: D1BF06D8  stfs f13, 0x6d8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1752 as u32), tmp.u32 ) };
	// 8221AE24: EDA20032  fmuls f13, f2, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AE28: ED810032  fmuls f12, f1, f0
	ctx.f[12].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AE2C: C13F0724  lfs f9, 0x724(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1828 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221AE30: ED5F02F2  fmuls f10, f31, f11
	ctx.f[10].f64 = (((ctx.f[31].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AE34: D15F06E0  stfs f10, 0x6e0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1760 as u32), tmp.u32 ) };
	// 8221AE38: ED5E02F2  fmuls f10, f30, f11
	ctx.f[10].f64 = (((ctx.f[30].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AE3C: D15F06E4  stfs f10, 0x6e4(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1764 as u32), tmp.u32 ) };
	// 8221AE40: ED7D02F2  fmuls f11, f29, f11
	ctx.f[11].f64 = (((ctx.f[29].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AE44: D17F06E8  stfs f11, 0x6e8(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1768 as u32), tmp.u32 ) };
	// 8221AE48: ED760032  fmuls f11, f22, f0
	ctx.f[11].f64 = (((ctx.f[22].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AE4C: C11F0728  lfs f8, 0x728(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1832 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221AE50: C0FF0740  lfs f7, 0x740(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1856 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221AE54: C0DF0744  lfs f6, 0x744(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1860 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221AE58: C0BF0748  lfs f5, 0x748(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1864 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8221AE5C: C09F0750  lfs f4, 0x750(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1872 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221AE60: ED5C0372  fmuls f10, f28, f13
	ctx.f[10].f64 = (((ctx.f[28].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AE64: D15F0700  stfs f10, 0x700(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1792 as u32), tmp.u32 ) };
	// 8221AE68: ED5B0372  fmuls f10, f27, f13
	ctx.f[10].f64 = (((ctx.f[27].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AE6C: D15F0704  stfs f10, 0x704(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1796 as u32), tmp.u32 ) };
	// 8221AE70: EDBA0372  fmuls f13, f26, f13
	ctx.f[13].f64 = (((ctx.f[26].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AE74: D1BF0708  stfs f13, 0x708(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1800 as u32), tmp.u32 ) };
	// 8221AE78: EDB90332  fmuls f13, f25, f12
	ctx.f[13].f64 = (((ctx.f[25].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE7C: D1BF0710  stfs f13, 0x710(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1808 as u32), tmp.u32 ) };
	// 8221AE80: EDB80332  fmuls f13, f24, f12
	ctx.f[13].f64 = (((ctx.f[24].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE84: D1BF0714  stfs f13, 0x714(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1812 as u32), tmp.u32 ) };
	// 8221AE88: EDB70332  fmuls f13, f23, f12
	ctx.f[13].f64 = (((ctx.f[23].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AE8C: D1BF0718  stfs f13, 0x718(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1816 as u32), tmp.u32 ) };
	// 8221AE90: C1BE0560  lfs f13, 0x560(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1376 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AE94: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AE98: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AE9C: C15F0720  lfs f10, 0x720(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1824 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221AEA0: C19E0564  lfs f12, 0x564(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1380 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AEA4: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AEA8: ED0802F2  fmuls f8, f8, f11
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AEAC: C17E0568  lfs f11, 0x568(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1384 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221AEB0: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AEB4: D15F0720  stfs f10, 0x720(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1824 as u32), tmp.u32 ) };
	// 8221AEB8: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AEBC: C07F0754  lfs f3, 0x754(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1876 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221AEC0: C3DF0760  lfs f30, 0x760(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221AEC4: C05F0758  lfs f2, 0x758(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1880 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221AEC8: C3BF0764  lfs f29, 0x764(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221AECC: C39F0768  lfs f28, 0x768(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1896 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8221AED0: C03E0570  lfs f1, 0x570(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1392 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221AED4: ED470372  fmuls f10, f7, f13
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AED8: D15F0740  stfs f10, 0x740(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1856 as u32), tmp.u32 ) };
	// 8221AEDC: ED460372  fmuls f10, f6, f13
	ctx.f[10].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AEE0: D15F0744  stfs f10, 0x744(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1860 as u32), tmp.u32 ) };
	// 8221AEE4: EDA50372  fmuls f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AEE8: D1BF0748  stfs f13, 0x748(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1864 as u32), tmp.u32 ) };
	// 8221AEEC: EDA40332  fmuls f13, f4, f12
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AEF0: D1BF0750  stfs f13, 0x750(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1872 as u32), tmp.u32 ) };
	// 8221AEF4: EDA30332  fmuls f13, f3, f12
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AEF8: D1BF0754  stfs f13, 0x754(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1876 as u32), tmp.u32 ) };
	// 8221AEFC: ED5E02F2  fmuls f10, f30, f11
	ctx.f[10].f64 = (((ctx.f[30].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AF00: D15F0760  stfs f10, 0x760(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1888 as u32), tmp.u32 ) };
	// 8221AF04: C3FE0574  lfs f31, 0x574(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1396 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221AF08: EDA20332  fmuls f13, f2, f12
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AF0C: ED5D02F2  fmuls f10, f29, f11
	ctx.f[10].f64 = (((ctx.f[29].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AF10: D1BF0758  stfs f13, 0x758(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1880 as u32), tmp.u32 ) };
	// 8221AF14: ED7C02F2  fmuls f11, f28, f11
	ctx.f[11].f64 = (((ctx.f[28].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AF18: C37F0780  lfs f27, 0x780(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1920 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8221AF1C: C35F0784  lfs f26, 0x784(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1924 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8221AF20: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AF24: C33F0788  lfs f25, 0x788(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1928 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8221AF28: ED9F0032  fmuls f12, f31, f0
	ctx.f[12].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AF2C: C31F0790  lfs f24, 0x790(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1936 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8221AF30: C2FF0794  lfs f23, 0x794(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1940 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8221AF34: C2DE0578  lfs f22, 0x578(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1400 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8221AF38: C2BF0798  lfs f21, 0x798(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1944 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 8221AF3C: D13F0724  stfs f9, 0x724(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1828 as u32), tmp.u32 ) };
	// 8221AF40: D11F0728  stfs f8, 0x728(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1832 as u32), tmp.u32 ) };
	// 8221AF44: D15F0764  stfs f10, 0x764(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1892 as u32), tmp.u32 ) };
	// 8221AF48: D17F0768  stfs f11, 0x768(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1896 as u32), tmp.u32 ) };
	// 8221AF4C: ED5B0372  fmuls f10, f27, f13
	ctx.f[10].f64 = (((ctx.f[27].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AF50: D15F0780  stfs f10, 0x780(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1920 as u32), tmp.u32 ) };
	// 8221AF54: ED760032  fmuls f11, f22, f0
	ctx.f[11].f64 = (((ctx.f[22].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AF58: C0FE0584  lfs f7, 0x584(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1412 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221AF5C: ED5A0372  fmuls f10, f26, f13
	ctx.f[10].f64 = (((ctx.f[26].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AF60: D15F0784  stfs f10, 0x784(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1924 as u32), tmp.u32 ) };
	// 8221AF64: EDB90372  fmuls f13, f25, f13
	ctx.f[13].f64 = (((ctx.f[25].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AF68: D1BF0788  stfs f13, 0x788(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1928 as u32), tmp.u32 ) };
	// 8221AF6C: EDB80332  fmuls f13, f24, f12
	ctx.f[13].f64 = (((ctx.f[24].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AF70: D1BF0790  stfs f13, 0x790(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1936 as u32), tmp.u32 ) };
	// 8221AF74: EDB70332  fmuls f13, f23, f12
	ctx.f[13].f64 = (((ctx.f[23].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AF78: D1BF0794  stfs f13, 0x794(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1940 as u32), tmp.u32 ) };
	// 8221AF7C: C1BF07A0  lfs f13, 0x7a0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1952 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AF80: ED550332  fmuls f10, f21, f12
	ctx.f[10].f64 = (((ctx.f[21].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AF84: C19F07A4  lfs f12, 0x7a4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1956 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AF88: C0DE0588  lfs f6, 0x588(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1416 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221AF8C: C0BF07C8  lfs f5, 0x7c8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1992 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8221AF90: C09F07D0  lfs f4, 0x7d0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2000 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8221AF94: ED2D02F2  fmuls f9, f13, f11
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AF98: C1BF07A8  lfs f13, 0x7a8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1960 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221AF9C: ED0C02F2  fmuls f8, f12, f11
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AFA0: C19E0580  lfs f12, 0x580(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1408 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221AFA4: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221AFA8: D17F07A8  stfs f11, 0x7a8(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1960 as u32), tmp.u32 ) };
	// 8221AFAC: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AFB0: C07F07D4  lfs f3, 0x7d4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2004 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221AFB4: ED870032  fmuls f12, f7, f0
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AFB8: C0FF07C0  lfs f7, 0x7c0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1984 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221AFBC: EC060032  fmuls f0, f6, f0
	ctx.f[0].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221AFC0: C0DF07C4  lfs f6, 0x7c4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1988 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221AFC4: C05F07D8  lfs f2, 0x7d8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2008 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221AFC8: C03F07E0  lfs f1, 0x7e0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2016 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221AFCC: C3FF07E4  lfs f31, 0x7e4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2020 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221AFD0: C3DF07E8  lfs f30, 0x7e8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2024 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221AFD4: D15F0798  stfs f10, 0x798(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1944 as u32), tmp.u32 ) };
	// 8221AFD8: D13F07A0  stfs f9, 0x7a0(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1952 as u32), tmp.u32 ) };
	// 8221AFDC: D11F07A4  stfs f8, 0x7a4(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1956 as u32), tmp.u32 ) };
	// 8221AFE0: ED670372  fmuls f11, f7, f13
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AFE4: D17F07C0  stfs f11, 0x7c0(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1984 as u32), tmp.u32 ) };
	// 8221AFE8: ED660372  fmuls f11, f6, f13
	ctx.f[11].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AFEC: D17F07C4  stfs f11, 0x7c4(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1988 as u32), tmp.u32 ) };
	// 8221AFF0: EDA50372  fmuls f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221AFF4: D1BF07C8  stfs f13, 0x7c8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1992 as u32), tmp.u32 ) };
	// 8221AFF8: EDA40332  fmuls f13, f4, f12
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221AFFC: D1BF07D0  stfs f13, 0x7d0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2000 as u32), tmp.u32 ) };
	// 8221B000: EDA30332  fmuls f13, f3, f12
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221B004: D1BF07D4  stfs f13, 0x7d4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2004 as u32), tmp.u32 ) };
	// 8221B008: EDA20332  fmuls f13, f2, f12
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221B00C: D1BF07D8  stfs f13, 0x7d8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2008 as u32), tmp.u32 ) };
	// 8221B010: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221B014: D1BF07E0  stfs f13, 0x7e0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2016 as u32), tmp.u32 ) };
	// 8221B018: EDBF0032  fmuls f13, f31, f0
	ctx.f[13].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221B01C: D1BF07E4  stfs f13, 0x7e4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2020 as u32), tmp.u32 ) };
	// 8221B020: EC1E0032  fmuls f0, f30, f0
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221B024: D01F07E8  stfs f0, 0x7e8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(2024 as u32), tmp.u32 ) };
	// 8221B028: 382108F0  addi r1, r1, 0x8f0
	ctx.r[1].s64 = ctx.r[1].s64 + 2288;
	// 8221B02C: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 8221B030: 4831AFE9  bl 0x82536018
	ctx.lr = 0x8221B034;
	sub_82535FFC(ctx, base);
	// 8221B034: 4831A0D4  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221B038(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221B038 size=3992
    let mut pc: u32 = 0x8221B038;
    'dispatch: loop {
        match pc {
            0x8221B038 => {
    //   block [0x8221B038..0x8221BFD0)
	// 8221B038: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221B03C: 4831A04D  bl 0x82535088
	ctx.lr = 0x8221B040;
	sub_82535080(ctx, base);
	// 8221B040: 3981FF78  addi r12, r1, -0x88
	ctx.r[12].s64 = ctx.r[1].s64 + -136;
	// 8221B044: 4831AF81  bl 0x82535fc4
	ctx.lr = 0x8221B048;
	sub_82535FB0(ctx, base);
	// 8221B048: 3980FEE0  li r12, -0x120
	ctx.r[12].s64 = -288;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221BFD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221BFD0 size=760
    let mut pc: u32 = 0x8221BFD0;
    'dispatch: loop {
        match pc {
            0x8221BFD0 => {
    //   block [0x8221BFD0..0x8221C2C8)
	// 8221BFD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221BFD4: 483190D1  bl 0x825350a4
	ctx.lr = 0x8221BFD8;
	sub_82535080(ctx, base);
	// 8221BFD8: DBA1FF98  stfd f29, -0x68(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-104 as u32), ctx.f[29].u64 ) };
	// 8221BFDC: DBC1FFA0  stfd f30, -0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-96 as u32), ctx.f[30].u64 ) };
	// 8221BFE0: DBE1FFA8  stfd f31, -0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 8221BFE4: 3980FF80  li r12, -0x80
	ctx.r[12].s64 = -128;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221C2C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221C2C8 size=536
    let mut pc: u32 = 0x8221C2C8;
    'dispatch: loop {
        match pc {
            0x8221C2C8 => {
    //   block [0x8221C2C8..0x8221C4E0)
	// 8221C2C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221C2CC: 48318DE9  bl 0x825350b4
	ctx.lr = 0x8221C2D0;
	sub_82535080(ctx, base);
	// 8221C2D0: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 8221C2D4: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221C2D8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221C2DC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8221C2E0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8221C2E4: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 8221C2E8: 2F050012  cmpwi cr6, r5, 0x12
	ctx.cr[6].compare_i32(ctx.r[5].s32, 18, &mut ctx.xer);
	// 8221C2EC: C1AB1FF8  lfs f13, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C2F0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221C2F4: D1A10068  stfs f13, 0x68(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8221C2F8: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 8221C2FC: D1A10078  stfs f13, 0x78(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8221C300: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 8221C304: C01D03C4  lfs f0, 0x3c4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(964 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C308: C1AB2BA8  lfs f13, 0x2ba8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(11176 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C30C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221C310: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221C314: D1A10060  stfs f13, 0x60(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8221C318: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8221C31C: C18B2BA4  lfs f12, 0x2ba4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(11172 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221C320: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221C324: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221C328: D1810064  stfs f12, 0x64(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8221C32C: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8221C330: C18B26CC  lfs f12, 0x26cc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9932 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221C334: 397E0440  addi r11, r30, 0x440
	ctx.r[11].s64 = ctx.r[30].s64 + 1088;
	// 8221C338: EC000332  fmuls f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221C33C: D0010074  stfs f0, 0x74(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221C4E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221C4E0 size=1336
    let mut pc: u32 = 0x8221C4E0;
    'dispatch: loop {
        match pc {
            0x8221C4E0 => {
    //   block [0x8221C4E0..0x8221CA18)
	// 8221C4E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221C4E4: 48318BA9  bl 0x8253508c
	ctx.lr = 0x8221C4E8;
	sub_82535080(ctx, base);
	// 8221C4E8: DBA1FF68  stfd f29, -0x98(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.f[29].u64 ) };
	// 8221C4EC: DBC1FF70  stfd f30, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.f[30].u64 ) };
	// 8221C4F0: DBE1FF78  stfd f31, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.f[31].u64 ) };
	// 8221C4F4: 3BE1FE80  addi r31, r1, -0x180
	ctx.r[31].s64 = ctx.r[1].s64 + -384;
	// 8221C4F8: 9421FE80  stwu r1, -0x180(r1)
	ea = ctx.r[1].u32.wrapping_add(-384 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221C4FC: 81610000  lwz r11, 0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221C500: 7C741B78  mr r20, r3
	ctx.r[20].u64 = ctx.r[3].u64;
	// 8221C504: 909F0058  stw r4, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[4].u32 ) };
	// 8221C508: 9561F990  stwu r11, -0x670(r1)
	ea = ctx.r[1].u32.wrapping_add(-1648 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[11].u32) };
	ctx.r[1].u32 = ea;
	// 8221C50C: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8221C510: 396B007F  addi r11, r11, 0x7f
	ctx.r[11].s64 = ctx.r[11].s64 + 127;
	// 8221C514: 556B0030  rlwinm r11, r11, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8221C518: 394B02D0  addi r10, r11, 0x2d0
	ctx.r[10].s64 = ctx.r[11].s64 + 720;
	// 8221C51C: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8221C520: 915F0054  stw r10, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 8221C524: 7C005FEC  dcbz 0, r11
	ea.u32 = ctx.r[11].u32;
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C528: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 8221C52C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C530: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C534: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 8221C538: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C53C: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C540: 39400180  li r10, 0x180
	ctx.r[10].s64 = 384;
	// 8221C544: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C548: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C54C: 39400200  li r10, 0x200
	ctx.r[10].s64 = 512;
	// 8221C550: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C554: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C558: 39400280  li r10, 0x280
	ctx.r[10].s64 = 640;
	// 8221C55C: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C560: 7C0A5FEC  dcbz r10, r11
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[11].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 8221C564: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8221C568: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221C56C: 82BF0058  lwz r21, 0x58(r31)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 8221C570: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 8221C574: 82DF0050  lwz r22, 0x50(r31)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221C578: 83DF0054  lwz r30, 0x54(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8221C57C: 3A200000  li r17, 0
	ctx.r[17].s64 = 0;
	// 8221C580: 3A4BAF40  addi r18, r11, -0x50c0
	ctx.r[18].s64 = ctx.r[11].s64 + -20672;
	// 8221C584: C3C9BA38  lfs f30, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221C588: C3AA1FF8  lfs f29, 0x1ff8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221C58C: 562B003E  slwi r11, r17, 0
	ctx.r[11].u32 = ctx.r[17].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221C590: 3A600002  li r19, 2
	ctx.r[19].s64 = 2;
	// 8221C594: 1D6B00B0  mulli r11, r11, 0xb0
	ctx.r[11].s64 = ctx.r[11].s64 * 176;
	// 8221C598: 7D6BA214  add r11, r11, r20
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[20].u64;
	// 8221C59C: 3AEB0008  addi r23, r11, 8
	ctx.r[23].s64 = ctx.r[11].s64 + 8;
	// 8221C5A0: E9770010  ld r11, 0x10(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[23].u32.wrapping_add(16 as u32) ) };
	// 8221C5A4: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221C5A8: 419A01CC  beq cr6, 0x8221c774
	if ctx.cr[6].eq {
	pc = 0x8221C774; continue 'dispatch;
	}
	// 8221C5AC: 81740000  lwz r11, 0(r20)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221C5B0: 2B310000  cmpldi cr6, r17, 0
	ctx.cr[6].compare_u64(ctx.r[17].u64, 0, &mut ctx.xer);
	// 8221C5B4: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 8221C5B8: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8221C5BC: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 8221C5C0: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8221C5C4: 7E469378  mr r6, r18
	ctx.r[6].u64 = ctx.r[18].u64;
	// 8221C5C8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8221C5CC: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 8221C5D0: 409A0010  bne cr6, 0x8221c5e0
	if !ctx.cr[6].eq {
	pc = 0x8221C5E0; continue 'dispatch;
	}
	// 8221C5D4: 38AB01E0  addi r5, r11, 0x1e0
	ctx.r[5].s64 = ctx.r[11].s64 + 480;
	// 8221C5D8: 4BFF8089  bl 0x82214660
	ctx.lr = 0x8221C5DC;
	sub_82214660(ctx, base);
	// 8221C5DC: 480000E4  b 0x8221c6c0
	pc = 0x8221C6C0; continue 'dispatch;
	// 8221C5E0: 38AB02D0  addi r5, r11, 0x2d0
	ctx.r[5].s64 = ctx.r[11].s64 + 720;
	// 8221C5E4: 4BFF807D  bl 0x82214660
	ctx.lr = 0x8221C5E8;
	sub_82214660(ctx, base);
	// 8221C5E8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8221C5EC: 554B003E  slwi r11, r10, 0
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221C5F0: 394A0005  addi r10, r10, 5
	ctx.r[10].s64 = ctx.r[10].s64 + 5;
	// 8221C5F4: 5568083C  slwi r8, r11, 1
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8221C5F8: 392B0002  addi r9, r11, 2
	ctx.r[9].s64 = ctx.r[11].s64 + 2;
	// 8221C5FC: 7CEB4214  add r7, r11, r8
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8221C600: 390B0003  addi r8, r11, 3
	ctx.r[8].s64 = ctx.r[11].s64 + 3;
	// 8221C604: 54E62036  slwi r6, r7, 4
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221C608: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8221C60C: 7D66F214  add r11, r6, r30
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[30].u64;
	// 8221C610: 5526083C  slwi r6, r9, 1
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221C614: 2B2A000E  cmpldi cr6, r10, 0xe
	ctx.cr[6].compare_u64(ctx.r[10].u64, 14, &mut ctx.xer);
	// 8221C618: 7CC93214  add r6, r9, r6
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 8221C61C: 5509083C  slwi r9, r8, 1
	ctx.r[9].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221C620: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C624: 54C62036  slwi r6, r6, 4
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221C628: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C62C: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221C630: C00B0030  lfs f0, 0x30(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C634: 7D284A14  add r9, r8, r9
	ctx.r[9].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 8221C638: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C63C: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C640: FDA06850  fneg f13, f13
	ctx.f[13].u64 = ctx.f[13].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C644: D00B0030  stfs f0, 0x30(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221C648: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221C64C: 55292036  slwi r9, r9, 4
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221C650: C00B0038  lfs f0, 0x38(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C654: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C658: D00B0038  stfs f0, 0x38(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221C65C: 7D66F214  add r11, r6, r30
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[30].u64;
	// 8221C660: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C664: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C668: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221C66C: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C670: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C674: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221C678: 7D69F214  add r11, r9, r30
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 8221C67C: 54E9083C  slwi r9, r7, 1
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221C680: 7D274A14  add r9, r7, r9
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 8221C684: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C688: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C68C: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221C690: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C694: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C698: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221C69C: 552B2036  slwi r11, r9, 4
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221C6A0: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8221C6A4: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C6A8: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C6AC: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221C6B0: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C6B4: FC000050  fneg f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221C6B8: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221C6BC: 4099FF30  ble cr6, 0x8221c5ec
	if !ctx.cr[6].gt {
	pc = 0x8221C5EC; continue 'dispatch;
	}
	// 8221C6C0: EB370010  ld r25, 0x10(r23)
	ctx.r[25].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[23].u32.wrapping_add(16 as u32) ) };
	// 8221C6C4: 3B770018  addi r27, r23, 0x18
	ctx.r[27].s64 = ctx.r[23].s64 + 24;
	// 8221C6C8: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8221C6CC: 3B96001C  addi r28, r22, 0x1c
	ctx.r[28].s64 = ctx.r[22].s64 + 28;
	// 8221C6D0: 3BBE0018  addi r29, r30, 0x18
	ctx.r[29].s64 = ctx.r[30].s64 + 24;
	// 8221C6D4: 7F1EB050  subf r24, r30, r22
	ctx.r[24].s64 = ctx.r[22].s64 - ctx.r[30].s64;
	// 8221C6D8: 2B390000  cmpldi cr6, r25, 0
	ctx.cr[6].compare_u64(ctx.r[25].u64, 0, &mut ctx.xer);
	// 8221C6DC: 419A0098  beq cr6, 0x8221c774
	if ctx.cr[6].eq {
	pc = 0x8221C774; continue 'dispatch;
	}
	// 8221C6E0: 7B2B07E0  clrldi r11, r25, 0x3f
	ctx.r[11].u64 = ctx.r[25].u64 & 0x0000000000000001u64;
	// 8221C6E4: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221C6E8: 419A0070  beq cr6, 0x8221c758
	if ctx.cr[6].eq {
	pc = 0x8221C758; continue 'dispatch;
	}
	// 8221C6EC: 389CFFE4  addi r4, r28, -0x1c
	ctx.r[4].s64 = ctx.r[28].s64 + -28;
	// 8221C6F0: C3FB0000  lfs f31, 0(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221C6F4: 38BDFFE8  addi r5, r29, -0x18
	ctx.r[5].s64 = ctx.r[29].s64 + -24;
	// 8221C6F8: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 8221C6FC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8221C700: 481580A1  bl 0x823747a0
	ctx.lr = 0x8221C704;
	sub_823747A0(ctx, base);
	// 8221C704: EC1EF828  fsubs f0, f30, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (((ctx.f[30].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221C708: C1BCFFF4  lfs f13, -0xc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C70C: C19CFFF8  lfs f12, -8(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(-8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221C710: 7D78EC2E  lfsx f11, r24, r29
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[29].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221C714: C15C0000  lfs f10, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221C718: C13DFFF8  lfs f9, -8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221C71C: C11DFFFC  lfs f8, -4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221C720: C0FD0000  lfs f7, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221C724: C0DD0004  lfs f6, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221C728: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221C72C: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221C730: ED6002F2  fmuls f11, f0, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221C734: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221C738: EC096FFA  fmadds f0, f9, f31, f13
	ctx.f[0].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221C73C: D01CFFF4  stfs f0, -0xc(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 8221C740: EC0867FA  fmadds f0, f8, f31, f12
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221C744: D01CFFF8  stfs f0, -8(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8221C748: EC075FFA  fmadds f0, f7, f31, f11
	ctx.f[0].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[11].f64) as f32) as f64);
	// 8221C74C: 7C18ED2E  stfsx f0, r24, r29
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[24].u32.wrapping_add(ctx.r[29].u32), tmp.u32) };
	// 8221C750: EC0657FA  fmadds f0, f6, f31, f10
	ctx.f[0].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[10].f64) as f32) as f64);
	// 8221C754: D01C0000  stfs f0, 0(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221C758: 3B5A0001  addi r26, r26, 1
	ctx.r[26].s64 = ctx.r[26].s64 + 1;
	// 8221C75C: 3BBD0030  addi r29, r29, 0x30
	ctx.r[29].s64 = ctx.r[29].s64 + 48;
	// 8221C760: 3B9C0030  addi r28, r28, 0x30
	ctx.r[28].s64 = ctx.r[28].s64 + 48;
	// 8221C764: 7B39F842  rldicl r25, r25, 0x3f, 1
	ctx.r[25].u64 = ctx.r[25].u64 & 0x0000000000000001u64;
	// 8221C768: 3B7B0004  addi r27, r27, 4
	ctx.r[27].s64 = ctx.r[27].s64 + 4;
	// 8221C76C: 2B3A000F  cmpldi cr6, r26, 0xf
	ctx.cr[6].compare_u64(ctx.r[26].u64, 15, &mut ctx.xer);
	// 8221C770: 4198FF68  blt cr6, 0x8221c6d8
	if ctx.cr[6].lt {
	pc = 0x8221C6D8; continue 'dispatch;
	}
	// 8221C774: 3A73FFFF  addi r19, r19, -1
	ctx.r[19].s64 = ctx.r[19].s64 + -1;
	// 8221C778: 3AF70058  addi r23, r23, 0x58
	ctx.r[23].s64 = ctx.r[23].s64 + 88;
	// 8221C77C: 2B330000  cmpldi cr6, r19, 0
	ctx.cr[6].compare_u64(ctx.r[19].u64, 0, &mut ctx.xer);
	// 8221C780: 4199FE20  bgt cr6, 0x8221c5a0
	if ctx.cr[6].gt {
	pc = 0x8221C5A0; continue 'dispatch;
	}
	// 8221C784: 817401E0  lwz r11, 0x1e0(r20)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(480 as u32) ) } as u64;
	// 8221C788: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221C78C: 419A016C  beq cr6, 0x8221c8f8
	if ctx.cr[6].eq {
	pc = 0x8221C8F8; continue 'dispatch;
	}
	// 8221C790: 81540004  lwz r10, 4(r20)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) } as u64;
	// 8221C794: 7EDAB378  mr r26, r22
	ctx.r[26].u64 = ctx.r[22].u64;
	// 8221C798: 2B310000  cmpldi cr6, r17, 0
	ctx.cr[6].compare_u64(ctx.r[17].u64, 0, &mut ctx.xer);
	// 8221C79C: 409A0014  bne cr6, 0x8221c7b0
	if !ctx.cr[6].eq {
	pc = 0x8221C7B0; continue 'dispatch;
	}
	// 8221C7A0: 3B6B0800  addi r27, r11, 0x800
	ctx.r[27].s64 = ctx.r[11].s64 + 2048;
	// 8221C7A4: 3BAA0080  addi r29, r10, 0x80
	ctx.r[29].s64 = ctx.r[10].s64 + 128;
	// 8221C7A8: 3B940168  addi r28, r20, 0x168
	ctx.r[28].s64 = ctx.r[20].s64 + 360;
	// 8221C7AC: 48000010  b 0x8221c7bc
	pc = 0x8221C7BC; continue 'dispatch;
	// 8221C7B0: 3B6B0BC0  addi r27, r11, 0xbc0
	ctx.r[27].s64 = ctx.r[11].s64 + 3008;
	// 8221C7B4: 3B9401A4  addi r28, r20, 0x1a4
	ctx.r[28].s64 = ctx.r[20].s64 + 420;
	// 8221C7B8: 3BAA00BC  addi r29, r10, 0xbc
	ctx.r[29].s64 = ctx.r[10].s64 + 188;
	// 8221C7BC: 3B20000F  li r25, 0xf
	ctx.r[25].s64 = 15;
	// 8221C7C0: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221C7C4: 387F0060  addi r3, r31, 0x60
	ctx.r[3].s64 = ctx.r[31].s64 + 96;
	// 8221C7C8: 815401E0  lwz r10, 0x1e0(r20)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(480 as u32) ) } as u64;
	// 8221C7CC: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221C7D0: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8221C7D4: 4814C1F5  bl 0x823689c8
	ctx.lr = 0x8221C7D8;
	sub_823689C8(ctx, base);
	// 8221C7D8: C01F0070  lfs f0, 0x70(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C7DC: C1BF0064  lfs f13, 0x64(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(100 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C7E0: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 8221C7E4: D1BF0070  stfs f13, 0x70(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8221C7E8: 387F00A0  addi r3, r31, 0xa0
	ctx.r[3].s64 = ctx.r[31].s64 + 160;
	// 8221C7EC: D01F0064  stfs f0, 0x64(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8221C7F0: C01F0080  lfs f0, 0x80(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C7F4: C1BF0068  lfs f13, 0x68(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(104 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C7F8: D1BF0080  stfs f13, 0x80(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8221C7FC: D01F0068  stfs f0, 0x68(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8221C800: C01F0084  lfs f0, 0x84(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(132 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C804: C1BF0078  lfs f13, 0x78(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C808: D1BF0084  stfs f13, 0x84(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8221C80C: D01F0078  stfs f0, 0x78(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8221C810: 4814C1B9  bl 0x823689c8
	ctx.lr = 0x8221C814;
	sub_823689C8(ctx, base);
	// 8221C814: 397F00A0  addi r11, r31, 0xa0
	ctx.r[11].s64 = ctx.r[31].s64 + 160;
	// 8221C818: C01F006C  lfs f0, 0x6c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(108 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221C81C: C1BF007C  lfs f13, 0x7c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(124 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221C820: 389F0060  addi r4, r31, 0x60
	ctx.r[4].s64 = ctx.r[31].s64 + 96;
	// 8221C824: C19F008C  lfs f12, 0x8c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(140 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221C828: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CA18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221CA18 size=12
    let mut pc: u32 = 0x8221CA18;
    'dispatch: loop {
        match pc {
            0x8221CA18 => {
    //   block [0x8221CA18..0x8221CA24)
	// 8221CA18: 3964FFFF  addi r11, r4, -1
	ctx.r[11].s64 = ctx.r[4].s64 + -1;
	// 8221CA1C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CA20: 4D980020  bltlr cr6
	if ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CA24(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221CA24 size=56
    let mut pc: u32 = 0x8221CA24;
    'dispatch: loop {
        match pc {
            0x8221CA24 => {
    //   block [0x8221CA24..0x8221CA5C)
	// 8221CA24: 394B0006  addi r10, r11, 6
	ctx.r[10].s64 = ctx.r[11].s64 + 6;
	// 8221CA28: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8221CA2C: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8221CA30: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221CA34: 7C291D2E  stfsx f1, r9, r3
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 8221CA38: C00A2150  lfs f0, 0x2150(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CA3C: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221CA40: 4098001C  bge cr6, 0x8221ca5c
	if !ctx.cr[6].lt {
		sub_8221CA5C(ctx, base);
		return;
	}
	// 8221CA44: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8221CA48: E9230010  ld r9, 0x10(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221CA4C: 7D4B5836  sld r11, r10, r11
	if (ctx.r[11].u8 & 0x40) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = (ctx.r[10].u64) << ((ctx.r[11].u8 & 0x3F) as u32);
	}
	// 8221CA50: 7D2B5878  andc r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 & !ctx.r[11].u64;
	// 8221CA54: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221CA58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CA5C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221CA5C size=24
    let mut pc: u32 = 0x8221CA5C;
    'dispatch: loop {
        match pc {
            0x8221CA5C => {
    //   block [0x8221CA5C..0x8221CA74)
	// 8221CA5C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8221CA60: E9430010  ld r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221CA64: 7D2B5836  sld r11, r9, r11
	if (ctx.r[11].u8 & 0x40) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = (ctx.r[9].u64) << ((ctx.r[11].u8 & 0x3F) as u32);
	}
	// 8221CA68: 7D6B5378  or r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 8221CA6C: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221CA70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CA78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221CA78 size=28
    let mut pc: u32 = 0x8221CA78;
    'dispatch: loop {
        match pc {
            0x8221CA78 => {
    //   block [0x8221CA78..0x8221CA94)
	// 8221CA78: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221CA7C: C00B2150  lfs f0, 0x2150(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CA80: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221CA84: 40980010  bge cr6, 0x8221ca94
	if !ctx.cr[6].lt {
		sub_8221CA94(ctx, base);
		return;
	}
	// 8221CA88: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8221CA8C: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221CA90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CA94(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221CA94 size=60
    let mut pc: u32 = 0x8221CA94;
    'dispatch: loop {
        match pc {
            0x8221CA94 => {
    //   block [0x8221CA94..0x8221CAD0)
	// 8221CA94: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8221CA98: 39430018  addi r10, r3, 0x18
	ctx.r[10].s64 = ctx.r[3].s64 + 24;
	// 8221CA9C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8221CAA0: 3960001F  li r11, 0x1f
	ctx.r[11].s64 = 31;
	// 8221CAA4: F9030010  std r8, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[8].u64 ) };
	// 8221CAA8: D02A0000  stfs f1, 0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CAAC: E9030010  ld r8, 0x10(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221CAB0: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8221CAB4: 7D084B78  or r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8221CAB8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8221CABC: 79290FA4  sldi r9, r9, 1
	ctx.r[9].u64 = ctx.r[9].u64.wrapping_shl(1);
	ctx.r[9].u32 = ctx.r[9].u64 as u32;
	// 8221CAC0: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221CAC4: F9030010  std r8, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[8].u64 ) };
	// 8221CAC8: 4199FFE0  bgt cr6, 0x8221caa8
	if ctx.cr[6].gt {
	pc = 0x8221CAA8; continue 'dispatch;
	}
	// 8221CACC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221CAD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221CAD0 size=2468
    let mut pc: u32 = 0x8221CAD0;
    'dispatch: loop {
        match pc {
            0x8221CAD0 => {
    //   block [0x8221CAD0..0x8221CBF0)
	// 8221CAD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221CAD4: 483185AD  bl 0x82535080
	ctx.lr = 0x8221CAD8;
	sub_82535080(ctx, base);
	// 8221CAD8: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 8221CADC: 483194D5  bl 0x82535fb0
	ctx.lr = 0x8221CAE0;
	sub_82535FB0(ctx, base);
	// 8221CAE0: 9421FE50  stwu r1, -0x1b0(r1)
	ea = ctx.r[1].u32.wrapping_add(-432 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221CAE4: 54CB077A  rlwinm r11, r6, 0, 0x1d, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 8221CAE8: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 8221CAEC: 54CE07B6  rlwinm r14, r6, 0, 0x1e, 0x1b
	ctx.r[14].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 8221CAF0: 7C932378  mr r19, r4
	ctx.r[19].u64 = ctx.r[4].u64;
	// 8221CAF4: 7CB92B78  mr r25, r5
	ctx.r[25].u64 = ctx.r[5].u64;
	// 8221CAF8: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8221CAFC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221CB00: 54D10738  rlwinm r17, r6, 0, 0x1c, 0x1c
	ctx.r[17].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 8221CB04: 3FA0820C  lis r29, -0x7df4
	ctx.r[29].s64 = -2113142784;
	// 8221CB08: 91DA00C8  stw r14, 0xc8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(200 as u32), ctx.r[14].u32 ) };
	// 8221CB0C: 3FC0820A  lis r30, -0x7df6
	ctx.r[30].s64 = -2113273856;
	// 8221CB10: 3FE0820D  lis r31, -0x7df3
	ctx.r[31].s64 = -2113077248;
	// 8221CB14: C30B1FF8  lfs f24, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8221CB18: 3D6082CF  lis r11, -0x7d31
	ctx.r[11].s64 = -2100363264;
	// 8221CB1C: 3C60820D  lis r3, -0x7df3
	ctx.r[3].s64 = -2113077248;
	// 8221CB20: D31A00C4  stfs f24, 0xc4(r26)
	tmp.f32 = (ctx.f[24].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221CB24: 3C80820D  lis r4, -0x7df3
	ctx.r[4].s64 = -2113077248;
	// 8221CB28: C27DD218  lfs f19, -0x2de8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(-11752 as u32) ) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 8221CB2C: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8221CB30: C21EBA44  lfs f16, -0x45bc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-17852 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 8221CB34: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8221CB38: C1DF2038  lfs f14, 0x2038(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8248 as u32) ) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 8221CB3C: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8221CB40: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8221CB44: C1E3D6C8  lfs f15, -0x2938(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-10552 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 8221CB48: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8221CB4C: C2842190  lfs f20, 0x2190(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8592 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 8221CB50: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221CB54: C2252194  lfs f17, 0x2194(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8596 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 8221CB58: 3B8BDBD0  addi r28, r11, -0x2430
	ctx.r[28].s64 = ctx.r[11].s64 + -9264;
	// 8221CB5C: C2C6BFFC  lfs f22, -0x4004(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8221CB60: 3A000000  li r16, 0
	ctx.r[16].s64 = 0;
	// 8221CB64: C2E72048  lfs f23, 0x2048(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8264 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8221CB68: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 8221CB6C: C2A82BA0  lfs f21, 0x2ba0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(11168 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 8221CB70: C3292760  lfs f25, 0x2760(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(10080 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8221CB74: 7F5BD378  mr r27, r26
	ctx.r[27].u64 = ctx.r[26].u64;
	// 8221CB78: C24A235C  lfs f18, 0x235c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(9052 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 8221CB7C: 7E188378  mr r24, r16
	ctx.r[24].u64 = ctx.r[16].u64;
	// 8221CB80: 3AEBAF38  addi r23, r11, -0x50c8
	ctx.r[23].s64 = ctx.r[11].s64 + -20680;
	// 8221CB84: 39E00001  li r15, 1
	ctx.r[15].s64 = 1;
	// 8221CB88: 3A800030  li r20, 0x30
	ctx.r[20].s64 = 48;
	// 8221CB8C: 3AA00010  li r21, 0x10
	ctx.r[21].s64 = 16;
	// 8221CB90: 3AC00020  li r22, 0x20
	ctx.r[22].s64 = 32;
	// 8221CB94: 3A40FFFF  li r18, -1
	ctx.r[18].s64 = -1;
	// 8221CB98: 570B003E  slwi r11, r24, 0
	ctx.r[11].u32 = ctx.r[24].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221CB9C: 2B380007  cmpldi cr6, r24, 7
	ctx.cr[6].compare_u64(ctx.r[24].u64, 7, &mut ctx.xer);
	// 8221CBA0: 7D4BB8AE  lbzx r10, r11, r23
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[23].u32)) } as u64;
	// 8221CBA4: 554A303E  rotlwi r10, r10, 6
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(6)) as u64;
	// 8221CBA8: 7FAACA14  add r29, r10, r25
	ctx.r[29].u64 = ctx.r[10].u64 + ctx.r[25].u64;
	// 8221CBAC: 41990508  bgt cr6, 0x8221d0b4
	if ctx.cr[6].gt {
	pc = 0x8221D0B4; continue 'dispatch;
	}
	// 8221CBB0: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8221CBB4: 2B0B0006  cmplwi cr6, r11, 6
	ctx.cr[6].compare_u32(ctx.r[11].u32, 6 as u32, &mut ctx.xer);
	// 8221CBB8: 419904FC  bgt cr6, 0x8221d0b4
	if ctx.cr[6].gt {
	pc = 0x8221D0B4; continue 'dispatch;
	}
	// 8221CBBC: 3D808222  lis r12, -0x7dde
	ctx.r[12].s64 = -2111700992;
	// 8221CBC0: 398CCBD4  addi r12, r12, -0x342c
	ctx.r[12].s64 = ctx.r[12].s64 + -13356;
	// 8221CBC4: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8221CBC8: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8221CBCC: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8221CBD0: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8221CBF0; continue 'dispatch;
		},
		1 => {
	pc = 0x8221CBF0; continue 'dispatch;
		},
		2 => {
	pc = 0x8221CEB4; continue 'dispatch;
		},
		3 => {
	pc = 0x8221CD38; continue 'dispatch;
		},
		4 => {
	pc = 0x8221CDFC; continue 'dispatch;
		},
		5 => {
	pc = 0x8221CDFC; continue 'dispatch;
		},
		6 => {
	pc = 0x8221CDFC; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8221CBD4: 8221CBF0  lwz r17, -0x3410(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-13328 as u32) ) } as u64;
	// 8221CBD8: 8221CBF0  lwz r17, -0x3410(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-13328 as u32) ) } as u64;
	// 8221CBDC: 8221CEB4  lwz r17, -0x314c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12620 as u32) ) } as u64;
	// 8221CBE0: 8221CD38  lwz r17, -0x32c8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-13000 as u32) ) } as u64;
	// 8221CBE4: 8221CDFC  lwz r17, -0x3204(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12804 as u32) ) } as u64;
	// 8221CBE8: 8221CDFC  lwz r17, -0x3204(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12804 as u32) ) } as u64;
	// 8221CBEC: 8221CDFC  lwz r17, -0x3204(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12804 as u32) ) } as u64;
            }
            0x8221CBF0 => {
    //   block [0x8221CBF0..0x8221CD38)
	// 8221CBF0: 2B380001  cmpldi cr6, r24, 1
	ctx.cr[6].compare_u64(ctx.r[24].u64, 1, &mut ctx.xer);
	// 8221CBF4: 409A0010  bne cr6, 0x8221cc04
	if !ctx.cr[6].eq {
	pc = 0x8221CC04; continue 'dispatch;
	}
	// 8221CBF8: 3BF90440  addi r31, r25, 0x440
	ctx.r[31].s64 = ctx.r[25].s64 + 1088;
	// 8221CBFC: 3BD90480  addi r30, r25, 0x480
	ctx.r[30].s64 = ctx.r[25].s64 + 1152;
	// 8221CC00: 4800000C  b 0x8221cc0c
	pc = 0x8221CC0C; continue 'dispatch;
	// 8221CC04: 3BF90540  addi r31, r25, 0x540
	ctx.r[31].s64 = ctx.r[25].s64 + 1344;
	// 8221CC08: 3BD90580  addi r30, r25, 0x580
	ctx.r[30].s64 = ctx.r[25].s64 + 1408;
	// 8221CC0C: 897C0001  lbz r11, 1(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 8221CC10: C05E0038  lfs f2, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221CC14: C03E0030  lfs f1, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221CC18: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CC1C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CC20: 40990018  ble cr6, 0x8221cc38
	if !ctx.cr[6].gt {
	pc = 0x8221CC38; continue 'dispatch;
	}
	// 8221CC24: 897C0002  lbz r11, 2(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(2 as u32) ) } as u64;
	// 8221CC28: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CC2C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CC30: 7DEB7B78  mr r11, r15
	ctx.r[11].u64 = ctx.r[15].u64;
	// 8221CC34: 41990008  bgt cr6, 0x8221cc3c
	if ctx.cr[6].gt {
	pc = 0x8221CC3C; continue 'dispatch;
	}
	// 8221CC38: 7E0B8378  mr r11, r16
	ctx.r[11].u64 = ctx.r[16].u64;
	// 8221CC3C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8221CC40: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221CC44: 409A0010  bne cr6, 0x8221cc54
	if !ctx.cr[6].eq {
	pc = 0x8221CC54; continue 'dispatch;
	}
	// 8221CC48: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8221CC4C: 4BF9A87D  bl 0x821b74c8
	ctx.lr = 0x8221CC50;
	sub_821B74C8(ctx, base);
	// 8221CC50: 48000014  b 0x8221cc64
	pc = 0x8221CC64; continue 'dispatch;
	// 8221CC54: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8221CC58: 92010050  stw r16, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[16].u32 ) };
	// 8221CC5C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8221CC60: 4BF9A8D1  bl 0x821b7530
	ctx.lr = 0x8221CC64;
	sub_821B7530(ctx, base);
	// 8221CC64: 897C0001  lbz r11, 1(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 8221CC68: C1BA00DC  lfs f13, 0xdc(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(220 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221CC6C: C05F0038  lfs f2, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221CC70: EFE1682A  fadds f31, f1, f13
	ctx.f[31].f64 = ((ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64;
	// 8221CC74: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CC78: C01F0030  lfs f0, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CC7C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CC80: 40990018  ble cr6, 0x8221cc98
	if !ctx.cr[6].gt {
	pc = 0x8221CC98; continue 'dispatch;
	}
	// 8221CC84: 897C0002  lbz r11, 2(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(2 as u32) ) } as u64;
	// 8221CC88: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CC8C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CC90: 7DEB7B78  mr r11, r15
	ctx.r[11].u64 = ctx.r[15].u64;
	// 8221CC94: 41990008  bgt cr6, 0x8221cc9c
	if ctx.cr[6].gt {
	pc = 0x8221CC9C; continue 'dispatch;
	}
	// 8221CC98: 7E0B8378  mr r11, r16
	ctx.r[11].u64 = ctx.r[16].u64;
	// 8221CC9C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8221CCA0: FC200090  fmr f1, f0
	ctx.f[1].f64 = ctx.f[0].f64;
	// 8221CCA4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221CCA8: 409A0010  bne cr6, 0x8221ccb8
	if !ctx.cr[6].eq {
	pc = 0x8221CCB8; continue 'dispatch;
	}
	// 8221CCAC: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8221CCB0: 4BF9A819  bl 0x821b74c8
	ctx.lr = 0x8221CCB4;
	sub_821B74C8(ctx, base);
	// 8221CCB4: 48000014  b 0x8221ccc8
	pc = 0x8221CCC8; continue 'dispatch;
	// 8221CCB8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8221CCBC: 92010050  stw r16, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[16].u32 ) };
	// 8221CCC0: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8221CCC4: 4BF9A86D  bl 0x821b7530
	ctx.lr = 0x8221CCC8;
	sub_821B7530(ctx, base);
	// 8221CCC8: C15E0034  lfs f10, 0x34(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221CCCC: C01A00DC  lfs f0, 0xdc(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(220 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CCD0: EDAAF828  fsubs f13, f10, f31
	ctx.f[13].f64 = (((ctx.f[10].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221CCD4: EC01002A  fadds f0, f1, f0
	ctx.f[0].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 8221CCD8: C19F0034  lfs f12, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221CCDC: FF0DC000  fcmpu cr6, f13, f24
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[24].f64);
	// 8221CCE0: ED6C0028  fsubs f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8221CCE4: 41980034  blt cr6, 0x8221cd18
	if ctx.cr[6].lt {
	pc = 0x8221CD18; continue 'dispatch;
	}
	// 8221CCE8: FF0BC000  fcmpu cr6, f11, f24
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[24].f64);
	// 8221CCEC: 4198001C  blt cr6, 0x8221cd08
	if ctx.cr[6].lt {
	pc = 0x8221CD08; continue 'dispatch;
	}
	// 8221CCF0: EDA0F828  fsubs f13, f0, f31
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[31].f64) as f32) as f64);
	// 8221CCF4: FDA06A10  fabs f13, f13
	ctx.f[13].u64 = ctx.f[13].u64 & !0x8000_0000_0000_0000u64;
	// 8221CCF8: FF0D9800  fcmpu cr6, f13, f19
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[19].f64);
	// 8221CCFC: 4198000C  blt cr6, 0x8221cd08
	if ctx.cr[6].lt {
	pc = 0x8221CD08; continue 'dispatch;
	}
	// 8221CD00: FF00F800  fcmpu cr6, f0, f31
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[31].f64);
	// 8221CD04: 41980024  blt cr6, 0x8221cd28
	if ctx.cr[6].lt {
	pc = 0x8221CD28; continue 'dispatch;
	}
	// 8221CD08: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221CD0C: 91FB000C  stw r15, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[15].u32 ) };
	// 8221CD10: D19B0000  stfs f12, 0(r27)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CD14: 48000450  b 0x8221d164
	pc = 0x8221D164; continue 'dispatch;
	// 8221CD18: FF0BC000  fcmpu cr6, f11, f24
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[24].f64);
	// 8221CD1C: 4098FFEC  bge cr6, 0x8221cd08
	if !ctx.cr[6].lt {
	pc = 0x8221CD08; continue 'dispatch;
	}
	// 8221CD20: FF0D5800  fcmpu cr6, f13, f11
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[11].f64);
	// 8221CD24: 4099FFE4  ble cr6, 0x8221cd08
	if !ctx.cr[6].gt {
	pc = 0x8221CD08; continue 'dispatch;
	}
	// 8221CD28: D15B0000  stfs f10, 0(r27)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CD2C: 91FB000C  stw r15, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[15].u32 ) };
	// 8221CD30: D3FB0004  stfs f31, 4(r27)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221CD34: 48000430  b 0x8221d164
	pc = 0x8221D164; continue 'dispatch;
            }
            0x8221CD38 => {
    //   block [0x8221CD38..0x8221CDFC)
	// 8221CD38: 897C0001  lbz r11, 1(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 8221CD3C: C01303C0  lfs f0, 0x3c0(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(960 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CD40: EDA00632  fmuls f13, f0, f24
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[24].f64) as f32) as f64);
	// 8221CD44: D001007C  stfs f0, 0x7c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 8221CD48: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CD4C: ED8004B2  fmuls f12, f0, f18
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[18].f64) as f32) as f64);
	// 8221CD50: D1810078  stfs f12, 0x78(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8221CD54: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8221CD58: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CD5C: D1A10074  stfs f13, 0x74(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 8221CD60: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	pc = 0x8221CDFC; continue 'dispatch;
            }
            0x8221CDFC => {
    //   block [0x8221CDFC..0x8221CEB4)
	// 8221CDFC: 2F0E0001  cmpwi cr6, r14, 1
	ctx.cr[6].compare_i32(ctx.r[14].s32, 1, &mut ctx.xer);
	// 8221CE00: 419A009C  beq cr6, 0x8221ce9c
	if ctx.cr[6].eq {
	pc = 0x8221CE9C; continue 'dispatch;
	}
	// 8221CE04: 817A0050  lwz r11, 0x50(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(80 as u32) ) } as u64;
	// 8221CE08: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CE0C: 419A0090  beq cr6, 0x8221ce9c
	if ctx.cr[6].eq {
	pc = 0x8221CE9C; continue 'dispatch;
	}
	// 8221CE10: 897C0001  lbz r11, 1(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 8221CE14: C05D0038  lfs f2, 0x38(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221CE18: C03D0030  lfs f1, 0x30(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(48 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221CE1C: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CE20: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CE24: 40990018  ble cr6, 0x8221ce3c
	if !ctx.cr[6].gt {
	pc = 0x8221CE3C; continue 'dispatch;
	}
	// 8221CE28: 897C0002  lbz r11, 2(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(2 as u32) ) } as u64;
	// 8221CE2C: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221CE30: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221CE34: 7DEB7B78  mr r11, r15
	ctx.r[11].u64 = ctx.r[15].u64;
	// 8221CE38: 41990008  bgt cr6, 0x8221ce40
	if ctx.cr[6].gt {
	pc = 0x8221CE40; continue 'dispatch;
	}
	// 8221CE3C: 7E0B8378  mr r11, r16
	ctx.r[11].u64 = ctx.r[16].u64;
	// 8221CE40: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8221CE44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221CE48: 409A0028  bne cr6, 0x8221ce70
	if !ctx.cr[6].eq {
	pc = 0x8221CE70; continue 'dispatch;
	}
	// 8221CE4C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8221CE50: 4BF9A679  bl 0x821b74c8
	ctx.lr = 0x8221CE54;
	sub_821B74C8(ctx, base);
	// 8221CE54: C01A00DC  lfs f0, 0xdc(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(220 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CE58: EC00082A  fadds f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[1].f64) as f32) as f64;
	// 8221CE5C: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221CE60: C01D0034  lfs f0, 0x34(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CE64: 925B000C  stw r18, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[18].u32 ) };
	// 8221CE68: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CE6C: 480002F8  b 0x8221d164
	pc = 0x8221D164; continue 'dispatch;
	// 8221CE70: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8221CE74: 92010050  stw r16, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[16].u32 ) };
	// 8221CE78: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8221CE7C: 4BF9A6B5  bl 0x821b7530
	ctx.lr = 0x8221CE80;
	sub_821B7530(ctx, base);
	// 8221CE80: C01A00DC  lfs f0, 0xdc(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(220 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CE84: EC00082A  fadds f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[1].f64) as f32) as f64;
	// 8221CE88: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221CE8C: C01D0034  lfs f0, 0x34(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CE90: 925B000C  stw r18, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[18].u32 ) };
	// 8221CE94: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CE98: 480002CC  b 0x8221d164
	pc = 0x8221D164; continue 'dispatch;
	// 8221CE9C: C01A004C  lfs f0, 0x4c(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(76 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CEA0: 925B000C  stw r18, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[18].u32 ) };
	// 8221CEA4: D01B0004  stfs f0, 4(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221CEA8: C01D0034  lfs f0, 0x34(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CEAC: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221CEB0: 480002B4  b 0x8221d164
	pc = 0x8221D164; continue 'dispatch;
            }
            0x8221CEB4 => {
    //   block [0x8221CEB4..0x8221D474)
	// 8221CEB4: 895C0001  lbz r10, 1(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(1 as u32) ) } as u64;
	// 8221CEB8: C01D0000  lfs f0, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CEBC: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8221CEC0: 11A1038C  vspltisw v13, 1
	for i in 0..4 {
		ctx.v[13].u32[i] = 1;
	}
	// 8221CEC4: 7D4A0774  extsb r10, r10
	ctx.r[10].s64 = ctx.r[10].s8 as i64;
	// 8221CEC8: C01D0008  lfs f0, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CECC: D3010064  stfs f24, 0x64(r1)
	tmp.f32 = (ctx.f[24].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8221CED0: 8161006C  lwz r11, 0x6c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8221CED4: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8221CED8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8221CEDC: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8221CEE0: 11616B4A  vcfsx v11, v13, 1
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (1 as u32)) << 23));
	for i in 0..4 {
		ctx.v[11].f32[i] = (ctx.v[13].s32[i] as f32) * scale;
	}
	// 8221CEE4: 11A06B4A  vcfsx v13, v13, 0
	let scale = f32::from_bits(((127u32 - (0 as u32)) << 23));
	for i in 0..4 {
		ctx.v[13].f32[i] = (ctx.v[13].s32[i] as f32) * scale;
	}
	// 8221CEE8: C01D0038  lfs f0, 0x38(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221CEEC: C1BD0030  lfs f13, 0x30(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D478(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D478 size=228
    let mut pc: u32 = 0x8221D478;
    'dispatch: loop {
        match pc {
            0x8221D478 => {
    //   block [0x8221D478..0x8221D4F0)
	// 8221D478: 3964FFFF  addi r11, r4, -1
	ctx.r[11].s64 = ctx.r[4].s64 + -1;
	// 8221D47C: 2B0B0014  cmplwi cr6, r11, 0x14
	ctx.cr[6].compare_u32(ctx.r[11].u32, 20 as u32, &mut ctx.xer);
	// 8221D480: 419900D0  bgt cr6, 0x8221d550
	if ctx.cr[6].gt {
	pc = 0x8221D550; continue 'dispatch;
	}
	// 8221D484: 3D808222  lis r12, -0x7dde
	ctx.r[12].s64 = -2111700992;
	// 8221D488: 398CD49C  addi r12, r12, -0x2b64
	ctx.r[12].s64 = ctx.r[12].s64 + -11108;
	// 8221D48C: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8221D490: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8221D494: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8221D498: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8221D4F0; continue 'dispatch;
		},
		1 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		2 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		3 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		4 => {
	pc = 0x8221D520; continue 'dispatch;
		},
		5 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		6 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		7 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		8 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		9 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		10 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		11 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		12 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		13 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		14 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		15 => {
	pc = 0x8221D530; continue 'dispatch;
		},
		16 => {
	pc = 0x8221D500; continue 'dispatch;
		},
		17 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		18 => {
	pc = 0x8221D550; continue 'dispatch;
		},
		19 => {
	pc = 0x8221D540; continue 'dispatch;
		},
		20 => {
	pc = 0x8221D510; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8221D49C: 8221D4F0  lwz r17, -0x2b10(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-11024 as u32) ) } as u64;
	// 8221D4A0: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4A4: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4A8: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4AC: 8221D520  lwz r17, -0x2ae0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10976 as u32) ) } as u64;
	// 8221D4B0: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4B4: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4B8: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4BC: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4C0: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4C4: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4C8: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4CC: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4D0: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4D4: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4D8: 8221D530  lwz r17, -0x2ad0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10960 as u32) ) } as u64;
	// 8221D4DC: 8221D500  lwz r17, -0x2b00(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-11008 as u32) ) } as u64;
	// 8221D4E0: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4E4: 8221D550  lwz r17, -0x2ab0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10928 as u32) ) } as u64;
	// 8221D4E8: 8221D540  lwz r17, -0x2ac0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10944 as u32) ) } as u64;
	// 8221D4EC: 8221D510  lwz r17, -0x2af0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10992 as u32) ) } as u64;
            }
            0x8221D4F0 => {
    //   block [0x8221D4F0..0x8221D500)
	// 8221D4F0: C003004C  lfs f0, 0x4c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D4F4: C1A30048  lfs f13, 0x48(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(72 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D4F8: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D4FC: 4E800020  blr
	return;
            }
            0x8221D500 => {
    //   block [0x8221D500..0x8221D510)
	// 8221D500: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D504: C1A30018  lfs f13, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D508: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D50C: 4E800020  blr
	return;
            }
            0x8221D510 => {
    //   block [0x8221D510..0x8221D520)
	// 8221D510: C0030034  lfs f0, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D514: C1A30030  lfs f13, 0x30(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D518: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D51C: 4E800020  blr
	return;
            }
            0x8221D520 => {
    //   block [0x8221D520..0x8221D530)
	// 8221D520: C0030064  lfs f0, 0x64(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(100 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D524: C1A30060  lfs f13, 0x60(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(96 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D528: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D52C: 4E800020  blr
	return;
            }
            0x8221D530 => {
    //   block [0x8221D530..0x8221D540)
	// 8221D530: C003007C  lfs f0, 0x7c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(124 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D534: C1A30078  lfs f13, 0x78(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(120 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D538: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D53C: 4E800020  blr
	return;
            }
            0x8221D540 => {
    //   block [0x8221D540..0x8221D550)
	// 8221D540: C0030094  lfs f0, 0x94(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(148 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D544: C1A30090  lfs f13, 0x90(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(144 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D548: EC206828  fsubs f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221D54C: 4E800020  blr
	return;
            }
            0x8221D550 => {
    //   block [0x8221D550..0x8221D55C)
	// 8221D550: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221D554: C02B1FF8  lfs f1, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221D558: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D560(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D560 size=40
    let mut pc: u32 = 0x8221D560;
    'dispatch: loop {
        match pc {
            0x8221D560 => {
    //   block [0x8221D560..0x8221D588)
	// 8221D560: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221D564: D0230018  stfs f1, 0x18(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221D568: D023001C  stfs f1, 0x1c(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8221D56C: D0230020  stfs f1, 0x20(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8221D570: C00B2150  lfs f0, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D574: E9630010  ld r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221D578: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221D57C: 4098000C  bge cr6, 0x8221d588
	if !ctx.cr[6].lt {
		sub_8221D588(ctx, base);
		return;
	}
	// 8221D580: 796B0724  rldicr r11, r11, 0, 0x3c
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(0) & 0xFFFFFFFFFFFFFFF8;
	// 8221D584: 48000008  b 0x8221d58c
	sub_8221D588(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D588 size=44
    let mut pc: u32 = 0x8221D588;
    'dispatch: loop {
        match pc {
            0x8221D588 => {
    //   block [0x8221D588..0x8221D5B4)
	// 8221D588: 616B0007  ori r11, r11, 7
	ctx.r[11].u64 = ctx.r[11].u64 | 7;
	// 8221D58C: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D590: D0230024  stfs f1, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8221D594: D0230028  stfs f1, 0x28(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 8221D598: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221D59C: D023002C  stfs f1, 0x2c(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 8221D5A0: E9630010  ld r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221D5A4: 40980010  bge cr6, 0x8221d5b4
	if !ctx.cr[6].lt {
		sub_8221D5B4(ctx, base);
		return;
	}
	// 8221D5A8: 3980FFC7  li r12, -0x39
	ctx.r[12].s64 = -57;
	// 8221D5AC: 7D6B6038  and r11, r11, r12
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[12].u64;
	// 8221D5B0: 48000008  b 0x8221d5b8
	sub_8221D5B4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D5B4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D5B4 size=44
    let mut pc: u32 = 0x8221D5B4;
    'dispatch: loop {
        match pc {
            0x8221D5B4 => {
    //   block [0x8221D5B4..0x8221D5E0)
	// 8221D5B4: 616B0038  ori r11, r11, 0x38
	ctx.r[11].u64 = ctx.r[11].u64 | 56;
	// 8221D5B8: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D5BC: D0230030  stfs f1, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221D5C0: D0230034  stfs f1, 0x34(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221D5C4: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221D5C8: D0230038  stfs f1, 0x38(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221D5CC: E9630010  ld r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221D5D0: 40980010  bge cr6, 0x8221d5e0
	if !ctx.cr[6].lt {
		sub_8221D5E0(ctx, base);
		return;
	}
	// 8221D5D4: 3980FE3F  li r12, -0x1c1
	ctx.r[12].s64 = -449;
	// 8221D5D8: 7D6B6038  and r11, r11, r12
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[12].u64;
	// 8221D5DC: 48000008  b 0x8221d5e4
	sub_8221D5E0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D5E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D5E0 size=44
    let mut pc: u32 = 0x8221D5E0;
    'dispatch: loop {
        match pc {
            0x8221D5E0 => {
    //   block [0x8221D5E0..0x8221D60C)
	// 8221D5E0: 616B01C0  ori r11, r11, 0x1c0
	ctx.r[11].u64 = ctx.r[11].u64 | 448;
	// 8221D5E4: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D5E8: D023003C  stfs f1, 0x3c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221D5EC: D0230040  stfs f1, 0x40(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8221D5F0: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221D5F4: D0230044  stfs f1, 0x44(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), tmp.u32 ) };
	// 8221D5F8: E9630010  ld r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221D5FC: 40980010  bge cr6, 0x8221d60c
	if !ctx.cr[6].lt {
		sub_8221D60C(ctx, base);
		return;
	}
	// 8221D600: 3980F1FF  li r12, -0xe01
	ctx.r[12].s64 = -3585;
	// 8221D604: 7D6B6038  and r11, r11, r12
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[12].u64;
	// 8221D608: 48000008  b 0x8221d610
	sub_8221D60C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D60C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D60C size=48
    let mut pc: u32 = 0x8221D60C;
    'dispatch: loop {
        match pc {
            0x8221D60C => {
    //   block [0x8221D60C..0x8221D63C)
	// 8221D60C: 616B0E00  ori r11, r11, 0xe00
	ctx.r[11].u64 = ctx.r[11].u64 | 3584;
	// 8221D610: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D614: D0230048  stfs f1, 0x48(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8221D618: D023004C  stfs f1, 0x4c(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 8221D61C: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8221D620: D0230050  stfs f1, 0x50(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8221D624: E9630010  ld r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	// 8221D628: 40980014  bge cr6, 0x8221d63c
	if !ctx.cr[6].lt {
		sub_8221D63C(ctx, base);
		return;
	}
	// 8221D62C: 39808FFF  li r12, -0x7001
	ctx.r[12].s64 = -28673;
	// 8221D630: 7D6B6038  and r11, r11, r12
	ctx.r[11].u64 = ctx.r[11].u64 & ctx.r[12].u64;
	// 8221D634: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D638: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D63C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221D63C size=12
    let mut pc: u32 = 0x8221D63C;
    'dispatch: loop {
        match pc {
            0x8221D63C => {
    //   block [0x8221D63C..0x8221D648)
	// 8221D63C: 616B7000  ori r11, r11, 0x7000
	ctx.r[11].u64 = ctx.r[11].u64 | 28672;
	// 8221D640: F9630010  std r11, 0x10(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 8221D644: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221D648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221D648 size=1112
    let mut pc: u32 = 0x8221D648;
    'dispatch: loop {
        match pc {
            0x8221D648 => {
    //   block [0x8221D648..0x8221D7D0)
	// 8221D648: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8221D64C: 3D40803F  lis r10, -0x7fc1
	ctx.r[10].s64 = -2143354880;
	// 8221D650: F8A10020  std r5, 0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(32 as u32), ctx.r[5].u64 ) };
	// 8221D654: 39640040  addi r11, r4, 0x40
	ctx.r[11].s64 = ctx.r[4].s64 + 64;
	// 8221D658: 6144FFFE  ori r4, r10, 0xfffe
	ctx.r[4].u64 = ctx.r[10].u64 | 65534;
	// 8221D65C: 3D401FFF  lis r10, 0x1fff
	ctx.r[10].s64 = 536805376;
	// 8221D660: 3CE0820A  lis r7, -0x7df6
	ctx.r[7].s64 = -2113273856;
	// 8221D664: 614AFFFF  ori r10, r10, 0xffff
	ctx.r[10].u64 = ctx.r[10].u64 | 65535;
	// 8221D668: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8221D66C: 7944000E  rldimi r4, r10, 0x20, 0
	ctx.r[4].u64 = ((ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFF00000000) | (ctx.r[4].u64 & 0x00000000FFFFFFFF);
	// 8221D670: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8221D674: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221D678: C0E7BA38  lfs f7, -0x45c8(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8221D67C: 38C00060  li r6, 0x60
	ctx.r[6].s64 = 96;
	// 8221D680: C0081FF8  lfs f0, 0x1ff8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221D684: 38A02000  li r5, 0x2000
	ctx.r[5].s64 = 8192;
	// 8221D688: C18926B8  lfs f12, 0x26b8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(9912 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221D68C: C0CA2150  lfs f6, 0x2150(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8528 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8221D690: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D694: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 8221D698: ED2B02F2  fmuls f9, f11, f11
	ctx.f[9].f64 = (((ctx.f[11].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221D69C: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D6A0: C16B0014  lfs f11, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D6A4: ED6B02F2  fmuls f11, f11, f11
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221D6A8: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D6AC: C10B0024  lfs f8, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8221D6B0: ED080232  fmuls f8, f8, f8
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[8].f64) as f32) as f64);
	// 8221D6B4: EDAD4B7A  fmadds f13, f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64);
	// 8221D6B8: C12B0018  lfs f9, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221D6BC: ED695A7A  fmadds f11, f9, f9, f11
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64);
	// 8221D6C0: C12B0028  lfs f9, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221D6C4: ED29427A  fmadds f9, f9, f9, f8
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64);
	// 8221D6C8: EDAA6ABA  fmadds f13, f10, f10, f13
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221D6CC: C14B0010  lfs f10, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D6D0: ED6A5ABA  fmadds f11, f10, f10, f11
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 8221D6D4: C14B0020  lfs f10, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D6D8: ED4A4ABA  fmadds f10, f10, f10, f9
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64);
	// 8221D6DC: EDA0682C  fsqrts f13, f13
	ctx.f[13].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 8221D6E0: FCA06A10  fabs f5, f13
	ctx.f[5].u64 = ctx.f[13].u64 & !0x8000_0000_0000_0000u64;
	// 8221D6E4: ED60582C  fsqrts f11, f11
	ctx.f[11].f64 = ((ctx.f[11].f64).sqrt() as f32) as f64;
	// 8221D6E8: FF053000  fcmpu cr6, f5, f6
	ctx.cr[6].compare_f64(ctx.f[5].f64, ctx.f[6].f64);
	// 8221D6EC: ED40502C  fsqrts f10, f10
	ctx.f[10].f64 = ((ctx.f[10].f64).sqrt() as f32) as f64;
	// 8221D6F0: 41980008  blt cr6, 0x8221d6f8
	if ctx.cr[6].lt {
	pc = 0x8221D6F8; continue 'dispatch;
	}
	// 8221D6F4: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8221D6F8: FD205A10  fabs f9, f11
	ctx.f[9].u64 = ctx.f[11].u64 & !0x8000_0000_0000_0000u64;
	// 8221D6FC: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8221D700: FF093000  fcmpu cr6, f9, f6
	ctx.cr[6].compare_f64(ctx.f[9].f64, ctx.f[6].f64);
	// 8221D704: 41980008  blt cr6, 0x8221d70c
	if ctx.cr[6].lt {
	pc = 0x8221D70C; continue 'dispatch;
	}
	// 8221D708: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8221D70C: FD205210  fabs f9, f10
	ctx.f[9].u64 = ctx.f[10].u64 & !0x8000_0000_0000_0000u64;
	// 8221D710: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8221D714: FF093000  fcmpu cr6, f9, f6
	ctx.cr[6].compare_f64(ctx.f[9].f64, ctx.f[6].f64);
	// 8221D718: 41980008  blt cr6, 0x8221d720
	if ctx.cr[6].lt {
	pc = 0x8221D720; continue 'dispatch;
	}
	// 8221D71C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8221D720: ED2D0332  fmuls f9, f13, f12
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221D724: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8221D728: ED0B0332  fmuls f8, f11, f12
	ctx.f[8].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221D72C: ECAA0332  fmuls f5, f10, f12
	ctx.f[5].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221D730: 7D4A4B78  or r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 8221D734: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8221D738: 7D4A4378  or r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[8].u64;
	// 8221D73C: 554A063E  clrlwi r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8221D740: FD20481E  fctiwz f9, f9
	ctx.f[9].s64 = if ctx.f[9].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[9].f64.trunc() as i32 as i64 };
	// 8221D744: D921FFB0  stfd f9, -0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), ctx.f[9].u64 ) };
	// 8221D748: FD20401E  fctiwz f9, f8
	ctx.f[9].s64 = if ctx.f[8].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[8].f64.trunc() as i32 as i64 };
	// 8221D74C: D921FFB8  stfd f9, -0x48(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[9].u64 ) };
	// 8221D750: FD20281E  fctiwz f9, f5
	ctx.f[9].s64 = if ctx.f[5].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[5].f64.trunc() as i32 as i64 };
	// 8221D754: D921FFC0  stfd f9, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[9].u64 ) };
	// 8221D758: 9943001A  stb r10, 0x1a(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(26 as u32), ctx.r[10].u8 ) };
	// 8221D75C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8221D760: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8221D764: 2B090006  cmplwi cr6, r9, 6
	ctx.cr[6].compare_u32(ctx.r[9].u32, 6 as u32, &mut ctx.xer);
	// 8221D768: A101FFB6  lhz r8, -0x4a(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[1].u32.wrapping_add(-74 as u32) ) } as u64;
	// 8221D76C: A0E1FFBE  lhz r7, -0x42(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[1].u32.wrapping_add(-66 as u32) ) } as u64;
	// 8221D770: A3E1FFC6  lhz r31, -0x3a(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[1].u32.wrapping_add(-58 as u32) ) } as u64;
	// 8221D774: B103000C  sth r8, 0xc(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[8].u16 ) };
	// 8221D778: B0E3000E  sth r7, 0xe(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(14 as u32), ctx.r[7].u16 ) };
	// 8221D77C: B3E30010  sth r31, 0x10(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[31].u16 ) };
	// 8221D780: C12B0030  lfs f9, 0x30(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221D784: D1230000  stfs f9, 0(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221D788: C12B0034  lfs f9, 0x34(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221D78C: D1230004  stfs f9, 4(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221D790: C12B0038  lfs f9, 0x38(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8221D794: D1230008  stfs f9, 8(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221D798: 41990158  bgt cr6, 0x8221d8f0
	if ctx.cr[6].gt {
	pc = 0x8221D8F0; continue 'dispatch;
	}
	// 8221D79C: 3D808222  lis r12, -0x7dde
	ctx.r[12].s64 = -2111700992;
	// 8221D7A0: 398CD7B4  addi r12, r12, -0x284c
	ctx.r[12].s64 = ctx.r[12].s64 + -10316;
	// 8221D7A4: 5520103A  slwi r0, r9, 2
	ctx.r[0].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8221D7A8: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8221D7AC: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8221D7B0: 4E800420  bctr
	match ctx.r[9].u64 {
		0 => {
	pc = 0x8221D7D0; continue 'dispatch;
		},
		1 => {
	pc = 0x8221D804; continue 'dispatch;
		},
		2 => {
	pc = 0x8221D83C; continue 'dispatch;
		},
		3 => {
	pc = 0x8221D8F0; continue 'dispatch;
		},
		4 => {
	pc = 0x8221D8A4; continue 'dispatch;
		},
		5 => {
	pc = 0x8221D870; continue 'dispatch;
		},
		6 => {
	pc = 0x8221D8C4; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8221D7B4: 8221D7D0  lwz r17, -0x2830(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10288 as u32) ) } as u64;
	// 8221D7B8: 8221D804  lwz r17, -0x27fc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10236 as u32) ) } as u64;
	// 8221D7BC: 8221D83C  lwz r17, -0x27c4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10180 as u32) ) } as u64;
	// 8221D7C0: 8221D8F0  lwz r17, -0x2710(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10000 as u32) ) } as u64;
	// 8221D7C4: 8221D8A4  lwz r17, -0x275c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10076 as u32) ) } as u64;
	// 8221D7C8: 8221D870  lwz r17, -0x2790(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10128 as u32) ) } as u64;
	// 8221D7CC: 8221D8C4  lwz r17, -0x273c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-10044 as u32) ) } as u64;
            }
            0x8221D7D0 => {
    //   block [0x8221D7D0..0x8221D804)
	// 8221D7D0: C1AB0020  lfs f13, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D7D4: D1A1FFE0  stfs f13, -0x20(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D7D8: EDAC5024  fdivs f13, f12, f10
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[10].f64) as f32) as f64;
	// 8221D7DC: C14B0024  lfs f10, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D7E0: D141FFE4  stfs f10, -0x1c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D7E4: C14B0028  lfs f10, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D7E8: D141FFE8  stfs f10, -0x18(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D7EC: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D7F0: D141FFD0  stfs f10, -0x30(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D7F4: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D7F8: D141FFD4  stfs f10, -0x2c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D7FC: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D800: 48000120  b 0x8221d920
	pc = 0x8221D920; continue 'dispatch;
            }
            0x8221D804 => {
    //   block [0x8221D804..0x8221D83C)
	// 8221D804: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D808: EDAC6824  fdivs f13, f12, f13
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[13].f64) as f32) as f64;
	// 8221D80C: D161FFE0  stfs f11, -0x20(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D810: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D814: D161FFE4  stfs f11, -0x1c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D818: ED6C5024  fdivs f11, f12, f10
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[10].f64) as f32) as f64;
	// 8221D81C: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D820: D141FFE8  stfs f10, -0x18(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D824: C14B0020  lfs f10, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D828: D141FFD0  stfs f10, -0x30(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D82C: C14B0024  lfs f10, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D830: D141FFD4  stfs f10, -0x2c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D834: C14B0028  lfs f10, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D838: 480000EC  b 0x8221d924
	pc = 0x8221D924; continue 'dispatch;
            }
            0x8221D83C => {
    //   block [0x8221D83C..0x8221D870)
	// 8221D83C: C1AB0020  lfs f13, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D840: D1A1FFE0  stfs f13, -0x20(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D844: EDAC5024  fdivs f13, f12, f10
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[10].f64) as f32) as f64;
	// 8221D848: C16B0024  lfs f11, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D84C: C14B0028  lfs f10, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D850: D161FFE4  stfs f11, -0x1c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D854: FD600090  fmr f11, f0
	ctx.f[11].f64 = ctx.f[0].f64;
	// 8221D858: D141FFE8  stfs f10, -0x18(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D85C: D001FFD0  stfs f0, -0x30(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D860: D001FFD4  stfs f0, -0x2c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D864: D001FFD8  stfs f0, -0x28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), tmp.u32 ) };
	// 8221D868: D0E1FFDC  stfs f7, -0x24(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-36 as u32), tmp.u32 ) };
	// 8221D86C: 480000BC  b 0x8221d928
	pc = 0x8221D928; continue 'dispatch;
            }
            0x8221D870 => {
    //   block [0x8221D870..0x8221D8A4)
	// 8221D870: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D874: EDAC6824  fdivs f13, f12, f13
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[13].f64) as f32) as f64;
	// 8221D878: D161FFE0  stfs f11, -0x20(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D87C: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221D880: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D884: D161FFE4  stfs f11, -0x1c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D888: FD600090  fmr f11, f0
	ctx.f[11].f64 = ctx.f[0].f64;
	// 8221D88C: D141FFE8  stfs f10, -0x18(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D890: D001FFD0  stfs f0, -0x30(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D894: D001FFD4  stfs f0, -0x2c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D898: D001FFD8  stfs f0, -0x28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), tmp.u32 ) };
	// 8221D89C: D0E1FFDC  stfs f7, -0x24(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-36 as u32), tmp.u32 ) };
	// 8221D8A0: 48000088  b 0x8221d928
	pc = 0x8221D928; continue 'dispatch;
            }
            0x8221D8A4 => {
    //   block [0x8221D8A4..0x8221D8C4)
	// 8221D8A4: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221D8A8: D1A1FFD0  stfs f13, -0x30(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D8AC: FDA00090  fmr f13, f0
	ctx.f[13].f64 = ctx.f[0].f64;
	// 8221D8B0: D001FFE0  stfs f0, -0x20(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D8B4: D001FFE4  stfs f0, -0x1c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D8B8: D001FFE8  stfs f0, -0x18(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D8BC: D0E1FFEC  stfs f7, -0x14(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-20 as u32), tmp.u32 ) };
	// 8221D8C0: 48000054  b 0x8221d914
	pc = 0x8221D914; continue 'dispatch;
            }
            0x8221D8C4 => {
    //   block [0x8221D8C4..0x8221D8F0)
	// 8221D8C4: D001FFE0  stfs f0, -0x20(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D8C8: FDA00090  fmr f13, f0
	ctx.f[13].f64 = ctx.f[0].f64;
	// 8221D8CC: D001FFE4  stfs f0, -0x1c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D8D0: FD600090  fmr f11, f0
	ctx.f[11].f64 = ctx.f[0].f64;
	// 8221D8D4: D001FFE8  stfs f0, -0x18(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D8D8: D0E1FFEC  stfs f7, -0x14(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-20 as u32), tmp.u32 ) };
	// 8221D8DC: D001FFD0  stfs f0, -0x30(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D8E0: D001FFD4  stfs f0, -0x2c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D8E4: D001FFD8  stfs f0, -0x28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), tmp.u32 ) };
	// 8221D8E8: D0E1FFDC  stfs f7, -0x24(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-36 as u32), tmp.u32 ) };
	// 8221D8EC: 4800003C  b 0x8221d928
	pc = 0x8221D928; continue 'dispatch;
            }
            0x8221D8F0 => {
    //   block [0x8221D8F0..0x8221DAA0)
	// 8221D8F0: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D8F4: EDAC6824  fdivs f13, f12, f13
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[13].f64) as f32) as f64;
	// 8221D8F8: D141FFE0  stfs f10, -0x20(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221D8FC: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D900: D141FFE4  stfs f10, -0x1c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221D904: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D908: D141FFE8  stfs f10, -0x18(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 8221D90C: C14B0010  lfs f10, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D910: D141FFD0  stfs f10, -0x30(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), tmp.u32 ) };
	// 8221D914: C14B0014  lfs f10, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D918: D141FFD4  stfs f10, -0x2c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221D91C: C14B0018  lfs f10, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221D920: ED6C5824  fdivs f11, f12, f11
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[11].f64) as f32) as f64;
	// 8221D924: D141FFD8  stfs f10, -0x28(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), tmp.u32 ) };
	// 8221D928: 788A07E0  clrldi r10, r4, 0x3f
	ctx.r[10].u64 = ctx.r[4].u64 & 0x0000000000000001u64;
	// 8221D92C: 2B2A0000  cmpldi cr6, r10, 0
	ctx.cr[6].compare_u64(ctx.r[10].u64, 0, &mut ctx.xer);
	// 8221D930: 419A00B4  beq cr6, 0x8221d9e4
	if ctx.cr[6].eq {
	pc = 0x8221D9E4; continue 'dispatch;
	}
	// 8221D934: 3941FFE0  addi r10, r1, -0x20
	ctx.r[10].s64 = ctx.r[1].s64 + -32;
	// 8221D938: 11A1038C  vspltisw v13, 1
	for i in 0..4 {
		ctx.v[13].u32[i] = 1;
	}
	// 8221D93C: 3921FFD0  addi r9, r1, -0x30
	ctx.r[9].s64 = ctx.r[1].s64 + -48;
	// 8221D940: B0A30010  sth r5, 0x10(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[5].u16 ) };
	// 8221D944: 3901FFE0  addi r8, r1, -0x20
	ctx.r[8].s64 = ctx.r[1].s64 + -32;
	// 8221D948: B0A3000E  sth r5, 0xe(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(14 as u32), ctx.r[5].u16 ) };
	// 8221D94C: B0A3000C  sth r5, 0xc(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[5].u16 ) };
	// 8221D950: FDA06090  fmr f13, f12
	ctx.f[13].f64 = ctx.f[12].f64;
	// 8221D954: 10016B4A  vcfsx v0, v13, 1
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (1 as u32)) << 23));
	for i in 0..4 {
		ctx.v[0].f32[i] = (ctx.v[13].s32[i] as f32) * scale;
	}
	// 8221D958: FD606090  fmr f11, f12
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[11].f64 = ctx.f[12].f64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221DAA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221DAA0 size=1864
    let mut pc: u32 = 0x8221DAA0;
    'dispatch: loop {
        match pc {
            0x8221DAA0 => {
    //   block [0x8221DAA0..0x8221E1E8)
	// 8221DAA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221DAA4: 4831760D  bl 0x825350b0
	ctx.lr = 0x8221DAA8;
	sub_82535080(ctx, base);
	// 8221DAA8: 3981FFC8  addi r12, r1, -0x38
	ctx.r[12].s64 = ctx.r[1].s64 + -56;
	// 8221DAAC: 48318509  bl 0x82535fb4
	ctx.lr = 0x8221DAB0;
	sub_82535FB0(ctx, base);
	// 8221DAB0: 9421FDC0  stwu r1, -0x240(r1)
	ea = ctx.r[1].u32.wrapping_add(-576 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221DAB4: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8221DAB8: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8221DABC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221DAC0: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 8221DAC4: 4831660D  bl 0x825340d0
	ctx.lr = 0x8221DAC8;
	sub_825340D0(ctx, base);
	// 8221DAC8: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8221DACC: C261007C  lfs f19, 0x7c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 8221DAD0: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221DAD4: C1E1006C  lfs f15, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 8221DAD8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221DADC: FFC00818  frsp f30, f1
	ctx.f[30].f64 = (ctx.f[1].f64 as f32) as f64;
	// 8221DAE0: 3BDC0012  addi r30, r28, 0x12
	ctx.r[30].s64 = ctx.r[28].s64 + 18;
	// 8221DAE4: 3BFF0040  addi r31, r31, 0x40
	ctx.r[31].s64 = ctx.r[31].s64 + 64;
	// 8221DAE8: C389BA38  lfs f28, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8221DAEC: 3B400060  li r26, 0x60
	ctx.r[26].s64 = 96;
	// 8221DAF0: C3AA1FF8  lfs f29, 0x1ff8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221DAF4: 3BBB0008  addi r29, r27, 8
	ctx.r[29].s64 = ctx.r[27].s64 + 8;
	// 8221DAF8: C28B290C  lfs f20, 0x290c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10508 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 8221DAFC: 7F9BE050  subf r28, r27, r28
	ctx.r[28].s64 = ctx.r[28].s64 - ctx.r[27].s64;
	// 8221DB00: 897E0008  lbz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8221DB04: C25EFFEE  lfs f18, -0x12(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-18 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 8221DB08: C23EFFF2  lfs f17, -0xe(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-14 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 8221DB0C: 7D690774  extsb r9, r11
	ctx.r[9].s64 = ctx.r[11].s8 as i64;
	// 8221DB10: 7E1CEC2E  lfsx f16, r28, r29
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[29].u32)) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 8221DB14: D39F003C  stfs f28, 0x3c(r31)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221DB18: D25F0030  stfs f18, 0x30(r31)
	tmp.f32 = (ctx.f[18].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221DB1C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8221DB20: D23F0034  stfs f17, 0x34(r31)
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221DB24: D21F0038  stfs f16, 0x38(r31)
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221DB28: 409A012C  bne cr6, 0x8221dc54
	if !ctx.cr[6].eq {
	pc = 0x8221DC54; continue 'dispatch;
	}
	// 8221DB2C: A17E0000  lhz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221DB30: A15E0002  lhz r10, 2(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(2 as u32) ) } as u64;
	// 8221DB34: 7D670734  extsh r7, r11
	ctx.r[7].s64 = ctx.r[11].s16 as i64;
	// 8221DB38: 891E0009  lbz r8, 9(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(9 as u32) ) } as u64;
	// 8221DB3C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8221DB40: 7D0B0774  extsb r11, r8
	ctx.r[11].s64 = ctx.r[8].s8 as i64;
	// 8221DB44: F8E10130  std r7, 0x130(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[7].u64 ) };
	// 8221DB48: F94100F8  std r10, 0xf8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), ctx.r[10].u64 ) };
	// 8221DB4C: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 8221DB50: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8221DB54: C8010130  lfd f0, 0x130(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) };
	// 8221DB58: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8221DB5C: C9A100F8  lfd f13, 0xf8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) };
	// 8221DB60: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221DB64: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8221DB68: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8221DB6C: ED200532  fmuls f9, f0, f20
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[20].f64) as f32) as f64);
	// 8221DB70: D1210070  stfs f9, 0x70(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8221DB74: ED0D0532  fmuls f8, f13, f20
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[20].f64) as f32) as f64);
	// 8221DB78: D1010074  stfs f8, 0x74(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 8221DB7C: EC090272  fmuls f0, f9, f9
	ctx.f[0].f64 = (((ctx.f[9].f64 * ctx.f[9].f64) as f32) as f64);
	// 8221DB80: EC08023A  fmadds f0, f8, f8, f0
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221DB84: EC1C0028  fsubs f0, f28, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 - ctx.f[0].f64) as f32) as f64);
	// 8221DB88: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8221DB8C: 409A000C  bne cr6, 0x8221db98
	if !ctx.cr[6].eq {
	pc = 0x8221DB98; continue 'dispatch;
	}
	// 8221DB90: ECC0002C  fsqrts f6, f0
	ctx.f[6].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8221DB94: 4800000C  b 0x8221dba0
	pc = 0x8221DBA0; continue 'dispatch;
	// 8221DB98: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8221DB9C: FCC00050  fneg f6, f0
	ctx.f[6].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221DBA0: A15E0004  lhz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8221DBA4: 556B07BC  rlwinm r11, r11, 0, 0x1e, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8221DBA8: A11E0006  lhz r8, 6(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(6 as u32) ) } as u64;
	// 8221DBAC: D0C10078  stfs f6, 0x78(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8221DBB0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8221DBB4: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8221DBB8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221DBBC: F9410108  std r10, 0x108(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), ctx.r[10].u64 ) };
	// 8221DBC0: F9010118  std r8, 0x118(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[8].u64 ) };
	// 8221DBC4: C8010108  lfd f0, 0x108(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) };
	// 8221DBC8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8221DBCC: C9A10118  lfd f13, 0x118(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) };
	// 8221DBD0: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8221DBD4: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8221DBD8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8221DBDC: ED600532  fmuls f11, f0, f20
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[20].f64) as f32) as f64);
	// 8221DBE0: D1610060  stfs f11, 0x60(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8221DBE4: ED4D0532  fmuls f10, f13, f20
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[20].f64) as f32) as f64);
	// 8221DBE8: D1410064  stfs f10, 0x64(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8221DBEC: EC0B02F2  fmuls f0, f11, f11
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221DBF0: EC0A02BA  fmadds f0, f10, f10, f0
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64);
	// 8221DBF4: EC1C0028  fsubs f0, f28, f0
	ctx.f[0].f64 = (((ctx.f[28].f64 - ctx.f[0].f64) as f32) as f64);
	// 8221DBF8: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8221DBFC: 409A000C  bne cr6, 0x8221dc08
	if !ctx.cr[6].eq {
	pc = 0x8221DC08; continue 'dispatch;
	}
	// 8221DC00: ECE0002C  fsqrts f7, f0
	ctx.f[7].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8221DC04: 4800000C  b 0x8221dc10
	pc = 0x8221DC10; continue 'dispatch;
	// 8221DC08: EC00002C  fsqrts f0, f0
	ctx.f[0].f64 = ((ctx.f[0].f64).sqrt() as f32) as f64;
	// 8221DC0C: FCE00050  fneg f7, f0
	ctx.f[7].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221DC10: D0E10068  stfs f7, 0x68(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8221DC14: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E1E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221E1E8 size=284
    let mut pc: u32 = 0x8221E1E8;
    'dispatch: loop {
        match pc {
            0x8221E1E8 => {
    //   block [0x8221E1E8..0x8221E304)
	// 8221E1E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221E1EC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221E1F0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8221E1F4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8221E1F8: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8221E1FC: 9421F790  stwu r1, -0x870(r1)
	ea = ctx.r[1].u32.wrapping_add(-2160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221E200: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8221E204: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221E208: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8221E20C: 3940001F  li r10, 0x1f
	ctx.r[10].s64 = 31;
	// 8221E210: 39610278  addi r11, r1, 0x278
	ctx.r[11].s64 = ctx.r[1].s64 + 632;
	// 8221E214: C3E9BA38  lfs f31, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221E218: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8221E21C: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221E220: D3EB0000  stfs f31, 0(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221E224: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8221E228: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8221E22C: D3EBFFF8  stfs f31, -8(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8221E230: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8221E234: 4098FFE4  bge cr6, 0x8221e218
	if !ctx.cr[6].lt {
	pc = 0x8221E218; continue 'dispatch;
	}
	// 8221E238: 38A00600  li r5, 0x600
	ctx.r[5].s64 = 1536;
	// 8221E23C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8221E240: 38610250  addi r3, r1, 0x250
	ctx.r[3].s64 = ctx.r[1].s64 + 592;
	// 8221E244: 48316F8D  bl 0x825351d0
	ctx.lr = 0x8221E248;
	sub_825351D0(ctx, base);
	// 8221E248: 38A00200  li r5, 0x200
	ctx.r[5].s64 = 512;
	// 8221E24C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8221E250: 38610250  addi r3, r1, 0x250
	ctx.r[3].s64 = ctx.r[1].s64 + 592;
	// 8221E254: 48316F7D  bl 0x825351d0
	ctx.lr = 0x8221E258;
	sub_825351D0(ctx, base);
	// 8221E258: 3941005C  addi r10, r1, 0x5c
	ctx.r[10].s64 = ctx.r[1].s64 + 92;
	// 8221E25C: 39600020  li r11, 0x20
	ctx.r[11].s64 = 32;
	// 8221E260: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8221E264: D3EA0000  stfs f31, 0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221E268: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 8221E26C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221E270: 409AFFF0  bne cr6, 0x8221e260
	if !ctx.cr[6].eq {
	pc = 0x8221E260; continue 'dispatch;
	}
	// 8221E274: 3D608286  lis r11, -0x7d7a
	ctx.r[11].s64 = -2105147392;
	// 8221E278: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8221E27C: 38CBF360  addi r6, r11, -0xca0
	ctx.r[6].s64 = ctx.r[11].s64 + -3232;
	// 8221E280: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221E284: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8221E288: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8221E28C: 38810250  addi r4, r1, 0x250
	ctx.r[4].s64 = ctx.r[1].s64 + 592;
	// 8221E290: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221E294: C04B1FF8  lfs f2, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221E298: FC201090  fmr f1, f2
	ctx.f[1].f64 = ctx.f[2].f64;
	// 8221E29C: 4BFF63C5  bl 0x82214660
	ctx.lr = 0x8221E2A0;
	sub_82214660(ctx, base);
	// 8221E2A0: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8221E2A4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8221E2A8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221E2AC: 4099003C  ble cr6, 0x8221e2e8
	if !ctx.cr[6].gt {
	pc = 0x8221E2E8; continue 'dispatch;
	}
	// 8221E2B0: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 8221E2B4: 39610260  addi r11, r1, 0x260
	ctx.r[11].s64 = ctx.r[1].s64 + 608;
	// 8221E2B8: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 8221E2BC: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8221E2C0: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8221E2C4: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8221E2C8: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 8221E2CC: E8C80000  ld r6, 0(r8)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	// 8221E2D0: E9080008  ld r8, 8(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) };
	// 8221E2D4: F8C70000  std r6, 0(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[6].u64 ) };
	// 8221E2D8: F9070008  std r8, 8(r7)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[8].u64 ) };
	// 8221E2DC: 811F0010  lwz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8221E2E0: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8221E2E4: 4198FFD4  blt cr6, 0x8221e2b8
	if ctx.cr[6].lt {
	pc = 0x8221E2B8; continue 'dispatch;
	}
	// 8221E2E8: 38210870  addi r1, r1, 0x870
	ctx.r[1].s64 = ctx.r[1].s64 + 2160;
	// 8221E2EC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E2F0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E2F4: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8221E2F8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8221E2FC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E300: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E308(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E308 size=48
    let mut pc: u32 = 0x8221E308;
    'dispatch: loop {
        match pc {
            0x8221E308 => {
    //   block [0x8221E308..0x8221E338)
	// 8221E308: 38E0FFFF  li r7, -1
	ctx.r[7].s64 = -1;
	// 8221E30C: 39630210  addi r11, r3, 0x210
	ctx.r[11].s64 = ctx.r[3].s64 + 528;
	// 8221E310: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 8221E314: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 8221E318: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8221E31C: F92B0000  std r9, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8221E320: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8221E324: 4200FFF8  bdnz 0x8221e31c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8221E31C; continue 'dispatch;
	}
	// 8221E328: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8221E32C: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 8221E330: F9630000  std r11, 0(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 8221E334: 4C990020  blelr cr6
	if !ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E338(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221E338 size=96
    let mut pc: u32 = 0x8221E338;
    'dispatch: loop {
        match pc {
            0x8221E338 => {
    //   block [0x8221E338..0x8221E398)
	// 8221E338: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8221E33C: 3944004E  addi r10, r4, 0x4e
	ctx.r[10].s64 = ctx.r[4].s64 + 78;
	// 8221E340: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 8221E344: C00BBA38  lfs f0, -0x45c8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E348: 896AFFFD  lbz r11, -3(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(-3 as u32) ) } as u64;
	// 8221E34C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 8221E350: 40980068  bge cr6, 0x8221e3b8
	if !ctx.cr[6].lt {
		sub_8221E398(ctx, base);
		return;
	}
	// 8221E354: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221E358: C1AAFFC2  lfs f13, -0x3e(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-62 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221E35C: 552B203E  rotlwi r11, r9, 4
	ctx.r[11].u64 = ((ctx.r[9].u32).rotate_left(4)) as u64;
	// 8221E360: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8221E364: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221E368: C1AAFFC6  lfs f13, -0x3a(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-58 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221E36C: D1AB0014  stfs f13, 0x14(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8221E370: C1AAFFCA  lfs f13, -0x36(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-54 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221E374: D1AB0018  stfs f13, 0x18(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221E378: D00B001C  stfs f0, 0x1c(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8221E37C: A16AFFFE  lhz r11, -2(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(-2 as u32) ) } as u64;
	// 8221E380: 2B0BFFFF  cmplwi cr6, r11, 0xffff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65535 as u32, &mut ctx.xer);
	// 8221E384: 409A0014  bne cr6, 0x8221e398
	if !ctx.cr[6].eq {
		sub_8221E398(ctx, base);
		return;
	}
	// 8221E388: 39690108  addi r11, r9, 0x108
	ctx.r[11].s64 = ctx.r[9].s64 + 264;
	// 8221E38C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221E390: 7CEB1B2E  sthx r7, r11, r3
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), ctx.r[7].u16) };
	// 8221E394: 48000010  b 0x8221e3a4
	sub_8221E398(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E398(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E398 size=52
    let mut pc: u32 = 0x8221E398;
    'dispatch: loop {
        match pc {
            0x8221E398 => {
    //   block [0x8221E398..0x8221E3CC)
	// 8221E398: 38C90108  addi r6, r9, 0x108
	ctx.r[6].s64 = ctx.r[9].s64 + 264;
	// 8221E39C: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8221E3A0: 7D661B2E  sthx r11, r6, r3
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[6].u32.wrapping_add(ctx.r[3].u32), ctx.r[11].u16) };
	// 8221E3A4: 7D2B07B4  extsw r11, r9
	ctx.r[11].s64 = ctx.r[9].s32 as i64;
	// 8221E3A8: E9230000  ld r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	// 8221E3AC: 7D0B5836  sld r11, r8, r11
	if (ctx.r[11].u8 & 0x40) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = (ctx.r[8].u64) << ((ctx.r[11].u8 & 0x3F) as u32);
	}
	// 8221E3B0: 7D6B4B78  or r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[9].u64;
	// 8221E3B4: F9630000  std r11, 0(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 8221E3B8: 38A5FFFF  addi r5, r5, -1
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	// 8221E3BC: 394A0050  addi r10, r10, 0x50
	ctx.r[10].s64 = ctx.r[10].s64 + 80;
	// 8221E3C0: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8221E3C4: 409AFF84  bne cr6, 0x8221e348
	if !ctx.cr[6].eq {
		sub_8221E338(ctx, base);
		return;
	}
	// 8221E3C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E3D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221E3D0 size=304
    let mut pc: u32 = 0x8221E3D0;
    'dispatch: loop {
        match pc {
            0x8221E3D0 => {
    //   block [0x8221E3D0..0x8221E500)
	// 8221E3D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221E3D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221E3D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8221E3DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8221E3E0: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8221E3E4: 9421F390  stwu r1, -0xc70(r1)
	ea = ctx.r[1].u32.wrapping_add(-3184 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221E3E8: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8221E3EC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221E3F0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8221E3F4: 3940003F  li r10, 0x3f
	ctx.r[10].s64 = 63;
	// 8221E3F8: 39610078  addi r11, r1, 0x78
	ctx.r[11].s64 = ctx.r[1].s64 + 120;
	// 8221E3FC: C3E9BA38  lfs f31, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221E400: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8221E404: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221E408: D3EB0000  stfs f31, 0(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221E40C: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8221E410: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8221E414: D3EBFFF8  stfs f31, -8(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8221E418: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8221E41C: 4098FFE4  bge cr6, 0x8221e400
	if !ctx.cr[6].lt {
	pc = 0x8221E400; continue 'dispatch;
	}
	// 8221E420: 38A00C00  li r5, 0xc00
	ctx.r[5].s64 = 3072;
	// 8221E424: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8221E428: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221E42C: 48316DA5  bl 0x825351d0
	ctx.lr = 0x8221E430;
	sub_825351D0(ctx, base);
	// 8221E430: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 8221E434: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8221E438: 38CBACD0  addi r6, r11, -0x5330
	ctx.r[6].s64 = ctx.r[11].s64 + -21296;
	// 8221E43C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221E440: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8221E444: 38BF0010  addi r5, r31, 0x10
	ctx.r[5].s64 = ctx.r[31].s64 + 16;
	// 8221E448: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221E44C: 387F0290  addi r3, r31, 0x290
	ctx.r[3].s64 = ctx.r[31].s64 + 656;
	// 8221E450: C04B1FF8  lfs f2, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221E454: FC201090  fmr f1, f2
	ctx.f[1].f64 = ctx.f[2].f64;
	// 8221E458: 4BFF6209  bl 0x82214660
	ctx.lr = 0x8221E45C;
	sub_82214660(ctx, base);
	// 8221E45C: E8FF0000  ld r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	// 8221E460: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8221E464: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 8221E468: 419A007C  beq cr6, 0x8221e4e4
	if ctx.cr[6].eq {
	pc = 0x8221E4E4; continue 'dispatch;
	}
	// 8221E46C: 38DF0210  addi r6, r31, 0x210
	ctx.r[6].s64 = ctx.r[31].s64 + 528;
	// 8221E470: 39010068  addi r8, r1, 0x68
	ctx.r[8].s64 = ctx.r[1].s64 + 104;
	// 8221E474: 78EB07E0  clrldi r11, r7, 0x3f
	ctx.r[11].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221E478: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221E47C: 419A0050  beq cr6, 0x8221e4cc
	if ctx.cr[6].eq {
	pc = 0x8221E4CC; continue 'dispatch;
	}
	// 8221E480: 3888FFE8  addi r4, r8, -0x18
	ctx.r[4].s64 = ctx.r[8].s64 + -24;
	// 8221E484: 4814A0B5  bl 0x82368538
	ctx.lr = 0x8221E488;
	sub_82368538(ctx, base);
	// 8221E488: C008FFF8  lfs f0, -8(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E48C: C1A8FFFC  lfs f13, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221E490: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8221E494: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221E498: D0030030  stfs f0, 0x30(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221E49C: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221E4A0: D1830038  stfs f12, 0x38(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221E4A4: D3E3003C  stfs f31, 0x3c(r3)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221E4A8: A1660000  lhz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221E4AC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221E4B0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221E4B4: 41980010  blt cr6, 0x8221e4c4
	if ctx.cr[6].lt {
	pc = 0x8221E4C4; continue 'dispatch;
	}
	// 8221E4B8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221E4BC: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8221E4C0: 48000008  b 0x8221e4c8
	pc = 0x8221E4C8; continue 'dispatch;
	// 8221E4C4: 389F0250  addi r4, r31, 0x250
	ctx.r[4].s64 = ctx.r[31].s64 + 592;
	// 8221E4C8: 48149869  bl 0x82367d30
	ctx.lr = 0x8221E4CC;
	sub_82367D30(ctx, base);
	// 8221E4CC: 78E7F842  rldicl r7, r7, 0x3f, 1
	ctx.r[7].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221E4D0: 38C60002  addi r6, r6, 2
	ctx.r[6].s64 = ctx.r[6].s64 + 2;
	// 8221E4D4: 39080030  addi r8, r8, 0x30
	ctx.r[8].s64 = ctx.r[8].s64 + 48;
	// 8221E4D8: 38630040  addi r3, r3, 0x40
	ctx.r[3].s64 = ctx.r[3].s64 + 64;
	// 8221E4DC: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 8221E4E0: 409AFF94  bne cr6, 0x8221e474
	if !ctx.cr[6].eq {
	pc = 0x8221E474; continue 'dispatch;
	}
	// 8221E4E4: 38210C70  addi r1, r1, 0xc70
	ctx.r[1].s64 = ctx.r[1].s64 + 3184;
	// 8221E4E8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E4EC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E4F0: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8221E4F4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8221E4F8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E4FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E500(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221E500 size=304
    let mut pc: u32 = 0x8221E500;
    'dispatch: loop {
        match pc {
            0x8221E500 => {
    //   block [0x8221E500..0x8221E630)
	// 8221E500: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221E504: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221E508: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8221E50C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8221E510: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8221E514: 9421F390  stwu r1, -0xc70(r1)
	ea = ctx.r[1].u32.wrapping_add(-3184 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221E518: 3D20820A  lis r9, -0x7df6
	ctx.r[9].s64 = -2113273856;
	// 8221E51C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221E520: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8221E524: 3940003F  li r10, 0x3f
	ctx.r[10].s64 = 63;
	// 8221E528: 39610078  addi r11, r1, 0x78
	ctx.r[11].s64 = ctx.r[1].s64 + 120;
	// 8221E52C: C3E9BA38  lfs f31, -0x45c8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221E530: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8221E534: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221E538: D3EB0000  stfs f31, 0(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221E53C: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8221E540: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8221E544: D3EBFFF8  stfs f31, -8(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8221E548: 396B0030  addi r11, r11, 0x30
	ctx.r[11].s64 = ctx.r[11].s64 + 48;
	// 8221E54C: 4098FFE4  bge cr6, 0x8221e530
	if !ctx.cr[6].lt {
	pc = 0x8221E530; continue 'dispatch;
	}
	// 8221E550: 38A00C00  li r5, 0xc00
	ctx.r[5].s64 = 3072;
	// 8221E554: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8221E558: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221E55C: 48316C75  bl 0x825351d0
	ctx.lr = 0x8221E560;
	sub_825351D0(ctx, base);
	// 8221E560: 3D60820B  lis r11, -0x7df5
	ctx.r[11].s64 = -2113208320;
	// 8221E564: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8221E568: 38CBAD10  addi r6, r11, -0x52f0
	ctx.r[6].s64 = ctx.r[11].s64 + -21232;
	// 8221E56C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221E570: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8221E574: 38BF0010  addi r5, r31, 0x10
	ctx.r[5].s64 = ctx.r[31].s64 + 16;
	// 8221E578: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221E57C: 387F0290  addi r3, r31, 0x290
	ctx.r[3].s64 = ctx.r[31].s64 + 656;
	// 8221E580: C04B1FF8  lfs f2, 0x1ff8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221E584: FC201090  fmr f1, f2
	ctx.f[1].f64 = ctx.f[2].f64;
	// 8221E588: 4BFF60D9  bl 0x82214660
	ctx.lr = 0x8221E58C;
	sub_82214660(ctx, base);
	// 8221E58C: E8FF0000  ld r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	// 8221E590: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8221E594: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 8221E598: 419A007C  beq cr6, 0x8221e614
	if ctx.cr[6].eq {
	pc = 0x8221E614; continue 'dispatch;
	}
	// 8221E59C: 38DF0210  addi r6, r31, 0x210
	ctx.r[6].s64 = ctx.r[31].s64 + 528;
	// 8221E5A0: 39010068  addi r8, r1, 0x68
	ctx.r[8].s64 = ctx.r[1].s64 + 104;
	// 8221E5A4: 78EB07E0  clrldi r11, r7, 0x3f
	ctx.r[11].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221E5A8: 2B2B0000  cmpldi cr6, r11, 0
	ctx.cr[6].compare_u64(ctx.r[11].u64, 0, &mut ctx.xer);
	// 8221E5AC: 419A0050  beq cr6, 0x8221e5fc
	if ctx.cr[6].eq {
	pc = 0x8221E5FC; continue 'dispatch;
	}
	// 8221E5B0: 3888FFE8  addi r4, r8, -0x18
	ctx.r[4].s64 = ctx.r[8].s64 + -24;
	// 8221E5B4: 48149F85  bl 0x82368538
	ctx.lr = 0x8221E5B8;
	sub_82368538(ctx, base);
	// 8221E5B8: C008FFF8  lfs f0, -8(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E5BC: C1A8FFFC  lfs f13, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221E5C0: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8221E5C4: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221E5C8: D0030030  stfs f0, 0x30(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221E5CC: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221E5D0: D1830038  stfs f12, 0x38(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221E5D4: D3E3003C  stfs f31, 0x3c(r3)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221E5D8: A1660000  lhz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221E5DC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221E5E0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221E5E4: 41980010  blt cr6, 0x8221e5f4
	if ctx.cr[6].lt {
	pc = 0x8221E5F4; continue 'dispatch;
	}
	// 8221E5E8: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221E5EC: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8221E5F0: 48000008  b 0x8221e5f8
	pc = 0x8221E5F8; continue 'dispatch;
	// 8221E5F4: 389F0250  addi r4, r31, 0x250
	ctx.r[4].s64 = ctx.r[31].s64 + 592;
	// 8221E5F8: 48149739  bl 0x82367d30
	ctx.lr = 0x8221E5FC;
	sub_82367D30(ctx, base);
	// 8221E5FC: 78E7F842  rldicl r7, r7, 0x3f, 1
	ctx.r[7].u64 = ctx.r[7].u64 & 0x0000000000000001u64;
	// 8221E600: 38C60002  addi r6, r6, 2
	ctx.r[6].s64 = ctx.r[6].s64 + 2;
	// 8221E604: 39080030  addi r8, r8, 0x30
	ctx.r[8].s64 = ctx.r[8].s64 + 48;
	// 8221E608: 38630040  addi r3, r3, 0x40
	ctx.r[3].s64 = ctx.r[3].s64 + 64;
	// 8221E60C: 2B270000  cmpldi cr6, r7, 0
	ctx.cr[6].compare_u64(ctx.r[7].u64, 0, &mut ctx.xer);
	// 8221E610: 409AFF94  bne cr6, 0x8221e5a4
	if !ctx.cr[6].eq {
	pc = 0x8221E5A4; continue 'dispatch;
	}
	// 8221E614: 38210C70  addi r1, r1, 0xc70
	ctx.r[1].s64 = ctx.r[1].s64 + 3184;
	// 8221E618: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E61C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E620: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8221E624: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8221E628: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E62C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E630 size=36
    let mut pc: u32 = 0x8221E630;
    'dispatch: loop {
        match pc {
            0x8221E630 => {
    //   block [0x8221E630..0x8221E654)
	// 8221E630: 89630069  lbz r11, 0x69(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(105 as u32) ) } as u64;
	// 8221E634: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221E638: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8221E63C: 419A0020  beq cr6, 0x8221e65c
	if ctx.cr[6].eq {
		sub_8221E65C(ctx, base);
		return;
	}
	// 8221E640: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8221E644: 419A0014  beq cr6, 0x8221e658
	if ctx.cr[6].eq {
		sub_8221E658(ctx, base);
		return;
	}
	// 8221E648: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 8221E64C: 419A0008  beq cr6, 0x8221e654
	if ctx.cr[6].eq {
		sub_8221E654(ctx, base);
		return;
	}
	// 8221E650: 48003548  b 0x82221b98
	sub_82221B98(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E654(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E654 size=4
    let mut pc: u32 = 0x8221E654;
    'dispatch: loop {
        match pc {
            0x8221E654 => {
    //   block [0x8221E654..0x8221E658)
	// 8221E654: 48003434  b 0x82221a88
	sub_82221A88(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E658 size=4
    let mut pc: u32 = 0x8221E658;
    'dispatch: loop {
        match pc {
            0x8221E658 => {
    //   block [0x8221E658..0x8221E65C)
	// 8221E658: 48003260  b 0x822218b8
	sub_822218B8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E65C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E65C size=4
    let mut pc: u32 = 0x8221E65C;
    'dispatch: loop {
        match pc {
            0x8221E65C => {
    //   block [0x8221E65C..0x8221E660)
	// 8221E65C: 48002B54  b 0x822211b0
	sub_822211B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8221E660 size=160
    let mut pc: u32 = 0x8221E660;
    'dispatch: loop {
        match pc {
            0x8221E660 => {
    //   block [0x8221E660..0x8221E700)
	// 8221E660: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221E664: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221E668: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8221E66C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221E670: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221E674: 897F0068  lbz r11, 0x68(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(104 as u32) ) } as u64;
	// 8221E678: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8221E67C: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8221E680: 419A0064  beq cr6, 0x8221e6e4
	if ctx.cr[6].eq {
	pc = 0x8221E6E4; continue 'dispatch;
	}
	// 8221E684: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8221E688: 419A0024  beq cr6, 0x8221e6ac
	if ctx.cr[6].eq {
	pc = 0x8221E6AC; continue 'dispatch;
	}
	// 8221E68C: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 8221E690: 419A0028  beq cr6, 0x8221e6b8
	if ctx.cr[6].eq {
	pc = 0x8221E6B8; continue 'dispatch;
	}
	// 8221E694: 48003625  bl 0x82221cb8
	ctx.lr = 0x8221E698;
	sub_82221CB8(ctx, base);
	// 8221E698: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8221E69C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E6A0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E6A4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E6A8: 4E800020  blr
	return;
	// 8221E6AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221E6B0: 48003209  bl 0x822218b8
	ctx.lr = 0x8221E6B4;
	sub_822218B8(ctx, base);
	// 8221E6B4: 480024AD  bl 0x82220b60
	ctx.lr = 0x8221E6B8;
	sub_82220B60(ctx, base);
	// 8221E6B8: 397F0080  addi r11, r31, 0x80
	ctx.r[11].s64 = ctx.r[31].s64 + 128;
	// 8221E6BC: 395F0070  addi r10, r31, 0x70
	ctx.r[10].s64 = ctx.r[31].s64 + 112;
	// 8221E6C0: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 8221E6C4: E96B0008  ld r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	// 8221E6C8: F92A0000  std r9, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 8221E6CC: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8221E6D0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8221E6D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E6D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E6DC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E6E0: 4E800020  blr
	return;
	// 8221E6E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221E6E8: 48002479  bl 0x82220b60
	ctx.lr = 0x8221E6EC;
	sub_82220B60(ctx, base);
	// 8221E6EC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8221E6F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221E6F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221E6F8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221E6FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E700(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E700 size=156
    let mut pc: u32 = 0x8221E700;
    'dispatch: loop {
        match pc {
            0x8221E700 => {
    //   block [0x8221E700..0x8221E79C)
	// 8221E700: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E79C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E79C size=8
    let mut pc: u32 = 0x8221E79C;
    'dispatch: loop {
        match pc {
            0x8221E79C => {
    //   block [0x8221E79C..0x8221E7A4)
	// 8221E79C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8221E7A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E7A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E7A8 size=364
    let mut pc: u32 = 0x8221E7A8;
    'dispatch: loop {
        match pc {
            0x8221E7A8 => {
    //   block [0x8221E7A8..0x8221E914)
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E914(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221E914 size=8
    let mut pc: u32 = 0x8221E914;
    'dispatch: loop {
        match pc {
            0x8221E914 => {
    //   block [0x8221E914..0x8221E91C)
	// 8221E914: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8221E918: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221E920(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221E920 size=712
    let mut pc: u32 = 0x8221E920;
    'dispatch: loop {
        match pc {
            0x8221E920 => {
    //   block [0x8221E920..0x8221EA18)
	// 8221E920: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221E924: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221E928: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8221E92C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8221E930: DBE1FFE0  stfd f31, -0x20(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 8221E934: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221E938: 3D60820C  lis r11, -0x7df4
	ctx.r[11].s64 = -2113142784;
	// 8221E93C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8221E940: 396B4638  addi r11, r11, 0x4638
	ctx.r[11].s64 = ctx.r[11].s64 + 17976;
	// 8221E944: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8221E948: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8221E94C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8221E950: 915F0024  stw r10, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 8221E954: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8221E958: A17E004E  lhz r11, 0x4e(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(78 as u32) ) } as u64;
	// 8221E95C: B17F0020  sth r11, 0x20(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u16 ) };
	// 8221E960: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8221E964: B17F0022  sth r11, 0x22(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(34 as u32), ctx.r[11].u16 ) };
	// 8221E968: A17E004C  lhz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8221E96C: 2B0BFFFF  cmplwi cr6, r11, 0xffff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65535 as u32, &mut ctx.xer);
	// 8221E970: 419A001C  beq cr6, 0x8221e98c
	if ctx.cr[6].eq {
	pc = 0x8221E98C; continue 'dispatch;
	}
	// 8221E974: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8221E978: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8221E97C: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221E980: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8221E984: A16B004C  lhz r11, 0x4c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 8221E988: 48000008  b 0x8221e990
	pc = 0x8221E990; continue 'dispatch;
	// 8221E98C: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 8221E990: B17F00D0  sth r11, 0xd0(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[11].u16 ) };
	// 8221E994: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8221E998: C01E0010  lfs f0, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E99C: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221E9A0: C01E0014  lfs f0, 0x14(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E9A4: D01F0014  stfs f0, 0x14(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8221E9A8: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221E9AC: 90BF00D4  stw r5, 0xd4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(212 as u32), ctx.r[5].u32 ) };
	// 8221E9B0: C3EBBA38  lfs f31, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221E9B4: D01F0018  stfs f0, 0x18(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221E9B8: D3FF001C  stfs f31, 0x1c(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8221E9BC: 897E004B  lbz r11, 0x4b(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(75 as u32) ) } as u64;
	// 8221E9C0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8221E9C4: 394AFFF4  addi r10, r10, -0xc
	ctx.r[10].s64 = ctx.r[10].s64 + -12;
	// 8221E9C8: B17F00D2  sth r11, 0xd2(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(210 as u32), ctx.r[11].u16 ) };
	// 8221E9CC: 2B0A000A  cmplwi cr6, r10, 0xa
	ctx.cr[6].compare_u32(ctx.r[10].u32, 10 as u32, &mut ctx.xer);
	// 8221E9D0: 419901F8  bgt cr6, 0x8221ebc8
	if ctx.cr[6].gt {
	pc = 0x8221EBC8; continue 'dispatch;
	}
	// 8221E9D4: 3D808222  lis r12, -0x7dde
	ctx.r[12].s64 = -2111700992;
	// 8221E9D8: 398CE9EC  addi r12, r12, -0x1614
	ctx.r[12].s64 = ctx.r[12].s64 + -5652;
	// 8221E9DC: 5540103A  slwi r0, r10, 2
	ctx.r[0].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8221E9E0: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8221E9E4: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8221E9E8: 4E800420  bctr
	match ctx.r[10].u64 {
		0 => {
	pc = 0x8221EA18; continue 'dispatch;
		},
		1 => {
	pc = 0x8221EA8C; continue 'dispatch;
		},
		2 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		3 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		4 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		5 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		6 => {
	pc = 0x8221EB14; continue 'dispatch;
		},
		7 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		8 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		9 => {
	pc = 0x8221EBC8; continue 'dispatch;
		},
		10 => {
	pc = 0x8221EB6C; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8221E9EC: 8221EA18  lwz r17, -0x15e8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5608 as u32) ) } as u64;
	// 8221E9F0: 8221EA8C  lwz r17, -0x1574(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5492 as u32) ) } as u64;
	// 8221E9F4: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221E9F8: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221E9FC: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221EA00: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221EA04: 8221EB14  lwz r17, -0x14ec(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5356 as u32) ) } as u64;
	// 8221EA08: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221EA0C: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221EA10: 8221EBC8  lwz r17, -0x1438(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5176 as u32) ) } as u64;
	// 8221EA14: 8221EB6C  lwz r17, -0x1494(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-5268 as u32) ) } as u64;
            }
            0x8221EA18 => {
    //   block [0x8221EA18..0x8221EA8C)
	// 8221EA18: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EA1C: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EA20: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EA24: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EA28: 481497F1  bl 0x82368218
	ctx.lr = 0x8221EA2C;
	sub_82368218(ctx, base);
	// 8221EA2C: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8221EA30: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EA34: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EA38: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EA3C: 481497DD  bl 0x82368218
	ctx.lr = 0x8221EA40;
	sub_82368218(ctx, base);
	// 8221EA40: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8221EA44: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EA48: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EA4C: 481493A5  bl 0x82367df0
	ctx.lr = 0x8221EA50;
	sub_82367DF0(ctx, base);
	// 8221EA50: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EA54: 387F00B0  addi r3, r31, 0xb0
	ctx.r[3].s64 = ctx.r[31].s64 + 176;
	// 8221EA58: 48155949  bl 0x823743a0
	ctx.lr = 0x8221EA5C;
	sub_823743A0(ctx, base);
	// 8221EA5C: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EA60: EC1F0024  fdivs f0, f31, f0
	ctx.f[0].f64 = ((ctx.f[31].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221EA64: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8221EA68: D01F00C0  stfs f0, 0xc0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221EA6C: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EA70: EC1F0024  fdivs f0, f31, f0
	ctx.f[0].f64 = ((ctx.f[31].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221EA74: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8221EA78: D01F00C4  stfs f0, 0xc4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221EA7C: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EA80: EC1F0024  fdivs f0, f31, f0
	ctx.f[0].f64 = ((ctx.f[31].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221EA84: FC000210  fabs f0, f0
	ctx.f[0].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 8221EA88: 4800013C  b 0x8221ebc4
	pc = 0x8221EBC4; continue 'dispatch;
            }
            0x8221EA8C => {
    //   block [0x8221EA8C..0x8221EB14)
	// 8221EA8C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221EA90: D3FF00BC  stfs f31, 0xbc(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(188 as u32), tmp.u32 ) };
	// 8221EA94: 397F00C0  addi r11, r31, 0xc0
	ctx.r[11].s64 = ctx.r[31].s64 + 192;
	// 8221EA98: 1001038C  vspltisw v0, 1
	for i in 0..4 {
		ctx.v[0].u32[i] = 1;
	}
	// 8221EA9C: C00A1FF8  lfs f0, 0x1ff8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EAA0: 1181034A  vcfsx v12, v0, 1
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (1 as u32)) << 23));
	for i in 0..4 {
		ctx.v[12].f32[i] = (ctx.v[0].s32[i] as f32) * scale;
	}
	// 8221EAA4: D01F00B8  stfs f0, 0xb8(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), tmp.u32 ) };
	// 8221EAA8: 1160034A  vcfsx v11, v0, 0
	ctx.fpscr.enable_flush_mode_unconditional();
	let scale = f32::from_bits(((127u32 - (0 as u32)) << 23));
	for i in 0..4 {
		ctx.v[11].f32[i] = (ctx.v[0].s32[i] as f32) * scale;
	}
	// 8221EAAC: D01F00B4  stfs f0, 0xb4(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(180 as u32), tmp.u32 ) };
	// 8221EAB0: D01F00B0  stfs f0, 0xb0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 8221EAB4: C01E0000  lfs f0, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EAB8: D01F00C0  stfs f0, 0xc0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221EABC: C01E0004  lfs f0, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EAC0: D01F00C4  stfs f0, 0xc4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221EAC4: C01E0008  lfs f0, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EAC8: D01F00C8  stfs f0, 0xc8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 8221EACC: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	pc = 0x8221EB14; continue 'dispatch;
            }
            0x8221EB14 => {
    //   block [0x8221EB14..0x8221EB6C)
	// 8221EB14: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EB18: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EB1C: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EB20: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EB24: 481496F5  bl 0x82368218
	ctx.lr = 0x8221EB28;
	sub_82368218(ctx, base);
	// 8221EB28: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8221EB2C: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EB30: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EB34: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EB38: 481496E1  bl 0x82368218
	ctx.lr = 0x8221EB3C;
	sub_82368218(ctx, base);
	// 8221EB3C: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8221EB40: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EB44: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EB48: 481492A9  bl 0x82367df0
	ctx.lr = 0x8221EB4C;
	sub_82367DF0(ctx, base);
	// 8221EB4C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EB50: 387F00B0  addi r3, r31, 0xb0
	ctx.r[3].s64 = ctx.r[31].s64 + 176;
	// 8221EB54: 4815584D  bl 0x823743a0
	ctx.lr = 0x8221EB58;
	sub_823743A0(ctx, base);
	// 8221EB58: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EB5C: D01F00C0  stfs f0, 0xc0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221EB60: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EB64: D01F00C4  stfs f0, 0xc4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221EB68: 48000060  b 0x8221ebc8
	pc = 0x8221EBC8; continue 'dispatch;
            }
            0x8221EB6C => {
    //   block [0x8221EB6C..0x8221EBC8)
	// 8221EB6C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EB70: C07E0028  lfs f3, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EB74: C05E0024  lfs f2, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EB78: C03E0020  lfs f1, 0x20(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EB7C: 4814969D  bl 0x82368218
	ctx.lr = 0x8221EB80;
	sub_82368218(ctx, base);
	// 8221EB80: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8221EB84: C07E0008  lfs f3, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8221EB88: C05E0004  lfs f2, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8221EB8C: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EB90: 48149689  bl 0x82368218
	ctx.lr = 0x8221EB94;
	sub_82368218(ctx, base);
	// 8221EB94: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 8221EB98: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EB9C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8221EBA0: 48149251  bl 0x82367df0
	ctx.lr = 0x8221EBA4;
	sub_82367DF0(ctx, base);
	// 8221EBA4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8221EBA8: 387F00B0  addi r3, r31, 0xb0
	ctx.r[3].s64 = ctx.r[31].s64 + 176;
	// 8221EBAC: 481557F5  bl 0x823743a0
	ctx.lr = 0x8221EBB0;
	sub_823743A0(ctx, base);
	// 8221EBB0: C01E0030  lfs f0, 0x30(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EBB4: D01F00C0  stfs f0, 0xc0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221EBB8: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EBBC: D01F00C4  stfs f0, 0xc4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221EBC0: C01E0038  lfs f0, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EBC4: D01F00C8  stfs f0, 0xc8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), tmp.u32 ) };
	pc = 0x8221EBC8; continue 'dispatch;
            }
            0x8221EBC8 => {
    //   block [0x8221EBC8..0x8221EBE8)
	// 8221EBC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221EBCC: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8221EBD0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221EBD4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221EBD8: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8221EBDC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8221EBE0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8221EBE4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EBE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221EBE8 size=128
    let mut pc: u32 = 0x8221EBE8;
    'dispatch: loop {
        match pc {
            0x8221EBE8 => {
    //   block [0x8221EBE8..0x8221EC68)
	// 8221EBE8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221EBEC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221EBF0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221EBF4: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 8221EBF8: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8221EBFC: 38680030  addi r3, r8, 0x30
	ctx.r[3].s64 = ctx.r[8].s64 + 48;
	// 8221EC00: 388800B0  addi r4, r8, 0xb0
	ctx.r[4].s64 = ctx.r[8].s64 + 176;
	// 8221EC04: 48149935  bl 0x82368538
	ctx.lr = 0x8221EC08;
	sub_82368538(ctx, base);
	// 8221EC08: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8221EC0C: C1A80010  lfs f13, 0x10(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221EC10: D1A30030  stfs f13, 0x30(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 8221EC14: C1A80014  lfs f13, 0x14(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221EC18: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8221EC1C: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EC20: C1A80018  lfs f13, 0x18(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221EC24: D1A30038  stfs f13, 0x38(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 8221EC28: D003003C  stfs f0, 0x3c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 8221EC2C: A1680022  lhz r11, 0x22(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(34 as u32) ) } as u64;
	// 8221EC30: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221EC34: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 8221EC38: 419A0014  beq cr6, 0x8221ec4c
	if ctx.cr[6].eq {
	pc = 0x8221EC4C; continue 'dispatch;
	}
	// 8221EC3C: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8221EC40: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8221EC44: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8221EC48: 481490E9  bl 0x82367d30
	ctx.lr = 0x8221EC4C;
	sub_82367D30(ctx, base);
	// 8221EC4C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8221EC50: 38680070  addi r3, r8, 0x70
	ctx.r[3].s64 = ctx.r[8].s64 + 112;
	// 8221EC54: 48149035  bl 0x82367c88
	ctx.lr = 0x8221EC58;
	sub_82367C88(ctx, base);
	// 8221EC58: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8221EC5C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221EC60: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8221EC64: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EC68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221EC68 size=36
    let mut pc: u32 = 0x8221EC68;
    'dispatch: loop {
        match pc {
            0x8221EC68 => {
    //   block [0x8221EC68..0x8221EC8C)
	// 8221EC68: A1630020  lhz r11, 0x20(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8221EC6C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221EC70: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221EC74: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8221EC78: 7D6B28AE  lbzx r11, r11, r5
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32)) } as u64;
	// 8221EC7C: 556B103E  rotlwi r11, r11, 2
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(2)) as u64;
	// 8221EC80: 7C2B242E  lfsx f1, r11, r4
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221EC84: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8221EC88: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EC90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221EC90 size=68
    let mut pc: u32 = 0x8221EC90;
    'dispatch: loop {
        match pc {
            0x8221EC90 => {
    //   block [0x8221EC90..0x8221ECD4)
	// 8221EC90: C0030010  lfs f0, 0x10(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EC94: C1A30014  lfs f13, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221EC98: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221EC9C: C1830018  lfs f12, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221ECA0: EDA10372  fmuls f13, f1, f13
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221ECA4: ED810332  fmuls f12, f1, f12
	ctx.f[12].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221ECA8: D0030010  stfs f0, 0x10(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8221ECAC: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8221ECB0: D1830018  stfs f12, 0x18(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8221ECB4: A16300D2  lhz r11, 0xd2(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(210 as u32) ) } as u64;
	// 8221ECB8: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221ECBC: 2F0B000C  cmpwi cr6, r11, 0xc
	ctx.cr[6].compare_i32(ctx.r[11].s32, 12, &mut ctx.xer);
	// 8221ECC0: 419A0058  beq cr6, 0x8221ed18
	if ctx.cr[6].eq {
		sub_8221ED18(ctx, base);
		return;
	}
	// 8221ECC4: 2F0B0012  cmpwi cr6, r11, 0x12
	ctx.cr[6].compare_i32(ctx.r[11].s32, 18, &mut ctx.xer);
	// 8221ECC8: 419A0034  beq cr6, 0x8221ecfc
	if ctx.cr[6].eq {
		sub_8221ECFC(ctx, base);
		return;
	}
	// 8221ECCC: 2F0B0016  cmpwi cr6, r11, 0x16
	ctx.cr[6].compare_i32(ctx.r[11].s32, 22, &mut ctx.xer);
	// 8221ECD0: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221ECD4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221ECD4 size=40
    let mut pc: u32 = 0x8221ECD4;
    'dispatch: loop {
        match pc {
            0x8221ECD4 => {
    //   block [0x8221ECD4..0x8221ECFC)
	// 8221ECD4: C00300C0  lfs f0, 0xc0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(192 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221ECD8: C1A300C4  lfs f13, 0xc4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(196 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221ECDC: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221ECE0: C18300C8  lfs f12, 0xc8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(200 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221ECE4: EDAD0072  fmuls f13, f13, f1
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221ECE8: ED8C0072  fmuls f12, f12, f1
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221ECEC: D00300C0  stfs f0, 0xc0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221ECF0: D18300C8  stfs f12, 0xc8(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 8221ECF4: D1A300C4  stfs f13, 0xc4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221ECF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221ECFC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221ECFC size=28
    let mut pc: u32 = 0x8221ECFC;
    'dispatch: loop {
        match pc {
            0x8221ECFC => {
    //   block [0x8221ECFC..0x8221ED18)
	// 8221ECFC: C00300C0  lfs f0, 0xc0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(192 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221ED00: C1A300C4  lfs f13, 0xc4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(196 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221ED04: EC000072  fmuls f0, f0, f1
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221ED08: EDAD0072  fmuls f13, f13, f1
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221ED0C: D00300C0  stfs f0, 0xc0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221ED10: D1A300C4  stfs f13, 0xc4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221ED14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221ED18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221ED18 size=52
    let mut pc: u32 = 0x8221ED18;
    'dispatch: loop {
        match pc {
            0x8221ED18 => {
    //   block [0x8221ED18..0x8221ED4C)
	// 8221ED18: 3D60820A  lis r11, -0x7df6
	ctx.r[11].s64 = -2113273856;
	// 8221ED1C: C1A300C0  lfs f13, 0xc0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(192 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221ED20: C18300C4  lfs f12, 0xc4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(196 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221ED24: C16300C8  lfs f11, 0xc8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(200 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8221ED28: C00BBA38  lfs f0, -0x45c8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17864 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221ED2C: EC000824  fdivs f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 / ctx.f[1].f64) as f32) as f64;
	// 8221ED30: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ED34: D1A300C0  stfs f13, 0xc0(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8221ED38: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ED3C: D1A300C4  stfs f13, 0xc4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 8221ED40: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221ED44: D00300C8  stfs f0, 0xc8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 8221ED48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221ED50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221ED50 size=180
    let mut pc: u32 = 0x8221ED50;
    'dispatch: loop {
        match pc {
            0x8221ED50 => {
    //   block [0x8221ED50..0x8221EE04)
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EE04(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221EE04 size=88
    let mut pc: u32 = 0x8221EE04;
    'dispatch: loop {
        match pc {
            0x8221EE04 => {
    //   block [0x8221EE04..0x8221EE5C)
	// 8221EE04: ED890332  fmuls f12, f9, f12
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221EE08: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221EE0C: ED2A3028  fsubs f9, f10, f6
	ctx.f[9].f64 = (((ctx.f[10].f64 - ctx.f[6].f64) as f32) as f64);
	// 8221EE10: ED460024  fdivs f10, f6, f0
	ctx.f[10].f64 = ((ctx.f[6].f64 / ctx.f[0].f64) as f32) as f64;
	// 8221EE14: EDA7637A  fmadds f13, f7, f13, f12
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 8221EE18: EC090032  fmuls f0, f9, f0
	ctx.f[0].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221EE1C: EDA86AFA  fmadds f13, f8, f11, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[11].f64 + ctx.f[13].f64) as f32) as f64);
	// 8221EE20: ED8D0378  fmsubs f12, f13, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8221EE24: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221EE28: FF0C0000  fcmpu cr6, f12, f0
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[0].f64);
	// 8221EE2C: 4198FFD0  blt cr6, 0x8221edfc
	if ctx.cr[6].lt {
		sub_8221ED50(ctx, base);
		return;
	}
	// 8221EE30: FD606850  fneg f11, f13
	ctx.f[11].u64 = ctx.f[13].u64 ^ 0x8000_0000_0000_0000u64;
	// 8221EE34: 61430004  ori r3, r10, 4
	ctx.r[3].u64 = ctx.r[10].u64 | 4;
	// 8221EE38: ED80602C  fsqrts f12, f12
	ctx.f[12].f64 = ((ctx.f[12].f64).sqrt() as f32) as f64;
	// 8221EE3C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8221EE40: EDAC6828  fsubs f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 8221EE44: ED6B6028  fsubs f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8221EE48: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8221EE4C: D1A70000  stfs f13, 0(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221EE50: ED8B02B2  fmuls f12, f11, f10
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[10].f64) as f32) as f64);
	// 8221EE54: D1860000  stfs f12, 0(r6)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221EE58: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EE5C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221EE5C size=228
    let mut pc: u32 = 0x8221EE5C;
    'dispatch: loop {
        match pc {
            0x8221EE5C => {
    //   block [0x8221EE5C..0x8221EF40)
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221EF40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221EF40 size=400
    let mut pc: u32 = 0x8221EF40;
    'dispatch: loop {
        match pc {
            0x8221EF40 => {
    //   block [0x8221EF40..0x8221F0D0)
	// 8221EF40: EDA0682C  fsqrts f13, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 8221EF44: EDA66824  fdivs f13, f6, f13
	ctx.f[13].f64 = ((ctx.f[6].f64 / ctx.f[13].f64) as f32) as f64;
	// 8221EF48: ED0C0372  fmuls f8, f12, f13
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221EF4C: C181FFBC  lfs f12, -0x44(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-68 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8221EF50: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221EF54: D101FFB8  stfs f8, -0x48(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), tmp.u32 ) };
	// 8221EF58: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221EF5C: D121FFB0  stfs f9, -0x50(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), tmp.u32 ) };
	// 8221EF60: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8221EF64: D161FFB4  stfs f11, -0x4c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-76 as u32), tmp.u32 ) };
	// 8221EF68: D1A1FFBC  stfs f13, -0x44(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-68 as u32), tmp.u32 ) };
	// 8221EF6C: 3961FFB0  addi r11, r1, -0x50
	ctx.r[11].s64 = ctx.r[1].s64 + -80;
	// 8221EF70: 10EC6484  vmr v7, v12
	ctx.v[7] = ctx.v[12];
	// 8221EF74: 1001038C  vspltisw v0, 1
	for i in 0..4 {
		ctx.v[0].u32[i] = 1;
	}
	// 8221EF78: C1A1FFB4  lfs f13, -0x4c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-76 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221EF7C: D1A1FFD4  stfs f13, -0x2c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-44 as u32), tmp.u32 ) };
	// 8221EF80: D121FFC4  stfs f9, -0x3c(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-60 as u32), tmp.u32 ) };
	// 8221EF84: D101FFE4  stfs f8, -0x1c(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F0D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8221F0D0 size=24
    let mut pc: u32 = 0x8221F0D0;
    'dispatch: loop {
        match pc {
            0x8221F0D0 => {
    //   block [0x8221F0D0..0x8221F0E8)
	// 8221F0D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8221F0D4: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8221F0D8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221F0DC: 419A000C  beq cr6, 0x8221f0e8
	if ctx.cr[6].eq {
		sub_8221F0E8(ctx, base);
		return;
	}
	// 8221F0E0: FD600090  fmr f11, f0
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[11].f64 = ctx.f[0].f64;
	// 8221F0E4: 48000008  b 0x8221f0ec
	sub_8221F0E8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F0E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221F0E8 size=92
    let mut pc: u32 = 0x8221F0E8;
    'dispatch: loop {
        match pc {
            0x8221F0E8 => {
    //   block [0x8221F0E8..0x8221F144)
	// 8221F0E8: FD603890  fmr f11, f7
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[11].f64 = ctx.f[7].f64;
	// 8221F0EC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221F0F0: C1A1FF50  lfs f13, -0xb0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221F0F4: D1680008  stfs f11, 8(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221F0F8: C14B2074  lfs f10, 0x2074(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8308 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221F0FC: FF0D5000  fcmpu cr6, f13, f10
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[10].f64);
	// 8221F100: 40990118  ble cr6, 0x8221f218
	if !ctx.cr[6].gt {
		sub_8221F218(ctx, base);
		return;
	}
	// 8221F104: ED4C0332  fmuls f10, f12, f12
	ctx.f[10].f64 = (((ctx.f[12].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221F108: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8221F10C: ED4B52FA  fmadds f10, f11, f11, f10
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64);
	// 8221F110: 41980034  blt cr6, 0x8221f144
	if ctx.cr[6].lt {
		sub_8221F144(ctx, base);
		return;
	}
	// 8221F114: EDA0502C  fsqrts f13, f10
	ctx.f[13].f64 = ((ctx.f[10].f64).sqrt() as f32) as f64;
	// 8221F118: C148000C  lfs f10, 0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8221F11C: EDA66824  fdivs f13, f6, f13
	ctx.f[13].f64 = ((ctx.f[6].f64 / ctx.f[13].f64) as f32) as f64;
	// 8221F120: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221F124: D0080000  stfs f0, 0(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221F128: EC0D0332  fmuls f0, f13, f12
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221F12C: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221F130: EC0D02F2  fmuls f0, f13, f11
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221F134: D0080008  stfs f0, 8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221F138: EC0D02B2  fmuls f0, f13, f10
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8221F13C: D008000C  stfs f0, 0xc(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8221F140: 48000034  b 0x8221f174
	sub_8221F144(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F144(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221F144 size=212
    let mut pc: u32 = 0x8221F144;
    'dispatch: loop {
        match pc {
            0x8221F144 => {
    //   block [0x8221F144..0x8221F218)
	// 8221F144: EDAD337C  fnmsubs f13, f13, f13, f6
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = -(((ctx.f[13].f64 * ctx.f[13].f64 - ctx.f[6].f64) as f32) as f64);
	// 8221F148: C028000C  lfs f1, 0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8221F14C: EDAD5024  fdivs f13, f13, f10
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[10].f64) as f32) as f64;
	// 8221F150: EDA0682C  fsqrts f13, f13
	ctx.f[13].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 8221F154: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8221F158: ED4D0332  fmuls f10, f13, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8221F15C: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8221F160: EDAD0072  fmuls f13, f13, f1
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 8221F164: D0080000  stfs f0, 0(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221F168: D1480004  stfs f10, 4(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221F16C: D1680008  stfs f11, 8(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221F170: D1A8000C  stfs f13, 0xc(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8221F174: C0080004  lfs f0, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8221F178: 8168000C  lwz r11, 0xc(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 8221F17C: C1A80008  lfs f13, 8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8221F180: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8221F184: D061FFE0  stfs f3, -0x20(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 8221F188: EDAD3828  fsubs f13, f13, f7
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[7].f64) as f32) as f64);
	// 8221F18C: D041FFE4  stfs f2, -0x1c(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 8221F190: 3941FFE0  addi r10, r1, -0x20
	ctx.r[10].s64 = ctx.r[1].s64 + -32;
	// 8221F194: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221F198: D1A80008  stfs f13, 8(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F218(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8221F218 size=20
    let mut pc: u32 = 0x8221F218;
    'dispatch: loop {
        match pc {
            0x8221F218 => {
    //   block [0x8221F218..0x8221F22C)
	// 8221F218: D0080000  stfs f0, 0(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8221F21C: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8221F220: D0C8000C  stfs f6, 0xc(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8221F224: D0080008  stfs f0, 8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8221F228: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F230(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8221F230 size=836
    let mut pc: u32 = 0x8221F230;
    'dispatch: loop {
        match pc {
            0x8221F230 => {
    //   block [0x8221F230..0x8221F574)
	// 8221F230: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221F234: 48315E89  bl 0x825350bc
	ctx.lr = 0x8221F238;
	sub_82535080(ctx, base);
	// 8221F238: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221F23C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8221F240: 409A0008  bne cr6, 0x8221f248
	if !ctx.cr[6].eq {
	pc = 0x8221F248; continue 'dispatch;
	}
	// 8221F244: 39230030  addi r9, r3, 0x30
	ctx.r[9].s64 = ctx.r[3].s64 + 48;
	// 8221F248: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8221F24C: 409A0008  bne cr6, 0x8221f254
	if !ctx.cr[6].eq {
	pc = 0x8221F254; continue 'dispatch;
	}
	// 8221F250: 39430070  addi r10, r3, 0x70
	ctx.r[10].s64 = ctx.r[3].s64 + 112;
	// 8221F254: A16300D2  lhz r11, 0xd2(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(210 as u32) ) } as u64;
	// 8221F258: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8221F25C: 2F0B000C  cmpwi cr6, r11, 0xc
	ctx.cr[6].compare_i32(ctx.r[11].s32, 12, &mut ctx.xer);
	// 8221F260: 409A00EC  bne cr6, 0x8221f34c
	if !ctx.cr[6].eq {
	pc = 0x8221F34C; continue 'dispatch;
	}
	// 8221F264: 39600030  li r11, 0x30
	ctx.r[11].s64 = 48;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221F578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8221F578 size=1216
    let mut pc: u32 = 0x8221F578;
    'dispatch: loop {
        match pc {
            0x8221F578 => {
    //   block [0x8221F578..0x8221FA38)
	// 8221F578: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221F57C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8221F580: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221F584: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8221F588: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8221F58C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8221F590: 409A0008  bne cr6, 0x8221f598
	if !ctx.cr[6].eq {
	pc = 0x8221F598; continue 'dispatch;
	}
	// 8221F594: 38CB0030  addi r6, r11, 0x30
	ctx.r[6].s64 = ctx.r[11].s64 + 48;
	// 8221F598: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8221F59C: 409A0008  bne cr6, 0x8221f5a4
	if !ctx.cr[6].eq {
	pc = 0x8221F5A4; continue 'dispatch;
	}
	// 8221F5A0: 38EB0070  addi r7, r11, 0x70
	ctx.r[7].s64 = ctx.r[11].s64 + 112;
	// 8221F5A4: A14B00D2  lhz r10, 0xd2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(210 as u32) ) } as u64;
	// 8221F5A8: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8221F5AC: 2F0A000C  cmpwi cr6, r10, 0xc
	ctx.cr[6].compare_i32(ctx.r[10].s32, 12, &mut ctx.xer);
	// 8221F5B0: 409A0150  bne cr6, 0x8221f700
	if !ctx.cr[6].eq {
	pc = 0x8221F700; continue 'dispatch;
	}
	// 8221F5B4: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8221FA38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8221FA38 size=3224
    let mut pc: u32 = 0x8221FA38;
    'dispatch: loop {
        match pc {
            0x8221FA38 => {
    //   block [0x8221FA38..0x822206D0)
	// 8221FA38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8221FA3C: 48315645  bl 0x82535080
	ctx.lr = 0x8221FA40;
	sub_82535080(ctx, base);
	// 8221FA40: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 8221FA44: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 8221FA48: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 8221FA4C: 39809E40  li r12, -0x61c0
	ctx.r[12].s64 = -25024;
	// 8221FA50: 483C2875  bl 0x825e22c4
	ctx.lr = 0x8221FA54;
	sub_825E22C4(ctx, base);
	// 8221FA54: 7C21616E  stwux r1, r1, r12
	ea = ctx.r[1].u32.wrapping_add(ctx.r[12].u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8221FA58: 3D60829E  lis r11, -0x7d62
	ctx.r[11].s64 = -2103574528;
	// 8221FA5C: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8221FA60: 7C932378  mr r19, r4
	ctx.r[19].u64 = ctx.r[4].u64;
	// 8221FA64: 816B64D8  lwz r11, 0x64d8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(25816 as u32) ) } as u64;
	// 8221FA68: 936161D4  stw r27, 0x61d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(25044 as u32), ctx.r[27].u32 ) };
	// 8221FA6C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8221FA70: 409A0C4C  bne cr6, 0x822206bc
	if !ctx.cr[6].eq {
	pc = 0x822206BC; continue 'dispatch;
	}
	// 8221FA74: 897B0048  lbz r11, 0x48(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(72 as u32) ) } as u64;
	// 8221FA78: 3AA00000  li r21, 0
	ctx.r[21].s64 = 0;
	// 8221FA7C: 83DB0044  lwz r30, 0x44(r27)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(68 as u32) ) } as u64;
	// 8221FA80: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 8221FA84: 7D7D0774  extsb r29, r11
	ctx.r[29].s64 = ctx.r[11].s8 as i64;
	// 8221FA88: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221FA8C: 3BE10110  addi r31, r1, 0x110
	ctx.r[31].s64 = ctx.r[1].s64 + 272;
	// 8221FA90: 3A800001  li r20, 1
	ctx.r[20].s64 = 1;
	// 8221FA94: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8221FA98: C3EBBFFC  lfs f31, -0x4004(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8221FA9C: 40990068  ble cr6, 0x8221fb04
	if !ctx.cr[6].gt {
	pc = 0x8221FB04; continue 'dispatch;
	}
	// 8221FAA0: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 8221FAA4: 409A0030  bne cr6, 0x8221fad4
	if !ctx.cr[6].eq {
	pc = 0x8221FAD4; continue 'dispatch;
	}
	// 8221FAA8: 897E0068  lbz r11, 0x68(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(104 as u32) ) } as u64;
	// 8221FAAC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221FAB0: 419A0024  beq cr6, 0x8221fad4
	if ctx.cr[6].eq {
	pc = 0x8221FAD4; continue 'dispatch;
	}
	// 8221FAB4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8221FAB8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221FABC: 48000C15  bl 0x822206d0
	ctx.lr = 0x8221FAC0;
	sub_822206D0(ctx, base);
	// 8221FAC0: 7E659B78  mr r5, r19
	ctx.r[5].u64 = ctx.r[19].u64;
	// 8221FAC4: 38810110  addi r4, r1, 0x110
	ctx.r[4].s64 = ctx.r[1].s64 + 272;
	// 8221FAC8: 48000E69  bl 0x82220930
	ctx.lr = 0x8221FACC;
	sub_82220930(ctx, base);
	// 8221FACC: 3BFF0080  addi r31, r31, 0x80
	ctx.r[31].s64 = ctx.r[31].s64 + 128;
	// 8221FAD0: 48000018  b 0x8221fae8
	pc = 0x8221FAE8; continue 'dispatch;
	// 8221FAD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8221FAD8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8221FADC: 7E9CA378  mr r28, r20
	ctx.r[28].u64 = ctx.r[20].u64;
	// 8221FAE0: 3BFF0080  addi r31, r31, 0x80
	ctx.r[31].s64 = ctx.r[31].s64 + 128;
	// 8221FAE4: 48000BED  bl 0x822206d0
	ctx.lr = 0x8221FAE8;
	sub_822206D0(ctx, base);
	// 8221FAE8: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8221FAEC: 83DE0024  lwz r30, 0x24(r30)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 8221FAF0: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8221FAF4: 4199FFAC  bgt cr6, 0x8221faa0
	if ctx.cr[6].gt {
	pc = 0x8221FAA0; continue 'dispatch;
	}
	// 8221FAF8: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 8221FAFC: 409A0840  bne cr6, 0x8222033c
	if !ctx.cr[6].eq {
	pc = 0x8222033C; continue 'dispatch;
	}
	// 8221FB00: 836161D4  lwz r27, 0x61d4(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(25044 as u32) ) } as u64;
	// 8221FB04: 897B0048  lbz r11, 0x48(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(72 as u32) ) } as u64;
	// 8221FB08: 3BC10110  addi r30, r1, 0x110
	ctx.r[30].s64 = ctx.r[1].s64 + 272;
	// 8221FB0C: 7D7F0774  extsb r31, r11
	ctx.r[31].s64 = ctx.r[11].s8 as i64;
	// 8221FB10: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8221FB14: 40990024  ble cr6, 0x8221fb38
	if !ctx.cr[6].gt {
	pc = 0x8221FB38; continue 'dispatch;
	}
	// 8221FB18: 7E659B78  mr r5, r19
	ctx.r[5].u64 = ctx.r[19].u64;
	// 8221FB1C: 38810110  addi r4, r1, 0x110
	ctx.r[4].s64 = ctx.r[1].s64 + 272;
	// 8221FB20: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8221FB24: 48000F25  bl 0x82220a48
	ctx.lr = 0x8221FB28;
	sub_82220A48(ctx, base);
	// 8221FB28: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 8221FB2C: 3BDE0080  addi r30, r30, 0x80
	ctx.r[30].s64 = ctx.r[30].s64 + 128;
	// 8221FB30: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8221FB34: 4199FFE4  bgt cr6, 0x8221fb18
	if ctx.cr[6].gt {
	pc = 0x8221FB18; continue 'dispatch;
	}
	// 8221FB38: 897B0048  lbz r11, 0x48(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(72 as u32) ) } as u64;
	// 8221FB3C: 39C00030  li r14, 0x30
	ctx.r[14].s64 = 48;
	// 8221FB40: 39E00010  li r15, 0x10
	ctx.r[15].s64 = 16;
	// 8221FB44: 7D720774  extsb r18, r11
	ctx.r[18].s64 = ctx.r[11].s8 as i64;
	// 8221FB48: 3A000020  li r16, 0x20
	ctx.r[16].s64 = 32;
	// 8221FB4C: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8221FB50: 40990554  ble cr6, 0x822200a4
	if !ctx.cr[6].gt {
	pc = 0x822200A4; continue 'dispatch;
	}
	// 8221FB54: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8221FB58: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8221FB5C: 3B41015C  addi r26, r1, 0x15c
	ctx.r[26].s64 = ctx.r[1].s64 + 348;
	// 8221FB60: C3AA2498  lfs f29, 0x2498(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(9368 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8221FB64: C3CB2150  lfs f30, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8221FB68: 3B9AFFB4  addi r28, r26, -0x4c
	ctx.r[28].s64 = ctx.r[26].s64 + -76;
	// 8221FB6C: 833AFFD4  lwz r25, -0x2c(r26)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-44 as u32) ) } as u64;
	// 8221FB70: 38C10090  addi r6, r1, 0x90
	ctx.r[6].s64 = ctx.r[1].s64 + 144;
	// 8221FB74: 7E659B78  mr r5, r19
	ctx.r[5].u64 = ctx.r[19].u64;
	// 8221FB78: 38810110  addi r4, r1, 0x110
	ctx.r[4].s64 = ctx.r[1].s64 + 272;
	// 8221FB7C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8221FB80: 48000CF1  bl 0x82220870
	ctx.lr = 0x8221FB84;
	sub_82220870(ctx, base);
	// 8221FB84: 897A0000  lbz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8221FB88: 38810110  addi r4, r1, 0x110
	ctx.r[4].s64 = ctx.r[1].s64 + 272;
	// 8221FB8C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8221FB90: 419A0044  beq cr6, 0x8221fbd4
	if ctx.cr[6].eq {
	pc = 0x8221FBD4; continue 'dispatch;
	}
	// 8221FB94: 897AFFF8  lbz r11, -8(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[26].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8221FB98: 39410110  addi r10, r1, 0x110
	ctx.r[10].s64 = ctx.r[1].s64 + 272;
	// 8221FB9C: 38C100B0  addi r6, r1, 0xb0
	ctx.r[6].s64 = ctx.r[1].s64 + 176;
	// 8221FBA0: 556B383E  rotlwi r11, r11, 7
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(7)) as u64;
	// 8221FBA4: 7CEB5214  add r7, r11, r10
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8221FBA8: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8221FBAC: 48000CC5  bl 0x82220870
	ctx.lr = 0x8221FBB0;
	sub_82220870(ctx, base);
	// 8221FBB0: 396100B0  addi r11, r1, 0xb0
	ctx.r[11].s64 = ctx.r[1].s64 + 176;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822206D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x822206D0 size=60
    let mut pc: u32 = 0x822206D0;
    'dispatch: loop {
        match pc {
            0x822206D0 => {
    //   block [0x822206D0..0x8222070C)
	// 822206D0: 39640080  addi r11, r4, 0x80
	ctx.r[11].s64 = ctx.r[4].s64 + 128;
	// 822206D4: E94B0000  ld r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 822206D8: F9430000  std r10, 0(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 822206DC: E96B0008  ld r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	// 822206E0: F9630008  std r11, 8(r3)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 822206E4: C00400A0  lfs f0, 0xa0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(160 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822206E8: D0030010  stfs f0, 0x10(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 822206EC: C0040058  lfs f0, 0x58(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822206F0: 90830018  stw r4, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[4].u32 ) };
	// 822206F4: D0030014  stfs f0, 0x14(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 822206F8: 81640040  lwz r11, 0x40(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(64 as u32) ) } as u64;
	// 822206FC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82220700: 419A000C  beq cr6, 0x8222070c
	if ctx.cr[6].eq {
		sub_8222070C(ctx, base);
		return;
	}
	// 82220704: 896B0061  lbz r11, 0x61(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(97 as u32) ) } as u64;
	// 82220708: 48000008  b 0x82220710
	sub_8222070C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8222070C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8222070C size=356
    let mut pc: u32 = 0x8222070C;
    'dispatch: loop {
        match pc {
            0x8222070C => {
    //   block [0x8222070C..0x82220870)
	// 8222070C: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 82220710: 9963001C  stb r11, 0x1c(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u8 ) };
	// 82220714: 396400D0  addi r11, r4, 0xd0
	ctx.r[11].s64 = ctx.r[4].s64 + 208;
	// 82220718: A14400A6  lhz r10, 0xa6(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(166 as u32) ) } as u64;
	// 8222071C: 39230024  addi r9, r3, 0x24
	ctx.r[9].s64 = ctx.r[3].s64 + 36;
	// 82220720: 39030048  addi r8, r3, 0x48
	ctx.r[8].s64 = ctx.r[3].s64 + 72;
	// 82220724: 5547063E  clrlwi r7, r10, 0x18
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 82220728: 54EA063E  clrlwi r10, r7, 0x18
	ctx.r[10].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8222072C: 91630020  stw r11, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 82220730: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82220734: 98E3001D  stb r7, 0x1d(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(29 as u32), ctx.r[7].u8 ) };
	// 82220738: 98E3001F  stb r7, 0x1f(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(31 as u32), ctx.r[7].u8 ) };
	// 8222073C: 40990034  ble cr6, 0x82220770
	if !ctx.cr[6].gt {
	pc = 0x82220770; continue 'dispatch;
	}
	// 82220740: 38E00260  li r7, 0x260
	ctx.r[7].s64 = 608;
	// 82220744: 7C075A2C  dcbt r7, r11
	// 82220748: 80EB0050  lwz r7, 0x50(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 8222074C: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82220750: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 82220754: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82220758: 90E90000  stw r7, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 8222075C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82220760: 80E700D4  lwz r7, 0xd4(r7)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(212 as u32) ) } as u64;
	// 82220764: 98E80000  stb r7, 0(r8)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[7].u8 ) };
	// 82220768: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8222076C: 4199FFD4  bgt cr6, 0x82220740
	if ctx.cr[6].gt {
	pc = 0x82220740; continue 'dispatch;
	}
	// 82220770: A16400A4  lhz r11, 0xa4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(164 as u32) ) } as u64;
	// 82220774: 39430044  addi r10, r3, 0x44
	ctx.r[10].s64 = ctx.r[3].s64 + 68;
	// 82220778: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 8222077C: 5567063E  clrlwi r7, r11, 0x18
	ctx.r[7].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82220780: 396400A8  addi r11, r4, 0xa8
	ctx.r[11].s64 = ctx.r[4].s64 + 168;
	// 82220784: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 82220788: 2F080004  cmpwi cr6, r8, 4
	ctx.cr[6].compare_i32(ctx.r[8].s32, 4, &mut ctx.xer);
	// 8222078C: 98E3001E  stb r7, 0x1e(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(30 as u32), ctx.r[7].u8 ) };
	// 82220790: 41980080  blt cr6, 0x82220810
	if ctx.cr[6].lt {
	pc = 0x82220810; continue 'dispatch;
	}
	// 82220794: 38E8FFFC  addi r7, r8, -4
	ctx.r[7].s64 = ctx.r[8].s64 + -4;
	// 82220798: 54E7F0BE  srwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8222079C: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 822207A0: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 822207A4: 7D064050  subf r8, r6, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[6].s64;
	// 822207A8: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 822207AC: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 822207B0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 822207B4: 88C60061  lbz r6, 0x61(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[6].u32.wrapping_add(97 as u32) ) } as u64;
	// 822207B8: 98CA0000  stb r6, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[6].u8 ) };
	// 822207BC: C00B0004  lfs f0, 4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822207C0: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 822207C4: 80CB0008  lwz r6, 8(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 822207C8: 88C60061  lbz r6, 0x61(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[6].u32.wrapping_add(97 as u32) ) } as u64;
	// 822207CC: 98CA0001  stb r6, 1(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(1 as u32), ctx.r[6].u8 ) };
	// 822207D0: C00B000C  lfs f0, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822207D4: D0090004  stfs f0, 4(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 822207D8: 80CB0010  lwz r6, 0x10(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 822207DC: 88C60061  lbz r6, 0x61(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[6].u32.wrapping_add(97 as u32) ) } as u64;
	// 822207E0: 98CA0002  stb r6, 2(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(2 as u32), ctx.r[6].u8 ) };
	// 822207E4: C00B0014  lfs f0, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822207E8: D0090008  stfs f0, 8(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 822207EC: 80CB0018  lwz r6, 0x18(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 822207F0: 88C60061  lbz r6, 0x61(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[6].u32.wrapping_add(97 as u32) ) } as u64;
	// 822207F4: 98CA0003  stb r6, 3(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(3 as u32), ctx.r[6].u8 ) };
	// 822207F8: C00B001C  lfs f0, 0x1c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 822207FC: D009000C  stfs f0, 0xc(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82220800: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82220804: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82220808: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 8222080C: 409AFF9C  bne cr6, 0x822207a8
	if !ctx.cr[6].eq {
	pc = 0x822207A8; continue 'dispatch;
	}
	// 82220810: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82220814: 40990030  ble cr6, 0x82220844
	if !ctx.cr[6].gt {
	pc = 0x82220844; continue 'dispatch;
	}
	// 82220818: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8222081C: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82220820: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82220824: 88E70061  lbz r7, 0x61(r7)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(97 as u32) ) } as u64;
	// 82220828: 98EA0000  stb r7, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u8 ) };
	// 8222082C: C00B0004  lfs f0, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82220830: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82220834: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82220838: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8222083C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82220840: 4199FFD8  bgt cr6, 0x82220818
	if ctx.cr[6].gt {
	pc = 0x82220818; continue 'dispatch;
	}
	// 82220844: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 82220848: C1A40044  lfs f13, 0x44(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(68 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8222084C: C00B2150  lfs f0, 0x2150(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8528 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82220850: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82220854: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82220858: 41980008  blt cr6, 0x82220860
	if ctx.cr[6].lt {
	pc = 0x82220860; continue 'dispatch;
	}
	// 8222085C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82220860: 9963004C  stb r11, 0x4c(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), ctx.r[11].u8 ) };
	// 82220864: 8964004F  lbz r11, 0x4f(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(79 as u32) ) } as u64;
	// 82220868: 9963004D  stb r11, 0x4d(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(77 as u32), ctx.r[11].u8 ) };
	// 8222086C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82220870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82220870 size=124
    let mut pc: u32 = 0x82220870;
    'dispatch: loop {
        match pc {
            0x82220870 => {
    //   block [0x82220870..0x822208EC)
	// 82220870: 8963001C  lbz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82220874: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82220878: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8222087C: 40980094  bge cr6, 0x82220910
	if !ctx.cr[6].lt {
		sub_82220910(ctx, base);
		return;
	}
	// 82220880: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82220884: 816A0040  lwz r11, 0x40(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 82220888: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8222088C: 409A007C  bne cr6, 0x82220908
	if !ctx.cr[6].eq {
		sub_82220908(ctx, base);
		return;
	}
	// 82220890: A16A0022  lhz r11, 0x22(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(34 as u32) ) } as u64;
	// 82220894: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 82220898: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 8222089C: 419A0050  beq cr6, 0x822208ec
	if ctx.cr[6].eq {
		sub_822208EC(ctx, base);
		return;
	}
	// 822208A0: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 822208A4: 556B3032  slwi r11, r11, 6
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(6);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 822208A8: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 822208AC: 7D6B2A14  add r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 822208B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_822208EC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x822208EC size=28
    let mut pc: u32 = 0x822208EC;
    'dispatch: loop {
        match pc {
            0x822208EC => {
    //   block [0x822208EC..0x82220908)
	// 822208EC: 396A0010  addi r11, r10, 0x10
	ctx.r[11].s64 = ctx.r[10].s64 + 16;
	// 822208F0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 822208F4: E94B0000  ld r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 822208F8: F9460000  std r10, 0(r6)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 822208FC: E96B0008  ld r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	// 82220900: F9660008  std r11, 8(r6)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 82220904: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82220908(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82220908 size=8
    let mut pc: u32 = 0x82220908;
    'dispatch: loop {
        match pc {
            0x82220908 => {
    //   block [0x82220908..0x82220910)
	// 82220908: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 8222090C: 4800000C  b 0x82220918
	sub_82220910(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}



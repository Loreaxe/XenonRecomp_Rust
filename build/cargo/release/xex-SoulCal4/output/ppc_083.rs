pub fn sub_8258B664(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B664 size=20
    let mut pc: u32 = 0x8258B664;
    'dispatch: loop {
        match pc {
            0x8258B664 => {
    //   block [0x8258B664..0x8258B678)
	// 8258B664: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258B668: 816B0040  lwz r11, 0x40(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 8258B66C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B670: 5563A63E  rlwinm r3, r11, 0x14, 0x18, 0x1f
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x00000FFFu64;
	// 8258B674: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B678(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B678 size=28
    let mut pc: u32 = 0x8258B678;
    'dispatch: loop {
        match pc {
            0x8258B678 => {
    //   block [0x8258B678..0x8258B694)
	// 8258B678: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B67C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B680: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 8258B684: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B688: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258B68C: 806B004C  lwz r3, 0x4c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258B690: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B698(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B698 size=84
    let mut pc: u32 = 0x8258B698;
    'dispatch: loop {
        match pc {
            0x8258B698 => {
    //   block [0x8258B698..0x8258B6EC)
	// 8258B698: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B69C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B6A0: 556B039C  rlwinm r11, r11, 0, 0xe, 0xe
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258B6A4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B6A8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B6AC: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 8258B6B0: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B6B4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258B6B8: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8258B6BC: 409A0008  bne cr6, 0x8258b6c4
	if !ctx.cr[6].eq {
	pc = 0x8258B6C4; continue 'dispatch;
	}
	// 8258B6C0: 816A0040  lwz r11, 0x40(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 8258B6C4: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B6C8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258B6CC: 55290296  rlwinm r9, r9, 0, 0xa, 0xb
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 8258B6D0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258B6D4: 409A0018  bne cr6, 0x8258b6ec
	if !ctx.cr[6].eq {
		sub_8258B6EC(ctx, base);
		return;
	}
	// 8258B6D8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258B6DC: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258B6E0: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258B6E4: 91650008  stw r11, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258B6E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B6EC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B6EC size=52
    let mut pc: u32 = 0x8258B6EC;
    'dispatch: loop {
        match pc {
            0x8258B6EC => {
    //   block [0x8258B6EC..0x8258B720)
	// 8258B6EC: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258B6F0: 55290FFE  srwi r9, r9, 0x1f
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(31);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258B6F4: 39290015  addi r9, r9, 0x15
	ctx.r[9].s64 = ctx.r[9].s64 + 21;
	// 8258B6F8: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258B6FC: 7D49502E  lwzx r10, r9, r10
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 8258B700: 91450000  stw r10, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8258B704: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B708: 554A01BE  clrlwi r10, r10, 6
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x03FFFFFFu64;
	// 8258B70C: 91450004  stw r10, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258B710: 896B0004  lbz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B714: 556B077E  clrlwi r11, r11, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 8258B718: 91650008  stw r11, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258B71C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B720 size=52
    let mut pc: u32 = 0x8258B720;
    'dispatch: loop {
        match pc {
            0x8258B720 => {
    //   block [0x8258B720..0x8258B754)
	// 8258B720: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B724: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B728: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258B72C: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 8258B730: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B734: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258B738: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B73C: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B740: 5145000A  rlwimi r5, r10, 0, 0, 5
	ctx.r[5].u64 = (((ctx.r[10].u32).rotate_left(0) as u64) & 0x00000000FC000000) | (ctx.r[5].u64 & 0xFFFFFFFF03FFFFFF);
	// 8258B744: 50C9C14E  rlwimi r9, r6, 0x18, 5, 7
	ctx.r[9].u64 = (((ctx.r[6].u32).rotate_left(24) as u64) & 0x0000000007000000) | (ctx.r[9].u64 & 0xFFFFFFFFF8FFFFFF);
	// 8258B748: 90AB0008  stw r5, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 8258B74C: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8258B750: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B758(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258B758 size=80
    let mut pc: u32 = 0x8258B758;
    'dispatch: loop {
        match pc {
            0x8258B758 => {
    //   block [0x8258B758..0x8258B7A8)
	// 8258B758: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258B75C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258B760: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258B764: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258B768: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258B76C: 4BFFF76D  bl 0x8258aed8
	ctx.lr = 0x8258B770;
	sub_8258AED8(ctx, base);
	// 8258B770: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B774: 556B07BC  rlwinm r11, r11, 0, 0x1e, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258B778: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B77C: 409A0014  bne cr6, 0x8258b790
	if !ctx.cr[6].eq {
	pc = 0x8258B790; continue 'dispatch;
	}
	// 8258B780: 3C80A782  lis r4, -0x587e
	ctx.r[4].s64 = -1484652544;
	// 8258B784: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258B788: 60840007  ori r4, r4, 7
	ctx.r[4].u64 = ctx.r[4].u64 | 7;
	// 8258B78C: 4BE3EACD  bl 0x823ca258
	ctx.lr = 0x8258B790;
	sub_823CA258(ctx, base);
	// 8258B790: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258B794: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258B798: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258B79C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258B7A0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258B7A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B7A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258B7A8 size=224
    let mut pc: u32 = 0x8258B7A8;
    'dispatch: loop {
        match pc {
            0x8258B7A8 => {
    //   block [0x8258B7A8..0x8258B888)
	// 8258B7A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258B7AC: 4BFA990D  bl 0x825350b8
	ctx.lr = 0x8258B7B0;
	sub_82535080(ctx, base);
	// 8258B7B0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258B7B4: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B7B8: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B7BC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8258B7C0: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 8258B7C4: 54DEAAFE  srwi r30, r6, 0xb
	ctx.r[30].u32 = ctx.r[6].u32.wrapping_shr(11);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8258B7C8: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258B7CC: 7FEB5214  add r31, r11, r10
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258B7D0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B7D4: 557C67BE  rlwinm r28, r11, 0xc, 0x1e, 0x1f
	ctx.r[28].u64 = ctx.r[11].u32 as u64 & 0x000FFFFFu64;
	// 8258B7D8: 578B07FE  clrlwi r11, r28, 0x1f
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0x00000001u64;
	// 8258B7DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B7E0: 409A0028  bne cr6, 0x8258b808
	if !ctx.cr[6].eq {
	pc = 0x8258B808; continue 'dispatch;
	}
	// 8258B7E4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258B7E8: 481820E5  bl 0x8270d8cc
	ctx.lr = 0x8258B7EC;
	// extern call 0x8270D8CC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 8258B7EC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B7F0: 907F0014  stw r3, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 8258B7F4: 517E0026  rlwimi r30, r11, 0, 0, 0x13
	ctx.r[30].u64 = (((ctx.r[11].u32).rotate_left(0) as u64) & 0x00000000FFFFF000) | (ctx.r[30].u64 & 0xFFFFFFFF00000FFF);
	// 8258B7F8: 67CB0010  oris r11, r30, 0x10
	ctx.r[11].u64 = ctx.r[30].u64 | 1048576;
	// 8258B7FC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258B800: 93BF0054  stw r29, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[29].u32 ) };
	// 8258B804: 48000038  b 0x8258b83c
	pc = 0x8258B83C; continue 'dispatch;
	// 8258B808: 578B07BC  rlwinm r11, r28, 0, 0x1e, 0x1e
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0xFFFFFFFFu64;
	// 8258B80C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B810: 409A0068  bne cr6, 0x8258b878
	if !ctx.cr[6].eq {
	pc = 0x8258B878; continue 'dispatch;
	}
	// 8258B814: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258B818: 481820B5  bl 0x8270d8cc
	ctx.lr = 0x8258B81C;
	// extern call 0x8270D8CC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 8258B81C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B820: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B824: 517E0026  rlwimi r30, r11, 0, 0, 0x13
	ctx.r[30].u64 = (((ctx.r[11].u32).rotate_left(0) as u64) & 0x00000000FFFFF000) | (ctx.r[30].u64 & 0xFFFFFFFF00000FFF);
	// 8258B828: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 8258B82C: 654B0020  oris r11, r10, 0x20
	ctx.r[11].u64 = ctx.r[10].u64 | 2097152;
	// 8258B830: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8258B834: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258B838: 93BF0058  stw r29, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[29].u32 ) };
	// 8258B83C: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 8258B840: 409A002C  bne cr6, 0x8258b86c
	if !ctx.cr[6].eq {
	pc = 0x8258B86C; continue 'dispatch;
	}
	// 8258B844: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B848: 2B0B7FFF  cmplwi cr6, r11, 0x7fff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32767 as u32, &mut ctx.xer);
	// 8258B84C: 419A0020  beq cr6, 0x8258b86c
	if ctx.cr[6].eq {
	pc = 0x8258B86C; continue 'dispatch;
	}
	// 8258B850: 556BAC7E  rlwinm r11, r11, 0x15, 0x11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000007FFu64;
	// 8258B854: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 8258B858: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B85C: 419A0010  beq cr6, 0x8258b86c
	if ctx.cr[6].eq {
	pc = 0x8258B86C; continue 'dispatch;
	}
	// 8258B860: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B864: 514B000A  rlwimi r11, r10, 0, 0, 5
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(0) as u64) & 0x00000000FC000000) | (ctx.r[11].u64 & 0xFFFFFFFF03FFFFFF);
	// 8258B868: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258B86C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258B870: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258B874: 4BFA9894  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 8258B878: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 8258B87C: 60630005  ori r3, r3, 5
	ctx.r[3].u64 = ctx.r[3].u64 | 5;
	// 8258B880: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258B884: 4BFA9884  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B888(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B888 size=336
    let mut pc: u32 = 0x8258B888;
    'dispatch: loop {
        match pc {
            0x8258B888 => {
    //   block [0x8258B888..0x8258B9D8)
	// 8258B888: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 8258B88C: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8258B890: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 8258B894: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258B898: 556B039C  rlwinm r11, r11, 0, 0xe, 0xe
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258B89C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258B8A0: 409A0118  bne cr6, 0x8258b9b8
	if !ctx.cr[6].eq {
	pc = 0x8258B9B8; continue 'dispatch;
	}
	// 8258B8A4: 3D607FEA  lis r11, 0x7fea
	ctx.r[11].s64 = 2146041856;
	// 8258B8A8: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B8AC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8258B8B0: 616B1818  ori r11, r11, 0x1818
	ctx.r[11].u64 = ctx.r[11].u64 | 6168;
	// 8258B8B4: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8258B8B8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258B8BC: 7D605C2C  lwbrx r11, 0, r11
	ctx.r[11].u64 = (unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32) }).swap_bytes() as u64;
	// 8258B8C0: 69670200  xori r7, r11, 0x200
	ctx.r[7].u64 = ctx.r[11].u64 ^ 512;
	// 8258B8C4: 419A002C  beq cr6, 0x8258b8f0
	if ctx.cr[6].eq {
	pc = 0x8258B8F0; continue 'dispatch;
	}
	// 8258B8C8: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B8CC: 396B0050  addi r11, r11, 0x50
	ctx.r[11].s64 = ctx.r[11].s64 + 80;
	// 8258B8D0: A0CB0000  lhz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B8D4: 7F063840  cmplw cr6, r6, r7
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8258B8D8: 419A00F0  beq cr6, 0x8258b9c8
	if ctx.cr[6].eq {
	pc = 0x8258B9C8; continue 'dispatch;
	}
	// 8258B8DC: 80C90000  lwz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B8E0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8258B8E4: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 8258B8E8: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8258B8EC: 4198FFE4  blt cr6, 0x8258b8d0
	if ctx.cr[6].lt {
	pc = 0x8258B8D0; continue 'dispatch;
	}
	// 8258B8F0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258B8F4: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258B8F8: 419A00B4  beq cr6, 0x8258b9ac
	if ctx.cr[6].eq {
	pc = 0x8258B9AC; continue 'dispatch;
	}
	// 8258B8FC: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 8258B900: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 8258B904: 38A00020  li r5, 0x20
	ctx.r[5].s64 = 32;
	// 8258B908: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B90C: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258B910: 38CB0010  addi r6, r11, 0x10
	ctx.r[6].s64 = ctx.r[11].s64 + 16;
	// 8258B914: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258B9D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258B9D8 size=288
    let mut pc: u32 = 0x8258B9D8;
    'dispatch: loop {
        match pc {
            0x8258B9D8 => {
    //   block [0x8258B9D8..0x8258BAF8)
	// 8258B9D8: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8258B9DC: 80A70000  lwz r5, 0(r7)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B9E0: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8258B9E4: 419A0044  beq cr6, 0x8258ba28
	if ctx.cr[6].eq {
	pc = 0x8258BA28; continue 'dispatch;
	}
	// 8258B9E8: 81070008  lwz r8, 8(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258B9EC: 54A6003E  slwi r6, r5, 0
	ctx.r[6].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8258B9F0: 81480000  lwz r10, 0(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258B9F4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258B9F8: 81280044  lwz r9, 0x44(r8)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(68 as u32) ) } as u64;
	// 8258B9FC: 554A94EE  rlwinm r10, r10, 0x12, 0x13, 0x17
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x00003FFFu64;
	// 8258BA00: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BA04: 419A0014  beq cr6, 0x8258ba18
	if ctx.cr[6].eq {
	pc = 0x8258BA18; continue 'dispatch;
	}
	// 8258BA08: 7C0B48AC  dcbf r11, r9
	// 8258BA0C: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 8258BA10: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258BA14: 4198FFF4  blt cr6, 0x8258ba08
	if ctx.cr[6].lt {
	pc = 0x8258BA08; continue 'dispatch;
	}
	// 8258BA18: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8258BA1C: 39080060  addi r8, r8, 0x60
	ctx.r[8].s64 = ctx.r[8].s64 + 96;
	// 8258BA20: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8258BA24: 409AFFCC  bne cr6, 0x8258b9f0
	if !ctx.cr[6].eq {
	pc = 0x8258B9F0; continue 'dispatch;
	}
	// 8258BA28: 81670004  lwz r11, 4(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BA2C: 556B039C  rlwinm r11, r11, 0, 0xe, 0xe
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258BA30: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BA34: 419A0054  beq cr6, 0x8258ba88
	if ctx.cr[6].eq {
	pc = 0x8258BA88; continue 'dispatch;
	}
	// 8258BA38: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8258BA3C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8258BA40: 419A0048  beq cr6, 0x8258ba88
	if ctx.cr[6].eq {
	pc = 0x8258BA88; continue 'dispatch;
	}
	// 8258BA44: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258BA48: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 8258BA4C: 38C00020  li r6, 0x20
	ctx.r[6].s64 = 32;
	// 8258BA50: 81670008  lwz r11, 8(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258BA54: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8258BA58: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 8258BA5C: 39290060  addi r9, r9, 0x60
	ctx.r[9].s64 = ctx.r[9].s64 + 96;
	// 8258BA60: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BAF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258BAF8 size=528
    let mut pc: u32 = 0x8258BAF8;
    'dispatch: loop {
        match pc {
            0x8258BAF8 => {
    //   block [0x8258BAF8..0x8258BD08)
	// 8258BAF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258BAFC: 4BFA95A9  bl 0x825350a4
	ctx.lr = 0x8258BB00;
	sub_82535080(ctx, base);
	// 8258BB00: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258BB04: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258BB08: 7C992378  mr r25, r4
	ctx.r[25].u64 = ctx.r[4].u64;
	// 8258BB0C: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 8258BB10: 7CD73378  mr r23, r6
	ctx.r[23].u64 = ctx.r[6].u64;
	// 8258BB14: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 8258BB18: 4BFFF299  bl 0x8258adb0
	ctx.lr = 0x8258BB1C;
	sub_8258ADB0(ctx, base);
	// 8258BB1C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258BB20: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 8258BB24: 409A002C  bne cr6, 0x8258bb50
	if !ctx.cr[6].eq {
	pc = 0x8258BB50; continue 'dispatch;
	}
	// 8258BB28: 3C80A782  lis r4, -0x587e
	ctx.r[4].s64 = -1484652544;
	// 8258BB2C: 60840007  ori r4, r4, 7
	ctx.r[4].u64 = ctx.r[4].u64 | 7;
	// 8258BB30: 4BE3E691  bl 0x823ca1c0
	ctx.lr = 0x8258BB34;
	sub_823CA1C0(ctx, base);
	// 8258BB34: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 8258BB38: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 8258BB3C: 409A0014  bne cr6, 0x8258bb50
	if !ctx.cr[6].eq {
	pc = 0x8258BB50; continue 'dispatch;
	}
	// 8258BB40: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 8258BB44: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 8258BB48: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258BB4C: 4BFA95A8  b 0x825350f4
	sub_825350D0(ctx, base);
	return;
	// 8258BB50: 576B083C  slwi r11, r27, 1
	ctx.r[11].u32 = ctx.r[27].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258BB54: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8258BB58: 7D7B5A14  add r11, r27, r11
	ctx.r[11].u64 = ctx.r[27].u64 + ctx.r[11].u64;
	// 8258BB5C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8258BB60: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258BB64: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258BB68: 396B008F  addi r11, r11, 0x8f
	ctx.r[11].s64 = ctx.r[11].s64 + 143;
	// 8258BB6C: 557F0030  rlwinm r31, r11, 0, 0, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258BB70: 7FDFF050  subf r30, r31, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 8258BB74: 4BE34E2D  bl 0x823c09a0
	ctx.lr = 0x8258BB78;
	sub_823C09A0(ctx, base);
	// 8258BB78: 395A0010  addi r10, r26, 0x10
	ctx.r[10].s64 = ctx.r[26].s64 + 16;
	// 8258BB7C: 937A0000  stw r27, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 8258BB80: 7FBFD214  add r29, r31, r26
	ctx.r[29].u64 = ctx.r[31].u64 + ctx.r[26].u64;
	// 8258BB84: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258BB88: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8258BB8C: 915A0008  stw r10, 8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8258BB90: 419A0014  beq cr6, 0x8258bba4
	if ctx.cr[6].eq {
	pc = 0x8258BBA4; continue 'dispatch;
	}
	// 8258BB94: 7C0BE8AC  dcbf r11, r29
	// 8258BB98: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 8258BB9C: 7F0BF040  cmplw cr6, r11, r30
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[30].u32, &mut ctx.xer);
	// 8258BBA0: 4198FFF4  blt cr6, 0x8258bb94
	if ctx.cr[6].lt {
	pc = 0x8258BB94; continue 'dispatch;
	}
	// 8258BBA4: 670B0003  oris r11, r24, 3
	ctx.r[11].u64 = ctx.r[24].u64 | 196608;
	// 8258BBA8: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 8258BBAC: 917A0004  stw r11, 4(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258BBB0: 419A00F4  beq cr6, 0x8258bca4
	if ctx.cr[6].eq {
	pc = 0x8258BCA4; continue 'dispatch;
	}
	// 8258BBB4: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 8258BBB8: 3BD90008  addi r30, r25, 8
	ctx.r[30].s64 = ctx.r[25].s64 + 8;
	// 8258BBBC: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 8258BBC0: 6179AC44  ori r25, r11, 0xac44
	ctx.r[25].u64 = ctx.r[11].u64 | 44100;
	// 8258BBC4: 817A0008  lwz r11, 8(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258BBC8: 7FFC5A14  add r31, r28, r11
	ctx.r[31].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 8258BBCC: 93BF0044  stw r29, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[29].u32 ) };
	// 8258BBD0: 817EFFF8  lwz r11, -8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258BBD4: 2B0B5DC0  cmplwi cr6, r11, 0x5dc0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 24000 as u32, &mut ctx.xer);
	// 8258BBD8: 4199000C  bgt cr6, 0x8258bbe4
	if ctx.cr[6].gt {
	pc = 0x8258BBE4; continue 'dispatch;
	}
	// 8258BBDC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258BBE0: 48000024  b 0x8258bc04
	pc = 0x8258BC04; continue 'dispatch;
	// 8258BBE4: 2B0B7D00  cmplwi cr6, r11, 0x7d00
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32000 as u32, &mut ctx.xer);
	// 8258BBE8: 4199000C  bgt cr6, 0x8258bbf4
	if ctx.cr[6].gt {
	pc = 0x8258BBF4; continue 'dispatch;
	}
	// 8258BBEC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8258BBF0: 48000014  b 0x8258bc04
	pc = 0x8258BC04; continue 'dispatch;
	// 8258BBF4: 7D6BC810  subfc r11, r11, r25
	ctx.xer.ca = ctx.r[25].u32 >= ctx.r[11].u32;
	ctx.r[11].s64 = ctx.r[25].s64 - ctx.r[11].s64;
	// 8258BBF8: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8258BBFC: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 8258BC00: 394B0002  addi r10, r11, 2
	ctx.r[10].s64 = ctx.r[11].s64 + 2;
	// 8258BC04: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BC08: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258BC0C: 514BD8C8  rlwimi r11, r10, 0x1b, 3, 4
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(27) as u64) & 0x0000000018000000) | (ctx.r[11].u64 & 0xFFFFFFFFE7FFFFFF);
	// 8258BC10: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258BC14: 895E0000  lbz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BC18: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8258BC1C: 514BE884  rlwimi r11, r10, 0x1d, 2, 2
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(29) as u64) & 0x0000000020000000) | (ctx.r[11].u64 & 0xFFFFFFFFDFFFFFFF);
	// 8258BC20: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8258BC24: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258BC28: 897E0001  lbz r11, 1(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 8258BC2C: 516AA216  rlwimi r10, r11, 0x14, 8, 0xb
	ctx.r[10].u64 = (((ctx.r[11].u32).rotate_left(20) as u64) & 0x0000000000F00000) | (ctx.r[10].u64 & 0xFFFFFFFFFF0FFFFF);
	// 8258BC30: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258BC34: 48181C99  bl 0x8270d8cc
	ctx.lr = 0x8258BC38;
	// extern call 0x8270D8CC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 8258BC38: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BC3C: 907F001C  stw r3, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[3].u32 ) };
	// 8258BC40: 654A8000  oris r10, r10, 0x8000
	ctx.r[10].u64 = ctx.r[10].u64 | 2147483648;
	// 8258BC44: 893E0000  lbz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BC48: 811EFFFC  lwz r8, -4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) } as u64;
	// 8258BC4C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BC50: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258BC54: 7D4941D6  mullw r10, r9, r8
	ctx.r[10].s64 = (ctx.r[9].s32 as i64) * (ctx.r[8].s32 as i64);
	// 8258BC58: 514B7952  rlwimi r11, r10, 0xf, 5, 9
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(15) as u64) & 0x0000000007C00000) | (ctx.r[11].u64 & 0xFFFFFFFFF83FFFFF);
	// 8258BC5C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258BC60: 897E0000  lbz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BC64: 815EFFFC  lwz r10, -4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) } as u64;
	// 8258BC68: 7D6B51D6  mullw r11, r11, r10
	ctx.r[11].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8258BC6C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258BC70: 7FABEA14  add r29, r11, r29
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8258BC74: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258BC78: 93BF0048  stw r29, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[29].u32 ) };
	// 8258BC7C: 48181C51  bl 0x8270d8cc
	ctx.lr = 0x8258BC80;
	// extern call 0x8270D8CC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 8258BC80: 907F0020  stw r3, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 8258BC84: 3B7BFFFF  addi r27, r27, -1
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	// 8258BC88: 897E0000  lbz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BC8C: 3B9C0060  addi r28, r28, 0x60
	ctx.r[28].s64 = ctx.r[28].s64 + 96;
	// 8258BC90: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 8258BC94: 556B403E  rotlwi r11, r11, 8
	ctx.r[11].u64 = ((ctx.r[11].u32).rotate_left(8)) as u64;
	// 8258BC98: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 8258BC9C: 7FABEA14  add r29, r11, r29
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8258BCA0: 409AFF24  bne cr6, 0x8258bbc4
	if !ctx.cr[6].eq {
	pc = 0x8258BBC4; continue 'dispatch;
	}
	// 8258BCA4: 570B07FE  clrlwi r11, r24, 0x1f
	ctx.r[11].u64 = ctx.r[24].u32 as u64 & 0x00000001u64;
	// 8258BCA8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BCAC: 409A004C  bne cr6, 0x8258bcf8
	if !ctx.cr[6].eq {
	pc = 0x8258BCF8; continue 'dispatch;
	}
	// 8258BCB0: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258BCB4: 4BFFF155  bl 0x8258ae08
	ctx.lr = 0x8258BCB8;
	sub_8258AE08(ctx, base);
	// 8258BCB8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258BCBC: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8258BCC0: 40980038  bge cr6, 0x8258bcf8
	if !ctx.cr[6].lt {
	pc = 0x8258BCF8; continue 'dispatch;
	}
	// 8258BCC4: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258BCC8: 4BFFF211  bl 0x8258aed8
	ctx.lr = 0x8258BCCC;
	sub_8258AED8(ctx, base);
	// 8258BCCC: 817A0004  lwz r11, 4(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BCD0: 556B07BC  rlwinm r11, r11, 0, 0x1e, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258BCD4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BCD8: 409A0014  bne cr6, 0x8258bcec
	if !ctx.cr[6].eq {
	pc = 0x8258BCEC; continue 'dispatch;
	}
	// 8258BCDC: 3C80A782  lis r4, -0x587e
	ctx.r[4].s64 = -1484652544;
	// 8258BCE0: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258BCE4: 60840007  ori r4, r4, 7
	ctx.r[4].u64 = ctx.r[4].u64 | 7;
	// 8258BCE8: 4BE3E571  bl 0x823ca258
	ctx.lr = 0x8258BCEC;
	sub_823CA258(ctx, base);
	// 8258BCEC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258BCF0: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258BCF4: 4BFA9400  b 0x825350f4
	sub_825350D0(ctx, base);
	return;
	// 8258BCF8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258BCFC: 93570000  stw r26, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 8258BD00: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258BD04: 4BFA93F0  b 0x825350f4
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BD08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258BD08 size=200
    let mut pc: u32 = 0x8258BD08;
    'dispatch: loop {
        match pc {
            0x8258BD08 => {
    //   block [0x8258BD08..0x8258BDD0)
	// 8258BD08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258BD0C: 4BFA93B1  bl 0x825350bc
	ctx.lr = 0x8258BD10;
	sub_82535080(ctx, base);
	// 8258BD10: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258BD14: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258BD18: 7FAC42E6  mftb r29, 0x10c
	ctx.r[29].u64 = crate::rt::rdtsc_u64();
	// 8258BD1C: 4BFFFB6D  bl 0x8258b888
	ctx.lr = 0x8258BD20;
	sub_8258B888(ctx, base);
	// 8258BD20: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258BD24: 409A0030  bne cr6, 0x8258bd54
	if !ctx.cr[6].eq {
	pc = 0x8258BD54; continue 'dispatch;
	}
	// 8258BD28: 7D6C42E6  mftb r11, 0x10c
	ctx.r[11].u64 = crate::rt::rdtsc_u64();
	// 8258BD2C: 7FFD5850  subf r31, r29, r11
	ctx.r[31].s64 = ctx.r[11].s64 - ctx.r[29].s64;
	// 8258BD30: 48181BCD  bl 0x8270d8fc
	ctx.lr = 0x8258BD34;
	// extern call 0x8270D8FC → crate::xboxkrnl::KeQueryPerformanceFrequency
	crate::xboxkrnl::KeQueryPerformanceFrequency(ctx, base);
	// 8258BD34: 786BE8C2  rldicl r11, r3, 0x3d, 3
	ctx.r[11].u64 = ctx.r[3].u64 & 0x0000000000000007u64;
	// 8258BD38: 7F3F5840  cmpld cr6, r31, r11
	ctx.cr[6].compare_u64(ctx.r[31].u64, ctx.r[11].u64, &mut ctx.xer);
	// 8258BD3C: 41990028  bgt cr6, 0x8258bd64
	if ctx.cr[6].gt {
	pc = 0x8258BD64; continue 'dispatch;
	}
	// 8258BD40: 7FFFFB78  mr r31, r31
	ctx.r[31].u64 = ctx.r[31].u64;
	// 8258BD44: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258BD48: 4BFFFB41  bl 0x8258b888
	ctx.lr = 0x8258BD4C;
	sub_8258B888(ctx, base);
	// 8258BD4C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258BD50: 419AFFD8  beq cr6, 0x8258bd28
	if ctx.cr[6].eq {
	pc = 0x8258BD28; continue 'dispatch;
	}
	// 8258BD54: 48181BA9  bl 0x8270d8fc
	ctx.lr = 0x8258BD58;
	// extern call 0x8270D8FC → crate::xboxkrnl::KeQueryPerformanceFrequency
	crate::xboxkrnl::KeQueryPerformanceFrequency(ctx, base);
	// 8258BD58: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258BD5C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258BD60: 4BFA93AC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 8258BD64: 3D607FEA  lis r11, 0x7fea
	ctx.r[11].s64 = 2146041856;
	// 8258BD68: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8258BD6C: 616B1804  ori r11, r11, 0x1804
	ctx.r[11].u64 = ctx.r[11].u64 | 6148;
	// 8258BD70: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8258BD74: 7FE0512E  stwx r31, 0, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, ctx.r[31].u32) };
	// 8258BD78: 7C0006AC  eieio
	// 8258BD7C: 3D400300  lis r10, 0x300
	ctx.r[10].s64 = 50331648;
	// 8258BD80: 7D40592E  stwx r10, 0, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, ctx.r[10].u32) };
	// 8258BD84: 7C0006AC  eieio
	// 8258BD88: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258BD8C: 4BFFFAFD  bl 0x8258b888
	ctx.lr = 0x8258BD90;
	sub_8258B888(ctx, base);
	// 8258BD90: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BD94: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BD98: 40990020  ble cr6, 0x8258bdb8
	if !ctx.cr[6].gt {
	pc = 0x8258BDB8; continue 'dispatch;
	}
	// 8258BD9C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258BDA0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258BDA4: 4BFFF6D5  bl 0x8258b478
	ctx.lr = 0x8258BDA8;
	sub_8258B478(ctx, base);
	// 8258BDA8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BDAC: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 8258BDB0: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258BDB4: 4198FFE8  blt cr6, 0x8258bd9c
	if ctx.cr[6].lt {
	pc = 0x8258BD9C; continue 'dispatch;
	}
	// 8258BDB8: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BDBC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8258BDC0: 656B0008  oris r11, r11, 8
	ctx.r[11].u64 = ctx.r[11].u64 | 524288;
	// 8258BDC4: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258BDC8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258BDCC: 4BFA9340  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BDD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BDD0 size=32
    let mut pc: u32 = 0x8258BDD0;
    'dispatch: loop {
        match pc {
            0x8258BDD0 => {
    //   block [0x8258BDD0..0x8258BDF0)
	// 8258BDD0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258BDD4: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 8258BDD8: 409A0008  bne cr6, 0x8258bde0
	if !ctx.cr[6].eq {
	pc = 0x8258BDE0; continue 'dispatch;
	}
	// 8258BDDC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258BDE0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BDE4: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BDE8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258BDEC: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BDF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BDF0 size=32
    let mut pc: u32 = 0x8258BDF0;
    'dispatch: loop {
        match pc {
            0x8258BDF0 => {
    //   block [0x8258BDF0..0x8258BE10)
	// 8258BDF0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258BDF4: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 8258BDF8: 409A0008  bne cr6, 0x8258be00
	if !ctx.cr[6].eq {
	pc = 0x8258BE00; continue 'dispatch;
	}
	// 8258BDFC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258BE00: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BE04: 816B0018  lwz r11, 0x18(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258BE08: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258BE0C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BE10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BE10 size=20
    let mut pc: u32 = 0x8258BE10;
    'dispatch: loop {
        match pc {
            0x8258BE10 => {
    //   block [0x8258BE10..0x8258BE24)
	// 8258BE10: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8258BE14: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BE18: 386A0001  addi r3, r10, 1
	ctx.r[3].s64 = ctx.r[10].s64 + 1;
	// 8258BE1C: 906B0004  stw r3, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 8258BE20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BE28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BE28 size=40
    let mut pc: u32 = 0x8258BE28;
    'dispatch: loop {
        match pc {
            0x8258BE28 => {
    //   block [0x8258BE28..0x8258BE50)
	// 8258BE28: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8258BE2C: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8258BE30: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BE34: 2B0A007F  cmplwi cr6, r10, 0x7f
	ctx.cr[6].compare_u32(ctx.r[10].u32, 127 as u32, &mut ctx.xer);
	// 8258BE38: 41990018  bgt cr6, 0x8258be50
	if ctx.cr[6].gt {
		sub_8258BE50(ctx, base);
		return;
	}
	// 8258BE3C: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258BE40: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258BE44: 40980040  bge cr6, 0x8258be84
	if !ctx.cr[6].lt {
		sub_8258BE50(ctx, base);
		return;
	}
	// 8258BE48: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258BE4C: 48000018  b 0x8258be64
	sub_8258BE50(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BE50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BE50 size=76
    let mut pc: u32 = 0x8258BE50;
    'dispatch: loop {
        match pc {
            0x8258BE50 => {
    //   block [0x8258BE50..0x8258BE9C)
	// 8258BE50: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258BE54: 394AFF80  addi r10, r10, -0x80
	ctx.r[10].s64 = ctx.r[10].s64 + -128;
	// 8258BE58: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258BE5C: 40980028  bge cr6, 0x8258be84
	if !ctx.cr[6].lt {
	pc = 0x8258BE84; continue 'dispatch;
	}
	// 8258BE60: 812B0014  lwz r9, 0x14(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BE64: 554B1838  slwi r11, r10, 3
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258BE68: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8258BE6C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BE70: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BE74: 419A0010  beq cr6, 0x8258be84
	if ctx.cr[6].eq {
	pc = 0x8258BE84; continue 'dispatch;
	}
	// 8258BE78: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BE7C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BE80: 409A0008  bne cr6, 0x8258be88
	if !ctx.cr[6].eq {
	pc = 0x8258BE88; continue 'dispatch;
	}
	// 8258BE84: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258BE88: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BE8C: 409A0010  bne cr6, 0x8258be9c
	if !ctx.cr[6].eq {
		sub_8258BE9C(ctx, base);
		return;
	}
	// 8258BE90: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 8258BE94: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 8258BE98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BE9C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BE9C size=16
    let mut pc: u32 = 0x8258BE9C;
    'dispatch: loop {
        match pc {
            0x8258BE9C => {
    //   block [0x8258BE9C..0x8258BEAC)
	// 8258BE9C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BEA0: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8258BEA4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258BEA8: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BEB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BEB0 size=44
    let mut pc: u32 = 0x8258BEB0;
    'dispatch: loop {
        match pc {
            0x8258BEB0 => {
    //   block [0x8258BEB0..0x8258BEDC)
	// 8258BEB0: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8258BEB4: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8258BEB8: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8258BEBC: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BEC0: 2B0B007F  cmplwi cr6, r11, 0x7f
	ctx.cr[6].compare_u32(ctx.r[11].u32, 127 as u32, &mut ctx.xer);
	// 8258BEC4: 41990018  bgt cr6, 0x8258bedc
	if ctx.cr[6].gt {
		sub_8258BEDC(ctx, base);
		return;
	}
	// 8258BEC8: 812A0008  lwz r9, 8(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258BECC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258BED0: 40980040  bge cr6, 0x8258bf10
	if !ctx.cr[6].lt {
		sub_8258BEDC(ctx, base);
		return;
	}
	// 8258BED4: 814A000C  lwz r10, 0xc(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258BED8: 48000018  b 0x8258bef0
	sub_8258BEDC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BEDC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BEDC size=76
    let mut pc: u32 = 0x8258BEDC;
    'dispatch: loop {
        match pc {
            0x8258BEDC => {
    //   block [0x8258BEDC..0x8258BF28)
	// 8258BEDC: 812A0010  lwz r9, 0x10(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258BEE0: 396BFF80  addi r11, r11, -0x80
	ctx.r[11].s64 = ctx.r[11].s64 + -128;
	// 8258BEE4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258BEE8: 40980028  bge cr6, 0x8258bf10
	if !ctx.cr[6].lt {
	pc = 0x8258BF10; continue 'dispatch;
	}
	// 8258BEEC: 814A0014  lwz r10, 0x14(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BEF0: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258BEF4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258BEF8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BEFC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BF00: 419A0010  beq cr6, 0x8258bf10
	if ctx.cr[6].eq {
	pc = 0x8258BF10; continue 'dispatch;
	}
	// 8258BF04: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BF08: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BF0C: 409A0008  bne cr6, 0x8258bf14
	if !ctx.cr[6].eq {
	pc = 0x8258BF14; continue 'dispatch;
	}
	// 8258BF10: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258BF14: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BF18: 409A0010  bne cr6, 0x8258bf28
	if !ctx.cr[6].eq {
		sub_8258BF28(ctx, base);
		return;
	}
	// 8258BF1C: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 8258BF20: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 8258BF24: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BF28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258BF28 size=16
    let mut pc: u32 = 0x8258BF28;
    'dispatch: loop {
        match pc {
            0x8258BF28 => {
    //   block [0x8258BF28..0x8258BF38)
	// 8258BF28: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BF2C: 7CC53378  mr r5, r6
	ctx.r[5].u64 = ctx.r[6].u64;
	// 8258BF30: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258BF34: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258BF38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258BF38 size=516
    let mut pc: u32 = 0x8258BF38;
    'dispatch: loop {
        match pc {
            0x8258BF38 => {
    //   block [0x8258BF38..0x8258C13C)
	// 8258BF38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258BF3C: 4BFA9171  bl 0x825350ac
	ctx.lr = 0x8258BF40;
	sub_82535080(ctx, base);
	// 8258BF40: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258BF44: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 8258BF48: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 8258BF4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258BF50: 7F3ACB78  mr r26, r25
	ctx.r[26].u64 = ctx.r[25].u64;
	// 8258BF54: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 8258BF58: 895B0000  lbz r10, 0(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BF5C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BF60: 419A00A4  beq cr6, 0x8258c004
	if ctx.cr[6].eq {
	pc = 0x8258C004; continue 'dispatch;
	}
	// 8258BF64: 7F28CB78  mr r8, r25
	ctx.r[8].u64 = ctx.r[25].u64;
	// 8258BF68: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258BF6C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258BF70: 409A0008  bne cr6, 0x8258bf78
	if !ctx.cr[6].eq {
	pc = 0x8258BF78; continue 'dispatch;
	}
	// 8258BF74: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BF78: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258BF7C: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BF80: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258BF84: 7D4A3A14  add r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 8258BF88: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258BF8C: 40980078  bge cr6, 0x8258c004
	if !ctx.cr[6].lt {
	pc = 0x8258C004; continue 'dispatch;
	}
	// 8258BF90: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BF94: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BF98: 409A0010  bne cr6, 0x8258bfa8
	if !ctx.cr[6].eq {
	pc = 0x8258BFA8; continue 'dispatch;
	}
	// 8258BF9C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BFA0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258BFA4: 419A0024  beq cr6, 0x8258bfc8
	if ctx.cr[6].eq {
	pc = 0x8258BFC8; continue 'dispatch;
	}
	// 8258BFA8: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258BFAC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258BFB0: 813F0014  lwz r9, 0x14(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258BFB4: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258BFB8: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8258BFBC: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258BFC0: 4198FFD0  blt cr6, 0x8258bf90
	if ctx.cr[6].lt {
	pc = 0x8258BF90; continue 'dispatch;
	}
	// 8258BFC4: 48000040  b 0x8258c004
	pc = 0x8258C004; continue 'dispatch;
	// 8258BFC8: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BFCC: 7D275850  subf r9, r7, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8258BFD0: 3B5A0001  addi r26, r26, 1
	ctx.r[26].s64 = ctx.r[26].s64 + 1;
	// 8258BFD4: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8258BFD8: 7D291E70  srawi r9, r9, 3
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 3) as i64;
	// 8258BFDC: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 8258BFE0: 39290080  addi r9, r9, 0x80
	ctx.r[9].s64 = ctx.r[9].s64 + 128;
	// 8258BFE4: 80EA0004  lwz r7, 4(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258BFE8: 992A0000  stb r9, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 8258BFEC: 90EB0000  stw r7, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 8258BFF0: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258BFF4: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258BFF8: 895B0000  lbz r10, 0(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258BFFC: 7F1A5040  cmplw cr6, r26, r10
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258C000: 4198FF68  blt cr6, 0x8258bf68
	if ctx.cr[6].lt {
	pc = 0x8258BF68; continue 'dispatch;
	}
	// 8258C004: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C008: 7FDA5850  subf r30, r26, r11
	ctx.r[30].s64 = ctx.r[11].s64 - ctx.r[26].s64;
	// 8258C00C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8258C010: 409A0010  bne cr6, 0x8258c020
	if !ctx.cr[6].eq {
	pc = 0x8258C020; continue 'dispatch;
	}
	// 8258C014: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C018: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258C01C: 4BFA90E0  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
	// 8258C020: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258C024: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8258C028: 2B0B0080  cmplwi cr6, r11, 0x80
	ctx.cr[6].compare_u32(ctx.r[11].u32, 128 as u32, &mut ctx.xer);
	// 8258C02C: 40990014  ble cr6, 0x8258c040
	if !ctx.cr[6].gt {
	pc = 0x8258C040; continue 'dispatch;
	}
	// 8258C030: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 8258C034: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 8258C038: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258C03C: 4BFA90C0  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
	// 8258C040: 3D40829A  lis r10, -0x7d66
	ctx.r[10].s64 = -2103836672;
	// 8258C044: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 8258C048: 3B8A38C8  addi r28, r10, 0x38c8
	ctx.r[28].s64 = ctx.r[10].s64 + 14536;
	// 8258C04C: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 8258C050: 55641838  slwi r4, r11, 3
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8258C054: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8258C058: 4BFF8899  bl 0x825848f0
	ctx.lr = 0x8258C05C;
	sub_825848F0(ctx, base);
	// 8258C05C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258C060: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8258C064: 409A0018  bne cr6, 0x8258c07c
	if !ctx.cr[6].eq {
	pc = 0x8258C07C; continue 'dispatch;
	}
	// 8258C068: 3F208007  lis r25, -0x7ff9
	ctx.r[25].s64 = -2147024896;
	// 8258C06C: 6339000E  ori r25, r25, 0xe
	ctx.r[25].u64 = ctx.r[25].u64 | 14;
	// 8258C070: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 8258C074: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258C078: 4BFA9084  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
	// 8258C07C: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258C080: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C084: 419A0034  beq cr6, 0x8258c0b8
	if ctx.cr[6].eq {
	pc = 0x8258C0B8; continue 'dispatch;
	}
	// 8258C088: 55651838  slwi r5, r11, 3
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8258C08C: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C090: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258C094: 4BFA8ABD  bl 0x82534b50
	ctx.lr = 0x8258C098;
	sub_82534B50(ctx, base);
	// 8258C098: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C09C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8258C0A0: 419A0018  beq cr6, 0x8258c0b8
	if ctx.cr[6].eq {
	pc = 0x8258C0B8; continue 'dispatch;
	}
	// 8258C0A4: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 8258C0A8: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8258C0AC: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 8258C0B0: 4BFF8851  bl 0x82584900
	ctx.lr = 0x8258C0B4;
	sub_82584900(ctx, base);
	// 8258C0B4: 933F0014  stw r25, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[25].u32 ) };
	// 8258C0B8: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258C0BC: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8258C0C0: 93BF0014  stw r29, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u32 ) };
	// 8258C0C4: 7D4BF214  add r10, r11, r30
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8258C0C8: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 8258C0CC: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8258C0D0: 419A0060  beq cr6, 0x8258c130
	if ctx.cr[6].eq {
	pc = 0x8258C130; continue 'dispatch;
	}
	// 8258C0D4: 574A083C  slwi r10, r26, 1
	ctx.r[10].u32 = ctx.r[26].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258C0D8: 7D5A5214  add r10, r26, r10
	ctx.r[10].u64 = ctx.r[26].u64 + ctx.r[10].u64;
	// 8258C0DC: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258C0E0: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258C0E4: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C0E8: 7D3E4850  subf r9, r30, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[30].s64;
	// 8258C0EC: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C0F0: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 8258C0F4: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8258C0F8: 55291838  slwi r9, r9, 3
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258C0FC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258C100: 7D29EA14  add r9, r9, r29
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[29].u64;
	// 8258C104: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 8258C108: 7CE74850  subf r7, r7, r9
	ctx.r[7].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 8258C10C: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C110: 7F0BF040  cmplw cr6, r11, r30
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[30].u32, &mut ctx.xer);
	// 8258C114: 7CE71E70  srawi r7, r7, 3
	ctx.xer.ca = (ctx.r[7].s32 < 0) && ((ctx.r[7].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[7].s32 >> 3) as i64;
	// 8258C118: 38E70080  addi r7, r7, 0x80
	ctx.r[7].s64 = ctx.r[7].s64 + 128;
	// 8258C11C: 98EA0000  stb r7, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u8 ) };
	// 8258C120: 90C90000  stw r6, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 8258C124: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C128: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258C12C: 4198FFB4  blt cr6, 0x8258c0e0
	if ctx.cr[6].lt {
	pc = 0x8258C0E0; continue 'dispatch;
	}
	// 8258C130: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 8258C134: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258C138: 4BFA8FC4  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C140(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C140 size=120
    let mut pc: u32 = 0x8258C140;
    'dispatch: loop {
        match pc {
            0x8258C140 => {
    //   block [0x8258C140..0x8258C1B8)
	// 8258C140: 89640000  lbz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C144: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8258C148: 7D094378  mr r9, r8
	ctx.r[9].u64 = ctx.r[8].u64;
	// 8258C14C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C150: 419A0060  beq cr6, 0x8258c1b0
	if ctx.cr[6].eq {
	pc = 0x8258C1B0; continue 'dispatch;
	}
	// 8258C154: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C158: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258C15C: 7D6958AE  lbzx r11, r9, r11
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8258C160: 396BFF80  addi r11, r11, -0x80
	ctx.r[11].s64 = ctx.r[11].s64 + -128;
	// 8258C164: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258C168: 40980038  bge cr6, 0x8258c1a0
	if !ctx.cr[6].lt {
	pc = 0x8258C1A0; continue 'dispatch;
	}
	// 8258C16C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C170: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258C174: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258C178: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C17C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258C180: 419A0020  beq cr6, 0x8258c1a0
	if ctx.cr[6].eq {
	pc = 0x8258C1A0; continue 'dispatch;
	}
	// 8258C184: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C188: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258C18C: 419A0014  beq cr6, 0x8258c1a0
	if ctx.cr[6].eq {
	pc = 0x8258C1A0; continue 'dispatch;
	}
	// 8258C190: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C194: 419A000C  beq cr6, 0x8258c1a0
	if ctx.cr[6].eq {
	pc = 0x8258C1A0; continue 'dispatch;
	}
	// 8258C198: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8258C19C: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 8258C1A0: 89640000  lbz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C1A4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258C1A8: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258C1AC: 4198FFA8  blt cr6, 0x8258c154
	if ctx.cr[6].lt {
	pc = 0x8258C154; continue 'dispatch;
	}
	// 8258C1B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C1B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C1B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C1B8 size=16
    let mut pc: u32 = 0x8258C1B8;
    'dispatch: loop {
        match pc {
            0x8258C1B8 => {
    //   block [0x8258C1B8..0x8258C1C8)
	// 8258C1B8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8258C1BC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C1C0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C1C4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C1C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C1C8 size=12
    let mut pc: u32 = 0x8258C1C8;
    'dispatch: loop {
        match pc {
            0x8258C1C8 => {
    //   block [0x8258C1C8..0x8258C1D4)
	// 8258C1C8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C1CC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258C1D0: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C1D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C1D4 size=68
    let mut pc: u32 = 0x8258C1D4;
    'dispatch: loop {
        match pc {
            0x8258C1D4 => {
    //   block [0x8258C1D4..0x8258C218)
	// 8258C1D4: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C1D8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258C1DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C1E0: 419A0030  beq cr6, 0x8258c210
	if ctx.cr[6].eq {
	pc = 0x8258C210; continue 'dispatch;
	}
	// 8258C1E4: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C1E8: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 8258C1EC: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C1F0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258C1F4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258C1F8: 40990008  ble cr6, 0x8258c200
	if !ctx.cr[6].gt {
	pc = 0x8258C200; continue 'dispatch;
	}
	// 8258C1FC: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8258C200: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258C204: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 8258C208: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258C20C: 409AFFE0  bne cr6, 0x8258c1ec
	if !ctx.cr[6].eq {
	pc = 0x8258C1EC; continue 'dispatch;
	}
	// 8258C210: 55231838  slwi r3, r9, 3
	ctx.r[3].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 8258C214: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C218(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C218 size=280
    let mut pc: u32 = 0x8258C218;
    'dispatch: loop {
        match pc {
            0x8258C218 => {
    //   block [0x8258C218..0x8258C330)
	// 8258C218: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C21C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258C220: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258C224: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258C228: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C22C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258C230: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258C234: 396B67F0  addi r11, r11, 0x67f0
	ctx.r[11].s64 = ctx.r[11].s64 + 26608;
	// 8258C238: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8258C23C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8258C240: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258C244: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C248: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258C24C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C250: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C254: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258C258: 419A002C  beq cr6, 0x8258c284
	if ctx.cr[6].eq {
	pc = 0x8258C284; continue 'dispatch;
	}
	// 8258C25C: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C260: 89680000  lbz r11, 0(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C264: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258C268: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258C26C: 40990008  ble cr6, 0x8258c274
	if !ctx.cr[6].gt {
	pc = 0x8258C274; continue 'dispatch;
	}
	// 8258C270: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8258C274: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8258C278: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 8258C27C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258C280: 409AFFE0  bne cr6, 0x8258c260
	if !ctx.cr[6].eq {
	pc = 0x8258C260; continue 'dispatch;
	}
	// 8258C284: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258C288: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8258C28C: 419A0020  beq cr6, 0x8258c2ac
	if ctx.cr[6].eq {
	pc = 0x8258C2AC; continue 'dispatch;
	}
	// 8258C290: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C294: 55241838  slwi r4, r9, 3
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8258C298: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8258C29C: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C2A0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C2A4: 4E800421  bctrl
	ctx.lr = 0x8258C2A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C2A8: 907F000C  stw r3, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 8258C2AC: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C2B0: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258C2B4: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C2B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C2BC: 419A0058  beq cr6, 0x8258c314
	if ctx.cr[6].eq {
	pc = 0x8258C314; continue 'dispatch;
	}
	// 8258C2C0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258C2C4: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C2C8: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258C2CC: 80FF000C  lwz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C2D0: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8258C2D4: 890A0000  lbz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C2D8: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C2DC: 550A183E  rotlwi r10, r8, 3
	ctx.r[10].u64 = ((ctx.r[8].u32).rotate_left(3)) as u64;
	// 8258C2E0: 7CC7512E  stwx r6, r7, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32.wrapping_add(ctx.r[10].u32), ctx.r[6].u32) };
	// 8258C2E4: 80FE0000  lwz r7, 0(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C2E8: 811F000C  lwz r8, 0xc(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C2EC: 7D085214  add r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 8258C2F0: 81470004  lwz r10, 4(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C2F4: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8258C2F8: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8258C2FC: 814A0008  lwz r10, 8(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C300: 91480004  stw r10, 4(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258C304: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C308: 890A0000  lbz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C30C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258C310: 4198FFB4  blt cr6, 0x8258c2c4
	if ctx.cr[6].lt {
	pc = 0x8258C2C4; continue 'dispatch;
	}
	// 8258C314: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C318: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258C31C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258C320: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258C324: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258C328: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258C32C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C330 size=108
    let mut pc: u32 = 0x8258C330;
    'dispatch: loop {
        match pc {
            0x8258C330 => {
    //   block [0x8258C330..0x8258C39C)
	// 8258C330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C334: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258C338: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258C33C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C340: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258C344: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258C348: 396B67F0  addi r11, r11, 0x67f0
	ctx.r[11].s64 = ctx.r[11].s64 + 26608;
	// 8258C34C: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C350: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8258C354: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C358: 419A0020  beq cr6, 0x8258c378
	if ctx.cr[6].eq {
	pc = 0x8258C378; continue 'dispatch;
	}
	// 8258C35C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C360: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 8258C364: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 8258C368: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 8258C36C: 4BFF8595  bl 0x82584900
	ctx.lr = 0x8258C370;
	sub_82584900(ctx, base);
	// 8258C370: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258C374: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8258C378: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258C37C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C380: 396B62E8  addi r11, r11, 0x62e8
	ctx.r[11].s64 = ctx.r[11].s64 + 25320;
	// 8258C384: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C388: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258C38C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258C390: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258C394: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258C398: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C3A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C3A0 size=60
    let mut pc: u32 = 0x8258C3A0;
    'dispatch: loop {
        match pc {
            0x8258C3A0 => {
    //   block [0x8258C3A0..0x8258C3DC)
	// 8258C3A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C3A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258C3A8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258C3AC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C3B0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258C3B4: 4BFFFE05  bl 0x8258c1b8
	ctx.lr = 0x8258C3B8;
	sub_8258C1B8(ctx, base);
	// 8258C3B8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8258C3BC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C3C0: 396B0018  addi r11, r11, 0x18
	ctx.r[11].s64 = ctx.r[11].s64 + 24;
	// 8258C3C4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C3C8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258C3CC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258C3D0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258C3D4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258C3D8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C3E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C3E0 size=116
    let mut pc: u32 = 0x8258C3E0;
    'dispatch: loop {
        match pc {
            0x8258C3E0 => {
    //   block [0x8258C3E0..0x8258C454)
	// 8258C3E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C3E4: 4BFA8CD9  bl 0x825350bc
	ctx.lr = 0x8258C3E8;
	sub_82535080(ctx, base);
	// 8258C3E8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C3EC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258C3F0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258C3F4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8258C3F8: 38800018  li r4, 0x18
	ctx.r[4].s64 = 24;
	// 8258C3FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C400: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C404: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258C408: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C40C: 4E800421  bctrl
	ctx.lr = 0x8258C410;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C410: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258C414: 419A0030  beq cr6, 0x8258c444
	if ctx.cr[6].eq {
	pc = 0x8258C444; continue 'dispatch;
	}
	// 8258C418: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8258C41C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8258C420: 4BFFFDF9  bl 0x8258c218
	ctx.lr = 0x8258C424;
	sub_8258C218(ctx, base);
	// 8258C424: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8258C428: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C42C: 419A0018  beq cr6, 0x8258c444
	if ctx.cr[6].eq {
	pc = 0x8258C444; continue 'dispatch;
	}
	// 8258C430: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258C434: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C438: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C43C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258C440: 4BFA8CCC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 8258C444: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 8258C448: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 8258C44C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258C450: 4BFA8CBC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C458(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C458 size=72
    let mut pc: u32 = 0x8258C458;
    'dispatch: loop {
        match pc {
            0x8258C458 => {
    //   block [0x8258C458..0x8258C4A0)
	// 8258C458: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C45C: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 8258C460: 409A0040  bne cr6, 0x8258c4a0
	if !ctx.cr[6].eq {
		sub_8258C4A0(ctx, base);
		return;
	}
	// 8258C464: 89030004  lbz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C468: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258C46C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258C470: 419A0028  beq cr6, 0x8258c498
	if ctx.cr[6].eq {
	pc = 0x8258C498; continue 'dispatch;
	}
	// 8258C474: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258C478: 55691838  slwi r9, r11, 3
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258C47C: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 8258C480: 7D291A14  add r9, r9, r3
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[3].u64;
	// 8258C484: 54EB063E  clrlwi r11, r7, 0x18
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8258C488: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258C48C: 8929000C  lbz r9, 0xc(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C490: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8258C494: 4198FFE4  blt cr6, 0x8258c478
	if ctx.cr[6].lt {
	pc = 0x8258C478; continue 'dispatch;
	}
	// 8258C498: 99440001  stb r10, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[10].u8 ) };
	// 8258C49C: 4800000C  b 0x8258c4a8
	sub_8258C4A0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C4A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C4A0 size=32
    let mut pc: u32 = 0x8258C4A0;
    'dispatch: loop {
        match pc {
            0x8258C4A0 => {
    //   block [0x8258C4A0..0x8258C4C0)
	// 8258C4A0: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C4A4: 99640001  stb r11, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[11].u8 ) };
	// 8258C4A8: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 8258C4AC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258C4B0: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 8258C4B4: 99440000  stb r10, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8258C4B8: 91640004  stw r11, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258C4BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C4C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C4C0 size=100
    let mut pc: u32 = 0x8258C4C0;
    'dispatch: loop {
        match pc {
            0x8258C4C0 => {
    //   block [0x8258C4C0..0x8258C524)
	// 8258C4C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C4C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258C4C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258C4CC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C4D0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258C4D4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8258C4D8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C4DC: 816B003C  lwz r11, 0x3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 8258C4E0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C4E4: 4E800421  bctrl
	ctx.lr = 0x8258C4E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C4E8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C4EC: 41980024  blt cr6, 0x8258c510
	if ctx.cr[6].lt {
	pc = 0x8258C510; continue 'dispatch;
	}
	// 8258C4F0: 817F004C  lwz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258C4F4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C4F8: 419A0018  beq cr6, 0x8258c510
	if ctx.cr[6].eq {
	pc = 0x8258C510; continue 'dispatch;
	}
	// 8258C4FC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C500: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8258C504: 816A0020  lwz r11, 0x20(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258C508: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C50C: 4E800421  bctrl
	ctx.lr = 0x8258C510;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C510: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258C514: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258C518: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258C51C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258C520: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C528(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C528 size=228
    let mut pc: u32 = 0x8258C528;
    'dispatch: loop {
        match pc {
            0x8258C528 => {
    //   block [0x8258C528..0x8258C60C)
	// 8258C528: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C52C: 4BFA8B89  bl 0x825350b4
	ctx.lr = 0x8258C530;
	sub_82535080(ctx, base);
	// 8258C530: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C534: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258C538: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 8258C53C: 48181911  bl 0x8270de4c
	ctx.lr = 0x8258C540;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258C540: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C544: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258C548: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258C54C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258C550: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C554: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258C558: 419A0010  beq cr6, 0x8258c568
	if ctx.cr[6].eq {
	pc = 0x8258C568; continue 'dispatch;
	}
	// 8258C55C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C560: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258C564: 419A0018  beq cr6, 0x8258c57c
	if ctx.cr[6].eq {
	pc = 0x8258C57C; continue 'dispatch;
	}
	// 8258C568: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C56C: 48181321  bl 0x8270d88c
	ctx.lr = 0x8258C570;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258C570: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258C574: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258C578: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C57C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258C580: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258C584: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258C588: 807C004C  lwz r3, 0x4c(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258C58C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C590: 816B002C  lwz r11, 0x2c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 8258C594: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C598: 4E800421  bctrl
	ctx.lr = 0x8258C59C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C59C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258C5A0: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8258C5A4: 41980014  blt cr6, 0x8258c5b8
	if ctx.cr[6].lt {
	pc = 0x8258C5B8; continue 'dispatch;
	}
	// 8258C5A8: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258C5AC: 89410050  lbz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258C5B0: 7D6B5378  or r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 8258C5B4: 997B0000  stb r11, 0(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8258C5B8: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C5BC: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 8258C5C0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8258C5C4: 419A003C  beq cr6, 0x8258c600
	if ctx.cr[6].eq {
	pc = 0x8258C600; continue 'dispatch;
	}
	// 8258C5C8: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C5CC: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258C5D0: 409A0030  bne cr6, 0x8258c600
	if !ctx.cr[6].eq {
	pc = 0x8258C600; continue 'dispatch;
	}
	// 8258C5D4: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 8258C5D8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258C5DC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258C5E0: 409A0020  bne cr6, 0x8258c600
	if !ctx.cr[6].eq {
	pc = 0x8258C600; continue 'dispatch;
	}
	// 8258C5E4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C5E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C5EC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258C5F0: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258C5F4: 48181289  bl 0x8270d87c
	ctx.lr = 0x8258C5F8;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258C5F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258C5FC: 48181861  bl 0x8270de5c
	ctx.lr = 0x8258C600;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258C600: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258C604: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258C608: 4BFA8AFC  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258C610 size=28
    let mut pc: u32 = 0x8258C610;
    'dispatch: loop {
        match pc {
            0x8258C610 => {
    //   block [0x8258C610..0x8258C62C)
	// 8258C610: 896D010C  lbz r11, 0x10c(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 8258C614: 556A183E  rotlwi r10, r11, 3
	ctx.r[10].u64 = ((ctx.r[11].u32).rotate_left(3)) as u64;
	// 8258C618: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C61C: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C620: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8258C624: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C628: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C630 size=240
    let mut pc: u32 = 0x8258C630;
    'dispatch: loop {
        match pc {
            0x8258C630 => {
    //   block [0x8258C630..0x8258C720)
	// 8258C630: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C634: 4BFA8A89  bl 0x825350bc
	ctx.lr = 0x8258C638;
	sub_82535080(ctx, base);
	// 8258C638: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C63C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258C640: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8258C644: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C648: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8258C64C: 895F0090  lbz r10, 0x90(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(144 as u32) ) } as u64;
	// 8258C650: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C654: 816B008C  lwz r11, 0x8c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(140 as u32) ) } as u64;
	// 8258C658: 7D2A5030  slw r10, r9, r10
	if (ctx.r[10].u8 & 0x20) != 0 {
		ctx.r[10].u64 = 0;
	} else {
		ctx.r[10].u64 = ((ctx.r[9].u32) << ((ctx.r[10].u8 & 0x1F) as u32)) as u64;
	}
	// 8258C65C: 7D4B5838  and r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 & ctx.r[11].u64;
	// 8258C660: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258C664: 419A001C  beq cr6, 0x8258c680
	if ctx.cr[6].eq {
	pc = 0x8258C680; continue 'dispatch;
	}
	// 8258C668: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C66C: 816B005C  lwz r11, 0x5c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 8258C670: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C674: 4E800421  bctrl
	ctx.lr = 0x8258C678;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C678: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C67C: 4198009C  blt cr6, 0x8258c718
	if ctx.cr[6].lt {
	pc = 0x8258C718; continue 'dispatch;
	}
	// 8258C680: 3BBF004C  addi r29, r31, 0x4c
	ctx.r[29].s64 = ctx.r[31].s64 + 76;
	// 8258C684: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8258C688: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C68C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8258C690: 48016A21  bl 0x825a30b0
	ctx.lr = 0x8258C694;
	sub_825A30B0(ctx, base);
	// 8258C694: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C698: 41980080  blt cr6, 0x8258c718
	if ctx.cr[6].lt {
	pc = 0x8258C718; continue 'dispatch;
	}
	// 8258C69C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8258C6A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C6A4: 480160AD  bl 0x825a2750
	ctx.lr = 0x8258C6A8;
	sub_825A2750(ctx, base);
	// 8258C6A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C6AC: 4198006C  blt cr6, 0x8258c718
	if ctx.cr[6].lt {
	pc = 0x8258C718; continue 'dispatch;
	}
	// 8258C6B0: 807D0000  lwz r3, 0(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C6B4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258C6B8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C6BC: 816B002C  lwz r11, 0x2c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 8258C6C0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C6C4: 4E800421  bctrl
	ctx.lr = 0x8258C6C8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C6C8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258C6CC: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8258C6D0: 41980044  blt cr6, 0x8258c714
	if ctx.cr[6].lt {
	pc = 0x8258C714; continue 'dispatch;
	}
	// 8258C6D4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8258C6D8: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 8258C6DC: 4800121D  bl 0x8258d8f8
	ctx.lr = 0x8258C6E0;
	sub_8258D8F8(ctx, base);
	// 8258C6E0: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258C6E4: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 8258C6E8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C6EC: 409A0028  bne cr6, 0x8258c714
	if !ctx.cr[6].eq {
	pc = 0x8258C714; continue 'dispatch;
	}
	// 8258C6F0: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258C6F4: 556B077A  rlwinm r11, r11, 0, 0x1d, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258C6F8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C6FC: 409A0018  bne cr6, 0x8258c714
	if !ctx.cr[6].eq {
	pc = 0x8258C714; continue 'dispatch;
	}
	// 8258C700: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8258C704: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C708: 48016CE1  bl 0x825a33e8
	ctx.lr = 0x8258C70C;
	sub_825A33E8(ctx, base);
	// 8258C70C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258C710: 4BFA89FC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 8258C714: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258C718: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258C71C: 4BFA89F0  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258C720 size=36
    let mut pc: u32 = 0x8258C720;
    'dispatch: loop {
        match pc {
            0x8258C720 => {
    //   block [0x8258C720..0x8258C744)
	// 8258C720: 89630090  lbz r11, 0x90(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(144 as u32) ) } as u64;
	// 8258C724: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 8258C728: 4098001C  bge cr6, 0x8258c744
	if !ctx.cr[6].lt {
		sub_8258C744(ctx, base);
		return;
	}
	// 8258C72C: 396B0021  addi r11, r11, 0x21
	ctx.r[11].s64 = ctx.r[11].s64 + 33;
	// 8258C730: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258C734: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C738: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C73C: 7C0A5C2E  lfsx f0, r10, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258C740: 4800000C  b 0x8258c74c
	sub_8258C744(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C744(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258C744 size=40
    let mut pc: u32 = 0x8258C744;
    'dispatch: loop {
        match pc {
            0x8258C744 => {
    //   block [0x8258C744..0x8258C76C)
	// 8258C744: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8258C748: C00B1850  lfs f0, 0x1850(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(6224 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258C74C: 8163004C  lwz r11, 0x4c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258C750: C1A3008C  lfs f13, 0x8c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(140 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258C754: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258C758: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8258C75C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C760: 816A0058  lwz r11, 0x58(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258C764: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C768: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C770(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C770 size=200
    let mut pc: u32 = 0x8258C770;
    'dispatch: loop {
        match pc {
            0x8258C770 => {
    //   block [0x8258C770..0x8258C838)
	// 8258C770: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C774: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258C778: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C77C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8258C780: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258C784: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 8258C788: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8258C78C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8258C790: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8258C794: 4200FFF8  bdnz 0x8258c78c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8258C78C; continue 'dispatch;
	}
	// 8258C798: 4BFFFCC1  bl 0x8258c458
	ctx.lr = 0x8258C79C;
	sub_8258C458(ctx, base);
	// 8258C79C: 81430044  lwz r10, 0x44(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(68 as u32) ) } as u64;
	// 8258C7A0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258C7A4: 91440008  stw r10, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8258C7A8: 3D40829A  lis r10, -0x7d66
	ctx.r[10].s64 = -2103836672;
	// 8258C7AC: 812A3920  lwz r9, 0x3920(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C7B0: 3949000C  addi r10, r9, 0xc
	ctx.r[10].s64 = ctx.r[9].s64 + 12;
	// 8258C7B4: 810A0000  lwz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C7B8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258C7BC: 409A006C  bne cr6, 0x8258c828
	if !ctx.cr[6].eq {
	pc = 0x8258C828; continue 'dispatch;
	}
	// 8258C7C0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258C7C4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8258C7C8: 2B0B0006  cmplwi cr6, r11, 6
	ctx.cr[6].compare_u32(ctx.r[11].u32, 6 as u32, &mut ctx.xer);
	// 8258C7CC: 4198FFE8  blt cr6, 0x8258c7b4
	if ctx.cr[6].lt {
	pc = 0x8258C7B4; continue 'dispatch;
	}
	// 8258C7D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258C7D4: 9164000C  stw r11, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8258C7D8: 8163004C  lwz r11, 0x4c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258C7DC: 91640010  stw r11, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258C7E0: 81630058  lwz r11, 0x58(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258C7E4: 91640014  stw r11, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8258C7E8: 89630039  lbz r11, 0x39(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(57 as u32) ) } as u64;
	// 8258C7EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C7F0: 409A0008  bne cr6, 0x8258c7f8
	if !ctx.cr[6].eq {
	pc = 0x8258C7F8; continue 'dispatch;
	}
	// 8258C7F4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8258C7F8: 99640018  stb r11, 0x18(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), ctx.r[11].u8 ) };
	// 8258C7FC: 8963003A  lbz r11, 0x3a(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(58 as u32) ) } as u64;
	// 8258C800: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258C804: 409A0008  bne cr6, 0x8258c80c
	if !ctx.cr[6].eq {
	pc = 0x8258C80C; continue 'dispatch;
	}
	// 8258C808: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 8258C80C: 99640019  stb r11, 0x19(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(25 as u32), ctx.r[11].u8 ) };
	// 8258C810: 81630048  lwz r11, 0x48(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(72 as u32) ) } as u64;
	// 8258C814: 9164001C  stw r11, 0x1c(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8258C818: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258C81C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258C820: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258C824: 4E800020  blr
	return;
	// 8258C828: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258C82C: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8258C830: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258C834: 4BFFFFA0  b 0x8258c7d4
	pc = 0x8258C7D4; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258C838 size=220
    let mut pc: u32 = 0x8258C838;
    'dispatch: loop {
        match pc {
            0x8258C838 => {
    //   block [0x8258C838..0x8258C914)
	// 8258C838: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C83C: 4BFA8881  bl 0x825350bc
	ctx.lr = 0x8258C840;
	sub_82535080(ctx, base);
	// 8258C840: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C844: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C848: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8258C84C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8258C850: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258C854: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C858: 83CB003C  lwz r30, 0x3c(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 8258C85C: 4BFFFF15  bl 0x8258c770
	ctx.lr = 0x8258C860;
	sub_8258C770(ctx, base);
	// 8258C860: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258C864: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8258C868: 480159F9  bl 0x825a2260
	ctx.lr = 0x8258C86C;
	sub_825A2260(ctx, base);
	// 8258C86C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C870: 41980098  blt cr6, 0x8258c908
	if ctx.cr[6].lt {
	pc = 0x8258C908; continue 'dispatch;
	}
	// 8258C874: 39610080  addi r11, r1, 0x80
	ctx.r[11].s64 = ctx.r[1].s64 + 128;
	// 8258C878: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258C87C: 3920000A  li r9, 0xa
	ctx.r[9].s64 = 10;
	// 8258C880: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8258C884: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 8258C888: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258C88C: 4200FFF8  bdnz 0x8258c884
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8258C884; continue 'dispatch;
	}
	// 8258C890: 817F0058  lwz r11, 0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258C894: 38610088  addi r3, r1, 0x88
	ctx.r[3].s64 = ctx.r[1].s64 + 136;
	// 8258C898: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 8258C89C: 99410080  stb r10, 0x80(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[10].u8 ) };
	// 8258C8A0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258C8A4: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8258C8A8: 4BFA82A9  bl 0x82534b50
	ctx.lr = 0x8258C8AC;
	sub_82534B50(ctx, base);
	// 8258C8AC: 897F003B  lbz r11, 0x3b(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(59 as u32) ) } as u64;
	// 8258C8B0: 38A10054  addi r5, r1, 0x54
	ctx.r[5].s64 = ctx.r[1].s64 + 84;
	// 8258C8B4: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8258C8B8: C01F003C  lfs f0, 0x3c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258C8BC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258C8C0: D00100C0  stfs f0, 0xc0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8258C8C4: 996100C4  stb r11, 0xc4(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u8 ) };
	// 8258C8C8: 897F0040  lbz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 8258C8CC: 996100C5  stb r11, 0xc5(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(197 as u32), ctx.r[11].u8 ) };
	// 8258C8D0: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258C8D4: 916100C8  stw r11, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 8258C8D8: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258C8DC: 916100CC  stw r11, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[11].u32 ) };
	// 8258C8E0: 4BFFF4F1  bl 0x8258bdd0
	ctx.lr = 0x8258C8E4;
	sub_8258BDD0(ctx, base);
	// 8258C8E4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C8E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C8EC: 41980020  blt cr6, 0x8258c90c
	if ctx.cr[6].lt {
	pc = 0x8258C90C; continue 'dispatch;
	}
	// 8258C8F0: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258C8F4: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258C8F8: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258C8FC: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C900: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8258C904: 4BFA8808  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 8258C908: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258C90C: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8258C910: 4BFA87FC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258C918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258C918 size=336
    let mut pc: u32 = 0x8258C918;
    'dispatch: loop {
        match pc {
            0x8258C918 => {
    //   block [0x8258C918..0x8258CA68)
	// 8258C918: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258C91C: 4BFA8799  bl 0x825350b4
	ctx.lr = 0x8258C920;
	sub_82535080(ctx, base);
	// 8258C920: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258C924: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258C928: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258C92C: 396B6818  addi r11, r11, 0x6818
	ctx.r[11].s64 = ctx.r[11].s64 + 26648;
	// 8258C930: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8258C934: 917B0000  stw r11, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C938: 816B003C  lwz r11, 0x3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 8258C93C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C940: 4E800421  bctrl
	ctx.lr = 0x8258C944;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C944: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258C948: 41980020  blt cr6, 0x8258c968
	if ctx.cr[6].lt {
	pc = 0x8258C968; continue 'dispatch;
	}
	// 8258C94C: 807B004C  lwz r3, 0x4c(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258C950: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258C954: 419A0014  beq cr6, 0x8258c968
	if ctx.cr[6].eq {
	pc = 0x8258C968; continue 'dispatch;
	}
	// 8258C958: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C95C: 816B0020  lwz r11, 0x20(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258C960: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258C964: 4E800421  bctrl
	ctx.lr = 0x8258C968;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258C968: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C96C: 838B3920  lwz r28, 0x3920(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258C970: 481814DD  bl 0x8270de4c
	ctx.lr = 0x8258C974;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258C974: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258C978: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258C97C: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258C980: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258C984: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C988: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258C98C: 419A0010  beq cr6, 0x8258c99c
	if ctx.cr[6].eq {
	pc = 0x8258C99C; continue 'dispatch;
	}
	// 8258C990: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C994: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258C998: 419A001C  beq cr6, 0x8258c9b4
	if ctx.cr[6].eq {
	pc = 0x8258C9B4; continue 'dispatch;
	}
	// 8258C99C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258C9A0: 48180EED  bl 0x8270d88c
	ctx.lr = 0x8258C9A4;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258C9A4: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8258C9A8: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8258C9AC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258C9B0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C9B4: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 8258C9B8: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258C9BC: 817C0058  lwz r11, 0x58(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258C9C0: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 8258C9C4: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C9C8: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258C9CC: 419A0028  beq cr6, 0x8258c9f4
	if ctx.cr[6].eq {
	pc = 0x8258C9F4; continue 'dispatch;
	}
	// 8258C9D0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C9D4: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258C9D8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C9DC: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258C9E0: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8258C9E4: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258C9E8: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258C9EC: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258C9F0: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258C9F4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8258C9F8: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 8258C9FC: 419A0038  beq cr6, 0x8258ca34
	if ctx.cr[6].eq {
	pc = 0x8258CA34; continue 'dispatch;
	}
	// 8258CA00: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258CA04: 409A0030  bne cr6, 0x8258ca34
	if !ctx.cr[6].eq {
	pc = 0x8258CA34; continue 'dispatch;
	}
	// 8258CA08: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 8258CA0C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CA10: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CA14: 409A0020  bne cr6, 0x8258ca34
	if !ctx.cr[6].eq {
	pc = 0x8258CA34; continue 'dispatch;
	}
	// 8258CA18: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CA1C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CA20: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CA24: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CA28: 48180E55  bl 0x8270d87c
	ctx.lr = 0x8258CA2C;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CA2C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CA30: 4818142D  bl 0x8270de5c
	ctx.lr = 0x8258CA34;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CA34: 807B004C  lwz r3, 0x4c(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258CA38: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258CA3C: 419A001C  beq cr6, 0x8258ca58
	if ctx.cr[6].eq {
	pc = 0x8258CA58; continue 'dispatch;
	}
	// 8258CA40: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258CA44: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CA48: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258CA4C: 4E800421  bctrl
	ctx.lr = 0x8258CA50;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258CA50: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258CA54: 917B004C  stw r11, 0x4c(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8258CA58: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8258CA5C: 48015B8D  bl 0x825a25e8
	ctx.lr = 0x8258CA60;
	sub_825A25E8(ctx, base);
	// 8258CA60: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258CA64: 4BFA86A0  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CA68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258CA68 size=16
    let mut pc: u32 = 0x8258CA68;
    'dispatch: loop {
        match pc {
            0x8258CA68 => {
    //   block [0x8258CA68..0x8258CA78)
	// 8258CA68: 81630030  lwz r11, 0x30(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) } as u64;
	// 8258CA6C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258CA70: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258CA74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CA78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258CA78 size=16
    let mut pc: u32 = 0x8258CA78;
    'dispatch: loop {
        match pc {
            0x8258CA78 => {
    //   block [0x8258CA78..0x8258CA88)
	// 8258CA78: 8963000C  lbz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CA7C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258CA80: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8258CA84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CA88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258CA88 size=28
    let mut pc: u32 = 0x8258CA88;
    'dispatch: loop {
        match pc {
            0x8258CA88 => {
    //   block [0x8258CA88..0x8258CAA4)
	// 8258CA88: 39630034  addi r11, r3, 0x34
	ctx.r[11].s64 = ctx.r[3].s64 + 52;
	// 8258CA8C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258CA90: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258CA94: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8258CA98: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CA9C: 91640004  stw r11, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CAA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CAA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258CAA8 size=12
    let mut pc: u32 = 0x8258CAA8;
    'dispatch: loop {
        match pc {
            0x8258CAA8 => {
    //   block [0x8258CAA8..0x8258CAB4)
	// 8258CAA8: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 8258CAAC: 60634005  ori r3, r3, 0x4005
	ctx.r[3].u64 = ctx.r[3].u64 | 16389;
	// 8258CAB0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258CAB8 size=220
    let mut pc: u32 = 0x8258CAB8;
    'dispatch: loop {
        match pc {
            0x8258CAB8 => {
    //   block [0x8258CAB8..0x8258CB94)
	// 8258CAB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258CABC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258CAC0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258CAC4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258CAC8: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258CACC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258CAD0: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 8258CAD4: 387E0054  addi r3, r30, 0x54
	ctx.r[3].s64 = ctx.r[30].s64 + 84;
	// 8258CAD8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258CADC: 4BFA8075  bl 0x82534b50
	ctx.lr = 0x8258CAE0;
	sub_82534B50(ctx, base);
	// 8258CAE0: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 8258CAE4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258CAE8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CAEC: 997E0090  stb r11, 0x90(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(144 as u32), ctx.r[11].u8 ) };
	// 8258CAF0: 4BFFFC81  bl 0x8258c770
	ctx.lr = 0x8258CAF4;
	sub_8258C770(ctx, base);
	// 8258CAF4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258CAF8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CAFC: 4801581D  bl 0x825a2318
	ctx.lr = 0x8258CB00;
	sub_825A2318(ctx, base);
	// 8258CB00: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258CB04: 41980078  blt cr6, 0x8258cb7c
	if ctx.cr[6].lt {
	pc = 0x8258CB7C; continue 'dispatch;
	}
	// 8258CB08: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 8258CB0C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258CB10: 3920000A  li r9, 0xa
	ctx.r[9].s64 = 10;
	// 8258CB14: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8258CB18: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 8258CB1C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258CB20: 4200FFF8  bdnz 0x8258cb18
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8258CB18; continue 'dispatch;
	}
	// 8258CB24: 817F0058  lwz r11, 0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258CB28: 38610078  addi r3, r1, 0x78
	ctx.r[3].s64 = ctx.r[1].s64 + 120;
	// 8258CB2C: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 8258CB30: 99410070  stb r10, 0x70(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u8 ) };
	// 8258CB34: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258CB38: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258CB3C: 4BFA8015  bl 0x82534b50
	ctx.lr = 0x8258CB40;
	sub_82534B50(ctx, base);
	// 8258CB40: 897F003B  lbz r11, 0x3b(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(59 as u32) ) } as u64;
	// 8258CB44: 38C000FF  li r6, 0xff
	ctx.r[6].s64 = 255;
	// 8258CB48: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 8258CB4C: C01F003C  lfs f0, 0x3c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258CB50: 389E004C  addi r4, r30, 0x4c
	ctx.r[4].s64 = ctx.r[30].s64 + 76;
	// 8258CB54: D00100B0  stfs f0, 0xb0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 8258CB58: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CB5C: 996100B4  stb r11, 0xb4(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u8 ) };
	// 8258CB60: 897F0040  lbz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 8258CB64: 996100B5  stb r11, 0xb5(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(181 as u32), ctx.r[11].u8 ) };
	// 8258CB68: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258CB6C: 916100B8  stw r11, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 8258CB70: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258CB74: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8258CB78: 48016229  bl 0x825a2da0
	ctx.lr = 0x8258CB7C;
	sub_825A2DA0(ctx, base);
	// 8258CB7C: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 8258CB80: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258CB84: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258CB88: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258CB8C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258CB90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CB98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258CB98 size=636
    let mut pc: u32 = 0x8258CB98;
    'dispatch: loop {
        match pc {
            0x8258CB98 => {
    //   block [0x8258CB98..0x8258CE14)
	// 8258CB98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258CB9C: 4BFA8519  bl 0x825350b4
	ctx.lr = 0x8258CBA0;
	sub_82535080(ctx, base);
	// 8258CBA0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258CBA4: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258CBA8: 481812A5  bl 0x8270de4c
	ctx.lr = 0x8258CBAC;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CBAC: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258CBB0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258CBB4: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258CBB8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258CBBC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CBC0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CBC4: 419A0010  beq cr6, 0x8258cbd4
	if ctx.cr[6].eq {
	pc = 0x8258CBD4; continue 'dispatch;
	}
	// 8258CBC8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CBCC: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CBD0: 419A0024  beq cr6, 0x8258cbf4
	if ctx.cr[6].eq {
	pc = 0x8258CBF4; continue 'dispatch;
	}
	// 8258CBD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CBD8: 48180CB5  bl 0x8270d88c
	ctx.lr = 0x8258CBDC;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CBDC: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 8258CBE0: 7FBEEB78  mr r30, r29
	ctx.r[30].u64 = ctx.r[29].u64;
	// 8258CBE4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8258CBE8: 9BDF000C  stb r30, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 8258CBEC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CBF0: 48000008  b 0x8258cbf8
	pc = 0x8258CBF8; continue 'dispatch;
	// 8258CBF4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CBF8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258CBFC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CC00: 893B003D  lbz r9, 0x3d(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258CC04: 55290672  rlwinm r9, r9, 0, 0x19, 0x19
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 8258CC08: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258CC0C: 409A0050  bne cr6, 0x8258cc5c
	if !ctx.cr[6].eq {
	pc = 0x8258CC5C; continue 'dispatch;
	}
	// 8258CC10: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CC14: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 8258CC18: 419A0034  beq cr6, 0x8258cc4c
	if ctx.cr[6].eq {
	pc = 0x8258CC4C; continue 'dispatch;
	}
	// 8258CC1C: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CC20: 409A002C  bne cr6, 0x8258cc4c
	if !ctx.cr[6].eq {
	pc = 0x8258CC4C; continue 'dispatch;
	}
	// 8258CC24: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258CC28: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CC2C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CC30: 409A001C  bne cr6, 0x8258cc4c
	if !ctx.cr[6].eq {
	pc = 0x8258CC4C; continue 'dispatch;
	}
	// 8258CC34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CC38: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CC3C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CC40: 48180C3D  bl 0x8270d87c
	ctx.lr = 0x8258CC44;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CC44: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CC48: 48181215  bl 0x8270de5c
	ctx.lr = 0x8258CC4C;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CC4C: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 8258CC50: 60634004  ori r3, r3, 0x4004
	ctx.r[3].u64 = ctx.r[3].u64 | 16388;
	// 8258CC54: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258CC58: 4BFA84AC  b 0x82535104
	sub_825350D0(ctx, base);
	return;
	// 8258CC5C: 3FC0829A  lis r30, -0x7d66
	ctx.r[30].s64 = -2103836672;
	// 8258CC60: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 8258CC64: 807E3920  lwz r3, 0x3920(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258CC68: 4BFFCB39  bl 0x825897a0
	ctx.lr = 0x8258CC6C;
	sub_825897A0(ctx, base);
	// 8258CC6C: 839E3920  lwz r28, 0x3920(r30)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258CC70: 481811DD  bl 0x8270de4c
	ctx.lr = 0x8258CC74;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CC74: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CC78: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258CC7C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258CC80: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CC84: 419A0010  beq cr6, 0x8258cc94
	if ctx.cr[6].eq {
	pc = 0x8258CC94; continue 'dispatch;
	}
	// 8258CC88: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CC8C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258CC90: 419A001C  beq cr6, 0x8258ccac
	if ctx.cr[6].eq {
	pc = 0x8258CCAC; continue 'dispatch;
	}
	// 8258CC94: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CC98: 48180BF5  bl 0x8270d88c
	ctx.lr = 0x8258CC9C;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CC9C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8258CCA0: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8258CCA4: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258CCA8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CCAC: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 8258CCB0: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258CCB4: 817C004C  lwz r11, 0x4c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258CCB8: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 8258CCBC: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258CCC0: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258CCC4: 419A0028  beq cr6, 0x8258ccec
	if ctx.cr[6].eq {
	pc = 0x8258CCEC; continue 'dispatch;
	}
	// 8258CCC8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CCCC: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258CCD0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CCD4: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258CCD8: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8258CCDC: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CCE0: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258CCE4: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CCE8: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CCEC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8258CCF0: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 8258CCF4: 419A0038  beq cr6, 0x8258cd2c
	if ctx.cr[6].eq {
	pc = 0x8258CD2C; continue 'dispatch;
	}
	// 8258CCF8: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258CCFC: 409A0030  bne cr6, 0x8258cd2c
	if !ctx.cr[6].eq {
	pc = 0x8258CD2C; continue 'dispatch;
	}
	// 8258CD00: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 8258CD04: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CD08: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CD0C: 409A0020  bne cr6, 0x8258cd2c
	if !ctx.cr[6].eq {
	pc = 0x8258CD2C; continue 'dispatch;
	}
	// 8258CD10: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CD14: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CD18: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CD1C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CD20: 48180B5D  bl 0x8270d87c
	ctx.lr = 0x8258CD24;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CD24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CD28: 48181135  bl 0x8270de5c
	ctx.lr = 0x8258CD2C;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CD2C: 48181121  bl 0x8270de4c
	ctx.lr = 0x8258CD30;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CD30: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CD34: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258CD38: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CD3C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258CD40: 419A0010  beq cr6, 0x8258cd50
	if ctx.cr[6].eq {
	pc = 0x8258CD50; continue 'dispatch;
	}
	// 8258CD44: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CD48: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CD4C: 419A0018  beq cr6, 0x8258cd64
	if ctx.cr[6].eq {
	pc = 0x8258CD64; continue 'dispatch;
	}
	// 8258CD50: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CD54: 48180B39  bl 0x8270d88c
	ctx.lr = 0x8258CD58;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CD58: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258CD5C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258CD60: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CD64: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258CD68: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258CD6C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CD70: 897B003D  lbz r11, 0x3d(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258CD74: 716B00BF  andi. r11, r11, 0xbf
	ctx.r[11].u64 = ctx.r[11].u64 & 191;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CD78: 997B003D  stb r11, 0x3d(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(61 as u32), ctx.r[11].u8 ) };
	// 8258CD7C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CD80: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CD84: 419A0040  beq cr6, 0x8258cdc4
	if ctx.cr[6].eq {
	pc = 0x8258CDC4; continue 'dispatch;
	}
	// 8258CD88: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CD8C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258CD90: 409A0034  bne cr6, 0x8258cdc4
	if !ctx.cr[6].eq {
	pc = 0x8258CDC4; continue 'dispatch;
	}
	// 8258CD94: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258CD98: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CD9C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CDA0: 409A0024  bne cr6, 0x8258cdc4
	if !ctx.cr[6].eq {
	pc = 0x8258CDC4; continue 'dispatch;
	}
	// 8258CDA4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CDA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CDAC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CDB0: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CDB4: 48180AC9  bl 0x8270d87c
	ctx.lr = 0x8258CDB8;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CDB8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CDBC: 481810A1  bl 0x8270de5c
	ctx.lr = 0x8258CDC0;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CDC0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CDC4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CDC8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258CDCC: 419A003C  beq cr6, 0x8258ce08
	if ctx.cr[6].eq {
	pc = 0x8258CE08; continue 'dispatch;
	}
	// 8258CDD0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CDD4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258CDD8: 409A0030  bne cr6, 0x8258ce08
	if !ctx.cr[6].eq {
	pc = 0x8258CE08; continue 'dispatch;
	}
	// 8258CDDC: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258CDE0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CDE4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CDE8: 409A0020  bne cr6, 0x8258ce08
	if !ctx.cr[6].eq {
	pc = 0x8258CE08; continue 'dispatch;
	}
	// 8258CDEC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CDF0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CDF4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CDF8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CDFC: 48180A81  bl 0x8270d87c
	ctx.lr = 0x8258CE00;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CE00: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CE04: 48181059  bl 0x8270de5c
	ctx.lr = 0x8258CE08;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CE08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258CE0C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258CE10: 4BFA82F4  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CE18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258CE18 size=244
    let mut pc: u32 = 0x8258CE18;
    'dispatch: loop {
        match pc {
            0x8258CE18 => {
    //   block [0x8258CE18..0x8258CF0C)
	// 8258CE18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258CE1C: 4BFA8299  bl 0x825350b4
	ctx.lr = 0x8258CE20;
	sub_82535080(ctx, base);
	// 8258CE20: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258CE24: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258CE28: 480153A9  bl 0x825a21d0
	ctx.lr = 0x8258CE2C;
	sub_825A21D0(ctx, base);
	// 8258CE2C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258CE30: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8258CE34: 396B6818  addi r11, r11, 0x6818
	ctx.r[11].s64 = ctx.r[11].s64 + 26648;
	// 8258CE38: C00A1850  lfs f0, 0x1850(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(6224 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258CE3C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258CE40: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258CE44: D01E008C  stfs f0, 0x8c(r30)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 8258CE48: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258CE4C: 3BAB0050  addi r29, r11, 0x50
	ctx.r[29].s64 = ctx.r[11].s64 + 80;
	// 8258CE50: 48180FFD  bl 0x8270de4c
	ctx.lr = 0x8258CE54;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CE54: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258CE58: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258CE5C: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258CE60: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 8258CE64: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CE68: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CE6C: 419A0010  beq cr6, 0x8258ce7c
	if ctx.cr[6].eq {
	pc = 0x8258CE7C; continue 'dispatch;
	}
	// 8258CE70: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CE74: 7F1C5040  cmplw cr6, r28, r10
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CE78: 419A0018  beq cr6, 0x8258ce90
	if ctx.cr[6].eq {
	pc = 0x8258CE90; continue 'dispatch;
	}
	// 8258CE7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CE80: 48180A0D  bl 0x8270d88c
	ctx.lr = 0x8258CE84;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CE84: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 8258CE88: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 8258CE8C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CE90: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258CE94: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258CE98: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CE9C: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CEA0: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8258CEA4: 93AB0000  stw r29, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8258CEA8: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CEAC: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8258CEB0: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CEB4: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CEB8: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258CEBC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CEC0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CEC4: 419A003C  beq cr6, 0x8258cf00
	if ctx.cr[6].eq {
	pc = 0x8258CF00; continue 'dispatch;
	}
	// 8258CEC8: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CECC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258CED0: 409A0030  bne cr6, 0x8258cf00
	if !ctx.cr[6].eq {
	pc = 0x8258CF00; continue 'dispatch;
	}
	// 8258CED4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258CED8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CEDC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CEE0: 409A0020  bne cr6, 0x8258cf00
	if !ctx.cr[6].eq {
	pc = 0x8258CF00; continue 'dispatch;
	}
	// 8258CEE4: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258CEE8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CEEC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258CEF0: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258CEF4: 48180989  bl 0x8270d87c
	ctx.lr = 0x8258CEF8;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258CEF8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258CEFC: 48180F61  bl 0x8270de5c
	ctx.lr = 0x8258CF00;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258CF00: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258CF04: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258CF08: 4BFA81FC  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CF10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258CF10 size=48
    let mut pc: u32 = 0x8258CF10;
    'dispatch: loop {
        match pc {
            0x8258CF10 => {
    //   block [0x8258CF10..0x8258CF40)
	// 8258CF10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258CF14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258CF18: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258CF1C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258CF20: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258CF24: 4BFFF9F5  bl 0x8258c918
	ctx.lr = 0x8258CF28;
	sub_8258C918(ctx, base);
	// 8258CF28: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CF2C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258CF30: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258CF34: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258CF38: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258CF3C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258CF40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258CF40 size=544
    let mut pc: u32 = 0x8258CF40;
    'dispatch: loop {
        match pc {
            0x8258CF40 => {
    //   block [0x8258CF40..0x8258D160)
	// 8258CF40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258CF44: 4BFA816D  bl 0x825350b0
	ctx.lr = 0x8258CF48;
	sub_82535080(ctx, base);
	// 8258CF48: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258CF4C: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258CF50: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8258CF54: 48180EF9  bl 0x8270de4c
	ctx.lr = 0x8258CF58;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CF58: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258CF5C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258CF60: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258CF64: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258CF68: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CF6C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CF70: 419A0010  beq cr6, 0x8258cf80
	if ctx.cr[6].eq {
	pc = 0x8258CF80; continue 'dispatch;
	}
	// 8258CF74: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CF78: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CF7C: 419A0018  beq cr6, 0x8258cf94
	if ctx.cr[6].eq {
	pc = 0x8258CF94; continue 'dispatch;
	}
	// 8258CF80: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CF84: 48180909  bl 0x8270d88c
	ctx.lr = 0x8258CF88;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CF88: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258CF8C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258CF90: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CF94: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258CF98: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258CF9C: 895B003D  lbz r10, 0x3d(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258CFA0: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 8258CFA4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258CFA8: 419A0010  beq cr6, 0x8258cfb8
	if ctx.cr[6].eq {
	pc = 0x8258CFB8; continue 'dispatch;
	}
	// 8258CFAC: 3F408000  lis r26, -0x8000
	ctx.r[26].s64 = -2147483648;
	// 8258CFB0: 635AFFFF  ori r26, r26, 0xffff
	ctx.r[26].u64 = ctx.r[26].u64 | 65535;
	// 8258CFB4: 4800015C  b 0x8258d110
	pc = 0x8258D110; continue 'dispatch;
	// 8258CFB8: 554A0672  rlwinm r10, r10, 0, 0x19, 0x19
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 8258CFBC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258CFC0: 409A0150  bne cr6, 0x8258d110
	if !ctx.cr[6].eq {
	pc = 0x8258D110; continue 'dispatch;
	}
	// 8258CFC4: 48180E89  bl 0x8270de4c
	ctx.lr = 0x8258CFC8;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258CFC8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CFCC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258CFD0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258CFD4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258CFD8: 419A0010  beq cr6, 0x8258cfe8
	if ctx.cr[6].eq {
	pc = 0x8258CFE8; continue 'dispatch;
	}
	// 8258CFDC: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258CFE0: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258CFE4: 419A0018  beq cr6, 0x8258cffc
	if ctx.cr[6].eq {
	pc = 0x8258CFFC; continue 'dispatch;
	}
	// 8258CFE8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258CFEC: 481808A1  bl 0x8270d88c
	ctx.lr = 0x8258CFF0;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258CFF0: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258CFF4: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258CFF8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258CFFC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258D000: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258D004: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D008: 897B003D  lbz r11, 0x3d(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258D00C: 616B0040  ori r11, r11, 0x40
	ctx.r[11].u64 = ctx.r[11].u64 | 64;
	// 8258D010: 997B003D  stb r11, 0x3d(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(61 as u32), ctx.r[11].u8 ) };
	// 8258D014: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D018: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D01C: 419A003C  beq cr6, 0x8258d058
	if ctx.cr[6].eq {
	pc = 0x8258D058; continue 'dispatch;
	}
	// 8258D020: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D024: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258D028: 409A0030  bne cr6, 0x8258d058
	if !ctx.cr[6].eq {
	pc = 0x8258D058; continue 'dispatch;
	}
	// 8258D02C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258D030: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D034: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D038: 409A0020  bne cr6, 0x8258d058
	if !ctx.cr[6].eq {
	pc = 0x8258D058; continue 'dispatch;
	}
	// 8258D03C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D040: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D044: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258D048: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D04C: 48180831  bl 0x8270d87c
	ctx.lr = 0x8258D050;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258D050: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D054: 48180E09  bl 0x8270de5c
	ctx.lr = 0x8258D058;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258D058: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D05C: 83AB3920  lwz r29, 0x3920(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258D060: 48180DED  bl 0x8270de4c
	ctx.lr = 0x8258D064;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258D064: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D068: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258D06C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258D070: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D074: 419A0010  beq cr6, 0x8258d084
	if ctx.cr[6].eq {
	pc = 0x8258D084; continue 'dispatch;
	}
	// 8258D078: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D07C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258D080: 419A0018  beq cr6, 0x8258d098
	if ctx.cr[6].eq {
	pc = 0x8258D098; continue 'dispatch;
	}
	// 8258D084: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D088: 48180805  bl 0x8270d88c
	ctx.lr = 0x8258D08C;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258D08C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258D090: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 8258D094: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D098: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258D09C: 395D0044  addi r10, r29, 0x44
	ctx.r[10].s64 = ctx.r[29].s64 + 68;
	// 8258D0A0: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 8258D0A4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D0A8: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D0AC: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 8258D0B0: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8258D0B4: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D0B8: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 8258D0BC: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D0C0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D0C4: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258D0C8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D0CC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D0D0: 419A0040  beq cr6, 0x8258d110
	if ctx.cr[6].eq {
	pc = 0x8258D110; continue 'dispatch;
	}
	// 8258D0D4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D0D8: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258D0DC: 409A0034  bne cr6, 0x8258d110
	if !ctx.cr[6].eq {
	pc = 0x8258D110; continue 'dispatch;
	}
	// 8258D0E0: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258D0E4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D0E8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D0EC: 409A0024  bne cr6, 0x8258d110
	if !ctx.cr[6].eq {
	pc = 0x8258D110; continue 'dispatch;
	}
	// 8258D0F0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D0F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D0F8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258D0FC: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D100: 4818077D  bl 0x8270d87c
	ctx.lr = 0x8258D104;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258D104: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D108: 48180D55  bl 0x8270de5c
	ctx.lr = 0x8258D10C;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258D10C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D110: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D114: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258D118: 419A003C  beq cr6, 0x8258d154
	if ctx.cr[6].eq {
	pc = 0x8258D154; continue 'dispatch;
	}
	// 8258D11C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D120: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258D124: 409A0030  bne cr6, 0x8258d154
	if !ctx.cr[6].eq {
	pc = 0x8258D154; continue 'dispatch;
	}
	// 8258D128: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258D12C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D130: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D134: 409A0020  bne cr6, 0x8258d154
	if !ctx.cr[6].eq {
	pc = 0x8258D154; continue 'dispatch;
	}
	// 8258D138: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D13C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D140: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258D144: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D148: 48180735  bl 0x8270d87c
	ctx.lr = 0x8258D14C;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258D14C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D150: 48180D0D  bl 0x8270de5c
	ctx.lr = 0x8258D154;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258D154: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258D158: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258D15C: 4BFA7FA4  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D160(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D160 size=172
    let mut pc: u32 = 0x8258D160;
    'dispatch: loop {
        match pc {
            0x8258D160 => {
    //   block [0x8258D160..0x8258D20C)
	// 8258D160: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D164: 4BFA7F59  bl 0x825350bc
	ctx.lr = 0x8258D168;
	sub_82535080(ctx, base);
	// 8258D168: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D16C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D170: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258D174: 4BFFFA25  bl 0x8258cb98
	ctx.lr = 0x8258D178;
	sub_8258CB98(ctx, base);
	// 8258D178: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 8258D17C: 616B4004  ori r11, r11, 0x4004
	ctx.r[11].u64 = ctx.r[11].u64 | 16388;
	// 8258D180: 7F035800  cmpw cr6, r3, r11
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8258D184: 409A0080  bne cr6, 0x8258d204
	if !ctx.cr[6].eq {
	pc = 0x8258D204; continue 'dispatch;
	}
	// 8258D188: 807E004C  lwz r3, 0x4c(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258D18C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258D190: 419A0068  beq cr6, 0x8258d1f8
	if ctx.cr[6].eq {
	pc = 0x8258D1F8; continue 'dispatch;
	}
	// 8258D194: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D198: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258D19C: 816B0034  lwz r11, 0x34(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 8258D1A0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D1A4: 4E800421  bctrl
	ctx.lr = 0x8258D1A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D1A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D1AC: 41980058  blt cr6, 0x8258d204
	if ctx.cr[6].lt {
	pc = 0x8258D204; continue 'dispatch;
	}
	// 8258D1B0: 57FD063E  clrlwi r29, r31, 0x18
	ctx.r[29].u64 = ctx.r[31].u32 as u64 & 0x000000FFu64;
	// 8258D1B4: 57AB07FE  clrlwi r11, r29, 0x1f
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x00000001u64;
	// 8258D1B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D1BC: 409A003C  bne cr6, 0x8258d1f8
	if !ctx.cr[6].eq {
	pc = 0x8258D1F8; continue 'dispatch;
	}
	// 8258D1C0: 807E004C  lwz r3, 0x4c(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258D1C4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D1C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D1CC: 816B002C  lwz r11, 0x2c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 8258D1D0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D1D4: 4E800421  bctrl
	ctx.lr = 0x8258D1D8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D1D8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D1DC: 41980028  blt cr6, 0x8258d204
	if ctx.cr[6].lt {
	pc = 0x8258D204; continue 'dispatch;
	}
	// 8258D1E0: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258D1E4: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 8258D1E8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D1EC: 409A000C  bne cr6, 0x8258d1f8
	if !ctx.cr[6].eq {
	pc = 0x8258D1F8; continue 'dispatch;
	}
	// 8258D1F0: 57AB063E  clrlwi r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	// 8258D1F4: 617F0001  ori r31, r11, 1
	ctx.r[31].u64 = ctx.r[11].u64 | 1;
	// 8258D1F8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258D1FC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D200: 480161E9  bl 0x825a33e8
	ctx.lr = 0x8258D204;
	sub_825A33E8(ctx, base);
	// 8258D204: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258D208: 4BFA7F04  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D210(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D210 size=256
    let mut pc: u32 = 0x8258D210;
    'dispatch: loop {
        match pc {
            0x8258D210 => {
    //   block [0x8258D210..0x8258D310)
	// 8258D210: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D214: 4BFA7EA5  bl 0x825350b8
	ctx.lr = 0x8258D218;
	sub_82535080(ctx, base);
	// 8258D218: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D21C: 9081009C  stw r4, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[4].u32 ) };
	// 8258D220: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D224: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258D228: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 8258D22C: 4BFFF60D  bl 0x8258c838
	ctx.lr = 0x8258D230;
	sub_8258C838(ctx, base);
	// 8258D230: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D234: 41980010  blt cr6, 0x8258d244
	if ctx.cr[6].lt {
	pc = 0x8258D244; continue 'dispatch;
	}
	// 8258D238: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258D23C: 388B0094  addi r4, r11, 0x94
	ctx.r[4].s64 = ctx.r[11].s64 + 148;
	// 8258D240: 48000008  b 0x8258d248
	pc = 0x8258D248; continue 'dispatch;
	// 8258D244: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258D248: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D24C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D250: 41980098  blt cr6, 0x8258d2e8
	if ctx.cr[6].lt {
	pc = 0x8258D2E8; continue 'dispatch;
	}
	// 8258D254: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 8258D258: 38A1009C  addi r5, r1, 0x9c
	ctx.r[5].s64 = ctx.r[1].s64 + 156;
	// 8258D25C: 60630006  ori r3, r3, 6
	ctx.r[3].u64 = ctx.r[3].u64 | 6;
	// 8258D260: 48014EC1  bl 0x825a2120
	ctx.lr = 0x8258D264;
	sub_825A2120(ctx, base);
	// 8258D264: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D268: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8258D26C: 4198007C  blt cr6, 0x8258d2e8
	if ctx.cr[6].lt {
	pc = 0x8258D2E8; continue 'dispatch;
	}
	// 8258D270: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 8258D274: 38800094  li r4, 0x94
	ctx.r[4].s64 = 148;
	// 8258D278: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D27C: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258D280: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D284: 4E800421  bctrl
	ctx.lr = 0x8258D288;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D288: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258D28C: 419A001C  beq cr6, 0x8258d2a8
	if ctx.cr[6].eq {
	pc = 0x8258D2A8; continue 'dispatch;
	}
	// 8258D290: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8258D294: 8081009C  lwz r4, 0x9c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 8258D298: 4BFFFB81  bl 0x8258ce18
	ctx.lr = 0x8258D29C;
	sub_8258CE18(ctx, base);
	// 8258D29C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D2A0: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8258D2A4: 409A0010  bne cr6, 0x8258d2b4
	if !ctx.cr[6].eq {
	pc = 0x8258D2B4; continue 'dispatch;
	}
	// 8258D2A8: 3FE08007  lis r31, -0x7ff9
	ctx.r[31].s64 = -2147024896;
	// 8258D2AC: 63FF000E  ori r31, r31, 0xe
	ctx.r[31].u64 = ctx.r[31].u64 | 14;
	// 8258D2B0: 48000038  b 0x8258d2e8
	pc = 0x8258D2E8; continue 'dispatch;
	// 8258D2B4: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8258D2B8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D2BC: 4BFFF7FD  bl 0x8258cab8
	ctx.lr = 0x8258D2C0;
	sub_8258CAB8(ctx, base);
	// 8258D2C0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D2C4: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8258D2C8: 4198000C  blt cr6, 0x8258d2d4
	if ctx.cr[6].lt {
	pc = 0x8258D2D4; continue 'dispatch;
	}
	// 8258D2CC: 93DC0000  stw r30, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8258D2D0: 48000018  b 0x8258d2e8
	pc = 0x8258D2E8; continue 'dispatch;
	// 8258D2D4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D2D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D2DC: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D2E0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D2E4: 4E800421  bctrl
	ctx.lr = 0x8258D2E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D2E8: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 8258D2EC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258D2F0: 419A0014  beq cr6, 0x8258d304
	if ctx.cr[6].eq {
	pc = 0x8258D304; continue 'dispatch;
	}
	// 8258D2F4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D2F8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D2FC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D300: 4E800421  bctrl
	ctx.lr = 0x8258D304;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D304: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D308: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258D30C: 4BFA7DFC  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D310(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D310 size=160
    let mut pc: u32 = 0x8258D310;
    'dispatch: loop {
        match pc {
            0x8258D310 => {
    //   block [0x8258D310..0x8258D3B0)
	// 8258D310: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D314: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D318: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D31C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D320: 548B07FE  clrlwi r11, r4, 0x1f
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 8258D324: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D328: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D32C: 419A001C  beq cr6, 0x8258d348
	if ctx.cr[6].eq {
	pc = 0x8258D348; continue 'dispatch;
	}
	// 8258D330: 4BFFFC11  bl 0x8258cf40
	ctx.lr = 0x8258D334;
	sub_8258CF40(ctx, base);
	// 8258D334: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258D338: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D33C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D340: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D344: 4E800020  blr
	return;
	// 8258D348: 4BFFF851  bl 0x8258cb98
	ctx.lr = 0x8258D34C;
	sub_8258CB98(ctx, base);
	// 8258D34C: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 8258D350: 616B4004  ori r11, r11, 0x4004
	ctx.r[11].u64 = ctx.r[11].u64 | 16388;
	// 8258D354: 7F035800  cmpw cr6, r3, r11
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8258D358: 419A000C  beq cr6, 0x8258d364
	if ctx.cr[6].eq {
	pc = 0x8258D364; continue 'dispatch;
	}
	// 8258D35C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D360: 4198003C  blt cr6, 0x8258d39c
	if ctx.cr[6].lt {
	pc = 0x8258D39C; continue 'dispatch;
	}
	// 8258D364: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D368: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D36C: 816B005C  lwz r11, 0x5c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 8258D370: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D374: 4E800421  bctrl
	ctx.lr = 0x8258D378;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D378: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258D37C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D380: 816B0030  lwz r11, 0x30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 8258D384: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D388: 4E800421  bctrl
	ctx.lr = 0x8258D38C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D38C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D390: 4198000C  blt cr6, 0x8258d39c
	if ctx.cr[6].lt {
	pc = 0x8258D39C; continue 'dispatch;
	}
	// 8258D394: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D398: 48015E39  bl 0x825a31d0
	ctx.lr = 0x8258D39C;
	sub_825A31D0(ctx, base);
	// 8258D39C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258D3A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D3A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D3A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D3AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D3B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D3B0 size=112
    let mut pc: u32 = 0x8258D3B0;
    'dispatch: loop {
        match pc {
            0x8258D3B0 => {
    //   block [0x8258D3B0..0x8258D420)
	// 8258D3B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D3B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D3B8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258D3BC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D3C0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D3C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D3C8: 48015741  bl 0x825a2b08
	ctx.lr = 0x8258D3CC;
	sub_825A2B08(ctx, base);
	// 8258D3CC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D3D0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8258D3D4: 41980030  blt cr6, 0x8258d404
	if ctx.cr[6].lt {
	pc = 0x8258D404; continue 'dispatch;
	}
	// 8258D3D8: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258D3DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D3E0: 386BFFF8  addi r3, r11, -8
	ctx.r[3].s64 = ctx.r[11].s64 + -8;
	// 8258D3E4: 409A0008  bne cr6, 0x8258d3ec
	if !ctx.cr[6].eq {
	pc = 0x8258D3EC; continue 'dispatch;
	}
	// 8258D3E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258D3EC: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 8258D3F0: 389F0034  addi r4, r31, 0x34
	ctx.r[4].s64 = ctx.r[31].s64 + 52;
	// 8258D3F4: 4BFF71B5  bl 0x825845a8
	ctx.lr = 0x8258D3F8;
	sub_825845A8(ctx, base);
	// 8258D3F8: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8258D3FC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8258D400: 480004F9  bl 0x8258d8f8
	ctx.lr = 0x8258D404;
	sub_8258D8F8(ctx, base);
	// 8258D404: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D408: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258D40C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D410: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D414: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258D418: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D41C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D420(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258D420 size=128
    let mut pc: u32 = 0x8258D420;
    'dispatch: loop {
        match pc {
            0x8258D420 => {
    //   block [0x8258D420..0x8258D4A0)
	// 8258D420: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8258D424: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8258D428: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 8258D42C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8258D430: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8258D434: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8258D438: 4200FFF8  bdnz 0x8258d430
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8258D430; continue 'dispatch;
	}
	// 8258D43C: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 8258D440: 99240000  stb r9, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 8258D444: 89430001  lbz r10, 1(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(1 as u32) ) } as u64;
	// 8258D448: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 8258D44C: 99440001  stb r10, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[10].u8 ) };
	// 8258D450: 91640004  stw r11, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D454: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D458: 91640008  stw r11, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D45C: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258D460: 91640010  stw r11, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258D464: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258D468: 91640014  stw r11, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8258D46C: 89630008  lbz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D470: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D474: 409A0008  bne cr6, 0x8258d47c
	if !ctx.cr[6].eq {
	pc = 0x8258D47C; continue 'dispatch;
	}
	// 8258D478: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8258D47C: 99640018  stb r11, 0x18(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), ctx.r[11].u8 ) };
	// 8258D480: 89630009  lbz r11, 9(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(9 as u32) ) } as u64;
	// 8258D484: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258D488: 409A0008  bne cr6, 0x8258d490
	if !ctx.cr[6].eq {
	pc = 0x8258D490; continue 'dispatch;
	}
	// 8258D48C: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 8258D490: 99640019  stb r11, 0x19(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(25 as u32), ctx.r[11].u8 ) };
	// 8258D494: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258D498: 9164001C  stw r11, 0x1c(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8258D49C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D4A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D4A0 size=116
    let mut pc: u32 = 0x8258D4A0;
    'dispatch: loop {
        match pc {
            0x8258D4A0 => {
    //   block [0x8258D4A0..0x8258D514)
	// 8258D4A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D4A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D4A8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258D4AC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D4B0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D4B4: 89640001  lbz r11, 1(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(1 as u32) ) } as u64;
	// 8258D4B8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D4BC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D4C0: 99610051  stb r11, 0x51(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(81 as u32), ctx.r[11].u8 ) };
	// 8258D4C4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258D4C8: 99610050  stb r11, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u8 ) };
	// 8258D4CC: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 8258D4D0: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 8258D4D4: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8258D4D8: 48014D39  bl 0x825a2210
	ctx.lr = 0x8258D4DC;
	sub_825A2210(ctx, base);
	// 8258D4DC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D4E0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8258D4E4: 41980014  blt cr6, 0x8258d4f8
	if ctx.cr[6].lt {
	pc = 0x8258D4F8; continue 'dispatch;
	}
	// 8258D4E8: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 8258D4EC: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258D4F0: 389F0034  addi r4, r31, 0x34
	ctx.r[4].s64 = ctx.r[31].s64 + 52;
	// 8258D4F4: 4BFF71DD  bl 0x825846d0
	ctx.lr = 0x8258D4F8;
	sub_825846D0(ctx, base);
	// 8258D4F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D4FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8258D500: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D504: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D508: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258D50C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D510: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D518(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D518 size=272
    let mut pc: u32 = 0x8258D518;
    'dispatch: loop {
        match pc {
            0x8258D518 => {
    //   block [0x8258D518..0x8258D628)
	// 8258D518: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D51C: 4BFA7B99  bl 0x825350b4
	ctx.lr = 0x8258D520;
	sub_82535080(ctx, base);
	// 8258D520: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D524: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258D528: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D52C: 396B6878  addi r11, r11, 0x6878
	ctx.r[11].s64 = ctx.r[11].s64 + 26744;
	// 8258D530: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8258D534: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258D538: 48015EB1  bl 0x825a33e8
	ctx.lr = 0x8258D53C;
	sub_825A33E8(ctx, base);
	// 8258D53C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D540: 893E004C  lbz r9, 0x4c(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 8258D544: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258D548: 814B007C  lwz r10, 0x7c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(124 as u32) ) } as u64;
	// 8258D54C: 1D69002C  mulli r11, r9, 0x2c
	ctx.r[11].s64 = ctx.r[9].s64 * 44;
	// 8258D550: 7F6B5214  add r27, r11, r10
	ctx.r[27].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8258D554: 481808F9  bl 0x8270de4c
	ctx.lr = 0x8258D558;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258D558: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D55C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258D560: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 8258D564: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258D568: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D56C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D570: 419A0010  beq cr6, 0x8258d580
	if ctx.cr[6].eq {
	pc = 0x8258D580; continue 'dispatch;
	}
	// 8258D574: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D578: 7F1D4040  cmplw cr6, r29, r8
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258D57C: 419A001C  beq cr6, 0x8258d598
	if ctx.cr[6].eq {
	pc = 0x8258D598; continue 'dispatch;
	}
	// 8258D580: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D584: 48180309  bl 0x8270d88c
	ctx.lr = 0x8258D588;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258D588: 7FA8EB78  mr r8, r29
	ctx.r[8].u64 = ctx.r[29].u64;
	// 8258D58C: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8258D590: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 8258D594: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D598: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 8258D59C: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258D5A0: 817B0008  lwz r11, 8(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D5A4: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8258D5A8: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D5AC: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258D5B0: 419A0028  beq cr6, 0x8258d5d8
	if ctx.cr[6].eq {
	pc = 0x8258D5D8; continue 'dispatch;
	}
	// 8258D5B4: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D5B8: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8258D5BC: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D5C0: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D5C4: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8258D5C8: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D5CC: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258D5D0: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D5D4: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D5D8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8258D5DC: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 8258D5E0: 419A0038  beq cr6, 0x8258d618
	if ctx.cr[6].eq {
	pc = 0x8258D618; continue 'dispatch;
	}
	// 8258D5E4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8258D5E8: 409A0030  bne cr6, 0x8258d618
	if !ctx.cr[6].eq {
	pc = 0x8258D618; continue 'dispatch;
	}
	// 8258D5EC: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 8258D5F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D5F4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D5F8: 409A0020  bne cr6, 0x8258d618
	if !ctx.cr[6].eq {
	pc = 0x8258D618; continue 'dispatch;
	}
	// 8258D5FC: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D600: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D604: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258D608: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D60C: 48180271  bl 0x8270d87c
	ctx.lr = 0x8258D610;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258D610: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258D614: 48180849  bl 0x8270de5c
	ctx.lr = 0x8258D618;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258D618: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D61C: 48014FCD  bl 0x825a25e8
	ctx.lr = 0x8258D620;
	sub_825A25E8(ctx, base);
	// 8258D620: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258D624: 4BFA7AE0  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D628(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258D628 size=16
    let mut pc: u32 = 0x8258D628;
    'dispatch: loop {
        match pc {
            0x8258D628 => {
    //   block [0x8258D628..0x8258D638)
	// 8258D628: 8963003D  lbz r11, 0x3d(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(61 as u32) ) } as u64;
	// 8258D62C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258D630: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8258D634: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D638(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258D638 size=8
    let mut pc: u32 = 0x8258D638;
    'dispatch: loop {
        match pc {
            0x8258D638 => {
    //   block [0x8258D638..0x8258D640)
	// 8258D638: 80630020  lwz r3, 0x20(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258D63C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258D640 size=4
    let mut pc: u32 = 0x8258D640;
    'dispatch: loop {
        match pc {
            0x8258D640 => {
    //   block [0x8258D640..0x8258D644)
	// 8258D640: 48015048  b 0x825a2688
	sub_825A2688(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D648 size=104
    let mut pc: u32 = 0x8258D648;
    'dispatch: loop {
        match pc {
            0x8258D648 => {
    //   block [0x8258D648..0x8258D6B0)
	// 8258D648: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D64C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D650: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258D654: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D658: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D65C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D660: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8258D664: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D668: 4BFFFDB9  bl 0x8258d420
	ctx.lr = 0x8258D66C;
	sub_8258D420(ctx, base);
	// 8258D66C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D670: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D674: 48014CA5  bl 0x825a2318
	ctx.lr = 0x8258D678;
	sub_825A2318(ctx, base);
	// 8258D678: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D67C: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8258D680: 41980014  blt cr6, 0x8258d694
	if ctx.cr[6].lt {
	pc = 0x8258D694; continue 'dispatch;
	}
	// 8258D684: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 8258D688: 807E0020  lwz r3, 0x20(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 8258D68C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8258D690: 4BFF7041  bl 0x825846d0
	ctx.lr = 0x8258D694;
	sub_825846D0(ctx, base);
	// 8258D694: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D698: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258D69C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D6A0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D6A4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258D6A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D6AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D6B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D6B0 size=264
    let mut pc: u32 = 0x8258D6B0;
    'dispatch: loop {
        match pc {
            0x8258D6B0 => {
    //   block [0x8258D6B0..0x8258D7B8)
	// 8258D6B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D6B4: 4BFA7A01  bl 0x825350b4
	ctx.lr = 0x8258D6B8;
	sub_82535080(ctx, base);
	// 8258D6B8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D6BC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8258D6C0: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8258D6C4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8258D6C8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D6CC: 48014B05  bl 0x825a21d0
	ctx.lr = 0x8258D6D0;
	sub_825A21D0(ctx, base);
	// 8258D6D0: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258D6D4: 396B6878  addi r11, r11, 0x6878
	ctx.r[11].s64 = ctx.r[11].s64 + 26744;
	// 8258D6D8: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258D6DC: 897F000A  lbz r11, 0xa(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(10 as u32) ) } as u64;
	// 8258D6E0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8258D6E4: 1D4A002C  mulli r10, r10, 0x2c
	ctx.r[10].s64 = ctx.r[10].s64 * 44;
	// 8258D6E8: 997E004C  stb r11, 0x4c(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(76 as u32), ctx.r[11].u8 ) };
	// 8258D6EC: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D6F0: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 8258D6F4: 816B007C  lwz r11, 0x7c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(124 as u32) ) } as u64;
	// 8258D6F8: 7FAA5A14  add r29, r10, r11
	ctx.r[29].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8258D6FC: 48180751  bl 0x8270de4c
	ctx.lr = 0x8258D700;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258D700: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D704: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8258D708: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258D70C: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 8258D710: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D714: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D718: 419A0010  beq cr6, 0x8258d728
	if ctx.cr[6].eq {
	pc = 0x8258D728; continue 'dispatch;
	}
	// 8258D71C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D720: 7F1C5040  cmplw cr6, r28, r10
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258D724: 419A0018  beq cr6, 0x8258d73c
	if ctx.cr[6].eq {
	pc = 0x8258D73C; continue 'dispatch;
	}
	// 8258D728: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D72C: 48180161  bl 0x8270d88c
	ctx.lr = 0x8258D730;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258D730: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 8258D734: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 8258D738: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D73C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258D740: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258D744: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D748: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D74C: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8258D750: 93AB0000  stw r29, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8258D754: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D758: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8258D75C: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D760: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D764: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258D768: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D76C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D770: 419A003C  beq cr6, 0x8258d7ac
	if ctx.cr[6].eq {
	pc = 0x8258D7AC; continue 'dispatch;
	}
	// 8258D774: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D778: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258D77C: 409A0030  bne cr6, 0x8258d7ac
	if !ctx.cr[6].eq {
	pc = 0x8258D7AC; continue 'dispatch;
	}
	// 8258D780: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258D784: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258D788: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258D78C: 409A0020  bne cr6, 0x8258d7ac
	if !ctx.cr[6].eq {
	pc = 0x8258D7AC; continue 'dispatch;
	}
	// 8258D790: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D794: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D798: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258D79C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258D7A0: 481800DD  bl 0x8270d87c
	ctx.lr = 0x8258D7A4;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258D7A4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8258D7A8: 481806B5  bl 0x8270de5c
	ctx.lr = 0x8258D7AC;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258D7AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D7B0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8258D7B4: 4BFA7950  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D7B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D7B8 size=48
    let mut pc: u32 = 0x8258D7B8;
    'dispatch: loop {
        match pc {
            0x8258D7B8 => {
    //   block [0x8258D7B8..0x8258D7E8)
	// 8258D7B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D7BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D7C0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D7C4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D7C8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D7CC: 4BFFFD4D  bl 0x8258d518
	ctx.lr = 0x8258D7D0;
	sub_8258D518(ctx, base);
	// 8258D7D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D7D4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8258D7D8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D7DC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D7E0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D7E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D7E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D7E8 size=268
    let mut pc: u32 = 0x8258D7E8;
    'dispatch: loop {
        match pc {
            0x8258D7E8 => {
    //   block [0x8258D7E8..0x8258D8F4)
	// 8258D7E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D7EC: 4BFA78CD  bl 0x825350b8
	ctx.lr = 0x8258D7F0;
	sub_82535080(ctx, base);
	// 8258D7F0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D7F4: 908100CC  stw r4, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[4].u32 ) };
	// 8258D7F8: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8258D7FC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258D800: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 8258D804: 4BFFFC1D  bl 0x8258d420
	ctx.lr = 0x8258D808;
	sub_8258D420(ctx, base);
	// 8258D808: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D80C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8258D810: 48014A51  bl 0x825a2260
	ctx.lr = 0x8258D814;
	sub_825A2260(ctx, base);
	// 8258D814: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D818: 41980010  blt cr6, 0x8258d828
	if ctx.cr[6].lt {
	pc = 0x8258D828; continue 'dispatch;
	}
	// 8258D81C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258D820: 396B0050  addi r11, r11, 0x50
	ctx.r[11].s64 = ctx.r[11].s64 + 80;
	// 8258D824: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8258D828: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D82C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8258D830: 4198009C  blt cr6, 0x8258d8cc
	if ctx.cr[6].lt {
	pc = 0x8258D8CC; continue 'dispatch;
	}
	// 8258D834: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 8258D838: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258D83C: 38A100CC  addi r5, r1, 0xcc
	ctx.r[5].s64 = ctx.r[1].s64 + 204;
	// 8258D840: 60630006  ori r3, r3, 6
	ctx.r[3].u64 = ctx.r[3].u64 | 6;
	// 8258D844: 480148DD  bl 0x825a2120
	ctx.lr = 0x8258D848;
	sub_825A2120(ctx, base);
	// 8258D848: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D84C: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8258D850: 4198007C  blt cr6, 0x8258d8cc
	if ctx.cr[6].lt {
	pc = 0x8258D8CC; continue 'dispatch;
	}
	// 8258D854: 806100CC  lwz r3, 0xcc(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 8258D858: 38800050  li r4, 0x50
	ctx.r[4].s64 = 80;
	// 8258D85C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D860: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258D864: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D868: 4E800421  bctrl
	ctx.lr = 0x8258D86C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D86C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258D870: 419A001C  beq cr6, 0x8258d88c
	if ctx.cr[6].eq {
	pc = 0x8258D88C; continue 'dispatch;
	}
	// 8258D874: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8258D878: 80A100CC  lwz r5, 0xcc(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 8258D87C: 4BFFFE35  bl 0x8258d6b0
	ctx.lr = 0x8258D880;
	sub_8258D6B0(ctx, base);
	// 8258D880: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8258D884: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8258D888: 409A0010  bne cr6, 0x8258d898
	if !ctx.cr[6].eq {
	pc = 0x8258D898; continue 'dispatch;
	}
	// 8258D88C: 3FC08007  lis r30, -0x7ff9
	ctx.r[30].s64 = -2147024896;
	// 8258D890: 63DE000E  ori r30, r30, 0xe
	ctx.r[30].u64 = ctx.r[30].u64 | 14;
	// 8258D894: 48000038  b 0x8258d8cc
	pc = 0x8258D8CC; continue 'dispatch;
	// 8258D898: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8258D89C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D8A0: 4BFFFDA9  bl 0x8258d648
	ctx.lr = 0x8258D8A4;
	sub_8258D648(ctx, base);
	// 8258D8A4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258D8A8: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8258D8AC: 4198000C  blt cr6, 0x8258d8b8
	if ctx.cr[6].lt {
	pc = 0x8258D8B8; continue 'dispatch;
	}
	// 8258D8B0: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8258D8B4: 48000018  b 0x8258d8cc
	pc = 0x8258D8CC; continue 'dispatch;
	// 8258D8B8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D8BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258D8C0: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D8C4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D8C8: 4E800421  bctrl
	ctx.lr = 0x8258D8CC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D8CC: 806100CC  lwz r3, 0xcc(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 8258D8D0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8258D8D4: 419A0014  beq cr6, 0x8258d8e8
	if ctx.cr[6].eq {
	pc = 0x8258D8E8; continue 'dispatch;
	}
	// 8258D8D8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D8DC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D8E0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8258D8E4: 4E800421  bctrl
	ctx.lr = 0x8258D8E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8258D8E8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258D8EC: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8258D8F0: 4BFA7818  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D8F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258D8F8 size=52
    let mut pc: u32 = 0x8258D8F8;
    'dispatch: loop {
        match pc {
            0x8258D8F8 => {
    //   block [0x8258D8F8..0x8258D92C)
	// 8258D8F8: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D8FC: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258D900: 396B3928  addi r11, r11, 0x3928
	ctx.r[11].s64 = ctx.r[11].s64 + 14632;
	// 8258D904: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8258D908: 7CE000A6  mfmsr r7
	ctx.r[7].u64 = ctx.msr;
	// 8258D90C: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8258D910: 7D205828  lwarx r9, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[9].u64 = ctx.reserved.u32 as u64;
	// 8258D914: 7D044A14  add r8, r4, r9
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[9].u64;
	// 8258D918: 7D00592D  stwcx. r8, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[8].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8258D91C: 7CE10164  mtmsrd r7, 1
	ctx.msr = (ctx.r[7].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8258D920: 4082FFE8  bne 0x8258d908
	if !ctx.cr[0].eq {
	pc = 0x8258D908; continue 'dispatch;
	}
	// 8258D924: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258D928: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258D930(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8258D930 size=208
    let mut pc: u32 = 0x8258D930;
    'dispatch: loop {
        match pc {
            0x8258D930 => {
    //   block [0x8258D930..0x8258DA00)
	// 8258D930: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258D934: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8258D938: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8258D93C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8258D940: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258D944: 7D4C42E6  mftb r10, 0x10c
	ctx.r[10].u64 = crate::rt::rdtsc_u64();
	// 8258D948: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8258D94C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8258D950: 7D490676  sradi r9, r10, 0x20
	ctx.xer.ca = (ctx.r[10].s64 < 0) && ((ctx.r[10].u64 & ((1u64 << 32) - 1)) != 0);
	ctx.r[9].s64 = ctx.r[10].s64 >> 32;
	// 8258D954: 3C605841  lis r3, 0x5841
	ctx.r[3].s64 = 1480654848;
	// 8258D958: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 8258D95C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258D960: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 8258D964: 60637564  ori r3, r3, 0x7564
	ctx.r[3].u64 = ctx.r[3].u64 | 30052;
	// 8258D968: FBCB0008  std r30, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 8258D96C: FBCB0010  std r30, 0x10(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u64 ) };
	// 8258D970: FBCB0018  std r30, 0x18(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[30].u64 ) };
	// 8258D974: FBCB0020  std r30, 0x20(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), ctx.r[30].u64 ) };
	// 8258D978: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258D97C: 91210054  stw r9, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[9].u32 ) };
	// 8258D980: 3BEB3928  addi r31, r11, 0x3928
	ctx.r[31].s64 = ctx.r[11].s64 + 14632;
	// 8258D984: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8258D988: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258D98C: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8258D990: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258D994: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8258D998: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258D99C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8258D9A0: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258D9A4: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 8258D9A8: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258D9AC: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8258D9B0: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8258D9B4: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 8258D9B8: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258D9BC: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258D9C0: 4BFB8731  bl 0x825460f0
	ctx.lr = 0x8258D9C4;
	sub_825460F0(ctx, base);
	// 8258D9C4: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 8258D9C8: 7D2BF82E  lwzx r9, r11, r31
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 8258D9CC: 395F001C  addi r10, r31, 0x1c
	ctx.r[10].s64 = ctx.r[31].s64 + 28;
	// 8258D9D0: 7FCBF92E  stwx r30, r11, r31
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32), ctx.r[30].u32) };
	// 8258D9D4: 7D2B512E  stwx r9, r11, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[9].u32) };
	// 8258D9D8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8258D9DC: 2F0B001C  cmpwi cr6, r11, 0x1c
	ctx.cr[6].compare_i32(ctx.r[11].s32, 28, &mut ctx.xer);
	// 8258D9E0: 4198FFE8  blt cr6, 0x8258d9c8
	if ctx.cr[6].lt {
	pc = 0x8258D9C8; continue 'dispatch;
	}
	// 8258D9E4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258D9E8: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8258D9EC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8258D9F0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8258D9F4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8258D9F8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8258D9FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258DA00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258DA00 size=24
    let mut pc: u32 = 0x8258DA00;
    'dispatch: loop {
        match pc {
            0x8258DA00 => {
    //   block [0x8258DA00..0x8258DA18)
	// 8258DA00: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 8258DA04: 39400EA6  li r10, 0xea6
	ctx.r[10].s64 = 3750;
	// 8258DA08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258DA0C: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8258DA10: B1440002  sth r10, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[10].u16 ) };
	// 8258DA14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258DA18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258DA18 size=528
    let mut pc: u32 = 0x8258DA18;
    'dispatch: loop {
        match pc {
            0x8258DA18 => {
    //   block [0x8258DA18..0x8258DC28)
	// 8258DA18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258DA1C: 4BFA7695  bl 0x825350b0
	ctx.lr = 0x8258DA20;
	sub_82535080(ctx, base);
	// 8258DA20: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 8258DA24: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258DA28: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 8258DA2C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258DA30: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 8258DA34: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 8258DA38: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8258DA3C: 419A0118  beq cr6, 0x8258db54
	if ctx.cr[6].eq {
	pc = 0x8258DB54; continue 'dispatch;
	}
	// 8258DA40: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 8258DA44: 419A0018  beq cr6, 0x8258da5c
	if ctx.cr[6].eq {
	pc = 0x8258DA5C; continue 'dispatch;
	}
	// 8258DA48: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 8258DA4C: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 8258DA50: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258DA54: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8258DA58: 4BFA76A8  b 0x82535100
	sub_825350D0(ctx, base);
	return;
	// 8258DA5C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8258DA60: 4BFB85F1  bl 0x82546050
	ctx.lr = 0x8258DA64;
	sub_82546050(ctx, base);
	// 8258DA64: 481803E9  bl 0x8270de4c
	ctx.lr = 0x8258DA68;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DA68: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258DA6C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258DA70: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258DA74: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DA78: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DA7C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8258DA80: 419A0010  beq cr6, 0x8258da90
	if ctx.cr[6].eq {
	pc = 0x8258DA90; continue 'dispatch;
	}
	// 8258DA84: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DA88: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8258DA8C: 419A0018  beq cr6, 0x8258daa4
	if ctx.cr[6].eq {
	pc = 0x8258DAA4; continue 'dispatch;
	}
	// 8258DA90: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DA94: 4817FDF9  bl 0x8270d88c
	ctx.lr = 0x8258DA98;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DA98: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DA9C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 8258DAA0: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DAA4: 3D7D0005  addis r11, r29, 5
	ctx.r[11].s64 = ctx.r[29].s64 + 327680;
	// 8258DAA8: C8010050  lfd f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8258DAAC: 3D5D0005  addis r10, r29, 5
	ctx.r[10].s64 = ctx.r[29].s64 + 327680;
	// 8258DAB0: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 8258DAB4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258DAB8: 396BBAA8  addi r11, r11, -0x4558
	ctx.r[11].s64 = ctx.r[11].s64 + -17752;
	// 8258DABC: 394ABAA0  addi r10, r10, -0x4560
	ctx.r[10].s64 = ctx.r[10].s64 + -17760;
	// 8258DAC0: 7DA86B78  mr r8, r13
	ctx.r[8].u64 = ctx.r[13].u64;
	// 8258DAC4: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8258DAC8: 3D208209  lis r9, -0x7df7
	ctx.r[9].s64 = -2113339392;
	// 8258DACC: C80B0000  lfd f0, 0(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 8258DAD0: C98A0000  lfd f12, 0(r10)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 8258DAD4: FD60069C  fcfid f11, f0
	ctx.f[11].f64 = (ctx.f[0].s64 as f64);
	// 8258DAD8: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8258DADC: C80968D8  lfd f0, 0x68d8(r9)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[9].u32.wrapping_add(26840 as u32) ) };
	// 8258DAE0: FC0B0032  fmul f0, f11, f0
	ctx.f[0].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 8258DAE4: FDAC6824  fdiv f13, f12, f13
	ctx.f[13].f64 = ctx.f[12].f64 / ctx.f[13].f64;
	// 8258DAE8: FC0D0024  fdiv f0, f13, f0
	ctx.f[0].f64 = ctx.f[13].f64 / ctx.f[0].f64;
	// 8258DAEC: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8258DAF0: D01A0000  stfs f0, 0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258DAF4: FB6A0000  std r27, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[27].u64 ) };
	// 8258DAF8: FB6B0000  std r27, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[27].u64 ) };
	// 8258DAFC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DB00: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DB04: 419A0114  beq cr6, 0x8258dc18
	if ctx.cr[6].eq {
	pc = 0x8258DC18; continue 'dispatch;
	}
	// 8258DB08: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DB0C: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DB10: 409A0108  bne cr6, 0x8258dc18
	if !ctx.cr[6].eq {
	pc = 0x8258DC18; continue 'dispatch;
	}
	// 8258DB14: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258DB18: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DB1C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DB20: 409A00F8  bne cr6, 0x8258dc18
	if !ctx.cr[6].eq {
	pc = 0x8258DC18; continue 'dispatch;
	}
	// 8258DB24: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 8258DB28: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DB2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DB30: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258DB34: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258DB38: 4817FD45  bl 0x8270d87c
	ctx.lr = 0x8258DB3C;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258DB3C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258DB40: 4818031D  bl 0x8270de5c
	ctx.lr = 0x8258DB44;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258DB44: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8258DB48: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258DB4C: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8258DB50: 4BFA75B0  b 0x82535100
	sub_825350D0(ctx, base);
	return;
	// 8258DB54: 481802F9  bl 0x8270de4c
	ctx.lr = 0x8258DB58;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DB58: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258DB5C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258DB60: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258DB64: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DB68: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DB6C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DB70: 419A0010  beq cr6, 0x8258db80
	if ctx.cr[6].eq {
	pc = 0x8258DB80; continue 'dispatch;
	}
	// 8258DB74: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DB78: 7F1E4840  cmplw cr6, r30, r9
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258DB7C: 419A0024  beq cr6, 0x8258dba0
	if ctx.cr[6].eq {
	pc = 0x8258DBA0; continue 'dispatch;
	}
	// 8258DB80: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DB84: 4817FD09  bl 0x8270d88c
	ctx.lr = 0x8258DB88;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DB88: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 8258DB8C: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 8258DB90: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8258DB94: 9BDF000C  stb r30, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 8258DB98: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DB9C: 48000008  b 0x8258dba4
	pc = 0x8258DBA4; continue 'dispatch;
	// 8258DBA0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DBA4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DBA8: 7DA86B78  mr r8, r13
	ctx.r[8].u64 = ctx.r[13].u64;
	// 8258DBAC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DBB0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DBB4: 815D0010  lwz r10, 0x10(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258DBB8: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DBBC: 7D4AEA14  add r10, r10, r29
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 8258DBC0: C1AA006C  lfs f13, 0x6c(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258DBC4: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8258DBC8: C00A2094  lfs f0, 0x2094(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8340 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DBCC: EFED0032  fmuls f31, f13, f0
	ctx.f[31].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258DBD0: 419A0038  beq cr6, 0x8258dc08
	if ctx.cr[6].eq {
	pc = 0x8258DC08; continue 'dispatch;
	}
	// 8258DBD4: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258DBD8: 409A0030  bne cr6, 0x8258dc08
	if !ctx.cr[6].eq {
	pc = 0x8258DC08; continue 'dispatch;
	}
	// 8258DBDC: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258DBE0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DBE4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DBE8: 409A0020  bne cr6, 0x8258dc08
	if !ctx.cr[6].eq {
	pc = 0x8258DC08; continue 'dispatch;
	}
	// 8258DBEC: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 8258DBF0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DBF4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258DBF8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258DBFC: 4817FC81  bl 0x8270d87c
	ctx.lr = 0x8258DC00;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258DC00: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258DC04: 48180259  bl 0x8270de5c
	ctx.lr = 0x8258DC08;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258DC08: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8258DC0C: C00B20B0  lfs f0, 0x20b0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DC10: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258DC14: D01A0000  stfs f0, 0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258DC18: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8258DC1C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8258DC20: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8258DC24: 4BFA74DC  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258DC28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258DC28 size=940
    let mut pc: u32 = 0x8258DC28;
    'dispatch: loop {
        match pc {
            0x8258DC28 => {
    //   block [0x8258DC28..0x8258DFD4)
	// 8258DC28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258DC2C: 4BFA7485  bl 0x825350b0
	ctx.lr = 0x8258DC30;
	sub_82535080(ctx, base);
	// 8258DC30: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 8258DC34: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258DC38: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 8258DC3C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258DC40: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8258DC44: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8258DC48: 4198017C  blt cr6, 0x8258ddc4
	if ctx.cr[6].lt {
	pc = 0x8258DDC4; continue 'dispatch;
	}
	// 8258DC4C: 419A00CC  beq cr6, 0x8258dd18
	if ctx.cr[6].eq {
	pc = 0x8258DD18; continue 'dispatch;
	}
	// 8258DC50: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 8258DC54: 4198001C  blt cr6, 0x8258dc70
	if ctx.cr[6].lt {
	pc = 0x8258DC70; continue 'dispatch;
	}
	// 8258DC58: 3F408007  lis r26, -0x7ff9
	ctx.r[26].s64 = -2147024896;
	// 8258DC5C: 635A0057  ori r26, r26, 0x57
	ctx.r[26].u64 = ctx.r[26].u64 | 87;
	// 8258DC60: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258DC64: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8258DC68: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8258DC6C: 4BFA7494  b 0x82535100
	sub_825350D0(ctx, base);
	return;
	// 8258DC70: C3E60000  lfs f31, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8258DC74: 481801D9  bl 0x8270de4c
	ctx.lr = 0x8258DC78;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DC78: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258DC7C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258DC80: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258DC84: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DC88: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DC8C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DC90: 419A0010  beq cr6, 0x8258dca0
	if ctx.cr[6].eq {
	pc = 0x8258DCA0; continue 'dispatch;
	}
	// 8258DC94: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DC98: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DC9C: 419A0018  beq cr6, 0x8258dcb4
	if ctx.cr[6].eq {
	pc = 0x8258DCB4; continue 'dispatch;
	}
	// 8258DCA0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DCA4: 4817FBE9  bl 0x8270d88c
	ctx.lr = 0x8258DCA8;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DCA8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DCAC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258DCB0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DCB4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DCB8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DCBC: 48180191  bl 0x8270de4c
	ctx.lr = 0x8258DCC0;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DCC0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DCC4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258DCC8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DCCC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DCD0: 419A0010  beq cr6, 0x8258dce0
	if ctx.cr[6].eq {
	pc = 0x8258DCE0; continue 'dispatch;
	}
	// 8258DCD4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DCD8: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DCDC: 419A0018  beq cr6, 0x8258dcf4
	if ctx.cr[6].eq {
	pc = 0x8258DCF4; continue 'dispatch;
	}
	// 8258DCE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DCE4: 4817FBA9  bl 0x8270d88c
	ctx.lr = 0x8258DCE8;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DCE8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DCEC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258DCF0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DCF4: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8258DCF8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DCFC: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8258DD00: C00A2094  lfs f0, 0x2094(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8340 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DD04: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DD08: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258DD0C: D01C00C8  stfs f0, 0xc8(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 8258DD10: 993C00CC  stb r9, 0xcc(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(204 as u32), ctx.r[9].u8 ) };
	// 8258DD14: 48000220  b 0x8258df34
	pc = 0x8258DF34; continue 'dispatch;
	// 8258DD18: 83660000  lwz r27, 0(r6)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258DD1C: 48180131  bl 0x8270de4c
	ctx.lr = 0x8258DD20;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DD20: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258DD24: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258DD28: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258DD2C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DD30: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DD34: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DD38: 419A0010  beq cr6, 0x8258dd48
	if ctx.cr[6].eq {
	pc = 0x8258DD48; continue 'dispatch;
	}
	// 8258DD3C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DD40: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DD44: 419A0018  beq cr6, 0x8258dd5c
	if ctx.cr[6].eq {
	pc = 0x8258DD5C; continue 'dispatch;
	}
	// 8258DD48: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DD4C: 4817FB41  bl 0x8270d88c
	ctx.lr = 0x8258DD50;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DD50: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DD54: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258DD58: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DD5C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DD60: 3BDC0010  addi r30, r28, 0x10
	ctx.r[30].s64 = ctx.r[28].s64 + 16;
	// 8258DD64: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DD68: 481800E5  bl 0x8270de4c
	ctx.lr = 0x8258DD6C;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DD6C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DD70: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258DD74: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 8258DD78: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DD7C: 419A0010  beq cr6, 0x8258dd8c
	if ctx.cr[6].eq {
	pc = 0x8258DD8C; continue 'dispatch;
	}
	// 8258DD80: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DD84: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DD88: 419A0018  beq cr6, 0x8258dda0
	if ctx.cr[6].eq {
	pc = 0x8258DDA0; continue 'dispatch;
	}
	// 8258DD8C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DD90: 4817FAFD  bl 0x8270d88c
	ctx.lr = 0x8258DD94;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DD94: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 8258DD98: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 8258DD9C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DDA0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DDA4: 387E0088  addi r3, r30, 0x88
	ctx.r[3].s64 = ctx.r[30].s64 + 136;
	// 8258DDA8: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 8258DDAC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 8258DDB0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DDB4: 4BFA6D9D  bl 0x82534b50
	ctx.lr = 0x8258DDB8;
	sub_82534B50(ctx, base);
	// 8258DDB8: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8258DDBC: 997E00BE  stb r11, 0xbe(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(190 as u32), ctx.r[11].u8 ) };
	// 8258DDC0: 48000174  b 0x8258df34
	pc = 0x8258DF34; continue 'dispatch;
	// 8258DDC4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8258DDC8: 83E60000  lwz r31, 0(r6)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258DDCC: 48015B65  bl 0x825a3930
	ctx.lr = 0x8258DDD0;
	sub_825A3930(ctx, base);
	// 8258DDD0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258DDD4: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8258DDD8: 897F0004  lbz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DDDC: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8258DDE0: 897F0006  lbz r11, 6(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(6 as u32) ) } as u64;
	// 8258DDE4: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8258DDE8: 897F0007  lbz r11, 7(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(7 as u32) ) } as u64;
	// 8258DDEC: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8258DDF0: 897F0008  lbz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DDF4: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8258DDF8: 897F0009  lbz r11, 9(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(9 as u32) ) } as u64;
	// 8258DDFC: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8258DE00: 897F000A  lbz r11, 0xa(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(10 as u32) ) } as u64;
	// 8258DE04: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 8258DE08: 897F000B  lbz r11, 0xb(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(11 as u32) ) } as u64;
	// 8258DE0C: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8258DE10: 897F000C  lbz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DE14: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 8258DE18: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8258DE1C: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258DE20: 897F000E  lbz r11, 0xe(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 8258DE24: 91610078  stw r11, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 8258DE28: 897F000F  lbz r11, 0xf(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(15 as u32) ) } as u64;
	// 8258DE2C: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8258DE30: 897F0005  lbz r11, 5(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(5 as u32) ) } as u64;
	// 8258DE34: 91610080  stw r11, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8258DE38: C01F0010  lfs f0, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE3C: D0010084  stfs f0, 0x84(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8258DE40: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8258DE44: C01F0014  lfs f0, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE48: D0010088  stfs f0, 0x88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8258DE4C: C01F0018  lfs f0, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE50: D001008C  stfs f0, 0x8c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 8258DE54: C01F001C  lfs f0, 0x1c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE58: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 8258DE5C: C01F0020  lfs f0, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE60: D0010094  stfs f0, 0x94(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 8258DE64: C01F0024  lfs f0, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE68: D0010098  stfs f0, 0x98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 8258DE6C: C00B2094  lfs f0, 0x2094(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8340 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE70: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8258DE74: C1BF0028  lfs f13, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258DE78: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258DE7C: D001009C  stfs f0, 0x9c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 8258DE80: C1BF002C  lfs f13, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258DE84: C00B68E0  lfs f0, 0x68e0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26848 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DE88: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258DE8C: D00100A0  stfs f0, 0xa0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 8258DE90: 4817FFBD  bl 0x8270de4c
	ctx.lr = 0x8258DE94;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DE94: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 8258DE98: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8258DE9C: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 8258DEA0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DEA4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DEA8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DEAC: 419A0010  beq cr6, 0x8258debc
	if ctx.cr[6].eq {
	pc = 0x8258DEBC; continue 'dispatch;
	}
	// 8258DEB0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DEB4: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DEB8: 419A0018  beq cr6, 0x8258ded0
	if ctx.cr[6].eq {
	pc = 0x8258DED0; continue 'dispatch;
	}
	// 8258DEBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DEC0: 4817F9CD  bl 0x8270d88c
	ctx.lr = 0x8258DEC4;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DEC4: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DEC8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 8258DECC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DED0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DED4: 3BBC0010  addi r29, r28, 0x10
	ctx.r[29].s64 = ctx.r[28].s64 + 16;
	// 8258DED8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DEDC: 4817FF71  bl 0x8270de4c
	ctx.lr = 0x8258DEE0;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 8258DEE0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DEE4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8258DEE8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 8258DEEC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DEF0: 419A0010  beq cr6, 0x8258df00
	if ctx.cr[6].eq {
	pc = 0x8258DF00; continue 'dispatch;
	}
	// 8258DEF4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DEF8: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8258DEFC: 419A0018  beq cr6, 0x8258df14
	if ctx.cr[6].eq {
	pc = 0x8258DF14; continue 'dispatch;
	}
	// 8258DF00: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DF04: 4817F989  bl 0x8270d88c
	ctx.lr = 0x8258DF08;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 8258DF08: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8258DF0C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 8258DF10: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DF14: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258DF18: 387D0034  addi r3, r29, 0x34
	ctx.r[3].s64 = ctx.r[29].s64 + 52;
	// 8258DF1C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8258DF20: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 8258DF24: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DF28: 4BFA6C29  bl 0x82534b50
	ctx.lr = 0x8258DF2C;
	sub_82534B50(ctx, base);
	// 8258DF2C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8258DF30: 997D00BD  stb r11, 0xbd(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(189 as u32), ctx.r[11].u8 ) };
	// 8258DF34: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DF38: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258DF3C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DF40: 419A0040  beq cr6, 0x8258df80
	if ctx.cr[6].eq {
	pc = 0x8258DF80; continue 'dispatch;
	}
	// 8258DF44: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DF48: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258DF4C: 409A0034  bne cr6, 0x8258df80
	if !ctx.cr[6].eq {
	pc = 0x8258DF80; continue 'dispatch;
	}
	// 8258DF50: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258DF54: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DF58: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DF5C: 409A0024  bne cr6, 0x8258df80
	if !ctx.cr[6].eq {
	pc = 0x8258DF80; continue 'dispatch;
	}
	// 8258DF60: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DF64: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DF68: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258DF6C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258DF70: 4817F90D  bl 0x8270d87c
	ctx.lr = 0x8258DF74;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258DF74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258DF78: 4817FEE5  bl 0x8270de5c
	ctx.lr = 0x8258DF7C;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258DF7C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258DF80: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DF84: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 8258DF88: 419A003C  beq cr6, 0x8258dfc4
	if ctx.cr[6].eq {
	pc = 0x8258DFC4; continue 'dispatch;
	}
	// 8258DF8C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DF90: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258DF94: 409A0030  bne cr6, 0x8258dfc4
	if !ctx.cr[6].eq {
	pc = 0x8258DFC4; continue 'dispatch;
	}
	// 8258DF98: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258DF9C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258DFA0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8258DFA4: 409A0020  bne cr6, 0x8258dfc4
	if !ctx.cr[6].eq {
	pc = 0x8258DFC4; continue 'dispatch;
	}
	// 8258DFA8: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DFAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8258DFB0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8258DFB4: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8258DFB8: 4817F8C5  bl 0x8270d87c
	ctx.lr = 0x8258DFBC;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 8258DFBC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8258DFC0: 4817FE9D  bl 0x8270de5c
	ctx.lr = 0x8258DFC4;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 8258DFC4: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 8258DFC8: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 8258DFCC: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8258DFD0: 4BFA7130  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258DFD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258DFD8 size=1620
    let mut pc: u32 = 0x8258DFD8;
    'dispatch: loop {
        match pc {
            0x8258DFD8 => {
    //   block [0x8258DFD8..0x8258E62C)
	// 8258DFD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258DFDC: 4BFA70B1  bl 0x8253508c
	ctx.lr = 0x8258DFE0;
	sub_82535080(ctx, base);
	// 8258DFE0: 8103000C  lwz r8, 0xc(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258DFE4: C0030014  lfs f0, 0x14(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258DFE8: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258DFEC: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258DFF0: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 8258DFF4: 7F284850  subf r25, r8, r9
	ctx.r[25].s64 = ctx.r[9].s64 - ctx.r[8].s64;
	// 8258DFF8: 2B190004  cmplwi cr6, r25, 4
	ctx.cr[6].compare_u32(ctx.r[25].u32, 4 as u32, &mut ctx.xer);
	// 8258DFFC: 41990014  bgt cr6, 0x8258e010
	if ctx.cr[6].gt {
	pc = 0x8258E010; continue 'dispatch;
	}
	// 8258E000: 7D694050  subf r11, r9, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 8258E004: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8258E008: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 8258E00C: 40990008  ble cr6, 0x8258e014
	if !ctx.cr[6].gt {
	pc = 0x8258E014; continue 'dispatch;
	}
	// 8258E010: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 8258E014: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8258E018: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E01C: 38E1FF70  addi r7, r1, -0x90
	ctx.r[7].s64 = ctx.r[1].s64 + -144;
	// 8258E020: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258E024: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 8258E028: 3AC30018  addi r22, r3, 0x18
	ctx.r[22].s64 = ctx.r[3].s64 + 24;
	// 8258E02C: C00B2208  lfs f0, 0x2208(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8712 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E030: EC0C0032  fmuls f0, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258E034: FC00065E  fctidz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 8258E038: 7C003FAE  stfiwx f0, 0, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32, tmp.u32) };
	// 8258E03C: 8161FF70  lwz r11, -0x90(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-144 as u32) ) } as u64;
	// 8258E040: 5567F87E  srwi r7, r11, 1
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shr(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8258E044: 2B070100  cmplwi cr6, r7, 0x100
	ctx.cr[6].compare_u32(ctx.r[7].u32, 256 as u32, &mut ctx.xer);
	// 8258E048: 40980408  bge cr6, 0x8258e450
	if !ctx.cr[6].lt {
	pc = 0x8258E450; continue 'dispatch;
	}
	// 8258E04C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8258E050: 3CC08209  lis r6, -0x7df7
	ctx.r[6].s64 = -2113339392;
	// 8258E054: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 8258E058: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 8258E05C: C16B1850  lfs f11, 0x1850(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(6224 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E060: 39630020  addi r11, r3, 0x20
	ctx.r[11].s64 = ctx.r[3].s64 + 32;
	// 8258E064: C00668E8  lfs f0, 0x68e8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(26856 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E068: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258E06C: 41980128  blt cr6, 0x8258e194
	if ctx.cr[6].lt {
	pc = 0x8258E194; continue 'dispatch;
	}
	// 8258E070: 54FDF0BE  srwi r29, r7, 2
	ctx.r[29].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 8258E074: 38CA0002  addi r6, r10, 2
	ctx.r[6].s64 = ctx.r[10].s64 + 2;
	// 8258E078: 7F895050  subf r28, r9, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 8258E07C: 7D285050  subf r9, r8, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8258E080: 57BB103A  slwi r27, r29, 2
	ctx.r[27].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 8258E084: 54C8103A  slwi r8, r6, 2
	ctx.r[8].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258E088: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 8258E08C: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 8258E090: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258E094: 3BC40008  addi r30, r4, 8
	ctx.r[30].s64 = ctx.r[4].s64 + 8;
	// 8258E098: 3925000C  addi r9, r5, 0xc
	ctx.r[9].s64 = ctx.r[5].s64 + 12;
	// 8258E09C: 7F452050  subf r26, r5, r4
	ctx.r[26].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 8258E0A0: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 8258E0A4: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 8258E0A8: 5798143A  rlwinm r24, r28, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0AC: C15EFFF8  lfs f10, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E0B0: 7E9CCA14  add r20, r28, r25
	ctx.r[20].u64 = ctx.r[28].u64 + ctx.r[25].u64;
	// 8258E0B4: C13EFFFC  lfs f9, -4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E0B8: 3A66FFFF  addi r19, r6, -1
	ctx.r[19].s64 = ctx.r[6].s64 + -1;
	// 8258E0BC: C11E0000  lfs f8, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E0C0: 5694143A  rlwinm r20, r20, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0C4: 7CFA4C2E  lfsx f7, r26, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258E0C8: 5673143A  rlwinm r19, r19, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0CC: 7CD85C2E  lfsx f6, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E0D0: 3B1FFFFF  addi r24, r31, -1
	ctx.r[24].s64 = ctx.r[31].s64 + -1;
	// 8258E0D4: ECC60372  fmuls f6, f6, f13
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E0D8: 54D2143A  rlwinm r18, r6, 2, 0x10, 0x1d
	ctx.r[18].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0DC: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E0E0: 5718143A  rlwinm r24, r24, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[24].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0E4: 7CB45C2E  lfsx f5, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258E0E8: 57F4143A  rlwinm r20, r31, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E0EC: D148FFF8  stfs f10, -8(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258E0F0: 3A3F0001  addi r17, r31, 1
	ctx.r[17].s64 = ctx.r[31].s64 + 1;
	// 8258E0F4: 7D535C2E  lfsx f10, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E0F8: 3A660001  addi r19, r6, 1
	ctx.r[19].s64 = ctx.r[6].s64 + 1;
	// 8258E0FC: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8258E100: 7C985C2E  lfsx f4, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258E104: 5678143A  rlwinm r24, r19, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[19].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E108: D128FFFC  stfs f9, -4(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E10C: 5633143A  rlwinm r19, r17, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E110: 7D325C2E  lfsx f9, r18, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[18].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E114: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258E118: 7C745C2E  lfsx f3, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8258E11C: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 8258E120: ECC5333A  fmadds f6, f5, f12, f6
	ctx.f[6].f64 = (((ctx.f[5].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258E124: D1080000  stfs f8, 0(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E128: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E12C: 7D185C2E  lfsx f8, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E130: 7CB35C2E  lfsx f5, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258E134: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258E138: D0C9FFF8  stfs f6, -8(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258E13C: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 8258E140: D0E80004  stfs f7, 4(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E144: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8258E148: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 8258E14C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E150: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E154: ED44537A  fmadds f10, f4, f13, f10
	ctx.f[10].f64 = (((ctx.f[4].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E158: D149FFFC  stfs f10, -4(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E15C: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E160: ED490332  fmuls f10, f9, f12
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E164: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E168: ED43537A  fmadds f10, f3, f13, f10
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E16C: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E170: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E174: ED480332  fmuls f10, f8, f12
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E178: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E17C: ED45537A  fmadds f10, f5, f13, f10
	ctx.f[10].f64 = (((ctx.f[5].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E180: D1490004  stfs f10, 4(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E184: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E188: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 8258E18C: 409AFF1C  bne cr6, 0x8258e0a8
	if !ctx.cr[6].eq {
	pc = 0x8258E0A8; continue 'dispatch;
	}
	// 8258E190: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E194: 7F1B3840  cmplw cr6, r27, r7
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8258E198: 4199008C  bgt cr6, 0x8258e224
	if ctx.cr[6].gt {
	pc = 0x8258E224; continue 'dispatch;
	}
	// 8258E19C: 5766103A  slwi r6, r27, 2
	ctx.r[6].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8258E1A0: 83A30008  lwz r29, 8(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258E1A4: 7D3B3850  subf r9, r27, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[27].s64;
	// 8258E1A8: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258E1AC: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258E1B0: C1970000  lfs f12, 0(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E1B4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258E1B8: 7F862214  add r28, r6, r4
	ctx.r[28].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 8258E1BC: 7FE85A14  add r31, r8, r11
	ctx.r[31].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258E1C0: 7D1D5050  subf r8, r29, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[29].s64;
	// 8258E1C4: 7FC62A14  add r30, r6, r5
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8258E1C8: 38DCFFFC  addi r6, r28, -4
	ctx.r[6].s64 = ctx.r[28].s64 + -4;
	// 8258E1CC: 7FBBE850  subf r29, r27, r29
	ctx.r[29].s64 = ctx.r[29].s64 - ctx.r[27].s64;
	// 8258E1D0: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8258E1D4: 551C143A  rlwinm r28, r8, 2, 0x10, 0x1d
	ctx.r[28].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E1D8: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E1DC: 7F7D4214  add r27, r29, r8
	ctx.r[27].u64 = ctx.r[29].u64 + ctx.r[8].u64;
	// 8258E1E0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258E1E4: 577B143A  rlwinm r27, r27, 2, 0x10, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E1E8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8258E1EC: 7D3C5C2E  lfsx f9, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E1F0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258E1F4: ED290372  fmuls f9, f9, f13
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E1F8: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258E1FC: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E200: 7D1B5C2E  lfsx f8, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E204: D15F0000  stfs f10, 0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E208: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258E20C: ED484B3A  fmadds f10, f8, f12, f9
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258E210: D15E0000  stfs f10, 0(r30)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E214: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E218: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 8258E21C: 409AFFB8  bne cr6, 0x8258e1d4
	if !ctx.cr[6].eq {
	pc = 0x8258E1D4; continue 'dispatch;
	}
	// 8258E220: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E224: 83230010  lwz r25, 0x10(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258E228: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258E22C: 7F194840  cmplw cr6, r25, r9
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258E230: 419A000C  beq cr6, 0x8258e23c
	if ctx.cr[6].eq {
	pc = 0x8258E23C; continue 'dispatch;
	}
	// 8258E234: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 8258E238: 4800000C  b 0x8258e244
	pc = 0x8258E244; continue 'dispatch;
	// 8258E23C: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8258E240: C1881FF8  lfs f12, 0x1ff8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8184 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E244: 21070100  subfic r8, r7, 0x100
	ctx.xer.ca = ctx.r[7].u32 <= 256 as u32;
	ctx.r[8].s64 = (256 as i64) - ctx.r[7].s64;
	// 8258E248: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E24C: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258E250: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 8258E254: 2F080004  cmpwi cr6, r8, 4
	ctx.cr[6].compare_i32(ctx.r[8].s32, 4, &mut ctx.xer);
	// 8258E258: 9123000C  stw r9, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 8258E25C: 93230008  stw r25, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 8258E260: 41980148  blt cr6, 0x8258e3a8
	if ctx.cr[6].lt {
	pc = 0x8258E3A8; continue 'dispatch;
	}
	// 8258E264: 212700FC  subfic r9, r7, 0xfc
	ctx.xer.ca = ctx.r[7].u32 <= 252 as u32;
	ctx.r[9].s64 = (252 as i64) - ctx.r[7].s64;
	// 8258E268: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258E26C: 390A0002  addi r8, r10, 2
	ctx.r[8].s64 = ctx.r[10].s64 + 2;
	// 8258E270: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258E274: 3BE70002  addi r31, r7, 2
	ctx.r[31].s64 = ctx.r[7].s64 + 2;
	// 8258E278: 3BA90001  addi r29, r9, 1
	ctx.r[29].s64 = ctx.r[9].s64 + 1;
	// 8258E27C: 39270003  addi r9, r7, 3
	ctx.r[9].s64 = ctx.r[7].s64 + 3;
	// 8258E280: 57BA103A  slwi r26, r29, 2
	ctx.r[26].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[26].u64 = ctx.r[26].u32 as u64;
	// 8258E284: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8258E288: 7F995050  subf r28, r25, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[25].s64;
	// 8258E28C: 7FC62214  add r30, r6, r4
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 8258E290: 7CDB5050  subf r6, r27, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[27].s64;
	// 8258E294: 57E9103A  slwi r9, r31, 2
	ctx.r[9].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258E298: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258E29C: 7D5A5214  add r10, r26, r10
	ctx.r[10].u64 = ctx.r[26].u64 + ctx.r[10].u64;
	// 8258E2A0: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258E2A4: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8258E2A8: 7F052050  subf r24, r5, r4
	ctx.r[24].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 8258E2AC: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 8258E2B0: 38C60002  addi r6, r6, 2
	ctx.r[6].s64 = ctx.r[6].s64 + 2;
	// 8258E2B4: 7F7BC850  subf r27, r27, r25
	ctx.r[27].s64 = ctx.r[25].s64 - ctx.r[27].s64;
	// 8258E2B8: 7F5A3A14  add r26, r26, r7
	ctx.r[26].u64 = ctx.r[26].u64 + ctx.r[7].u64;
	// 8258E2BC: 5787143A  rlwinm r7, r28, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E2C0: C17EFFF4  lfs f11, -0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E2C4: 7F3BE214  add r25, r27, r28
	ctx.r[25].u64 = ctx.r[27].u64 + ctx.r[28].u64;
	// 8258E2C8: C15EFFF8  lfs f10, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E2CC: 3A9FFFFF  addi r20, r31, -1
	ctx.r[20].s64 = ctx.r[31].s64 + -1;
	// 8258E2D0: 7D29C42E  lfsx f9, r9, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E2D4: 5739143A  rlwinm r25, r25, 2, 0x10, 0x1d
	ctx.r[25].u64 = ctx.r[25].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E2D8: C11E0000  lfs f8, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E2DC: 5694143A  rlwinm r20, r20, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E2E0: 7CE75C2E  lfsx f7, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258E2E4: 38E6FFFF  addi r7, r6, -1
	ctx.r[7].s64 = ctx.r[6].s64 + -1;
	// 8258E2E8: ECE70372  fmuls f7, f7, f13
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E2EC: 57F3143A  rlwinm r19, r31, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E2F0: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E2F4: 54E7143A  rlwinm r7, r7, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E2F8: 7CD95C2E  lfsx f6, r25, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E2FC: 54D9143A  rlwinm r25, r6, 2, 0x10, 0x1d
	ctx.r[25].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E300: D168FFF8  stfs f11, -8(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258E304: 3A460001  addi r18, r6, 1
	ctx.r[18].s64 = ctx.r[6].s64 + 1;
	// 8258E308: 7D745C2E  lfsx f11, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E30C: 3A9F0001  addi r20, r31, 1
	ctx.r[20].s64 = ctx.r[31].s64 + 1;
	// 8258E310: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8258E314: 7CA75C2E  lfsx f5, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258E318: 5687143A  rlwinm r7, r20, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E31C: D148FFFC  stfs f10, -4(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E320: 5654143A  rlwinm r20, r18, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[18].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E324: 7D535C2E  lfsx f10, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E328: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258E32C: 7C995C2E  lfsx f4, r25, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258E330: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 8258E334: ECE63B3A  fmadds f7, f6, f12, f7
	ctx.f[7].f64 = (((ctx.f[6].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258E338: D1280000  stfs f9, 0(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E33C: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E340: 7D275C2E  lfsx f9, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E344: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E348: 7CD45C2E  lfsx f6, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E34C: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E350: D0E9FFFC  stfs f7, -4(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E354: D1080004  stfs f8, 4(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E358: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258E35C: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 8258E360: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 8258E364: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8258E368: ED655B3A  fmadds f11, f5, f12, f11
	ctx.f[11].f64 = (((ctx.f[5].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258E36C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E370: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E374: ED6A0372  fmuls f11, f10, f13
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E378: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E37C: ED645B3A  fmadds f11, f4, f12, f11
	ctx.f[11].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258E380: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E384: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E388: ED690372  fmuls f11, f9, f13
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E38C: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E390: ED665B3A  fmadds f11, f6, f12, f11
	ctx.f[11].f64 = (((ctx.f[6].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258E394: D1690008  stfs f11, 8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258E398: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E39C: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 8258E3A0: 409AFF1C  bne cr6, 0x8258e2bc
	if !ctx.cr[6].eq {
	pc = 0x8258E2BC; continue 'dispatch;
	}
	// 8258E3A4: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E3A8: 2B1A0100  cmplwi cr6, r26, 0x100
	ctx.cr[6].compare_u32(ctx.r[26].u32, 256 as u32, &mut ctx.xer);
	// 8258E3AC: 40980088  bge cr6, 0x8258e434
	if !ctx.cr[6].lt {
	pc = 0x8258E434; continue 'dispatch;
	}
	// 8258E3B0: 5747103A  slwi r7, r26, 2
	ctx.r[7].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8258E3B4: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258E3B8: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258E3BC: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258E3C0: 7C672A14  add r3, r7, r5
	ctx.r[3].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 8258E3C4: C1970000  lfs f12, 0(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E3C8: 213A0100  subfic r9, r26, 0x100
	ctx.xer.ca = ctx.r[26].u32 <= 256 as u32;
	ctx.r[9].s64 = (256 as i64) - ctx.r[26].s64;
	// 8258E3CC: 7CC85A14  add r6, r8, r11
	ctx.r[6].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258E3D0: 7CE72214  add r7, r7, r4
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[4].u64;
	// 8258E3D4: 7D1F5050  subf r8, r31, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258E3D8: 38830004  addi r4, r3, 4
	ctx.r[4].s64 = ctx.r[3].s64 + 4;
	// 8258E3DC: 7C7EF850  subf r3, r30, r31
	ctx.r[3].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 8258E3E0: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8258E3E4: 551F143A  rlwinm r31, r8, 2, 0x10, 0x1d
	ctx.r[31].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E3E8: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E3EC: 7FC34214  add r30, r3, r8
	ctx.r[30].u64 = ctx.r[3].u64 + ctx.r[8].u64;
	// 8258E3F0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258E3F4: 57DE143A  rlwinm r30, r30, 2, 0x10, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E3F8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8258E3FC: 7D5F5C2E  lfsx f10, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E400: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8258E404: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E408: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258E40C: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258E410: 7D3E5C2E  lfsx f9, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E414: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E418: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258E41C: ED69533A  fmadds f11, f9, f12, f10
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E420: D1640000  stfs f11, 0(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E424: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E428: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258E42C: 409AFFB8  bne cr6, 0x8258e3e4
	if !ctx.cr[6].eq {
	pc = 0x8258E3E4; continue 'dispatch;
	}
	// 8258E430: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E434: 554B04BE  clrlwi r11, r10, 0x12
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x00003FFFu64;
	// 8258E438: C0050400  lfs f0, 0x400(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(1024 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E43C: D0150000  stfs f0, 0(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E440: 91760000  stw r11, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258E444: 554B04BE  clrlwi r11, r10, 0x12
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x00003FFFu64;
	// 8258E448: 91760000  stw r11, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258E44C: 4BFA6C90  b 0x825350dc
	sub_825350D0(ctx, base);
	return;
	// 8258E450: 3BEA0100  addi r31, r10, 0x100
	ctx.r[31].s64 = ctx.r[10].s64 + 256;
	// 8258E454: 2B1F4000  cmplwi cr6, r31, 0x4000
	ctx.cr[6].compare_u32(ctx.r[31].u32, 16384 as u32, &mut ctx.xer);
	// 8258E458: 40980140  bge cr6, 0x8258e598
	if !ctx.cr[6].lt {
	pc = 0x8258E598; continue 'dispatch;
	}
	// 8258E45C: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8258E460: 39670100  addi r11, r7, 0x100
	ctx.r[11].s64 = ctx.r[7].s64 + 256;
	// 8258E464: 2B0B4000  cmplwi cr6, r11, 0x4000
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16384 as u32, &mut ctx.xer);
	// 8258E468: 40980130  bge cr6, 0x8258e598
	if !ctx.cr[6].lt {
	pc = 0x8258E598; continue 'dispatch;
	}
	// 8258E46C: 7D695050  subf r11, r9, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 8258E470: 3BCB0100  addi r30, r11, 0x100
	ctx.r[30].s64 = ctx.r[11].s64 + 256;
	// 8258E474: 2B1E4000  cmplwi cr6, r30, 0x4000
	ctx.cr[6].compare_u32(ctx.r[30].u32, 16384 as u32, &mut ctx.xer);
	// 8258E478: 40980120  bge cr6, 0x8258e598
	if !ctx.cr[6].lt {
	pc = 0x8258E598; continue 'dispatch;
	}
	// 8258E47C: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8258E480: 41980118  blt cr6, 0x8258e598
	if ctx.cr[6].lt {
	pc = 0x8258E598; continue 'dispatch;
	}
	// 8258E484: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8258E488: 41980110  blt cr6, 0x8258e598
	if ctx.cr[6].lt {
	pc = 0x8258E598; continue 'dispatch;
	}
	// 8258E48C: 396A0008  addi r11, r10, 8
	ctx.r[11].s64 = ctx.r[10].s64 + 8;
	// 8258E490: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8258E494: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258E498: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8258E49C: 409A007C  bne cr6, 0x8258e518
	if !ctx.cr[6].eq {
	pc = 0x8258E518; continue 'dispatch;
	}
	// 8258E4A0: 550A103A  slwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258E4A4: 39250004  addi r9, r5, 4
	ctx.r[9].s64 = ctx.r[5].s64 + 4;
	// 8258E4A8: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 8258E4AC: 38E00041  li r7, 0x41
	ctx.r[7].s64 = 65;
	// 8258E4B0: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258E630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258E630 size=300
    let mut pc: u32 = 0x8258E630;
    'dispatch: loop {
        match pc {
            0x8258E630 => {
    //   block [0x8258E630..0x8258E75C)
	// 8258E630: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8258E634: C1230014  lfs f9, 0x14(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E638: C1830010  lfs f12, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E63C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8258E640: D1250000  stfs f9, 0(r5)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E644: 2F060004  cmpwi cr6, r6, 4
	ctx.cr[6].compare_i32(ctx.r[6].s32, 4, &mut ctx.xer);
	// 8258E648: 39650004  addi r11, r5, 4
	ctx.r[11].s64 = ctx.r[5].s64 + 4;
	// 8258E64C: C0EA1850  lfs f7, 0x1850(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(6224 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258E650: 419800B0  blt cr6, 0x8258e700
	if ctx.cr[6].lt {
	pc = 0x8258E700; continue 'dispatch;
	}
	// 8258E654: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E658: 54CAF0BE  srwi r10, r6, 2
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258E65C: ED470028  fsubs f10, f7, f0
	ctx.f[10].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E660: C1630018  lfs f11, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E664: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258E668: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258E66C: EDAB02B2  fmuls f13, f11, f10
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[10].f64) as f32) as f64);
	// 8258E670: C0C40000  lfs f6, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E674: FD006090  fmr f8, f12
	ctx.f[8].f64 = ctx.f[12].f64;
	// 8258E678: ECC60372  fmuls f6, f6, f13
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E67C: C0A40004  lfs f5, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258E680: ED200272  fmuls f9, f0, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8258E684: C0840008  lfs f4, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258E688: ECA502F2  fmuls f5, f5, f11
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258E68C: C064000C  lfs f3, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8258E690: EC8402F2  fmuls f4, f4, f11
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258E694: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8258E698: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 8258E69C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258E6A0: ED80333A  fmadds f12, f0, f12, f6
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258E6A4: ED2D4A3A  fmadds f9, f13, f8, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258E6A8: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E6AC: ECC302F2  fmuls f6, f3, f11
	ctx.f[6].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258E6B0: FD006090  fmr f8, f12
	ctx.f[8].f64 = ctx.f[12].f64;
	// 8258E6B4: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E6B8: ED8562BA  fmadds f12, f5, f10, f12
	ctx.f[12].f64 = (((ctx.f[5].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E6BC: ECA00272  fmuls f5, f0, f9
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8258E6C0: ED2D2A3A  fmadds f9, f13, f8, f5
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[5].f64) as f32) as f64);
	// 8258E6C4: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E6C8: FD006090  fmr f8, f12
	ctx.f[8].f64 = ctx.f[12].f64;
	// 8258E6CC: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E6D0: ECA00272  fmuls f5, f0, f9
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8258E6D4: ED8462BA  fmadds f12, f4, f10, f12
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E6D8: ED2D2A3A  fmadds f9, f13, f8, f5
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[5].f64) as f32) as f64);
	// 8258E6DC: D12B0008  stfs f9, 8(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258E6E0: FD006090  fmr f8, f12
	ctx.f[8].f64 = ctx.f[12].f64;
	// 8258E6E4: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E6E8: ED8662BA  fmadds f12, f6, f10, f12
	ctx.f[12].f64 = (((ctx.f[6].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E6EC: ECC00272  fmuls f6, f0, f9
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8258E6F0: ED2D323A  fmadds f9, f13, f8, f6
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258E6F4: D12B000C  stfs f9, 0xc(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258E6F8: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 8258E6FC: 409AFF74  bne cr6, 0x8258e670
	if !ctx.cr[6].eq {
	pc = 0x8258E670; continue 'dispatch;
	}
	// 8258E700: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8258E704: 4199004C  bgt cr6, 0x8258e750
	if ctx.cr[6].gt {
	pc = 0x8258E750; continue 'dispatch;
	}
	// 8258E708: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E70C: 7D493050  subf r10, r9, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[9].s64;
	// 8258E710: ED670028  fsubs f11, f7, f0
	ctx.f[11].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258E714: C1A30018  lfs f13, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258E718: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8258E71C: EDAB0372  fmuls f13, f11, f13
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E720: FD606090  fmr f11, f12
	ctx.f[11].f64 = ctx.f[12].f64;
	// 8258E724: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8258E728: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E72C: ED400272  fmuls f10, f0, f9
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8258E730: C1240000  lfs f9, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E734: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258E738: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8258E73C: ED8D627A  fmadds f12, f13, f9, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E740: ED2D52FA  fmadds f9, f13, f11, f10
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E744: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E748: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8258E74C: 409AFFD4  bne cr6, 0x8258e720
	if !ctx.cr[6].eq {
	pc = 0x8258E720; continue 'dispatch;
	}
	// 8258E750: D1830010  stfs f12, 0x10(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258E754: D1230014  stfs f9, 0x14(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258E758: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258E760(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258E760 size=204
    let mut pc: u32 = 0x8258E760;
    'dispatch: loop {
        match pc {
            0x8258E760 => {
    //   block [0x8258E760..0x8258E82C)
	// 8258E760: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258E764: 4BFA6951  bl 0x825350b4
	ctx.lr = 0x8258E768;
	sub_82535080(ctx, base);
	// 8258E768: 80E30024  lwz r7, 0x24(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 8258E76C: 3943002C  addi r10, r3, 0x2c
	ctx.r[10].s64 = ctx.r[3].s64 + 44;
	// 8258E770: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258E774: C1630008  lfs f11, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E778: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258E77C: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258E780: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258E784: C1430020  lfs f10, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E788: 7D7F3850  subf r11, r31, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 8258E78C: C0030010  lfs f0, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E790: 7FDEF850  subf r30, r30, r31
	ctx.r[30].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 8258E794: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258E798: C183001C  lfs f12, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E79C: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 8258E7A0: D1650000  stfs f11, 0(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E7A4: 7D085214  add r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 8258E7A8: D1460000  stfs f10, 0(r6)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E7AC: 7FFDF850  subf r31, r29, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[29].s64;
	// 8258E7B0: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258E7B4: 557D157A  rlwinm r29, r11, 2, 0x15, 0x1d
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E7B8: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E7BC: 7F9E5A14  add r28, r30, r11
	ctx.r[28].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8258E7C0: 7F7F5A14  add r27, r31, r11
	ctx.r[27].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258E7C4: 579C157A  rlwinm r28, r28, 2, 0x15, 0x1d
	ctx.r[28].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E7C8: 577B157A  rlwinm r27, r27, 2, 0x15, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E7CC: 7D5D542E  lfsx f10, r29, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E7D0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8258E7D4: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258E7D8: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258E7DC: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258E7E0: 7D3C542E  lfsx f9, r28, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E7E4: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258E7E8: 7D1B542E  lfsx f8, r27, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E7EC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258E7F0: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E7F4: ED680332  fmuls f11, f8, f12
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258E7F8: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E7FC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8258E800: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258E804: ED49503A  fmadds f10, f9, f0, f10
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E808: D1450000  stfs f10, 0(r5)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E80C: 409AFFA8  bne cr6, 0x8258e7b4
	if !ctx.cr[6].eq {
	pc = 0x8258E7B4; continue 'dispatch;
	}
	// 8258E810: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 8258E814: FC005090  fmr f0, f10
	ctx.f[0].f64 = ctx.f[10].f64;
	// 8258E818: FDA05890  fmr f13, f11
	ctx.f[13].f64 = ctx.f[11].f64;
	// 8258E81C: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258E820: D1A30020  stfs f13, 0x20(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8258E824: 91630024  stw r11, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8258E828: 4BFA68DC  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258E830(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258E830 size=644
    let mut pc: u32 = 0x8258E830;
    'dispatch: loop {
        match pc {
            0x8258E830 => {
    //   block [0x8258E830..0x8258EAB4)
	// 8258E830: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258E834: 4BFA6889  bl 0x825350bc
	ctx.lr = 0x8258E838;
	sub_82535080(ctx, base);
	// 8258E838: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258E83C: 39630018  addi r11, r3, 0x18
	ctx.r[11].s64 = ctx.r[3].s64 + 24;
	// 8258E840: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258E844: C183000C  lfs f12, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E848: 392A0002  addi r9, r10, 2
	ctx.r[9].s64 = ctx.r[10].s64 + 2;
	// 8258E84C: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258E850: 7D465050  subf r10, r6, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[6].s64;
	// 8258E854: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258E858: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258E85C: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 8258E860: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8258E864: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 8258E868: 38EAFFFE  addi r7, r10, -2
	ctx.r[7].s64 = ctx.r[10].s64 + -2;
	// 8258E86C: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E870: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E874: 38AAFFFF  addi r5, r10, -1
	ctx.r[5].s64 = ctx.r[10].s64 + -1;
	// 8258E878: 54E715FA  rlwinm r7, r7, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E87C: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E880: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E884: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E888: 555F15FA  rlwinm r31, r10, 2, 0x17, 0x1d
	ctx.r[31].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E88C: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E890: 3BCA0002  addi r30, r10, 2
	ctx.r[30].s64 = ctx.r[10].s64 + 2;
	// 8258E894: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258E898: 3BAA0003  addi r29, r10, 3
	ctx.r[29].s64 = ctx.r[10].s64 + 3;
	// 8258E89C: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E8A0: 7D875C2E  lfsx f12, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E8A4: 38EA0001  addi r7, r10, 1
	ctx.r[7].s64 = ctx.r[10].s64 + 1;
	// 8258E8A8: ED605B3A  fmadds f11, f0, f12, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258E8AC: D169FFF8  stfs f11, -8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258E8B0: 54E715FA  rlwinm r7, r7, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E8B4: 57DE15FA  rlwinm r30, r30, 2, 0x17, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E8B8: 57BD15FA  rlwinm r29, r29, 2, 0x17, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E8BC: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258E8C0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258E8C4: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E8C8: 7D855C2E  lfsx f12, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E8CC: D1640004  stfs f11, 4(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E8D0: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E8D4: D169FFFC  stfs f11, -4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E8D8: 38AA0005  addi r5, r10, 5
	ctx.r[5].s64 = ctx.r[10].s64 + 5;
	// 8258E8DC: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E8E0: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E8E4: 7D9F5C2E  lfsx f12, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E8E8: D1640008  stfs f11, 8(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258E8EC: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258E8F0: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E8F4: C1240018  lfs f9, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E8F8: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E8FC: 7D875C2E  lfsx f12, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E900: D164000C  stfs f11, 0xc(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258E904: ED60433A  fmadds f11, f0, f12, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258E908: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E90C: 38EA0004  addi r7, r10, 4
	ctx.r[7].s64 = ctx.r[10].s64 + 4;
	// 8258E910: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8258E914: 54E715FA  rlwinm r7, r7, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E918: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E91C: 7D9E5C2E  lfsx f12, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E920: D1640010  stfs f11, 0x10(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258E924: ED603B3A  fmadds f11, f0, f12, f7
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258E928: D1690008  stfs f11, 8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258E92C: ED4D62FA  fmadds f10, f13, f11, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E930: 7D9D5C2E  lfsx f12, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E934: ED60333A  fmadds f11, f0, f12, f6
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258E938: D169000C  stfs f11, 0xc(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258E93C: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258E940: C144001C  lfs f10, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E944: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E948: 7D875C2E  lfsx f12, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E94C: D1640018  stfs f11, 0x18(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8258E950: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258E954: D1690010  stfs f11, 0x10(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258E958: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E95C: 7D855C2E  lfsx f12, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E960: D164001C  stfs f11, 0x1c(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8258E964: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E968: D1690014  stfs f11, 0x14(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258E96C: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 8258E970: 39290020  addi r9, r9, 0x20
	ctx.r[9].s64 = ctx.r[9].s64 + 32;
	// 8258E974: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258E978: 409AFEF0  bne cr6, 0x8258e868
	if !ctx.cr[6].eq {
	pc = 0x8258E868; continue 'dispatch;
	}
	// 8258E97C: 7CE600D0  neg r7, r6
	ctx.r[7].s64 = -ctx.r[6].s64;
	// 8258E980: 21260002  subfic r9, r6, 2
	ctx.xer.ca = ctx.r[6].u32 <= 2 as u32;
	ctx.r[9].s64 = (2 as i64) - ctx.r[6].s64;
	// 8258E984: 394B0008  addi r10, r11, 8
	ctx.r[10].s64 = ctx.r[11].s64 + 8;
	// 8258E988: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 8258E98C: 54E615FA  rlwinm r6, r7, 2, 0x17, 0x1d
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E990: C1440000  lfs f10, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258E994: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258E998: 38A9FFFF  addi r5, r9, -1
	ctx.r[5].s64 = ctx.r[9].s64 + -1;
	// 8258E99C: C1240004  lfs f9, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258E9A0: 3BE90001  addi r31, r9, 1
	ctx.r[31].s64 = ctx.r[9].s64 + 1;
	// 8258E9A4: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E9A8: C1040008  lfs f8, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258E9AC: 57FF15FA  rlwinm r31, r31, 2, 0x17, 0x1d
	ctx.r[31].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E9B0: C0E4000C  lfs f7, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258E9B4: 7D665C2E  lfsx f11, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258E9B8: 552615FA  rlwinm r6, r9, 2, 0x17, 0x1d
	ctx.r[6].u64 = ctx.r[9].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E9BC: ED8052FA  fmadds f12, f0, f11, f10
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258E9C0: D18AFFF8  stfs f12, -8(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258E9C4: 3BC90002  addi r30, r9, 2
	ctx.r[30].s64 = ctx.r[9].s64 + 2;
	// 8258E9C8: C0C40010  lfs f6, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258E9CC: 3BA90003  addi r29, r9, 3
	ctx.r[29].s64 = ctx.r[9].s64 + 3;
	// 8258E9D0: C0A40014  lfs f5, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258E9D4: 57DE15FA  rlwinm r30, r30, 2, 0x17, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E9D8: 57BD15FA  rlwinm r29, r29, 2, 0x17, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258E9DC: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258E9E0: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 8258E9E4: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258E9E8: ED6D5B3A  fmadds f11, f13, f12, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258E9EC: 7D855C2E  lfsx f12, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258E9F0: D1640004  stfs f11, 4(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258E9F4: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258E9F8: D16AFFFC  stfs f11, -4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258E9FC: 38A90005  addi r5, r9, 5
	ctx.r[5].s64 = ctx.r[9].s64 + 5;
	// 8258EA00: C124001C  lfs f9, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EA04: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EA08: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA0C: 7D865C2E  lfsx f12, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA10: D1640008  stfs f11, 8(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EA14: ED60433A  fmadds f11, f0, f12, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258EA18: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EA1C: 38C90004  addi r6, r9, 4
	ctx.r[6].s64 = ctx.r[9].s64 + 4;
	// 8258EA20: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 8258EA24: 54C615FA  rlwinm r6, r6, 2, 0x17, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EA28: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA2C: 7D9F5C2E  lfsx f12, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA30: D164000C  stfs f11, 0xc(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EA34: ED603B3A  fmadds f11, f0, f12, f7
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258EA38: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EA3C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA40: 7D9E5C2E  lfsx f12, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA44: D1640010  stfs f11, 0x10(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EA48: ED60333A  fmadds f11, f0, f12, f6
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258EA4C: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EA50: ED4D62FA  fmadds f10, f13, f11, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA54: 7D9D5C2E  lfsx f12, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA58: ED602B3A  fmadds f11, f0, f12, f5
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 8258EA5C: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EA60: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EA64: C1440018  lfs f10, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EA68: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA6C: 7D865C2E  lfsx f12, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA70: D1640018  stfs f11, 0x18(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8258EA74: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EA78: D16A0010  stfs f11, 0x10(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EA7C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA80: 7D855C2E  lfsx f12, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EA84: D164001C  stfs f11, 0x1c(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8258EA88: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EA8C: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EA90: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 8258EA94: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 8258EA98: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EA9C: 409AFEF0  bne cr6, 0x8258e98c
	if !ctx.cr[6].eq {
	pc = 0x8258E98C; continue 'dispatch;
	}
	// 8258EAA0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258EAA4: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EAA8: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EAAC: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258EAB0: 4BFA665C  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258EAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258EAB8 size=204
    let mut pc: u32 = 0x8258EAB8;
    'dispatch: loop {
        match pc {
            0x8258EAB8 => {
    //   block [0x8258EAB8..0x8258EB84)
	// 8258EAB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258EABC: 4BFA65F9  bl 0x825350b4
	ctx.lr = 0x8258EAC0;
	sub_82535080(ctx, base);
	// 8258EAC0: 80E30024  lwz r7, 0x24(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 8258EAC4: 3943002C  addi r10, r3, 0x2c
	ctx.r[10].s64 = ctx.r[3].s64 + 44;
	// 8258EAC8: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258EACC: C1630008  lfs f11, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258EAD0: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258EAD4: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258EAD8: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258EADC: C1430020  lfs f10, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EAE0: 7D7F3850  subf r11, r31, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 8258EAE4: C0030010  lfs f0, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258EAE8: 7FDEF850  subf r30, r30, r31
	ctx.r[30].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 8258EAEC: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258EAF0: C183001C  lfs f12, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EAF4: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 8258EAF8: D1650000  stfs f11, 0(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EAFC: 7D085214  add r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 8258EB00: D1460000  stfs f10, 0(r6)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EB04: 7FFDF850  subf r31, r29, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[29].s64;
	// 8258EB08: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258EB0C: 557D14FA  rlwinm r29, r11, 2, 0x13, 0x1d
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EB10: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258EB14: 7F9E5A14  add r28, r30, r11
	ctx.r[28].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8258EB18: 7F7F5A14  add r27, r31, r11
	ctx.r[27].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258EB1C: 579C14FA  rlwinm r28, r28, 2, 0x13, 0x1d
	ctx.r[28].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EB20: 577B14FA  rlwinm r27, r27, 2, 0x13, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EB24: 7D5D542E  lfsx f10, r29, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EB28: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8258EB2C: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258EB30: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258EB34: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258EB38: 7D3C542E  lfsx f9, r28, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EB3C: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258EB40: 7D1B542E  lfsx f8, r27, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258EB44: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258EB48: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EB4C: ED680332  fmuls f11, f8, f12
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258EB50: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EB54: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8258EB58: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258EB5C: ED49503A  fmadds f10, f9, f0, f10
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EB60: D1450000  stfs f10, 0(r5)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EB64: 409AFFA8  bne cr6, 0x8258eb0c
	if !ctx.cr[6].eq {
	pc = 0x8258EB0C; continue 'dispatch;
	}
	// 8258EB68: 54EB057E  clrlwi r11, r7, 0x15
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000007FFu64;
	// 8258EB6C: FC005090  fmr f0, f10
	ctx.f[0].f64 = ctx.f[10].f64;
	// 8258EB70: FDA05890  fmr f13, f11
	ctx.f[13].f64 = ctx.f[11].f64;
	// 8258EB74: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EB78: D1A30020  stfs f13, 0x20(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 8258EB7C: 91630024  stw r11, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8258EB80: 4BFA6584  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258EB88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258EB88 size=356
    let mut pc: u32 = 0x8258EB88;
    'dispatch: loop {
        match pc {
            0x8258EB88 => {
    //   block [0x8258EB88..0x8258ECEC)
	// 8258EB88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258EB8C: 4BFA6531  bl 0x825350bc
	ctx.lr = 0x8258EB90;
	sub_82535080(ctx, base);
	// 8258EB90: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258EB94: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 8258EB98: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258EB9C: C183000C  lfs f12, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EBA0: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 8258EBA4: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258EBA8: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8258EBAC: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258EBB0: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258EBB4: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 8258EBB8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8258EBBC: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8258EBC0: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258EBC4: 38CBFFFE  addi r6, r11, -2
	ctx.r[6].s64 = ctx.r[11].s64 + -2;
	// 8258EBC8: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258EBCC: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EBD0: 38ABFFFF  addi r5, r11, -1
	ctx.r[5].s64 = ctx.r[11].s64 + -1;
	// 8258EBD4: 54C615BA  rlwinm r6, r6, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EBD8: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EBDC: 54A515BA  rlwinm r5, r5, 2, 0x16, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EBE0: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EBE4: 557F15BA  rlwinm r31, r11, 2, 0x16, 0x1d
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EBE8: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258EBEC: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 8258EBF0: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258EBF4: 3BAB0003  addi r29, r11, 3
	ctx.r[29].s64 = ctx.r[11].s64 + 3;
	// 8258EBF8: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258EBFC: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC00: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 8258EC04: ED605B3A  fmadds f11, f0, f12, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258EC08: D16AFFF8  stfs f11, -8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258EC0C: 54C615BA  rlwinm r6, r6, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EC10: 57DE15BA  rlwinm r30, r30, 2, 0x16, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EC14: 57BD15BA  rlwinm r29, r29, 2, 0x16, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EC18: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258EC1C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258EC20: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EC24: 7D854C2E  lfsx f12, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC28: D1640004  stfs f11, 4(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EC2C: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EC30: D16AFFFC  stfs f11, -4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258EC34: 38AB0005  addi r5, r11, 5
	ctx.r[5].s64 = ctx.r[11].s64 + 5;
	// 8258EC38: 54A515BA  rlwinm r5, r5, 2, 0x16, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EC3C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EC40: 7D9F4C2E  lfsx f12, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC44: D1640008  stfs f11, 8(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EC48: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EC4C: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EC50: C1240018  lfs f9, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EC54: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EC58: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC5C: D164000C  stfs f11, 0xc(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EC60: ED60433A  fmadds f11, f0, f12, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258EC64: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EC68: 38CB0004  addi r6, r11, 4
	ctx.r[6].s64 = ctx.r[11].s64 + 4;
	// 8258EC6C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258EC70: 54C615BA  rlwinm r6, r6, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EC74: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EC78: 7D9E4C2E  lfsx f12, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC7C: D1640010  stfs f11, 0x10(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EC80: ED603B3A  fmadds f11, f0, f12, f7
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258EC84: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EC88: ED4D62FA  fmadds f10, f13, f11, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EC8C: 7D9D4C2E  lfsx f12, r29, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EC90: ED60333A  fmadds f11, f0, f12, f6
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258EC94: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EC98: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EC9C: C144001C  lfs f10, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258ECA0: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258ECA4: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258ECA8: D1640018  stfs f11, 0x18(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8258ECAC: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258ECB0: D16A0010  stfs f11, 0x10(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258ECB4: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258ECB8: 7D854C2E  lfsx f12, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258ECBC: D164001C  stfs f11, 0x1c(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8258ECC0: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258ECC4: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258ECC8: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 8258ECCC: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 8258ECD0: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258ECD4: 409AFEF0  bne cr6, 0x8258ebc4
	if !ctx.cr[6].eq {
	pc = 0x8258EBC4; continue 'dispatch;
	}
	// 8258ECD8: 54EB063E  clrlwi r11, r7, 0x18
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8258ECDC: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258ECE0: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258ECE4: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258ECE8: 4BFA6424  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258ECF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258ECF0 size=356
    let mut pc: u32 = 0x8258ECF0;
    'dispatch: loop {
        match pc {
            0x8258ECF0 => {
    //   block [0x8258ECF0..0x8258EE54)
	// 8258ECF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258ECF4: 4BFA63C9  bl 0x825350bc
	ctx.lr = 0x8258ECF8;
	sub_82535080(ctx, base);
	// 8258ECF8: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258ECFC: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 8258ED00: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258ED04: C183000C  lfs f12, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258ED08: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 8258ED0C: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258ED10: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8258ED14: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258ED18: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258ED1C: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 8258ED20: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8258ED24: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8258ED28: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258ED2C: 38CBFFFE  addi r6, r11, -2
	ctx.r[6].s64 = ctx.r[11].s64 + -2;
	// 8258ED30: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258ED34: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258ED38: 38ABFFFF  addi r5, r11, -1
	ctx.r[5].s64 = ctx.r[11].s64 + -1;
	// 8258ED3C: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED40: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258ED44: 54A5157A  rlwinm r5, r5, 2, 0x15, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED48: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258ED4C: 557F157A  rlwinm r31, r11, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED50: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258ED54: 3BCB0002  addi r30, r11, 2
	ctx.r[30].s64 = ctx.r[11].s64 + 2;
	// 8258ED58: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258ED5C: 3BAB0003  addi r29, r11, 3
	ctx.r[29].s64 = ctx.r[11].s64 + 3;
	// 8258ED60: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258ED64: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258ED68: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 8258ED6C: ED605B3A  fmadds f11, f0, f12, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258ED70: D16AFFF8  stfs f11, -8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258ED74: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED78: 57DE157A  rlwinm r30, r30, 2, 0x15, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED7C: 57BD157A  rlwinm r29, r29, 2, 0x15, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258ED80: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258ED84: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258ED88: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258ED8C: 7D854C2E  lfsx f12, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258ED90: D1640004  stfs f11, 4(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258ED94: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258ED98: D16AFFFC  stfs f11, -4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258ED9C: 38AB0005  addi r5, r11, 5
	ctx.r[5].s64 = ctx.r[11].s64 + 5;
	// 8258EDA0: 54A5157A  rlwinm r5, r5, 2, 0x15, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EDA4: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EDA8: 7D9F4C2E  lfsx f12, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EDAC: D1640008  stfs f11, 8(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EDB0: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EDB4: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EDB8: C1240018  lfs f9, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EDBC: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EDC0: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EDC4: D164000C  stfs f11, 0xc(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EDC8: ED60433A  fmadds f11, f0, f12, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258EDCC: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EDD0: 38CB0004  addi r6, r11, 4
	ctx.r[6].s64 = ctx.r[11].s64 + 4;
	// 8258EDD4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258EDD8: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EDDC: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EDE0: 7D9E4C2E  lfsx f12, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EDE4: D1640010  stfs f11, 0x10(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EDE8: ED603B3A  fmadds f11, f0, f12, f7
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258EDEC: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EDF0: ED4D62FA  fmadds f10, f13, f11, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EDF4: 7D9D4C2E  lfsx f12, r29, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EDF8: ED60333A  fmadds f11, f0, f12, f6
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258EDFC: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EE00: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EE04: C144001C  lfs f10, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EE08: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EE0C: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EE10: D1640018  stfs f11, 0x18(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8258EE14: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EE18: D16A0010  stfs f11, 0x10(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EE1C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EE20: 7D854C2E  lfsx f12, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EE24: D164001C  stfs f11, 0x1c(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8258EE28: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EE2C: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EE30: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 8258EE34: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 8258EE38: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EE3C: 409AFEF0  bne cr6, 0x8258ed2c
	if !ctx.cr[6].eq {
	pc = 0x8258ED2C; continue 'dispatch;
	}
	// 8258EE40: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 8258EE44: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EE48: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EE4C: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258EE50: 4BFA62BC  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258EE58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258EE58 size=360
    let mut pc: u32 = 0x8258EE58;
    'dispatch: loop {
        match pc {
            0x8258EE58 => {
    //   block [0x8258EE58..0x8258EFC0)
	// 8258EE58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258EE5C: 4BFA625D  bl 0x825350b8
	ctx.lr = 0x8258EE60;
	sub_82535080(ctx, base);
	// 8258EE60: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258EE64: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 8258EE68: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258EE6C: C183000C  lfs f12, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EE70: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 8258EE74: C0030008  lfs f0, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258EE78: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8258EE7C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258EE80: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8258EE84: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 8258EE88: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8258EE8C: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8258EE90: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258EE94: 38CBFFFE  addi r6, r11, -2
	ctx.r[6].s64 = ctx.r[11].s64 + -2;
	// 8258EE98: D1850000  stfs f12, 0(r5)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EE9C: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258EEA0: 3BEBFFFF  addi r31, r11, -1
	ctx.r[31].s64 = ctx.r[11].s64 + -1;
	// 8258EEA4: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEA8: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EEAC: 57FF157A  rlwinm r31, r31, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEB0: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EEB4: 557E157A  rlwinm r30, r11, 2, 0x15, 0x1d
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEB8: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258EEBC: 3BAB0002  addi r29, r11, 2
	ctx.r[29].s64 = ctx.r[11].s64 + 2;
	// 8258EEC0: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258EEC4: 3B8B0003  addi r28, r11, 3
	ctx.r[28].s64 = ctx.r[11].s64 + 3;
	// 8258EEC8: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258EECC: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EED0: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 8258EED4: ED605B3A  fmadds f11, f0, f12, f11
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258EED8: D16AFFF8  stfs f11, -8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258EEDC: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEE0: 57BD157A  rlwinm r29, r29, 2, 0x15, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEE4: 579C157A  rlwinm r28, r28, 2, 0x15, 0x1d
	ctx.r[28].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EEE8: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258EEEC: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258EEF0: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EEF4: 7D9F4C2E  lfsx f12, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EEF8: D1650004  stfs f11, 4(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EEFC: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EF00: D16AFFFC  stfs f11, -4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258EF04: 3BEB0005  addi r31, r11, 5
	ctx.r[31].s64 = ctx.r[11].s64 + 5;
	// 8258EF08: C1440018  lfs f10, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258EF0C: 57FF157A  rlwinm r31, r31, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EF10: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF14: 7D9E4C2E  lfsx f12, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF18: D1650008  stfs f11, 8(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EF1C: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EF20: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EF24: C124001C  lfs f9, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258EF28: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 8258EF2C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF30: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF34: D165000C  stfs f11, 0xc(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EF38: ED60433A  fmadds f11, f0, f12, f8
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258EF3C: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258EF40: 38CB0004  addi r6, r11, 4
	ctx.r[6].s64 = ctx.r[11].s64 + 4;
	// 8258EF44: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8258EF48: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258EF4C: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF50: 7D9D4C2E  lfsx f12, r29, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF54: D1650010  stfs f11, 0x10(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EF58: ED603B3A  fmadds f11, f0, f12, f7
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258EF5C: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258EF60: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF64: 7D9C4C2E  lfsx f12, r28, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF68: D1650014  stfs f11, 0x14(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EF6C: ED60333A  fmadds f11, f0, f12, f6
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258EF70: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EF74: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF78: 7D864C2E  lfsx f12, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF7C: D1650018  stfs f11, 0x18(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8258EF80: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258EF84: D16A0010  stfs f11, 0x10(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8258EF88: ED6D62FA  fmadds f11, f13, f11, f12
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EF8C: 7D9F4C2E  lfsx f12, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EF90: D165001C  stfs f11, 0x1c(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 8258EF94: ED604B3A  fmadds f11, f0, f12, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258EF98: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258EF9C: 38A50020  addi r5, r5, 0x20
	ctx.r[5].s64 = ctx.r[5].s64 + 32;
	// 8258EFA0: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 8258EFA4: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 8258EFA8: 409AFEEC  bne cr6, 0x8258ee94
	if !ctx.cr[6].eq {
	pc = 0x8258EE94; continue 'dispatch;
	}
	// 8258EFAC: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 8258EFB0: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8258EFB4: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EFB8: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8258EFBC: 4BFA614C  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258EFC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258EFC0 size=168
    let mut pc: u32 = 0x8258EFC0;
    'dispatch: loop {
        match pc {
            0x8258EFC0 => {
    //   block [0x8258EFC0..0x8258F068)
	// 8258EFC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258EFC4: 4BFA60F9  bl 0x825350bc
	ctx.lr = 0x8258EFC8;
	sub_82535080(ctx, base);
	// 8258EFC8: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258EFCC: 3BE30020  addi r31, r3, 0x20
	ctx.r[31].s64 = ctx.r[3].s64 + 32;
	// 8258EFD0: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258EFD4: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258EFD8: 83C30000  lwz r30, 0(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258EFDC: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258EFE0: 7D2A3850  subf r9, r10, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8258EFE4: C1A30014  lfs f13, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258EFE8: 7D5E3850  subf r10, r30, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[30].s64;
	// 8258EFEC: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258EFF0: C1630010  lfs f11, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258EFF4: 39600100  li r11, 0x100
	ctx.r[11].s64 = 256;
	// 8258EFF8: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258EFFC: 7D08FA14  add r8, r8, r31
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 8258F000: D1A60000  stfs f13, 0(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F004: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 8258F008: 555E153A  rlwinm r30, r10, 2, 0x14, 0x1d
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F00C: C1440000  lfs f10, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F010: 553D153A  rlwinm r29, r9, 2, 0x14, 0x1d
	ctx.r[29].u64 = ctx.r[9].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F014: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8258F018: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F01C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8258F020: 7C1EFC2E  lfsx f0, r30, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F024: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258F028: 7DBDFC2E  lfsx f13, r29, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258F02C: EC000332  fmuls f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258F030: D1480000  stfs f10, 0(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F034: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258F038: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F03C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8258F040: D1A60000  stfs f13, 0(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F044: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258F048: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8258F04C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8258F050: 409AFFB8  bne cr6, 0x8258f008
	if !ctx.cr[6].eq {
	pc = 0x8258F008; continue 'dispatch;
	}
	// 8258F054: 54EB05BE  clrlwi r11, r7, 0x16
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000003FFu64;
	// 8258F058: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258F05C: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258F060: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8258F064: 4BFA60A8  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258F068(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8258F068 size=1280
    let mut pc: u32 = 0x8258F068;
    'dispatch: loop {
        match pc {
            0x8258F068 => {
    //   block [0x8258F068..0x8258F568)
	// 8258F068: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258F06C: 4BFA602D  bl 0x82535098
	ctx.lr = 0x8258F070;
	sub_82535080(ctx, base);
	// 8258F070: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8258F074: C0030014  lfs f0, 0x14(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F078: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F07C: 3921FF90  addi r9, r1, -0x70
	ctx.r[9].s64 = ctx.r[1].s64 + -112;
	// 8258F080: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F084: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8258F088: C00B2208  lfs f0, 0x2208(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8712 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F08C: EC0C0032  fmuls f0, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258F090: FC00065E  fctidz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 8258F094: 7C004FAE  stfiwx f0, 0, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32, tmp.u32) };
	// 8258F098: 8161FF90  lwz r11, -0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-112 as u32) ) } as u64;
	// 8258F09C: 5567F87E  srwi r7, r11, 1
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shr(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8258F0A0: 2B070100  cmplwi cr6, r7, 0x100
	ctx.cr[6].compare_u32(ctx.r[7].u32, 256 as u32, &mut ctx.xer);
	// 8258F0A4: 40980414  bge cr6, 0x8258f4b8
	if !ctx.cr[6].lt {
	pc = 0x8258F4B8; continue 'dispatch;
	}
	// 8258F0A8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8258F0AC: 3D208209  lis r9, -0x7df7
	ctx.r[9].s64 = -2113339392;
	// 8258F0B0: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 8258F0B4: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 8258F0B8: C16B1850  lfs f11, 0x1850(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(6224 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F0BC: 39630020  addi r11, r3, 0x20
	ctx.r[11].s64 = ctx.r[3].s64 + 32;
	// 8258F0C0: C00968E8  lfs f0, 0x68e8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(26856 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F0C4: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258F0C8: 41980134  blt cr6, 0x8258f1fc
	if ctx.cr[6].lt {
	pc = 0x8258F1FC; continue 'dispatch;
	}
	// 8258F0CC: 54FDF0BE  srwi r29, r7, 2
	ctx.r[29].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 8258F0D0: 80C30008  lwz r6, 8(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258F0D4: 83E3000C  lwz r31, 0xc(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F0D8: 392A0002  addi r9, r10, 2
	ctx.r[9].s64 = ctx.r[10].s64 + 2;
	// 8258F0DC: 57BB103A  slwi r27, r29, 2
	ctx.r[27].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 8258F0E0: 7F865050  subf r28, r6, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[6].s64;
	// 8258F0E4: 7F5F5050  subf r26, r31, r10
	ctx.r[26].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258F0E8: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258F0EC: 7F1F3050  subf r24, r31, r6
	ctx.r[24].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 8258F0F0: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 8258F0F4: 3BC40008  addi r30, r4, 8
	ctx.r[30].s64 = ctx.r[4].s64 + 8;
	// 8258F0F8: 3925000C  addi r9, r5, 0xc
	ctx.r[9].s64 = ctx.r[5].s64 + 12;
	// 8258F0FC: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258F100: 7F252050  subf r25, r5, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 8258F104: 38DA0002  addi r6, r26, 2
	ctx.r[6].s64 = ctx.r[26].s64 + 2;
	// 8258F108: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 8258F10C: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 8258F110: 579A15BA  rlwinm r26, r28, 2, 0x16, 0x1d
	ctx.r[26].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F114: C15EFFF8  lfs f10, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F118: 7EFCC214  add r23, r28, r24
	ctx.r[23].u64 = ctx.r[28].u64 + ctx.r[24].u64;
	// 8258F11C: C13EFFFC  lfs f9, -4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F120: 3AC6FFFF  addi r22, r6, -1
	ctx.r[22].s64 = ctx.r[6].s64 + -1;
	// 8258F124: C11E0000  lfs f8, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258F128: 56F715BA  rlwinm r23, r23, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F12C: 7CF94C2E  lfsx f7, r25, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258F130: 56D615BA  rlwinm r22, r22, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[22].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F134: 7CDA5C2E  lfsx f6, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258F138: 3B5FFFFF  addi r26, r31, -1
	ctx.r[26].s64 = ctx.r[31].s64 + -1;
	// 8258F13C: ECC60372  fmuls f6, f6, f13
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F140: 54D515BA  rlwinm r21, r6, 2, 0x16, 0x1d
	ctx.r[21].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F144: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F148: 575A15BA  rlwinm r26, r26, 2, 0x16, 0x1d
	ctx.r[26].u64 = ctx.r[26].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F14C: 7CB75C2E  lfsx f5, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258F150: 57F715BA  rlwinm r23, r31, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F154: D148FFF8  stfs f10, -8(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258F158: 3A9F0001  addi r20, r31, 1
	ctx.r[20].s64 = ctx.r[31].s64 + 1;
	// 8258F15C: 7D565C2E  lfsx f10, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F160: 3AC60001  addi r22, r6, 1
	ctx.r[22].s64 = ctx.r[6].s64 + 1;
	// 8258F164: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8258F168: 7C9A5C2E  lfsx f4, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258F16C: 56DA15BA  rlwinm r26, r22, 2, 0x16, 0x1d
	ctx.r[26].u64 = ctx.r[22].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F170: D128FFFC  stfs f9, -4(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258F174: 569615BA  rlwinm r22, r20, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F178: 7D355C2E  lfsx f9, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F17C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F180: 7C775C2E  lfsx f3, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8258F184: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 8258F188: ECC5333A  fmadds f6, f5, f12, f6
	ctx.f[6].f64 = (((ctx.f[5].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258F18C: D1080000  stfs f8, 0(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F190: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F194: 7D1A5C2E  lfsx f8, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258F198: 7CB65C2E  lfsx f5, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258F19C: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258F1A0: D0C9FFF8  stfs f6, -8(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258F1A4: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 8258F1A8: D0E80004  stfs f7, 4(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F1AC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8258F1B0: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 8258F1B4: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258F1B8: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F1BC: ED44537A  fmadds f10, f4, f13, f10
	ctx.f[10].f64 = (((ctx.f[4].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258F1C0: D149FFFC  stfs f10, -4(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258F1C4: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F1C8: ED490332  fmuls f10, f9, f12
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258F1CC: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F1D0: ED43537A  fmadds f10, f3, f13, f10
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258F1D4: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F1D8: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F1DC: ED480332  fmuls f10, f8, f12
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258F1E0: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F1E4: ED45537A  fmadds f10, f5, f13, f10
	ctx.f[10].f64 = (((ctx.f[5].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258F1E8: D1490004  stfs f10, 4(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F1EC: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F1F0: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 8258F1F4: 409AFF1C  bne cr6, 0x8258f110
	if !ctx.cr[6].eq {
	pc = 0x8258F110; continue 'dispatch;
	}
	// 8258F1F8: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F1FC: 7F1B3840  cmplw cr6, r27, r7
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8258F200: 4199008C  bgt cr6, 0x8258f28c
	if ctx.cr[6].gt {
	pc = 0x8258F28C; continue 'dispatch;
	}
	// 8258F204: 5766103A  slwi r6, r27, 2
	ctx.r[6].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8258F208: 83A30008  lwz r29, 8(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258F20C: 7D3B3850  subf r9, r27, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[27].s64;
	// 8258F210: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F214: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258F218: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F21C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8258F220: 7F862214  add r28, r6, r4
	ctx.r[28].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 8258F224: 7FE85A14  add r31, r8, r11
	ctx.r[31].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258F228: 7D1D5050  subf r8, r29, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[29].s64;
	// 8258F22C: 7FC62A14  add r30, r6, r5
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8258F230: 38DCFFFC  addi r6, r28, -4
	ctx.r[6].s64 = ctx.r[28].s64 + -4;
	// 8258F234: 7FBBE850  subf r29, r27, r29
	ctx.r[29].s64 = ctx.r[29].s64 - ctx.r[27].s64;
	// 8258F238: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8258F23C: 551C15BA  rlwinm r28, r8, 2, 0x16, 0x1d
	ctx.r[28].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F240: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F244: 7F7D4214  add r27, r29, r8
	ctx.r[27].u64 = ctx.r[29].u64 + ctx.r[8].u64;
	// 8258F248: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258F24C: 577B15BA  rlwinm r27, r27, 2, 0x16, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F250: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8258F254: 7D3C5C2E  lfsx f9, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F258: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F25C: ED290372  fmuls f9, f9, f13
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F260: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258F264: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F268: 7D1B5C2E  lfsx f8, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258F26C: D15F0000  stfs f10, 0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F270: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258F274: ED484B3A  fmadds f10, f8, f12, f9
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258F278: D15E0000  stfs f10, 0(r30)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F27C: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F280: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 8258F284: 409AFFB8  bne cr6, 0x8258f23c
	if !ctx.cr[6].eq {
	pc = 0x8258F23C; continue 'dispatch;
	}
	// 8258F288: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F28C: 83230010  lwz r25, 0x10(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258F290: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258F294: 7F194840  cmplw cr6, r25, r9
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8258F298: 419A000C  beq cr6, 0x8258f2a4
	if ctx.cr[6].eq {
	pc = 0x8258F2A4; continue 'dispatch;
	}
	// 8258F29C: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 8258F2A0: 4800000C  b 0x8258f2ac
	pc = 0x8258F2AC; continue 'dispatch;
	// 8258F2A4: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8258F2A8: C1881FF8  lfs f12, 0x1ff8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8184 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F2AC: 21070100  subfic r8, r7, 0x100
	ctx.xer.ca = ctx.r[7].u32 <= 256 as u32;
	ctx.r[8].s64 = (256 as i64) - ctx.r[7].s64;
	// 8258F2B0: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F2B4: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258F2B8: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 8258F2BC: 9123000C  stw r9, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 8258F2C0: 2F080004  cmpwi cr6, r8, 4
	ctx.cr[6].compare_i32(ctx.r[8].s32, 4, &mut ctx.xer);
	// 8258F2C4: 93230008  stw r25, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 8258F2C8: 41980148  blt cr6, 0x8258f410
	if ctx.cr[6].lt {
	pc = 0x8258F410; continue 'dispatch;
	}
	// 8258F2CC: 212700FC  subfic r9, r7, 0xfc
	ctx.xer.ca = ctx.r[7].u32 <= 252 as u32;
	ctx.r[9].s64 = (252 as i64) - ctx.r[7].s64;
	// 8258F2D0: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F2D4: 390A0002  addi r8, r10, 2
	ctx.r[8].s64 = ctx.r[10].s64 + 2;
	// 8258F2D8: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258F2DC: 3BE70002  addi r31, r7, 2
	ctx.r[31].s64 = ctx.r[7].s64 + 2;
	// 8258F2E0: 3BA90001  addi r29, r9, 1
	ctx.r[29].s64 = ctx.r[9].s64 + 1;
	// 8258F2E4: 39270003  addi r9, r7, 3
	ctx.r[9].s64 = ctx.r[7].s64 + 3;
	// 8258F2E8: 57BA103A  slwi r26, r29, 2
	ctx.r[26].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[26].u64 = ctx.r[26].u32 as u64;
	// 8258F2EC: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8258F2F0: 7F995050  subf r28, r25, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[25].s64;
	// 8258F2F4: 7FC62214  add r30, r6, r4
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 8258F2F8: 7CDB5050  subf r6, r27, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[27].s64;
	// 8258F2FC: 57E9103A  slwi r9, r31, 2
	ctx.r[9].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8258F300: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258F304: 7D5A5214  add r10, r26, r10
	ctx.r[10].u64 = ctx.r[26].u64 + ctx.r[10].u64;
	// 8258F308: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258F30C: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8258F310: 7F052050  subf r24, r5, r4
	ctx.r[24].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 8258F314: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 8258F318: 38C60002  addi r6, r6, 2
	ctx.r[6].s64 = ctx.r[6].s64 + 2;
	// 8258F31C: 7F7BC850  subf r27, r27, r25
	ctx.r[27].s64 = ctx.r[25].s64 - ctx.r[27].s64;
	// 8258F320: 7F5A3A14  add r26, r26, r7
	ctx.r[26].u64 = ctx.r[26].u64 + ctx.r[7].u64;
	// 8258F324: 578715BA  rlwinm r7, r28, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F328: C17EFFF4  lfs f11, -0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F32C: 7F3BE214  add r25, r27, r28
	ctx.r[25].u64 = ctx.r[27].u64 + ctx.r[28].u64;
	// 8258F330: C15EFFF8  lfs f10, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F334: 3AFFFFFF  addi r23, r31, -1
	ctx.r[23].s64 = ctx.r[31].s64 + -1;
	// 8258F338: 7D384C2E  lfsx f9, r24, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F33C: 573915BA  rlwinm r25, r25, 2, 0x16, 0x1d
	ctx.r[25].u64 = ctx.r[25].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F340: C11E0000  lfs f8, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258F344: 56F715BA  rlwinm r23, r23, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F348: 7CE75C2E  lfsx f7, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258F34C: 38E6FFFF  addi r7, r6, -1
	ctx.r[7].s64 = ctx.r[6].s64 + -1;
	// 8258F350: ECE70372  fmuls f7, f7, f13
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F354: 57F615BA  rlwinm r22, r31, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F358: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F35C: 54E715BA  rlwinm r7, r7, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F360: 7CD95C2E  lfsx f6, r25, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258F364: 54D915BA  rlwinm r25, r6, 2, 0x16, 0x1d
	ctx.r[25].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F368: D168FFF8  stfs f11, -8(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8258F36C: 3AA60001  addi r21, r6, 1
	ctx.r[21].s64 = ctx.r[6].s64 + 1;
	// 8258F370: 7D775C2E  lfsx f11, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F374: 3AFF0001  addi r23, r31, 1
	ctx.r[23].s64 = ctx.r[31].s64 + 1;
	// 8258F378: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 8258F37C: 7CA75C2E  lfsx f5, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258F380: 56E715BA  rlwinm r7, r23, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F384: D148FFFC  stfs f10, -4(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258F388: 56B715BA  rlwinm r23, r21, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[21].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F38C: 7D565C2E  lfsx f10, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F390: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F394: 7C995C2E  lfsx f4, r25, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258F398: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 8258F39C: ECE63B3A  fmadds f7, f6, f12, f7
	ctx.f[7].f64 = (((ctx.f[6].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258F3A0: D1280000  stfs f9, 0(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F3A4: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F3A8: 7D275C2E  lfsx f9, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F3AC: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F3B0: 7CD75C2E  lfsx f6, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258F3B4: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F3B8: D0E9FFFC  stfs f7, -4(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8258F3BC: D1080004  stfs f8, 4(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F3C0: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8258F3C4: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 8258F3C8: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 8258F3CC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8258F3D0: ED655B3A  fmadds f11, f5, f12, f11
	ctx.f[11].f64 = (((ctx.f[5].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258F3D4: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F3D8: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F3DC: ED6A0372  fmuls f11, f10, f13
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F3E0: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F3E4: ED645B3A  fmadds f11, f4, f12, f11
	ctx.f[11].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258F3E8: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F3EC: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F3F0: ED690372  fmuls f11, f9, f13
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F3F4: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F3F8: ED665B3A  fmadds f11, f6, f12, f11
	ctx.f[11].f64 = (((ctx.f[6].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 8258F3FC: D1690008  stfs f11, 8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8258F400: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F404: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 8258F408: 409AFF1C  bne cr6, 0x8258f324
	if !ctx.cr[6].eq {
	pc = 0x8258F324; continue 'dispatch;
	}
	// 8258F40C: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F410: 2B1A0100  cmplwi cr6, r26, 0x100
	ctx.cr[6].compare_u32(ctx.r[26].u32, 256 as u32, &mut ctx.xer);
	// 8258F414: 40980088  bge cr6, 0x8258f49c
	if !ctx.cr[6].lt {
	pc = 0x8258F49C; continue 'dispatch;
	}
	// 8258F418: 5747103A  slwi r7, r26, 2
	ctx.r[7].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8258F41C: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258F420: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8258F424: 83A3000C  lwz r29, 0xc(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F428: 7FC72A14  add r30, r7, r5
	ctx.r[30].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 8258F42C: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F430: 213A0100  subfic r9, r26, 0x100
	ctx.xer.ca = ctx.r[26].u32 <= 256 as u32;
	ctx.r[9].s64 = (256 as i64) - ctx.r[26].s64;
	// 8258F434: 7CC85A14  add r6, r8, r11
	ctx.r[6].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8258F438: 7D1F5050  subf r8, r31, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258F43C: 7CE72214  add r7, r7, r4
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[4].u64;
	// 8258F440: 389E0004  addi r4, r30, 4
	ctx.r[4].s64 = ctx.r[30].s64 + 4;
	// 8258F444: 7FFDF850  subf r31, r29, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[29].s64;
	// 8258F448: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8258F44C: 551E15BA  rlwinm r30, r8, 2, 0x16, 0x1d
	ctx.r[30].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F450: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F454: 7FBF4214  add r29, r31, r8
	ctx.r[29].u64 = ctx.r[31].u64 + ctx.r[8].u64;
	// 8258F458: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8258F45C: 57BD15BA  rlwinm r29, r29, 2, 0x16, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F460: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8258F464: 7D5E5C2E  lfsx f10, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F468: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8258F46C: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F470: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8258F474: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8258F478: 7D3D5C2E  lfsx f9, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F47C: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F480: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F484: ED69533A  fmadds f11, f9, f12, f10
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258F488: D1640000  stfs f11, 0(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F48C: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 8258F490: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258F494: 409AFFB8  bne cr6, 0x8258f44c
	if !ctx.cr[6].eq {
	pc = 0x8258F44C; continue 'dispatch;
	}
	// 8258F498: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F49C: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8258F4A0: C0050400  lfs f0, 0x400(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(1024 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F4A4: D0030014  stfs f0, 0x14(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258F4A8: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8258F4AC: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8258F4B0: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8258F4B4: 4BFA5C34  b 0x825350e8
	sub_825350D0(ctx, base);
	return;
	// 8258F4B8: 7D6A5050  subf r11, r10, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[10].s64;
	// 8258F4BC: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8258F4C0: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F4C4: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 8258F4C8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258F4CC: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8258F4D0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258F4D4: 39230020  addi r9, r3, 0x20
	ctx.r[9].s64 = ctx.r[3].s64 + 32;
	// 8258F4D8: 7CCB2A14  add r6, r11, r5
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8258F4DC: C0081850  lfs f0, 0x1850(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(6224 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F4E0: 7D7F5050  subf r11, r31, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258F4E4: EDA06028  fsubs f13, f0, f12
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258F4E8: 7FFEF850  subf r31, r30, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 8258F4EC: FC006090  fmr f0, f12
	ctx.f[0].f64 = ctx.f[12].f64;
	// 8258F4F0: 3FC08209  lis r30, -0x7df7
	ctx.r[30].s64 = -2113339392;
	// 8258F4F4: 39000100  li r8, 0x100
	ctx.r[8].s64 = 256;
	// 8258F4F8: 7CE74A14  add r7, r7, r9
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 8258F4FC: 394A0100  addi r10, r10, 0x100
	ctx.r[10].s64 = ctx.r[10].s64 + 256;
	// 8258F500: C19E68E8  lfs f12, 0x68e8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(26856 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F504: 557E15BA  rlwinm r30, r11, 2, 0x16, 0x1d
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F508: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F50C: 7FBF5A14  add r29, r31, r11
	ctx.r[29].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258F510: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8258F514: 57BD15BA  rlwinm r29, r29, 2, 0x16, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 8258F518: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8258F51C: 7D5E4C2E  lfsx f10, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F520: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8258F524: ED4A0372  fmuls f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 8258F528: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8258F52C: EDAD602A  fadds f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8258F530: 7D3D4C2E  lfsx f9, r29, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258F534: D1670000  stfs f11, 0(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F538: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8258F53C: ED69503A  fmadds f11, f9, f0, f10
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64);
	// 8258F540: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8258F544: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8258F548: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8258F54C: 409AFFB8  bne cr6, 0x8258f504
	if !ctx.cr[6].eq {
	pc = 0x8258F504; continue 'dispatch;
	}
	// 8258F550: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8258F554: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8258F558: C0050400  lfs f0, 0x400(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(1024 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F55C: D0030014  stfs f0, 0x14(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8258F560: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8258F564: 4BFA5B84  b 0x825350e8
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258F568(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8258F568 size=20
    let mut pc: u32 = 0x8258F568;
    'dispatch: loop {
        match pc {
            0x8258F568 => {
    //   block [0x8258F568..0x8258F57C)
	// 8258F568: 3D600004  lis r11, 4
	ctx.r[11].s64 = 262144;
	// 8258F56C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8258F570: 616BBAB0  ori r11, r11, 0xbab0
	ctx.r[11].u64 = ctx.r[11].u64 | 47792;
	// 8258F574: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8258F578: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8258F580(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8258F580 size=5792
    let mut pc: u32 = 0x8258F580;
    'dispatch: loop {
        match pc {
            0x8258F580 => {
    //   block [0x8258F580..0x82590C20)
	// 8258F580: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8258F584: 4BFA5AFD  bl 0x82535080
	ctx.lr = 0x8258F588;
	sub_82535080(ctx, base);
	// 8258F588: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 8258F58C: 4BFA6A25  bl 0x82535fb0
	ctx.lr = 0x8258F590;
	sub_82535FB0(ctx, base);
	// 8258F590: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 8258F594: E981E000  ld r12, -0x2000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8192 as u32) ) };
	// 8258F598: E981D000  ld r12, -0x3000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-12288 as u32) ) };
	// 8258F59C: E981C000  ld r12, -0x4000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16384 as u32) ) };
	// 8258F5A0: 9421BA30  stwu r1, -0x45d0(r1)
	ea = ctx.r[1].u32.wrapping_add(-17872 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8258F5A4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8258F5A8: 817E0064  lwz r11, 0x64(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(100 as u32) ) } as u64;
	// 8258F5AC: 93C145E4  stw r30, 0x45e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(17892 as u32), ctx.r[30].u32 ) };
	// 8258F5B0: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8258F5B4: 419A0020  beq cr6, 0x8258f5d4
	if ctx.cr[6].eq {
	pc = 0x8258F5D4; continue 'dispatch;
	}
	// 8258F5B8: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8258F5BC: 419A0010  beq cr6, 0x8258f5cc
	if ctx.cr[6].eq {
	pc = 0x8258F5CC; continue 'dispatch;
	}
	// 8258F5C0: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258F5C4: 83A40004  lwz r29, 4(r4)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258F5C8: 48000014  b 0x8258f5dc
	pc = 0x8258F5DC; continue 'dispatch;
	// 8258F5CC: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258F5D0: 48000008  b 0x8258f5d8
	pc = 0x8258F5D8; continue 'dispatch;
	// 8258F5D4: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258F5D8: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 8258F5DC: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 8258F5E0: 91610094  stw r11, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[11].u32 ) };
	// 8258F5E4: 93A1008C  stw r29, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[29].u32 ) };
	// 8258F5E8: 9141013C  stw r10, 0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[10].u32 ) };
	// 8258F5EC: 81450004  lwz r10, 4(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 8258F5F0: 91410134  stw r10, 0x134(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), ctx.r[10].u32 ) };
	// 8258F5F4: 8145000C  lwz r10, 0xc(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 8258F5F8: 9141012C  stw r10, 0x12c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(300 as u32), ctx.r[10].u32 ) };
	// 8258F5FC: 81450010  lwz r10, 0x10(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(16 as u32) ) } as u64;
	// 8258F600: 91410124  stw r10, 0x124(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(292 as u32), ctx.r[10].u32 ) };
	// 8258F604: 7C005A2C  dcbt 0, r11
	// 8258F608: 7C00EA2C  dcbt 0, r29
	// 8258F60C: 39400080  li r10, 0x80
	ctx.r[10].s64 = 128;
	// 8258F610: 7C0A5A2C  dcbt r10, r11
	// 8258F614: 7C0AEA2C  dcbt r10, r29
	// 8258F618: 38A11DE0  addi r5, r1, 0x1de0
	ctx.r[5].s64 = ctx.r[1].s64 + 7648;
	// 8258F61C: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 8258F620: 387E0068  addi r3, r30, 0x68
	ctx.r[3].s64 = ctx.r[30].s64 + 104;
	// 8258F624: 4BFFE9B5  bl 0x8258dfd8
	ctx.lr = 0x8258F628;
	sub_8258DFD8(ctx, base);
	// 8258F628: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F62C: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 8258F630: 38A12660  addi r5, r1, 0x2660
	ctx.r[5].s64 = ctx.r[1].s64 + 9824;
	// 8258F634: 38811DE0  addi r4, r1, 0x1de0
	ctx.r[4].s64 = ctx.r[1].s64 + 7648;
	// 8258F638: 386300A8  addi r3, r3, 0xa8
	ctx.r[3].s64 = ctx.r[3].s64 + 168;
	// 8258F63C: 4BFFEFF5  bl 0x8258e630
	ctx.lr = 0x8258F640;
	sub_8258E630(ctx, base);
	// 8258F640: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F644: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 8258F648: 38C119D0  addi r6, r1, 0x19d0
	ctx.r[6].s64 = ctx.r[1].s64 + 6608;
	// 8258F64C: 38A111C0  addi r5, r1, 0x11c0
	ctx.r[5].s64 = ctx.r[1].s64 + 4544;
	// 8258F650: 38812660  addi r4, r1, 0x2660
	ctx.r[4].s64 = ctx.r[1].s64 + 9824;
	// 8258F654: 386300F0  addi r3, r3, 0xf0
	ctx.r[3].s64 = ctx.r[3].s64 + 240;
	// 8258F658: 4BFFF109  bl 0x8258e760
	ctx.lr = 0x8258F65C;
	sub_8258E760(ctx, base);
	// 8258F65C: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F660: 388111C0  addi r4, r1, 0x11c0
	ctx.r[4].s64 = ctx.r[1].s64 + 4544;
	// 8258F664: 3863091C  addi r3, r3, 0x91c
	ctx.r[3].s64 = ctx.r[3].s64 + 2332;
	// 8258F668: 4BFFF1C9  bl 0x8258e830
	ctx.lr = 0x8258F66C;
	sub_8258E830(ctx, base);
	// 8258F66C: 3961377F  addi r11, r1, 0x377f
	ctx.r[11].s64 = ctx.r[1].s64 + 14207;
	// 8258F670: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F674: 557F0030  rlwinm r31, r11, 0, 0, 0x18
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258F678: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 8258F67C: 38C132F0  addi r6, r1, 0x32f0
	ctx.r[6].s64 = ctx.r[1].s64 + 13040;
	// 8258F680: 388111C0  addi r4, r1, 0x11c0
	ctx.r[4].s64 = ctx.r[1].s64 + 4544;
	// 8258F684: 38630B34  addi r3, r3, 0xb34
	ctx.r[3].s64 = ctx.r[3].s64 + 2868;
	// 8258F688: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8258F68C: 4BFFF42D  bl 0x8258eab8
	ctx.lr = 0x8258F690;
	sub_8258EAB8(ctx, base);
	// 8258F690: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F694: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258F698: 38632B60  addi r3, r3, 0x2b60
	ctx.r[3].s64 = ctx.r[3].s64 + 11104;
	// 8258F69C: 4BFFF4ED  bl 0x8258eb88
	ctx.lr = 0x8258F6A0;
	sub_8258EB88(ctx, base);
	// 8258F6A0: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F6A4: 38A10DB0  addi r5, r1, 0xdb0
	ctx.r[5].s64 = ctx.r[1].s64 + 3504;
	// 8258F6A8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8258F6AC: 38632F78  addi r3, r3, 0x2f78
	ctx.r[3].s64 = ctx.r[3].s64 + 12152;
	// 8258F6B0: 4BFFF7A9  bl 0x8258ee58
	ctx.lr = 0x8258F6B4;
	sub_8258EE58(ctx, base);
	// 8258F6B4: 39613C0F  addi r11, r1, 0x3c0f
	ctx.r[11].s64 = ctx.r[1].s64 + 15375;
	// 8258F6B8: 3941409F  addi r10, r1, 0x409f
	ctx.r[10].s64 = ctx.r[1].s64 + 16543;
	// 8258F6BC: 556B0030  rlwinm r11, r11, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258F6C0: 55450030  rlwinm r5, r10, 0, 0, 0x18
	ctx.r[5].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 8258F6C4: 38CB0008  addi r6, r11, 8
	ctx.r[6].s64 = ctx.r[11].s64 + 8;
	// 8258F6C8: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F6CC: 38810DB0  addi r4, r1, 0xdb0
	ctx.r[4].s64 = ctx.r[1].s64 + 3504;
	// 8258F6D0: 38633790  addi r3, r3, 0x3790
	ctx.r[3].s64 = ctx.r[3].s64 + 14224;
	// 8258F6D4: 90A100DC  stw r5, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[5].u32 ) };
	// 8258F6D8: 90C100D0  stw r6, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[6].u32 ) };
	// 8258F6DC: 4BFFF8E5  bl 0x8258efc0
	ctx.lr = 0x8258F6E0;
	sub_8258EFC0(ctx, base);
	// 8258F6E0: 3C7E0001  addis r3, r30, 1
	ctx.r[3].s64 = ctx.r[30].s64 + 65536;
	// 8258F6E4: 38A11DE0  addi r5, r1, 0x1de0
	ctx.r[5].s64 = ctx.r[1].s64 + 7648;
	// 8258F6E8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8258F6EC: 38630088  addi r3, r3, 0x88
	ctx.r[3].s64 = ctx.r[3].s64 + 136;
	// 8258F6F0: 4BFFE8E9  bl 0x8258dfd8
	ctx.lr = 0x8258F6F4;
	sub_8258DFD8(ctx, base);
	// 8258F6F4: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F6F8: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 8258F6FC: 38A12660  addi r5, r1, 0x2660
	ctx.r[5].s64 = ctx.r[1].s64 + 9824;
	// 8258F700: 38811DE0  addi r4, r1, 0x1de0
	ctx.r[4].s64 = ctx.r[1].s64 + 7648;
	// 8258F704: 386300C8  addi r3, r3, 0xc8
	ctx.r[3].s64 = ctx.r[3].s64 + 200;
	// 8258F708: 4BFFEF29  bl 0x8258e630
	ctx.lr = 0x8258F70C;
	sub_8258E630(ctx, base);
	// 8258F70C: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 8258F710: 38C10DB0  addi r6, r1, 0xdb0
	ctx.r[6].s64 = ctx.r[1].s64 + 3504;
	// 8258F714: 38A109A0  addi r5, r1, 0x9a0
	ctx.r[5].s64 = ctx.r[1].s64 + 2464;
	// 8258F718: 38812660  addi r4, r1, 0x2660
	ctx.r[4].s64 = ctx.r[1].s64 + 9824;
	// 8258F71C: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F720: 386347B8  addi r3, r3, 0x47b8
	ctx.r[3].s64 = ctx.r[3].s64 + 18360;
	// 8258F724: 4BFFF03D  bl 0x8258e760
	ctx.lr = 0x8258F728;
	sub_8258E760(ctx, base);
	// 8258F728: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F72C: 388109A0  addi r4, r1, 0x9a0
	ctx.r[4].s64 = ctx.r[1].s64 + 2464;
	// 8258F730: 38634FE4  addi r3, r3, 0x4fe4
	ctx.r[3].s64 = ctx.r[3].s64 + 20452;
	// 8258F734: 4BFFF0FD  bl 0x8258e830
	ctx.lr = 0x8258F738;
	sub_8258E830(ctx, base);
	// 8258F738: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F73C: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 8258F740: 38C12EE0  addi r6, r1, 0x2ee0
	ctx.r[6].s64 = ctx.r[1].s64 + 12000;
	// 8258F744: 38A10590  addi r5, r1, 0x590
	ctx.r[5].s64 = ctx.r[1].s64 + 1424;
	// 8258F748: 388109A0  addi r4, r1, 0x9a0
	ctx.r[4].s64 = ctx.r[1].s64 + 2464;
	// 8258F74C: 386351FC  addi r3, r3, 0x51fc
	ctx.r[3].s64 = ctx.r[3].s64 + 20988;
	// 8258F750: 4BFFF369  bl 0x8258eab8
	ctx.lr = 0x8258F754;
	sub_8258EAB8(ctx, base);
	// 8258F754: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F758: 38810590  addi r4, r1, 0x590
	ctx.r[4].s64 = ctx.r[1].s64 + 1424;
	// 8258F75C: 38637228  addi r3, r3, 0x7228
	ctx.r[3].s64 = ctx.r[3].s64 + 29224;
	// 8258F760: 4BFFF429  bl 0x8258eb88
	ctx.lr = 0x8258F764;
	sub_8258EB88(ctx, base);
	// 8258F764: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F768: 38A10180  addi r5, r1, 0x180
	ctx.r[5].s64 = ctx.r[1].s64 + 384;
	// 8258F76C: 38810590  addi r4, r1, 0x590
	ctx.r[4].s64 = ctx.r[1].s64 + 1424;
	// 8258F770: 38637640  addi r3, r3, 0x7640
	ctx.r[3].s64 = ctx.r[3].s64 + 30272;
	// 8258F774: 4BFFF6E5  bl 0x8258ee58
	ctx.lr = 0x8258F778;
	sub_8258EE58(ctx, base);
	// 8258F778: 39611E5F  addi r11, r1, 0x1e5f
	ctx.r[11].s64 = ctx.r[1].s64 + 7775;
	// 8258F77C: 394126DF  addi r10, r1, 0x26df
	ctx.r[10].s64 = ctx.r[1].s64 + 9951;
	// 8258F780: 556B0030  rlwinm r11, r11, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8258F784: 55450030  rlwinm r5, r10, 0, 0, 0x18
	ctx.r[5].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 8258F788: 38CB0008  addi r6, r11, 8
	ctx.r[6].s64 = ctx.r[11].s64 + 8;
	// 8258F78C: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 8258F790: 38810180  addi r4, r1, 0x180
	ctx.r[4].s64 = ctx.r[1].s64 + 384;
	// 8258F794: 38637E58  addi r3, r3, 0x7e58
	ctx.r[3].s64 = ctx.r[3].s64 + 32344;
	// 8258F798: 90A100D4  stw r5, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[5].u32 ) };
	// 8258F79C: 90C100D8  stw r6, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[6].u32 ) };
	// 8258F7A0: 90A100CC  stw r5, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[5].u32 ) };
	// 8258F7A4: 4BFFF81D  bl 0x8258efc0
	ctx.lr = 0x8258F7A8;
	sub_8258EFC0(ctx, base);
	// 8258F7A8: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 8258F7AC: C01E0060  lfs f0, 0x60(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258F7B0: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 8258F7B4: 616B47B0  ori r11, r11, 0x47b0
	ctx.r[11].u64 = ctx.r[11].u64 | 18352;
	// 8258F7B8: 614A00EC  ori r10, r10, 0xec
	ctx.r[10].u64 = ctx.r[10].u64 | 236;
	// 8258F7BC: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 8258F7C0: 3D000002  lis r8, 2
	ctx.r[8].s64 = 131072;
	// 8258F7C4: 612947B4  ori r9, r9, 0x47b4
	ctx.r[9].u64 = ctx.r[9].u64 | 18356;
	// 8258F7C8: 7DBE5C2E  lfsx f13, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8258F7CC: 39610590  addi r11, r1, 0x590
	ctx.r[11].s64 = ctx.r[1].s64 + 1424;
	// 8258F7D0: 7D9E542E  lfsx f12, r30, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8258F7D4: 394111C0  addi r10, r1, 0x11c0
	ctx.r[10].s64 = ctx.r[1].s64 + 4544;
	// 8258F7D8: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F7DC: 610800E8  ori r8, r8, 0xe8
	ctx.r[8].u64 = ctx.r[8].u64 | 232;
	// 8258F7E0: 7D7E4C2E  lfsx f11, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8258F7E4: 39210DB0  addi r9, r1, 0xdb0
	ctx.r[9].s64 = ctx.r[1].s64 + 3504;
	// 8258F7E8: 38E109A0  addi r7, r1, 0x9a0
	ctx.r[7].s64 = ctx.r[1].s64 + 2464;
	// 8258F7EC: 38A119D4  addi r5, r1, 0x19d4
	ctx.r[5].s64 = ctx.r[1].s64 + 6612;
	// 8258F7F0: 91610088  stw r11, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[11].u32 ) };
	// 8258F7F4: 7D7F5050  subf r11, r31, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258F7F8: 7D5E442E  lfsx f10, r30, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8258F7FC: 390109A4  addi r8, r1, 0x9a4
	ctx.r[8].s64 = ctx.r[1].s64 + 2468;
	// 8258F800: 7CFF3850  subf r7, r31, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 8258F804: 38C119D0  addi r6, r1, 0x19d0
	ctx.r[6].s64 = ctx.r[1].s64 + 6608;
	// 8258F808: 3ADF0004  addi r22, r31, 4
	ctx.r[22].s64 = ctx.r[31].s64 + 4;
	// 8258F80C: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 8258F810: 7D7F4850  subf r11, r31, r9
	ctx.r[11].s64 = ctx.r[9].s64 - ctx.r[31].s64;
	// 8258F814: 38810594  addi r4, r1, 0x594
	ctx.r[4].s64 = ctx.r[1].s64 + 1428;
	// 8258F818: 90E10080  stw r7, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[7].u32 ) };
	// 8258F81C: 7CFF3050  subf r7, r31, r6
	ctx.r[7].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 8258F820: 386111C4  addi r3, r1, 0x11c4
	ctx.r[3].s64 = ctx.r[1].s64 + 4548;
	// 8258F824: 3BC10DB4  addi r30, r1, 0xdb4
	ctx.r[30].s64 = ctx.r[1].s64 + 3508;
	// 8258F828: 92C10098  stw r22, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[22].u32 ) };
	// 8258F82C: 916100B8  stw r11, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 8258F830: 7D7F4050  subf r11, r31, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 8258F834: 3BA109A8  addi r29, r1, 0x9a8
	ctx.r[29].s64 = ctx.r[1].s64 + 2472;
	// 8258F838: 3B8119D8  addi r28, r1, 0x19d8
	ctx.r[28].s64 = ctx.r[1].s64 + 6616;
	// 8258F83C: 90E10070  stw r7, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[7].u32 ) };
	// 8258F840: 3B610598  addi r27, r1, 0x598
	ctx.r[27].s64 = ctx.r[1].s64 + 1432;
	// 8258F844: 3B4111C8  addi r26, r1, 0x11c8
	ctx.r[26].s64 = ctx.r[1].s64 + 4552;
	// 8258F848: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8258F84C: 7D7F2850  subf r11, r31, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 8258F850: 3B210DB8  addi r25, r1, 0xdb8
	ctx.r[25].s64 = ctx.r[1].s64 + 3512;
	// 8258F854: 3B0109AC  addi r24, r1, 0x9ac
	ctx.r[24].s64 = ctx.r[1].s64 + 2476;
	// 8258F858: 3AE119DC  addi r23, r1, 0x19dc
	ctx.r[23].s64 = ctx.r[1].s64 + 6620;
	// 8258F85C: 916100A8  stw r11, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[11].u32 ) };
	// 8258F860: 7D7F2050  subf r11, r31, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 8258F864: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 8258F868: 7D7F1850  subf r11, r31, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[31].s64;
	// 8258F86C: 394111CC  addi r10, r1, 0x11cc
	ctx.r[10].s64 = ctx.r[1].s64 + 4556;
	// 8258F870: 392115E8  addi r9, r1, 0x15e8
	ctx.r[9].s64 = ctx.r[1].s64 + 5608;
	// 8258F874: 39010198  addi r8, r1, 0x198
	ctx.r[8].s64 = ctx.r[1].s64 + 408;
	// 8258F878: 38E109B4  addi r7, r1, 0x9b4
	ctx.r[7].s64 = ctx.r[1].s64 + 2484;
	// 8258F87C: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8258F880: 7D7FF050  subf r11, r31, r30
	ctx.r[11].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 8258F884: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8258F888: 39410DBC  addi r10, r1, 0xdbc
	ctx.r[10].s64 = ctx.r[1].s64 + 3516;
	// 8258F88C: 38C119E4  addi r6, r1, 0x19e4
	ctx.r[6].s64 = ctx.r[1].s64 + 6628;
	// 8258F890: 38A105A4  addi r5, r1, 0x5a4
	ctx.r[5].s64 = ctx.r[1].s64 + 1444;
	// 8258F894: 388111D4  addi r4, r1, 0x11d4
	ctx.r[4].s64 = ctx.r[1].s64 + 4564;
	// 8258F898: 916100C8  stw r11, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 8258F89C: 7D7FE850  subf r11, r31, r29
	ctx.r[11].s64 = ctx.r[29].s64 - ctx.r[31].s64;
	// 8258F8A0: 91410054  stw r10, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 8258F8A4: 394109B0  addi r10, r1, 0x9b0
	ctx.r[10].s64 = ctx.r[1].s64 + 2480;
	// 8258F8A8: 38610DC4  addi r3, r1, 0xdc4
	ctx.r[3].s64 = ctx.r[1].s64 + 3524;
	// 8258F8AC: 3BC109B8  addi r30, r1, 0x9b8
	ctx.r[30].s64 = ctx.r[1].s64 + 2488;
	// 8258F8B0: 3BA119E8  addi r29, r1, 0x19e8
	ctx.r[29].s64 = ctx.r[1].s64 + 6632;
	// 8258F8B4: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8258F8B8: 7D7FE050  subf r11, r31, r28
	ctx.r[11].s64 = ctx.r[28].s64 - ctx.r[31].s64;
	// 8258F8BC: 91410064  stw r10, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[10].u32 ) };
	// 8258F8C0: 394119E0  addi r10, r1, 0x19e0
	ctx.r[10].s64 = ctx.r[1].s64 + 6624;
	// 8258F8C4: 3B8105A8  addi r28, r1, 0x5a8
	ctx.r[28].s64 = ctx.r[1].s64 + 1448;
	// 8258F8C8: 3AC10184  addi r22, r1, 0x184
	ctx.r[22].s64 = ctx.r[1].s64 + 388;
	// 8258F8CC: 3AA115D8  addi r21, r1, 0x15d8
	ctx.r[21].s64 = ctx.r[1].s64 + 5592;
	// 8258F8D0: 916100B0  stw r11, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[11].u32 ) };
	// 8258F8D4: 7D7FD850  subf r11, r31, r27
	ctx.r[11].s64 = ctx.r[27].s64 - ctx.r[31].s64;
	// 8258F8D8: 91410060  stw r10, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 8258F8DC: 394105A0  addi r10, r1, 0x5a0
	ctx.r[10].s64 = ctx.r[1].s64 + 1440;
	// 8258F8E0: 3B6111D8  addi r27, r1, 0x11d8
	ctx.r[27].s64 = ctx.r[1].s64 + 4568;
	// 8258F8E4: 3A810188  addi r20, r1, 0x188
	ctx.r[20].s64 = ctx.r[1].s64 + 392;
	// 8258F8E8: 3A6115DC  addi r19, r1, 0x15dc
	ctx.r[19].s64 = ctx.r[1].s64 + 5596;
	// 8258F8EC: 91610090  stw r11, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 8258F8F0: 7D7FD050  subf r11, r31, r26
	ctx.r[11].s64 = ctx.r[26].s64 - ctx.r[31].s64;
	// 8258F8F4: 9141005C  stw r10, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[10].u32 ) };
	// 8258F8F8: 394111D0  addi r10, r1, 0x11d0
	ctx.r[10].s64 = ctx.r[1].s64 + 4560;
	// 8258F8FC: 3B410DC8  addi r26, r1, 0xdc8
	ctx.r[26].s64 = ctx.r[1].s64 + 3528;
	// 8258F900: 3A41018C  addi r18, r1, 0x18c
	ctx.r[18].s64 = ctx.r[1].s64 + 396;
	// 8258F904: 3A2115E0  addi r17, r1, 0x15e0
	ctx.r[17].s64 = ctx.r[1].s64 + 5600;
	// 8258F908: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8258F90C: 7D7FC850  subf r11, r31, r25
	ctx.r[11].s64 = ctx.r[25].s64 - ctx.r[31].s64;
	// 8258F910: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8258F914: 39410DC0  addi r10, r1, 0xdc0
	ctx.r[10].s64 = ctx.r[1].s64 + 3520;
	// 8258F918: 3B2115D0  addi r25, r1, 0x15d0
	ctx.r[25].s64 = ctx.r[1].s64 + 5584;
	// 8258F91C: 3A010190  addi r16, r1, 0x190
	ctx.r[16].s64 = ctx.r[1].s64 + 400;
	// 8258F920: 39E115E4  addi r15, r1, 0x15e4
	ctx.r[15].s64 = ctx.r[1].s64 + 5604;
	// 8258F924: 916100C0  stw r11, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 8258F928: 7D7FC050  subf r11, r31, r24
	ctx.r[11].s64 = ctx.r[24].s64 - ctx.r[31].s64;
	// 8258F92C: 3B010180  addi r24, r1, 0x180
	ctx.r[24].s64 = ctx.r[1].s64 + 384;
	// 8258F930: 39C10194  addi r14, r1, 0x194
	ctx.r[14].s64 = ctx.r[1].s64 + 404;
	// 8258F934: 7CFF3850  subf r7, r31, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 8258F938: 7CDF3050  subf r6, r31, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 8258F93C: 916100A0  stw r11, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 8258F940: 7D7FB850  subf r11, r31, r23
	ctx.r[11].s64 = ctx.r[23].s64 - ctx.r[31].s64;
	// 8258F944: 3AE115D4  addi r23, r1, 0x15d4
	ctx.r[23].s64 = ctx.r[1].s64 + 5588;
	// 8258F948: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8258F94C: 3961059C  addi r11, r1, 0x59c
	ctx.r[11].s64 = ctx.r[1].s64 + 1436;
	// 8258F950: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F954: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8258F958: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258F95C: 91210050  stw r9, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u32 ) };
	// 8258F960: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F964: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258F968: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258F96C: 91010054  stw r8, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[8].u32 ) };
	// 8258F970: 7D1F5050  subf r8, r31, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8258F974: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F978: 91610078  stw r11, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 8258F97C: 81610064  lwz r11, 0x64(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8258F980: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F984: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8258F988: 81610060  lwz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 8258F98C: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F990: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8258F994: 8161005C  lwz r11, 0x5c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8258F998: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F99C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8258F9A0: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258F9A4: 7D3F5850  subf r9, r31, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F9A8: 7D7F7850  subf r11, r31, r15
	ctx.r[11].s64 = ctx.r[15].s64 - ctx.r[31].s64;
	// 8258F9AC: 7CBF2850  subf r5, r31, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 8258F9B0: 7C9F2050  subf r4, r31, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 8258F9B4: 7C7F1850  subf r3, r31, r3
	ctx.r[3].s64 = ctx.r[3].s64 - ctx.r[31].s64;
	// 8258F9B8: 7FDFF050  subf r30, r31, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 8258F9BC: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8258F9C0: 7D7F7050  subf r11, r31, r14
	ctx.r[11].s64 = ctx.r[14].s64 - ctx.r[31].s64;
	// 8258F9C4: 7FBFE850  subf r29, r31, r29
	ctx.r[29].s64 = ctx.r[29].s64 - ctx.r[31].s64;
	// 8258F9C8: 7F9FE050  subf r28, r31, r28
	ctx.r[28].s64 = ctx.r[28].s64 - ctx.r[31].s64;
	// 8258F9CC: 7F7FD850  subf r27, r31, r27
	ctx.r[27].s64 = ctx.r[27].s64 - ctx.r[31].s64;
	// 8258F9D0: 7F5FD050  subf r26, r31, r26
	ctx.r[26].s64 = ctx.r[26].s64 - ctx.r[31].s64;
	// 8258F9D4: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8258F9D8: 7F3FC850  subf r25, r31, r25
	ctx.r[25].s64 = ctx.r[25].s64 - ctx.r[31].s64;
	// 8258F9DC: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258F9E0: 7F1FC050  subf r24, r31, r24
	ctx.r[24].s64 = ctx.r[24].s64 - ctx.r[31].s64;
	// 8258F9E4: 7EFFB850  subf r23, r31, r23
	ctx.r[23].s64 = ctx.r[23].s64 - ctx.r[31].s64;
	// 8258F9E8: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258F9EC: 7EDFB050  subf r22, r31, r22
	ctx.r[22].s64 = ctx.r[22].s64 - ctx.r[31].s64;
	// 8258F9F0: 7EBFA850  subf r21, r31, r21
	ctx.r[21].s64 = ctx.r[21].s64 - ctx.r[31].s64;
	// 8258F9F4: 7E9FA050  subf r20, r31, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[31].s64;
	// 8258F9F8: 7E7F9850  subf r19, r31, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[31].s64;
	// 8258F9FC: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8258FA00: 7E5F9050  subf r18, r31, r18
	ctx.r[18].s64 = ctx.r[18].s64 - ctx.r[31].s64;
	// 8258FA04: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258FA08: 7E3F8850  subf r17, r31, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[31].s64;
	// 8258FA0C: 7E1F8050  subf r16, r31, r16
	ctx.r[16].s64 = ctx.r[16].s64 - ctx.r[31].s64;
	// 8258FA10: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 8258FA14: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8258FA18: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8258FA1C: 81610098  lwz r11, 0x98(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) } as u64;
	// 8258FA20: 3BE10590  addi r31, r1, 0x590
	ctx.r[31].s64 = ctx.r[1].s64 + 1424;
	// 8258FA24: 81E10088  lwz r15, 0x88(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 8258FA28: 81C10080  lwz r14, 0x80(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 8258FA2C: C12BFFFC  lfs f9, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258FA30: ED290332  fmuls f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FA34: C0EB0004  lfs f7, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258FA38: C0AB0008  lfs f5, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258FA3C: ECE70332  fmuls f7, f7, f12
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FA40: ECA50332  fmuls f5, f5, f12
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FA44: 7C8AFC2E  lfsx f4, r10, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258FA48: 83E10090  lwz r31, 0x90(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 8258FA4C: 7D0F5C2E  lfsx f8, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258FA50: 81E10084  lwz r15, 0x84(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 8258FA54: 7C4E5C2E  lfsx f2, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8258FA58: 81C10070  lwz r14, 0x70(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 8258FA5C: EC8402F2  fmuls f4, f4, f11
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FA60: ED0802F2  fmuls f8, f8, f11
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FA64: 7C7F5C2E  lfsx f3, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8258FA68: 3BE109A0  addi r31, r1, 0x9a0
	ctx.r[31].s64 = ctx.r[1].s64 + 2464;
	// 8258FA6C: 7CCF5C2E  lfsx f6, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258FA70: 39E111C0  addi r15, r1, 0x11c0
	ctx.r[15].s64 = ctx.r[1].s64 + 4544;
	// 8258FA74: ECC602F2  fmuls f6, f6, f11
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FA78: 7C2E5C2E  lfsx f1, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8258FA7C: EC6302F2  fmuls f3, f3, f11
	ctx.f[3].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FA80: 81C10068  lwz r14, 0x68(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 8258FA84: EC420B7A  fmadds f2, f2, f13, f1
	ctx.f[2].f64 = (((ctx.f[2].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 8258FA88: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8258FA8C: 7FCAFC2E  lfsx f30, r10, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8258FA90: 83E100AC  lwz r31, 0xac(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) } as u64;
	// 8258FA94: 7FAA7C2E  lfsx f29, r10, r15
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[15].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8258FA98: 39E10DB0  addi r15, r1, 0xdb0
	ctx.r[15].s64 = ctx.r[1].s64 + 3504;
	// 8258FA9C: ED3E4B7A  fmadds f9, f30, f13, f9
	ctx.f[9].f64 = (((ctx.f[30].f64 * ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258FAA0: EC9D22BA  fmadds f4, f29, f10, f4
	ctx.f[4].f64 = (((ctx.f[29].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 8258FAA4: 7FEE5C2E  lfsx f31, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8258FAA8: 81C100B8  lwz r14, 0xb8(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 8258FAAC: ED1F42BA  fmadds f8, f31, f10, f8
	ctx.f[8].f64 = (((ctx.f[31].f64 * ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258FAB0: 7F9F5C2E  lfsx f28, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8258FAB4: 83E100B4  lwz r31, 0xb4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 8258FAB8: ECFC3B7A  fmadds f7, f28, f13, f7
	ctx.f[7].f64 = (((ctx.f[28].f64 * ctx.f[13].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258FABC: 7FEE5C2E  lfsx f31, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8258FAC0: 81C100A8  lwz r14, 0xa8(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) } as u64;
	// 8258FAC4: 7F7F5C2E  lfsx f27, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8258FAC8: 83E100BC  lwz r31, 0xbc(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 8258FACC: ECDB32BA  fmadds f6, f27, f10, f6
	ctx.f[6].f64 = (((ctx.f[27].f64 * ctx.f[10].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258FAD0: 7F6A7C2E  lfsx f27, r10, r15
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[15].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8258FAD4: 81E100C8  lwz r15, 0xc8(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 8258FAD8: EC4C107A  fmadds f2, f12, f1, f2
	ctx.f[2].f64 = (((ctx.f[12].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 8258FADC: EC84D82A  fadds f4, f4, f27
	ctx.f[4].f64 = ((ctx.f[4].f64 + ctx.f[27].f64) as f32) as f64;
	// 8258FAE0: 7FAE5C2E  lfsx f29, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8258FAE4: ED08F82A  fadds f8, f8, f31
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[31].f64) as f32) as f64;
	// 8258FAE8: 7F5F5C2E  lfsx f26, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8258FAEC: 83E100C4  lwz r31, 0xc4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) } as u64;
	// 8258FAF0: ECBA2B7A  fmadds f5, f26, f13, f5
	ctx.f[5].f64 = (((ctx.f[26].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8258FAF4: 81C100A0  lwz r14, 0xa0(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 8258FAF8: ECE7E82A  fadds f7, f7, f29
	ctx.f[7].f64 = ((ctx.f[7].f64 + ctx.f[29].f64) as f32) as f64;
	// 8258FAFC: 7FDF5C2E  lfsx f30, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8258FB00: 3BE119D0  addi r31, r1, 0x19d0
	ctx.r[31].s64 = ctx.r[1].s64 + 6608;
	// 8258FB04: EC7E1ABA  fmadds f3, f30, f10, f3
	ctx.f[3].f64 = (((ctx.f[30].f64 * ctx.f[10].f64 + ctx.f[3].f64) as f32) as f64);
	// 8258FB08: 7FCF5C2E  lfsx f30, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8258FB0C: 81E100B0  lwz r15, 0xb0(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 8258FB10: 7F6E5C2E  lfsx f27, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8258FB14: ECC6F02A  fadds f6, f6, f30
	ctx.f[6].f64 = ((ctx.f[6].f64 + ctx.f[30].f64) as f32) as f64;
	// 8258FB18: 7F8AFC2E  lfsx f28, r10, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8258FB1C: 3BE115D0  addi r31, r1, 0x15d0
	ctx.r[31].s64 = ctx.r[1].s64 + 5584;
	// 8258FB20: ED29E02A  fadds f9, f9, f28
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[28].f64) as f32) as f64;
	// 8258FB24: 7F4F5C2E  lfsx f26, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8258FB28: 81E100C0  lwz r15, 0xc0(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 8258FB2C: ECA5D02A  fadds f5, f5, f26
	ctx.f[5].f64 = ((ctx.f[5].f64 + ctx.f[26].f64) as f32) as f64;
	// 8258FB30: 7F8F5C2E  lfsx f28, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8258FB34: 39E10180  addi r15, r1, 0x180
	ctx.r[15].s64 = ctx.r[1].s64 + 384;
	// 8258FB38: EC63E02A  fadds f3, f3, f28
	ctx.f[3].f64 = ((ctx.f[3].f64 + ctx.f[28].f64) as f32) as f64;
	// 8258FB3C: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB40: 7D2AFD2E  stfsx f9, r10, r31
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32), tmp.u32) };
	// 8258FB44: ED240032  fmuls f9, f4, f0
	ctx.f[9].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB48: 7D2A7D2E  stfsx f9, r10, r15
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[15].u32), tmp.u32) };
	// 8258FB4C: ED220032  fmuls f9, f2, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB50: 7D395D2E  stfsx f9, r25, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB54: ED280032  fmuls f9, f8, f0
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB58: 7D385D2E  stfsx f9, r24, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB5C: ED270032  fmuls f9, f7, f0
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB60: 7D375D2E  stfsx f9, r23, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB64: 83E100A4  lwz r31, 0xa4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) } as u64;
	// 8258FB68: ED260032  fmuls f9, f6, f0
	ctx.f[9].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB6C: 7D365D2E  stfsx f9, r22, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB70: ED250032  fmuls f9, f5, f0
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB74: 7D355D2E  stfsx f9, r21, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB78: ED230032  fmuls f9, f3, f0
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FB7C: 7D345D2E  stfsx f9, r20, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FB80: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 8258FB84: C12B000C  lfs f9, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8258FB88: 7D1F5C2E  lfsx f8, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8258FB8C: 83E10064  lwz r31, 0x64(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8258FB90: ED290332  fmuls f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FB94: C0EB0010  lfs f7, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8258FB98: ED0802F2  fmuls f8, f8, f11
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FB9C: C0AB0014  lfs f5, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8258FBA0: ECE70332  fmuls f7, f7, f12
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FBA4: 7C855C2E  lfsx f4, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8258FBA8: ECA50332  fmuls f5, f5, f12
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FBAC: 7FC95C2E  lfsx f30, r9, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8258FBB0: 7CDF5C2E  lfsx f6, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8258FBB4: 83E10074  lwz r31, 0x74(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 8258FBB8: ECC602F2  fmuls f6, f6, f11
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FBBC: 7FA75C2E  lfsx f29, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8258FBC0: EC8402F2  fmuls f4, f4, f11
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FBC4: C06B0018  lfs f3, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8258FBC8: EC630332  fmuls f3, f3, f12
	ctx.f[3].f64 = (((ctx.f[3].f64 * ctx.f[12].f64) as f32) as f64);
	// 8258FBCC: 7F845C2E  lfsx f28, r4, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8258FBD0: 7C5C5C2E  lfsx f2, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8258FBD4: 7C3F5C2E  lfsx f1, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8258FBD8: 83E1007C  lwz r31, 0x7c(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 8258FBDC: ED3B4B7A  fmadds f9, f27, f13, f9
	ctx.f[9].f64 = (((ctx.f[27].f64 * ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64);
	// 8258FBE0: 7F5E5C2E  lfsx f26, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8258FBE4: ED0142BA  fmadds f8, f1, f10, f8
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64);
	// 8258FBE8: 7F3B5C2E  lfsx f25, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8258FBEC: EC4202F2  fmuls f2, f2, f11
	ctx.f[2].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 8258FBF0: 7EFA5C2E  lfsx f23, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 8258FBF4: ECBD2B7A  fmadds f5, f29, f13, f5
	ctx.f[5].f64 = (((ctx.f[29].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8258FBF8: 7FA35C2E  lfsx f29, r3, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8258FBFC: 7FFF5C2E  lfsx f31, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8258FC00: 83E1006C  lwz r31, 0x6c(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8258FC04: ECFF3B7A  fmadds f7, f31, f13, f7
	ctx.f[7].f64 = (((ctx.f[31].f64 * ctx.f[13].f64 + ctx.f[7].f64) as f32) as f64);
	// 8258FC08: 7FE85C2E  lfsx f31, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8258FC0C: ECDE32BA  fmadds f6, f30, f10, f6
	ctx.f[6].f64 = (((ctx.f[30].f64 * ctx.f[10].f64 + ctx.f[6].f64) as f32) as f64);
	// 8258FC10: 7FC65C2E  lfsx f30, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8258FC14: EC9C22BA  fmadds f4, f28, f10, f4
	ctx.f[4].f64 = (((ctx.f[28].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 8258FC18: 7F9D5C2E  lfsx f28, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8258FC1C: EC7A1B7A  fmadds f3, f26, f13, f3
	ctx.f[3].f64 = (((ctx.f[26].f64 * ctx.f[13].f64 + ctx.f[3].f64) as f32) as f64);
	// 8258FC20: 7F1F5C2E  lfsx f24, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 8258FC24: 83E10078  lwz r31, 0x78(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 8258FC28: ED29C02A  fadds f9, f9, f24
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[24].f64) as f32) as f64;
	// 8258FC2C: EC5912BA  fmadds f2, f25, f10, f2
	ctx.f[2].f64 = (((ctx.f[25].f64 * ctx.f[10].f64 + ctx.f[2].f64) as f32) as f64);
	// 8258FC30: ECA5F02A  fadds f5, f5, f30
	ctx.f[5].f64 = ((ctx.f[5].f64 + ctx.f[30].f64) as f32) as f64;
	// 8258FC34: 7F7F5C2E  lfsx f27, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8258FC38: 83E10060  lwz r31, 0x60(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 8258FC3C: ED08D82A  fadds f8, f8, f27
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[27].f64) as f32) as f64;
	// 8258FC40: ECC6F82A  fadds f6, f6, f31
	ctx.f[6].f64 = ((ctx.f[6].f64 + ctx.f[31].f64) as f32) as f64;
	// 8258FC44: EC84E82A  fadds f4, f4, f29
	ctx.f[4].f64 = ((ctx.f[4].f64 + ctx.f[29].f64) as f32) as f64;
	// 8258FC48: EC63E02A  fadds f3, f3, f28
	ctx.f[3].f64 = ((ctx.f[3].f64 + ctx.f[28].f64) as f32) as f64;
	// 8258FC4C: 7C3F5C2E  lfsx f1, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8258FC50: 83E1005C  lwz r31, 0x5c(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8258FC54: ECE7082A  fadds f7, f7, f1
	ctx.f[7].f64 = ((ctx.f[7].f64 + ctx.f[1].f64) as f32) as f64;
	// 8258FC58: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC5C: 7D335D2E  stfsx f9, r19, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC60: EC42B82A  fadds f2, f2, f23
	ctx.f[2].f64 = ((ctx.f[2].f64 + ctx.f[23].f64) as f32) as f64;
	// 8258FC64: ED280032  fmuls f9, f8, f0
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC68: 7D325D2E  stfsx f9, r18, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[18].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC6C: ED270032  fmuls f9, f7, f0
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC70: 7D315D2E  stfsx f9, r17, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC74: ED260032  fmuls f9, f6, f0
	ctx.f[9].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC78: 7D305D2E  stfsx f9, r16, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC7C: ED250032  fmuls f9, f5, f0
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC80: 7D3F5D2E  stfsx f9, r31, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC84: 83E10058  lwz r31, 0x58(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8258FC88: ED240032  fmuls f9, f4, f0
	ctx.f[9].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC8C: 7D3F5D2E  stfsx f9, r31, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC90: 83E10050  lwz r31, 0x50(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8258FC94: ED230032  fmuls f9, f3, f0
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FC98: 7D3F5D2E  stfsx f9, r31, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FC9C: 83E10054  lwz r31, 0x54(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8258FCA0: ED220032  fmuls f9, f2, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 8258FCA4: 7D3F5D2E  stfsx f9, r31, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8258FCA8: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 8258FCAC: 2F0A0400  cmpwi cr6, r10, 0x400
	ctx.cr[6].compare_i32(ctx.r[10].s32, 1024, &mut ctx.xer);
	// 8258FCB0: 4198FD70  blt cr6, 0x8258fa20
	if ctx.cr[6].lt {
	pc = 0x8258FA20; continue 'dispatch;
	}
	// 8258FCB4: 816145E4  lwz r11, 0x45e4(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(17892 as u32) ) } as u64;
	// 8258FCB8: 83E145E4  lwz r31, 0x45e4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(17892 as u32) ) } as u64;
	// 8258FCBC: 3D4B0003  addis r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 196608;
	// 8258FCC0: 394A8E78  addi r10, r10, -0x7188
	ctx.r[10].s64 = ctx.r[10].s64 + -29064;
	// 8258FCC4: 91410090  stw r10, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[10].u32 ) };
	// 8258FCC8: 3D4B0003  addis r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 196608;
	// 8258FCCC: 3D6B0003  addis r11, r11, 3
	ctx.r[11].s64 = ctx.r[11].s64 + 196608;
	// 8258FCD0: 394A9690  addi r10, r10, -0x6970
	ctx.r[10].s64 = ctx.r[10].s64 + -26992;
	// 8258FCD4: 396B9EA8  addi r11, r11, -0x6158
	ctx.r[11].s64 = ctx.r[11].s64 + -24920;
	// 8258FCD8: 91410084  stw r10, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[10].u32 ) };
	// 8258FCDC: 91610164  stw r11, 0x164(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), ctx.r[11].u32 ) };
	// 8258FCE0: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 8258FCE4: 616B969C  ori r11, r11, 0x969c
	ctx.r[11].u64 = ctx.r[11].u64 | 38556;
	// 8258FCE8: 91610078  stw r11, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 8258FCEC: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 8258FCF0: 616B9EB0  ori r11, r11, 0x9eb0
	ctx.r[11].u64 = ctx.r[11].u64 | 40624;
	// 8258FCF4: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8258FCF8: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 8258FCFC: 616B9ED0  ori r11, r11, 0x9ed0
	ctx.r[11].u64 = ctx.r[11].u64 | 40656;
	// 8258FD00: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8258FD04: 3D600002  lis r11, 2
	ctx.r[11].s64 = 131072;
	// 8258FD08: 616B9EE4  ori r11, r11, 0x9ee4
	ctx.r[11].u64 = ctx.r[11].u64 | 40676;
	// 8258FD0C: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258FD10: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8258FD14: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 8258FD18: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD1C: 396B8E84  addi r11, r11, -0x717c
	ctx.r[11].s64 = ctx.r[11].s64 + -29052;
	// 8258FD20: 916100C0  stw r11, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 8258FD24: 82410090  lwz r18, 0x90(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 8258FD28: 3BD20010  addi r30, r18, 0x10
	ctx.r[30].s64 = ctx.r[18].s64 + 16;
	// 8258FD2C: 81610078  lwz r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 8258FD30: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258FD34: 916100B0  stw r11, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[11].u32 ) };
	// 8258FD38: 8161006C  lwz r11, 0x6c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8258FD3C: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258FD40: 916100C8  stw r11, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[11].u32 ) };
	// 8258FD44: 8161007C  lwz r11, 0x7c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 8258FD48: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258FD4C: 916100A8  stw r11, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[11].u32 ) };
	// 8258FD50: 81610074  lwz r11, 0x74(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 8258FD54: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 8258FD58: 916100B8  stw r11, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 8258FD5C: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD60: 396B9F04  addi r11, r11, -0x60fc
	ctx.r[11].s64 = ctx.r[11].s64 + -24828;
	// 8258FD64: 916100C4  stw r11, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[11].u32 ) };
	// 8258FD68: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD6C: 396BDF24  addi r11, r11, -0x20dc
	ctx.r[11].s64 = ctx.r[11].s64 + -8412;
	// 8258FD70: 916100BC  stw r11, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[11].u32 ) };
	// 8258FD74: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD78: 396B9F10  addi r11, r11, -0x60f0
	ctx.r[11].s64 = ctx.r[11].s64 + -24816;
	// 8258FD7C: 9161007C  stw r11, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 8258FD80: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD84: 396BDF40  addi r11, r11, -0x20c0
	ctx.r[11].s64 = ctx.r[11].s64 + -8384;
	// 8258FD88: 916100B4  stw r11, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[11].u32 ) };
	// 8258FD8C: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD90: 396BE758  addi r11, r11, -0x18a8
	ctx.r[11].s64 = ctx.r[11].s64 + -6312;
	// 8258FD94: 916100AC  stw r11, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[11].u32 ) };
	// 8258FD98: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FD9C: 396BEF6C  addi r11, r11, -0x1094
	ctx.r[11].s64 = ctx.r[11].s64 + -4244;
	// 8258FDA0: 91610100  stw r11, 0x100(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), ctx.r[11].u32 ) };
	// 8258FDA4: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDA8: 396BEF8C  addi r11, r11, -0x1074
	ctx.r[11].s64 = ctx.r[11].s64 + -4212;
	// 8258FDAC: 916100E4  stw r11, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[11].u32 ) };
	// 8258FDB0: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDB4: 396BEFA0  addi r11, r11, -0x1060
	ctx.r[11].s64 = ctx.r[11].s64 + -4192;
	// 8258FDB8: 916100E8  stw r11, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 8258FDBC: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDC0: 396BEFC0  addi r11, r11, -0x1040
	ctx.r[11].s64 = ctx.r[11].s64 + -4160;
	// 8258FDC4: 9161014C  stw r11, 0x14c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), ctx.r[11].u32 ) };
	// 8258FDC8: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDCC: 396B2FE0  addi r11, r11, 0x2fe0
	ctx.r[11].s64 = ctx.r[11].s64 + 12256;
	// 8258FDD0: 916100F0  stw r11, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[11].u32 ) };
	// 8258FDD4: 554B003E  slwi r11, r10, 0
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8258FDD8: 3BAB0010  addi r29, r11, 0x10
	ctx.r[29].s64 = ctx.r[11].s64 + 16;
	// 8258FDDC: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDE0: 396BEFCC  addi r11, r11, -0x1034
	ctx.r[11].s64 = ctx.r[11].s64 + -4148;
	// 8258FDE4: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 8258FDE8: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDEC: 396B2FFC  addi r11, r11, 0x2ffc
	ctx.r[11].s64 = ctx.r[11].s64 + 12284;
	// 8258FDF0: 9161016C  stw r11, 0x16c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), ctx.r[11].u32 ) };
	// 8258FDF4: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FDF8: 396B5018  addi r11, r11, 0x5018
	ctx.r[11].s64 = ctx.r[11].s64 + 20504;
	// 8258FDFC: 3D5F0003  addis r10, r31, 3
	ctx.r[10].s64 = ctx.r[31].s64 + 196608;
	// 8258FE00: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 8258FE04: 394ADF34  addi r10, r10, -0x20cc
	ctx.r[10].s64 = ctx.r[10].s64 + -8396;
	// 8258FE08: 3D1F0003  addis r8, r31, 3
	ctx.r[8].s64 = ctx.r[31].s64 + 196608;
	// 8258FE0C: 916100F8  stw r11, 0xf8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), ctx.r[11].u32 ) };
	// 8258FE10: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FE14: 3B8A0010  addi r28, r10, 0x10
	ctx.r[28].s64 = ctx.r[10].s64 + 16;
	// 8258FE18: 396B7030  addi r11, r11, 0x7030
	ctx.r[11].s64 = ctx.r[11].s64 + 28720;
	// 8258FE1C: 91410144  stw r10, 0x144(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), ctx.r[10].u32 ) };
	// 8258FE20: 3F3F0003  addis r25, r31, 3
	ctx.r[25].s64 = ctx.r[31].s64 + 196608;
	// 8258FE24: 3D5F0004  addis r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 262144;
	// 8258FE28: 3F1F0003  addis r24, r31, 3
	ctx.r[24].s64 = ctx.r[31].s64 + 196608;
	// 8258FE2C: 3929E74C  addi r9, r9, -0x18b4
	ctx.r[9].s64 = ctx.r[9].s64 + -6324;
	// 8258FE30: 91610154  stw r11, 0x154(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), ctx.r[11].u32 ) };
	// 8258FE34: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FE38: 3CFF0003  addis r7, r31, 3
	ctx.r[7].s64 = ctx.r[31].s64 + 196608;
	// 8258FE3C: 396B9048  addi r11, r11, -0x6fb8
	ctx.r[11].s64 = ctx.r[11].s64 + -28600;
	// 8258FE40: 39085008  addi r8, r8, 0x5008
	ctx.r[8].s64 = ctx.r[8].s64 + 20488;
	// 8258FE44: 394A00A8  addi r10, r10, 0xa8
	ctx.r[10].s64 = ctx.r[10].s64 + 168;
	// 8258FE48: 91210128  stw r9, 0x128(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), ctx.r[9].u32 ) };
	// 8258FE4C: 3B392FF0  addi r25, r25, 0x2ff0
	ctx.r[25].s64 = ctx.r[25].s64 + 12272;
	// 8258FE50: 3B187024  addi r24, r24, 0x7024
	ctx.r[24].s64 = ctx.r[24].s64 + 28708;
	// 8258FE54: 916100E0  stw r11, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[11].u32 ) };
	// 8258FE58: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FE5C: 38E79EFC  addi r7, r7, -0x6104
	ctx.r[7].s64 = ctx.r[7].s64 + -24836;
	// 8258FE60: 91010138  stw r8, 0x138(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), ctx.r[8].u32 ) };
	// 8258FE64: 396BA05C  addi r11, r11, -0x5fa4
	ctx.r[11].s64 = ctx.r[11].s64 + -24484;
	// 8258FE68: 91410098  stw r10, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[10].u32 ) };
	// 8258FE6C: 3CDF0003  addis r6, r31, 3
	ctx.r[6].s64 = ctx.r[31].s64 + 196608;
	// 8258FE70: 93210150  stw r25, 0x150(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[25].u32 ) };
	// 8258FE74: 3CBF0003  addis r5, r31, 3
	ctx.r[5].s64 = ctx.r[31].s64 + 196608;
	// 8258FE78: 93010158  stw r24, 0x158(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), ctx.r[24].u32 ) };
	// 8258FE7C: 3EDF0003  addis r22, r31, 3
	ctx.r[22].s64 = ctx.r[31].s64 + 196608;
	// 8258FE80: 3EBF0003  addis r21, r31, 3
	ctx.r[21].s64 = ctx.r[31].s64 + 196608;
	// 8258FE84: 91610174  stw r11, 0x174(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(372 as u32), ctx.r[11].u32 ) };
	// 8258FE88: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FE8C: 3C9F0003  addis r4, r31, 3
	ctx.r[4].s64 = ctx.r[31].s64 + 196608;
	// 8258FE90: 396BE078  addi r11, r11, -0x1f88
	ctx.r[11].s64 = ctx.r[11].s64 + -8072;
	// 8258FE94: 3C7F0004  addis r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 262144;
	// 8258FE98: 3EFF0004  addis r23, r31, 4
	ctx.r[23].s64 = ctx.r[31].s64 + 262144;
	// 8258FE9C: 38C69EC0  addi r6, r6, -0x6140
	ctx.r[6].s64 = ctx.r[6].s64 + -24896;
	// 8258FEA0: 38A5EF7C  addi r5, r5, -0x1084
	ctx.r[5].s64 = ctx.r[5].s64 + -4228;
	// 8258FEA4: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 8258FEA8: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FEAC: 3AD69EE0  addi r22, r22, -0x6120
	ctx.r[22].s64 = ctx.r[22].s64 + -24864;
	// 8258FEB0: 396BE09C  addi r11, r11, -0x1f64
	ctx.r[11].s64 = ctx.r[11].s64 + -8036;
	// 8258FEB4: 3AB5EF9C  addi r21, r21, -0x1064
	ctx.r[21].s64 = ctx.r[21].s64 + -4196;
	// 8258FEB8: 3884EFB8  addi r4, r4, -0x1048
	ctx.r[4].s64 = ctx.r[4].s64 + -4168;
	// 8258FEBC: 3B690010  addi r27, r9, 0x10
	ctx.r[27].s64 = ctx.r[9].s64 + 16;
	// 8258FEC0: 3863A054  addi r3, r3, -0x5fac
	ctx.r[3].s64 = ctx.r[3].s64 + -24492;
	// 8258FEC4: 91610108  stw r11, 0x108(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), ctx.r[11].u32 ) };
	// 8258FEC8: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FECC: 3AF7903C  addi r23, r23, -0x6fc4
	ctx.r[23].s64 = ctx.r[23].s64 + -28612;
	// 8258FED0: 396B00B8  addi r11, r11, 0xb8
	ctx.r[11].s64 = ctx.r[11].s64 + 184;
	// 8258FED4: 9161015C  stw r11, 0x15c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), ctx.r[11].u32 ) };
	// 8258FED8: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FEDC: 396B20D0  addi r11, r11, 0x20d0
	ctx.r[11].s64 = ctx.r[11].s64 + 8400;
	// 8258FEE0: 91610110  stw r11, 0x110(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 8258FEE4: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FEE8: 396B40E8  addi r11, r11, 0x40e8
	ctx.r[11].s64 = ctx.r[11].s64 + 16616;
	// 8258FEEC: 91610170  stw r11, 0x170(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), ctx.r[11].u32 ) };
	// 8258FEF0: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FEF4: 396B50FC  addi r11, r11, 0x50fc
	ctx.r[11].s64 = ctx.r[11].s64 + 20732;
	// 8258FEF8: 91610118  stw r11, 0x118(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[11].u32 ) };
	// 8258FEFC: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 8258FF00: 396B9118  addi r11, r11, -0x6ee8
	ctx.r[11].s64 = ctx.r[11].s64 + -28392;
	// 8258FF04: 91610078  stw r11, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 8258FF08: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FF0C: 396B5108  addi r11, r11, 0x5108
	ctx.r[11].s64 = ctx.r[11].s64 + 20744;
	// 8258FF10: 916100A4  stw r11, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[11].u32 ) };
	// 8258FF14: 3D7F0004  addis r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 262144;
	// 8258FF18: 396BA068  addi r11, r11, -0x5f98
	ctx.r[11].s64 = ctx.r[11].s64 + -24472;
	// 8258FF1C: 916100A0  stw r11, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 8258FF20: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FF24: 396BDF1C  addi r11, r11, -0x20e4
	ctx.r[11].s64 = ctx.r[11].s64 + -8420;
	// 8258FF28: 91610120  stw r11, 0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 8258FF2C: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 8258FF30: 396BEF64  addi r11, r11, -0x109c
	ctx.r[11].s64 = ctx.r[11].s64 + -4252;
	// 8258FF34: 91610148  stw r11, 0x148(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), ctx.r[11].u32 ) };
	// 8258FF38: 39670018  addi r11, r7, 0x18
	ctx.r[11].s64 = ctx.r[7].s64 + 24;
	// 8258FF3C: 3B480014  addi r26, r8, 0x14
	ctx.r[26].s64 = ctx.r[8].s64 + 20;
	// 8258FF40: 828100D4  lwz r20, 0xd4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) } as u64;
	// 8258FF44: 3D1F0004  addis r8, r31, 4
	ctx.r[8].s64 = ctx.r[31].s64 + 262144;
	// 8258FF48: 92E10140  stw r23, 0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[23].u32 ) };
	// 8258FF4C: 3D5F0004  addis r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 262144;
	// 8258FF50: 390850F4  addi r8, r8, 0x50f4
	ctx.r[8].s64 = ctx.r[8].s64 + 20724;
	// 8258FF54: 394AE074  addi r10, r10, -0x1f8c
	ctx.r[10].s64 = ctx.r[10].s64 + -8076;
	// 8258FF58: 3D3F0004  addis r9, r31, 4
	ctx.r[9].s64 = ctx.r[31].s64 + 262144;
	// 8258FF5C: 3A600100  li r19, 0x100
	ctx.r[19].s64 = 256;
	// 8258FF60: 392940DC  addi r9, r9, 0x40dc
	ctx.r[9].s64 = ctx.r[9].s64 + 16604;
	// 8258FF64: 9101010C  stw r8, 0x10c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(268 as u32), ctx.r[8].u32 ) };
	// 8258FF68: 3D1F0005  addis r8, r31, 5
	ctx.r[8].s64 = ctx.r[31].s64 + 327680;
	// 8258FF6C: 91410168  stw r10, 0x168(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), ctx.r[10].u32 ) };
	// 8258FF70: 3D5F0004  addis r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 262144;
	// 8258FF74: 39089114  addi r8, r8, -0x6eec
	ctx.r[8].s64 = ctx.r[8].s64 + -28396;
	// 8258FF78: 394AE090  addi r10, r10, -0x1f70
	ctx.r[10].s64 = ctx.r[10].s64 + -8048;
	// 8258FF7C: 92610070  stw r19, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[19].u32 ) };
	// 8258FF80: 91210054  stw r9, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[9].u32 ) };
	// 8258FF84: 3B390010  addi r25, r25, 0x10
	ctx.r[25].s64 = ctx.r[25].s64 + 16;
	// 8258FF88: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 8258FF8C: 3B180010  addi r24, r24, 0x10
	ctx.r[24].s64 = ctx.r[24].s64 + 16;
	// 8258FF90: 91010114  stw r8, 0x114(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), ctx.r[8].u32 ) };
	// 8258FF94: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8258FF98: 91410088  stw r10, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[10].u32 ) };
	// 8258FF9C: 3D5F0004  addis r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 262144;
	// 8258FFA0: 3AF70010  addi r23, r23, 0x10
	ctx.r[23].s64 = ctx.r[23].s64 + 16;
	// 8258FFA4: 394A20C4  addi r10, r10, 0x20c4
	ctx.r[10].s64 = ctx.r[10].s64 + 8388;
	// 8258FFA8: 91010050  stw r8, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u32 ) };
	// 8258FFAC: 810100CC  lwz r8, 0xcc(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 8258FFB0: 7E344050  subf r17, r20, r8
	ctx.r[17].s64 = ctx.r[8].s64 - ctx.r[20].s64;
	// 8258FFB4: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8258FFB8: 3D5F0003  addis r10, r31, 3
	ctx.r[10].s64 = ctx.r[31].s64 + 196608;
	// 8258FFBC: 394A2FD8  addi r10, r10, 0x2fd8
	ctx.r[10].s64 = ctx.r[10].s64 + 12248;
	// 8258FFC0: 92210064  stw r17, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[17].u32 ) };
	// 8258FFC4: 822100DC  lwz r17, 0xdc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) } as u64;
	// 8258FFC8: 7E348850  subf r17, r20, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[20].s64;
	// 8258FFCC: 91410130  stw r10, 0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[10].u32 ) };
	// 8258FFD0: 39440018  addi r10, r4, 0x18
	ctx.r[10].s64 = ctx.r[4].s64 + 24;
	// 8258FFD4: 9221005C  stw r17, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[17].u32 ) };
	// 8258FFD8: 822100D0  lwz r17, 0xd0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) } as u64;
	// 8258FFDC: 7E348850  subf r17, r20, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[20].s64;
	// 8258FFE0: 92210060  stw r17, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[17].u32 ) };
	// 8258FFE4: 822100D8  lwz r17, 0xd8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) } as u64;
	// 8258FFE8: 7E948850  subf r20, r20, r17
	ctx.r[20].s64 = ctx.r[17].s64 - ctx.r[20].s64;
	// 8258FFEC: 3E208200  lis r17, -0x7e00
	ctx.r[17].s64 = -2113929216;
	// 8258FFF0: 92810080  stw r20, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[20].u32 ) };
	// 8258FFF4: 3E80820D  lis r20, -0x7df3
	ctx.r[20].s64 = -2113077248;
	// 8258FFF8: C0111848  lfs f0, 0x1848(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(6216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8258FFFC: D00100CC  stfs f0, 0xcc(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), tmp.u32 ) };
	// 82590000: C2542068  lfs f18, 0x2068(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8296 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 82590004: 48000008  b 0x8259000c
	pc = 0x8259000C; continue 'dispatch;
	// 82590008: 82610070  lwz r19, 0x70(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 8259000C: 82810068  lwz r20, 0x68(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82590010: 569406FE  clrlwi r20, r20, 0x1b
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x0000001Fu64;
	// 82590014: 2F140000  cmpwi cr6, r20, 0
	ctx.cr[6].compare_i32(ctx.r[20].s32, 0, &mut ctx.xer);
	// 82590018: 409A0014  bne cr6, 0x8259002c
	if !ctx.cr[6].eq {
	pc = 0x8259002C; continue 'dispatch;
	}
	// 8259001C: 82810094  lwz r20, 0x94(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) } as u64;
	// 82590020: 7C13A22C  dcbt r19, r20
	// 82590024: 8281008C  lwz r20, 0x8c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 82590028: 7C13A22C  dcbt r19, r20
	// 8259002C: 81E1007C  lwz r15, 0x7c(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 82590030: 3A2115D0  addi r17, r1, 0x15d0
	ctx.r[17].s64 = ctx.r[1].s64 + 5584;
	// 82590034: 82810078  lwz r20, 0x78(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 82590038: C1120008  lfs f8, 8(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259003C: 82720000  lwz r19, 0(r18)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590040: C1D20004  lfs f14, 4(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(4 as u32) ) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 82590044: 8201005C  lwz r16, 0x5c(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82590048: 39C132F0  addi r14, r1, 0x32f0
	ctx.r[14].s64 = ctx.r[1].s64 + 13040;
	// 8259004C: C0AF0000  lfs f5, 0(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82590050: 81E10074  lwz r15, 0x74(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 82590054: C1B40000  lfs f13, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590058: 8281006C  lwz r20, 0x6c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8259005C: 7DE8842E  lfsx f15, r8, r16
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[16].u32)) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 82590060: 3A010180  addi r16, r1, 0x180
	ctx.r[16].s64 = ctx.r[1].s64 + 384;
	// 82590064: C08F0000  lfs f4, 0(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82590068: 81E100A0  lwz r15, 0xa0(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 8259006C: C1940000  lfs f12, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590070: 829E0000  lwz r20, 0(r30)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590074: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 82590078: C16F0000  lfs f11, 0(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259007C: 81E10050  lwz r15, 0x50(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82590080: 5692103A  slwi r18, r20, 2
	ctx.r[18].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[18].u64 = ctx.r[18].u32 as u64;
	// 82590084: 828100A4  lwz r20, 0xa4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) } as u64;
	// 82590088: 7D4F8C2E  lfsx f10, r15, r17
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[17].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259008C: 82210080  lwz r17, 0x80(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82590090: C0140000  lfs f0, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590094: 3A812EE0  addi r20, r1, 0x2ee0
	ctx.r[20].s64 = ctx.r[1].s64 + 12000;
	// 82590098: 7E314214  add r17, r17, r8
	ctx.r[17].u64 = ctx.r[17].u64 + ctx.r[8].u64;
	// 8259009C: EE2A002A  fadds f17, f10, f0
	ctx.f[17].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 825900A0: 7D2F842E  lfsx f9, r15, r16
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[16].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825900A4: ED29582A  fadds f9, f9, f11
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64;
	// 825900A8: 922100FC  stw r17, 0xfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(252 as u32), ctx.r[17].u32 ) };
	// 825900AC: 822100C0  lwz r17, 0xc0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 825900B0: C0F10000  lfs f7, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 825900B4: 822100B0  lwz r17, 0xb0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 825900B8: C3F10000  lfs f31, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 825900BC: 822100C8  lwz r17, 0xc8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 825900C0: C3D10000  lfs f30, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 825900C4: 822100A8  lwz r17, 0xa8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) } as u64;
	// 825900C8: C3B10000  lfs f29, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 825900CC: 822100B8  lwz r17, 0xb8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 825900D0: C3910000  lfs f28, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 825900D4: 822100C4  lwz r17, 0xc4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) } as u64;
	// 825900D8: C3710000  lfs f27, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 825900DC: 822100BC  lwz r17, 0xbc(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 825900E0: C0710000  lfs f3, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 825900E4: 822100B4  lwz r17, 0xb4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 825900E8: C3510000  lfs f26, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 825900EC: 822100AC  lwz r17, 0xac(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) } as u64;
	// 825900F0: C3310000  lfs f25, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 825900F4: 82210100  lwz r17, 0x100(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(256 as u32) ) } as u64;
	// 825900F8: C3110000  lfs f24, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 825900FC: 822100E4  lwz r17, 0xe4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) } as u64;
	// 82590100: C2F10000  lfs f23, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 82590104: 822100E8  lwz r17, 0xe8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) } as u64;
	// 82590108: C2D10000  lfs f22, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 8259010C: 8221014C  lwz r17, 0x14c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(332 as u32) ) } as u64;
	// 82590110: C2B10000  lfs f21, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 82590114: 822100F0  lwz r17, 0xf0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) } as u64;
	// 82590118: C0510000  lfs f2, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8259011C: 8221016C  lwz r17, 0x16c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(364 as u32) ) } as u64;
	// 82590120: C2910000  lfs f20, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 82590124: 822100F8  lwz r17, 0xf8(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) } as u64;
	// 82590128: C2710000  lfs f19, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 8259012C: 82210154  lwz r17, 0x154(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(340 as u32) ) } as u64;
	// 82590130: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590134: 822100E0  lwz r17, 0xe0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) } as u64;
	// 82590138: D0010160  stfs f0, 0x160(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 8259013C: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590140: 82210174  lwz r17, 0x174(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(372 as u32) ) } as u64;
	// 82590144: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82590148: C1710000  lfs f11, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259014C: 82210108  lwz r17, 0x108(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) } as u64;
	// 82590150: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590154: 8221015C  lwz r17, 0x15c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(348 as u32) ) } as u64;
	// 82590158: D001009C  stfs f0, 0x9c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 8259015C: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590160: 82210110  lwz r17, 0x110(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(272 as u32) ) } as u64;
	// 82590164: D00100EC  stfs f0, 0xec(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 82590168: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259016C: D0010104  stfs f0, 0x104(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 82590170: 82210170  lwz r17, 0x170(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(368 as u32) ) } as u64;
	// 82590174: EE09202A  fadds f16, f9, f4
	ctx.f[16].f64 = ((ctx.f[9].f64 + ctx.f[4].f64) as f32) as f64;
	// 82590178: 82010064  lwz r16, 0x64(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8259017C: EE31282A  fadds f17, f17, f5
	ctx.f[17].f64 = ((ctx.f[17].f64 + ctx.f[5].f64) as f32) as f64;
	// 82590180: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590184: 82210118  lwz r17, 0x118(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82590188: 7C30A42E  lfsx f1, r16, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8259018C: 82810060  lwz r20, 0x60(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82590190: D00100F4  stfs f0, 0xf4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), tmp.u32 ) };
	// 82590194: 7D50742E  lfsx f10, r16, r14
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[14].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590198: C0110000  lfs f0, 0(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259019C: EE1004B2  fmuls f16, f16, f18
	ctx.f[16].f64 = (((ctx.f[16].f64 * ctx.f[18].f64) as f32) as f64);
	// 825901A0: D001011C  stfs f0, 0x11c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(284 as u32), tmp.u32 ) };
	// 825901A4: EE3104B2  fmuls f17, f17, f18
	ctx.f[17].f64 = (((ctx.f[17].f64 * ctx.f[18].f64) as f32) as f64);
	// 825901A8: 7C14442E  lfsx f0, r20, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825901AC: 82810080  lwz r20, 0x80(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 825901B0: 7CD4442E  lfsx f6, r20, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 825901B4: 829E0000  lwz r20, 0(r30)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 825901B8: 7E93A050  subf r20, r19, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[19].s64;
	// 825901BC: 569405FE  clrlwi r20, r20, 0x17
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x000001FFu64;
	// 825901C0: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 825901C4: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 825901C8: 7D34F42E  lfsx f9, r20, r30
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[30].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825901CC: ED087A7A  fmadds f8, f8, f9, f15
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[15].f64) as f32) as f64);
	// 825901D0: ED08682A  fadds f8, f8, f13
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[13].f64) as f32) as f64;
	// 825901D4: ED08602A  fadds f8, f8, f12
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 825901D8: 7D12F52E  stfsx f8, r18, r30
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[18].u32.wrapping_add(ctx.r[30].u32), tmp.u32) };
	// 825901DC: 829E0000  lwz r20, 0(r30)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 825901E0: 82410090  lwz r18, 0x90(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 825901E4: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 825901E8: 569405FE  clrlwi r20, r20, 0x17
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x000001FFu64;
	// 825901EC: 929E0000  stw r20, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 825901F0: ED2E4A3A  fmadds f9, f14, f8, f9
	ctx.f[9].f64 = (((ctx.f[14].f64 * ctx.f[8].f64 + ctx.f[9].f64) as f32) as f64);
	// 825901F4: 82810084  lwz r20, 0x84(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 825901F8: D132000C  stfs f9, 0xc(r18)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 825901FC: 827D0000  lwz r19, 0(r29)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590200: ED2AF82A  fadds f9, f10, f31
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[31].f64) as f32) as f64;
	// 82590204: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590208: C1F40008  lfs f15, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 8259020C: C1D40004  lfs f14, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 82590210: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 82590214: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 82590218: 3A330002  addi r17, r19, 2
	ctx.r[17].s64 = ctx.r[19].s64 + 2;
	// 8259021C: 827D0000  lwz r19, 0(r29)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590220: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590224: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590228: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 8259022C: 7D11EC2E  lfsx f8, r17, r29
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[29].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590230: ECEF3A3A  fmadds f7, f15, f8, f7
	ctx.f[7].f64 = (((ctx.f[15].f64 * ctx.f[8].f64 + ctx.f[7].f64) as f32) as f64);
	// 82590234: 7CF3ED2E  stfsx f7, r19, r29
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[29].u32), tmp.u32) };
	// 82590238: 827D0000  lwz r19, 0(r29)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259023C: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590240: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 82590244: 927D0000  stw r19, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590248: ED0743BA  fmadds f8, f7, f14, f8
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[14].f64 + ctx.f[8].f64) as f32) as f64);
	// 8259024C: D114000C  stfs f8, 0xc(r20)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590250: 82810164  lwz r20, 0x164(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(356 as u32) ) } as u64;
	// 82590254: 3A74000C  addi r19, r20, 0xc
	ctx.r[19].s64 = ctx.r[20].s64 + 12;
	// 82590258: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259025C: C1140004  lfs f8, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590260: 563107FE  clrlwi r17, r17, 0x1f
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 82590264: C0F30004  lfs f7, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82590268: 3A310004  addi r17, r17, 4
	ctx.r[17].s64 = ctx.r[17].s64 + 4;
	// 8259026C: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590270: 7FF1A42E  lfsx f31, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82590274: D0F30008  stfs f7, 8(r19)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590278: ED1F4A3A  fmadds f8, f31, f8, f9
	ctx.f[8].f64 = (((ctx.f[31].f64 * ctx.f[8].f64 + ctx.f[9].f64) as f32) as f64);
	// 8259027C: D1330004  stfs f9, 4(r19)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590280: D1140008  stfs f8, 8(r20)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590284: 82860000  lwz r20, 0(r6)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590288: C0E6000C  lfs f7, 0xc(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8259028C: 569307FE  clrlwi r19, r20, 0x1f
	ctx.r[19].u64 = ctx.r[20].u32 as u64 & 0x00000001u64;
	// 82590290: C1060008  lfs f8, 8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590294: 3A860014  addi r20, r6, 0x14
	ctx.r[20].s64 = ctx.r[6].s64 + 20;
	// 82590298: C3E60004  lfs f31, 4(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8259029C: 3A730006  addi r19, r19, 6
	ctx.r[19].s64 = ctx.r[19].s64 + 6;
	// 825902A0: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825902A4: C1F40004  lfs f15, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 825902A8: 7D33342E  lfsx f9, r19, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825902AC: D1F40008  stfs f15, 8(r20)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825902B0: ECE70272  fmuls f7, f7, f9
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 825902B4: ED28F27A  fmadds f9, f8, f9, f30
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[30].f64) as f32) as f64);
	// 825902B8: D1340004  stfs f9, 4(r20)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825902BC: 3A960010  addi r20, r22, 0x10
	ctx.r[20].s64 = ctx.r[22].s64 + 16;
	// 825902C0: ED8D6028  fsubs f12, f13, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 825902C4: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 825902C8: ED293FFA  fmadds f9, f9, f31, f7
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[31].f64 + ctx.f[7].f64) as f32) as f64);
	// 825902CC: D1260010  stfs f9, 0x10(r6)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 825902D0: 82760000  lwz r19, 0(r22)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 825902D4: C136000C  lfs f9, 0xc(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825902D8: C1140004  lfs f8, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825902DC: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 825902E0: 3A730005  addi r19, r19, 5
	ctx.r[19].s64 = ctx.r[19].s64 + 5;
	// 825902E4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825902E8: 7CF3B42E  lfsx f7, r19, r22
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[22].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 825902EC: ED27EA7A  fmadds f9, f7, f9, f29
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[9].f64 + ctx.f[29].f64) as f32) as f64);
	// 825902F0: D1340004  stfs f9, 4(r20)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825902F4: D1140008  stfs f8, 8(r20)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825902F8: C1160008  lfs f8, 8(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825902FC: ED280272  fmuls f9, f8, f9
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[9].f64) as f32) as f64);
	// 82590300: D1360004  stfs f9, 4(r22)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590304: 828B0000  lwz r20, 0(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590308: C1070004  lfs f8, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259030C: 8267000C  lwz r19, 0xc(r7)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 82590310: C0E70010  lfs f7, 0x10(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82590314: 7E91A378  mr r17, r20
	ctx.r[17].u64 = ctx.r[20].u64;
	// 82590318: 7E93A050  subf r20, r19, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[19].s64;
	// 8259031C: 82670000  lwz r19, 0(r7)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590320: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590324: 7E738850  subf r19, r19, r17
	ctx.r[19].s64 = ctx.r[17].s64 - ctx.r[19].s64;
	// 82590328: 3A340002  addi r17, r20, 2
	ctx.r[17].s64 = ctx.r[20].s64 + 2;
	// 8259032C: 5674053E  clrlwi r20, r19, 0x14
	ctx.r[20].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 82590330: 5633103A  slwi r19, r17, 2
	ctx.r[19].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590334: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 82590338: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 8259033C: 7D335C2E  lfsx f9, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82590340: ECE901F2  fmuls f7, f9, f7
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[7].f64) as f32) as f64);
	// 82590344: C12100CC  lfs f9, 0xcc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82590348: EFFC0272  fmuls f31, f28, f9
	ctx.f[31].f64 = (((ctx.f[28].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259034C: 7DB45C2E  lfsx f13, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590350: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 82590354: D1A70008  stfs f13, 8(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590358: D0E70014  stfs f7, 0x14(r7)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259035C: 828B0000  lwz r20, 0(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590360: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 82590364: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82590368: 7FF45D2E  stfsx f31, r20, r11
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 8259036C: 828B0000  lwz r20, 0(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590370: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 82590374: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590378: 928B0000  stw r20, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 8259037C: 82810120  lwz r20, 0x120(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(288 as u32) ) } as u64;
	// 82590380: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590384: C1B40004  lfs f13, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590388: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 8259038C: 3A730004  addi r19, r19, 4
	ctx.r[19].s64 = ctx.r[19].s64 + 4;
	// 82590390: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590394: 7D13A42E  lfsx f8, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590398: EDA80372  fmuls f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259039C: D1B40008  stfs f13, 8(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825903A0: 3A94000C  addi r20, r20, 0xc
	ctx.r[20].s64 = ctx.r[20].s64 + 12;
	// 825903A4: C1B40004  lfs f13, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825903A8: D1B40008  stfs f13, 8(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825903AC: D3740004  stfs f27, 4(r20)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825903B0: 827C0000  lwz r19, 0(r28)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 825903B4: 82810144  lwz r20, 0x144(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(324 as u32) ) } as u64;
	// 825903B8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825903BC: 566E103A  slwi r14, r19, 2
	ctx.r[14].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 825903C0: 827C0000  lwz r19, 0(r28)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 825903C4: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825903C8: C1140008  lfs f8, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825903CC: C0F40004  lfs f7, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 825903D0: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 825903D4: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 825903D8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825903DC: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825903E0: 7DB3E42E  lfsx f13, r19, r28
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[28].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825903E4: ED88637A  fmadds f12, f8, f13, f12
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 825903E8: ED8CF02A  fadds f12, f12, f30
	ctx.f[12].f64 = ((ctx.f[12].f64 + ctx.f[30].f64) as f32) as f64;
	// 825903EC: 7D8EE52E  stfsx f12, r14, r28
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[28].u32), tmp.u32) };
	// 825903F0: 827C0000  lwz r19, 0(r28)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 825903F4: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 825903F8: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 825903FC: EDAC69FA  fmadds f13, f12, f7, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64);
	// 82590400: ED360272  fmuls f9, f22, f9
	ctx.f[9].f64 = (((ctx.f[22].f64 * ctx.f[9].f64) as f32) as f64);
	// 82590404: 927C0000  stw r19, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590408: D1B4000C  stfs f13, 0xc(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259040C: 82810128  lwz r20, 0x128(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(296 as u32) ) } as u64;
	// 82590410: 823B0000  lwz r17, 0(r27)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590414: 7E338B78  mr r19, r17
	ctx.r[19].u64 = ctx.r[17].u64;
	// 82590418: 81D40000  lwz r14, 0(r20)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259041C: C1940008  lfs f12, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590420: C1140004  lfs f8, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590424: 7E2E8850  subf r17, r14, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 82590428: 39D30002  addi r14, r19, 2
	ctx.r[14].s64 = ctx.r[19].s64 + 2;
	// 8259042C: 563305FE  clrlwi r19, r17, 0x17
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x000001FFu64;
	// 82590430: 55D1103A  slwi r17, r14, 2
	ctx.r[17].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590434: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590438: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 8259043C: 7DB3DC2E  lfsx f13, r19, r27
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[27].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590440: ED8CD37A  fmadds f12, f12, f13, f26
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[26].f64) as f32) as f64);
	// 82590444: 7D91DD2E  stfsx f12, r17, r27
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[27].u32), tmp.u32) };
	// 82590448: 827B0000  lwz r19, 0(r27)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259044C: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590450: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 82590454: 927B0000  stw r19, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590458: ED8C6A3A  fmadds f12, f12, f8, f13
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[8].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259045C: D194000C  stfs f12, 0xc(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590460: 82810148  lwz r20, 0x148(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(328 as u32) ) } as u64;
	// 82590464: EDA1C82A  fadds f13, f1, f25
	ctx.f[13].f64 = ((ctx.f[1].f64 + ctx.f[25].f64) as f32) as f64;
	// 82590468: 3A74000C  addi r19, r20, 0xc
	ctx.r[19].s64 = ctx.r[20].s64 + 12;
	// 8259046C: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590470: C1940004  lfs f12, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590474: 563107FE  clrlwi r17, r17, 0x1f
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 82590478: C1130004  lfs f8, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259047C: 3A310004  addi r17, r17, 4
	ctx.r[17].s64 = ctx.r[17].s64 + 4;
	// 82590480: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590484: 7CF1A42E  lfsx f7, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82590488: D1B30004  stfs f13, 4(r19)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259048C: ED876B3A  fmadds f12, f7, f12, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 82590490: D1130008  stfs f8, 8(r19)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590494: D1940008  stfs f12, 8(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590498: 82850000  lwz r20, 0(r5)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259049C: C1850008  lfs f12, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825904A0: 569307FE  clrlwi r19, r20, 0x1f
	ctx.r[19].u64 = ctx.r[20].u32 as u64 & 0x00000001u64;
	// 825904A4: C1050004  lfs f8, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825904A8: 3A850014  addi r20, r5, 0x14
	ctx.r[20].s64 = ctx.r[5].s64 + 20;
	// 825904AC: C0E5000C  lfs f7, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 825904B0: 3A730006  addi r19, r19, 6
	ctx.r[19].s64 = ctx.r[19].s64 + 6;
	// 825904B4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825904B8: C3F40004  lfs f31, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 825904BC: 7DB32C2E  lfsx f13, r19, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825904C0: ED8CC37A  fmadds f12, f12, f13, f24
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[24].f64) as f32) as f64);
	// 825904C4: D3F40008  stfs f31, 8(r20)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825904C8: D1940004  stfs f12, 4(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825904CC: 3A950010  addi r20, r21, 0x10
	ctx.r[20].s64 = ctx.r[21].s64 + 16;
	// 825904D0: ED0C0232  fmuls f8, f12, f8
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 825904D4: EDAD41FA  fmadds f13, f13, f7, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[8].f64) as f32) as f64);
	// 825904D8: D1A50010  stfs f13, 0x10(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 825904DC: 82750000  lwz r19, 0(r21)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 825904E0: C1B5000C  lfs f13, 0xc(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825904E4: C1940004  lfs f12, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825904E8: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 825904EC: 3A730005  addi r19, r19, 5
	ctx.r[19].s64 = ctx.r[19].s64 + 5;
	// 825904F0: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825904F4: 7D13AC2E  lfsx f8, r19, r21
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[21].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825904F8: EDA8BB7A  fmadds f13, f8, f13, f23
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64 + ctx.f[23].f64) as f32) as f64);
	// 825904FC: D1B40004  stfs f13, 4(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590500: D1940008  stfs f12, 8(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590504: C1950008  lfs f12, 8(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590508: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259050C: D1B50004  stfs f13, 4(r21)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590510: 828A0000  lwz r20, 0(r10)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590514: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590518: 8264000C  lwz r19, 0xc(r4)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 8259051C: C1040010  lfs f8, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590520: 7E91A378  mr r17, r20
	ctx.r[17].u64 = ctx.r[20].u64;
	// 82590524: 7E93A050  subf r20, r19, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[19].s64;
	// 82590528: 82640000  lwz r19, 0(r4)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259052C: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590530: 7E738850  subf r19, r19, r17
	ctx.r[19].s64 = ctx.r[17].s64 - ctx.r[19].s64;
	// 82590534: 3A340002  addi r17, r20, 2
	ctx.r[17].s64 = ctx.r[20].s64 + 2;
	// 82590538: 5674053E  clrlwi r20, r19, 0x14
	ctx.r[20].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 8259053C: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 82590540: 5633103A  slwi r19, r17, 2
	ctx.r[19].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590544: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82590548: 7DB3542E  lfsx f13, r19, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259054C: 7CF4542E  lfsx f7, r20, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82590550: EDA80372  fmuls f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82590554: ED870332  fmuls f12, f7, f12
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 82590558: D1A40014  stfs f13, 0x14(r4)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259055C: D1840008  stfs f12, 8(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590560: 828A0000  lwz r20, 0(r10)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590564: EDA0A02A  fadds f13, f0, f20
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[20].f64) as f32) as f64;
	// 82590568: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 8259056C: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82590570: 7D34552E  stfsx f9, r20, r10
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82590574: 828A0000  lwz r20, 0(r10)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590578: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 8259057C: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590580: 928A0000  stw r20, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 82590584: 82810130  lwz r20, 0x130(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 82590588: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259058C: C1940004  lfs f12, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590590: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 82590594: 3A730004  addi r19, r19, 4
	ctx.r[19].s64 = ctx.r[19].s64 + 4;
	// 82590598: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 8259059C: 7D33A42E  lfsx f9, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825905A0: ED890332  fmuls f12, f9, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 825905A4: D1940008  stfs f12, 8(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825905A8: 3A94000C  addi r20, r20, 0xc
	ctx.r[20].s64 = ctx.r[20].s64 + 12;
	// 825905AC: C1940004  lfs f12, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825905B0: D1940008  stfs f12, 8(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825905B4: D2B40004  stfs f21, 4(r20)
	tmp.f32 = (ctx.f[21].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825905B8: 82790000  lwz r19, 0(r25)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 825905BC: 82810150  lwz r20, 0x150(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(336 as u32) ) } as u64;
	// 825905C0: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825905C4: 566E103A  slwi r14, r19, 2
	ctx.r[14].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 825905C8: 82790000  lwz r19, 0(r25)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 825905CC: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825905D0: C1340008  lfs f9, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825905D4: C1140004  lfs f8, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 825905D8: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 825905DC: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 825905E0: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825905E4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825905E8: 7D93CC2E  lfsx f12, r19, r25
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[25].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825905EC: ED2C327A  fmadds f9, f12, f9, f6
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[9].f64 + ctx.f[6].f64) as f32) as f64);
	// 825905F0: ED29102A  fadds f9, f9, f2
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[2].f64) as f32) as f64;
	// 825905F4: ED29182A  fadds f9, f9, f3
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[3].f64) as f32) as f64;
	// 825905F8: 7D2ECD2E  stfsx f9, r14, r25
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[25].u32), tmp.u32) };
	// 825905FC: 82790000  lwz r19, 0(r25)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590600: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590604: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 82590608: 92790000  stw r19, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 8259060C: ED89623A  fmadds f12, f9, f8, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64);
	// 82590610: D194000C  stfs f12, 0xc(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590614: 82810138  lwz r20, 0x138(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) } as u64;
	// 82590618: 823A0000  lwz r17, 0(r26)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259061C: 7E338B78  mr r19, r17
	ctx.r[19].u64 = ctx.r[17].u64;
	// 82590620: 81D40000  lwz r14, 0(r20)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590624: C134000C  lfs f9, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82590628: C1140004  lfs f8, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259062C: 7E2E8850  subf r17, r14, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 82590630: C0F40008  lfs f7, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82590634: 39D30002  addi r14, r19, 2
	ctx.r[14].s64 = ctx.r[19].s64 + 2;
	// 82590638: 5633057E  clrlwi r19, r17, 0x15
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 8259063C: 55D1103A  slwi r17, r14, 2
	ctx.r[17].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590640: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590644: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590648: 7D93D42E  lfsx f12, r19, r26
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[26].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259064C: ED2C0272  fmuls f9, f12, f9
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82590650: ED284B7A  fmadds f9, f8, f13, f9
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64);
	// 82590654: EDAC69FA  fmadds f13, f12, f7, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64);
	// 82590658: 7DB1D52E  stfsx f13, r17, r26
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[26].u32), tmp.u32) };
	// 8259065C: 827A0000  lwz r19, 0(r26)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590660: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590664: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 82590668: 927A0000  stw r19, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 8259066C: D1340010  stfs f9, 0x10(r20)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82590670: 82810158  lwz r20, 0x158(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(344 as u32) ) } as u64;
	// 82590674: 82380000  lwz r17, 0(r24)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590678: C1940008  lfs f12, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259067C: 81D40000  lwz r14, 0(r20)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590680: 7E338B78  mr r19, r17
	ctx.r[19].u64 = ctx.r[17].u64;
	// 82590684: C1340004  lfs f9, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82590688: 7E2E8850  subf r17, r14, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 8259068C: C1010160  lfs f8, 0x160(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(352 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82590690: 39D30002  addi r14, r19, 2
	ctx.r[14].s64 = ctx.r[19].s64 + 2;
	// 82590694: 5633057E  clrlwi r19, r17, 0x15
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 82590698: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 8259069C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825906A0: 7DB3C42E  lfsx f13, r19, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825906A4: 55D3103A  slwi r19, r14, 2
	ctx.r[19].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825906A8: ED8D9B3A  fmadds f12, f13, f12, f19
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[19].f64) as f32) as f64);
	// 825906AC: 7D93C52E  stfsx f12, r19, r24
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[24].u32), tmp.u32) };
	// 825906B0: 82780000  lwz r19, 0(r24)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) } as u64;
	// 825906B4: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 825906B8: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 825906BC: EDAC6A7A  fmadds f13, f12, f9, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64);
	// 825906C0: C1210050  lfs f9, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825906C4: ED4A482A  fadds f10, f10, f9
	ctx.f[10].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 825906C8: 92780000  stw r19, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 825906CC: D1B4000C  stfs f13, 0xc(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 825906D0: 82770000  lwz r19, 0(r23)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 825906D4: 82810140  lwz r20, 0x140(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(320 as u32) ) } as u64;
	// 825906D8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825906DC: 566E103A  slwi r14, r19, 2
	ctx.r[14].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 825906E0: 82770000  lwz r19, 0(r23)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 825906E4: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825906E8: C1940008  lfs f12, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825906EC: C1340004  lfs f9, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825906F0: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 825906F4: 567305BE  clrlwi r19, r19, 0x16
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000003FFu64;
	// 825906F8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825906FC: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590700: 7DB3BC2E  lfsx f13, r19, r23
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[23].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590704: ED8D033A  fmadds f12, f13, f12, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82590708: ED8C402A  fadds f12, f12, f8
	ctx.f[12].f64 = ((ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259070C: 7D8EBD2E  stfsx f12, r14, r23
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[23].u32), tmp.u32) };
	// 82590710: 82770000  lwz r19, 0(r23)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590714: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590718: 567305BE  clrlwi r19, r19, 0x16
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000003FFu64;
	// 8259071C: 92770000  stw r19, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590720: EDAC6A7A  fmadds f13, f12, f9, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64);
	// 82590724: D1B4000C  stfs f13, 0xc(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590728: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259072C: 8263000C  lwz r19, 0xc(r3)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82590730: C1230010  lfs f9, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82590734: 7E91A378  mr r17, r20
	ctx.r[17].u64 = ctx.r[20].u64;
	// 82590738: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259073C: 7E93A050  subf r20, r19, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[19].s64;
	// 82590740: 82630000  lwz r19, 0(r3)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590744: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590748: 7E738850  subf r19, r19, r17
	ctx.r[19].s64 = ctx.r[17].s64 - ctx.r[19].s64;
	// 8259074C: 3A340002  addi r17, r20, 2
	ctx.r[17].s64 = ctx.r[20].s64 + 2;
	// 82590750: 5674053E  clrlwi r20, r19, 0x14
	ctx.r[20].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 82590754: 5633103A  slwi r19, r17, 2
	ctx.r[19].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590758: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 8259075C: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82590760: 7DB34C2E  lfsx f13, r19, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590764: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 82590768: 7D144C2E  lfsx f8, r20, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259076C: ED880332  fmuls f12, f8, f12
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 82590770: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82590774: D1830008  stfs f12, 8(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590778: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259077C: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 82590780: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82590784: 7D544D2E  stfsx f10, r20, r9
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82590788: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259078C: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 82590790: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 82590794: 92890000  stw r20, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 82590798: 82810168  lwz r20, 0x168(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(360 as u32) ) } as u64;
	// 8259079C: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825907A0: C1B40008  lfs f13, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825907A4: C194000C  lfs f12, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825907A8: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 825907AC: 567107FE  clrlwi r17, r19, 0x1f
	ctx.r[17].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 825907B0: 3A740010  addi r19, r20, 0x10
	ctx.r[19].s64 = ctx.r[20].s64 + 16;
	// 825907B4: 3A310005  addi r17, r17, 5
	ctx.r[17].s64 = ctx.r[17].s64 + 5;
	// 825907B8: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 825907BC: C1530004  lfs f10, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 825907C0: 7D31A42E  lfsx f9, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 825907C4: D1530008  stfs f10, 8(r19)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 825907C8: EDA96B3A  fmadds f13, f9, f12, f13
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 825907CC: D1730004  stfs f11, 4(r19)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825907D0: D1B40004  stfs f13, 4(r20)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 825907D4: 82810068  lwz r20, 0x68(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 825907D8: 569406FE  clrlwi r20, r20, 0x1b
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x0000001Fu64;
	// 825907DC: 2F140000  cmpwi cr6, r20, 0
	ctx.cr[6].compare_i32(ctx.r[20].s32, 0, &mut ctx.xer);
	// 825907E0: 409A0010  bne cr6, 0x825907f0
	if !ctx.cr[6].eq {
	pc = 0x825907F0; continue 'dispatch;
	}
	// 825907E4: 82810070  lwz r20, 0x70(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 825907E8: 3A940080  addi r20, r20, 0x80
	ctx.r[20].s64 = ctx.r[20].s64 + 128;
	// 825907EC: 92810070  stw r20, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[20].u32 ) };
	// 825907F0: 82810088  lwz r20, 0x88(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 825907F4: ED621828  fsubs f11, f2, f3
	ctx.f[11].f64 = (((ctx.f[2].f64 - ctx.f[3].f64) as f32) as f64);
	// 825907F8: C1A1009C  lfs f13, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825907FC: EDA6682A  fadds f13, f6, f13
	ctx.f[13].f64 = ((ctx.f[6].f64 + ctx.f[13].f64) as f32) as f64;
	// 82590800: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590804: C1540008  lfs f10, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590808: C1340004  lfs f9, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259080C: 3A940010  addi r20, r20, 0x10
	ctx.r[20].s64 = ctx.r[20].s64 + 16;
	// 82590810: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590814: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590818: 566E103A  slwi r14, r19, 2
	ctx.r[14].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 8259081C: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590820: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 82590824: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 82590828: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 8259082C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590830: 7D93A42E  lfsx f12, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590834: ED6C5ABA  fmadds f11, f12, f10, f11
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 82590838: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259083C: 7C0EA52E  stfsx f0, r14, r20
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 82590840: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590844: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590848: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 8259084C: 92740000  stw r19, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590850: EC00627A  fmadds f0, f0, f9, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64);
	// 82590854: 82810088  lwz r20, 0x88(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 82590858: 82610098  lwz r19, 0x98(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) } as u64;
	// 8259085C: D014000C  stfs f0, 0xc(r20)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590860: 3A930014  addi r20, r19, 0x14
	ctx.r[20].s64 = ctx.r[19].s64 + 20;
	// 82590864: 81D30000  lwz r14, 0(r19)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590868: C193000C  lfs f12, 0xc(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259086C: C1530008  lfs f10, 8(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590870: C1730004  lfs f11, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82590874: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590878: 7DCE8850  subf r14, r14, r17
	ctx.r[14].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 8259087C: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 82590880: 9221009C  stw r17, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[17].u32 ) };
	// 82590884: 55D1057E  clrlwi r17, r14, 0x15
	ctx.r[17].u64 = ctx.r[14].u32 as u64 & 0x000007FFu64;
	// 82590888: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 8259088C: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590890: 7C11A42E  lfsx f0, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590894: ED800332  fmuls f12, f0, f12
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82590898: EC006ABA  fmadds f0, f0, f10, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259089C: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 825908A0: C16100EC  lfs f11, 0xec(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(236 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825908A4: 81C1009C  lwz r14, 0x9c(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 825908A8: 55CE103A  slwi r14, r14, 2
	ctx.r[14].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 825908AC: 7C0EA52E  stfsx f0, r14, r20
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 825908B0: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825908B4: 3A310001  addi r17, r17, 1
	ctx.r[17].s64 = ctx.r[17].s64 + 1;
	// 825908B8: 5631057E  clrlwi r17, r17, 0x15
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 825908BC: 92340000  stw r17, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[17].u32 ) };
	// 825908C0: D1930010  stfs f12, 0x10(r19)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 825908C4: 82610058  lwz r19, 0x58(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 825908C8: 3A930010  addi r20, r19, 0x10
	ctx.r[20].s64 = ctx.r[19].s64 + 16;
	// 825908CC: 81D30000  lwz r14, 0(r19)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 825908D0: C1B30008  lfs f13, 8(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825908D4: C1930004  lfs f12, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825908D8: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825908DC: 7E338B78  mr r19, r17
	ctx.r[19].u64 = ctx.r[17].u64;
	// 825908E0: 7E2E8850  subf r17, r14, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 825908E4: 39D30002  addi r14, r19, 2
	ctx.r[14].s64 = ctx.r[19].s64 + 2;
	// 825908E8: 5633057E  clrlwi r19, r17, 0x15
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 825908EC: 55D1103A  slwi r17, r14, 2
	ctx.r[17].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 825908F0: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 825908F4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 825908F8: 7C13A42E  lfsx f0, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825908FC: EDAD583A  fmadds f13, f13, f0, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 + ctx.f[11].f64) as f32) as f64);
	// 82590900: 7DB1A52E  stfsx f13, r17, r20
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 82590904: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590908: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 8259090C: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 82590910: 92740000  stw r19, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590914: EC0D033A  fmadds f0, f13, f12, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82590918: 82810058  lwz r20, 0x58(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8259091C: 82610054  lwz r19, 0x54(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82590920: D014000C  stfs f0, 0xc(r20)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82590924: 3A930010  addi r20, r19, 0x10
	ctx.r[20].s64 = ctx.r[19].s64 + 16;
	// 82590928: 81D30000  lwz r14, 0(r19)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259092C: C1B30008  lfs f13, 8(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590930: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590934: C1930004  lfs f12, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590938: 7E6E8850  subf r19, r14, r17
	ctx.r[19].s64 = ctx.r[17].s64 - ctx.r[14].s64;
	// 8259093C: C00100F4  lfs f0, 0xf4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(244 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590940: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 82590944: 567305BE  clrlwi r19, r19, 0x16
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000003FFu64;
	// 82590948: ED61002A  fadds f11, f1, f0
	ctx.f[11].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259094C: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590950: C1410104  lfs f10, 0x104(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(260 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590954: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590958: 81C1005C  lwz r14, 0x5c(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8259095C: 3A100004  addi r16, r16, 4
	ctx.r[16].s64 = ctx.r[16].s64 + 4;
	// 82590960: D2080000  stfs f16, 0(r8)
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82590964: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590968: 7E28752E  stfsx f17, r8, r14
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[14].u32), tmp.u32) };
	// 8259096C: 81C10060  lwz r14, 0x60(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82590970: 92010064  stw r16, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[16].u32 ) };
	// 82590974: 7C13A42E  lfsx f0, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590978: 82010068  lwz r16, 0x68(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 8259097C: EDA0337A  fmadds f13, f0, f13, f6
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[6].f64) as f32) as f64);
	// 82590980: 3A100001  addi r16, r16, 1
	ctx.r[16].s64 = ctx.r[16].s64 + 1;
	// 82590984: 7CAE452E  stfsx f5, r14, r8
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82590988: 81C100FC  lwz r14, 0xfc(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(252 as u32) ) } as u64;
	// 8259098C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 82590990: 92010068  stw r16, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[16].u32 ) };
	// 82590994: D08E0000  stfs f4, 0(r14)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82590998: EDAD502A  fadds f13, f13, f10
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259099C: 7DB1A52E  stfsx f13, r17, r20
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 825909A0: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825909A4: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 825909A8: 567305BE  clrlwi r19, r19, 0x16
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000003FFu64;
	// 825909AC: 92740000  stw r19, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 825909B0: EC0D033A  fmadds f0, f13, f12, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 825909B4: 82810054  lwz r20, 0x54(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 825909B8: 8261010C  lwz r19, 0x10c(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(268 as u32) ) } as u64;
	// 825909BC: D014000C  stfs f0, 0xc(r20)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 825909C0: 3A930018  addi r20, r19, 0x18
	ctx.r[20].s64 = ctx.r[19].s64 + 24;
	// 825909C4: 8213000C  lwz r16, 0xc(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(12 as u32) ) } as u64;
	// 825909C8: C1930010  lfs f12, 0x10(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825909CC: C1B30004  lfs f13, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825909D0: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 825909D4: 7E2E8B78  mr r14, r17
	ctx.r[14].u64 = ctx.r[17].u64;
	// 825909D8: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 825909DC: 82130000  lwz r16, 0(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 825909E0: 5631053E  clrlwi r17, r17, 0x14
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000FFFu64;
	// 825909E4: 7E107050  subf r16, r16, r14
	ctx.r[16].s64 = ctx.r[14].s64 - ctx.r[16].s64;
	// 825909E8: 39D10002  addi r14, r17, 2
	ctx.r[14].s64 = ctx.r[17].s64 + 2;
	// 825909EC: 5611053E  clrlwi r17, r16, 0x14
	ctx.r[17].u64 = ctx.r[16].u32 as u64 & 0x00000FFFu64;
	// 825909F0: 55D0103A  slwi r16, r14, 2
	ctx.r[16].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[16].u64 = ctx.r[16].u32 as u64;
	// 825909F4: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 825909F8: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 825909FC: 7C10A42E  lfsx f0, r16, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590A00: EC000332  fmuls f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82590A04: 7D51A42E  lfsx f10, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590A08: EDAA0372  fmuls f13, f10, f13
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 82590A0C: D0130014  stfs f0, 0x14(r19)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82590A10: D1B30008  stfs f13, 8(r19)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590A14: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590A18: C1A1011C  lfs f13, 0x11c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(284 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82590A1C: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 82590A20: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 82590A24: 7D73A52E  stfsx f11, r19, r20
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 82590A28: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590A2C: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 82590A30: 5673053E  clrlwi r19, r19, 0x14
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 82590A34: 92740000  stw r19, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82590A38: 82810114  lwz r20, 0x114(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(276 as u32) ) } as u64;
	// 82590A3C: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590A40: C0140008  lfs f0, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82590A44: EC000372  fmuls f0, f0, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82590A48: C194000C  lfs f12, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82590A4C: 567107FE  clrlwi r17, r19, 0x1f
	ctx.r[17].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 82590A50: 3A740010  addi r19, r20, 0x10
	ctx.r[19].s64 = ctx.r[20].s64 + 16;
	// 82590A54: 3A310005  addi r17, r17, 5
	ctx.r[17].s64 = ctx.r[17].s64 + 5;
	// 82590A58: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82590A5C: C1730004  lfs f11, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82590A60: 7D51A42E  lfsx f10, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82590A64: D1730008  stfs f11, 8(r19)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82590A68: EC0A033A  fmadds f0, f10, f12, f0
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82590A6C: D1B30004  stfs f13, 4(r19)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590A70: D0140004  stfs f0, 4(r20)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82590A74: 3A8F0004  addi r20, r15, 4
	ctx.r[20].s64 = ctx.r[15].s64 + 4;
	// 82590A78: 92810050  stw r20, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[20].u32 ) };
	// 82590A7C: 2F140400  cmpwi cr6, r20, 0x400
	ctx.cr[6].compare_i32(ctx.r[20].s32, 1024, &mut ctx.xer);
	// 82590A80: 4198F588  blt cr6, 0x82590008
	if ctx.cr[6].lt {
	pc = 0x82590008; continue 'dispatch;
	}
	// 82590A84: 836100DC  lwz r27, 0xdc(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) } as u64;
	// 82590A88: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590A8C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82590A90: 38639130  addi r3, r3, -0x6ed0
	ctx.r[3].s64 = ctx.r[3].s64 + -28368;
	// 82590A94: 4BFFE25D  bl 0x8258ecf0
	ctx.lr = 0x82590A98;
	sub_8258ECF0(ctx, base);
	// 82590A98: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590A9C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82590AA0: 38639948  addi r3, r3, -0x66b8
	ctx.r[3].s64 = ctx.r[3].s64 + -26296;
	// 82590AA4: 4BFFE24D  bl 0x8258ecf0
	ctx.lr = 0x82590AA8;
	sub_8258ECF0(ctx, base);
	// 82590AA8: 83C100D4  lwz r30, 0xd4(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) } as u64;
	// 82590AAC: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590AB0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82590AB4: 3863A160  addi r3, r3, -0x5ea0
	ctx.r[3].s64 = ctx.r[3].s64 + -24224;
	// 82590AB8: 4BFFE239  bl 0x8258ecf0
	ctx.lr = 0x82590ABC;
	sub_8258ECF0(ctx, base);
	// 82590ABC: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590AC0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82590AC4: 3863A978  addi r3, r3, -0x5688
	ctx.r[3].s64 = ctx.r[3].s64 + -22152;
	// 82590AC8: 4BFFE229  bl 0x8258ecf0
	ctx.lr = 0x82590ACC;
	sub_8258ECF0(ctx, base);
	// 82590ACC: 808100D0  lwz r4, 0xd0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) } as u64;
	// 82590AD0: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590AD4: 3BA4FFF8  addi r29, r4, -8
	ctx.r[29].s64 = ctx.r[4].s64 + -8;
	// 82590AD8: 3863B190  addi r3, r3, -0x4e70
	ctx.r[3].s64 = ctx.r[3].s64 + -20080;
	// 82590ADC: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 82590AE0: 4BFFE589  bl 0x8258f068
	ctx.lr = 0x82590AE4;
	sub_8258F068(ctx, base);
	// 82590AE4: 808100D8  lwz r4, 0xd8(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) } as u64;
	// 82590AE8: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 82590AEC: 3B84FFF8  addi r28, r4, -8
	ctx.r[28].s64 = ctx.r[4].s64 + -8;
	// 82590AF0: 3863B5B0  addi r3, r3, -0x4a50
	ctx.r[3].s64 = ctx.r[3].s64 + -19024;
	// 82590AF4: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82590AF8: 4BFFE571  bl 0x8258f068
	ctx.lr = 0x82590AFC;
	sub_8258F068(ctx, base);
	// 82590AFC: 3900005C  li r8, 0x5c
	ctx.r[8].s64 = 92;
	// 82590B00: 3D608283  lis r11, -0x7d7d
	ctx.r[11].s64 = -2105344000;
	// 82590B04: 81210094  lwz r9, 0x94(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) } as u64;
	// 82590B08: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 82590B0C: 80C10124  lwz r6, 0x124(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(292 as u32) ) } as u64;
	// 82590B10: 396B23B0  addi r11, r11, 0x23b0
	ctx.r[11].s64 = ctx.r[11].s64 + 9136;
	// 82590B14: 80E10134  lwz r7, 0x134(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(308 as u32) ) } as u64;
	// 82590B18: 7C69D850  subf r3, r9, r27
	ctx.r[3].s64 = ctx.r[27].s64 - ctx.r[9].s64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590C20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82590C20 size=88
    let mut pc: u32 = 0x82590C20;
    'dispatch: loop {
        match pc {
            0x82590C20 => {
    //   block [0x82590C20..0x82590C78)
	// 82590C20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82590C24: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82590C28: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82590C2C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82590C30: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82590C34: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82590C38: 396B68EC  addi r11, r11, 0x68ec
	ctx.r[11].s64 = ctx.r[11].s64 + 26860;
	// 82590C3C: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 82590C40: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82590C44: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82590C48: 419A0018  beq cr6, 0x82590c60
	if ctx.cr[6].eq {
	pc = 0x82590C60; continue 'dispatch;
	}
	// 82590C4C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 82590C50: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 82590C54: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 82590C58: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82590C5C: 4BFF3CA5  bl 0x82584900
	ctx.lr = 0x82590C60;
	sub_82584900(ctx, base);
	// 82590C60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82590C64: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82590C68: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82590C6C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82590C70: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82590C74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590C78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82590C78 size=320
    let mut pc: u32 = 0x82590C78;
    'dispatch: loop {
        match pc {
            0x82590C78 => {
    //   block [0x82590C78..0x82590DB8)
	// 82590C78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82590C7C: 4BFA4435  bl 0x825350b0
	ctx.lr = 0x82590C80;
	sub_82535080(ctx, base);
	// 82590C80: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82590C84: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82590C88: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82590C8C: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82590C90: 4817D1BD  bl 0x8270de4c
	ctx.lr = 0x82590C94;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 82590C94: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 82590C98: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82590C9C: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 82590CA0: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 82590CA4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590CA8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82590CAC: 419A0010  beq cr6, 0x82590cbc
	if ctx.cr[6].eq {
	pc = 0x82590CBC; continue 'dispatch;
	}
	// 82590CB0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82590CB4: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82590CB8: 419A0018  beq cr6, 0x82590cd0
	if ctx.cr[6].eq {
	pc = 0x82590CD0; continue 'dispatch;
	}
	// 82590CBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82590CC0: 4817CBCD  bl 0x8270d88c
	ctx.lr = 0x82590CC4;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 82590CC4: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82590CC8: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 82590CCC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590CD0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82590CD4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82590CD8: 897E00BC  lbz r11, 0xbc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(188 as u32) ) } as u64;
	// 82590CDC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82590CE0: 419A0018  beq cr6, 0x82590cf8
	if ctx.cr[6].eq {
	pc = 0x82590CF8; continue 'dispatch;
	}
	// 82590CE4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590CE8: C03E00B8  lfs f1, 0xb8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(184 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82590CEC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590CF0: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82590CF4: 48013105  bl 0x825a3df8
	ctx.lr = 0x82590CF8;
	sub_825A3DF8(ctx, base);
	// 82590CF8: 897E00BD  lbz r11, 0xbd(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(189 as u32) ) } as u64;
	// 82590CFC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82590D00: 419A001C  beq cr6, 0x82590d1c
	if ctx.cr[6].eq {
	pc = 0x82590D1C; continue 'dispatch;
	}
	// 82590D04: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590D08: 389E0034  addi r4, r30, 0x34
	ctx.r[4].s64 = ctx.r[30].s64 + 52;
	// 82590D0C: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590D10: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82590D14: 480130FD  bl 0x825a3e10
	ctx.lr = 0x82590D18;
	sub_825A3E10(ctx, base);
	// 82590D18: 48000020  b 0x82590d38
	pc = 0x82590D38; continue 'dispatch;
	// 82590D1C: 897E00BE  lbz r11, 0xbe(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(190 as u32) ) } as u64;
	// 82590D20: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82590D24: 419A0014  beq cr6, 0x82590d38
	if ctx.cr[6].eq {
	pc = 0x82590D38; continue 'dispatch;
	}
	// 82590D28: 38BE0088  addi r5, r30, 0x88
	ctx.r[5].s64 = ctx.r[30].s64 + 136;
	// 82590D2C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82590D30: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82590D34: 48014DB5  bl 0x825a5ae8
	ctx.lr = 0x82590D38;
	sub_825A5AE8(ctx, base);
	// 82590D38: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82590D3C: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 82590D40: 995E00BC  stb r10, 0xbc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(188 as u32), ctx.r[10].u8 ) };
	// 82590D44: 995E00BD  stb r10, 0xbd(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(189 as u32), ctx.r[10].u8 ) };
	// 82590D48: 995E00BE  stb r10, 0xbe(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(190 as u32), ctx.r[10].u8 ) };
	// 82590D4C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590D50: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82590D54: 419A0040  beq cr6, 0x82590d94
	if ctx.cr[6].eq {
	pc = 0x82590D94; continue 'dispatch;
	}
	// 82590D58: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82590D5C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82590D60: 409A0034  bne cr6, 0x82590d94
	if !ctx.cr[6].eq {
	pc = 0x82590D94; continue 'dispatch;
	}
	// 82590D64: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82590D68: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82590D6C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82590D70: 409A0024  bne cr6, 0x82590d94
	if !ctx.cr[6].eq {
	pc = 0x82590D94; continue 'dispatch;
	}
	// 82590D74: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 82590D78: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82590D7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82590D80: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 82590D84: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82590D88: 4817CAF5  bl 0x8270d87c
	ctx.lr = 0x82590D8C;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 82590D8C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82590D90: 4817D0CD  bl 0x8270de5c
	ctx.lr = 0x82590D94;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 82590D94: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82590D98: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 82590D9C: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 82590DA0: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82590DA4: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590DA8: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82590DAC: 4BFFE7D5  bl 0x8258f580
	ctx.lr = 0x82590DB0;
	sub_8258F580(ctx, base);
	// 82590DB0: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82590DB4: 4BFA434C  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590DB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82590DB8 size=116
    let mut pc: u32 = 0x82590DB8;
    'dispatch: loop {
        match pc {
            0x82590DB8 => {
    //   block [0x82590DB8..0x82590E2C)
	// 82590DB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82590DBC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82590DC0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82590DC4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82590DC8: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82590DCC: 3BE3FF40  addi r31, r3, -0xc0
	ctx.r[31].s64 = ctx.r[3].s64 + -192;
	// 82590DD0: 394B68D4  addi r10, r11, 0x68d4
	ctx.r[10].s64 = ctx.r[11].s64 + 26836;
	// 82590DD4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82590DD8: 392B68EC  addi r9, r11, 0x68ec
	ctx.r[9].s64 = ctx.r[11].s64 + 26860;
	// 82590DDC: 548B07FE  clrlwi r11, r4, 0x1f
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 82590DE0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82590DE4: 397F0034  addi r11, r31, 0x34
	ctx.r[11].s64 = ctx.r[31].s64 + 52;
	// 82590DE8: 810BFFCC  lwz r8, -0x34(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-52 as u32) ) } as u64;
	// 82590DEC: 81080004  lwz r8, 4(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590DF0: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 82590DF4: 914BFFCC  stw r10, -0x34(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-52 as u32), ctx.r[10].u32 ) };
	// 82590DF8: 913F00C0  stw r9, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[9].u32 ) };
	// 82590DFC: 419A0018  beq cr6, 0x82590e14
	if ctx.cr[6].eq {
	pc = 0x82590E14; continue 'dispatch;
	}
	// 82590E00: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 82590E04: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 82590E08: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 82590E0C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82590E10: 4BFF3AF1  bl 0x82584900
	ctx.lr = 0x82590E14;
	sub_82584900(ctx, base);
	// 82590E14: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82590E18: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82590E1C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82590E20: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82590E24: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82590E28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590E30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82590E30 size=8
    let mut pc: u32 = 0x82590E30;
    'dispatch: loop {
        match pc {
            0x82590E30 => {
    //   block [0x82590E30..0x82590E38)
	// 82590E30: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 82590E34: 480002AC  b 0x825910e0
	sub_825910E0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590E38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82590E38 size=20
    let mut pc: u32 = 0x82590E38;
    'dispatch: loop {
        match pc {
            0x82590E38 => {
    //   block [0x82590E38..0x82590E4C)
	// 82590E38: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82590E3C: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82590E40: 386A0001  addi r3, r10, 1
	ctx.r[3].s64 = ctx.r[10].s64 + 1;
	// 82590E44: 906B0008  stw r3, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82590E48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590E50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82590E50 size=360
    let mut pc: u32 = 0x82590E50;
    'dispatch: loop {
        match pc {
            0x82590E50 => {
    //   block [0x82590E50..0x82590FB8)
	// 82590E50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82590E54: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82590E58: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82590E5C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82590E60: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82590E64: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82590E68: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82590E6C: 38810078  addi r4, r1, 0x78
	ctx.r[4].s64 = ctx.r[1].s64 + 120;
	// 82590E70: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82590E74: 4BFF357D  bl 0x825843f0
	ctx.lr = 0x82590E78;
	sub_825843F0(ctx, base);
	// 82590E78: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82590E7C: 41980124  blt cr6, 0x82590fa0
	if ctx.cr[6].lt {
	pc = 0x82590FA0; continue 'dispatch;
	}
	// 82590E80: 38810068  addi r4, r1, 0x68
	ctx.r[4].s64 = ctx.r[1].s64 + 104;
	// 82590E84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82590E88: 4BFF3569  bl 0x825843f0
	ctx.lr = 0x82590E8C;
	sub_825843F0(ctx, base);
	// 82590E8C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82590E90: 41980110  blt cr6, 0x82590fa0
	if ctx.cr[6].lt {
	pc = 0x82590FA0; continue 'dispatch;
	}
	// 82590E94: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82590E98: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 82590E9C: 38810068  addi r4, r1, 0x68
	ctx.r[4].s64 = ctx.r[1].s64 + 104;
	// 82590EA0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82590EA4: 99610068  stb r11, 0x68(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u8 ) };
	// 82590EA8: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 82590EAC: 99610069  stb r11, 0x69(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(105 as u32), ctx.r[11].u8 ) };
	// 82590EB0: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 82590EB4: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 82590EB8: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 82590EBC: 4BFF3815  bl 0x825846d0
	ctx.lr = 0x82590EC0;
	sub_825846D0(ctx, base);
	// 82590EC0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82590EC4: 419800DC  blt cr6, 0x82590fa0
	if ctx.cr[6].lt {
	pc = 0x82590FA0; continue 'dispatch;
	}
	// 82590EC8: 89610079  lbz r11, 0x79(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(121 as u32) ) } as u64;
	// 82590ECC: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82590ED0: 419800CC  blt cr6, 0x82590f9c
	if ctx.cr[6].lt {
	pc = 0x82590F9C; continue 'dispatch;
	}
	// 82590ED4: 419A0020  beq cr6, 0x82590ef4
	if ctx.cr[6].eq {
	pc = 0x82590EF4; continue 'dispatch;
	}
	// 82590ED8: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 82590EDC: 41980010  blt cr6, 0x82590eec
	if ctx.cr[6].lt {
	pc = 0x82590EEC; continue 'dispatch;
	}
	// 82590EE0: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 82590EE4: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 82590EE8: 480000B8  b 0x82590fa0
	pc = 0x82590FA0; continue 'dispatch;
	// 82590EEC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82590EF0: 48000008  b 0x82590ef8
	pc = 0x82590EF8; continue 'dispatch;
	// 82590EF4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82590EF8: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82590EFC: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 82590F00: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590F04: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82590F08: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 82590F0C: 48012EE5  bl 0x825a3df0
	ctx.lr = 0x82590F10;
	sub_825A3DF0(ctx, base);
	// 82590F10: 81610080  lwz r11, 0x80(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82590F14: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82590F18: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82590F1C: 396B0400  addi r11, r11, 0x400
	ctx.r[11].s64 = ctx.r[11].s64 + 1024;
	// 82590F20: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82590F24: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82590F28: 394B0400  addi r10, r11, 0x400
	ctx.r[10].s64 = ctx.r[11].s64 + 1024;
	// 82590F2C: 91610090  stw r11, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 82590F30: 91410094  stw r10, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[10].u32 ) };
	// 82590F34: 394B0800  addi r10, r11, 0x800
	ctx.r[10].s64 = ctx.r[11].s64 + 2048;
	// 82590F38: 91410098  stw r10, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[10].u32 ) };
	// 82590F3C: 394B1000  addi r10, r11, 0x1000
	ctx.r[10].s64 = ctx.r[11].s64 + 4096;
	// 82590F40: 396B1400  addi r11, r11, 0x1400
	ctx.r[11].s64 = ctx.r[11].s64 + 5120;
	// 82590F44: 9141009C  stw r10, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[10].u32 ) };
	// 82590F48: 916100A0  stw r11, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 82590F4C: 4BE3932D  bl 0x823ca278
	ctx.lr = 0x82590F50;
	sub_823CA278(ctx, base);
	// 82590F50: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 82590F54: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82590F58: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82590F5C: 4BFFFD1D  bl 0x82590c78
	ctx.lr = 0x82590F60;
	sub_82590C78(ctx, base);
	// 82590F60: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82590F64: 4BE39315  bl 0x823ca278
	ctx.lr = 0x82590F68;
	sub_823CA278(ctx, base);
	// 82590F68: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 82590F6C: 3D5F0005  addis r10, r31, 5
	ctx.r[10].s64 = ctx.r[31].s64 + 327680;
	// 82590F70: E8E10058  ld r7, 0x58(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82590F74: 396BBAA0  addi r11, r11, -0x4560
	ctx.r[11].s64 = ctx.r[11].s64 + -17760;
	// 82590F78: 394ABAA8  addi r10, r10, -0x4558
	ctx.r[10].s64 = ctx.r[10].s64 + -17752;
	// 82590F7C: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 82590F80: E90A0000  ld r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	// 82590F84: 7D274850  subf r9, r7, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 82590F88: 38E80001  addi r7, r8, 1
	ctx.r[7].s64 = ctx.r[8].s64 + 1;
	// 82590F8C: E9010060  ld r8, 0x60(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 82590F90: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82590F94: F8EA0000  std r7, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u64 ) };
	// 82590F98: F92B0000  std r9, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 82590F9C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82590FA0: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 82590FA4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82590FA8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82590FAC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82590FB0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82590FB4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82590FB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82590FB8 size=116
    let mut pc: u32 = 0x82590FB8;
    'dispatch: loop {
        match pc {
            0x82590FB8 => {
    //   block [0x82590FB8..0x8259102C)
	// 82590FB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82590FBC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82590FC0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82590FC4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82590FC8: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82590FCC: 3BE3FFCC  addi r31, r3, -0x34
	ctx.r[31].s64 = ctx.r[3].s64 + -52;
	// 82590FD0: 394B68D4  addi r10, r11, 0x68d4
	ctx.r[10].s64 = ctx.r[11].s64 + 26836;
	// 82590FD4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82590FD8: 392B68EC  addi r9, r11, 0x68ec
	ctx.r[9].s64 = ctx.r[11].s64 + 26860;
	// 82590FDC: 548B07FE  clrlwi r11, r4, 0x1f
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 82590FE0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82590FE4: 397F0034  addi r11, r31, 0x34
	ctx.r[11].s64 = ctx.r[31].s64 + 52;
	// 82590FE8: 810BFFCC  lwz r8, -0x34(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-52 as u32) ) } as u64;
	// 82590FEC: 81080004  lwz r8, 4(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82590FF0: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 82590FF4: 914BFFCC  stw r10, -0x34(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-52 as u32), ctx.r[10].u32 ) };
	// 82590FF8: 913F0034  stw r9, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[9].u32 ) };
	// 82590FFC: 419A0018  beq cr6, 0x82591014
	if ctx.cr[6].eq {
	pc = 0x82591014; continue 'dispatch;
	}
	// 82591000: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 82591004: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 82591008: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 8259100C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82591010: 4BFF38F1  bl 0x82584900
	ctx.lr = 0x82591014;
	sub_82584900(ctx, base);
	// 82591014: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82591018: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8259101C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82591020: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82591024: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82591028: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591030(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82591030 size=176
    let mut pc: u32 = 0x82591030;
    'dispatch: loop {
        match pc {
            0x82591030 => {
    //   block [0x82591030..0x825910E0)
	// 82591030: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82591034: 4BFA4089  bl 0x825350bc
	ctx.lr = 0x82591038;
	sub_82535080(ctx, base);
	// 82591038: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259103C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82591040: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82591044: 396B62FC  addi r11, r11, 0x62fc
	ctx.r[11].s64 = ctx.r[11].s64 + 25340;
	// 82591048: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8259104C: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 82591050: 3D208209  lis r9, -0x7df7
	ctx.r[9].s64 = -2113339392;
	// 82591054: 3D008209  lis r8, -0x7df7
	ctx.r[8].s64 = -2113339392;
	// 82591058: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8259105C: 394A6918  addi r10, r10, 0x6918
	ctx.r[10].s64 = ctx.r[10].s64 + 26904;
	// 82591060: 90FF0008  stw r7, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82591064: 392968FC  addi r9, r9, 0x68fc
	ctx.r[9].s64 = ctx.r[9].s64 + 26876;
	// 82591068: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259106C: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 82591070: 390868F4  addi r8, r8, 0x68f4
	ctx.r[8].s64 = ctx.r[8].s64 + 26868;
	// 82591074: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82591078: 387E00C0  addi r3, r30, 0xc0
	ctx.r[3].s64 = ctx.r[30].s64 + 192;
	// 8259107C: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82591080: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82591084: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82591088: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 8259108C: 911E0000  stw r8, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82591090: 48013BB1  bl 0x825a4c40
	ctx.lr = 0x82591094;
	sub_825A4C40(ctx, base);
	// 82591094: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82591098: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8259109C: 48014BA5  bl 0x825a5c40
	ctx.lr = 0x825910A0;
	sub_825A5C40(ctx, base);
	// 825910A0: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 825910A4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825910A8: 387E0034  addi r3, r30, 0x34
	ctx.r[3].s64 = ctx.r[30].s64 + 52;
	// 825910AC: 396B68F0  addi r11, r11, 0x68f0
	ctx.r[11].s64 = ctx.r[11].s64 + 26864;
	// 825910B0: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 825910B4: 7D6AF12E  stwx r11, r10, r30
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[30].u32), ctx.r[11].u32) };
	// 825910B8: 48012879  bl 0x825a3930
	ctx.lr = 0x825910BC;
	sub_825A3930(ctx, base);
	// 825910BC: 3D600004  lis r11, 4
	ctx.r[11].s64 = 262144;
	// 825910C0: 3D400004  lis r10, 4
	ctx.r[10].s64 = 262144;
	// 825910C4: 616BBAA0  ori r11, r11, 0xbaa0
	ctx.r[11].u64 = ctx.r[11].u64 | 47776;
	// 825910C8: 614ABAA8  ori r10, r10, 0xbaa8
	ctx.r[10].u64 = ctx.r[10].u64 | 47784;
	// 825910CC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825910D0: 7FBF592A  stdx r29, r31, r11
	unsafe { crate::rt::store_u64(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), ctx.r[29].u64) };
	// 825910D4: 7FBF512A  stdx r29, r31, r10
	unsafe { crate::rt::store_u64(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[10].u32), ctx.r[29].u64) };
	// 825910D8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825910DC: 4BFA4030  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825910E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825910E0 size=84
    let mut pc: u32 = 0x825910E0;
    'dispatch: loop {
        match pc {
            0x825910E0 => {
    //   block [0x825910E0..0x82591134)
	// 825910E0: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825910E4: 3D208209  lis r9, -0x7df7
	ctx.r[9].s64 = -2113339392;
	// 825910E8: 394A6918  addi r10, r10, 0x6918
	ctx.r[10].s64 = ctx.r[10].s64 + 26904;
	// 825910EC: 39630010  addi r11, r3, 0x10
	ctx.r[11].s64 = ctx.r[3].s64 + 16;
	// 825910F0: 392968FC  addi r9, r9, 0x68fc
	ctx.r[9].s64 = ctx.r[9].s64 + 26876;
	// 825910F4: 3D008209  lis r8, -0x7df7
	ctx.r[8].s64 = -2113339392;
	// 825910F8: 3CE08209  lis r7, -0x7df7
	ctx.r[7].s64 = -2113339392;
	// 825910FC: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82591100: 394B0034  addi r10, r11, 0x34
	ctx.r[10].s64 = ctx.r[11].s64 + 52;
	// 82591104: 3CC08209  lis r6, -0x7df7
	ctx.r[6].s64 = -2113339392;
	// 82591108: 91230004  stw r9, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8259110C: 390868D4  addi r8, r8, 0x68d4
	ctx.r[8].s64 = ctx.r[8].s64 + 26836;
	// 82591110: 38E768EC  addi r7, r7, 0x68ec
	ctx.r[7].s64 = ctx.r[7].s64 + 26860;
	// 82591114: 38C662E8  addi r6, r6, 0x62e8
	ctx.r[6].s64 = ctx.r[6].s64 + 25320;
	// 82591118: 812AFFCC  lwz r9, -0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-52 as u32) ) } as u64;
	// 8259111C: 81290004  lwz r9, 4(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82591120: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82591124: 910AFFCC  stw r8, -0x34(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-52 as u32), ctx.r[8].u32 ) };
	// 82591128: 90EB00C0  stw r7, 0xc0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(192 as u32), ctx.r[7].u32 ) };
	// 8259112C: 90C30004  stw r6, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82591130: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591138(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82591138 size=184
    let mut pc: u32 = 0x82591138;
    'dispatch: loop {
        match pc {
            0x82591138 => {
    //   block [0x82591138..0x825911F0)
	// 82591138: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259113C: 4BFA3F7D  bl 0x825350b8
	ctx.lr = 0x82591140;
	sub_82535080(ctx, base);
	// 82591140: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82591144: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82591148: 3C800004  lis r4, 4
	ctx.r[4].s64 = 262144;
	// 8259114C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82591150: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82591154: 6084BAB0  ori r4, r4, 0xbab0
	ctx.r[4].u64 = ctx.r[4].u64 | 47792;
	// 82591158: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259115C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82591160: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82591164: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82591168: 4E800421  bctrl
	ctx.lr = 0x8259116C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8259116C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82591170: 419A001C  beq cr6, 0x8259118c
	if ctx.cr[6].eq {
	pc = 0x8259118C; continue 'dispatch;
	}
	// 82591174: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82591178: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8259117C: 4BFFFEB5  bl 0x82591030
	ctx.lr = 0x82591180;
	sub_82591030(ctx, base);
	// 82591180: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82591184: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82591188: 409A0014  bne cr6, 0x8259119c
	if !ctx.cr[6].eq {
	pc = 0x8259119C; continue 'dispatch;
	}
	// 8259118C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 82591190: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 82591194: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82591198: 4BFA3F70  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 8259119C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825911A0: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 825911A4: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 825911A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825911AC: 816B001C  lwz r11, 0x1c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 825911B0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825911B4: 4E800421  bctrl
	ctx.lr = 0x825911B8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825911B8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825911BC: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 825911C0: 41980010  blt cr6, 0x825911d0
	if ctx.cr[6].lt {
	pc = 0x825911D0; continue 'dispatch;
	}
	// 825911C4: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 825911C8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825911CC: 4BFA3F3C  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 825911D0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825911D4: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 825911D8: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 825911DC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825911E0: 4E800421  bctrl
	ctx.lr = 0x825911E4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825911E4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825911E8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825911EC: 4BFA3F1C  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825911F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825911F0 size=56
    let mut pc: u32 = 0x825911F0;
    'dispatch: loop {
        match pc {
            0x825911F0 => {
    //   block [0x825911F0..0x82591228)
	// 825911F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825911F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825911F8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825911FC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82591200: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82591204: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 82591208: 4BFF8E11  bl 0x8258a018
	ctx.lr = 0x8259120C;
	sub_8258A018(ctx, base);
	// 8259120C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82591210: 4BFF8E09  bl 0x8258a018
	ctx.lr = 0x82591214;
	sub_8258A018(ctx, base);
	// 82591214: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82591218: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259121C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82591220: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82591224: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591228(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82591228 size=192
    let mut pc: u32 = 0x82591228;
    'dispatch: loop {
        match pc {
            0x82591228 => {
    //   block [0x82591228..0x825912E8)
	// 82591228: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259122C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82591230: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82591234: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82591238: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259123C: 549E063E  clrlwi r30, r4, 0x18
	ctx.r[30].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 82591240: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82591244: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82591248: 419A0088  beq cr6, 0x825912d0
	if ctx.cr[6].eq {
	pc = 0x825912D0; continue 'dispatch;
	}
	// 8259124C: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82591250: 1C9E0078  mulli r4, r30, 0x78
	ctx.r[4].s64 = ctx.r[30].s64 * 120;
	// 82591254: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 82591258: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259125C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82591260: 4E800421  bctrl
	ctx.lr = 0x82591264;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82591264: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 82591268: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 8259126C: 419A0064  beq cr6, 0x825912d0
	if ctx.cr[6].eq {
	pc = 0x825912D0; continue 'dispatch;
	}
	// 82591270: 393F000C  addi r9, r31, 0xc
	ctx.r[9].s64 = ctx.r[31].s64 + 12;
	// 82591274: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82591278: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8259127C: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82591280: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82591284: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82591288: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259128C: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82591290: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82591294: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82591298: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259129C: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 825912A0: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 825912A4: 80FF0018  lwz r7, 0x18(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 825912A8: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 825912AC: 394A0078  addi r10, r10, 0x78
	ctx.r[10].s64 = ctx.r[10].s64 + 120;
	// 825912B0: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 825912B4: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 825912B8: 80E90004  lwz r7, 4(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 825912BC: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 825912C0: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825912C4: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825912C8: 91670000  stw r11, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825912CC: 409AFFB0  bne cr6, 0x8259127c
	if !ctx.cr[6].eq {
	pc = 0x8259127C; continue 'dispatch;
	}
	// 825912D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825912D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825912D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825912DC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825912E0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825912E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825912E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825912E8 size=36
    let mut pc: u32 = 0x825912E8;
    'dispatch: loop {
        match pc {
            0x825912E8 => {
    //   block [0x825912E8..0x8259130C)
	// 825912E8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825912EC: 90630000  stw r3, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 825912F0: 3963000C  addi r11, r3, 0xc
	ctx.r[11].s64 = ctx.r[3].s64 + 12;
	// 825912F4: 90630004  stw r3, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 825912F8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 825912FC: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82591300: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82591304: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82591308: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591310(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82591310 size=628
    let mut pc: u32 = 0x82591310;
    'dispatch: loop {
        match pc {
            0x82591310 => {
    //   block [0x82591310..0x82591584)
	// 82591310: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82591314: 4BFA3DA1  bl 0x825350b4
	ctx.lr = 0x82591318;
	sub_82535080(ctx, base);
	// 82591318: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259131C: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82591320: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82591324: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82591328: 7C001A2C  dcbt 0, r3
	// 8259132C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82591330: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82591334: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82591338: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 8259133C: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82591340: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 82591344: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 82591348: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 8259134C: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82591350: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 82591354: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 82591358: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 8259135C: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 82591360: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82591364: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82591368: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259136C: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82591370: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 82591374: 3B610068  addi r27, r1, 0x68
	ctx.r[27].s64 = ctx.r[1].s64 + 104;
	// 82591378: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82591588 size=728
    let mut pc: u32 = 0x82591588;
    'dispatch: loop {
        match pc {
            0x82591588 => {
    //   block [0x82591588..0x82591860)
	// 82591588: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259158C: 4BFA3B25  bl 0x825350b0
	ctx.lr = 0x82591590;
	sub_82535080(ctx, base);
	// 82591590: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82591594: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82591598: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259159C: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825915A0: 7C001A2C  dcbt 0, r3
	// 825915A4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825915A8: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825915AC: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825915B0: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 825915B4: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 825915B8: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 825915BC: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 825915C0: 13E1038C  vspltisw v31, 1
	for i in 0..4 {
		ctx.v[31].u32[i] = 1;
	}
	// 825915C4: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 825915C8: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825915CC: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825915D0: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825915D4: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 825915D8: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825915DC: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825915E0: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825915E4: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 825915E8: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825915EC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825915F0: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 825915F4: 3B610068  addi r27, r1, 0x68
	ctx.r[27].s64 = ctx.r[1].s64 + 104;
	// 825915F8: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
	// 825915FC: 3B810058  addi r28, r1, 0x58
	ctx.r[28].s64 = ctx.r[1].s64 + 88;
	// 82591600: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591860(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82591860 size=940
    let mut pc: u32 = 0x82591860;
    'dispatch: loop {
        match pc {
            0x82591860 => {
    //   block [0x82591860..0x82591C0C)
	// 82591860: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82591864: 4BFA382D  bl 0x82535090
	ctx.lr = 0x82591868;
	sub_82535080(ctx, base);
	// 82591868: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259186C: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 82591870: C1B90024  lfs f13, 0x24(r25)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82591874: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82591878: 7C001A2C  dcbt 0, r3
	// 8259187C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82591880: C1990030  lfs f12, 0x30(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82591884: C179002C  lfs f11, 0x2c(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82591888: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 8259188C: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 82591890: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 82591894: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 82591898: 1381038C  vspltisw v28, 1
	for i in 0..4 {
		ctx.v[28].u32[i] = 1;
	}
	// 8259189C: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 825918A0: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825918A4: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825918A8: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825918AC: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 825918B0: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825918B4: C0190028  lfs f0, 0x28(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825918B8: D0190024  stfs f0, 0x24(r25)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825918BC: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 825918C0: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825918C4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825918C8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 825918CC: 3BA10068  addi r29, r1, 0x68
	ctx.r[29].s64 = ctx.r[1].s64 + 104;
	// 825918D0: 3BE10058  addi r31, r1, 0x58
	ctx.r[31].s64 = ctx.r[1].s64 + 88;
	// 825918D4: 108C6484  vmr v4, v12
	ctx.v[4] = ctx.v[12];
	// 825918D8: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
	// 825918DC: 106C6484  vmr v3, v12
	ctx.v[3] = ctx.v[12];
	// 825918E0: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 825918E4: 10AC6484  vmr v5, v12
	ctx.v[5] = ctx.v[12];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82591C10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82591C10 size=1220
    let mut pc: u32 = 0x82591C10;
    'dispatch: loop {
        match pc {
            0x82591C10 => {
    //   block [0x82591C10..0x825920D4)
	// 82591C10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82591C14: 4BFA346D  bl 0x82535080
	ctx.lr = 0x82591C18;
	sub_82535080(ctx, base);
	// 82591C18: 9421FEE0  stwu r1, -0x120(r1)
	ea = ctx.r[1].u32.wrapping_add(-288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82591C1C: 7CF33B78  mr r19, r7
	ctx.r[19].u64 = ctx.r[7].u64;
	// 82591C20: 90C1014C  stw r6, 0x14c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), ctx.r[6].u32 ) };
	// 82591C24: C1B30024  lfs f13, 0x24(r19)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82591C28: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82591C2C: 7C001A2C  dcbt 0, r3
	// 82591C30: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82591C34: C1930030  lfs f12, 0x30(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82591C38: C173002C  lfs f11, 0x2c(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82591C3C: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 82591C40: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82591C44: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 82591C48: 3BE00004  li r31, 4
	ctx.r[31].s64 = 4;
	// 82591C4C: 12E1038C  vspltisw v23, 1
	for i in 0..4 {
		ctx.v[23].u32[i] = 1;
	}
	// 82591C50: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82591C54: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82591C58: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 82591C5C: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 82591C60: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 82591C64: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 82591C68: C0130028  lfs f0, 0x28(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82591C6C: D0130024  stfs f0, 0x24(r19)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82591C70: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82591C74: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82591C78: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82591C7C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82591C80: 3BC10070  addi r30, r1, 0x70
	ctx.r[30].s64 = ctx.r[1].s64 + 112;
	// 82591C84: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 82591C88: 13EC6484  vmr v31, v12
	ctx.v[31] = ctx.v[12];
	// 82591C8C: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 82591C90: 104C6484  vmr v2, v12
	ctx.v[2] = ctx.v[12];
	// 82591C94: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 82591C98: 108C6484  vmr v4, v12
	ctx.v[4] = ctx.v[12];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825920D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825920D8 size=444
    let mut pc: u32 = 0x825920D8;
    'dispatch: loop {
        match pc {
            0x825920D8 => {
    //   block [0x825920D8..0x82592220)
	// 825920D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825920DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825920E0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825920E4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825920E8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825920EC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825920F0: 83DF0008  lwz r30, 8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825920F4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825920F8: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825920FC: 4198000C  blt cr6, 0x82592108
	if ctx.cr[6].lt {
	pc = 0x82592108; continue 'dispatch;
	}
	// 82592100: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82592104: 48000178  b 0x8259227c
	pc = 0x8259227C; continue 'dispatch;
	// 82592108: 817F001C  lwz r11, 0x1c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259210C: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82592110: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82592114: 4098FFEC  bge cr6, 0x82592100
	if !ctx.cr[6].lt {
	pc = 0x82592100; continue 'dispatch;
	}
	// 82592118: 817F0050  lwz r11, 0x50(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8259211C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82592120: 419A0144  beq cr6, 0x82592264
	if ctx.cr[6].eq {
	pc = 0x82592264; continue 'dispatch;
	}
	// 82592124: 556B07BE  clrlwi r11, r11, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000003u64;
	// 82592128: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259212C: 419A0130  beq cr6, 0x8259225c
	if ctx.cr[6].eq {
	pc = 0x8259225C; continue 'dispatch;
	}
	// 82592130: 815F0020  lwz r10, 0x20(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 82592134: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82592138: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259213C: 817F0054  lwz r11, 0x54(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 82592140: F9210050  std r9, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u64 ) };
	// 82592144: 556907FE  clrlwi r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 82592148: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 8259214C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82592150: C8010050  lfd f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 82592154: C9A10058  lfd f13, 0x58(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82592158: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259215C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 82592160: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 82592164: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82592168: EC006824  fdivs f0, f0, f13
	ctx.f[0].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 8259216C: D01F002C  stfs f0, 0x2c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 82592170: 419A0058  beq cr6, 0x825921c8
	if ctx.cr[6].eq {
	pc = 0x825921C8; continue 'dispatch;
	}
	// 82592174: 811F0010  lwz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82592178: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259217C: 409A001C  bne cr6, 0x82592198
	if !ctx.cr[6].eq {
	pc = 0x82592198; continue 'dispatch;
	}
	// 82592180: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82592184: 216B0000  subfic r11, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[11].s64;
	// 82592188: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 8259218C: 556B07FA  rlwinm r11, r11, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82592190: 392B0004  addi r9, r11, 4
	ctx.r[9].s64 = ctx.r[11].s64 + 4;
	// 82592194: 48000048  b 0x825921dc
	pc = 0x825921DC; continue 'dispatch;
	// 82592198: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259219C: 419A002C  beq cr6, 0x825921c8
	if ctx.cr[6].eq {
	pc = 0x825921C8; continue 'dispatch;
	}
	// 825921A0: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 825921A4: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825921A8: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 825921AC: 409A001C  bne cr6, 0x825921c8
	if !ctx.cr[6].eq {
	pc = 0x825921C8; continue 'dispatch;
	}
	// 825921B0: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825921B4: 216B0000  subfic r11, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[11].s64;
	// 825921B8: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 825921BC: 556B07FA  rlwinm r11, r11, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825921C0: 392B0005  addi r9, r11, 5
	ctx.r[9].s64 = ctx.r[11].s64 + 5;
	// 825921C4: 48000018  b 0x825921dc
	pc = 0x825921DC; continue 'dispatch;
	// 825921C8: 556B0630  rlwinm r11, r11, 0, 0x18, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825921CC: 216B0000  subfic r11, r11, 0
	ctx.xer.ca = ctx.r[11].u32 <= 0 as u32;
	ctx.r[11].s64 = (0 as i64) - ctx.r[11].s64;
	// 825921D0: 7D6B5910  subfe r11, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[11].u32 = res;
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 825921D4: 556B07FA  rlwinm r11, r11, 0, 0x1f, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825921D8: 392B0003  addi r9, r11, 3
	ctx.r[9].s64 = ctx.r[11].s64 + 3;
	// 825921DC: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 825921E0: 88FF000C  lbz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825921E4: 394BFFFF  addi r10, r11, -1
	ctx.r[10].s64 = ctx.r[11].s64 + -1;
	// 825921E8: 2B0A0005  cmplwi cr6, r10, 5
	ctx.cr[6].compare_u32(ctx.r[10].u32, 5 as u32, &mut ctx.xer);
	// 825921EC: 41990040  bgt cr6, 0x8259222c
	if ctx.cr[6].gt {
	pc = 0x8259222C; continue 'dispatch;
	}
	// 825921F0: 3D808259  lis r12, -0x7da7
	ctx.r[12].s64 = -2108096512;
	// 825921F4: 398C2208  addi r12, r12, 0x2208
	ctx.r[12].s64 = ctx.r[12].s64 + 8712;
	// 825921F8: 5540103A  slwi r0, r10, 2
	ctx.r[0].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 825921FC: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 82592200: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 82592204: 4E800420  bctr
	match ctx.r[10].u64 {
		0 => {
	pc = 0x82592220; continue 'dispatch;
		},
		1 => {
	pc = 0x82592220; continue 'dispatch;
		},
		2 => {
	pc = 0x8259222C; continue 'dispatch;
		},
		3 => {
	pc = 0x82592220; continue 'dispatch;
		},
		4 => {
	pc = 0x8259222C; continue 'dispatch;
		},
		5 => {
	pc = 0x82592220; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 82592208: 82592220  lwz r18, 0x2220(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8736 as u32) ) } as u64;
	// 8259220C: 82592220  lwz r18, 0x2220(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8736 as u32) ) } as u64;
	// 82592210: 8259222C  lwz r18, 0x222c(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8748 as u32) ) } as u64;
	// 82592214: 82592220  lwz r18, 0x2220(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8736 as u32) ) } as u64;
	// 82592218: 8259222C  lwz r18, 0x222c(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8748 as u32) ) } as u64;
	// 8259221C: 82592220  lwz r18, 0x2220(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8736 as u32) ) } as u64;
            }
            0x82592220 => {
    //   block [0x82592220..0x8259222C)
	// 82592220: 556BF87E  srwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82592224: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 82592228: 48000008  b 0x82592230
	pc = 0x82592230; continue 'dispatch;
            }
            0x8259222C => {
    //   block [0x8259222C..0x82592294)
	// 8259222C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82592230: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82592234: 394B6938  addi r10, r11, 0x6938
	ctx.r[10].s64 = ctx.r[11].s64 + 26936;
	// 82592238: 552B103A  slwi r11, r9, 2
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259223C: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82592240: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82592244: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82592248: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8259224C: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82592250: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82592254: 7D6B502E  lwzx r11, r11, r10
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82592258: 917F004C  stw r11, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8259225C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82592260: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82592264: 817F004C  lwz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 82592268: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8259226C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82592270: 4E800421  bctrl
	ctx.lr = 0x82592274;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82592274: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82592278: 7C7E5850  subf r3, r30, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 8259227C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82592280: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82592284: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82592288: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259228C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82592290: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82592298(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82592298 size=520
    let mut pc: u32 = 0x82592298;
    'dispatch: loop {
        match pc {
            0x82592298 => {
    //   block [0x82592298..0x825924A0)
	// 82592298: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259229C: 4BFA2E1D  bl 0x825350b8
	ctx.lr = 0x825922A0;
	sub_82535080(ctx, base);
	// 825922A0: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825922A4: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 825922A8: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825922AC: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825922B0: 7C001A2C  dcbt 0, r3
	// 825922B4: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 825922B8: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825922BC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825922C0: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825922C4: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 825922C8: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 825922CC: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 825922D0: 1101038C  vspltisw v8, 1
	for i in 0..4 {
		ctx.v[8].u32[i] = 1;
	}
	// 825922D4: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 825922D8: F8E10068  std r7, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[7].u64 ) };
	// 825922DC: 3BC10060  addi r30, r1, 0x60
	ctx.r[30].s64 = ctx.r[1].s64 + 96;
	// 825922E0: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825922E4: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 825922E8: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825922EC: 3BA10054  addi r29, r1, 0x54
	ctx.r[29].s64 = ctx.r[1].s64 + 84;
	// 825922F0: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825922F4: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825922F8: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825922FC: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82592300: 3B810050  addi r28, r1, 0x50
	ctx.r[28].s64 = ctx.r[1].s64 + 80;
	// 82592304: 114C6484  vmr v10, v12
	ctx.v[10] = ctx.v[12];
	// 82592308: 38E10054  addi r7, r1, 0x54
	ctx.r[7].s64 = ctx.r[1].s64 + 84;
	// 8259230C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82592310: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 82592314: D98A0000  stfd f12, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
	// 82592318: FD805E5E  fctidz f12, f11
	ctx.f[12].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 8259231C: D98B0000  stfd f12, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825924A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825924A0 size=572
    let mut pc: u32 = 0x825924A0;
    'dispatch: loop {
        match pc {
            0x825924A0 => {
    //   block [0x825924A0..0x825926DC)
	// 825924A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825924A4: 4BFA2C15  bl 0x825350b8
	ctx.lr = 0x825924A8;
	sub_82535080(ctx, base);
	// 825924A8: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825924AC: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 825924B0: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825924B4: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825924B8: 7C001A2C  dcbt 0, r3
	// 825924BC: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 825924C0: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825924C4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825924C8: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825924CC: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 825924D0: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 825924D4: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 825924D8: 10C1038C  vspltisw v6, 1
	for i in 0..4 {
		ctx.v[6].u32[i] = 1;
	}
	// 825924DC: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 825924E0: F8E10068  std r7, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[7].u64 ) };
	// 825924E4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 825924E8: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825924EC: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 825924F0: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825924F4: 3B810050  addi r28, r1, 0x50
	ctx.r[28].s64 = ctx.r[1].s64 + 80;
	// 825924F8: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825924FC: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82592500: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82592504: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82592508: 3BC10054  addi r30, r1, 0x54
	ctx.r[30].s64 = ctx.r[1].s64 + 84;
	// 8259250C: 11600484  vmr v11, v0
	ctx.v[11] = ctx.v[0];
	// 82592510: 38E10054  addi r7, r1, 0x54
	ctx.r[7].s64 = ctx.r[1].s64 + 84;
	// 82592514: 11200484  vmr v9, v0
	ctx.v[9] = ctx.v[0];
	// 82592518: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8259251C: 11400484  vmr v10, v0
	ctx.v[10] = ctx.v[0];
	// 82592520: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 82592524: D98A0000  stfd f12, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
	// 82592528: FD805E5E  fctidz f12, f11
	ctx.f[12].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 8259252C: D98B0000  stfd f12, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825926E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825926E0 size=676
    let mut pc: u32 = 0x825926E0;
    'dispatch: loop {
        match pc {
            0x825926E0 => {
    //   block [0x825926E0..0x82592984)
	// 825926E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825926E4: 4BFA29BD  bl 0x825350a0
	ctx.lr = 0x825926E8;
	sub_82535080(ctx, base);
	// 825926E8: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825926EC: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 825926F0: C1BA0024  lfs f13, 0x24(r26)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825926F4: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825926F8: 7C001A2C  dcbt 0, r3
	// 825926FC: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 82592700: C19A0030  lfs f12, 0x30(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82592704: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82592708: C17A002C  lfs f11, 0x2c(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259270C: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82592710: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 82592714: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 82592718: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 8259271C: F8E10068  std r7, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[7].u64 ) };
	// 82592720: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82592724: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82592728: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 8259272C: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 82592730: 3BE10054  addi r31, r1, 0x54
	ctx.r[31].s64 = ctx.r[1].s64 + 84;
	// 82592734: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 82592738: C01A0028  lfs f0, 0x28(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259273C: D01A0024  stfs f0, 0x24(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82592740: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82592744: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82592748: 11600484  vmr v11, v0
	ctx.v[11] = ctx.v[0];
	// 8259274C: 38E10054  addi r7, r1, 0x54
	ctx.r[7].s64 = ctx.r[1].s64 + 84;
	// 82592750: 11800484  vmr v12, v0
	ctx.v[12] = ctx.v[0];
	// 82592754: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 82592758: 10A00484  vmr v5, v0
	ctx.v[5] = ctx.v[0];
	// 8259275C: 10C00484  vmr v6, v0
	ctx.v[6] = ctx.v[0];
	// 82592760: 3B60000C  li r27, 0xc
	ctx.r[27].s64 = 12;
	// 82592764: 10E00484  vmr v7, v0
	ctx.v[7] = ctx.v[0];
	// 82592768: 3B80001C  li r28, 0x1c
	ctx.r[28].s64 = 28;
	// 8259276C: 11000484  vmr v8, v0
	ctx.v[8] = ctx.v[0];
	// 82592770: 3BA00008  li r29, 8
	ctx.r[29].s64 = 8;
	// 82592774: 3AC00C00  li r22, 0xc00
	ctx.r[22].s64 = 3072;
	// 82592778: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 8259277C: D98A0000  stfd f12, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
	// 82592780: FD805E5E  fctidz f12, f11
	ctx.f[12].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 82592784: D98B0000  stfd f12, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82592988(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82592988 size=804
    let mut pc: u32 = 0x82592988;
    'dispatch: loop {
        match pc {
            0x82592988 => {
    //   block [0x82592988..0x82592CAC)
	// 82592988: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259298C: 4BFA26F9  bl 0x82535084
	ctx.lr = 0x82592990;
	sub_82535080(ctx, base);
	// 82592990: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82592994: 7CF53B78  mr r21, r7
	ctx.r[21].u64 = ctx.r[7].u64;
	// 82592998: C1B50024  lfs f13, 0x24(r21)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259299C: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825929A0: 7C001A2C  dcbt 0, r3
	// 825929A4: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 825929A8: C1950030  lfs f12, 0x30(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825929AC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825929B0: C175002C  lfs f11, 0x2c(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825929B4: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 825929B8: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 825929BC: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 825929C0: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 825929C4: F9010068  std r8, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[8].u64 ) };
	// 825929C8: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 825929CC: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825929D0: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 825929D4: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825929D8: 3BE10054  addi r31, r1, 0x54
	ctx.r[31].s64 = ctx.r[1].s64 + 84;
	// 825929DC: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825929E0: C0150028  lfs f0, 0x28(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825929E4: D0150024  stfs f0, 0x24(r21)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825929E8: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 825929EC: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 825929F0: 10C00484  vmr v6, v0
	ctx.v[6] = ctx.v[0];
	// 825929F4: 39010054  addi r8, r1, 0x54
	ctx.r[8].s64 = ctx.r[1].s64 + 84;
	// 825929F8: 10E00484  vmr v7, v0
	ctx.v[7] = ctx.v[0];
	// 825929FC: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 82592A00: 11000484  vmr v8, v0
	ctx.v[8] = ctx.v[0];
	// 82592A04: 11200484  vmr v9, v0
	ctx.v[9] = ctx.v[0];
	// 82592A08: 3AC00014  li r22, 0x14
	ctx.r[22].s64 = 20;
	// 82592A0C: 11400484  vmr v10, v0
	ctx.v[10] = ctx.v[0];
	// 82592A10: 3AE0002C  li r23, 0x2c
	ctx.r[23].s64 = 44;
	// 82592A14: 11600484  vmr v11, v0
	ctx.v[11] = ctx.v[0];
	// 82592A18: 3B000010  li r24, 0x10
	ctx.r[24].s64 = 16;
	// 82592A1C: 10200484  vmr v1, v0
	ctx.v[1] = ctx.v[0];
	// 82592A20: 3B200028  li r25, 0x28
	ctx.r[25].s64 = 40;
	// 82592A24: FD80665E  fctidz f12, f12
	ctx.f[12].s64 = if ctx.f[12].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[12].f64.trunc() as i64 };
	// 82592A28: D98A0000  stfd f12, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
	// 82592A2C: FD805E5E  fctidz f12, f11
	ctx.f[12].s64 = if ctx.f[11].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[11].f64.trunc() as i64 };
	// 82592A30: D98B0000  stfd f12, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.f[12].u64 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82592CB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82592CB0 size=808
    let mut pc: u32 = 0x82592CB0;
    'dispatch: loop {
        match pc {
            0x82592CB0 => {
    //   block [0x82592CB0..0x82592FD8)
	// 82592CB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82592CB4: 4BFA2405  bl 0x825350b8
	ctx.lr = 0x82592CB8;
	sub_82535080(ctx, base);
	// 82592CB8: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82592CBC: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82592CC0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82592CC4: C19F0024  lfs f12, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82592CC8: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82592CCC: 7C005A2C  dcbt 0, r11
	// 82592CD0: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 82592CD4: C17F0030  lfs f11, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82592CD8: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 82592CDC: C15F002C  lfs f10, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82592CE0: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 82592CE4: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82592CE8: 38E10058  addi r7, r1, 0x58
	ctx.r[7].s64 = ctx.r[1].s64 + 88;
	// 82592CEC: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82592CF0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82592CF4: 11A7030C  vspltisb v13, 7
	for i in 0..16 {
		ctx.v[13].u8[i] = 7 as u8;
	}
	// 82592CF8: F9210068  std r9, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[9].u64 ) };
	// 82592CFC: 3B810060  addi r28, r1, 0x60
	ctx.r[28].s64 = ctx.r[1].s64 + 96;
	// 82592D00: C9AAD700  lfd f13, -0x2900(r10)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[10].u32.wrapping_add(-10496 as u32) ) };
	// 82592D04: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 82592D08: FD6B0372  fmul f11, f11, f13
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[13].f64;
	// 82592D0C: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 82592D10: FDAA0372  fmul f13, f10, f13
	ctx.f[13].f64 = ctx.f[10].f64 * ctx.f[13].f64;
	// 82592D14: 3BC10054  addi r30, r1, 0x54
	ctx.r[30].s64 = ctx.r[1].s64 + 84;
	// 82592D18: 3BA10054  addi r29, r1, 0x54
	ctx.r[29].s64 = ctx.r[1].s64 + 84;
	// 82592D1C: 13ED6904  vslb v31, v13, v13
	ctx.v[31].u8[0] = ctx.v[13].u8[0] << (ctx.v[13].u8[0] & 0x7);
	ctx.v[31].u8[1] = ctx.v[13].u8[1] << (ctx.v[13].u8[1] & 0x7);
	ctx.v[31].u8[2] = ctx.v[13].u8[2] << (ctx.v[13].u8[2] & 0x7);
	ctx.v[31].u8[3] = ctx.v[13].u8[3] << (ctx.v[13].u8[3] & 0x7);
	ctx.v[31].u8[4] = ctx.v[13].u8[4] << (ctx.v[13].u8[4] & 0x7);
	ctx.v[31].u8[5] = ctx.v[13].u8[5] << (ctx.v[13].u8[5] & 0x7);
	ctx.v[31].u8[6] = ctx.v[13].u8[6] << (ctx.v[13].u8[6] & 0x7);
	ctx.v[31].u8[7] = ctx.v[13].u8[7] << (ctx.v[13].u8[7] & 0x7);
	ctx.v[31].u8[8] = ctx.v[13].u8[8] << (ctx.v[13].u8[8] & 0x7);
	ctx.v[31].u8[9] = ctx.v[13].u8[9] << (ctx.v[13].u8[9] & 0x7);
	ctx.v[31].u8[10] = ctx.v[13].u8[10] << (ctx.v[13].u8[10] & 0x7);
	ctx.v[31].u8[11] = ctx.v[13].u8[11] << (ctx.v[13].u8[11] & 0x7);
	ctx.v[31].u8[12] = ctx.v[13].u8[12] << (ctx.v[13].u8[12] & 0x7);
	ctx.v[31].u8[13] = ctx.v[13].u8[13] << (ctx.v[13].u8[13] & 0x7);
	ctx.v[31].u8[14] = ctx.v[13].u8[14] << (ctx.v[13].u8[14] & 0x7);
	ctx.v[31].u8[15] = ctx.v[13].u8[15] << (ctx.v[13].u8[15] & 0x7);
	// 82592D20: 1120038C  vspltisw v9, 0
	for i in 0..4 {
		ctx.v[9].u32[i] = 0;
	}
	// 82592D24: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82592FD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82592FD8 size=1012
    let mut pc: u32 = 0x82592FD8;
    'dispatch: loop {
        match pc {
            0x82592FD8 => {
    //   block [0x82592FD8..0x825933CC)
	// 82592FD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82592FDC: 4BFA20C5  bl 0x825350a0
	ctx.lr = 0x82592FE0;
	sub_82535080(ctx, base);
	// 82592FE0: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82592FE4: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82592FE8: C19F0024  lfs f12, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82592FEC: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82592FF0: 7C001A2C  dcbt 0, r3
	// 82592FF4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 82592FF8: C17F0030  lfs f11, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82592FFC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82593000: C15F002C  lfs f10, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82593004: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82593008: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259300C: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 82593010: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82593014: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 82593018: 1180038C  vspltisw v12, 0
	for i in 0..4 {
		ctx.v[12].u32[i] = 0;
	}
	// 8259301C: F9410068  std r10, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[10].u64 ) };
	// 82593020: 3B810060  addi r28, r1, 0x60
	ctx.r[28].s64 = ctx.r[1].s64 + 96;
	// 82593024: C9ABD700  lfd f13, -0x2900(r11)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82593028: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 8259302C: FD6B0372  fmul f11, f11, f13
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[13].f64;
	// 82593030: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 82593034: FDAA0372  fmul f13, f10, f13
	ctx.f[13].f64 = ctx.f[10].f64 * ctx.f[13].f64;
	// 82593038: 3BC10054  addi r30, r1, 0x54
	ctx.r[30].s64 = ctx.r[1].s64 + 84;
	// 8259303C: 3BA10054  addi r29, r1, 0x54
	ctx.r[29].s64 = ctx.r[1].s64 + 84;
	// 82593040: 1007030C  vspltisb v0, 7
	for i in 0..16 {
		ctx.v[0].u8[i] = 7 as u8;
	}
	// 82593044: 12CC6484  vmr v22, v12
	ctx.v[22] = ctx.v[12];
	// 82593048: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8259304C: 132C6484  vmr v25, v12
	ctx.v[25] = ctx.v[12];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825933D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825933D0 size=1420
    let mut pc: u32 = 0x825933D0;
    'dispatch: loop {
        match pc {
            0x825933D0 => {
    //   block [0x825933D0..0x8259395C)
	// 825933D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825933D4: 4BFA1CAD  bl 0x82535080
	ctx.lr = 0x825933D8;
	sub_82535080(ctx, base);
	// 825933D8: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825933DC: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 825933E0: 90C1013C  stw r6, 0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[6].u32 ) };
	// 825933E4: C1990024  lfs f12, 0x24(r25)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825933E8: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825933EC: 7C001A2C  dcbt 0, r3
	// 825933F0: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 825933F4: C1790030  lfs f11, 0x30(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(48 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825933F8: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825933FC: C159002C  lfs f10, 0x2c(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82593400: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82593404: C0190028  lfs f0, 0x28(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82593408: D0190024  stfs f0, 0x24(r25)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259340C: 38C10054  addi r6, r1, 0x54
	ctx.r[6].s64 = ctx.r[1].s64 + 84;
	// 82593410: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 82593414: 11A0038C  vspltisw v13, 0
	for i in 0..4 {
		ctx.v[13].u32[i] = 0;
	}
	// 82593418: F9410068  std r10, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[10].u64 ) };
	// 8259341C: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 82593420: C9ABD700  lfd f13, -0x2900(r11)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82593424: 39610058  addi r11, r1, 0x58
	ctx.r[11].s64 = ctx.r[1].s64 + 88;
	// 82593428: FD6B0372  fmul f11, f11, f13
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[13].f64;
	// 8259342C: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 82593430: FDAA0372  fmul f13, f10, f13
	ctx.f[13].f64 = ctx.f[10].f64 * ctx.f[13].f64;
	// 82593434: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 82593438: 3BE10060  addi r31, r1, 0x60
	ctx.r[31].s64 = ctx.r[1].s64 + 96;
	// 8259343C: 1007030C  vspltisb v0, 7
	for i in 0..16 {
		ctx.v[0].u8[i] = 7 as u8;
	}
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82593960(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82593960 size=1960
    let mut pc: u32 = 0x82593960;
    'dispatch: loop {
        match pc {
            0x82593960 => {
    //   block [0x82593960..0x82594108)
	// 82593960: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82593964: 4BFA171D  bl 0x82535080
	ctx.lr = 0x82593968;
	sub_82535080(ctx, base);
	// 82593968: 9421FEB0  stwu r1, -0x150(r1)
	ea = ctx.r[1].u32.wrapping_add(-336 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259396C: C1870024  lfs f12, 0x24(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82593970: 90C1017C  stw r6, 0x17c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(380 as u32), ctx.r[6].u32 ) };
	// 82593974: D1810050  stfs f12, 0x50(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82593978: 90E10184  stw r7, 0x184(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(388 as u32), ctx.r[7].u32 ) };
	// 8259397C: 7C001A2C  dcbt 0, r3
	// 82593980: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82593984: C1670030  lfs f11, 0x30(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82593988: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 8259398C: C147002C  lfs f10, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82593990: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 82593994: C0070028  lfs f0, 0x28(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82593998: 38C10054  addi r6, r1, 0x54
	ctx.r[6].s64 = ctx.r[1].s64 + 84;
	// 8259399C: D0070024  stfs f0, 0x24(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825939A0: 3AA00004  li r21, 4
	ctx.r[21].s64 = 4;
	// 825939A4: C9ABD700  lfd f13, -0x2900(r11)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825939A8: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825939AC: FD6B0372  fmul f11, f11, f13
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[13].f64;
	// 825939B0: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 825939B4: FDAA0372  fmul f13, f10, f13
	ctx.f[13].f64 = ctx.f[10].f64 * ctx.f[13].f64;
	// 825939B8: F9410080  std r10, 0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[10].u64 ) };
	// 825939BC: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 825939C0: 11A0038C  vspltisw v13, 0
	for i in 0..4 {
		ctx.v[13].u32[i] = 0;
	}
	// 825939C4: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 825939C8: 1007030C  vspltisb v0, 7
	for i in 0..16 {
		ctx.v[0].u8[i] = 7 as u8;
	}
	// 825939CC: 3BE10070  addi r31, r1, 0x70
	ctx.r[31].s64 = ctx.r[1].s64 + 112;
	// 825939D0: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 825939D4: 122D6C84  vmr v17, v13
	ctx.v[17] = ctx.v[13];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82594108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82594108 size=656
    let mut pc: u32 = 0x82594108;
    'dispatch: loop {
        match pc {
            0x82594108 => {
    //   block [0x82594108..0x82594398)
	// 82594108: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259410C: 4BFA0FA9  bl 0x825350b4
	ctx.lr = 0x82594110;
	sub_82535080(ctx, base);
	// 82594110: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82594114: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82594118: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259411C: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82594120: 7C001A2C  dcbt 0, r3
	// 82594124: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82594128: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259412C: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82594130: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 82594134: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 82594138: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 8259413C: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82594140: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82594144: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82594148: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 8259414C: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 82594150: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 82594154: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 82594158: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259415C: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82594160: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82594164: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82594168: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 8259416C: 3B610068  addi r27, r1, 0x68
	ctx.r[27].s64 = ctx.r[1].s64 + 104;
	// 82594170: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82594398(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82594398 size=756
    let mut pc: u32 = 0x82594398;
    'dispatch: loop {
        match pc {
            0x82594398 => {
    //   block [0x82594398..0x8259468C)
	// 82594398: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259439C: 4BFA0D15  bl 0x825350b0
	ctx.lr = 0x825943A0;
	sub_82535080(ctx, base);
	// 825943A0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825943A4: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 825943A8: C1BF0024  lfs f13, 0x24(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825943AC: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825943B0: 7C001A2C  dcbt 0, r3
	// 825943B4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825943B8: C19F0030  lfs f12, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825943BC: C17F002C  lfs f11, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825943C0: 7CC707B4  extsw r7, r6
	ctx.r[7].s64 = ctx.r[6].s32 as i64;
	// 825943C4: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 825943C8: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 825943CC: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 825943D0: 13C1038C  vspltisw v30, 1
	for i in 0..4 {
		ctx.v[30].u32[i] = 1;
	}
	// 825943D4: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 825943D8: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825943DC: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825943E0: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825943E4: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 825943E8: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825943EC: C01F0028  lfs f0, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825943F0: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825943F4: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 825943F8: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825943FC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82594400: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82594404: 3B610068  addi r27, r1, 0x68
	ctx.r[27].s64 = ctx.r[1].s64 + 104;
	// 82594408: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
	// 8259440C: 13E00484  vmr v31, v0
	ctx.v[31] = ctx.v[0];
	// 82594410: 3B810058  addi r28, r1, 0x58
	ctx.r[28].s64 = ctx.r[1].s64 + 88;
	// 82594414: 10600484  vmr v3, v0
	ctx.v[3] = ctx.v[0];
	// 82594418: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8259441C: 10200484  vmr v1, v0
	ctx.v[1] = ctx.v[0];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82594690(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82594690 size=968
    let mut pc: u32 = 0x82594690;
    'dispatch: loop {
        match pc {
            0x82594690 => {
    //   block [0x82594690..0x82594A58)
	// 82594690: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82594694: 4BFA09FD  bl 0x82535090
	ctx.lr = 0x82594698;
	sub_82535080(ctx, base);
	// 82594698: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259469C: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 825946A0: C1B90024  lfs f13, 0x24(r25)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825946A4: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825946A8: 7C001A2C  dcbt 0, r3
	// 825946AC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825946B0: C1990030  lfs f12, 0x30(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825946B4: C179002C  lfs f11, 0x2c(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 825946B8: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 825946BC: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 825946C0: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 825946C4: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 825946C8: 1321038C  vspltisw v25, 1
	for i in 0..4 {
		ctx.v[25].u32[i] = 1;
	}
	// 825946CC: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 825946D0: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 825946D4: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825946D8: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 825946DC: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 825946E0: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 825946E4: C0190028  lfs f0, 0x28(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825946E8: D0190024  stfs f0, 0x24(r25)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 825946EC: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 825946F0: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825946F4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825946F8: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 825946FC: 3BA10068  addi r29, r1, 0x68
	ctx.r[29].s64 = ctx.r[1].s64 + 104;
	// 82594700: 3BE10058  addi r31, r1, 0x58
	ctx.r[31].s64 = ctx.r[1].s64 + 88;
	// 82594704: 10200484  vmr v1, v0
	ctx.v[1] = ctx.v[0];
	// 82594708: 3BC10058  addi r30, r1, 0x58
	ctx.r[30].s64 = ctx.r[1].s64 + 88;
	// 8259470C: 10600484  vmr v3, v0
	ctx.v[3] = ctx.v[0];
	// 82594710: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 82594714: 13E00484  vmr v31, v0
	ctx.v[31] = ctx.v[0];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82594A58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82594A58 size=1228
    let mut pc: u32 = 0x82594A58;
    'dispatch: loop {
        match pc {
            0x82594A58 => {
    //   block [0x82594A58..0x82594F24)
	// 82594A58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82594A5C: 4BFA0625  bl 0x82535080
	ctx.lr = 0x82594A60;
	sub_82535080(ctx, base);
	// 82594A60: 9421FEE0  stwu r1, -0x120(r1)
	ea = ctx.r[1].u32.wrapping_add(-288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82594A64: 7CF33B78  mr r19, r7
	ctx.r[19].u64 = ctx.r[7].u64;
	// 82594A68: 90C1014C  stw r6, 0x14c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), ctx.r[6].u32 ) };
	// 82594A6C: C1B30024  lfs f13, 0x24(r19)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82594A70: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82594A74: 7C001A2C  dcbt 0, r3
	// 82594A78: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 82594A7C: C1930030  lfs f12, 0x30(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(48 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82594A80: C173002C  lfs f11, 0x2c(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(44 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82594A84: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 82594A88: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82594A8C: 1000038C  vspltisw v0, 0
	for i in 0..4 {
		ctx.v[0].u32[i] = 0;
	}
	// 82594A90: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82594A94: 12A1038C  vspltisw v21, 1
	for i in 0..4 {
		ctx.v[21].u32[i] = 1;
	}
	// 82594A98: 3AA00004  li r21, 4
	ctx.r[21].s64 = 4;
	// 82594A9C: C80BD700  lfd f0, -0x2900(r11)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-10496 as u32) ) };
	// 82594AA0: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 82594AA4: FD8C0032  fmul f12, f12, f0
	ctx.f[12].f64 = ctx.f[12].f64 * ctx.f[0].f64;
	// 82594AA8: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 82594AAC: FD6B0032  fmul f11, f11, f0
	ctx.f[11].f64 = ctx.f[11].f64 * ctx.f[0].f64;
	// 82594AB0: C0130028  lfs f0, 0x28(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82594AB4: D0130024  stfs f0, 0x24(r19)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82594AB8: EDA06828  fsubs f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82594ABC: C8010058  lfd f0, 0x58(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 82594AC0: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82594AC4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 82594AC8: 3BE10070  addi r31, r1, 0x70
	ctx.r[31].s64 = ctx.r[1].s64 + 112;
	// 82594ACC: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 82594AD0: 13800484  vmr v28, v0
	ctx.v[28] = ctx.v[0];
	// 82594AD4: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 82594AD8: 13C00484  vmr v30, v0
	ctx.v[30] = ctx.v[0];
	// 82594ADC: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 82594AE0: 10200484  vmr v1, v0
	ctx.v[1] = ctx.v[0];
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82594F28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82594F28 size=888
    let mut pc: u32 = 0x82594F28;
    'dispatch: loop {
        match pc {
            0x82594F28 => {
    //   block [0x82594F28..0x825952A0)
	// 82594F28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82594F2C: 4BFA0161  bl 0x8253508c
	ctx.lr = 0x82594F30;
	sub_82535080(ctx, base);
	// 82594F30: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82594F34: 3AE3000D  addi r23, r3, 0xd
	ctx.r[23].s64 = ctx.r[3].s64 + 13;
	// 82594F38: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82594F3C: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 82594F40: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82594F44: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 82594F48: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82594F4C: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82594F50: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82594F54: 7D0B51D6  mullw r8, r11, r10
	ctx.r[8].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82594F58: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82594F5C: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82594F60: 7FE9F850  subf r31, r9, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82594F64: 7F0B2050  subf r24, r11, r4
	ctx.r[24].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82594F68: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82594F6C: 7C862A14  add r4, r6, r5
	ctx.r[4].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 82594F70: 3AC30004  addi r22, r3, 4
	ctx.r[22].s64 = ctx.r[3].s64 + 4;
	// 82594F74: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 82594F78: 93E1FF60  stw r31, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[31].u32 ) };
	// 82594F7C: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 82594F80: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 82594F84: 7CCB3A14  add r6, r11, r7
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82594F88: 7C00322C  dcbt 0, r6
	// 82594F8C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82594F90: 3921FF60  addi r9, r1, -0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + -160;
	// 82594F94: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82594F98: 39000028  li r8, 0x28
	ctx.r[8].s64 = 40;
	// 82594F9C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82594FA0: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82594FA4: 3B230024  addi r25, r3, 0x24
	ctx.r[25].s64 = ctx.r[3].s64 + 36;
	// 82594FA8: 38E1FF68  addi r7, r1, -0x98
	ctx.r[7].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825952A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825952A0 size=736
    let mut pc: u32 = 0x825952A0;
    'dispatch: loop {
        match pc {
            0x825952A0 => {
    //   block [0x825952A0..0x82595580)
	// 825952A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825952A4: 4BF9FDF5  bl 0x82535098
	ctx.lr = 0x825952A8;
	sub_82535080(ctx, base);
	// 825952A8: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825952AC: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 825952B0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825952B4: 3AE30008  addi r23, r3, 8
	ctx.r[23].s64 = ctx.r[3].s64 + 8;
	// 825952B8: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825952BC: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825952C0: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825952C4: 3B43000D  addi r26, r3, 0xd
	ctx.r[26].s64 = ctx.r[3].s64 + 13;
	// 825952C8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825952CC: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 825952D0: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825952D4: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825952D8: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825952DC: 7CEA2050  subf r7, r10, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825952E0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825952E4: 3B230004  addi r25, r3, 4
	ctx.r[25].s64 = ctx.r[3].s64 + 4;
	// 825952E8: 3A83001C  addi r20, r3, 0x1c
	ctx.r[20].s64 = ctx.r[3].s64 + 28;
	// 825952EC: 3AC30014  addi r22, r3, 0x14
	ctx.r[22].s64 = ctx.r[3].s64 + 20;
	// 825952F0: 3AA30018  addi r21, r3, 0x18
	ctx.r[21].s64 = ctx.r[3].s64 + 24;
	// 825952F4: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 825952F8: 7F8B2850  subf r28, r11, r5
	ctx.r[28].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825952FC: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 82595300: 7C004A2C  dcbt 0, r9
	// 82595304: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82595308: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 8259530C: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82595310: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 82595314: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82595318: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 8259531C: 3BC30024  addi r30, r3, 0x24
	ctx.r[30].s64 = ctx.r[3].s64 + 36;
	// 82595320: 3881FF78  addi r4, r1, -0x88
	ctx.r[4].s64 = ctx.r[1].s64 + -136;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82595580(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82595580 size=808
    let mut pc: u32 = 0x82595580;
    'dispatch: loop {
        match pc {
            0x82595580 => {
    //   block [0x82595580..0x825958A8)
	// 82595580: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82595584: 4BF9FB09  bl 0x8253508c
	ctx.lr = 0x82595588;
	sub_82535080(ctx, base);
	// 82595588: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259558C: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 82595590: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82595594: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 82595598: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259559C: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 825955A0: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825955A4: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825955A8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825955AC: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825955B0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825955B4: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825955B8: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825955BC: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 825955C0: 7CCA2050  subf r6, r10, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825955C4: 7F2B2850  subf r25, r11, r5
	ctx.r[25].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825955C8: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 825955CC: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 825955D0: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 825955D4: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 825955D8: 90C1FF60  stw r6, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[6].u32 ) };
	// 825955DC: 7D683A14  add r11, r8, r7
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 825955E0: 7C004A2C  dcbt 0, r9
	// 825955E4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 825955E8: 3901FF60  addi r8, r1, -0xa0
	ctx.r[8].s64 = ctx.r[1].s64 + -160;
	// 825955EC: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825955F0: 3B630024  addi r27, r3, 0x24
	ctx.r[27].s64 = ctx.r[3].s64 + 36;
	// 825955F4: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825955F8: 794A07E6  rldicr r10, r10, 0x20, 0x3f
	ctx.r[10].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 825955FC: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 82595600: 3BE1FF68  addi r31, r1, -0x98
	ctx.r[31].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825958A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825958A8 size=1032
    let mut pc: u32 = 0x825958A8;
    'dispatch: loop {
        match pc {
            0x825958A8 => {
    //   block [0x825958A8..0x82595CB0)
	// 825958A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825958AC: 4BF9F7E9  bl 0x82535094
	ctx.lr = 0x825958B0;
	sub_82535080(ctx, base);
	// 825958B0: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 825958B4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825958B8: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 825958BC: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825958C0: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 825958C4: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825958C8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825958CC: 7EAB2850  subf r21, r11, r5
	ctx.r[21].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825958D0: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825958D4: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825958D8: 9101FF58  stw r8, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[8].u32 ) };
	// 825958DC: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 825958E0: 9121FF68  stw r9, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[9].u32 ) };
	// 825958E4: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825958E8: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 825958EC: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 825958F0: 7CA92050  subf r5, r9, r4
	ctx.r[5].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 825958F4: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 825958F8: 9101FF5C  stw r8, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[8].u32 ) };
	// 825958FC: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 82595900: 90E1FF64  stw r7, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[7].u32 ) };
	// 82595904: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82595908: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259590C: 90A1FF54  stw r5, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[5].u32 ) };
	// 82595910: 7D673214  add r11, r7, r6
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 82595914: 9101FF50  stw r8, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[8].u32 ) };
	// 82595918: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259591C: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82595920: 7C005A2C  dcbt 0, r11
	// 82595924: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82595928: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259592C: 3901FF54  addi r8, r1, -0xac
	ctx.r[8].s64 = ctx.r[1].s64 + -172;
	// 82595930: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82595934: 792907E6  rldicr r9, r9, 0x20, 0x3f
	ctx.r[9].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82595938: 3AE30024  addi r23, r3, 0x24
	ctx.r[23].s64 = ctx.r[3].s64 + 36;
	// 8259593C: 38E00028  li r7, 0x28
	ctx.r[7].s64 = 40;
	// 82595940: 3881FF70  addi r4, r1, -0x90
	ctx.r[4].s64 = ctx.r[1].s64 + -144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82595CB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82595CB0 size=1272
    let mut pc: u32 = 0x82595CB0;
    'dispatch: loop {
        match pc {
            0x82595CB0 => {
    //   block [0x82595CB0..0x825961A8)
	// 82595CB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82595CB4: 4BF9F3D9  bl 0x8253508c
	ctx.lr = 0x82595CB8;
	sub_82535080(ctx, base);
	// 82595CB8: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 82595CBC: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82595CC0: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 82595CC4: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82595CC8: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 82595CCC: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82595CD0: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82595CD4: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82595CD8: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82595CDC: 9101FF4C  stw r8, -0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), ctx.r[8].u32 ) };
	// 82595CE0: 90E1FF58  stw r7, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[7].u32 ) };
	// 82595CE4: 9121FF60  stw r9, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[9].u32 ) };
	// 82595CE8: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82595CEC: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 82595CF0: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 82595CF4: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 82595CF8: 7CA9F850  subf r5, r9, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82595CFC: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 82595D00: 9101FF50  stw r8, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[8].u32 ) };
	// 82595D04: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 82595D08: 90E1FF5C  stw r7, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[7].u32 ) };
	// 82595D0C: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82595D10: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82595D14: 9161FF48  stw r11, -0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), ctx.r[11].u32 ) };
	// 82595D18: 7D673214  add r11, r7, r6
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 82595D1C: 90A1FF40  stw r5, -0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), ctx.r[5].u32 ) };
	// 82595D20: 9101FF44  stw r8, -0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-188 as u32), ctx.r[8].u32 ) };
	// 82595D24: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82595D28: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82595D2C: 7C005A2C  dcbt 0, r11
	// 82595D30: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 82595D34: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82595D38: 38E1FF40  addi r7, r1, -0xc0
	ctx.r[7].s64 = ctx.r[1].s64 + -192;
	// 82595D3C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82595D40: 790807E6  rldicr r8, r8, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82595D44: 39230024  addi r9, r3, 0x24
	ctx.r[9].s64 = ctx.r[3].s64 + 36;
	// 82595D48: 3BE00028  li r31, 0x28
	ctx.r[31].s64 = 40;
	// 82595D4C: 3BC1FF68  addi r30, r1, -0x98
	ctx.r[30].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825961A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825961A8 size=948
    let mut pc: u32 = 0x825961A8;
    'dispatch: loop {
        match pc {
            0x825961A8 => {
    //   block [0x825961A8..0x8259655C)
	// 825961A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825961AC: 4BF9EEE1  bl 0x8253508c
	ctx.lr = 0x825961B0;
	sub_82535080(ctx, base);
	// 825961B0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825961B4: 3AE3000D  addi r23, r3, 0xd
	ctx.r[23].s64 = ctx.r[3].s64 + 13;
	// 825961B8: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825961BC: 3B630034  addi r27, r3, 0x34
	ctx.r[27].s64 = ctx.r[3].s64 + 52;
	// 825961C0: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825961C4: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 825961C8: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825961CC: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825961D0: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825961D4: 7D0A59D6  mullw r8, r10, r11
	ctx.r[8].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825961D8: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825961DC: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825961E0: 7FE9F850  subf r31, r9, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 825961E4: 7F0B2050  subf r24, r11, r4
	ctx.r[24].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 825961E8: 550B083C  slwi r11, r8, 1
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825961EC: 7C862A14  add r4, r6, r5
	ctx.r[4].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 825961F0: 3AC30004  addi r22, r3, 4
	ctx.r[22].s64 = ctx.r[3].s64 + 4;
	// 825961F4: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 825961F8: 93E1FF60  stw r31, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[31].u32 ) };
	// 825961FC: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 82596200: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 82596204: 7CCB3A14  add r6, r11, r7
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82596208: 7C00322C  dcbt 0, r6
	// 8259620C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82596210: 3921FF60  addi r9, r1, -0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + -160;
	// 82596214: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82596218: 39000028  li r8, 0x28
	ctx.r[8].s64 = 40;
	// 8259621C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82596220: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82596224: 3B230024  addi r25, r3, 0x24
	ctx.r[25].s64 = ctx.r[3].s64 + 36;
	// 82596228: 38E1FF68  addi r7, r1, -0x98
	ctx.r[7].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82596560(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82596560 size=792
    let mut pc: u32 = 0x82596560;
    'dispatch: loop {
        match pc {
            0x82596560 => {
    //   block [0x82596560..0x82596878)
	// 82596560: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82596564: 4BF9EB35  bl 0x82535098
	ctx.lr = 0x82596568;
	sub_82535080(ctx, base);
	// 82596568: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259656C: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 82596570: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82596574: 3AE30008  addi r23, r3, 8
	ctx.r[23].s64 = ctx.r[3].s64 + 8;
	// 82596578: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259657C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82596580: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82596584: 3B43000D  addi r26, r3, 0xd
	ctx.r[26].s64 = ctx.r[3].s64 + 13;
	// 82596588: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259658C: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82596590: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82596594: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82596598: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259659C: 7CEA2050  subf r7, r10, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825965A0: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825965A4: 3B230004  addi r25, r3, 4
	ctx.r[25].s64 = ctx.r[3].s64 + 4;
	// 825965A8: 3A83001C  addi r20, r3, 0x1c
	ctx.r[20].s64 = ctx.r[3].s64 + 28;
	// 825965AC: 3AC30014  addi r22, r3, 0x14
	ctx.r[22].s64 = ctx.r[3].s64 + 20;
	// 825965B0: 3AA30018  addi r21, r3, 0x18
	ctx.r[21].s64 = ctx.r[3].s64 + 24;
	// 825965B4: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 825965B8: 7F8B2850  subf r28, r11, r5
	ctx.r[28].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825965BC: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 825965C0: 7C004A2C  dcbt 0, r9
	// 825965C4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 825965C8: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 825965CC: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825965D0: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 825965D4: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825965D8: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 825965DC: 3BA30024  addi r29, r3, 0x24
	ctx.r[29].s64 = ctx.r[3].s64 + 36;
	// 825965E0: 3881FF78  addi r4, r1, -0x88
	ctx.r[4].s64 = ctx.r[1].s64 + -136;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82596878(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82596878 size=916
    let mut pc: u32 = 0x82596878;
    'dispatch: loop {
        match pc {
            0x82596878 => {
    //   block [0x82596878..0x82596C0C)
	// 82596878: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259687C: 4BF9E811  bl 0x8253508c
	ctx.lr = 0x82596880;
	sub_82535080(ctx, base);
	// 82596880: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82596884: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 82596888: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259688C: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 82596890: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82596894: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82596898: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259689C: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 825968A0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825968A4: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825968A8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825968AC: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825968B0: 7F2B2850  subf r25, r11, r5
	ctx.r[25].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825968B4: 7D683A14  add r11, r8, r7
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 825968B8: 7CEA2050  subf r7, r10, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825968BC: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825968C0: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 825968C4: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 825968C8: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 825968CC: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 825968D0: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 825968D4: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 825968D8: 7C004A2C  dcbt 0, r9
	// 825968DC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 825968E0: 3901FF60  addi r8, r1, -0xa0
	ctx.r[8].s64 = ctx.r[1].s64 + -160;
	// 825968E4: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825968E8: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 825968EC: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825968F0: 794A07E6  rldicr r10, r10, 0x20, 0x3f
	ctx.r[10].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 825968F4: 3B630024  addi r27, r3, 0x24
	ctx.r[27].s64 = ctx.r[3].s64 + 36;
	// 825968F8: 38A1FF68  addi r5, r1, -0x98
	ctx.r[5].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82596C10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82596C10 size=1240
    let mut pc: u32 = 0x82596C10;
    'dispatch: loop {
        match pc {
            0x82596C10 => {
    //   block [0x82596C10..0x825970E8)
	// 82596C10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82596C14: 4BF9E47D  bl 0x82535090
	ctx.lr = 0x82596C18;
	sub_82535080(ctx, base);
	// 82596C18: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 82596C1C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82596C20: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 82596C24: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82596C28: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 82596C2C: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82596C30: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82596C34: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82596C38: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82596C3C: 9101FF58  stw r8, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[8].u32 ) };
	// 82596C40: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 82596C44: 9121FF68  stw r9, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[9].u32 ) };
	// 82596C48: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82596C4C: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 82596C50: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 82596C54: 7EEB2050  subf r23, r11, r4
	ctx.r[23].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82596C58: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 82596C5C: 9101FF5C  stw r8, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[8].u32 ) };
	// 82596C60: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 82596C64: 90E1FF64  stw r7, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[7].u32 ) };
	// 82596C68: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82596C6C: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82596C70: 7D673214  add r11, r7, r6
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 82596C74: 7CC9F850  subf r6, r9, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82596C78: 9101FF50  stw r8, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[8].u32 ) };
	// 82596C7C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82596C80: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82596C84: 90C1FF54  stw r6, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[6].u32 ) };
	// 82596C88: 7C005A2C  dcbt 0, r11
	// 82596C8C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82596C90: 3901FF54  addi r8, r1, -0xac
	ctx.r[8].s64 = ctx.r[1].s64 + -172;
	// 82596C94: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82596C98: 792907E6  rldicr r9, r9, 0x20, 0x3f
	ctx.r[9].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82596C9C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82596CA0: 38E00028  li r7, 0x28
	ctx.r[7].s64 = 40;
	// 82596CA4: 3B030024  addi r24, r3, 0x24
	ctx.r[24].s64 = ctx.r[3].s64 + 36;
	// 82596CA8: 3881FF70  addi r4, r1, -0x90
	ctx.r[4].s64 = ctx.r[1].s64 + -144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825970E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825970E8 size=1572
    let mut pc: u32 = 0x825970E8;
    'dispatch: loop {
        match pc {
            0x825970E8 => {
    //   block [0x825970E8..0x8259770C)
	// 825970E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825970EC: 4BF9DF9D  bl 0x82535088
	ctx.lr = 0x825970F0;
	sub_82535080(ctx, base);
	// 825970F0: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 825970F4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825970F8: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 825970FC: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82597100: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82597104: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 82597108: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259710C: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82597110: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82597114: 9101FF3C  stw r8, -0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-196 as u32), ctx.r[8].u32 ) };
	// 82597118: 90E1FF48  stw r7, -0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), ctx.r[7].u32 ) };
	// 8259711C: 9121FF50  stw r9, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[9].u32 ) };
	// 82597120: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82597124: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 82597128: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 8259712C: 7D6B2050  subf r11, r11, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82597130: 38C30034  addi r6, r3, 0x34
	ctx.r[6].s64 = ctx.r[3].s64 + 52;
	// 82597134: 9101FF40  stw r8, -0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), ctx.r[8].u32 ) };
	// 82597138: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 8259713C: 90E1FF4C  stw r7, -0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), ctx.r[7].u32 ) };
	// 82597140: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82597144: 9161FF38  stw r11, -0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-200 as u32), ctx.r[11].u32 ) };
	// 82597148: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259714C: 7D672A14  add r11, r7, r5
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 82597150: 7CA9F850  subf r5, r9, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82597154: 9101FF34  stw r8, -0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-204 as u32), ctx.r[8].u32 ) };
	// 82597158: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259715C: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82597160: 90A1FF30  stw r5, -0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-208 as u32), ctx.r[5].u32 ) };
	// 82597164: 7C005A2C  dcbt 0, r11
	// 82597168: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8259716C: 38E1FF30  addi r7, r1, -0xd0
	ctx.r[7].s64 = ctx.r[1].s64 + -208;
	// 82597170: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82597174: 792907E6  rldicr r9, r9, 0x20, 0x3f
	ctx.r[9].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82597178: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259717C: 39030024  addi r8, r3, 0x24
	ctx.r[8].s64 = ctx.r[3].s64 + 36;
	// 82597180: 38800028  li r4, 0x28
	ctx.r[4].s64 = 40;
	// 82597184: 3BE1FF58  addi r31, r1, -0xa8
	ctx.r[31].s64 = ctx.r[1].s64 + -168;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82597710(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82597710 size=940
    let mut pc: u32 = 0x82597710;
    'dispatch: loop {
        match pc {
            0x82597710 => {
    //   block [0x82597710..0x82597ABC)
	// 82597710: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82597714: 4BF9D97D  bl 0x82535090
	ctx.lr = 0x82597718;
	sub_82535080(ctx, base);
	// 82597718: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259771C: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 82597720: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82597724: 3B230034  addi r25, r3, 0x34
	ctx.r[25].s64 = ctx.r[3].s64 + 52;
	// 82597728: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259772C: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 82597730: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82597734: 7F6A2050  subf r27, r10, r4
	ctx.r[27].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 82597738: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259773C: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82597740: 7C89F850  subf r4, r9, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82597744: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82597748: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259774C: 7D0A59D6  mullw r8, r10, r11
	ctx.r[8].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82597750: 9081FF60  stw r4, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[4].u32 ) };
	// 82597754: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 82597758: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 8259775C: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 82597760: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 82597764: 7FC62A14  add r30, r6, r5
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 82597768: 7CE74214  add r7, r7, r8
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 8259776C: 7C003A2C  dcbt 0, r7
	// 82597770: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82597774: 3921FF60  addi r9, r1, -0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + -160;
	// 82597778: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259777C: 39000028  li r8, 0x28
	ctx.r[8].s64 = 40;
	// 82597780: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82597784: 794A07E6  rldicr r10, r10, 0x20, 0x3f
	ctx.r[10].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82597788: 3B430024  addi r26, r3, 0x24
	ctx.r[26].s64 = ctx.r[3].s64 + 36;
	// 8259778C: 38C1FF68  addi r6, r1, -0x98
	ctx.r[6].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82597AC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82597AC0 size=824
    let mut pc: u32 = 0x82597AC0;
    'dispatch: loop {
        match pc {
            0x82597AC0 => {
    //   block [0x82597AC0..0x82597DF8)
	// 82597AC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82597AC4: 4BF9D5D1  bl 0x82535094
	ctx.lr = 0x82597AC8;
	sub_82535080(ctx, base);
	// 82597AC8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82597ACC: 3BC30034  addi r30, r3, 0x34
	ctx.r[30].s64 = ctx.r[3].s64 + 52;
	// 82597AD0: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82597AD4: 3AC30008  addi r22, r3, 8
	ctx.r[22].s64 = ctx.r[3].s64 + 8;
	// 82597AD8: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82597ADC: 3B23000D  addi r25, r3, 0xd
	ctx.r[25].s64 = ctx.r[3].s64 + 13;
	// 82597AE0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82597AE4: 7F6B3850  subf r27, r11, r7
	ctx.r[27].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 82597AE8: 80A30018  lwz r5, 0x18(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82597AEC: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82597AF0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82597AF4: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82597AF8: 7CEA2850  subf r7, r10, r5
	ctx.r[7].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 82597AFC: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82597B00: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82597B04: 3B030004  addi r24, r3, 4
	ctx.r[24].s64 = ctx.r[3].s64 + 4;
	// 82597B08: 3A63001C  addi r19, r3, 0x1c
	ctx.r[19].s64 = ctx.r[3].s64 + 28;
	// 82597B0C: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 82597B10: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 82597B14: 3A830018  addi r20, r3, 0x18
	ctx.r[20].s64 = ctx.r[3].s64 + 24;
	// 82597B18: 7D083214  add r8, r8, r6
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 82597B1C: 7C004A2C  dcbt 0, r9
	// 82597B20: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82597B24: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 82597B28: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82597B2C: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 82597B30: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82597B34: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82597B38: 3B830024  addi r28, r3, 0x24
	ctx.r[28].s64 = ctx.r[3].s64 + 36;
	// 82597B3C: 3881FF78  addi r4, r1, -0x88
	ctx.r[4].s64 = ctx.r[1].s64 + -136;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82597DF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82597DF8 size=992
    let mut pc: u32 = 0x82597DF8;
    'dispatch: loop {
        match pc {
            0x82597DF8 => {
    //   block [0x82597DF8..0x825981D8)
	// 82597DF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82597DFC: 4BF9D291  bl 0x8253508c
	ctx.lr = 0x82597E00;
	sub_82535080(ctx, base);
	// 82597E00: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82597E04: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 82597E08: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82597E0C: 3AA30008  addi r21, r3, 8
	ctx.r[21].s64 = ctx.r[3].s64 + 8;
	// 82597E10: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82597E14: 3B03000D  addi r24, r3, 0xd
	ctx.r[24].s64 = ctx.r[3].s64 + 13;
	// 82597E18: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82597E1C: 7F2B3850  subf r25, r11, r7
	ctx.r[25].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 82597E20: 80A30018  lwz r5, 0x18(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82597E24: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82597E28: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82597E2C: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82597E30: 7CEA2850  subf r7, r10, r5
	ctx.r[7].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 82597E34: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82597E38: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82597E3C: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 82597E40: 3A43001C  addi r18, r3, 0x1c
	ctx.r[18].s64 = ctx.r[3].s64 + 28;
	// 82597E44: 3A830014  addi r20, r3, 0x14
	ctx.r[20].s64 = ctx.r[3].s64 + 20;
	// 82597E48: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 82597E4C: 3A630018  addi r19, r3, 0x18
	ctx.r[19].s64 = ctx.r[3].s64 + 24;
	// 82597E50: 7D683214  add r11, r8, r6
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 82597E54: 7C004A2C  dcbt 0, r9
	// 82597E58: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82597E5C: 3901FF60  addi r8, r1, -0xa0
	ctx.r[8].s64 = ctx.r[1].s64 + -160;
	// 82597E60: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82597E64: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 82597E68: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82597E6C: 794A07E6  rldicr r10, r10, 0x20, 0x3f
	ctx.r[10].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82597E70: 3B630024  addi r27, r3, 0x24
	ctx.r[27].s64 = ctx.r[3].s64 + 36;
	// 82597E74: 38A1FF68  addi r5, r1, -0x98
	ctx.r[5].s64 = ctx.r[1].s64 + -152;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825981D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825981D8 size=1332
    let mut pc: u32 = 0x825981D8;
    'dispatch: loop {
        match pc {
            0x825981D8 => {
    //   block [0x825981D8..0x8259870C)
	// 825981D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825981DC: 4BF9CEBD  bl 0x82535098
	ctx.lr = 0x825981E0;
	sub_82535080(ctx, base);
	// 825981E0: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 825981E4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825981E8: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 825981EC: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825981F0: 38830014  addi r4, r3, 0x14
	ctx.r[4].s64 = ctx.r[3].s64 + 20;
	// 825981F4: 80C30004  lwz r6, 4(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825981F8: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 825981FC: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82598200: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 82598204: 9121FF7C  stw r9, -0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-132 as u32), ctx.r[9].u32 ) };
	// 82598208: 9081FF74  stw r4, -0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-140 as u32), ctx.r[4].u32 ) };
	// 8259820C: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82598210: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82598214: 9101FF6C  stw r8, -0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-148 as u32), ctx.r[8].u32 ) };
	// 82598218: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259821C: 38E3001C  addi r7, r3, 0x1c
	ctx.r[7].s64 = ctx.r[3].s64 + 28;
	// 82598220: 7D6B3050  subf r11, r11, r6
	ctx.r[11].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 82598224: 3BE30018  addi r31, r3, 0x18
	ctx.r[31].s64 = ctx.r[3].s64 + 24;
	// 82598228: 7CC92050  subf r6, r9, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 8259822C: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82598230: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82598234: 90E1FF60  stw r7, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[7].u32 ) };
	// 82598238: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 8259823C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82598240: 9161FF68  stw r11, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[11].u32 ) };
	// 82598244: 93E1FF78  stw r31, -0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[31].u32 ) };
	// 82598248: 7D683A14  add r11, r8, r7
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259824C: 90C1FF64  stw r6, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[6].u32 ) };
	// 82598250: 7C00522C  dcbt 0, r10
	// 82598254: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82598258: 3901FF64  addi r8, r1, -0x9c
	ctx.r[8].s64 = ctx.r[1].s64 + -156;
	// 8259825C: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82598260: 792907E6  rldicr r9, r9, 0x20, 0x3f
	ctx.r[9].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82598264: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82598268: 38E00028  li r7, 0x28
	ctx.r[7].s64 = 40;
	// 8259826C: 3AE30024  addi r23, r3, 0x24
	ctx.r[23].s64 = ctx.r[3].s64 + 36;
	// 82598270: 3881FF80  addi r4, r1, -0x80
	ctx.r[4].s64 = ctx.r[1].s64 + -128;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82598710(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82598710 size=1684
    let mut pc: u32 = 0x82598710;
    'dispatch: loop {
        match pc {
            0x82598710 => {
    //   block [0x82598710..0x82598DA4)
	// 82598710: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82598714: 4BF9C989  bl 0x8253509c
	ctx.lr = 0x82598718;
	sub_82535080(ctx, base);
	// 82598718: 38E30004  addi r7, r3, 4
	ctx.r[7].s64 = ctx.r[3].s64 + 4;
	// 8259871C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82598720: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 82598724: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82598728: 38830014  addi r4, r3, 0x14
	ctx.r[4].s64 = ctx.r[3].s64 + 20;
	// 8259872C: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82598730: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 82598734: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82598738: 90E1FF7C  stw r7, -0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-132 as u32), ctx.r[7].u32 ) };
	// 8259873C: 9121FF8C  stw r9, -0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-116 as u32), ctx.r[9].u32 ) };
	// 82598740: 9081FF84  stw r4, -0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-124 as u32), ctx.r[4].u32 ) };
	// 82598744: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82598748: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259874C: 9101FF78  stw r8, -0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.r[8].u32 ) };
	// 82598750: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82598754: 38E3001C  addi r7, r3, 0x1c
	ctx.r[7].s64 = ctx.r[3].s64 + 28;
	// 82598758: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 8259875C: 3BE30018  addi r31, r3, 0x18
	ctx.r[31].s64 = ctx.r[3].s64 + 24;
	// 82598760: 7C892050  subf r4, r9, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 82598764: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82598768: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259876C: 90E1FF68  stw r7, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[7].u32 ) };
	// 82598770: 38C30034  addi r6, r3, 0x34
	ctx.r[6].s64 = ctx.r[3].s64 + 52;
	// 82598774: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82598778: 9161FF64  stw r11, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[11].u32 ) };
	// 8259877C: 93E1FF88  stw r31, -0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.r[31].u32 ) };
	// 82598780: 7D683A14  add r11, r8, r7
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82598784: 9081FF60  stw r4, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[4].u32 ) };
	// 82598788: 7C00522C  dcbt 0, r10
	// 8259878C: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 82598790: 38E1FF60  addi r7, r1, -0xa0
	ctx.r[7].s64 = ctx.r[1].s64 + -160;
	// 82598794: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82598798: 790807E6  rldicr r8, r8, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 8259879C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825987A0: 39230024  addi r9, r3, 0x24
	ctx.r[9].s64 = ctx.r[3].s64 + 36;
	// 825987A4: 3BE00028  li r31, 0x28
	ctx.r[31].s64 = 40;
	// 825987A8: 3BC1FF70  addi r30, r1, -0x90
	ctx.r[30].s64 = ctx.r[1].s64 + -144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82598DA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82598DA8 size=976
    let mut pc: u32 = 0x82598DA8;
    'dispatch: loop {
        match pc {
            0x82598DA8 => {
    //   block [0x82598DA8..0x82599178)
	// 82598DA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82598DAC: 4BF9C2DD  bl 0x82535088
	ctx.lr = 0x82598DB0;
	sub_82535080(ctx, base);
	// 82598DB0: 8963000D  lbz r11, 0xd(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82598DB4: 3AC3000D  addi r22, r3, 0xd
	ctx.r[22].s64 = ctx.r[3].s64 + 13;
	// 82598DB8: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82598DBC: 3B430034  addi r26, r3, 0x34
	ctx.r[26].s64 = ctx.r[3].s64 + 52;
	// 82598DC0: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82598DC4: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 82598DC8: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82598DCC: 7D6B51D6  mullw r11, r11, r10
	ctx.r[11].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82598DD0: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82598DD4: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82598DD8: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82598DDC: 7FE9F850  subf r31, r9, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82598DE0: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82598DE4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82598DE8: 7EEA2050  subf r23, r10, r4
	ctx.r[23].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 82598DEC: 7C862A14  add r4, r6, r5
	ctx.r[4].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 82598DF0: 3A630008  addi r19, r3, 8
	ctx.r[19].s64 = ctx.r[3].s64 + 8;
	// 82598DF4: 93E1FF50  stw r31, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[31].u32 ) };
	// 82598DF8: 3AA30004  addi r21, r3, 4
	ctx.r[21].s64 = ctx.r[3].s64 + 4;
	// 82598DFC: 3A03001C  addi r16, r3, 0x1c
	ctx.r[16].s64 = ctx.r[3].s64 + 28;
	// 82598E00: 3A430014  addi r18, r3, 0x14
	ctx.r[18].s64 = ctx.r[3].s64 + 20;
	// 82598E04: 3A230018  addi r17, r3, 0x18
	ctx.r[17].s64 = ctx.r[3].s64 + 24;
	// 82598E08: 7CCB4214  add r6, r11, r8
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82598E0C: 7C00322C  dcbt 0, r6
	// 82598E10: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82598E14: 3941FF50  addi r10, r1, -0xb0
	ctx.r[10].s64 = ctx.r[1].s64 + -176;
	// 82598E18: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82598E1C: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 82598E20: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82598E24: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82598E28: 3B030024  addi r24, r3, 0x24
	ctx.r[24].s64 = ctx.r[3].s64 + 36;
	// 82598E2C: 3901FF58  addi r8, r1, -0xa8
	ctx.r[8].s64 = ctx.r[1].s64 + -168;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82599178(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82599178 size=816
    let mut pc: u32 = 0x82599178;
    'dispatch: loop {
        match pc {
            0x82599178 => {
    //   block [0x82599178..0x825994A8)
	// 82599178: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259917C: 4BF9BF19  bl 0x82535094
	ctx.lr = 0x82599180;
	sub_82535080(ctx, base);
	// 82599180: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82599184: 3BC30034  addi r30, r3, 0x34
	ctx.r[30].s64 = ctx.r[3].s64 + 52;
	// 82599188: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259918C: 3AC30008  addi r22, r3, 8
	ctx.r[22].s64 = ctx.r[3].s64 + 8;
	// 82599190: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82599194: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82599198: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259919C: 3B23000D  addi r25, r3, 0xd
	ctx.r[25].s64 = ctx.r[3].s64 + 13;
	// 825991A0: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825991A4: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 825991A8: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825991AC: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825991B0: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825991B4: 7CEA2050  subf r7, r10, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825991B8: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825991BC: 3B030004  addi r24, r3, 4
	ctx.r[24].s64 = ctx.r[3].s64 + 4;
	// 825991C0: 3A63001C  addi r19, r3, 0x1c
	ctx.r[19].s64 = ctx.r[3].s64 + 28;
	// 825991C4: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 825991C8: 3A830018  addi r20, r3, 0x18
	ctx.r[20].s64 = ctx.r[3].s64 + 24;
	// 825991CC: 90E1FF70  stw r7, -0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.r[7].u32 ) };
	// 825991D0: 7F6B2850  subf r27, r11, r5
	ctx.r[27].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825991D4: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 825991D8: 7C004A2C  dcbt 0, r9
	// 825991DC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 825991E0: 3941FF70  addi r10, r1, -0x90
	ctx.r[10].s64 = ctx.r[1].s64 + -144;
	// 825991E4: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825991E8: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 825991EC: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825991F0: 796B07E6  rldicr r11, r11, 0x20, 0x3f
	ctx.r[11].u64 = (ctx.r[11].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 825991F4: 3BA30024  addi r29, r3, 0x24
	ctx.r[29].s64 = ctx.r[3].s64 + 36;
	// 825991F8: 38A1FF78  addi r5, r1, -0x88
	ctx.r[5].s64 = ctx.r[1].s64 + -136;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825994A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x825994A8 size=968
    let mut pc: u32 = 0x825994A8;
    'dispatch: loop {
        match pc {
            0x825994A8 => {
    //   block [0x825994A8..0x82599870)
	// 825994A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825994AC: 4BF9BBDD  bl 0x82535088
	ctx.lr = 0x825994B0;
	sub_82535080(ctx, base);
	// 825994B0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825994B4: 3B830034  addi r28, r3, 0x34
	ctx.r[28].s64 = ctx.r[3].s64 + 52;
	// 825994B8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825994BC: 3A830008  addi r20, r3, 8
	ctx.r[20].s64 = ctx.r[3].s64 + 8;
	// 825994C0: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825994C4: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825994C8: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825994CC: 3AE3000D  addi r23, r3, 0xd
	ctx.r[23].s64 = ctx.r[3].s64 + 13;
	// 825994D0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825994D4: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825994D8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825994DC: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825994E0: 7F0B2850  subf r24, r11, r5
	ctx.r[24].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825994E4: 7D683A14  add r11, r8, r7
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 825994E8: 7CEA2050  subf r7, r10, r4
	ctx.r[7].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825994EC: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 825994F0: 3AC30004  addi r22, r3, 4
	ctx.r[22].s64 = ctx.r[3].s64 + 4;
	// 825994F4: 3A23001C  addi r17, r3, 0x1c
	ctx.r[17].s64 = ctx.r[3].s64 + 28;
	// 825994F8: 3A630014  addi r19, r3, 0x14
	ctx.r[19].s64 = ctx.r[3].s64 + 20;
	// 825994FC: 3A430018  addi r18, r3, 0x18
	ctx.r[18].s64 = ctx.r[3].s64 + 24;
	// 82599500: 90E1FF50  stw r7, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[7].u32 ) };
	// 82599504: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 82599508: 7C004A2C  dcbt 0, r9
	// 8259950C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82599510: 3901FF50  addi r8, r1, -0xb0
	ctx.r[8].s64 = ctx.r[1].s64 + -176;
	// 82599514: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82599518: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 8259951C: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82599520: 794A07E6  rldicr r10, r10, 0x20, 0x3f
	ctx.r[10].u64 = (ctx.r[10].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82599524: 3B430024  addi r26, r3, 0x24
	ctx.r[26].s64 = ctx.r[3].s64 + 36;
	// 82599528: 38A1FF58  addi r5, r1, -0xa8
	ctx.r[5].s64 = ctx.r[1].s64 + -168;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82599870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82599870 size=1336
    let mut pc: u32 = 0x82599870;
    'dispatch: loop {
        match pc {
            0x82599870 => {
    //   block [0x82599870..0x82599DA8)
	// 82599870: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82599874: 4BF9B81D  bl 0x82535090
	ctx.lr = 0x82599878;
	sub_82535080(ctx, base);
	// 82599878: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 8259987C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82599880: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 82599884: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82599888: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 8259988C: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82599890: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82599894: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82599898: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259989C: 9101FF5C  stw r8, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[8].u32 ) };
	// 825998A0: 90E1FF64  stw r7, -0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), ctx.r[7].u32 ) };
	// 825998A4: 9121FF6C  stw r9, -0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-148 as u32), ctx.r[9].u32 ) };
	// 825998A8: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825998AC: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 825998B0: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 825998B4: 7D6B2850  subf r11, r11, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 825998B8: 7CA9F850  subf r5, r9, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 825998BC: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 825998C0: 9101FF60  stw r8, -0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.r[8].u32 ) };
	// 825998C4: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 825998C8: 90E1FF68  stw r7, -0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.r[7].u32 ) };
	// 825998CC: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825998D0: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 825998D4: 9161FF58  stw r11, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[11].u32 ) };
	// 825998D8: 7D673214  add r11, r7, r6
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 825998DC: 90A1FF54  stw r5, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[5].u32 ) };
	// 825998E0: 9101FF50  stw r8, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[8].u32 ) };
	// 825998E4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825998E8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 825998EC: 7C005A2C  dcbt 0, r11
	// 825998F0: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 825998F4: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825998F8: 3901FF54  addi r8, r1, -0xac
	ctx.r[8].s64 = ctx.r[1].s64 + -172;
	// 825998FC: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82599900: 792907E6  rldicr r9, r9, 0x20, 0x3f
	ctx.r[9].u64 = (ctx.r[9].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82599904: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 82599908: 3AE30024  addi r23, r3, 0x24
	ctx.r[23].s64 = ctx.r[3].s64 + 36;
	// 8259990C: 3BE1FF70  addi r31, r1, -0x90
	ctx.r[31].s64 = ctx.r[1].s64 + -144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82599DA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82599DA8 size=1684
    let mut pc: u32 = 0x82599DA8;
    'dispatch: loop {
        match pc {
            0x82599DA8 => {
    //   block [0x82599DA8..0x8259A43C)
	// 82599DA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82599DAC: 4BF9B2DD  bl 0x82535088
	ctx.lr = 0x82599DB0;
	sub_82535080(ctx, base);
	// 82599DB0: 3903000D  addi r8, r3, 0xd
	ctx.r[8].s64 = ctx.r[3].s64 + 13;
	// 82599DB4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82599DB8: 38E30014  addi r7, r3, 0x14
	ctx.r[7].s64 = ctx.r[3].s64 + 20;
	// 82599DBC: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 82599DC0: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 82599DC4: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82599DC8: 83E30018  lwz r31, 0x18(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 82599DCC: 7D4A59D6  mullw r10, r10, r11
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82599DD0: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82599DD4: 9101FF4C  stw r8, -0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), ctx.r[8].u32 ) };
	// 82599DD8: 90E1FF54  stw r7, -0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), ctx.r[7].u32 ) };
	// 82599DDC: 9121FF5C  stw r9, -0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), ctx.r[9].u32 ) };
	// 82599DE0: 8123001C  lwz r9, 0x1c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 82599DE4: 39030004  addi r8, r3, 4
	ctx.r[8].s64 = ctx.r[3].s64 + 4;
	// 82599DE8: 38E30018  addi r7, r3, 0x18
	ctx.r[7].s64 = ctx.r[3].s64 + 24;
	// 82599DEC: 7D6B2050  subf r11, r11, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82599DF0: 7C89F850  subf r4, r9, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82599DF4: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 82599DF8: 9101FF50  stw r8, -0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.r[8].u32 ) };
	// 82599DFC: 3903001C  addi r8, r3, 0x1c
	ctx.r[8].s64 = ctx.r[3].s64 + 28;
	// 82599E00: 90E1FF58  stw r7, -0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.r[7].u32 ) };
	// 82599E04: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82599E08: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82599E0C: 9161FF48  stw r11, -0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), ctx.r[11].u32 ) };
	// 82599E10: 7D673214  add r11, r7, r6
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 82599E14: 9081FF44  stw r4, -0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-188 as u32), ctx.r[4].u32 ) };
	// 82599E18: 9101FF40  stw r8, -0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), ctx.r[8].u32 ) };
	// 82599E1C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 82599E20: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82599E24: 7C005A2C  dcbt 0, r11
	// 82599E28: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 82599E2C: C1A30030  lfs f13, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82599E30: 38E1FF44  addi r7, r1, -0xbc
	ctx.r[7].s64 = ctx.r[1].s64 + -188;
	// 82599E34: C183002C  lfs f12, 0x2c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82599E38: 790807E6  rldicr r8, r8, 0x20, 0x3f
	ctx.r[8].u64 = (ctx.r[8].u64).rotate_left(32) & 0xFFFFFFFFFFFFFFFF;
	// 82599E3C: 39230024  addi r9, r3, 0x24
	ctx.r[9].s64 = ctx.r[3].s64 + 36;
	// 82599E40: 38C00028  li r6, 0x28
	ctx.r[6].s64 = 40;
	// 82599E44: 3BE1FF60  addi r31, r1, -0xa0
	ctx.r[31].s64 = ctx.r[1].s64 + -160;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259A440(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259A440 size=276
    let mut pc: u32 = 0x8259A440;
    'dispatch: loop {
        match pc {
            0x8259A440 => {
    //   block [0x8259A440..0x8259A554)
	// 8259A440: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259A444: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259A448: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A44C: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A450: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259A454: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259A458: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A45C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259A460: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A464: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A468: 7D6A2050  subf r11, r10, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259A46C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A470: 7F095800  cmpw cr6, r9, r11
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259A474: 7CCA3214  add r6, r10, r6
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 8259A478: 550A103A  slwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A47C: 7D0A3A14  add r8, r10, r7
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 8259A480: 7D274B78  mr r7, r9
	ctx.r[7].u64 = ctx.r[9].u64;
	// 8259A484: 41980008  blt cr6, 0x8259a48c
	if ctx.cr[6].lt {
	pc = 0x8259A48C; continue 'dispatch;
	}
	// 8259A488: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 8259A48C: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259A490: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259A494: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259A498: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8259A49C: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8259A4A0: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259A4A4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259A4A8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259A4AC: EDAD6024  fdivs f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259A4B0: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259A4B4: 419A0030  beq cr6, 0x8259a4e4
	if ctx.cr[6].eq {
	pc = 0x8259A4E4; continue 'dispatch;
	}
	// 8259A4B8: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259A4BC: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 8259A4C0: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259A4C4: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A4C8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259A4CC: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A4D0: D1890000  stfs f12, 0(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259A4D4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259A4D8: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 8259A4DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259A4E0: 409AFFE4  bne cr6, 0x8259a4c4
	if !ctx.cr[6].eq {
	pc = 0x8259A4C4; continue 'dispatch;
	}
	// 8259A4E4: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259A4E8: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259A4EC: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 8259A4F0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8259A4F4: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259A4F8: 409AFFB8  bne cr6, 0x8259a4b0
	if !ctx.cr[6].eq {
	pc = 0x8259A4B0; continue 'dispatch;
	}
	// 8259A4FC: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A500: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A504: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8259A508: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259A50C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A510: 0CCA0000  twi 6, r10, 0
	// 8259A514: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259A518: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A51C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259A520: 41980008  blt cr6, 0x8259a528
	if ctx.cr[6].lt {
	pc = 0x8259A528; continue 'dispatch;
	}
	// 8259A524: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259A528: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A52C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A530: 7D4A3050  subf r10, r10, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259A534: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259A538: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A53C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A540: 40980008  bge cr6, 0x8259a548
	if !ctx.cr[6].lt {
	pc = 0x8259A548; continue 'dispatch;
	}
	// 8259A544: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259A548: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259A54C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259A550: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259A558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259A558 size=272
    let mut pc: u32 = 0x8259A558;
    'dispatch: loop {
        match pc {
            0x8259A558 => {
    //   block [0x8259A558..0x8259A668)
	// 8259A558: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259A55C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259A560: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A564: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A568: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259A56C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259A570: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A574: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259A578: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A57C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A580: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259A584: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259A588: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A58C: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259A590: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259A594: 7CEA4214  add r7, r10, r8
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259A598: 41980008  blt cr6, 0x8259a5a0
	if ctx.cr[6].lt {
	pc = 0x8259A5A0; continue 'dispatch;
	}
	// 8259A59C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259A5A0: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259A5A4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259A5A8: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 8259A5AC: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259A5B0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259A5B4: 419A0018  beq cr6, 0x8259a5cc
	if ctx.cr[6].eq {
	pc = 0x8259A5CC; continue 'dispatch;
	}
	// 8259A5B8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259A5BC: 7C055A2C  dcbt r5, r11
	// 8259A5C0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259A5C4: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259A5C8: 4198FFF0  blt cr6, 0x8259a5b8
	if ctx.cr[6].lt {
	pc = 0x8259A5B8; continue 'dispatch;
	}
	// 8259A5CC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259A5D0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259A5D4: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259A5D8: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259A5DC: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259A5E0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259A5E4: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259A5E8: EDAD6024  fdivs f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259A5EC: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A5F0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259A5F4: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A5F8: D1870000  stfs f12, 0(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259A5FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259A600: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259A604: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259A608: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259A60C: 409AFFE0  bne cr6, 0x8259a5ec
	if !ctx.cr[6].eq {
	pc = 0x8259A5EC; continue 'dispatch;
	}
	// 8259A610: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A614: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A618: 5548103E  rotlwi r8, r10, 2
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8259A61C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A620: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259A624: 0CC80000  twi 6, r8, 0
	// 8259A628: 7D6B4396  divwu r11, r11, r8
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[8].u32;
	// 8259A62C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259A630: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259A634: 41980008  blt cr6, 0x8259a63c
	if ctx.cr[6].lt {
	pc = 0x8259A63C; continue 'dispatch;
	}
	// 8259A638: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259A63C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A640: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A644: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259A648: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259A64C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A650: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A654: 40980008  bge cr6, 0x8259a65c
	if !ctx.cr[6].lt {
	pc = 0x8259A65C; continue 'dispatch;
	}
	// 8259A658: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259A65C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259A660: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259A664: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259A668(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259A668 size=284
    let mut pc: u32 = 0x8259A668;
    'dispatch: loop {
        match pc {
            0x8259A668 => {
    //   block [0x8259A668..0x8259A784)
	// 8259A668: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259A66C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259A670: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A674: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A678: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259A67C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259A680: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A684: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259A688: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A68C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A690: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259A694: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259A698: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A69C: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259A6A0: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259A6A4: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259A6A8: 41980008  blt cr6, 0x8259a6b0
	if ctx.cr[6].lt {
	pc = 0x8259A6B0; continue 'dispatch;
	}
	// 8259A6AC: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259A6B0: 55271838  slwi r7, r9, 3
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A6B4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259A6B8: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259A6BC: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A6C0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259A6C4: 419A0018  beq cr6, 0x8259a6dc
	if ctx.cr[6].eq {
	pc = 0x8259A6DC; continue 'dispatch;
	}
	// 8259A6C8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259A6CC: 7C055A2C  dcbt r5, r11
	// 8259A6D0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259A6D4: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259A6D8: 4198FFF0  blt cr6, 0x8259a6c8
	if ctx.cr[6].lt {
	pc = 0x8259A6C8; continue 'dispatch;
	}
	// 8259A6DC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259A6E0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259A6E4: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259A6E8: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259A6EC: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259A6F0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259A6F4: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259A6F8: EDAD6024  fdivs f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259A6FC: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A700: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259A704: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A708: D1880400  stfs f12, 0x400(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259A70C: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A710: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259A714: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A718: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259A71C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259A720: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259A724: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259A728: 409AFFD4  bne cr6, 0x8259a6fc
	if !ctx.cr[6].eq {
	pc = 0x8259A6FC; continue 'dispatch;
	}
	// 8259A72C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A730: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A734: 5547103E  rotlwi r7, r10, 2
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8259A738: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A73C: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259A740: 0CC70000  twi 6, r7, 0
	// 8259A744: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259A748: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259A74C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259A750: 41980008  blt cr6, 0x8259a758
	if ctx.cr[6].lt {
	pc = 0x8259A758; continue 'dispatch;
	}
	// 8259A754: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259A758: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A75C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A760: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259A764: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259A768: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A76C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A770: 40980008  bge cr6, 0x8259a778
	if !ctx.cr[6].lt {
	pc = 0x8259A778; continue 'dispatch;
	}
	// 8259A774: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259A778: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259A77C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259A780: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259A788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259A788 size=308
    let mut pc: u32 = 0x8259A788;
    'dispatch: loop {
        match pc {
            0x8259A788 => {
    //   block [0x8259A788..0x8259A8BC)
	// 8259A788: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259A78C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259A790: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A794: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A798: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259A79C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259A7A0: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A7A4: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259A7A8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A7AC: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A7B0: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259A7B4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A7B8: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259A7BC: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259A7C0: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259A7C4: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259A7C8: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259A7CC: 41980008  blt cr6, 0x8259a7d4
	if ctx.cr[6].lt {
	pc = 0x8259A7D4; continue 'dispatch;
	}
	// 8259A7D0: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259A7D4: 55072036  slwi r7, r8, 4
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A7D8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259A7DC: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259A7E0: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A7E4: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259A7E8: 419A0018  beq cr6, 0x8259a800
	if ctx.cr[6].eq {
	pc = 0x8259A800; continue 'dispatch;
	}
	// 8259A7EC: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259A7F0: 7C055A2C  dcbt r5, r11
	// 8259A7F4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259A7F8: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259A7FC: 4198FFF0  blt cr6, 0x8259a7ec
	if ctx.cr[6].lt {
	pc = 0x8259A7EC; continue 'dispatch;
	}
	// 8259A800: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 8259A804: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259A808: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259A80C: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259A810: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259A814: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259A818: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259A81C: EDAD6024  fdivs f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259A820: C18B000C  lfs f12, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A824: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259A828: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A82C: D18A0C00  stfs f12, 0xc00(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259A830: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A834: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259A838: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A83C: D18A0800  stfs f12, 0x800(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259A840: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A844: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A848: D18A0400  stfs f12, 0x400(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259A84C: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A850: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 8259A854: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A858: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259A85C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259A860: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259A864: 409AFFBC  bne cr6, 0x8259a820
	if !ctx.cr[6].eq {
	pc = 0x8259A820; continue 'dispatch;
	}
	// 8259A868: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A86C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A870: 5527103E  rotlwi r7, r9, 2
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 8259A874: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A878: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259A87C: 0CC70000  twi 6, r7, 0
	// 8259A880: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259A884: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259A888: 40980008  bge cr6, 0x8259a890
	if !ctx.cr[6].lt {
	pc = 0x8259A890; continue 'dispatch;
	}
	// 8259A88C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259A890: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A894: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A898: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259A89C: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259A8A0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A8A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A8A8: 40980008  bge cr6, 0x8259a8b0
	if !ctx.cr[6].lt {
	pc = 0x8259A8B0; continue 'dispatch;
	}
	// 8259A8AC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259A8B0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259A8B4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259A8B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259A8C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259A8C0 size=336
    let mut pc: u32 = 0x8259A8C0;
    'dispatch: loop {
        match pc {
            0x8259A8C0 => {
    //   block [0x8259A8C0..0x8259AA10)
	// 8259A8C0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259A8C4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259A8C8: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A8CC: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A8D0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259A8D4: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259A8D8: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A8DC: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259A8E0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A8E4: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A8E8: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259A8EC: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259A8F0: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A8F4: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259A8F8: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259A8FC: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8259A900: 41980008  blt cr6, 0x8259a908
	if ctx.cr[6].lt {
	pc = 0x8259A908; continue 'dispatch;
	}
	// 8259A904: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259A908: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A90C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259A910: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259A914: 54E71838  slwi r7, r7, 3
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A918: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259A91C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259A920: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259A924: 419A0018  beq cr6, 0x8259a93c
	if ctx.cr[6].eq {
	pc = 0x8259A93C; continue 'dispatch;
	}
	// 8259A928: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259A92C: 7C055A2C  dcbt r5, r11
	// 8259A930: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259A934: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259A938: 4198FFF0  blt cr6, 0x8259a928
	if ctx.cr[6].lt {
	pc = 0x8259A928; continue 'dispatch;
	}
	// 8259A93C: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 8259A940: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259A944: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259A948: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259A94C: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259A950: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259A954: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259A958: EDAD6024  fdivs f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259A95C: C18B0014  lfs f12, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A960: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259A964: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A968: D18A1400  stfs f12, 0x1400(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259A96C: C18B0010  lfs f12, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A970: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259A974: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A978: D18A1000  stfs f12, 0x1000(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259A97C: C18B000C  lfs f12, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A980: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A984: D18A0C00  stfs f12, 0xc00(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259A988: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A98C: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A990: D18A0800  stfs f12, 0x800(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259A994: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A998: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A99C: D18A0400  stfs f12, 0x400(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259A9A0: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259A9A4: 396B0018  addi r11, r11, 0x18
	ctx.r[11].s64 = ctx.r[11].s64 + 24;
	// 8259A9A8: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259A9AC: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259A9B0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259A9B4: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259A9B8: 409AFFA4  bne cr6, 0x8259a95c
	if !ctx.cr[6].eq {
	pc = 0x8259A95C; continue 'dispatch;
	}
	// 8259A9BC: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259A9C0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259A9C4: 5527103E  rotlwi r7, r9, 2
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 8259A9C8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259A9CC: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259A9D0: 0CC70000  twi 6, r7, 0
	// 8259A9D4: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259A9D8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259A9DC: 40980008  bge cr6, 0x8259a9e4
	if !ctx.cr[6].lt {
	pc = 0x8259A9E4; continue 'dispatch;
	}
	// 8259A9E0: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259A9E4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259A9E8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259A9EC: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259A9F0: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259A9F4: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259A9F8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259A9FC: 40980008  bge cr6, 0x8259aa04
	if !ctx.cr[6].lt {
	pc = 0x8259AA04; continue 'dispatch;
	}
	// 8259AA00: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259AA04: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259AA08: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259AA0C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259AA10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259AA10 size=316
    let mut pc: u32 = 0x8259AA10;
    'dispatch: loop {
        match pc {
            0x8259AA10 => {
    //   block [0x8259AA10..0x8259AB4C)
	// 8259AA10: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259AA14: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259AA18: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259AA1C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AA20: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AA24: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259AA28: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259AA2C: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AA30: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259AA34: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AA38: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AA3C: 7D6A2050  subf r11, r10, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259AA40: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AA44: 7F095800  cmpw cr6, r9, r11
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259AA48: 7CCA3214  add r6, r10, r6
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 8259AA4C: 550A083C  slwi r10, r8, 1
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AA50: 7D0A3A14  add r8, r10, r7
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 8259AA54: 7D274B78  mr r7, r9
	ctx.r[7].u64 = ctx.r[9].u64;
	// 8259AA58: 41980008  blt cr6, 0x8259aa60
	if ctx.cr[6].lt {
	pc = 0x8259AA60; continue 'dispatch;
	}
	// 8259AA5C: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 8259AA60: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259AA64: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259AA68: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259AA6C: 54A4083C  slwi r4, r5, 1
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8259AA70: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8259AA74: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259AA78: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AA7C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259AA80: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259AA84: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259AA88: C1AB206C  lfs f13, 0x206c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259AA8C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259AA90: 419A0048  beq cr6, 0x8259aad8
	if ctx.cr[6].eq {
	pc = 0x8259AAD8; continue 'dispatch;
	}
	// 8259AA94: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259AA98: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 8259AA9C: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259AAA0: A3EA0000  lhz r31, 0(r10)
	ctx.r[31].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AAA4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259AAA8: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8259AAAC: 7FFF0734  extsh r31, r31
	ctx.r[31].s64 = ctx.r[31].s16 as i64;
	// 8259AAB0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259AAB4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8259AAB8: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AABC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AAC0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AAC4: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AAC8: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AACC: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259AAD0: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 8259AAD4: 409AFFCC  bne cr6, 0x8259aaa0
	if !ctx.cr[6].eq {
	pc = 0x8259AAA0; continue 'dispatch;
	}
	// 8259AAD8: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259AADC: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259AAE0: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 8259AAE4: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8259AAE8: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259AAEC: 409AFFA0  bne cr6, 0x8259aa8c
	if !ctx.cr[6].eq {
	pc = 0x8259AA8C; continue 'dispatch;
	}
	// 8259AAF0: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AAF4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AAF8: 554A083E  rotlwi r10, r10, 1
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259AAFC: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259AB00: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AB04: 0CCA0000  twi 6, r10, 0
	// 8259AB08: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259AB0C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259AB10: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259AB14: 41980008  blt cr6, 0x8259ab1c
	if ctx.cr[6].lt {
	pc = 0x8259AB1C; continue 'dispatch;
	}
	// 8259AB18: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259AB1C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AB20: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AB24: 7D4A3050  subf r10, r10, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259AB28: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259AB2C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AB30: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259AB34: 40980008  bge cr6, 0x8259ab3c
	if !ctx.cr[6].lt {
	pc = 0x8259AB3C; continue 'dispatch;
	}
	// 8259AB38: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259AB3C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259AB40: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259AB44: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259AB48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259AB50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259AB50 size=304
    let mut pc: u32 = 0x8259AB50;
    'dispatch: loop {
        match pc {
            0x8259AB50 => {
    //   block [0x8259AB50..0x8259AC80)
	// 8259AB50: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259AB54: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259AB58: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AB5C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AB60: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259AB64: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259AB68: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AB6C: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259AB70: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AB74: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AB78: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259AB7C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259AB80: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AB84: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259AB88: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259AB8C: 7CEA4214  add r7, r10, r8
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259AB90: 41980008  blt cr6, 0x8259ab98
	if ctx.cr[6].lt {
	pc = 0x8259AB98; continue 'dispatch;
	}
	// 8259AB94: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259AB98: 5528083C  slwi r8, r9, 1
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259AB9C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259ABA0: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 8259ABA4: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259ABA8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259ABAC: 419A0018  beq cr6, 0x8259abc4
	if ctx.cr[6].eq {
	pc = 0x8259ABC4; continue 'dispatch;
	}
	// 8259ABB0: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259ABB4: 7C055A2C  dcbt r5, r11
	// 8259ABB8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259ABBC: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259ABC0: 4198FFF0  blt cr6, 0x8259abb0
	if ctx.cr[6].lt {
	pc = 0x8259ABB0; continue 'dispatch;
	}
	// 8259ABC4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259ABC8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259ABCC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259ABD0: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259ABD4: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259ABD8: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259ABDC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259ABE0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259ABE4: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259ABE8: C1AA206C  lfs f13, 0x206c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259ABEC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259ABF0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259ABF4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8259ABF8: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259ABFC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259AC00: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259AC04: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AC08: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AC0C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AC10: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AC14: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AC18: D1670000  stfs f11, 0(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259AC1C: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259AC20: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259AC24: 409AFFC8  bne cr6, 0x8259abec
	if !ctx.cr[6].eq {
	pc = 0x8259ABEC; continue 'dispatch;
	}
	// 8259AC28: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AC2C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AC30: 5548083E  rotlwi r8, r10, 1
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259AC34: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AC38: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259AC3C: 0CC80000  twi 6, r8, 0
	// 8259AC40: 7D6B4396  divwu r11, r11, r8
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[8].u32;
	// 8259AC44: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259AC48: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259AC4C: 41980008  blt cr6, 0x8259ac54
	if ctx.cr[6].lt {
	pc = 0x8259AC54; continue 'dispatch;
	}
	// 8259AC50: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259AC54: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AC58: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AC5C: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259AC60: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259AC64: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AC68: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259AC6C: 40980008  bge cr6, 0x8259ac74
	if !ctx.cr[6].lt {
	pc = 0x8259AC74; continue 'dispatch;
	}
	// 8259AC70: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259AC74: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259AC78: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259AC7C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259AC80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259AC80 size=340
    let mut pc: u32 = 0x8259AC80;
    'dispatch: loop {
        match pc {
            0x8259AC80 => {
    //   block [0x8259AC80..0x8259ADD4)
	// 8259AC80: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259AC84: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259AC88: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AC8C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AC90: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259AC94: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259AC98: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AC9C: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259ACA0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259ACA4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259ACA8: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259ACAC: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259ACB0: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259ACB4: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259ACB8: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259ACBC: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259ACC0: 41980008  blt cr6, 0x8259acc8
	if ctx.cr[6].lt {
	pc = 0x8259ACC8; continue 'dispatch;
	}
	// 8259ACC4: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259ACC8: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259ACCC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259ACD0: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259ACD4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259ACD8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259ACDC: 419A0018  beq cr6, 0x8259acf4
	if ctx.cr[6].eq {
	pc = 0x8259ACF4; continue 'dispatch;
	}
	// 8259ACE0: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259ACE4: 7C055A2C  dcbt r5, r11
	// 8259ACE8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259ACEC: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259ACF0: 4198FFF0  blt cr6, 0x8259ace0
	if ctx.cr[6].lt {
	pc = 0x8259ACE0; continue 'dispatch;
	}
	// 8259ACF4: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259ACF8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259ACFC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259AD00: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259AD04: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259AD08: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AD0C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259AD10: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259AD14: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259AD18: C1AA206C  lfs f13, 0x206c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259AD1C: A14B0002  lhz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259AD20: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259AD24: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AD28: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259AD2C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259AD30: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AD34: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AD38: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AD3C: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AD40: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AD44: D1680400  stfs f11, 0x400(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259AD48: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AD4C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259AD50: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AD54: F941FFF8  std r10, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[10].u64 ) };
	// 8259AD58: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259AD5C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AD60: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AD64: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AD68: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AD6C: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259AD70: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259AD74: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259AD78: 409AFFA4  bne cr6, 0x8259ad1c
	if !ctx.cr[6].eq {
	pc = 0x8259AD1C; continue 'dispatch;
	}
	// 8259AD7C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AD80: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AD84: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259AD88: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AD8C: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259AD90: 0CC70000  twi 6, r7, 0
	// 8259AD94: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259AD98: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259AD9C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259ADA0: 41980008  blt cr6, 0x8259ada8
	if ctx.cr[6].lt {
	pc = 0x8259ADA8; continue 'dispatch;
	}
	// 8259ADA4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259ADA8: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259ADAC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259ADB0: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259ADB4: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259ADB8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259ADBC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259ADC0: 40980008  bge cr6, 0x8259adc8
	if !ctx.cr[6].lt {
	pc = 0x8259ADC8; continue 'dispatch;
	}
	// 8259ADC4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259ADC8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259ADCC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259ADD0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259ADD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259ADD8 size=412
    let mut pc: u32 = 0x8259ADD8;
    'dispatch: loop {
        match pc {
            0x8259ADD8 => {
    //   block [0x8259ADD8..0x8259AF74)
	// 8259ADD8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259ADDC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259ADE0: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259ADE4: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259ADE8: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259ADEC: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259ADF0: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259ADF4: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259ADF8: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259ADFC: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AE00: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259AE04: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259AE08: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AE0C: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259AE10: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259AE14: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8259AE18: 41980008  blt cr6, 0x8259ae20
	if ctx.cr[6].lt {
	pc = 0x8259AE20; continue 'dispatch;
	}
	// 8259AE1C: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259AE20: 55071838  slwi r7, r8, 3
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259AE24: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259AE28: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259AE2C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259AE30: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259AE34: 419A0018  beq cr6, 0x8259ae4c
	if ctx.cr[6].eq {
	pc = 0x8259AE4C; continue 'dispatch;
	}
	// 8259AE38: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259AE3C: 7C055A2C  dcbt r5, r11
	// 8259AE40: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259AE44: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259AE48: 4198FFF0  blt cr6, 0x8259ae38
	if ctx.cr[6].lt {
	pc = 0x8259AE38; continue 'dispatch;
	}
	// 8259AE4C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259AE50: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259AE54: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259AE58: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 8259AE5C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259AE60: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259AE64: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259AE68: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259AE6C: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259AE70: C1AA206C  lfs f13, 0x206c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259AE74: A14B0006  lhz r10, 6(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259AE78: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259AE7C: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AE80: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259AE84: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 8259AE88: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259AE8C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AE90: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AE94: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AE98: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AE9C: D1690C00  stfs f11, 0xc00(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259AEA0: A14B0004  lhz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AEA4: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AEA8: F941FFE8  std r10, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[10].u64 ) };
	// 8259AEAC: C961FFE8  lfd f11, -0x18(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259AEB0: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AEB4: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AEB8: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AEBC: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AEC0: D1690800  stfs f11, 0x800(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259AEC4: A14B0002  lhz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259AEC8: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AECC: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259AED0: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259AED4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AED8: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AEDC: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AEE0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AEE4: D1690400  stfs f11, 0x400(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259AEE8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AEEC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259AEF0: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259AEF4: F941FFF8  std r10, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[10].u64 ) };
	// 8259AEF8: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259AEFC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259AF00: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259AF04: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259AF08: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259AF0C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259AF10: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259AF14: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259AF18: 409AFF5C  bne cr6, 0x8259ae74
	if !ctx.cr[6].eq {
	pc = 0x8259AE74; continue 'dispatch;
	}
	// 8259AF1C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AF20: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AF24: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259AF28: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AF2C: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259AF30: 0CC70000  twi 6, r7, 0
	// 8259AF34: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259AF38: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259AF3C: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 8259AF40: 41980008  blt cr6, 0x8259af48
	if ctx.cr[6].lt {
	pc = 0x8259AF48; continue 'dispatch;
	}
	// 8259AF44: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259AF48: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AF4C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AF50: 7D4A4850  subf r10, r10, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 8259AF54: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259AF58: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AF5C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259AF60: 40980008  bge cr6, 0x8259af68
	if !ctx.cr[6].lt {
	pc = 0x8259AF68; continue 'dispatch;
	}
	// 8259AF64: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259AF68: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259AF6C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259AF70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259AF78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259AF78 size=492
    let mut pc: u32 = 0x8259AF78;
    'dispatch: loop {
        match pc {
            0x8259AF78 => {
    //   block [0x8259AF78..0x8259B164)
	// 8259AF78: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259AF7C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259AF80: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259AF84: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259AF88: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259AF8C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259AF90: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259AF94: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259AF98: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259AF9C: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259AFA0: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259AFA4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259AFA8: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259AFAC: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259AFB0: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259AFB4: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259AFB8: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259AFBC: 41980008  blt cr6, 0x8259afc4
	if ctx.cr[6].lt {
	pc = 0x8259AFC4; continue 'dispatch;
	}
	// 8259AFC0: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259AFC4: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259AFC8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259AFCC: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259AFD0: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259AFD4: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259AFD8: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259AFDC: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259AFE0: 419A0018  beq cr6, 0x8259aff8
	if ctx.cr[6].eq {
	pc = 0x8259AFF8; continue 'dispatch;
	}
	// 8259AFE4: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259AFE8: 7C055A2C  dcbt r5, r11
	// 8259AFEC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259AFF0: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259AFF4: 4198FFF0  blt cr6, 0x8259afe4
	if ctx.cr[6].lt {
	pc = 0x8259AFE4; continue 'dispatch;
	}
	// 8259AFF8: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 8259AFFC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B000: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B004: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259B008: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259B00C: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259B010: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B014: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B018: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B01C: C1A9206C  lfs f13, 0x206c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B020: A12B000A  lhz r9, 0xa(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(10 as u32) ) } as u64;
	// 8259B024: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259B028: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B02C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259B030: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259B034: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259B038: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B03C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B040: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B044: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B048: D16A1400  stfs f11, 0x1400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259B04C: A12B0008  lhz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B050: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B054: F921FFD8  std r9, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[9].u64 ) };
	// 8259B058: C961FFD8  lfd f11, -0x28(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259B05C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B060: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B064: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B068: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B06C: D16A1000  stfs f11, 0x1000(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259B070: A12B0006  lhz r9, 6(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259B074: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B078: F921FFE0  std r9, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[9].u64 ) };
	// 8259B07C: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B080: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B084: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B088: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B08C: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B090: D16A0C00  stfs f11, 0xc00(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259B094: A12B0004  lhz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B098: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B09C: F921FFE8  std r9, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[9].u64 ) };
	// 8259B0A0: C961FFE8  lfd f11, -0x18(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259B0A4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B0A8: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B0AC: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B0B0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B0B4: D16A0800  stfs f11, 0x800(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259B0B8: A12B0002  lhz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259B0BC: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B0C0: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259B0C4: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B0C8: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B0CC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B0D0: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B0D4: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B0D8: D16A0400  stfs f11, 0x400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259B0DC: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B0E0: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8259B0E4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259B0E8: F921FFF8  std r9, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[9].u64 ) };
	// 8259B0EC: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259B0F0: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B0F4: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B0F8: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B0FC: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B100: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B104: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259B108: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B10C: 409AFF14  bne cr6, 0x8259b020
	if !ctx.cr[6].eq {
	pc = 0x8259B020; continue 'dispatch;
	}
	// 8259B110: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B114: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B118: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 8259B11C: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B120: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259B124: 0CC70000  twi 6, r7, 0
	// 8259B128: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259B12C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259B130: 40980008  bge cr6, 0x8259b138
	if !ctx.cr[6].lt {
	pc = 0x8259B138; continue 'dispatch;
	}
	// 8259B134: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B138: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B13C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B140: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259B144: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B148: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B14C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B150: 40980008  bge cr6, 0x8259b158
	if !ctx.cr[6].lt {
	pc = 0x8259B158; continue 'dispatch;
	}
	// 8259B154: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B158: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B15C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B160: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B168(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B168 size=292
    let mut pc: u32 = 0x8259B168;
    'dispatch: loop {
        match pc {
            0x8259B168 => {
    //   block [0x8259B168..0x8259B28C)
	// 8259B168: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B16C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B170: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B174: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B178: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B17C: 7CEB4050  subf r7, r11, r8
	ctx.r[7].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259B180: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B184: 7D0959D6  mullw r8, r9, r11
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B188: 80830000  lwz r4, 0(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B18C: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B190: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B194: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259B198: 7D082214  add r8, r8, r4
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[4].u64;
	// 8259B19C: 7F073000  cmpw cr6, r7, r6
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259B1A0: 7CAB2A14  add r5, r11, r5
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 8259B1A4: 41980008  blt cr6, 0x8259b1ac
	if ctx.cr[6].lt {
	pc = 0x8259B1AC; continue 'dispatch;
	}
	// 8259B1A8: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 8259B1AC: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259B1B0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B1B4: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B1B8: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259B1BC: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8259B1C0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259B1C4: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B1C8: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B1CC: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B1D0: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B1D4: C1AB2838  lfs f13, 0x2838(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B1D8: C18A2384  lfs f12, 0x2384(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(9092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259B1DC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8259B1E0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259B1E4: 419A003C  beq cr6, 0x8259b220
	if ctx.cr[6].eq {
	pc = 0x8259B220; continue 'dispatch;
	}
	// 8259B1E8: 7CAA2B78  mr r10, r5
	ctx.r[10].u64 = ctx.r[5].u64;
	// 8259B1EC: 7CCB40AE  lbzx r6, r11, r8
	ctx.r[6].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 8259B1F0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8259B1F4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259B1F8: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259B1FC: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B200: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B204: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B208: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B20C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B210: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B214: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B218: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 8259B21C: 4198FFD0  blt cr6, 0x8259b1ec
	if ctx.cr[6].lt {
	pc = 0x8259B1EC; continue 'dispatch;
	}
	// 8259B220: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259B224: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B228: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 8259B22C: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8259B230: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259B234: 409AFFA8  bne cr6, 0x8259b1dc
	if !ctx.cr[6].eq {
	pc = 0x8259B1DC; continue 'dispatch;
	}
	// 8259B238: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B23C: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B240: 7D2B4050  subf r9, r11, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259B244: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B248: 0CCA0000  twi 6, r10, 0
	// 8259B24C: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259B250: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B254: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259B258: 41980008  blt cr6, 0x8259b260
	if ctx.cr[6].lt {
	pc = 0x8259B260; continue 'dispatch;
	}
	// 8259B25C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B260: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B264: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B268: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 8259B26C: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B270: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B274: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B278: 40980008  bge cr6, 0x8259b280
	if !ctx.cr[6].lt {
	pc = 0x8259B280; continue 'dispatch;
	}
	// 8259B27C: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B280: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B284: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B288: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B290(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B290 size=300
    let mut pc: u32 = 0x8259B290;
    'dispatch: loop {
        match pc {
            0x8259B290 => {
    //   block [0x8259B290..0x8259B3BC)
	// 8259B290: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B294: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B298: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B29C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B2A0: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B2A4: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259B2A8: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B2AC: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B2B0: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B2B4: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B2B8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B2BC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B2C0: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259B2C4: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259B2C8: 7CEA4214  add r7, r10, r8
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259B2CC: 41980008  blt cr6, 0x8259b2d4
	if ctx.cr[6].lt {
	pc = 0x8259B2D4; continue 'dispatch;
	}
	// 8259B2D0: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259B2D4: 3909007F  addi r8, r9, 0x7f
	ctx.r[8].s64 = ctx.r[9].s64 + 127;
	// 8259B2D8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259B2DC: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259B2E0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259B2E4: 419A0018  beq cr6, 0x8259b2fc
	if ctx.cr[6].eq {
	pc = 0x8259B2FC; continue 'dispatch;
	}
	// 8259B2E8: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259B2EC: 7C055A2C  dcbt r5, r11
	// 8259B2F0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259B2F4: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259B2F8: 4198FFF0  blt cr6, 0x8259b2e8
	if ctx.cr[6].lt {
	pc = 0x8259B2E8; continue 'dispatch;
	}
	// 8259B2FC: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259B300: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B304: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B308: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259B30C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259B310: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259B314: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B318: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B31C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B320: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B324: C1AA2838  lfs f13, 0x2838(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B328: C1882384  lfs f12, 0x2384(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(9092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259B32C: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B330: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259B334: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8259B338: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259B33C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259B340: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B344: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B348: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B34C: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B350: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B354: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B358: D1470000  stfs f10, 0(r7)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B35C: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259B360: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B364: 409AFFC8  bne cr6, 0x8259b32c
	if !ctx.cr[6].eq {
	pc = 0x8259B32C; continue 'dispatch;
	}
	// 8259B368: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B36C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B370: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 8259B374: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B378: 0CC90000  twi 6, r9, 0
	// 8259B37C: 7D4A4B96  divwu r10, r10, r9
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[9].u32;
	// 8259B380: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B384: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259B388: 41980008  blt cr6, 0x8259b390
	if ctx.cr[6].lt {
	pc = 0x8259B390; continue 'dispatch;
	}
	// 8259B38C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B390: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B394: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B398: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259B39C: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B3A0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B3A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B3A8: 40980008  bge cr6, 0x8259b3b0
	if !ctx.cr[6].lt {
	pc = 0x8259B3B0; continue 'dispatch;
	}
	// 8259B3AC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B3B0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B3B4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B3B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B3C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B3C0 size=340
    let mut pc: u32 = 0x8259B3C0;
    'dispatch: loop {
        match pc {
            0x8259B3C0 => {
    //   block [0x8259B3C0..0x8259B514)
	// 8259B3C0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B3C4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B3C8: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B3CC: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B3D0: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B3D4: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B3D8: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259B3DC: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B3E0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B3E4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B3E8: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B3EC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B3F0: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259B3F4: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259B3F8: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259B3FC: 41980008  blt cr6, 0x8259b404
	if ctx.cr[6].lt {
	pc = 0x8259B404; continue 'dispatch;
	}
	// 8259B400: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259B404: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B408: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259B40C: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259B410: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B414: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259B418: 419A0018  beq cr6, 0x8259b430
	if ctx.cr[6].eq {
	pc = 0x8259B430; continue 'dispatch;
	}
	// 8259B41C: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259B420: 7C055A2C  dcbt r5, r11
	// 8259B424: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259B428: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259B42C: 4198FFF0  blt cr6, 0x8259b41c
	if ctx.cr[6].lt {
	pc = 0x8259B41C; continue 'dispatch;
	}
	// 8259B430: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259B434: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B438: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B43C: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8259B440: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259B444: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259B448: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B44C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B450: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B454: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B458: C1AA2838  lfs f13, 0x2838(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B45C: C1872384  lfs f12, 0x2384(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(9092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259B460: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259B464: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259B468: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259B46C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259B470: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B474: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B478: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B47C: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B480: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B484: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B488: D1480400  stfs f10, 0x400(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259B48C: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B490: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8259B494: F941FFF8  std r10, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[10].u64 ) };
	// 8259B498: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259B49C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B4A0: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B4A4: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B4A8: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B4AC: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B4B0: D1480000  stfs f10, 0(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B4B4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259B4B8: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B4BC: 409AFFA4  bne cr6, 0x8259b460
	if !ctx.cr[6].eq {
	pc = 0x8259B460; continue 'dispatch;
	}
	// 8259B4C0: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B4C4: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B4C8: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 8259B4CC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B4D0: 0CC90000  twi 6, r9, 0
	// 8259B4D4: 7D4A4B96  divwu r10, r10, r9
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[9].u32;
	// 8259B4D8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B4DC: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259B4E0: 41980008  blt cr6, 0x8259b4e8
	if ctx.cr[6].lt {
	pc = 0x8259B4E8; continue 'dispatch;
	}
	// 8259B4E4: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B4E8: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B4EC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B4F0: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259B4F4: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B4F8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B4FC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B500: 40980008  bge cr6, 0x8259b508
	if !ctx.cr[6].lt {
	pc = 0x8259B508; continue 'dispatch;
	}
	// 8259B504: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B508: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B50C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B510: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B518(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B518 size=412
    let mut pc: u32 = 0x8259B518;
    'dispatch: loop {
        match pc {
            0x8259B518 => {
    //   block [0x8259B518..0x8259B6B4)
	// 8259B518: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B51C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B520: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B524: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B528: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B52C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B530: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259B534: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B538: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B53C: 81230014  lwz r9, 0x14(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B540: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B544: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B548: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259B54C: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259B550: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8259B554: 41980008  blt cr6, 0x8259b55c
	if ctx.cr[6].lt {
	pc = 0x8259B55C; continue 'dispatch;
	}
	// 8259B558: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259B55C: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B560: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259B564: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259B568: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B56C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259B570: 419A0018  beq cr6, 0x8259b588
	if ctx.cr[6].eq {
	pc = 0x8259B588; continue 'dispatch;
	}
	// 8259B574: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259B578: 7C055A2C  dcbt r5, r11
	// 8259B57C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259B580: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259B584: 4198FFF0  blt cr6, 0x8259b574
	if ctx.cr[6].lt {
	pc = 0x8259B574; continue 'dispatch;
	}
	// 8259B588: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259B58C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B590: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B594: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8259B598: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 8259B59C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259B5A0: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B5A4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B5A8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B5AC: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B5B0: C1AA2838  lfs f13, 0x2838(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(10296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B5B4: C1872384  lfs f12, 0x2384(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(9092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259B5B8: 894B0003  lbz r10, 3(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8259B5BC: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259B5C0: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259B5C4: F941FFE0  std r10, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[10].u64 ) };
	// 8259B5C8: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B5CC: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B5D0: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B5D4: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B5D8: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B5DC: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B5E0: D1490C00  stfs f10, 0xc00(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259B5E4: 894B0002  lbz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259B5E8: F941FFE8  std r10, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[10].u64 ) };
	// 8259B5EC: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259B5F0: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B5F4: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B5F8: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B5FC: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B600: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B604: D1490800  stfs f10, 0x800(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259B608: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259B60C: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259B610: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B614: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B618: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B61C: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B620: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B624: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B628: D1490400  stfs f10, 0x400(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259B62C: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B630: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259B634: F941FFF8  std r10, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[10].u64 ) };
	// 8259B638: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259B63C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B640: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B644: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B648: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B64C: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B650: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B654: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259B658: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B65C: 409AFF5C  bne cr6, 0x8259b5b8
	if !ctx.cr[6].eq {
	pc = 0x8259B5B8; continue 'dispatch;
	}
	// 8259B660: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B664: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B668: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 8259B66C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B670: 0CC80000  twi 6, r8, 0
	// 8259B674: 7D4A4396  divwu r10, r10, r8
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[8].u32;
	// 8259B678: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B67C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259B680: 41980008  blt cr6, 0x8259b688
	if ctx.cr[6].lt {
	pc = 0x8259B688; continue 'dispatch;
	}
	// 8259B684: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 8259B688: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B68C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B690: 7D4A4850  subf r10, r10, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 8259B694: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259B698: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B69C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B6A0: 40980008  bge cr6, 0x8259b6a8
	if !ctx.cr[6].lt {
	pc = 0x8259B6A8; continue 'dispatch;
	}
	// 8259B6A4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B6A8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B6AC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B6B0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B6B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B6B8 size=492
    let mut pc: u32 = 0x8259B6B8;
    'dispatch: loop {
        match pc {
            0x8259B6B8 => {
    //   block [0x8259B6B8..0x8259B8A4)
	// 8259B6B8: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B6BC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B6C0: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B6C4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B6C8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B6CC: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B6D0: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B6D4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B6D8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B6DC: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259B6E0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B6E4: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B6E8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259B6EC: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259B6F0: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259B6F4: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259B6F8: 41980008  blt cr6, 0x8259b700
	if ctx.cr[6].lt {
	pc = 0x8259B700; continue 'dispatch;
	}
	// 8259B6FC: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259B700: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B704: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259B708: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259B70C: 54E7083C  slwi r7, r7, 1
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B710: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259B714: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259B718: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259B71C: 419A0018  beq cr6, 0x8259b734
	if ctx.cr[6].eq {
	pc = 0x8259B734; continue 'dispatch;
	}
	// 8259B720: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259B724: 7C055A2C  dcbt r5, r11
	// 8259B728: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259B72C: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259B730: 4198FFF0  blt cr6, 0x8259b720
	if ctx.cr[6].lt {
	pc = 0x8259B720; continue 'dispatch;
	}
	// 8259B734: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 8259B738: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B73C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B740: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8259B744: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259B748: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259B74C: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259B750: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B754: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B758: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B75C: C1A92838  lfs f13, 0x2838(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(10296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B760: C1872384  lfs f12, 0x2384(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(9092 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259B764: 892B0005  lbz r9, 5(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(5 as u32) ) } as u64;
	// 8259B768: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259B76C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259B770: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259B774: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259B778: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B77C: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B780: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B784: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B788: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B78C: D14A1400  stfs f10, 0x1400(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259B790: 892B0004  lbz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B794: F921FFD8  std r9, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[9].u64 ) };
	// 8259B798: C941FFD8  lfd f10, -0x28(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259B79C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B7A0: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B7A4: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B7A8: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B7AC: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B7B0: D14A1000  stfs f10, 0x1000(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259B7B4: 892B0003  lbz r9, 3(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8259B7B8: F921FFE0  std r9, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[9].u64 ) };
	// 8259B7BC: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B7C0: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B7C4: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B7C8: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B7CC: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B7D0: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B7D4: D14A0C00  stfs f10, 0xc00(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259B7D8: 892B0002  lbz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259B7DC: F921FFE8  std r9, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[9].u64 ) };
	// 8259B7E0: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259B7E4: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B7E8: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B7EC: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B7F0: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B7F4: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B7F8: D14A0800  stfs f10, 0x800(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259B7FC: 892B0001  lbz r9, 1(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259B800: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259B804: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B808: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B80C: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B810: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B814: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B818: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B81C: D14A0400  stfs f10, 0x400(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259B820: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B824: 396B0006  addi r11, r11, 6
	ctx.r[11].s64 = ctx.r[11].s64 + 6;
	// 8259B828: F921FFF8  std r9, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[9].u64 ) };
	// 8259B82C: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259B830: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259B834: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259B838: ED4A6828  fsubs f10, f10, f13
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 8259B83C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259B840: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B844: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B848: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259B84C: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B850: 409AFF14  bne cr6, 0x8259b764
	if !ctx.cr[6].eq {
	pc = 0x8259B764; continue 'dispatch;
	}
	// 8259B854: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B858: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B85C: 7D295850  subf r9, r9, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259B860: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B864: 0CC80000  twi 6, r8, 0
	// 8259B868: 7D294396  divwu r9, r9, r8
	ctx.r[9].u32 = ctx.r[9].u32 / ctx.r[8].u32;
	// 8259B86C: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B870: 41980008  blt cr6, 0x8259b878
	if ctx.cr[6].lt {
	pc = 0x8259B878; continue 'dispatch;
	}
	// 8259B874: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B878: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B87C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B880: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259B884: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B888: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B88C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B890: 40980008  bge cr6, 0x8259b898
	if !ctx.cr[6].lt {
	pc = 0x8259B898; continue 'dispatch;
	}
	// 8259B894: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B898: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B89C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B8A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B8A8 size=332
    let mut pc: u32 = 0x8259B8A8;
    'dispatch: loop {
        match pc {
            0x8259B8A8 => {
    //   block [0x8259B8A8..0x8259B9F4)
	// 8259B8A8: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 8259B8AC: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259B8B0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B8B4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259B8B8: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B8BC: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B8C0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259B8C4: 7D0559D6  mullw r8, r5, r11
	ctx.r[8].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259B8C8: 80830018  lwz r4, 0x18(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B8CC: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259B8D0: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B8D4: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B8D8: 7D6A2050  subf r11, r10, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259B8DC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B8E0: 7D244B78  mr r4, r9
	ctx.r[4].u64 = ctx.r[9].u64;
	// 8259B8E4: 7F095800  cmpw cr6, r9, r11
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259B8E8: 7CCA3214  add r6, r10, r6
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 8259B8EC: 550A083C  slwi r10, r8, 1
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B8F0: 7CEA3A14  add r7, r10, r7
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 8259B8F4: 41980008  blt cr6, 0x8259b8fc
	if ctx.cr[6].lt {
	pc = 0x8259B8FC; continue 'dispatch;
	}
	// 8259B8F8: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 8259B8FC: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259B900: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B904: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259B908: 54BF083C  slwi r31, r5, 1
	ctx.r[31].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 8259B90C: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 8259B910: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259B914: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B918: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259B91C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259B920: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259B924: C1AB206C  lfs f13, 0x206c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259B928: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259B92C: 419A0050  beq cr6, 0x8259b97c
	if ctx.cr[6].eq {
	pc = 0x8259B97C; continue 'dispatch;
	}
	// 8259B930: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259B934: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 8259B938: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259B93C: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B940: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259B944: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8259B948: 551EC63E  rlwinm r30, r8, 0x18, 0x18, 0x1f
	ctx.r[30].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259B94C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259B950: 511E442E  rlwimi r30, r8, 8, 0x10, 0x17
	ctx.r[30].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[30].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259B954: 7FC80734  extsh r8, r30
	ctx.r[8].s64 = ctx.r[30].s16 as i64;
	// 8259B958: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259B95C: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259B960: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259B964: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259B968: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259B96C: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259B970: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259B974: 39290400  addi r9, r9, 0x400
	ctx.r[9].s64 = ctx.r[9].s64 + 1024;
	// 8259B978: 409AFFC4  bne cr6, 0x8259b93c
	if !ctx.cr[6].eq {
	pc = 0x8259B93C; continue 'dispatch;
	}
	// 8259B97C: 3884FFFF  addi r4, r4, -1
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	// 8259B980: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259B984: 7CFF3A14  add r7, r31, r7
	ctx.r[7].u64 = ctx.r[31].u64 + ctx.r[7].u64;
	// 8259B988: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8259B98C: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 8259B990: 409AFF98  bne cr6, 0x8259b928
	if !ctx.cr[6].eq {
	pc = 0x8259B928; continue 'dispatch;
	}
	// 8259B994: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259B998: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259B99C: 554A083E  rotlwi r10, r10, 1
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259B9A0: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8259B9A4: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259B9A8: 0CCA0000  twi 6, r10, 0
	// 8259B9AC: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259B9B0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B9B4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259B9B8: 41980008  blt cr6, 0x8259b9c0
	if ctx.cr[6].lt {
	pc = 0x8259B9C0; continue 'dispatch;
	}
	// 8259B9BC: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259B9C0: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259B9C4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259B9C8: 7D4A3050  subf r10, r10, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259B9CC: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259B9D0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259B9D4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259B9D8: 40980008  bge cr6, 0x8259b9e0
	if !ctx.cr[6].lt {
	pc = 0x8259B9E0; continue 'dispatch;
	}
	// 8259B9DC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259B9E0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259B9E4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259B9E8: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259B9EC: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259B9F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259B9F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259B9F8 size=312
    let mut pc: u32 = 0x8259B9F8;
    'dispatch: loop {
        match pc {
            0x8259B9F8 => {
    //   block [0x8259B9F8..0x8259BB30)
	// 8259B9F8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259B9FC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259BA00: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BA04: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BA08: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259BA0C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259BA10: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BA14: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259BA18: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BA1C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BA20: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259BA24: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259BA28: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BA2C: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259BA30: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259BA34: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259BA38: 41980008  blt cr6, 0x8259ba40
	if ctx.cr[6].lt {
	pc = 0x8259BA40; continue 'dispatch;
	}
	// 8259BA3C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259BA40: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BA44: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259BA48: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259BA4C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BA50: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259BA54: 419A0018  beq cr6, 0x8259ba6c
	if ctx.cr[6].eq {
	pc = 0x8259BA6C; continue 'dispatch;
	}
	// 8259BA58: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259BA5C: 7C055A2C  dcbt r5, r11
	// 8259BA60: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259BA64: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259BA68: 4198FFF0  blt cr6, 0x8259ba58
	if ctx.cr[6].lt {
	pc = 0x8259BA58; continue 'dispatch;
	}
	// 8259BA6C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 8259BA70: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BA74: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259BA78: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259BA7C: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259BA80: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BA84: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259BA88: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259BA8C: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259BA90: C1AA206C  lfs f13, 0x206c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BA94: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BA98: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259BA9C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8259BAA0: 5547C63E  rlwinm r7, r10, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8259BAA4: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259BAA8: 5147442E  rlwimi r7, r10, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BAAC: 7CEA0734  extsh r10, r7
	ctx.r[10].s64 = ctx.r[7].s16 as i64;
	// 8259BAB0: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259BAB4: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BAB8: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BABC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BAC0: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BAC4: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BAC8: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259BACC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259BAD0: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259BAD4: 409AFFC0  bne cr6, 0x8259ba94
	if !ctx.cr[6].eq {
	pc = 0x8259BA94; continue 'dispatch;
	}
	// 8259BAD8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BADC: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BAE0: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259BAE4: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BAE8: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259BAEC: 0CC70000  twi 6, r7, 0
	// 8259BAF0: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259BAF4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259BAF8: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259BAFC: 41980008  blt cr6, 0x8259bb04
	if ctx.cr[6].lt {
	pc = 0x8259BB04; continue 'dispatch;
	}
	// 8259BB00: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259BB04: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BB08: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BB0C: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259BB10: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259BB14: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BB18: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259BB1C: 40980008  bge cr6, 0x8259bb24
	if !ctx.cr[6].lt {
	pc = 0x8259BB24; continue 'dispatch;
	}
	// 8259BB20: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259BB24: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259BB28: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259BB2C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259BB30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259BB30 size=352
    let mut pc: u32 = 0x8259BB30;
    'dispatch: loop {
        match pc {
            0x8259BB30 => {
    //   block [0x8259BB30..0x8259BC90)
	// 8259BB30: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259BB34: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259BB38: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BB3C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BB40: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259BB44: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259BB48: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BB4C: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259BB50: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BB54: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BB58: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259BB5C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259BB60: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BB64: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259BB68: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259BB6C: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259BB70: 41980008  blt cr6, 0x8259bb78
	if ctx.cr[6].lt {
	pc = 0x8259BB78; continue 'dispatch;
	}
	// 8259BB74: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259BB78: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BB7C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259BB80: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259BB84: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BB88: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259BB8C: 419A0018  beq cr6, 0x8259bba4
	if ctx.cr[6].eq {
	pc = 0x8259BBA4; continue 'dispatch;
	}
	// 8259BB90: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259BB94: 7C055A2C  dcbt r5, r11
	// 8259BB98: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259BB9C: 7F083840  cmplw cr6, r8, r7
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259BBA0: 4198FFF0  blt cr6, 0x8259bb90
	if ctx.cr[6].lt {
	pc = 0x8259BB90; continue 'dispatch;
	}
	// 8259BBA4: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 8259BBA8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BBAC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259BBB0: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259BBB4: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259BBB8: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BBBC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259BBC0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259BBC4: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259BBC8: C1A8206C  lfs f13, 0x206c(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BBCC: A10B0002  lhz r8, 2(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259BBD0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259BBD4: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BBD8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259BBDC: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BBE0: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BBE4: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259BBE8: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BBEC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BBF0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BBF4: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BBF8: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BBFC: D16A0400  stfs f11, 0x400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259BC00: A10B0000  lhz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BC04: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259BC08: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BC0C: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BC10: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BC14: F901FFF8  std r8, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[8].u64 ) };
	// 8259BC18: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259BC1C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BC20: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BC24: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BC28: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BC2C: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259BC30: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259BC34: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259BC38: 409AFF94  bne cr6, 0x8259bbcc
	if !ctx.cr[6].eq {
	pc = 0x8259BBCC; continue 'dispatch;
	}
	// 8259BC3C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BC40: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BC44: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 8259BC48: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BC4C: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259BC50: 0CC70000  twi 6, r7, 0
	// 8259BC54: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259BC58: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259BC5C: 40980008  bge cr6, 0x8259bc64
	if !ctx.cr[6].lt {
	pc = 0x8259BC64; continue 'dispatch;
	}
	// 8259BC60: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259BC64: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BC68: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BC6C: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259BC70: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259BC74: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BC78: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259BC7C: 40980008  bge cr6, 0x8259bc84
	if !ctx.cr[6].lt {
	pc = 0x8259BC84; continue 'dispatch;
	}
	// 8259BC80: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259BC84: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259BC88: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259BC8C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259BC90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259BC90 size=440
    let mut pc: u32 = 0x8259BC90;
    'dispatch: loop {
        match pc {
            0x8259BC90 => {
    //   block [0x8259BC90..0x8259BE48)
	// 8259BC90: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259BC94: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259BC98: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BC9C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BCA0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259BCA4: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259BCA8: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BCAC: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259BCB0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BCB4: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BCB8: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259BCBC: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259BCC0: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BCC4: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259BCC8: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259BCCC: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259BCD0: 41980008  blt cr6, 0x8259bcd8
	if ctx.cr[6].lt {
	pc = 0x8259BCD8; continue 'dispatch;
	}
	// 8259BCD4: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259BCD8: 55271838  slwi r7, r9, 3
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BCDC: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259BCE0: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259BCE4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BCE8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259BCEC: 419A0018  beq cr6, 0x8259bd04
	if ctx.cr[6].eq {
	pc = 0x8259BD04; continue 'dispatch;
	}
	// 8259BCF0: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259BCF4: 7C055A2C  dcbt r5, r11
	// 8259BCF8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259BCFC: 7F083840  cmplw cr6, r8, r7
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259BD00: 4198FFF0  blt cr6, 0x8259bcf0
	if ctx.cr[6].lt {
	pc = 0x8259BCF0; continue 'dispatch;
	}
	// 8259BD04: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 8259BD08: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BD0C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259BD10: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259BD14: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259BD18: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259BD1C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259BD20: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259BD24: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259BD28: C1A8206C  lfs f13, 0x206c(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BD2C: A10B0006  lhz r8, 6(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259BD30: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259BD34: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BD38: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259BD3C: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BD40: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BD44: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259BD48: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259BD4C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BD50: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BD54: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BD58: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BD5C: D16A0C00  stfs f11, 0xc00(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259BD60: A10B0004  lhz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BD64: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BD68: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BD6C: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BD70: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259BD74: C961FFE8  lfd f11, -0x18(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259BD78: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BD7C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BD80: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BD84: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BD88: D16A0800  stfs f11, 0x800(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259BD8C: A10B0002  lhz r8, 2(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259BD90: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BD94: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BD98: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BD9C: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259BDA0: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BDA4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BDA8: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BDAC: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BDB0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BDB4: D16A0400  stfs f11, 0x400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259BDB8: A10B0000  lhz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BDBC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259BDC0: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BDC4: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BDC8: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BDCC: F901FFF8  std r8, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[8].u64 ) };
	// 8259BDD0: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259BDD4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BDD8: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BDDC: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BDE0: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BDE4: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259BDE8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259BDEC: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259BDF0: 409AFF3C  bne cr6, 0x8259bd2c
	if !ctx.cr[6].eq {
	pc = 0x8259BD2C; continue 'dispatch;
	}
	// 8259BDF4: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BDF8: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BDFC: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 8259BE00: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BE04: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259BE08: 0CC70000  twi 6, r7, 0
	// 8259BE0C: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259BE10: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259BE14: 40980008  bge cr6, 0x8259be1c
	if !ctx.cr[6].lt {
	pc = 0x8259BE1C; continue 'dispatch;
	}
	// 8259BE18: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259BE1C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BE20: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BE24: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259BE28: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259BE2C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BE30: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259BE34: 40980008  bge cr6, 0x8259be3c
	if !ctx.cr[6].lt {
	pc = 0x8259BE3C; continue 'dispatch;
	}
	// 8259BE38: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259BE3C: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259BE40: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259BE44: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259BE48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259BE48 size=536
    let mut pc: u32 = 0x8259BE48;
    'dispatch: loop {
        match pc {
            0x8259BE48 => {
    //   block [0x8259BE48..0x8259C060)
	// 8259BE48: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259BE4C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259BE50: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BE54: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259BE58: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259BE5C: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259BE60: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259BE64: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259BE68: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BE6C: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259BE70: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259BE74: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259BE78: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259BE7C: 7F093000  cmpw cr6, r9, r6
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[6].s32, &mut ctx.xer);
	// 8259BE80: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259BE84: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259BE88: 41980008  blt cr6, 0x8259be90
	if ctx.cr[6].lt {
	pc = 0x8259BE90; continue 'dispatch;
	}
	// 8259BE8C: 7CC93378  mr r9, r6
	ctx.r[9].u64 = ctx.r[6].u64;
	// 8259BE90: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BE94: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259BE98: 7CE93A14  add r7, r9, r7
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8259BE9C: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BEA0: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259BEA4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259BEA8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259BEAC: 419A0018  beq cr6, 0x8259bec4
	if ctx.cr[6].eq {
	pc = 0x8259BEC4; continue 'dispatch;
	}
	// 8259BEB0: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259BEB4: 7C055A2C  dcbt r5, r11
	// 8259BEB8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259BEBC: 7F083840  cmplw cr6, r8, r7
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259BEC0: 4198FFF0  blt cr6, 0x8259beb0
	if ctx.cr[6].lt {
	pc = 0x8259BEB0; continue 'dispatch;
	}
	// 8259BEC4: 7CC807B4  extsw r8, r6
	ctx.r[8].s64 = ctx.r[6].s32 as i64;
	// 8259BEC8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BECC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259BED0: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 8259BED4: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259BED8: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259BEDC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259BEE0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259BEE4: ED8D6024  fdivs f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259BEE8: C1A8206C  lfs f13, 0x206c(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8300 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259BEEC: A10B000A  lhz r8, 0xa(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(10 as u32) ) } as u64;
	// 8259BEF0: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259BEF4: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BEF8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259BEFC: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BF00: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BF04: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 8259BF08: C961FFD0  lfd f11, -0x30(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259BF0C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BF10: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BF14: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BF18: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BF1C: D16A1400  stfs f11, 0x1400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259BF20: A10B0008  lhz r8, 8(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259BF24: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BF28: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BF2C: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BF30: F901FFD8  std r8, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[8].u64 ) };
	// 8259BF34: C961FFD8  lfd f11, -0x28(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259BF38: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BF3C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BF40: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BF44: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BF48: D16A1000  stfs f11, 0x1000(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259BF4C: A10B0006  lhz r8, 6(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259BF50: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BF54: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BF58: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BF5C: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259BF60: C961FFE0  lfd f11, -0x20(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259BF64: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BF68: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BF6C: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BF70: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BF74: D16A0C00  stfs f11, 0xc00(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259BF78: A10B0004  lhz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259BF7C: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BF80: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BF84: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BF88: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259BF8C: C961FFE8  lfd f11, -0x18(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259BF90: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BF94: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BF98: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BF9C: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BFA0: D16A0800  stfs f11, 0x800(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259BFA4: A10B0002  lhz r8, 2(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259BFA8: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BFAC: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BFB0: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BFB4: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259BFB8: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259BFBC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BFC0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BFC4: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BFC8: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BFCC: D16A0400  stfs f11, 0x400(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259BFD0: A10B0000  lhz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259BFD4: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8259BFD8: 5507C63E  rlwinm r7, r8, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0x000000FFu64;
	// 8259BFDC: 5107442E  rlwimi r7, r8, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[8].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259BFE0: 7CE80734  extsh r8, r7
	ctx.r[8].s64 = ctx.r[7].s16 as i64;
	// 8259BFE4: F901FFF8  std r8, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[8].u64 ) };
	// 8259BFE8: C961FFF8  lfd f11, -8(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259BFEC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259BFF0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259BFF4: ED6B0372  fmuls f11, f11, f13
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259BFF8: ED6B0032  fmuls f11, f11, f0
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259BFFC: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C000: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259C004: EC0C002A  fadds f0, f12, f0
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C008: 409AFEE4  bne cr6, 0x8259beec
	if !ctx.cr[6].eq {
	pc = 0x8259BEEC; continue 'dispatch;
	}
	// 8259C00C: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C010: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C014: 5527083E  rotlwi r7, r9, 1
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 8259C018: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C01C: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259C020: 0CC70000  twi 6, r7, 0
	// 8259C024: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259C028: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259C02C: 40980008  bge cr6, 0x8259c034
	if !ctx.cr[6].lt {
	pc = 0x8259C034; continue 'dispatch;
	}
	// 8259C030: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259C034: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C038: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C03C: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259C040: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259C044: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C048: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259C04C: 40980008  bge cr6, 0x8259c054
	if !ctx.cr[6].lt {
	pc = 0x8259C054; continue 'dispatch;
	}
	// 8259C050: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259C054: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C058: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259C05C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C060(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C060 size=420
    let mut pc: u32 = 0x8259C060;
    'dispatch: loop {
        match pc {
            0x8259C060 => {
    //   block [0x8259C060..0x8259C204)
	// 8259C060: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 8259C064: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259C068: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C06C: C1830024  lfs f12, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259C070: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C074: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 8259C078: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C07C: 5567103A  slwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C080: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C084: 7FCB4850  subf r30, r11, r9
	ctx.r[30].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259C088: 83E30004  lwz r31, 4(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C08C: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259C090: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C094: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C098: 7FCB0E70  srawi r11, r30, 1
	ctx.xer.ca = (ctx.r[30].s32 < 0) && ((ctx.r[30].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[30].s32 >> 1) as i64;
	// 8259C09C: 7D4AF850  subf r10, r10, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 8259C0A0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259C0A4: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 8259C0A8: 7CC73214  add r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259C0AC: 7CE94214  add r7, r9, r8
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 8259C0B0: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259C0B4: 7D5F5378  mr r31, r10
	ctx.r[31].u64 = ctx.r[10].u64;
	// 8259C0B8: 41980008  blt cr6, 0x8259c0c0
	if ctx.cr[6].lt {
	pc = 0x8259C0C0; continue 'dispatch;
	}
	// 8259C0BC: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 8259C0C0: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259C0C4: C0030028  lfs f0, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C0C8: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259C0CC: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259C0D0: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 8259C0D4: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259C0D8: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259C0DC: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259C0E0: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259C0E4: ED206824  fdivs f9, f0, f13
	ctx.f[9].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 8259C0E8: C00B2068  lfs f0, 0x2068(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C0EC: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C0F0: 419A001C  beq cr6, 0x8259c10c
	if ctx.cr[6].eq {
	pc = 0x8259C10C; continue 'dispatch;
	}
	// 8259C0F4: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8259C0F8: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259C0FC: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259C100: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259C104: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259C108: 409AFFF4  bne cr6, 0x8259c0fc
	if !ctx.cr[6].eq {
	pc = 0x8259C0FC; continue 'dispatch;
	}
	// 8259C10C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259C110: 54BE103A  slwi r30, r5, 2
	ctx.r[30].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8259C114: C14BBFFC  lfs f10, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C118: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259C11C: 419A0050  beq cr6, 0x8259c16c
	if ctx.cr[6].eq {
	pc = 0x8259C16C; continue 'dispatch;
	}
	// 8259C120: ED69602A  fadds f11, f9, f12
	ctx.f[11].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259C124: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 8259C128: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8259C12C: 7D043850  subf r8, r4, r7
	ctx.r[8].s64 = ctx.r[7].s64 - ctx.r[4].s64;
	// 8259C130: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 8259C134: 7C085C2E  lfsx f0, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C138: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259C13C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C140: EDA0682A  fadds f13, f0, f13
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8259C144: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C148: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C14C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259C150: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259C154: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C158: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259C15C: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C160: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C164: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 8259C168: 409AFFCC  bne cr6, 0x8259c134
	if !ctx.cr[6].eq {
	pc = 0x8259C134; continue 'dispatch;
	}
	// 8259C16C: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 8259C170: ED88602A  fadds f12, f8, f12
	ctx.f[12].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259C174: 7CFE3A14  add r7, r30, r7
	ctx.r[7].u64 = ctx.r[30].u64 + ctx.r[7].u64;
	// 8259C178: 38C60008  addi r6, r6, 8
	ctx.r[6].s64 = ctx.r[6].s64 + 8;
	// 8259C17C: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8259C180: 409AFF98  bne cr6, 0x8259c118
	if !ctx.cr[6].eq {
	pc = 0x8259C118; continue 'dispatch;
	}
	// 8259C184: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C188: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C18C: 554A103E  rotlwi r10, r10, 2
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8259C190: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8259C194: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C198: 0CCA0000  twi 6, r10, 0
	// 8259C19C: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259C1A0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259C1A4: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259C1A8: 41980008  blt cr6, 0x8259c1b0
	if ctx.cr[6].lt {
	pc = 0x8259C1B0; continue 'dispatch;
	}
	// 8259C1AC: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259C1B0: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C1B4: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C1B8: 7D4A3050  subf r10, r10, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259C1BC: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259C1C0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C1C4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259C1C8: 40980008  bge cr6, 0x8259c1d0
	if !ctx.cr[6].lt {
	pc = 0x8259C1D0; continue 'dispatch;
	}
	// 8259C1CC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259C1D0: D1830024  stfs f12, 0x24(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C1D4: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259C1D8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259C1DC: 419A001C  beq cr6, 0x8259c1f8
	if ctx.cr[6].eq {
	pc = 0x8259C1F8; continue 'dispatch;
	}
	// 8259C1E0: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8259C1E4: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259C1E8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259C1EC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259C1F0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259C1F4: 409AFFF4  bne cr6, 0x8259c1e8
	if !ctx.cr[6].eq {
	pc = 0x8259C1E8; continue 'dispatch;
	}
	// 8259C1F8: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259C1FC: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259C200: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C208(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C208 size=328
    let mut pc: u32 = 0x8259C208;
    'dispatch: loop {
        match pc {
            0x8259C208 => {
    //   block [0x8259C208..0x8259C350)
	// 8259C208: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C20C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C210: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C214: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C218: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C21C: 7C8B4850  subf r4, r11, r9
	ctx.r[4].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259C220: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C224: 7D2A4050  subf r9, r10, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259C228: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C22C: 7C880E70  srawi r8, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 8259C230: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C234: 7CC651D6  mullw r6, r6, r10
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259C238: 7D480194  addze r10, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[10].s64 = tmp.s64;
	// 8259C23C: 5568103A  slwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259C240: 54C6103A  slwi r6, r6, 2
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C244: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8259C248: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259C24C: 7D662A14  add r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259C250: 41980008  blt cr6, 0x8259c258
	if ctx.cr[6].lt {
	pc = 0x8259C258; continue 'dispatch;
	}
	// 8259C254: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259C258: 7D4607B4  extsw r6, r10
	ctx.r[6].s64 = ctx.r[10].s32 as i64;
	// 8259C25C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C260: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259C264: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C268: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259C26C: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259C270: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259C274: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259C278: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C27C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259C280: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259C284: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259C288: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259C28C: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259C290: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C294: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C298: 419A0018  beq cr6, 0x8259c2b0
	if ctx.cr[6].eq {
	pc = 0x8259C2B0; continue 'dispatch;
	}
	// 8259C29C: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C2A0: 7C065A2C  dcbt r6, r11
	// 8259C2A4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259C2A8: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259C2AC: 4198FFF0  blt cr6, 0x8259c29c
	if ctx.cr[6].lt {
	pc = 0x8259C29C; continue 'dispatch;
	}
	// 8259C2B0: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259C2B4: C12ABFFC  lfs f9, -0x4004(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259C2B8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C2BC: ED0B002A  fadds f8, f11, f0
	ctx.f[8].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C2C0: C1830034  lfs f12, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259C2C4: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259C2C8: ED8D602A  fadds f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259C2CC: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259C2D0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259C2D4: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259C2D8: EDA80372  fmuls f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C2DC: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C2E0: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C2E4: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259C2E8: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C2EC: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C2F0: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 8259C2F4: 409AFFC4  bne cr6, 0x8259c2b8
	if !ctx.cr[6].eq {
	pc = 0x8259C2B8; continue 'dispatch;
	}
	// 8259C2F8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C2FC: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C300: 5547103E  rotlwi r7, r10, 2
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(2)) as u64;
	// 8259C304: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C308: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259C30C: 0CC70000  twi 6, r7, 0
	// 8259C310: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259C314: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259C318: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259C31C: 41980008  blt cr6, 0x8259c324
	if ctx.cr[6].lt {
	pc = 0x8259C324; continue 'dispatch;
	}
	// 8259C320: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259C324: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C328: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C32C: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259C330: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259C334: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C338: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259C33C: 40980008  bge cr6, 0x8259c344
	if !ctx.cr[6].lt {
	pc = 0x8259C344; continue 'dispatch;
	}
	// 8259C340: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259C344: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C348: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259C34C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C350(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C350 size=408
    let mut pc: u32 = 0x8259C350;
    'dispatch: loop {
        match pc {
            0x8259C350 => {
    //   block [0x8259C350..0x8259C4E8)
	// 8259C350: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C354: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C358: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C35C: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 8259C360: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C364: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C368: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259C36C: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C370: 7D0A4050  subf r8, r10, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259C374: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C378: 7D4651D6  mullw r10, r6, r10
	ctx.r[10].s64 = (ctx.r[6].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259C37C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C380: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259C384: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C388: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C38C: 7D290194  addze r9, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[9].s64 = tmp.s64;
	// 8259C390: 7D662A14  add r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259C394: 7D4A3A14  add r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 8259C398: 7F084800  cmpw cr6, r8, r9
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[9].s32, &mut ctx.xer);
	// 8259C39C: 41980008  blt cr6, 0x8259c3a4
	if ctx.cr[6].lt {
	pc = 0x8259C3A4; continue 'dispatch;
	}
	// 8259C3A0: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259C3A4: 7D2607B4  extsw r6, r9
	ctx.r[6].s64 = ctx.r[9].s32 as i64;
	// 8259C3A8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C3AC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259C3B0: 55071838  slwi r7, r8, 3
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C3B4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259C3B8: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259C3BC: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259C3C0: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259C3C4: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C3C8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259C3CC: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259C3D0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259C3D4: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259C3D8: ED2D6024  fdivs f9, f13, f12
	ctx.f[9].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259C3DC: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C3E0: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C3E4: 419A0018  beq cr6, 0x8259c3fc
	if ctx.cr[6].eq {
	pc = 0x8259C3FC; continue 'dispatch;
	}
	// 8259C3E8: 55263830  slwi r6, r9, 7
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C3EC: 7C065A2C  dcbt r6, r11
	// 8259C3F0: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259C3F4: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259C3F8: 4198FFF0  blt cr6, 0x8259c3e8
	if ctx.cr[6].lt {
	pc = 0x8259C3E8; continue 'dispatch;
	}
	// 8259C3FC: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 8259C400: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 8259C404: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259C408: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259C40C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259C410: 409AFFF4  bne cr6, 0x8259c404
	if !ctx.cr[6].eq {
	pc = 0x8259C404; continue 'dispatch;
	}
	// 8259C414: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259C418: C169BFFC  lfs f11, -0x4004(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C41C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C420: ED89002A  fadds f12, f9, f0
	ctx.f[12].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C424: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C428: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259C42C: ED4D502A  fadds f10, f13, f10
	ctx.f[10].f64 = ((ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C430: D1A40004  stfs f13, 4(r4)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C434: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259C438: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C43C: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C440: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C444: D14A0400  stfs f10, 0x400(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259C448: D1AA0404  stfs f13, 0x404(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259C44C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C450: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259C454: C1440000  lfs f10, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C458: ED4D502A  fadds f10, f13, f10
	ctx.f[10].f64 = ((ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C45C: D1A40000  stfs f13, 0(r4)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C460: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C464: ED8A0032  fmuls f12, f10, f0
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C468: EC08002A  fadds f0, f8, f0
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C46C: ED8C02F2  fmuls f12, f12, f11
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C470: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C474: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C478: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8259C47C: 409AFFA0  bne cr6, 0x8259c41c
	if !ctx.cr[6].eq {
	pc = 0x8259C41C; continue 'dispatch;
	}
	// 8259C480: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C484: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C488: 5527103E  rotlwi r7, r9, 2
	ctx.r[7].u64 = ((ctx.r[9].u32).rotate_left(2)) as u64;
	// 8259C48C: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C490: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259C494: 0CC70000  twi 6, r7, 0
	// 8259C498: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259C49C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259C4A0: 40980008  bge cr6, 0x8259c4a8
	if !ctx.cr[6].lt {
	pc = 0x8259C4A8; continue 'dispatch;
	}
	// 8259C4A4: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259C4A8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C4AC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C4B0: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259C4B4: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259C4B8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C4BC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259C4C0: 41980008  blt cr6, 0x8259c4c8
	if ctx.cr[6].lt {
	pc = 0x8259C4C8; continue 'dispatch;
	}
	// 8259C4C4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8259C4C8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C4CC: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 8259C4D0: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 8259C4D4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259C4D8: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 8259C4DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259C4E0: 409AFFF4  bne cr6, 0x8259c4d4
	if !ctx.cr[6].eq {
	pc = 0x8259C4D4; continue 'dispatch;
	}
	// 8259C4E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C4E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C4E8 size=480
    let mut pc: u32 = 0x8259C4E8;
    'dispatch: loop {
        match pc {
            0x8259C4E8 => {
    //   block [0x8259C4E8..0x8259C6C8)
	// 8259C4E8: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C4EC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C4F0: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C4F4: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 8259C4F8: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C4FC: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C500: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259C504: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C508: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259C50C: 7CEA3850  subf r7, r10, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259C510: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C514: 7D4451D6  mullw r10, r4, r10
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259C518: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C51C: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259C520: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259C524: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259C528: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259C52C: 7D4A2A14  add r10, r10, r5
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[5].u64;
	// 8259C530: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259C534: 41980008  blt cr6, 0x8259c53c
	if ctx.cr[6].lt {
	pc = 0x8259C53C; continue 'dispatch;
	}
	// 8259C538: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259C53C: 7D0507B4  extsw r5, r8
	ctx.r[5].s64 = ctx.r[8].s32 as i64;
	// 8259C540: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C544: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259C548: 54E62036  slwi r6, r7, 4
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C54C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259C550: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259C554: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 8259C558: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259C55C: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C560: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259C564: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259C568: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259C56C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259C570: ED2D6024  fdivs f9, f13, f12
	ctx.f[9].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259C574: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C578: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C57C: 419A0018  beq cr6, 0x8259c594
	if ctx.cr[6].eq {
	pc = 0x8259C594; continue 'dispatch;
	}
	// 8259C580: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259C584: 7C05522C  dcbt r5, r10
	// 8259C588: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259C58C: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259C590: 4198FFF0  blt cr6, 0x8259c580
	if ctx.cr[6].lt {
	pc = 0x8259C580; continue 'dispatch;
	}
	// 8259C594: 7D264B78  mr r6, r9
	ctx.r[6].u64 = ctx.r[9].u64;
	// 8259C598: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 8259C59C: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259C5A0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8259C5A4: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259C5A8: 409AFFF4  bne cr6, 0x8259c59c
	if !ctx.cr[6].eq {
	pc = 0x8259C59C; continue 'dispatch;
	}
	// 8259C5AC: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259C5B0: C188BFFC  lfs f12, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259C5B4: C16A000C  lfs f11, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C5B8: EDA9002A  fadds f13, f9, f0
	ctx.f[13].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C5BC: C149000C  lfs f10, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C5C0: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259C5C4: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C5C8: D169000C  stfs f11, 0xc(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259C5CC: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259C5D0: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C5D4: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C5D8: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C5DC: D14B0C00  stfs f10, 0xc00(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259C5E0: D16B0C04  stfs f11, 0xc04(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259C5E4: C16A0008  lfs f11, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C5E8: C1490008  lfs f10, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C5EC: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C5F0: D1690008  stfs f11, 8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259C5F4: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C5F8: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C5FC: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C600: D14B0800  stfs f10, 0x800(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259C604: D16B0804  stfs f11, 0x804(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259C608: C16A0004  lfs f11, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C60C: C1490004  lfs f10, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C610: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C614: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C618: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C61C: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C620: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C624: D14B0400  stfs f10, 0x400(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259C628: D16B0404  stfs f11, 0x404(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259C62C: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C630: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 8259C634: C1490000  lfs f10, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C638: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C63C: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C640: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C644: ED6A0032  fmuls f11, f10, f0
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C648: EC08002A  fadds f0, f8, f0
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C64C: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C650: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C654: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C658: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259C65C: 409AFF58  bne cr6, 0x8259c5b4
	if !ctx.cr[6].eq {
	pc = 0x8259C5B4; continue 'dispatch;
	}
	// 8259C660: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C664: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C668: 5506103E  rotlwi r6, r8, 2
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(2)) as u64;
	// 8259C66C: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C670: 7D475050  subf r10, r7, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	// 8259C674: 0CC60000  twi 6, r6, 0
	// 8259C678: 7D4A3396  divwu r10, r10, r6
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[6].u32;
	// 8259C67C: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259C680: 40980008  bge cr6, 0x8259c688
	if !ctx.cr[6].lt {
	pc = 0x8259C688; continue 'dispatch;
	}
	// 8259C684: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259C688: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C68C: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C690: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259C694: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259C698: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259C69C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259C6A0: 40980008  bge cr6, 0x8259c6a8
	if !ctx.cr[6].lt {
	pc = 0x8259C6A8; continue 'dispatch;
	}
	// 8259C6A4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8259C6A8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C6AC: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 8259C6B0: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 8259C6B4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259C6B8: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259C6BC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259C6C0: 409AFFF4  bne cr6, 0x8259c6b4
	if !ctx.cr[6].eq {
	pc = 0x8259C6B4; continue 'dispatch;
	}
	// 8259C6C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C6C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C6C8 size=560
    let mut pc: u32 = 0x8259C6C8;
    'dispatch: loop {
        match pc {
            0x8259C6C8 => {
    //   block [0x8259C6C8..0x8259C8F8)
	// 8259C6C8: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C6CC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C6D0: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C6D4: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 8259C6D8: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C6DC: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C6E0: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259C6E4: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C6E8: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259C6EC: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 8259C6F0: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C6F4: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 8259C6F8: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C6FC: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259C700: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259C704: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259C708: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259C70C: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8259C710: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259C714: 41980008  blt cr6, 0x8259c71c
	if ctx.cr[6].lt {
	pc = 0x8259C71C; continue 'dispatch;
	}
	// 8259C718: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259C71C: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 8259C720: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C724: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259C728: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259C72C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259C730: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259C734: 54E6083C  slwi r6, r7, 1
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C738: 7CC73214  add r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259C73C: 54C61838  slwi r6, r6, 3
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(3);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C740: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259C744: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259C748: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259C74C: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259C750: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259C754: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259C758: ED2D6024  fdivs f9, f13, f12
	ctx.f[9].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259C75C: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C760: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259C764: 419A0018  beq cr6, 0x8259c77c
	if ctx.cr[6].eq {
	pc = 0x8259C77C; continue 'dispatch;
	}
	// 8259C768: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259C76C: 7C054A2C  dcbt r5, r9
	// 8259C770: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259C774: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259C778: 4198FFF0  blt cr6, 0x8259c768
	if ctx.cr[6].lt {
	pc = 0x8259C768; continue 'dispatch;
	}
	// 8259C77C: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 8259C780: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 8259C784: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259C788: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8259C78C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259C790: 409AFFF4  bne cr6, 0x8259c784
	if !ctx.cr[6].eq {
	pc = 0x8259C784; continue 'dispatch;
	}
	// 8259C794: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259C798: C188BFFC  lfs f12, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259C79C: C1690014  lfs f11, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C7A0: EDA9002A  fadds f13, f9, f0
	ctx.f[13].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C7A4: C14A0014  lfs f10, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C7A8: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259C7AC: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C7B0: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259C7B4: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259C7B8: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C7BC: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C7C0: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C7C4: D14B1400  stfs f10, 0x1400(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259C7C8: D16B1404  stfs f11, 0x1404(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 8259C7CC: C1690010  lfs f11, 0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C7D0: C14A0010  lfs f10, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C7D4: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C7D8: D16A0010  stfs f11, 0x10(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8259C7DC: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C7E0: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C7E4: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C7E8: D14B1000  stfs f10, 0x1000(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259C7EC: D16B1004  stfs f11, 0x1004(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 8259C7F0: C169000C  lfs f11, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C7F4: C14A000C  lfs f10, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C7F8: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C7FC: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259C800: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C804: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C808: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C80C: D14B0C00  stfs f10, 0xc00(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259C810: D16B0C04  stfs f11, 0xc04(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259C814: C1690008  lfs f11, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C818: C14A0008  lfs f10, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C81C: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C820: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259C824: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C828: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C82C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C830: D14B0800  stfs f10, 0x800(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259C834: D16B0804  stfs f11, 0x804(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259C838: C1690004  lfs f11, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C83C: C14A0004  lfs f10, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C840: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C844: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C848: ED6D02F2  fmuls f11, f13, f11
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C84C: ED4A0032  fmuls f10, f10, f0
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C850: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C854: D14B0400  stfs f10, 0x400(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259C858: D16B0404  stfs f11, 0x404(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259C85C: C1690000  lfs f11, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259C860: 39290018  addi r9, r9, 0x18
	ctx.r[9].s64 = ctx.r[9].s64 + 24;
	// 8259C864: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C868: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259C86C: ED4B502A  fadds f10, f11, f10
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64;
	// 8259C870: D16A0000  stfs f11, 0(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C874: ED6A0032  fmuls f11, f10, f0
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C878: EC08002A  fadds f0, f8, f0
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259C87C: ED6B0332  fmuls f11, f11, f12
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259C880: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C884: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259C888: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259C88C: 409AFF10  bne cr6, 0x8259c79c
	if !ctx.cr[6].eq {
	pc = 0x8259C79C; continue 'dispatch;
	}
	// 8259C890: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C894: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C898: 5506103E  rotlwi r6, r8, 2
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(2)) as u64;
	// 8259C89C: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C8A0: 7D274850  subf r9, r7, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 8259C8A4: 0CC60000  twi 6, r6, 0
	// 8259C8A8: 7D293396  divwu r9, r9, r6
	ctx.r[9].u32 = ctx.r[9].u32 / ctx.r[6].u32;
	// 8259C8AC: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259C8B0: 40980008  bge cr6, 0x8259c8b8
	if !ctx.cr[6].lt {
	pc = 0x8259C8B8; continue 'dispatch;
	}
	// 8259C8B4: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259C8B8: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C8BC: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C8C0: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259C8C4: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259C8C8: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259C8CC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259C8D0: 40980008  bge cr6, 0x8259c8d8
	if !ctx.cr[6].lt {
	pc = 0x8259C8D8; continue 'dispatch;
	}
	// 8259C8D4: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259C8D8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259C8DC: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 8259C8E0: 9123001C  stw r9, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[9].u32 ) };
	// 8259C8E4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8259C8E8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259C8EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8259C8F0: 409AFFF4  bne cr6, 0x8259c8e4
	if !ctx.cr[6].eq {
	pc = 0x8259C8E4; continue 'dispatch;
	}
	// 8259C8F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259C8F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259C8F8 size=552
    let mut pc: u32 = 0x8259C8F8;
    'dispatch: loop {
        match pc {
            0x8259C8F8 => {
    //   block [0x8259C8F8..0x8259CB20)
	// 8259C8F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259C8FC: 4BF987C1  bl 0x825350bc
	ctx.lr = 0x8259C900;
	sub_82535080(ctx, base);
	// 8259C900: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259C904: C1830024  lfs f12, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259C908: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259C90C: 3BE30034  addi r31, r3, 0x34
	ctx.r[31].s64 = ctx.r[3].s64 + 52;
	// 8259C910: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259C914: 5567103A  slwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259C918: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259C91C: 7FCB4850  subf r30, r11, r9
	ctx.r[30].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259C920: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259C924: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259C928: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259C92C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C930: 7FCB0E70  srawi r11, r30, 1
	ctx.xer.ca = (ctx.r[30].s32 < 0) && ((ctx.r[30].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[30].s32 >> 1) as i64;
	// 8259C934: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259C938: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259C93C: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 8259C940: 7CC73214  add r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259C944: 7CE94214  add r7, r9, r8
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 8259C948: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259C94C: 7D445378  mr r4, r10
	ctx.r[4].u64 = ctx.r[10].u64;
	// 8259C950: 41980008  blt cr6, 0x8259c958
	if ctx.cr[6].lt {
	pc = 0x8259C958; continue 'dispatch;
	}
	// 8259C954: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 8259C958: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259C95C: C0030028  lfs f0, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C960: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259C964: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259C968: F961FFD0  std r11, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[11].u64 ) };
	// 8259C96C: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259C970: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259C974: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259C978: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259C97C: ED006824  fdivs f8, f0, f13
	ctx.f[8].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 8259C980: C00B2068  lfs f0, 0x2068(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259C984: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259C988: C14B206C  lfs f10, 0x206c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8300 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259C98C: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259C990: 419A003C  beq cr6, 0x8259c9cc
	if ctx.cr[6].eq {
	pc = 0x8259C9CC; continue 'dispatch;
	}
	// 8259C994: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 8259C998: 7CAA2B78  mr r10, r5
	ctx.r[10].u64 = ctx.r[5].u64;
	// 8259C99C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C9A0: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259C9A4: 7D290734  extsh r9, r9
	ctx.r[9].s64 = ctx.r[9].s16 as i64;
	// 8259C9A8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259C9AC: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259C9B0: C801FFD0  lfd f0, -0x30(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259C9B4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259C9B8: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259C9BC: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259C9C0: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259C9C4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259C9C8: 409AFFD4  bne cr6, 0x8259c99c
	if !ctx.cr[6].eq {
	pc = 0x8259C99C; continue 'dispatch;
	}
	// 8259C9CC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259C9D0: 54BE083C  slwi r30, r5, 1
	ctx.r[30].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8259C9D4: C12BBFFC  lfs f9, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259C9D8: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259C9DC: 419A006C  beq cr6, 0x8259ca48
	if ctx.cr[6].eq {
	pc = 0x8259CA48; continue 'dispatch;
	}
	// 8259C9E0: ED68602A  fadds f11, f8, f12
	ctx.f[11].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259C9E4: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 8259C9E8: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 8259C9EC: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 8259C9F0: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 8259C9F4: A3A80000  lhz r29, 0(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259C9F8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259C9FC: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259CA00: 7FBD0734  extsh r29, r29
	ctx.r[29].s64 = ctx.r[29].s16 as i64;
	// 8259CA04: 39080002  addi r8, r8, 2
	ctx.r[8].s64 = ctx.r[8].s64 + 2;
	// 8259CA08: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259CA0C: FBA1FFD0  std r29, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[29].u64 ) };
	// 8259CA10: C801FFD0  lfd f0, -0x30(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259CA14: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259CA18: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259CA1C: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259CA20: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CA24: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259CA28: EDA0682A  fadds f13, f0, f13
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8259CA2C: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CA30: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259CA34: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259CA38: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CA3C: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259CA40: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 8259CA44: 409AFFB0  bne cr6, 0x8259c9f4
	if !ctx.cr[6].eq {
	pc = 0x8259C9F4; continue 'dispatch;
	}
	// 8259CA48: 3884FFFF  addi r4, r4, -1
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	// 8259CA4C: ED87602A  fadds f12, f7, f12
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259CA50: 7CFE3A14  add r7, r30, r7
	ctx.r[7].u64 = ctx.r[30].u64 + ctx.r[7].u64;
	// 8259CA54: 38C60008  addi r6, r6, 8
	ctx.r[6].s64 = ctx.r[6].s64 + 8;
	// 8259CA58: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 8259CA5C: 409AFF7C  bne cr6, 0x8259c9d8
	if !ctx.cr[6].eq {
	pc = 0x8259C9D8; continue 'dispatch;
	}
	// 8259CA60: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CA64: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CA68: 554A083E  rotlwi r10, r10, 1
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259CA6C: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 8259CA70: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CA74: 0CCA0000  twi 6, r10, 0
	// 8259CA78: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259CA7C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259CA80: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259CA84: 41980008  blt cr6, 0x8259ca8c
	if ctx.cr[6].lt {
	pc = 0x8259CA8C; continue 'dispatch;
	}
	// 8259CA88: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259CA8C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CA90: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CA94: 7D4A3050  subf r10, r10, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259CA98: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259CA9C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259CAA0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259CAA4: 40980008  bge cr6, 0x8259caac
	if !ctx.cr[6].lt {
	pc = 0x8259CAAC; continue 'dispatch;
	}
	// 8259CAA8: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259CAAC: D1830024  stfs f12, 0x24(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259CAB0: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259CAB4: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259CAB8: 419A0064  beq cr6, 0x8259cb1c
	if ctx.cr[6].eq {
	pc = 0x8259CB1C; continue 'dispatch;
	}
	// 8259CABC: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8259CAC0: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 8259CAC4: 39007FFF  li r8, 0x7fff
	ctx.r[8].s64 = 32767;
	// 8259CAC8: 3920801E  li r9, -0x7fe2
	ctx.r[9].s64 = -32738;
	// 8259CACC: C00A72B8  lfs f0, 0x72b8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CAD0: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CAD4: 3941FFD0  addi r10, r1, -0x30
	ctx.r[10].s64 = ctx.r[1].s64 + -48;
	// 8259CAD8: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CADC: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259CAE0: 7DA057AE  stfiwx f13, 0, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259CAE4: 8141FFD0  lwz r10, -0x30(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8259CAE8: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 8259CAEC: 4198000C  blt cr6, 0x8259caf8
	if ctx.cr[6].lt {
	pc = 0x8259CAF8; continue 'dispatch;
	}
	// 8259CAF0: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259CAF4: 48000018  b 0x8259cb0c
	pc = 0x8259CB0C; continue 'dispatch;
	// 8259CAF8: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 8259CAFC: 4199000C  bgt cr6, 0x8259cb08
	if ctx.cr[6].gt {
	pc = 0x8259CB08; continue 'dispatch;
	}
	// 8259CB00: B12B0000  sth r9, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8259CB04: 48000008  b 0x8259cb0c
	pc = 0x8259CB0C; continue 'dispatch;
	// 8259CB08: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 8259CB0C: 38A5FFFF  addi r5, r5, -1
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	// 8259CB10: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259CB14: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259CB18: 409AFFB8  bne cr6, 0x8259cad0
	if !ctx.cr[6].eq {
	pc = 0x8259CAD0; continue 'dispatch;
	}
	// 8259CB1C: 4BF985F0  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CB20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259CB20 size=440
    let mut pc: u32 = 0x8259CB20;
    'dispatch: loop {
        match pc {
            0x8259CB20 => {
    //   block [0x8259CB20..0x8259CCD8)
	// 8259CB20: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259CB24: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CB28: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CB2C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259CB30: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CB34: 7C8B4850  subf r4, r11, r9
	ctx.r[4].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259CB38: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CB3C: 7D2A4050  subf r9, r10, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259CB40: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CB44: 7C880E70  srawi r8, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 8259CB48: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CB4C: 7CC651D6  mullw r6, r6, r10
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259CB50: 7D480194  addze r10, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[10].s64 = tmp.s64;
	// 8259CB54: 5568103A  slwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259CB58: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CB5C: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8259CB60: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8259CB64: 7D662A14  add r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259CB68: 41980008  blt cr6, 0x8259cb70
	if ctx.cr[6].lt {
	pc = 0x8259CB70; continue 'dispatch;
	}
	// 8259CB6C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259CB70: 7D4607B4  extsw r6, r10
	ctx.r[6].s64 = ctx.r[10].s32 as i64;
	// 8259CB74: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CB78: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259CB7C: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259CB80: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259CB84: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259CB88: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259CB8C: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CB90: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259CB94: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259CB98: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259CB9C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259CBA0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259CBA4: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259CBA8: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CBAC: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CBB0: 419A0018  beq cr6, 0x8259cbc8
	if ctx.cr[6].eq {
	pc = 0x8259CBC8; continue 'dispatch;
	}
	// 8259CBB4: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CBB8: 7C065A2C  dcbt r6, r11
	// 8259CBBC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259CBC0: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259CBC4: 4198FFF0  blt cr6, 0x8259cbb4
	if ctx.cr[6].lt {
	pc = 0x8259CBB4; continue 'dispatch;
	}
	// 8259CBC8: A1430034  lhz r10, 0x34(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 8259CBCC: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259CBD0: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259CBD4: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CBD8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259CBDC: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259CBE0: C10A206C  lfs f8, 0x206c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8300 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259CBE4: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259CBE8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259CBEC: C12ABFFC  lfs f9, -0x4004(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259CBF0: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259CBF4: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259CBF8: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CBFC: C1830034  lfs f12, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259CC00: ECEB002A  fadds f7, f11, f0
	ctx.f[7].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259CC04: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259CC08: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259CC0C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8259CC10: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8259CC14: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259CC18: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CC1C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259CC20: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259CC24: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259CC28: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259CC2C: ED8D602A  fadds f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259CC30: EDA70372  fmuls f13, f7, f13
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CC34: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CC38: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259CC3C: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259CC40: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CC44: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259CC48: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 8259CC4C: 409AFFAC  bne cr6, 0x8259cbf8
	if !ctx.cr[6].eq {
	pc = 0x8259CBF8; continue 'dispatch;
	}
	// 8259CC50: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CC54: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CC58: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259CC5C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CC60: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259CC64: 0CC70000  twi 6, r7, 0
	// 8259CC68: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259CC6C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259CC70: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259CC74: 41980008  blt cr6, 0x8259cc7c
	if ctx.cr[6].lt {
	pc = 0x8259CC7C; continue 'dispatch;
	}
	// 8259CC78: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259CC7C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CC80: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CC84: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259CC88: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259CC8C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259CC90: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259CC94: 40980008  bge cr6, 0x8259cc9c
	if !ctx.cr[6].lt {
	pc = 0x8259CC9C; continue 'dispatch;
	}
	// 8259CC98: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259CC9C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259CCA0: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259CCA4: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259CCA8: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 8259CCAC: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CCB0: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CCB4: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CCB8: FC00001E  fctiwz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 8259CCBC: 7C0057AE  stfiwx f0, 0, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259CCC0: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8259CCC4: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259CCC8: 41980010  blt cr6, 0x8259ccd8
	if ctx.cr[6].lt {
		sub_8259CCD8(ctx, base);
		return;
	}
	// 8259CCCC: 39607FFF  li r11, 0x7fff
	ctx.r[11].s64 = 32767;
	// 8259CCD0: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 8259CCD4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CCD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259CCD8 size=20
    let mut pc: u32 = 0x8259CCD8;
    'dispatch: loop {
        match pc {
            0x8259CCD8 => {
    //   block [0x8259CCD8..0x8259CCEC)
	// 8259CCD8: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259CCDC: 41990008  bgt cr6, 0x8259cce4
	if ctx.cr[6].gt {
	pc = 0x8259CCE4; continue 'dispatch;
	}
	// 8259CCE0: 3960801E  li r11, -0x7fe2
	ctx.r[11].s64 = -32738;
	// 8259CCE4: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 8259CCE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CCF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259CCF0 size=540
    let mut pc: u32 = 0x8259CCF0;
    'dispatch: loop {
        match pc {
            0x8259CCF0 => {
    //   block [0x8259CCF0..0x8259CF0C)
	// 8259CCF0: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259CCF4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CCF8: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CCFC: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 8259CD00: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259CD04: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259CD08: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CD0C: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CD10: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259CD14: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CD18: 7CC651D6  mullw r6, r6, r10
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259CD1C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CD20: 7D0A4050  subf r8, r10, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259CD24: 7D490194  addze r10, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[10].s64 = tmp.s64;
	// 8259CD28: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259CD2C: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CD30: 7F085000  cmpw cr6, r8, r10
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8259CD34: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8259CD38: 7D662A14  add r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259CD3C: 41980008  blt cr6, 0x8259cd44
	if ctx.cr[6].lt {
	pc = 0x8259CD44; continue 'dispatch;
	}
	// 8259CD40: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259CD44: 7D4607B4  extsw r6, r10
	ctx.r[6].s64 = ctx.r[10].s32 as i64;
	// 8259CD48: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CD4C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259CD50: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259CD54: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259CD58: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259CD5C: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259CD60: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CD64: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259CD68: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259CD6C: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259CD70: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259CD74: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259CD78: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259CD7C: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CD80: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CD84: 419A0018  beq cr6, 0x8259cd9c
	if ctx.cr[6].eq {
	pc = 0x8259CD9C; continue 'dispatch;
	}
	// 8259CD88: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CD8C: 7C065A2C  dcbt r6, r11
	// 8259CD90: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259CD94: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259CD98: 4198FFF0  blt cr6, 0x8259cd88
	if ctx.cr[6].lt {
	pc = 0x8259CD88; continue 'dispatch;
	}
	// 8259CD9C: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259CDA0: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8259CDA4: 38E00002  li r7, 2
	ctx.r[7].s64 = 2;
	// 8259CDA8: C166206C  lfs f11, 0x206c(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8300 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259CDAC: A0CA0000  lhz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CDB0: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259CDB4: 7CC60734  extsh r6, r6
	ctx.r[6].s64 = ctx.r[6].s16 as i64;
	// 8259CDB8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259CDBC: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259CDC0: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CDC4: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259CDC8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259CDCC: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259CDD0: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CDD4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259CDD8: 409AFFD4  bne cr6, 0x8259cdac
	if !ctx.cr[6].eq {
	pc = 0x8259CDAC; continue 'dispatch;
	}
	// 8259CDDC: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259CDE0: C14ABFFC  lfs f10, -0x4004(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259CDE4: A14B0002  lhz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259CDE8: C1240004  lfs f9, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259CDEC: ED88002A  fadds f12, f8, f0
	ctx.f[12].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259CDF0: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259CDF4: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259CDF8: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259CDFC: F941FFF0  std r10, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[10].u64 ) };
	// 8259CE00: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259CE04: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259CE08: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259CE0C: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259CE10: D1A40004  stfs f13, 4(r4)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259CE14: ED2D482A  fadds f9, f13, f9
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259CE18: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CE1C: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CE20: ED2902B2  fmuls f9, f9, f10
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259CE24: D1290400  stfs f9, 0x400(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259CE28: D1A90404  stfs f13, 0x404(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259CE2C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CE30: C1240000  lfs f9, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259CE34: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259CE38: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8259CE3C: F941FFF8  std r10, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[10].u64 ) };
	// 8259CE40: C9A1FFF8  lfd f13, -8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259CE44: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259CE48: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259CE4C: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259CE50: D1A40000  stfs f13, 0(r4)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CE54: ED2D482A  fadds f9, f13, f9
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259CE58: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CE5C: ED890032  fmuls f12, f9, f0
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CE60: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259CE64: ED8C02B2  fmuls f12, f12, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259CE68: D1890000  stfs f12, 0(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259CE6C: D1A90004  stfs f13, 4(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259CE70: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 8259CE74: 409AFF70  bne cr6, 0x8259cde4
	if !ctx.cr[6].eq {
	pc = 0x8259CDE4; continue 'dispatch;
	}
	// 8259CE78: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CE7C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CE80: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259CE84: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CE88: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259CE8C: 0CC70000  twi 6, r7, 0
	// 8259CE90: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259CE94: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259CE98: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 8259CE9C: 41980008  blt cr6, 0x8259cea4
	if ctx.cr[6].lt {
	pc = 0x8259CEA4; continue 'dispatch;
	}
	// 8259CEA0: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259CEA4: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CEA8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CEAC: 7D4A4850  subf r10, r10, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 8259CEB0: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259CEB4: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259CEB8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259CEBC: 41980008  blt cr6, 0x8259cec4
	if ctx.cr[6].lt {
	pc = 0x8259CEC4; continue 'dispatch;
	}
	// 8259CEC0: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8259CEC4: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 8259CEC8: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8259CECC: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259CED0: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8259CED4: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 8259CED8: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 8259CEDC: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 8259CEE0: C00A72B8  lfs f0, 0x72b8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CEE4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CEE8: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 8259CEEC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259CEF0: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259CEF4: 7DA057AE  stfiwx f13, 0, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259CEF8: 8141FFF0  lwz r10, -0x10(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8259CEFC: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 8259CF00: 4198000C  blt cr6, 0x8259cf0c
	if ctx.cr[6].lt {
		sub_8259CF0C(ctx, base);
		return;
	}
	// 8259CF04: B0EB0000  sth r7, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259CF08: 48000018  b 0x8259cf20
	sub_8259CF1C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CF0C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259CF0C size=16
    let mut pc: u32 = 0x8259CF0C;
    'dispatch: loop {
        match pc {
            0x8259CF0C => {
    //   block [0x8259CF0C..0x8259CF1C)
	// 8259CF0C: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 8259CF10: 4199000C  bgt cr6, 0x8259cf1c
	if ctx.cr[6].gt {
		sub_8259CF1C(ctx, base);
		return;
	}
	// 8259CF14: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259CF18: 48000008  b 0x8259cf20
	sub_8259CF1C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CF1C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259CF1C size=24
    let mut pc: u32 = 0x8259CF1C;
    'dispatch: loop {
        match pc {
            0x8259CF1C => {
    //   block [0x8259CF1C..0x8259CF34)
	// 8259CF1C: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 8259CF20: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259CF24: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259CF28: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259CF2C: 409AFFB8  bne cr6, 0x8259cee4
	if !ctx.cr[6].eq {
		sub_8259CCF0(ctx, base);
		return;
	}
	// 8259CF30: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259CF38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259CF38 size=652
    let mut pc: u32 = 0x8259CF38;
    'dispatch: loop {
        match pc {
            0x8259CF38 => {
    //   block [0x8259CF38..0x8259D1C4)
	// 8259CF38: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259CF3C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259CF40: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259CF44: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 8259CF48: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259CF4C: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259CF50: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259CF54: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259CF58: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259CF5C: 7CEA3850  subf r7, r10, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259CF60: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CF64: 7D4451D6  mullw r10, r4, r10
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259CF68: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259CF6C: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259CF70: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259CF74: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259CF78: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259CF7C: 7D4A2A14  add r10, r10, r5
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[5].u64;
	// 8259CF80: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259CF84: 41980008  blt cr6, 0x8259cf8c
	if ctx.cr[6].lt {
	pc = 0x8259CF8C; continue 'dispatch;
	}
	// 8259CF88: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259CF8C: 7D0507B4  extsw r5, r8
	ctx.r[5].s64 = ctx.r[8].s32 as i64;
	// 8259CF90: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CF94: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259CF98: 54E61838  slwi r6, r7, 3
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(3);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CF9C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259CFA0: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259CFA4: F8A1FFE0  std r5, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[5].u64 ) };
	// 8259CFA8: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259CFAC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259CFB0: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259CFB4: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259CFB8: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259CFBC: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259CFC0: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259CFC4: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259CFC8: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259CFCC: 419A0018  beq cr6, 0x8259cfe4
	if ctx.cr[6].eq {
	pc = 0x8259CFE4; continue 'dispatch;
	}
	// 8259CFD0: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259CFD4: 7C05522C  dcbt r5, r10
	// 8259CFD8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259CFDC: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259CFE0: 4198FFF0  blt cr6, 0x8259cfd0
	if ctx.cr[6].lt {
	pc = 0x8259CFD0; continue 'dispatch;
	}
	// 8259CFE4: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259CFE8: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259CFEC: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 8259CFF0: C185206C  lfs f12, 0x206c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8300 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259CFF4: A0A80000  lhz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259CFF8: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259CFFC: 7CA50734  extsh r5, r5
	ctx.r[5].s64 = ctx.r[5].s16 as i64;
	// 8259D000: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259D004: F8A1FFE0  std r5, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[5].u64 ) };
	// 8259D008: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D00C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259D010: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259D014: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D018: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D01C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259D020: 409AFFD4  bne cr6, 0x8259cff4
	if !ctx.cr[6].eq {
	pc = 0x8259CFF4; continue 'dispatch;
	}
	// 8259D024: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259D028: C168BFFC  lfs f11, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259D02C: A10A0006  lhz r8, 6(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259D030: C129000C  lfs f9, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D034: EDA8002A  fadds f13, f8, f0
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D038: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259D03C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D040: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259D044: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259D048: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D04C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D050: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D054: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D058: D149000C  stfs f10, 0xc(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259D05C: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D060: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D064: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D068: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D06C: D12B0C00  stfs f9, 0xc00(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259D070: D14B0C04  stfs f10, 0xc04(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259D074: A10A0004  lhz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D078: C1290008  lfs f9, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D07C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D080: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259D084: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259D088: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D08C: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D090: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D094: D1490008  stfs f10, 8(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259D098: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D09C: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D0A0: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D0A4: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D0A8: D12B0800  stfs f9, 0x800(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259D0AC: D14B0804  stfs f10, 0x804(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259D0B0: A10A0002  lhz r8, 2(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259D0B4: C1290004  lfs f9, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D0B8: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D0BC: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259D0C0: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D0C4: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D0C8: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D0CC: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D0D0: D1490004  stfs f10, 4(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D0D4: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D0D8: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D0DC: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D0E0: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D0E4: D12B0400  stfs f9, 0x400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259D0E8: D14B0404  stfs f10, 0x404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259D0EC: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D0F0: C1290000  lfs f9, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D0F4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 8259D0F8: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D0FC: F901FFF8  std r8, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[8].u64 ) };
	// 8259D100: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259D104: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D108: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D10C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D110: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D114: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D118: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D11C: ED490032  fmuls f10, f9, f0
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D120: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D124: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D128: D14B0000  stfs f10, 0(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D12C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D130: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259D134: 409AFEF8  bne cr6, 0x8259d02c
	if !ctx.cr[6].eq {
	pc = 0x8259D02C; continue 'dispatch;
	}
	// 8259D138: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D13C: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D140: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 8259D144: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D148: 7D475050  subf r10, r7, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	// 8259D14C: 0CC60000  twi 6, r6, 0
	// 8259D150: 7D4A3396  divwu r10, r10, r6
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[6].u32;
	// 8259D154: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259D158: 40980008  bge cr6, 0x8259d160
	if !ctx.cr[6].lt {
	pc = 0x8259D160; continue 'dispatch;
	}
	// 8259D15C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259D160: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D164: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D168: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259D16C: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259D170: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D174: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259D178: 41980008  blt cr6, 0x8259d180
	if ctx.cr[6].lt {
	pc = 0x8259D180; continue 'dispatch;
	}
	// 8259D17C: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259D180: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259D184: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259D188: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259D18C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 8259D190: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 8259D194: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 8259D198: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D19C: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D1A0: 3961FFE0  addi r11, r1, -0x20
	ctx.r[11].s64 = ctx.r[1].s64 + -32;
	// 8259D1A4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D1A8: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259D1AC: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259D1B0: 8161FFE0  lwz r11, -0x20(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) } as u64;
	// 8259D1B4: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259D1B8: 4198000C  blt cr6, 0x8259d1c4
	if ctx.cr[6].lt {
		sub_8259D1C4(ctx, base);
		return;
	}
	// 8259D1BC: B0E90000  sth r7, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259D1C0: 48000018  b 0x8259d1d8
	sub_8259D1D4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D1C4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259D1C4 size=16
    let mut pc: u32 = 0x8259D1C4;
    'dispatch: loop {
        match pc {
            0x8259D1C4 => {
    //   block [0x8259D1C4..0x8259D1D4)
	// 8259D1C4: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259D1C8: 4199000C  bgt cr6, 0x8259d1d4
	if ctx.cr[6].gt {
		sub_8259D1D4(ctx, base);
		return;
	}
	// 8259D1CC: B1090000  sth r8, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259D1D0: 48000008  b 0x8259d1d8
	sub_8259D1D4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D1D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259D1D4 size=24
    let mut pc: u32 = 0x8259D1D4;
    'dispatch: loop {
        match pc {
            0x8259D1D4 => {
    //   block [0x8259D1D4..0x8259D1EC)
	// 8259D1D4: B1690000  sth r11, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 8259D1D8: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259D1DC: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259D1E0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259D1E4: 409AFFB8  bne cr6, 0x8259d19c
	if !ctx.cr[6].eq {
		sub_8259CF38(ctx, base);
		return;
	}
	// 8259D1E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D1F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259D1F0 size=780
    let mut pc: u32 = 0x8259D1F0;
    'dispatch: loop {
        match pc {
            0x8259D1F0 => {
    //   block [0x8259D1F0..0x8259D4FC)
	// 8259D1F0: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259D1F4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D1F8: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D1FC: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 8259D200: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259D204: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D208: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259D20C: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D210: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D214: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 8259D218: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D21C: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 8259D220: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D224: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259D228: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259D22C: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259D230: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259D234: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8259D238: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259D23C: 41980008  blt cr6, 0x8259d244
	if ctx.cr[6].lt {
	pc = 0x8259D244; continue 'dispatch;
	}
	// 8259D240: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259D244: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 8259D248: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D24C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259D250: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259D254: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259D258: F8C1FFD0  std r6, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[6].u64 ) };
	// 8259D25C: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259D260: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259D264: 54E6083C  slwi r6, r7, 1
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259D268: 7CC73214  add r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259D26C: 54C6103A  slwi r6, r6, 2
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259D270: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259D274: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259D278: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259D27C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259D280: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259D284: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D288: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259D28C: 419A0018  beq cr6, 0x8259d2a4
	if ctx.cr[6].eq {
	pc = 0x8259D2A4; continue 'dispatch;
	}
	// 8259D290: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259D294: 7C054A2C  dcbt r5, r9
	// 8259D298: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259D29C: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259D2A0: 4198FFF0  blt cr6, 0x8259d290
	if ctx.cr[6].lt {
	pc = 0x8259D290; continue 'dispatch;
	}
	// 8259D2A4: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259D2A8: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259D2AC: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 8259D2B0: C185206C  lfs f12, 0x206c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8300 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259D2B4: A0A80000  lhz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D2B8: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259D2BC: 7CA50734  extsh r5, r5
	ctx.r[5].s64 = ctx.r[5].s16 as i64;
	// 8259D2C0: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259D2C4: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 8259D2C8: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259D2CC: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259D2D0: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259D2D4: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D2D8: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D2DC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259D2E0: 409AFFD4  bne cr6, 0x8259d2b4
	if !ctx.cr[6].eq {
	pc = 0x8259D2B4; continue 'dispatch;
	}
	// 8259D2E4: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259D2E8: C168BFFC  lfs f11, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259D2EC: A109000A  lhz r8, 0xa(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(10 as u32) ) } as u64;
	// 8259D2F0: C12A0014  lfs f9, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D2F4: EDA8002A  fadds f13, f8, f0
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D2F8: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259D2FC: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D300: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 8259D304: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259D308: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D30C: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D310: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D314: D14A0014  stfs f10, 0x14(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259D318: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D31C: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D320: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D324: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D328: D12B1400  stfs f9, 0x1400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259D32C: D14B1404  stfs f10, 0x1404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 8259D330: A1090008  lhz r8, 8(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259D334: C12A0010  lfs f9, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D338: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D33C: F901FFD8  std r8, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[8].u64 ) };
	// 8259D340: C941FFD8  lfd f10, -0x28(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259D344: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D348: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D34C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D350: D14A0010  stfs f10, 0x10(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8259D354: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D358: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D35C: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D360: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D364: D12B1000  stfs f9, 0x1000(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259D368: D14B1004  stfs f10, 0x1004(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 8259D36C: A1090006  lhz r8, 6(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259D370: C12A000C  lfs f9, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D374: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D378: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259D37C: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D380: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D384: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D388: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D38C: D14A000C  stfs f10, 0xc(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259D390: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D394: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D398: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D39C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D3A0: D12B0C00  stfs f9, 0xc00(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259D3A4: D14B0C04  stfs f10, 0xc04(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259D3A8: A1090004  lhz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D3AC: C12A0008  lfs f9, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D3B0: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D3B4: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259D3B8: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259D3BC: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D3C0: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D3C4: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D3C8: D14A0008  stfs f10, 8(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259D3CC: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D3D0: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D3D4: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D3D8: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D3DC: D12B0800  stfs f9, 0x800(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259D3E0: D14B0804  stfs f10, 0x804(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259D3E4: A1090002  lhz r8, 2(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259D3E8: C12A0004  lfs f9, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D3EC: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D3F0: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 8259D3F4: C941FFF0  lfd f10, -0x10(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D3F8: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D3FC: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D400: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D404: D14A0004  stfs f10, 4(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D408: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D40C: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D410: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D414: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D418: D12B0400  stfs f9, 0x400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259D41C: D14B0404  stfs f10, 0x404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259D420: A1090000  lhz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D424: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D428: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 8259D42C: 7D080734  extsh r8, r8
	ctx.r[8].s64 = ctx.r[8].s16 as i64;
	// 8259D430: F901FFF8  std r8, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[8].u64 ) };
	// 8259D434: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259D438: C941FFF8  lfd f10, -8(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259D43C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259D440: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259D444: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D448: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D44C: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259D450: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259D454: ED490032  fmuls f10, f9, f0
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D458: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D45C: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259D460: D14B0000  stfs f10, 0(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D464: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D468: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259D46C: 409AFE80  bne cr6, 0x8259d2ec
	if !ctx.cr[6].eq {
	pc = 0x8259D2EC; continue 'dispatch;
	}
	// 8259D470: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D474: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D478: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 8259D47C: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D480: 7D274850  subf r9, r7, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 8259D484: 0CC60000  twi 6, r6, 0
	// 8259D488: 7D293396  divwu r9, r9, r6
	ctx.r[9].u32 = ctx.r[9].u32 / ctx.r[6].u32;
	// 8259D48C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259D490: 40980008  bge cr6, 0x8259d498
	if !ctx.cr[6].lt {
	pc = 0x8259D498; continue 'dispatch;
	}
	// 8259D494: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259D498: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D49C: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D4A0: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259D4A4: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259D4A8: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D4AC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259D4B0: 41980008  blt cr6, 0x8259d4b8
	if ctx.cr[6].lt {
	pc = 0x8259D4B8; continue 'dispatch;
	}
	// 8259D4B4: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 8259D4B8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259D4BC: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259D4C0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259D4C4: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8259D4C8: 38E07FFF  li r7, 0x7fff
	ctx.r[7].s64 = 32767;
	// 8259D4CC: 3900801E  li r8, -0x7fe2
	ctx.r[8].s64 = -32738;
	// 8259D4D0: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D4D4: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D4D8: 3961FFD0  addi r11, r1, -0x30
	ctx.r[11].s64 = ctx.r[1].s64 + -48;
	// 8259D4DC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D4E0: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259D4E4: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259D4E8: 8161FFD0  lwz r11, -0x30(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8259D4EC: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259D4F0: 4198000C  blt cr6, 0x8259d4fc
	if ctx.cr[6].lt {
		sub_8259D4FC(ctx, base);
		return;
	}
	// 8259D4F4: B0EA0000  sth r7, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259D4F8: 48000018  b 0x8259d510
	sub_8259D50C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D4FC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259D4FC size=16
    let mut pc: u32 = 0x8259D4FC;
    'dispatch: loop {
        match pc {
            0x8259D4FC => {
    //   block [0x8259D4FC..0x8259D50C)
	// 8259D4FC: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259D500: 4199000C  bgt cr6, 0x8259d50c
	if ctx.cr[6].gt {
		sub_8259D50C(ctx, base);
		return;
	}
	// 8259D504: B10A0000  sth r8, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259D508: 48000008  b 0x8259d510
	sub_8259D50C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D50C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259D50C size=24
    let mut pc: u32 = 0x8259D50C;
    'dispatch: loop {
        match pc {
            0x8259D50C => {
    //   block [0x8259D50C..0x8259D524)
	// 8259D50C: B16A0000  sth r11, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 8259D510: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259D514: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259D518: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259D51C: 409AFFB8  bne cr6, 0x8259d4d4
	if !ctx.cr[6].eq {
		sub_8259D1F0(ctx, base);
		return;
	}
	// 8259D520: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D528(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259D528 size=552
    let mut pc: u32 = 0x8259D528;
    'dispatch: loop {
        match pc {
            0x8259D528 => {
    //   block [0x8259D528..0x8259D750)
	// 8259D528: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 8259D52C: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259D530: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259D534: C1830024  lfs f12, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259D538: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D53C: 38830034  addi r4, r3, 0x34
	ctx.r[4].s64 = ctx.r[3].s64 + 52;
	// 8259D540: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259D544: 7FEB4850  subf r31, r11, r9
	ctx.r[31].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259D548: 80C30004  lwz r6, 4(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D54C: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D550: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D554: 7FFF0E70  srawi r31, r31, 1
	ctx.xer.ca = (ctx.r[31].s32 < 0) && ((ctx.r[31].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[31].s64 = (ctx.r[31].s32 >> 1) as i64;
	// 8259D558: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D55C: 7D2A3050  subf r9, r10, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 8259D560: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D564: 7CC851D6  mullw r6, r8, r10
	ctx.r[6].s64 = (ctx.r[8].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259D568: 7D5F0194  addze r10, r31
	tmp.s64 = ctx.r[31].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[31].u32);
	ctx.r[10].s64 = tmp.s64;
	// 8259D56C: 7CC62A14  add r6, r6, r5
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259D570: 7CEB3A14  add r7, r11, r7
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259D574: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8259D578: 7D254B78  mr r5, r9
	ctx.r[5].u64 = ctx.r[9].u64;
	// 8259D57C: 41980008  blt cr6, 0x8259d584
	if ctx.cr[6].lt {
	pc = 0x8259D584; continue 'dispatch;
	}
	// 8259D580: 7D455378  mr r5, r10
	ctx.r[5].u64 = ctx.r[10].u64;
	// 8259D584: 7D4B07B4  extsw r11, r10
	ctx.r[11].s64 = ctx.r[10].s32 as i64;
	// 8259D588: C0030028  lfs f0, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D58C: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259D590: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 8259D594: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259D598: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 8259D59C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D5A0: C12A2384  lfs f9, 0x2384(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(9092 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D5A4: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D5A8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259D5AC: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259D5B0: ECE06824  fdivs f7, f0, f13
	ctx.f[7].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 8259D5B4: C00B2068  lfs f0, 0x2068(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D5B8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D5BC: C14B2838  lfs f10, 0x2838(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10296 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259D5C0: ECC70032  fmuls f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D5C4: 419A003C  beq cr6, 0x8259d600
	if ctx.cr[6].eq {
	pc = 0x8259D600; continue 'dispatch;
	}
	// 8259D5C8: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8259D5CC: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 8259D5D0: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D5D4: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259D5D8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259D5DC: F921FFE0  std r9, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[9].u64 ) };
	// 8259D5E0: C801FFE0  lfd f0, -0x20(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D5E4: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259D5E8: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259D5EC: EC005028  fsubs f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[10].f64) as f32) as f64);
	// 8259D5F0: EC000272  fmuls f0, f0, f9
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259D5F4: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D5F8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259D5FC: 409AFFD4  bne cr6, 0x8259d5d0
	if !ctx.cr[6].eq {
	pc = 0x8259D5D0; continue 'dispatch;
	}
	// 8259D600: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D604: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8259D608: C10BBFFC  lfs f8, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259D60C: 7FE9FB78  mr r9, r31
	ctx.r[9].u64 = ctx.r[31].u64;
	// 8259D610: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259D614: 419A0060  beq cr6, 0x8259d674
	if ctx.cr[6].eq {
	pc = 0x8259D674; continue 'dispatch;
	}
	// 8259D618: ED67602A  fadds f11, f7, f12
	ctx.f[11].f64 = ((ctx.f[7].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259D61C: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 8259D620: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8259D624: 7FC930AE  lbzx r30, r9, r6
	ctx.r[30].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 8259D628: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D62C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259D630: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259D634: FBC1FFE0  std r30, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[30].u64 ) };
	// 8259D638: C801FFE0  lfd f0, -0x20(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D63C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259D640: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259D644: EC005028  fsubs f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[10].f64) as f32) as f64);
	// 8259D648: EC000272  fmuls f0, f0, f9
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259D64C: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D650: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259D654: EDA0682A  fadds f13, f0, f13
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8259D658: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D65C: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259D660: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259D664: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D668: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D66C: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 8259D670: 4198FFB4  blt cr6, 0x8259d624
	if ctx.cr[6].lt {
	pc = 0x8259D624; continue 'dispatch;
	}
	// 8259D674: 38A5FFFF  addi r5, r5, -1
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	// 8259D678: ED86602A  fadds f12, f6, f12
	ctx.f[12].f64 = ((ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259D67C: 7CC64214  add r6, r6, r8
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 8259D680: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 8259D684: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 8259D688: 409AFF84  bne cr6, 0x8259d60c
	if !ctx.cr[6].eq {
	pc = 0x8259D60C; continue 'dispatch;
	}
	// 8259D68C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D690: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D694: 7D2B3050  subf r9, r11, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259D698: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D69C: 0CCA0000  twi 6, r10, 0
	// 8259D6A0: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259D6A4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259D6A8: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259D6AC: 41980008  blt cr6, 0x8259d6b4
	if ctx.cr[6].lt {
	pc = 0x8259D6B4; continue 'dispatch;
	}
	// 8259D6B0: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259D6B4: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D6B8: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D6BC: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259D6C0: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259D6C4: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259D6C8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259D6CC: 40980008  bge cr6, 0x8259d6d4
	if !ctx.cr[6].lt {
	pc = 0x8259D6D4; continue 'dispatch;
	}
	// 8259D6D0: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259D6D4: D1830024  stfs f12, 0x24(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259D6D8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259D6DC: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259D6E0: 419A0064  beq cr6, 0x8259d744
	if ctx.cr[6].eq {
	pc = 0x8259D744; continue 'dispatch;
	}
	// 8259D6E4: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 8259D6E8: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8259D6EC: 392000FF  li r9, 0xff
	ctx.r[9].s64 = 255;
	// 8259D6F0: C00A6BA0  lfs f0, 0x6ba0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(27552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D6F4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D6F8: 3941FFE0  addi r10, r1, -0x20
	ctx.r[10].s64 = ctx.r[1].s64 + -32;
	// 8259D6FC: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D700: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259D704: 7DA057AE  stfiwx f13, 0, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259D708: 8141FFE0  lwz r10, -0x20(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) } as u64;
	// 8259D70C: 214A0080  subfic r10, r10, 0x80
	ctx.xer.ca = ctx.r[10].u32 <= 128 as u32;
	ctx.r[10].s64 = (128 as i64) - ctx.r[10].s64;
	// 8259D710: 2F0A00FF  cmpwi cr6, r10, 0xff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 255, &mut ctx.xer);
	// 8259D714: 4198000C  blt cr6, 0x8259d720
	if ctx.cr[6].lt {
	pc = 0x8259D720; continue 'dispatch;
	}
	// 8259D718: 992B0000  stb r9, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 8259D71C: 48000018  b 0x8259d734
	pc = 0x8259D734; continue 'dispatch;
	// 8259D720: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8259D724: 4199000C  bgt cr6, 0x8259d730
	if ctx.cr[6].gt {
	pc = 0x8259D730; continue 'dispatch;
	}
	// 8259D728: 9BEB0000  stb r31, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[31].u8 ) };
	// 8259D72C: 48000008  b 0x8259d734
	pc = 0x8259D734; continue 'dispatch;
	// 8259D730: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8259D734: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259D738: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259D73C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8259D740: 409AFFB4  bne cr6, 0x8259d6f4
	if !ctx.cr[6].eq {
	pc = 0x8259D6F4; continue 'dispatch;
	}
	// 8259D744: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D748: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259D74C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D750(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259D750 size=440
    let mut pc: u32 = 0x8259D750;
    'dispatch: loop {
        match pc {
            0x8259D750 => {
    //   block [0x8259D750..0x8259D908)
	// 8259D750: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259D754: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D758: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D75C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259D760: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259D764: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D768: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D76C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D770: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259D774: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D778: 7D0A4050  subf r8, r10, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259D77C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D780: 7D4551D6  mullw r10, r5, r10
	ctx.r[10].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259D784: 7D290194  addze r9, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[9].s64 = tmp.s64;
	// 8259D788: 7D4A3214  add r10, r10, r6
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 8259D78C: 7CEB3A14  add r7, r11, r7
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 8259D790: 7F084800  cmpw cr6, r8, r9
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[9].s32, &mut ctx.xer);
	// 8259D794: 41980008  blt cr6, 0x8259d79c
	if ctx.cr[6].lt {
	pc = 0x8259D79C; continue 'dispatch;
	}
	// 8259D798: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259D79C: 7D2607B4  extsw r6, r9
	ctx.r[6].s64 = ctx.r[9].s32 as i64;
	// 8259D7A0: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D7A4: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259D7A8: 3928007F  addi r9, r8, 0x7f
	ctx.r[9].s64 = ctx.r[8].s64 + 127;
	// 8259D7AC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8259D7B0: 5529C9FE  srwi r9, r9, 7
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(7);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259D7B4: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259D7B8: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259D7BC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259D7C0: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D7C4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259D7C8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259D7CC: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259D7D0: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D7D4: ECEB0372  fmuls f7, f11, f13
	ctx.f[7].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259D7D8: 419A0018  beq cr6, 0x8259d7f0
	if ctx.cr[6].eq {
	pc = 0x8259D7F0; continue 'dispatch;
	}
	// 8259D7DC: 55663830  slwi r6, r11, 7
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259D7E0: 7C06522C  dcbt r6, r10
	// 8259D7E4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8259D7E8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259D7EC: 4198FFF0  blt cr6, 0x8259d7dc
	if ctx.cr[6].lt {
	pc = 0x8259D7DC; continue 'dispatch;
	}
	// 8259D7F0: 89630034  lbz r11, 0x34(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 8259D7F4: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8259D7F8: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D7FC: C14B2838  lfs f10, 0x2838(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(10296 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259D800: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D804: C12B2384  lfs f9, 0x2384(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(9092 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259D808: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259D80C: C10BBFFC  lfs f8, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259D810: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D814: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259D818: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259D81C: EDAD5028  fsubs f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[10].f64) as f32) as f64);
	// 8259D820: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259D824: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259D828: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D82C: C1830034  lfs f12, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259D830: ECCB002A  fadds f6, f11, f0
	ctx.f[6].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D834: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259D838: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259D83C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259D840: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 8259D844: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259D848: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259D84C: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259D850: EDAD5028  fsubs f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[10].f64) as f32) as f64);
	// 8259D854: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259D858: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259D85C: ED8D602A  fadds f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259D860: EDA60372  fmuls f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259D864: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D868: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259D86C: ED8C0232  fmuls f12, f12, f8
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259D870: D1870000  stfs f12, 0(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259D874: D1A70004  stfs f13, 4(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259D878: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 8259D87C: 409AFFAC  bne cr6, 0x8259d828
	if !ctx.cr[6].eq {
	pc = 0x8259D828; continue 'dispatch;
	}
	// 8259D880: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D884: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D888: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 8259D88C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D890: 0CC90000  twi 6, r9, 0
	// 8259D894: 7D4A4B96  divwu r10, r10, r9
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[9].u32;
	// 8259D898: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259D89C: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259D8A0: 41980008  blt cr6, 0x8259d8a8
	if ctx.cr[6].lt {
	pc = 0x8259D8A8; continue 'dispatch;
	}
	// 8259D8A4: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259D8A8: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D8AC: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D8B0: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259D8B4: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259D8B8: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259D8BC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259D8C0: 40980008  bge cr6, 0x8259d8c8
	if !ctx.cr[6].lt {
	pc = 0x8259D8C8; continue 'dispatch;
	}
	// 8259D8C4: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259D8C8: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259D8CC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8259D8D0: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259D8D4: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 8259D8D8: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D8DC: C00B6BA0  lfs f0, 0x6ba0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(27552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D8E0: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259D8E4: FC00001E  fctiwz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 8259D8E8: 7C0057AE  stfiwx f0, 0, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259D8EC: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8259D8F0: 216B0080  subfic r11, r11, 0x80
	ctx.xer.ca = ctx.r[11].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[11].s64;
	// 8259D8F4: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 8259D8F8: 41980010  blt cr6, 0x8259d908
	if ctx.cr[6].lt {
		sub_8259D908(ctx, base);
		return;
	}
	// 8259D8FC: 396000FF  li r11, 0xff
	ctx.r[11].s64 = 255;
	// 8259D900: 99630034  stb r11, 0x34(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u8 ) };
	// 8259D904: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D908(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259D908 size=20
    let mut pc: u32 = 0x8259D908;
    'dispatch: loop {
        match pc {
            0x8259D908 => {
    //   block [0x8259D908..0x8259D91C)
	// 8259D908: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259D90C: 41990008  bgt cr6, 0x8259d914
	if ctx.cr[6].gt {
	pc = 0x8259D914; continue 'dispatch;
	}
	// 8259D910: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8259D914: 99630034  stb r11, 0x34(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u8 ) };
	// 8259D918: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259D920(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259D920 size=592
    let mut pc: u32 = 0x8259D920;
    'dispatch: loop {
        match pc {
            0x8259D920 => {
    //   block [0x8259D920..0x8259DB70)
	// 8259D920: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259D924: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259D928: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259D92C: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259D930: 38A30034  addi r5, r3, 0x34
	ctx.r[5].s64 = ctx.r[3].s64 + 52;
	// 8259D934: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259D938: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259D93C: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259D940: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259D944: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259D948: 7D3F0E70  srawi r31, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[31].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259D94C: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D950: 7CEA3850  subf r7, r10, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259D954: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259D958: 7D2451D6  mullw r9, r4, r10
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259D95C: 7D5F0194  addze r10, r31
	tmp.s64 = ctx.r[31].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[31].u32);
	ctx.r[10].s64 = tmp.s64;
	// 8259D960: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 8259D964: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259D968: 7F075000  cmpw cr6, r7, r10
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8259D96C: 41980008  blt cr6, 0x8259d974
	if ctx.cr[6].lt {
	pc = 0x8259D974; continue 'dispatch;
	}
	// 8259D970: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8259D974: 7D4607B4  extsw r6, r10
	ctx.r[6].s64 = ctx.r[10].s32 as i64;
	// 8259D978: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D97C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259D980: 54EA083C  slwi r10, r7, 1
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259D984: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8259D988: 394A007F  addi r10, r10, 0x7f
	ctx.r[10].s64 = ctx.r[10].s64 + 127;
	// 8259D98C: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 8259D990: F8C1FFE0  std r6, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[6].u64 ) };
	// 8259D994: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259D998: 554AC9FE  srwi r10, r10, 7
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(7);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259D99C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259D9A0: C981FFE0  lfd f12, -0x20(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D9A4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259D9A8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259D9AC: ECED6024  fdivs f7, f13, f12
	ctx.f[7].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259D9B0: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259D9B4: ECC70372  fmuls f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259D9B8: 419A0018  beq cr6, 0x8259d9d0
	if ctx.cr[6].eq {
	pc = 0x8259D9D0; continue 'dispatch;
	}
	// 8259D9BC: 55663830  slwi r6, r11, 7
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259D9C0: 7C064A2C  dcbt r6, r9
	// 8259D9C4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8259D9C8: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259D9CC: 4198FFF0  blt cr6, 0x8259d9bc
	if ctx.cr[6].lt {
	pc = 0x8259D9BC; continue 'dispatch;
	}
	// 8259D9D0: 3C80820D  lis r4, -0x7df3
	ctx.r[4].s64 = -2113077248;
	// 8259D9D4: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259D9D8: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259D9DC: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8259D9E0: C1442384  lfs f10, 0x2384(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(9092 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259D9E4: C1662838  lfs f11, 0x2838(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(10296 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259D9E8: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259D9EC: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259D9F0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259D9F4: F8C1FFE0  std r6, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[6].u64 ) };
	// 8259D9F8: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259D9FC: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259DA00: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259DA04: EDAD5828  fsubs f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[11].f64) as f32) as f64);
	// 8259DA08: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DA0C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DA10: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259DA14: 409AFFD4  bne cr6, 0x8259d9e8
	if !ctx.cr[6].eq {
	pc = 0x8259D9E8; continue 'dispatch;
	}
	// 8259DA18: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259DA1C: C12BBFFC  lfs f9, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259DA20: 89690001  lbz r11, 1(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259DA24: C1050004  lfs f8, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DA28: ED87002A  fadds f12, f7, f0
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259DA2C: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259DA30: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259DA34: F961FFE0  std r11, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[11].u64 ) };
	// 8259DA38: C9A1FFE0  lfd f13, -0x20(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259DA3C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259DA40: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259DA44: EDAD5828  fsubs f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[11].f64) as f32) as f64);
	// 8259DA48: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DA4C: D1A50004  stfs f13, 4(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259DA50: ED0D402A  fadds f8, f13, f8
	ctx.f[8].f64 = ((ctx.f[13].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DA54: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259DA58: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DA5C: ED080272  fmuls f8, f8, f9
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DA60: D1080400  stfs f8, 0x400(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259DA64: D1A80404  stfs f13, 0x404(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259DA68: 89690000  lbz r11, 0(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DA6C: C1050000  lfs f8, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DA70: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 8259DA74: F961FFE8  std r11, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[11].u64 ) };
	// 8259DA78: C9A1FFE8  lfd f13, -0x18(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259DA7C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259DA80: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259DA84: EDAD5828  fsubs f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[11].f64) as f32) as f64);
	// 8259DA88: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DA8C: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DA90: ED0D402A  fadds f8, f13, f8
	ctx.f[8].f64 = ((ctx.f[13].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DA94: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259DA98: ED880032  fmuls f12, f8, f0
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DA9C: EC06002A  fadds f0, f6, f0
	ctx.f[0].f64 = ((ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259DAA0: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DAA4: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DAA8: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259DAAC: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 8259DAB0: 409AFF70  bne cr6, 0x8259da20
	if !ctx.cr[6].eq {
	pc = 0x8259DA20; continue 'dispatch;
	}
	// 8259DAB4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DAB8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259DABC: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259DAC0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259DAC4: 0CCA0000  twi 6, r10, 0
	// 8259DAC8: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259DACC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259DAD0: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259DAD4: 41980008  blt cr6, 0x8259dadc
	if ctx.cr[6].lt {
	pc = 0x8259DADC; continue 'dispatch;
	}
	// 8259DAD8: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259DADC: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259DAE0: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259DAE4: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259DAE8: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259DAEC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259DAF0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259DAF4: 41980008  blt cr6, 0x8259dafc
	if ctx.cr[6].lt {
	pc = 0x8259DAFC; continue 'dispatch;
	}
	// 8259DAF8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8259DAFC: 9143001C  stw r10, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 8259DB00: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 8259DB04: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259DB08: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 8259DB0C: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 8259DB10: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 8259DB14: C00A6BA0  lfs f0, 0x6ba0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(27552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259DB18: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DB1C: 3941FFE0  addi r10, r1, -0x20
	ctx.r[10].s64 = ctx.r[1].s64 + -32;
	// 8259DB20: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DB24: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259DB28: 7DA057AE  stfiwx f13, 0, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259DB2C: 8141FFE0  lwz r10, -0x20(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) } as u64;
	// 8259DB30: 214A0080  subfic r10, r10, 0x80
	ctx.xer.ca = ctx.r[10].u32 <= 128 as u32;
	ctx.r[10].s64 = (128 as i64) - ctx.r[10].s64;
	// 8259DB34: 2F0A00FF  cmpwi cr6, r10, 0xff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 255, &mut ctx.xer);
	// 8259DB38: 4198000C  blt cr6, 0x8259db44
	if ctx.cr[6].lt {
	pc = 0x8259DB44; continue 'dispatch;
	}
	// 8259DB3C: 990B0000  stb r8, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8259DB40: 48000018  b 0x8259db58
	pc = 0x8259DB58; continue 'dispatch;
	// 8259DB44: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8259DB48: 4199000C  bgt cr6, 0x8259db54
	if ctx.cr[6].gt {
	pc = 0x8259DB54; continue 'dispatch;
	}
	// 8259DB4C: 9BEB0000  stb r31, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[31].u8 ) };
	// 8259DB50: 48000008  b 0x8259db58
	pc = 0x8259DB58; continue 'dispatch;
	// 8259DB54: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8259DB58: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259DB5C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259DB60: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259DB64: 409AFFB4  bne cr6, 0x8259db18
	if !ctx.cr[6].eq {
	pc = 0x8259DB18; continue 'dispatch;
	}
	// 8259DB68: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259DB6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259DB70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259DB70 size=704
    let mut pc: u32 = 0x8259DB70;
    'dispatch: loop {
        match pc {
            0x8259DB70 => {
    //   block [0x8259DB70..0x8259DE30)
	// 8259DB70: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259DB74: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259DB78: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259DB7C: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259DB80: 39230034  addi r9, r3, 0x34
	ctx.r[9].s64 = ctx.r[3].s64 + 52;
	// 8259DB84: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259DB88: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259DB8C: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259DB90: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259DB94: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259DB98: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259DB9C: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DBA0: 7CEA3850  subf r7, r10, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259DBA4: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259DBA8: 7D4451D6  mullw r10, r4, r10
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259DBAC: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259DBB0: 7D4A2A14  add r10, r10, r5
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[5].u64;
	// 8259DBB4: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259DBB8: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259DBBC: 41980008  blt cr6, 0x8259dbc4
	if ctx.cr[6].lt {
	pc = 0x8259DBC4; continue 'dispatch;
	}
	// 8259DBC0: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259DBC4: 7D0507B4  extsw r5, r8
	ctx.r[5].s64 = ctx.r[8].s32 as i64;
	// 8259DBC8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DBCC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259DBD0: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259DBD4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8259DBD8: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259DBDC: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 8259DBE0: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 8259DBE4: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259DBE8: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259DBEC: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259DBF0: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259DBF4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259DBF8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259DBFC: ECED6024  fdivs f7, f13, f12
	ctx.f[7].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259DC00: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DC04: ECC70372  fmuls f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259DC08: 419A0018  beq cr6, 0x8259dc20
	if ctx.cr[6].eq {
	pc = 0x8259DC20; continue 'dispatch;
	}
	// 8259DC0C: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259DC10: 7C05522C  dcbt r5, r10
	// 8259DC14: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259DC18: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259DC1C: 4198FFF0  blt cr6, 0x8259dc0c
	if ctx.cr[6].lt {
	pc = 0x8259DC0C; continue 'dispatch;
	}
	// 8259DC20: 3C80820D  lis r4, -0x7df3
	ctx.r[4].s64 = -2113077248;
	// 8259DC24: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259DC28: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259DC2C: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 8259DC30: C1642384  lfs f11, 0x2384(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(9092 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259DC34: C1852838  lfs f12, 0x2838(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(10296 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259DC38: 88A80000  lbz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DC3C: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259DC40: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259DC44: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 8259DC48: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259DC4C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259DC50: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259DC54: EDAD6028  fsubs f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DC58: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DC5C: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DC60: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259DC64: 409AFFD4  bne cr6, 0x8259dc38
	if !ctx.cr[6].eq {
	pc = 0x8259DC38; continue 'dispatch;
	}
	// 8259DC68: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259DC6C: C148BFFC  lfs f10, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259DC70: 890A0003  lbz r8, 3(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(3 as u32) ) } as u64;
	// 8259DC74: C109000C  lfs f8, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DC78: EDA7002A  fadds f13, f7, f0
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259DC7C: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259DC80: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259DC84: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 8259DC88: C921FFD0  lfd f9, -0x30(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259DC8C: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DC90: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DC94: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DC98: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DC9C: D129000C  stfs f9, 0xc(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259DCA0: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DCA4: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DCA8: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DCAC: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DCB0: D10B0C00  stfs f8, 0xc00(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259DCB4: D12B0C04  stfs f9, 0xc04(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259DCB8: 890A0002  lbz r8, 2(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259DCBC: C1090008  lfs f8, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DCC0: F901FFD8  std r8, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[8].u64 ) };
	// 8259DCC4: C921FFD8  lfd f9, -0x28(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259DCC8: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DCCC: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DCD0: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DCD4: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DCD8: D1290008  stfs f9, 8(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259DCDC: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DCE0: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DCE4: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DCE8: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DCEC: D10B0800  stfs f8, 0x800(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259DCF0: D12B0804  stfs f9, 0x804(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259DCF4: 890A0001  lbz r8, 1(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259DCF8: C1090004  lfs f8, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DCFC: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259DD00: C921FFE0  lfd f9, -0x20(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259DD04: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DD08: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DD0C: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DD10: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DD14: D1290004  stfs f9, 4(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259DD18: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DD1C: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DD20: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DD24: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DD28: D10B0400  stfs f8, 0x400(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259DD2C: D12B0404  stfs f9, 0x404(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259DD30: 890A0000  lbz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DD34: C1090000  lfs f8, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DD38: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259DD3C: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259DD40: C921FFE8  lfd f9, -0x18(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259DD44: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DD48: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DD4C: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DD50: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DD54: D1290000  stfs f9, 0(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DD58: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DD5C: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DD60: ED280032  fmuls f9, f8, f0
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DD64: EC06002A  fadds f0, f6, f0
	ctx.f[0].f64 = ((ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259DD68: ED2902B2  fmuls f9, f9, f10
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DD6C: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DD70: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259DD74: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259DD78: 409AFEF8  bne cr6, 0x8259dc70
	if !ctx.cr[6].eq {
	pc = 0x8259DC70; continue 'dispatch;
	}
	// 8259DD7C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DD80: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259DD84: 7D085050  subf r8, r8, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259DD88: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259DD8C: 0CC70000  twi 6, r7, 0
	// 8259DD90: 7D083B96  divwu r8, r8, r7
	ctx.r[8].u32 = ctx.r[8].u32 / ctx.r[7].u32;
	// 8259DD94: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259DD98: 41980008  blt cr6, 0x8259dda0
	if ctx.cr[6].lt {
	pc = 0x8259DDA0; continue 'dispatch;
	}
	// 8259DD9C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259DDA0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259DDA4: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259DDA8: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259DDAC: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259DDB0: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259DDB4: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259DDB8: 41980008  blt cr6, 0x8259ddc0
	if ctx.cr[6].lt {
	pc = 0x8259DDC0; continue 'dispatch;
	}
	// 8259DDBC: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259DDC0: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259DDC4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8259DDC8: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259DDCC: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 8259DDD0: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 8259DDD4: C00B6BA0  lfs f0, 0x6ba0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(27552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259DDD8: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DDDC: 3961FFD0  addi r11, r1, -0x30
	ctx.r[11].s64 = ctx.r[1].s64 + -48;
	// 8259DDE0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DDE4: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259DDE8: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259DDEC: 8161FFD0  lwz r11, -0x30(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8259DDF0: 216B0080  subfic r11, r11, 0x80
	ctx.xer.ca = ctx.r[11].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[11].s64;
	// 8259DDF4: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 8259DDF8: 4198000C  blt cr6, 0x8259de04
	if ctx.cr[6].lt {
	pc = 0x8259DE04; continue 'dispatch;
	}
	// 8259DDFC: 99090000  stb r8, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8259DE00: 48000018  b 0x8259de18
	pc = 0x8259DE18; continue 'dispatch;
	// 8259DE04: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259DE08: 4199000C  bgt cr6, 0x8259de14
	if ctx.cr[6].gt {
	pc = 0x8259DE14; continue 'dispatch;
	}
	// 8259DE0C: 9BE90000  stb r31, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[31].u8 ) };
	// 8259DE10: 48000008  b 0x8259de18
	pc = 0x8259DE18; continue 'dispatch;
	// 8259DE14: 99690000  stb r11, 0(r9)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8259DE18: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259DE1C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259DE20: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259DE24: 409AFFB4  bne cr6, 0x8259ddd8
	if !ctx.cr[6].eq {
	pc = 0x8259DDD8; continue 'dispatch;
	}
	// 8259DE28: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259DE2C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259DE30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259DE30 size=832
    let mut pc: u32 = 0x8259DE30;
    'dispatch: loop {
        match pc {
            0x8259DE30 => {
    //   block [0x8259DE30..0x8259E170)
	// 8259DE30: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259DE34: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259DE38: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259DE3C: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259DE40: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 8259DE44: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259DE48: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259DE4C: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259DE50: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259DE54: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259DE58: 7D080E70  srawi r8, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 8259DE5C: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DE60: 7CE93850  subf r7, r9, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 8259DE64: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259DE68: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 8259DE6C: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8259DE70: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8259DE74: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259DE78: 7F074000  cmpw cr6, r7, r8
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8259DE7C: 41980008  blt cr6, 0x8259de84
	if ctx.cr[6].lt {
	pc = 0x8259DE84; continue 'dispatch;
	}
	// 8259DE80: 7D074378  mr r7, r8
	ctx.r[7].u64 = ctx.r[8].u64;
	// 8259DE84: 7D0607B4  extsw r6, r8
	ctx.r[6].s64 = ctx.r[8].s32 as i64;
	// 8259DE88: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DE8C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259DE90: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259DE94: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8259DE98: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 8259DE9C: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 8259DEA0: 54E6083C  slwi r6, r7, 1
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259DEA4: 7CC73214  add r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259DEA8: 54C6083C  slwi r6, r6, 1
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259DEAC: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259DEB0: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259DEB4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259DEB8: C981FFC0  lfd f12, -0x40(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259DEBC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259DEC0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259DEC4: ECED6024  fdivs f7, f13, f12
	ctx.f[7].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259DEC8: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259DECC: ECC70372  fmuls f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259DED0: 419A0018  beq cr6, 0x8259dee8
	if ctx.cr[6].eq {
	pc = 0x8259DEE8; continue 'dispatch;
	}
	// 8259DED4: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259DED8: 7C054A2C  dcbt r5, r9
	// 8259DEDC: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259DEE0: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259DEE4: 4198FFF0  blt cr6, 0x8259ded4
	if ctx.cr[6].lt {
	pc = 0x8259DED4; continue 'dispatch;
	}
	// 8259DEE8: 3C80820D  lis r4, -0x7df3
	ctx.r[4].s64 = -2113077248;
	// 8259DEEC: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259DEF0: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 8259DEF4: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 8259DEF8: C1642384  lfs f11, 0x2384(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(9092 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259DEFC: C1852838  lfs f12, 0x2838(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(10296 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259DF00: 88A80000  lbz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259DF04: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259DF08: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259DF0C: F8A1FFC0  std r5, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[5].u64 ) };
	// 8259DF10: C9A1FFC0  lfd f13, -0x40(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259DF14: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259DF18: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259DF1C: EDAD6028  fsubs f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DF20: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DF24: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259DF28: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8259DF2C: 409AFFD4  bne cr6, 0x8259df00
	if !ctx.cr[6].eq {
	pc = 0x8259DF00; continue 'dispatch;
	}
	// 8259DF30: 3D00820D  lis r8, -0x7df3
	ctx.r[8].s64 = -2113077248;
	// 8259DF34: C148BFFC  lfs f10, -0x4004(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259DF38: 89090005  lbz r8, 5(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(5 as u32) ) } as u64;
	// 8259DF3C: C10A0014  lfs f8, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DF40: EDA7002A  fadds f13, f7, f0
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259DF44: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 8259DF48: F901FFC0  std r8, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[8].u64 ) };
	// 8259DF4C: C921FFC0  lfd f9, -0x40(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259DF50: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DF54: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DF58: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DF5C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DF60: D12A0014  stfs f9, 0x14(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259DF64: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DF68: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DF6C: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DF70: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DF74: D10B1400  stfs f8, 0x1400(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259DF78: D12B1404  stfs f9, 0x1404(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 8259DF7C: 89090004  lbz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259DF80: C10A0010  lfs f8, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DF84: F901FFC8  std r8, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[8].u64 ) };
	// 8259DF88: C921FFC8  lfd f9, -0x38(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 8259DF8C: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DF90: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DF94: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DF98: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DF9C: D12A0010  stfs f9, 0x10(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8259DFA0: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DFA4: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DFA8: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DFAC: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DFB0: D10B1000  stfs f8, 0x1000(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259DFB4: D12B1004  stfs f9, 0x1004(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 8259DFB8: 89090003  lbz r8, 3(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(3 as u32) ) } as u64;
	// 8259DFBC: C10A000C  lfs f8, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DFC0: F901FFD0  std r8, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[8].u64 ) };
	// 8259DFC4: C921FFD0  lfd f9, -0x30(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259DFC8: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259DFCC: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259DFD0: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259DFD4: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259DFD8: D12A000C  stfs f9, 0xc(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259DFDC: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259DFE0: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259DFE4: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259DFE8: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259DFEC: D10B0C00  stfs f8, 0xc00(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259DFF0: D12B0C04  stfs f9, 0xc04(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259DFF4: 89090002  lbz r8, 2(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259DFF8: C10A0008  lfs f8, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259DFFC: F901FFD8  std r8, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[8].u64 ) };
	// 8259E000: C921FFD8  lfd f9, -0x28(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259E004: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259E008: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259E00C: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259E010: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E014: D12A0008  stfs f9, 8(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259E018: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259E01C: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259E020: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E024: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E028: D10B0800  stfs f8, 0x800(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259E02C: D12B0804  stfs f9, 0x804(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259E030: 89090001  lbz r8, 1(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(1 as u32) ) } as u64;
	// 8259E034: C10A0004  lfs f8, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259E038: F901FFE0  std r8, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[8].u64 ) };
	// 8259E03C: C921FFE0  lfd f9, -0x20(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259E040: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259E044: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259E048: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259E04C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E050: D12A0004  stfs f9, 4(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E054: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259E058: ED2D0272  fmuls f9, f13, f9
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259E05C: ED080032  fmuls f8, f8, f0
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E060: ED0802B2  fmuls f8, f8, f10
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E064: D10B0400  stfs f8, 0x400(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259E068: D12B0404  stfs f9, 0x404(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259E06C: 89090000  lbz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E070: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259E074: 39290006  addi r9, r9, 6
	ctx.r[9].s64 = ctx.r[9].s64 + 6;
	// 8259E078: F901FFE8  std r8, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[8].u64 ) };
	// 8259E07C: C921FFE8  lfd f9, -0x18(r1)
	ctx.f[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259E080: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8259E084: FD204E9C  fcfid f9, f9
	ctx.f[9].f64 = (ctx.f[9].s64 as f64);
	// 8259E088: FD204818  frsp f9, f9
	ctx.f[9].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8259E08C: ED296028  fsubs f9, f9, f12
	ctx.f[9].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259E090: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E094: D12A0000  stfs f9, 0(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E098: ED09402A  fadds f8, f9, f8
	ctx.f[8].f64 = ((ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64;
	// 8259E09C: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259E0A0: ED280032  fmuls f9, f8, f0
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E0A4: EC06002A  fadds f0, f6, f0
	ctx.f[0].f64 = ((ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E0A8: ED2902B2  fmuls f9, f9, f10
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E0AC: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E0B0: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E0B4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259E0B8: 409AFE80  bne cr6, 0x8259df38
	if !ctx.cr[6].eq {
	pc = 0x8259DF38; continue 'dispatch;
	}
	// 8259E0BC: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E0C0: 88E3000D  lbz r7, 0xd(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E0C4: 7D084850  subf r8, r8, r9
	ctx.r[8].s64 = ctx.r[9].s64 - ctx.r[8].s64;
	// 8259E0C8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E0CC: 0CC70000  twi 6, r7, 0
	// 8259E0D0: 7D083B96  divwu r8, r8, r7
	ctx.r[8].u32 = ctx.r[8].u32 / ctx.r[7].u32;
	// 8259E0D4: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259E0D8: 41980008  blt cr6, 0x8259e0e0
	if ctx.cr[6].lt {
	pc = 0x8259E0E0; continue 'dispatch;
	}
	// 8259E0DC: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259E0E0: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E0E4: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E0E8: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259E0EC: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259E0F0: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259E0F4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259E0F8: 41980008  blt cr6, 0x8259e100
	if ctx.cr[6].lt {
	pc = 0x8259E100; continue 'dispatch;
	}
	// 8259E0FC: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 8259E100: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259E104: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 8259E108: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259E10C: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8259E110: 390000FF  li r8, 0xff
	ctx.r[8].s64 = 255;
	// 8259E114: C00B6BA0  lfs f0, 0x6ba0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(27552 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E118: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E11C: 3961FFC0  addi r11, r1, -0x40
	ctx.r[11].s64 = ctx.r[1].s64 + -64;
	// 8259E120: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E124: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259E128: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259E12C: 8161FFC0  lwz r11, -0x40(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) } as u64;
	// 8259E130: 216B0080  subfic r11, r11, 0x80
	ctx.xer.ca = ctx.r[11].u32 <= 128 as u32;
	ctx.r[11].s64 = (128 as i64) - ctx.r[11].s64;
	// 8259E134: 2F0B00FF  cmpwi cr6, r11, 0xff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 255, &mut ctx.xer);
	// 8259E138: 4198000C  blt cr6, 0x8259e144
	if ctx.cr[6].lt {
	pc = 0x8259E144; continue 'dispatch;
	}
	// 8259E13C: 990A0000  stb r8, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8259E140: 48000018  b 0x8259e158
	pc = 0x8259E158; continue 'dispatch;
	// 8259E144: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259E148: 4199000C  bgt cr6, 0x8259e154
	if ctx.cr[6].gt {
	pc = 0x8259E154; continue 'dispatch;
	}
	// 8259E14C: 9BEA0000  stb r31, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[31].u8 ) };
	// 8259E150: 48000008  b 0x8259e158
	pc = 0x8259E158; continue 'dispatch;
	// 8259E154: 996A0000  stb r11, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 8259E158: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259E15C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259E160: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259E164: 409AFFB4  bne cr6, 0x8259e118
	if !ctx.cr[6].eq {
	pc = 0x8259E118; continue 'dispatch;
	}
	// 8259E168: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259E16C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E170(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259E170 size=584
    let mut pc: u32 = 0x8259E170;
    'dispatch: loop {
        match pc {
            0x8259E170 => {
    //   block [0x8259E170..0x8259E3B8)
	// 8259E170: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259E174: 4BF96F45  bl 0x825350b8
	ctx.lr = 0x8259E178;
	sub_82535080(ctx, base);
	// 8259E178: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259E17C: C1830024  lfs f12, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259E180: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E184: 3BA30034  addi r29, r3, 0x34
	ctx.r[29].s64 = ctx.r[3].s64 + 52;
	// 8259E188: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259E18C: 5567103A  slwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259E190: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E194: 7FEB4850  subf r31, r11, r9
	ctx.r[31].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259E198: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E19C: 7D2551D6  mullw r9, r5, r10
	ctx.r[9].s64 = (ctx.r[5].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259E1A0: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E1A4: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E1A8: 7FEB0E70  srawi r11, r31, 1
	ctx.xer.ca = (ctx.r[31].s32 < 0) && ((ctx.r[31].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[31].s32 >> 1) as i64;
	// 8259E1AC: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259E1B0: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259E1B4: 7D6B0194  addze r11, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[11].s64 = tmp.s64;
	// 8259E1B8: 7C873214  add r4, r7, r6
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8259E1BC: 7CC94214  add r6, r9, r8
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 8259E1C0: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8259E1C4: 7D5F5378  mr r31, r10
	ctx.r[31].u64 = ctx.r[10].u64;
	// 8259E1C8: 41980008  blt cr6, 0x8259e1d0
	if ctx.cr[6].lt {
	pc = 0x8259E1D0; continue 'dispatch;
	}
	// 8259E1CC: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 8259E1D0: 7D6B07B4  extsw r11, r11
	ctx.r[11].s64 = ctx.r[11].s32 as i64;
	// 8259E1D4: C0030028  lfs f0, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E1D8: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 8259E1DC: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259E1E0: F961FFD0  std r11, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[11].u64 ) };
	// 8259E1E4: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E1E8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E1EC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259E1F0: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E1F4: ED006824  fdivs f8, f0, f13
	ctx.f[8].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 8259E1F8: C00B2068  lfs f0, 0x2068(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E1FC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259E200: C14B206C  lfs f10, 0x206c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8300 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259E204: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E208: 419A0044  beq cr6, 0x8259e24c
	if ctx.cr[6].eq {
	pc = 0x8259E24C; continue 'dispatch;
	}
	// 8259E20C: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 8259E210: 7CAA2B78  mr r10, r5
	ctx.r[10].u64 = ctx.r[5].u64;
	// 8259E214: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E218: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259E21C: 5528C63E  rlwinm r8, r9, 0x18, 0x18, 0x1f
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 8259E220: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259E224: 5128442E  rlwimi r8, r9, 8, 0x10, 0x17
	ctx.r[8].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[8].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E228: 7D090734  extsh r9, r8
	ctx.r[9].s64 = ctx.r[8].s16 as i64;
	// 8259E22C: F921FFD0  std r9, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[9].u64 ) };
	// 8259E230: C801FFD0  lfd f0, -0x30(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E234: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259E238: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259E23C: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E240: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E244: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259E248: 409AFFCC  bne cr6, 0x8259e214
	if !ctx.cr[6].eq {
	pc = 0x8259E214; continue 'dispatch;
	}
	// 8259E24C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259E250: 54BE083C  slwi r30, r5, 1
	ctx.r[30].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8259E254: C12BBFFC  lfs f9, -0x4004(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E258: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259E25C: 419A0074  beq cr6, 0x8259e2d0
	if ctx.cr[6].eq {
	pc = 0x8259E2D0; continue 'dispatch;
	}
	// 8259E260: ED68602A  fadds f11, f8, f12
	ctx.f[11].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259E264: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 8259E268: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 8259E26C: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 8259E270: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 8259E274: A0E80000  lhz r7, 0(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E278: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E27C: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259E280: 54FCC63E  rlwinm r28, r7, 0x18, 0x18, 0x1f
	ctx.r[28].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259E284: 39080002  addi r8, r8, 2
	ctx.r[8].s64 = ctx.r[8].s64 + 2;
	// 8259E288: 50FC442E  rlwimi r28, r7, 8, 0x10, 0x17
	ctx.r[28].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[28].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E28C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259E290: 7F870734  extsh r7, r28
	ctx.r[7].s64 = ctx.r[28].s16 as i64;
	// 8259E294: F8E1FFD0  std r7, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[7].u64 ) };
	// 8259E298: C801FFD0  lfd f0, -0x30(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E29C: FC00069C  fcfid f0, f0
	ctx.f[0].f64 = (ctx.f[0].s64 as f64);
	// 8259E2A0: FC000018  frsp f0, f0
	ctx.f[0].f64 = (ctx.f[0].f64 as f32) as f64;
	// 8259E2A4: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E2A8: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E2AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259E2B0: EDA0682A  fadds f13, f0, f13
	ctx.f[13].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8259E2B4: EC0B0032  fmuls f0, f11, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E2B8: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259E2BC: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259E2C0: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E2C4: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E2C8: 394A0400  addi r10, r10, 0x400
	ctx.r[10].s64 = ctx.r[10].s64 + 1024;
	// 8259E2CC: 409AFFA8  bne cr6, 0x8259e274
	if !ctx.cr[6].eq {
	pc = 0x8259E274; continue 'dispatch;
	}
	// 8259E2D0: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 8259E2D4: ED87602A  fadds f12, f7, f12
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259E2D8: 7CDE3214  add r6, r30, r6
	ctx.r[6].u64 = ctx.r[30].u64 + ctx.r[6].u64;
	// 8259E2DC: 38840008  addi r4, r4, 8
	ctx.r[4].s64 = ctx.r[4].s64 + 8;
	// 8259E2E0: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8259E2E4: 409AFF74  bne cr6, 0x8259e258
	if !ctx.cr[6].eq {
	pc = 0x8259E258; continue 'dispatch;
	}
	// 8259E2E8: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E2EC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E2F0: 554A083E  rotlwi r10, r10, 1
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259E2F4: 7D2B3050  subf r9, r11, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259E2F8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E2FC: 0CCA0000  twi 6, r10, 0
	// 8259E300: 7D495396  divwu r10, r9, r10
	ctx.r[10].u32 = ctx.r[9].u32 / ctx.r[10].u32;
	// 8259E304: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259E308: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259E30C: 41980008  blt cr6, 0x8259e314
	if ctx.cr[6].lt {
	pc = 0x8259E314; continue 'dispatch;
	}
	// 8259E310: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259E314: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E318: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E31C: 7D4A2050  subf r10, r10, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 8259E320: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259E324: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259E328: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259E32C: 40980008  bge cr6, 0x8259e334
	if !ctx.cr[6].lt {
	pc = 0x8259E334; continue 'dispatch;
	}
	// 8259E330: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259E334: D1830024  stfs f12, 0x24(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259E338: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259E33C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259E340: 419A0074  beq cr6, 0x8259e3b4
	if ctx.cr[6].eq {
	pc = 0x8259E3B4; continue 'dispatch;
	}
	// 8259E344: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8259E348: 3D200000  lis r9, 0
	ctx.r[9].s64 = 0;
	// 8259E34C: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 8259E350: 6129FF7F  ori r9, r9, 0xff7f
	ctx.r[9].u64 = ctx.r[9].u64 | 65407;
	// 8259E354: 39000080  li r8, 0x80
	ctx.r[8].s64 = 128;
	// 8259E358: C00A72B8  lfs f0, 0x72b8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E35C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E360: 3941FFD0  addi r10, r1, -0x30
	ctx.r[10].s64 = ctx.r[1].s64 + -48;
	// 8259E364: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E368: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259E36C: 7DA057AE  stfiwx f13, 0, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259E370: 8141FFD0  lwz r10, -0x30(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8259E374: 2F0A7FFF  cmpwi cr6, r10, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32767, &mut ctx.xer);
	// 8259E378: 4198000C  blt cr6, 0x8259e384
	if ctx.cr[6].lt {
	pc = 0x8259E384; continue 'dispatch;
	}
	// 8259E37C: B12B0000  sth r9, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8259E380: 48000024  b 0x8259e3a4
	pc = 0x8259E3A4; continue 'dispatch;
	// 8259E384: 2F0A8000  cmpwi cr6, r10, -0x8000
	ctx.cr[6].compare_i32(ctx.r[10].s32, -32768, &mut ctx.xer);
	// 8259E388: 4199000C  bgt cr6, 0x8259e394
	if ctx.cr[6].gt {
	pc = 0x8259E394; continue 'dispatch;
	}
	// 8259E38C: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259E390: 48000014  b 0x8259e3a4
	pc = 0x8259E3A4; continue 'dispatch;
	// 8259E394: 554A043E  clrlwi r10, r10, 0x10
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000FFFFu64;
	// 8259E398: 5547C63E  rlwinm r7, r10, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8259E39C: 5147442E  rlwimi r7, r10, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E3A0: B0EB0000  sth r7, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259E3A4: 38A5FFFF  addi r5, r5, -1
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	// 8259E3A8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8259E3AC: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8259E3B0: 409AFFAC  bne cr6, 0x8259e35c
	if !ctx.cr[6].eq {
	pc = 0x8259E35C; continue 'dispatch;
	}
	// 8259E3B4: 4BF96D54  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E3B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259E3B8 size=460
    let mut pc: u32 = 0x8259E3B8;
    'dispatch: loop {
        match pc {
            0x8259E3B8 => {
    //   block [0x8259E3B8..0x8259E584)
	// 8259E3B8: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259E3BC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E3C0: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259E3C4: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E3C8: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E3CC: 88C3000D  lbz r6, 0xd(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E3D0: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259E3D4: 7CEA3850  subf r7, r10, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 8259E3D8: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E3DC: 7D4651D6  mullw r10, r6, r10
	ctx.r[10].s64 = (ctx.r[6].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259E3E0: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E3E4: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259E3E8: 5546083C  slwi r6, r10, 1
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E3EC: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259E3F0: 7D290194  addze r9, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[9].s64 = tmp.s64;
	// 8259E3F4: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8259E3F8: 7D662A14  add r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 8259E3FC: 7F074800  cmpw cr6, r7, r9
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[9].s32, &mut ctx.xer);
	// 8259E400: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 8259E404: 41980008  blt cr6, 0x8259e40c
	if ctx.cr[6].lt {
	pc = 0x8259E40C; continue 'dispatch;
	}
	// 8259E408: 7D2A4B78  mr r10, r9
	ctx.r[10].u64 = ctx.r[9].u64;
	// 8259E40C: 7D2607B4  extsw r6, r9
	ctx.r[6].s64 = ctx.r[9].s32 as i64;
	// 8259E410: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E414: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259E418: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259E41C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259E420: 38E7007F  addi r7, r7, 0x7f
	ctx.r[7].s64 = ctx.r[7].s64 + 127;
	// 8259E424: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 8259E428: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E42C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259E430: 3CC0820D  lis r6, -0x7df3
	ctx.r[6].s64 = -2113077248;
	// 8259E434: 54E7C9FE  srwi r7, r7, 7
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(7);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259E438: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8259E43C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259E440: ED6D6024  fdivs f11, f13, f12
	ctx.f[11].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259E444: C1A62068  lfs f13, 0x2068(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E448: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E44C: 419A0018  beq cr6, 0x8259e464
	if ctx.cr[6].eq {
	pc = 0x8259E464; continue 'dispatch;
	}
	// 8259E450: 55263830  slwi r6, r9, 7
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E454: 7C065A2C  dcbt r6, r11
	// 8259E458: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259E45C: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 8259E460: 4198FFF0  blt cr6, 0x8259e450
	if ctx.cr[6].lt {
	pc = 0x8259E450; continue 'dispatch;
	}
	// 8259E464: A1230034  lhz r9, 0x34(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 8259E468: 5527C63E  rlwinm r7, r9, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 8259E46C: 5127442E  rlwimi r7, r9, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E470: 7CE90734  extsh r9, r7
	ctx.r[9].s64 = ctx.r[7].s16 as i64;
	// 8259E474: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259E478: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E47C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E480: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259E484: C109206C  lfs f8, 0x206c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8300 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8259E488: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259E48C: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E490: C129BFFC  lfs f9, -0x4004(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E494: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259E498: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259E49C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E4A0: C1830034  lfs f12, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259E4A4: ECEB002A  fadds f7, f11, f0
	ctx.f[7].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E4A8: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259E4AC: 5527C63E  rlwinm r7, r9, 0x18, 0x18, 0x1f
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 8259E4B0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8259E4B4: 5127442E  rlwimi r7, r9, 8, 0x10, 0x17
	ctx.r[7].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[7].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E4B8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8259E4BC: 7CE90734  extsh r9, r7
	ctx.r[9].s64 = ctx.r[7].s16 as i64;
	// 8259E4C0: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259E4C4: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E4C8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E4CC: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E4D0: EDAD0232  fmuls f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[8].f64) as f32) as f64);
	// 8259E4D4: D1A30034  stfs f13, 0x34(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 8259E4D8: ED8D602A  fadds f12, f13, f12
	ctx.f[12].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 8259E4DC: EDA70372  fmuls f13, f7, f13
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E4E0: ED8C0032  fmuls f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E4E4: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E4E8: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 8259E4EC: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E4F0: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E4F4: 39080008  addi r8, r8, 8
	ctx.r[8].s64 = ctx.r[8].s64 + 8;
	// 8259E4F8: 409AFFA4  bne cr6, 0x8259e49c
	if !ctx.cr[6].eq {
	pc = 0x8259E49C; continue 'dispatch;
	}
	// 8259E4FC: 8943000D  lbz r10, 0xd(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E500: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E504: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 8259E508: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E50C: 7D695850  subf r11, r9, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8259E510: 0CC70000  twi 6, r7, 0
	// 8259E514: 7D6B3B96  divwu r11, r11, r7
	ctx.r[11].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 8259E518: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259E51C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8259E520: 41980008  blt cr6, 0x8259e528
	if ctx.cr[6].lt {
	pc = 0x8259E528; continue 'dispatch;
	}
	// 8259E524: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259E528: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E52C: 81630018  lwz r11, 0x18(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E530: 7D4A4050  subf r10, r10, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259E534: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259E538: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259E53C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8259E540: 40980008  bge cr6, 0x8259e548
	if !ctx.cr[6].lt {
	pc = 0x8259E548; continue 'dispatch;
	}
	// 8259E544: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259E548: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259E54C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259E550: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259E554: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 8259E558: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E55C: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E560: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E564: FC00001E  fctiwz f0, f0
	ctx.f[0].s64 = if ctx.f[0].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[0].f64.trunc() as i32 as i64 };
	// 8259E568: 7C0057AE  stfiwx f0, 0, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, tmp.u32) };
	// 8259E56C: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8259E570: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259E574: 41980010  blt cr6, 0x8259e584
	if ctx.cr[6].lt {
		sub_8259E584(ctx, base);
		return;
	}
	// 8259E578: 3960FF7F  li r11, -0x81
	ctx.r[11].s64 = -129;
	// 8259E57C: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 8259E580: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E584(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259E584 size=20
    let mut pc: u32 = 0x8259E584;
    'dispatch: loop {
        match pc {
            0x8259E584 => {
    //   block [0x8259E584..0x8259E598)
	// 8259E584: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259E588: 41990010  bgt cr6, 0x8259e598
	if ctx.cr[6].gt {
		sub_8259E598(ctx, base);
		return;
	}
	// 8259E58C: 39600080  li r11, 0x80
	ctx.r[11].s64 = 128;
	// 8259E590: B1630034  sth r11, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u16 ) };
	// 8259E594: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259E598 size=20
    let mut pc: u32 = 0x8259E598;
    'dispatch: loop {
        match pc {
            0x8259E598 => {
    //   block [0x8259E598..0x8259E5AC)
	// 8259E598: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8259E59C: 556AC63E  rlwinm r10, r11, 0x18, 0x18, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8259E5A0: 516A442E  rlwimi r10, r11, 8, 0x10, 0x17
	ctx.r[10].u64 = (((ctx.r[11].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[10].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E5A4: B1430034  sth r10, 0x34(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[10].u16 ) };
	// 8259E5A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E5B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259E5B0 size=560
    let mut pc: u32 = 0x8259E5B0;
    'dispatch: loop {
        match pc {
            0x8259E5B0 => {
    //   block [0x8259E5B0..0x8259E7E0)
	// 8259E5B0: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259E5B4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E5B8: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E5BC: 38E30034  addi r7, r3, 0x34
	ctx.r[7].s64 = ctx.r[3].s64 + 52;
	// 8259E5C0: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259E5C4: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E5C8: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 8259E5CC: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E5D0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259E5D4: 7D0A4050  subf r8, r10, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[10].s64;
	// 8259E5D8: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E5DC: 7D4451D6  mullw r10, r4, r10
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259E5E0: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E5E4: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8259E5E8: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8259E5EC: 7D290194  addze r9, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[9].s64 = tmp.s64;
	// 8259E5F0: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259E5F4: 7D4A2A14  add r10, r10, r5
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[5].u64;
	// 8259E5F8: 7F084800  cmpw cr6, r8, r9
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[9].s32, &mut ctx.xer);
	// 8259E5FC: 41980008  blt cr6, 0x8259e604
	if ctx.cr[6].lt {
	pc = 0x8259E604; continue 'dispatch;
	}
	// 8259E600: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259E604: 7D2507B4  extsw r5, r9
	ctx.r[5].s64 = ctx.r[9].s32 as i64;
	// 8259E608: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E60C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259E610: 5506103A  slwi r6, r8, 2
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E614: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8259E618: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259E61C: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 8259E620: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E624: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259E628: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259E62C: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E630: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259E634: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259E638: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259E63C: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E640: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E644: 419A0018  beq cr6, 0x8259e65c
	if ctx.cr[6].eq {
	pc = 0x8259E65C; continue 'dispatch;
	}
	// 8259E648: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259E64C: 7C05522C  dcbt r5, r10
	// 8259E650: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8259E654: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259E658: 4198FFF0  blt cr6, 0x8259e648
	if ctx.cr[6].lt {
	pc = 0x8259E648; continue 'dispatch;
	}
	// 8259E65C: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259E660: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 8259E664: 38C00002  li r6, 2
	ctx.r[6].s64 = 2;
	// 8259E668: C165206C  lfs f11, 0x206c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8300 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259E66C: A0A90000  lhz r5, 0(r9)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E670: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259E674: 54A4C63E  rlwinm r4, r5, 0x18, 0x18, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 8259E678: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259E67C: 50A4442E  rlwimi r4, r5, 8, 0x10, 0x17
	ctx.r[4].u64 = (((ctx.r[5].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[4].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E680: 7C850734  extsh r5, r4
	ctx.r[5].s64 = ctx.r[4].s16 as i64;
	// 8259E684: F8A1FFF0  std r5, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[5].u64 ) };
	// 8259E688: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E68C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E690: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E694: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E698: D1A90000  stfs f13, 0(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E69C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8259E6A0: 409AFFCC  bne cr6, 0x8259e66c
	if !ctx.cr[6].eq {
	pc = 0x8259E66C; continue 'dispatch;
	}
	// 8259E6A4: 3D20820D  lis r9, -0x7df3
	ctx.r[9].s64 = -2113077248;
	// 8259E6A8: C149BFFC  lfs f10, -0x4004(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8259E6AC: A12A0002  lhz r9, 2(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259E6B0: C1270004  lfs f9, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E6B4: ED88002A  fadds f12, f8, f0
	ctx.f[12].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E6B8: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259E6BC: 5526C63E  rlwinm r6, r9, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 8259E6C0: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259E6C4: 5126442E  rlwimi r6, r9, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E6C8: 7CC90734  extsh r9, r6
	ctx.r[9].s64 = ctx.r[6].s16 as i64;
	// 8259E6CC: F921FFF0  std r9, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[9].u64 ) };
	// 8259E6D0: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259E6D4: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E6D8: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E6DC: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E6E0: D1A70004  stfs f13, 4(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E6E4: ED2D482A  fadds f9, f13, f9
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259E6E8: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E6EC: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E6F0: ED2902B2  fmuls f9, f9, f10
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E6F4: D12B0400  stfs f9, 0x400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259E6F8: D1AB0404  stfs f13, 0x404(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259E6FC: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E700: C1270000  lfs f9, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E704: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259E708: 5526C63E  rlwinm r6, r9, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	// 8259E70C: 5126442E  rlwimi r6, r9, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[9].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E710: 7CC90734  extsh r9, r6
	ctx.r[9].s64 = ctx.r[6].s16 as i64;
	// 8259E714: F921FFF8  std r9, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[9].u64 ) };
	// 8259E718: C9A1FFF8  lfd f13, -8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259E71C: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E720: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E724: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E728: D1A70000  stfs f13, 0(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E72C: ED2D482A  fadds f9, f13, f9
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259E730: EDAC0372  fmuls f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E734: ED890032  fmuls f12, f9, f0
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E738: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E73C: ED8C02B2  fmuls f12, f12, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E740: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E744: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E748: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259E74C: 409AFF60  bne cr6, 0x8259e6ac
	if !ctx.cr[6].eq {
	pc = 0x8259E6AC; continue 'dispatch;
	}
	// 8259E750: 8923000D  lbz r9, 0xd(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E754: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E758: 5526083E  rotlwi r6, r9, 1
	ctx.r[6].u64 = ((ctx.r[9].u32).rotate_left(1)) as u64;
	// 8259E75C: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E760: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 8259E764: 0CC60000  twi 6, r6, 0
	// 8259E768: 7D4A3396  divwu r10, r10, r6
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[6].u32;
	// 8259E76C: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259E770: 40980008  bge cr6, 0x8259e778
	if !ctx.cr[6].lt {
	pc = 0x8259E778; continue 'dispatch;
	}
	// 8259E774: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 8259E778: 81030014  lwz r8, 0x14(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E77C: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E780: 7D685850  subf r11, r8, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[8].s64;
	// 8259E784: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8259E788: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259E78C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8259E790: 41980008  blt cr6, 0x8259e798
	if ctx.cr[6].lt {
	pc = 0x8259E798; continue 'dispatch;
	}
	// 8259E794: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8259E798: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259E79C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259E7A0: 3D200000  lis r9, 0
	ctx.r[9].s64 = 0;
	// 8259E7A4: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259E7A8: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8259E7AC: 6129FF7F  ori r9, r9, 0xff7f
	ctx.r[9].u64 = ctx.r[9].u64 | 65407;
	// 8259E7B0: 39000080  li r8, 0x80
	ctx.r[8].s64 = 128;
	// 8259E7B4: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E7B8: C1A70000  lfs f13, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E7BC: 3961FFF0  addi r11, r1, -0x10
	ctx.r[11].s64 = ctx.r[1].s64 + -16;
	// 8259E7C0: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E7C4: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259E7C8: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259E7CC: 8161FFF0  lwz r11, -0x10(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) } as u64;
	// 8259E7D0: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259E7D4: 4198000C  blt cr6, 0x8259e7e0
	if ctx.cr[6].lt {
		sub_8259E7E0(ctx, base);
		return;
	}
	// 8259E7D8: B1270000  sth r9, 0(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8259E7DC: 48000024  b 0x8259e800
	sub_8259E7F0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E7E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259E7E0 size=16
    let mut pc: u32 = 0x8259E7E0;
    'dispatch: loop {
        match pc {
            0x8259E7E0 => {
    //   block [0x8259E7E0..0x8259E7F0)
	// 8259E7E0: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259E7E4: 4199000C  bgt cr6, 0x8259e7f0
	if ctx.cr[6].gt {
		sub_8259E7F0(ctx, base);
		return;
	}
	// 8259E7E8: B1070000  sth r8, 0(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259E7EC: 48000014  b 0x8259e800
	sub_8259E7F0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E7F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8259E7F0 size=36
    let mut pc: u32 = 0x8259E7F0;
    'dispatch: loop {
        match pc {
            0x8259E7F0 => {
    //   block [0x8259E7F0..0x8259E814)
	// 8259E7F0: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8259E7F4: 5566C63E  rlwinm r6, r11, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8259E7F8: 5166442E  rlwimi r6, r11, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[11].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E7FC: B0C70000  sth r6, 0(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 8259E800: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 8259E804: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259E808: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8259E80C: 409AFFAC  bne cr6, 0x8259e7b8
	if !ctx.cr[6].eq {
		sub_8259E5B0(ctx, base);
		return;
	}
	// 8259E810: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259E818(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259E818 size=756
    let mut pc: u32 = 0x8259E818;
    'dispatch: loop {
        match pc {
            0x8259E818 => {
    //   block [0x8259E818..0x8259EB0C)
	// 8259E818: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259E81C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259E820: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259E824: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259E828: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 8259E82C: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259E830: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E834: 7FEB4050  subf r31, r11, r8
	ctx.r[31].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259E838: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259E83C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259E840: 7D093850  subf r8, r9, r7
	ctx.r[8].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 8259E844: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E848: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 8259E84C: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259E850: 7FE70E70  srawi r7, r31, 1
	ctx.xer.ca = (ctx.r[31].s32 < 0) && ((ctx.r[31].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[31].s32 >> 1) as i64;
	// 8259E854: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259E858: 7CE70194  addze r7, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[7].s64 = tmp.s64;
	// 8259E85C: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259E860: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8259E864: 7F083800  cmpw cr6, r8, r7
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8259E868: 41980008  blt cr6, 0x8259e870
	if ctx.cr[6].lt {
	pc = 0x8259E870; continue 'dispatch;
	}
	// 8259E86C: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 8259E870: 7CE507B4  extsw r5, r7
	ctx.r[5].s64 = ctx.r[7].s32 as i64;
	// 8259E874: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E878: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259E87C: 55061838  slwi r6, r8, 3
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E880: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8259E884: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259E888: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 8259E88C: C981FFD0  lfd f12, -0x30(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E890: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259E894: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259E898: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259E89C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259E8A0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259E8A4: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259E8A8: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259E8AC: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259E8B0: 419A0018  beq cr6, 0x8259e8c8
	if ctx.cr[6].eq {
	pc = 0x8259E8C8; continue 'dispatch;
	}
	// 8259E8B4: 54E53830  slwi r5, r7, 7
	ctx.r[5].u32 = ctx.r[7].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259E8B8: 7C054A2C  dcbt r5, r9
	// 8259E8BC: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 8259E8C0: 7F073040  cmplw cr6, r7, r6
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259E8C4: 4198FFF0  blt cr6, 0x8259e8b4
	if ctx.cr[6].lt {
	pc = 0x8259E8B4; continue 'dispatch;
	}
	// 8259E8C8: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259E8CC: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8259E8D0: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 8259E8D4: C185206C  lfs f12, 0x206c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8300 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259E8D8: A0A70000  lhz r5, 0(r7)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E8DC: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259E8E0: 54A4C63E  rlwinm r4, r5, 0x18, 0x18, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 8259E8E4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259E8E8: 50A4442E  rlwimi r4, r5, 8, 0x10, 0x17
	ctx.r[4].u64 = (((ctx.r[5].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[4].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E8EC: 7C850734  extsh r5, r4
	ctx.r[5].s64 = ctx.r[4].s16 as i64;
	// 8259E8F0: F8A1FFD0  std r5, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[5].u64 ) };
	// 8259E8F4: C9A1FFD0  lfd f13, -0x30(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E8F8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259E8FC: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259E900: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259E904: D1A70000  stfs f13, 0(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259E908: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259E90C: 409AFFCC  bne cr6, 0x8259e8d8
	if !ctx.cr[6].eq {
	pc = 0x8259E8D8; continue 'dispatch;
	}
	// 8259E910: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8259E914: C167BFFC  lfs f11, -0x4004(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259E918: A0E90006  lhz r7, 6(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259E91C: C12A000C  lfs f9, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E920: EDA8002A  fadds f13, f8, f0
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259E924: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259E928: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259E92C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259E930: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E934: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259E938: F8E1FFD0  std r7, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[7].u64 ) };
	// 8259E93C: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259E940: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259E944: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259E948: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259E94C: D14A000C  stfs f10, 0xc(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259E950: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259E954: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E958: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E95C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E960: D12B0C00  stfs f9, 0xc00(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259E964: D14B0C04  stfs f10, 0xc04(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259E968: A0E90004  lhz r7, 4(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259E96C: C12A0008  lfs f9, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E970: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259E974: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E978: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259E97C: F8E1FFD8  std r7, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[7].u64 ) };
	// 8259E980: C941FFD8  lfd f10, -0x28(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259E984: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259E988: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259E98C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259E990: D14A0008  stfs f10, 8(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259E994: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259E998: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E99C: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E9A0: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E9A4: D12B0800  stfs f9, 0x800(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259E9A8: D14B0804  stfs f10, 0x804(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259E9AC: A0E90002  lhz r7, 2(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259E9B0: C12A0004  lfs f9, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E9B4: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259E9B8: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259E9BC: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259E9C0: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 8259E9C4: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259E9C8: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259E9CC: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259E9D0: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259E9D4: D14A0004  stfs f10, 4(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259E9D8: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259E9DC: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259E9E0: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259E9E4: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259E9E8: D12B0400  stfs f9, 0x400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259E9EC: D14B0404  stfs f10, 0x404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259E9F0: A0E90000  lhz r7, 0(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259E9F4: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259E9F8: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 8259E9FC: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259EA00: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EA04: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259EA08: F8E1FFE8  std r7, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[7].u64 ) };
	// 8259EA0C: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259EA10: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259EA14: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259EA18: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259EA1C: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259EA20: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259EA24: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259EA28: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259EA2C: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259EA30: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259EA34: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259EA38: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259EA3C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259EA40: 409AFED8  bne cr6, 0x8259e918
	if !ctx.cr[6].eq {
	pc = 0x8259E918; continue 'dispatch;
	}
	// 8259EA44: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259EA48: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EA4C: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 8259EA50: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259EA54: 7D274850  subf r9, r7, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 8259EA58: 0CC60000  twi 6, r6, 0
	// 8259EA5C: 7D293396  divwu r9, r9, r6
	ctx.r[9].u32 = ctx.r[9].u32 / ctx.r[6].u32;
	// 8259EA60: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259EA64: 40980008  bge cr6, 0x8259ea6c
	if !ctx.cr[6].lt {
	pc = 0x8259EA6C; continue 'dispatch;
	}
	// 8259EA68: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259EA6C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259EA70: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259EA74: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259EA78: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259EA7C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259EA80: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259EA84: 41980008  blt cr6, 0x8259ea8c
	if ctx.cr[6].lt {
	pc = 0x8259EA8C; continue 'dispatch;
	}
	// 8259EA88: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 8259EA8C: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259EA90: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259EA94: 3D000000  lis r8, 0
	ctx.r[8].s64 = 0;
	// 8259EA98: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259EA9C: 39200004  li r9, 4
	ctx.r[9].s64 = 4;
	// 8259EAA0: 6108FF7F  ori r8, r8, 0xff7f
	ctx.r[8].u64 = ctx.r[8].u64 | 65407;
	// 8259EAA4: 38E00080  li r7, 0x80
	ctx.r[7].s64 = 128;
	// 8259EAA8: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EAAC: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EAB0: 3961FFD0  addi r11, r1, -0x30
	ctx.r[11].s64 = ctx.r[1].s64 + -48;
	// 8259EAB4: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259EAB8: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259EABC: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259EAC0: 8161FFD0  lwz r11, -0x30(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) } as u64;
	// 8259EAC4: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259EAC8: 4198000C  blt cr6, 0x8259ead4
	if ctx.cr[6].lt {
	pc = 0x8259EAD4; continue 'dispatch;
	}
	// 8259EACC: B10A0000  sth r8, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259EAD0: 48000024  b 0x8259eaf4
	pc = 0x8259EAF4; continue 'dispatch;
	// 8259EAD4: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259EAD8: 4199000C  bgt cr6, 0x8259eae4
	if ctx.cr[6].gt {
	pc = 0x8259EAE4; continue 'dispatch;
	}
	// 8259EADC: B0EA0000  sth r7, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259EAE0: 48000014  b 0x8259eaf4
	pc = 0x8259EAF4; continue 'dispatch;
	// 8259EAE4: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8259EAE8: 5566C63E  rlwinm r6, r11, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8259EAEC: 5166442E  rlwimi r6, r11, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[11].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EAF0: B0CA0000  sth r6, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 8259EAF4: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259EAF8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259EAFC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259EB00: 409AFFAC  bne cr6, 0x8259eaac
	if !ctx.cr[6].eq {
	pc = 0x8259EAAC; continue 'dispatch;
	}
	// 8259EB04: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259EB08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259EB10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8259EB10 size=900
    let mut pc: u32 = 0x8259EB10;
    'dispatch: loop {
        match pc {
            0x8259EB10 => {
    //   block [0x8259EB10..0x8259EE94)
	// 8259EB10: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 8259EB14: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259EB18: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EB1C: 81030018  lwz r8, 0x18(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259EB20: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 8259EB24: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259EB28: 80E30004  lwz r7, 4(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259EB2C: 7FEB4050  subf r31, r11, r8
	ctx.r[31].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 8259EB30: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259EB34: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259EB38: 7D093850  subf r8, r9, r7
	ctx.r[8].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 8259EB3C: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EB40: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 8259EB44: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259EB48: 7FE70E70  srawi r7, r31, 1
	ctx.xer.ca = (ctx.r[31].s32 < 0) && ((ctx.r[31].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[31].s32 >> 1) as i64;
	// 8259EB4C: 5529083C  slwi r9, r9, 1
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8259EB50: 7CE70194  addze r7, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[7].s64 = tmp.s64;
	// 8259EB54: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8259EB58: 7D292A14  add r9, r9, r5
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[5].u64;
	// 8259EB5C: 7F083800  cmpw cr6, r8, r7
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8259EB60: 41980008  blt cr6, 0x8259eb68
	if ctx.cr[6].lt {
	pc = 0x8259EB68; continue 'dispatch;
	}
	// 8259EB64: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 8259EB68: 7CE607B4  extsw r6, r7
	ctx.r[6].s64 = ctx.r[7].s32 as i64;
	// 8259EB6C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EB70: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259EB74: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259EB78: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8259EB7C: F8C1FFC0  std r6, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[6].u64 ) };
	// 8259EB80: C981FFC0  lfd f12, -0x40(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259EB84: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259EB88: 5506083C  slwi r6, r8, 1
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259EB8C: 7CC83214  add r6, r8, r6
	ctx.r[6].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 8259EB90: 54C6103A  slwi r6, r6, 2
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259EB94: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259EB98: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259EB9C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259EBA0: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259EBA4: ED0D6024  fdivs f8, f13, f12
	ctx.f[8].f64 = ((ctx.f[13].f64 / ctx.f[12].f64) as f32) as f64;
	// 8259EBA8: C1A52068  lfs f13, 0x2068(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8296 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EBAC: ECE80372  fmuls f7, f8, f13
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 8259EBB0: 419A0018  beq cr6, 0x8259ebc8
	if ctx.cr[6].eq {
	pc = 0x8259EBC8; continue 'dispatch;
	}
	// 8259EBB4: 54E53830  slwi r5, r7, 7
	ctx.r[5].u32 = ctx.r[7].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259EBB8: 7C054A2C  dcbt r5, r9
	// 8259EBBC: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 8259EBC0: 7F073040  cmplw cr6, r7, r6
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259EBC4: 4198FFF0  blt cr6, 0x8259ebb4
	if ctx.cr[6].lt {
	pc = 0x8259EBB4; continue 'dispatch;
	}
	// 8259EBC8: 3CA0820D  lis r5, -0x7df3
	ctx.r[5].s64 = -2113077248;
	// 8259EBCC: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8259EBD0: 38C00006  li r6, 6
	ctx.r[6].s64 = 6;
	// 8259EBD4: C185206C  lfs f12, 0x206c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8300 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8259EBD8: A0A70000  lhz r5, 0(r7)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EBDC: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 8259EBE0: 54A4C63E  rlwinm r4, r5, 0x18, 0x18, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 8259EBE4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259EBE8: 50A4442E  rlwimi r4, r5, 8, 0x10, 0x17
	ctx.r[4].u64 = (((ctx.r[5].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[4].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EBEC: 7C850734  extsh r5, r4
	ctx.r[5].s64 = ctx.r[4].s16 as i64;
	// 8259EBF0: F8A1FFC0  std r5, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[5].u64 ) };
	// 8259EBF4: C9A1FFC0  lfd f13, -0x40(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259EBF8: FDA06E9C  fcfid f13, f13
	ctx.f[13].f64 = (ctx.f[13].s64 as f64);
	// 8259EBFC: FDA06818  frsp f13, f13
	ctx.f[13].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8259EC00: EDAD0332  fmuls f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259EC04: D1A70000  stfs f13, 0(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259EC08: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 8259EC0C: 409AFFCC  bne cr6, 0x8259ebd8
	if !ctx.cr[6].eq {
	pc = 0x8259EBD8; continue 'dispatch;
	}
	// 8259EC10: 3CE0820D  lis r7, -0x7df3
	ctx.r[7].s64 = -2113077248;
	// 8259EC14: C167BFFC  lfs f11, -0x4004(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8259EC18: A0E9000A  lhz r7, 0xa(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(10 as u32) ) } as u64;
	// 8259EC1C: C12A0014  lfs f9, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259EC20: EDA8002A  fadds f13, f8, f0
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259EC24: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 8259EC28: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259EC2C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259EC30: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EC34: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259EC38: F8E1FFC0  std r7, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.r[7].u64 ) };
	// 8259EC3C: C941FFC0  lfd f10, -0x40(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 8259EC40: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259EC44: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259EC48: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259EC4C: D14A0014  stfs f10, 0x14(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8259EC50: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259EC54: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259EC58: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259EC5C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259EC60: D12B1400  stfs f9, 0x1400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5120 as u32), tmp.u32 ) };
	// 8259EC64: D14B1404  stfs f10, 0x1404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(5124 as u32), tmp.u32 ) };
	// 8259EC68: A0E90008  lhz r7, 8(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259EC6C: C12A0010  lfs f9, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259EC70: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259EC74: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EC78: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259EC7C: F8E1FFC8  std r7, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.r[7].u64 ) };
	// 8259EC80: C941FFC8  lfd f10, -0x38(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 8259EC84: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259EC88: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259EC8C: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259EC90: D14A0010  stfs f10, 0x10(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8259EC94: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259EC98: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259EC9C: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259ECA0: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259ECA4: D12B1000  stfs f9, 0x1000(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4096 as u32), tmp.u32 ) };
	// 8259ECA8: D14B1004  stfs f10, 0x1004(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4100 as u32), tmp.u32 ) };
	// 8259ECAC: A0E90006  lhz r7, 6(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(6 as u32) ) } as u64;
	// 8259ECB0: C12A000C  lfs f9, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259ECB4: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259ECB8: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259ECBC: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259ECC0: F8E1FFD0  std r7, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.r[7].u64 ) };
	// 8259ECC4: C941FFD0  lfd f10, -0x30(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8259ECC8: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259ECCC: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259ECD0: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259ECD4: D14A000C  stfs f10, 0xc(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8259ECD8: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259ECDC: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259ECE0: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259ECE4: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259ECE8: D12B0C00  stfs f9, 0xc00(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3072 as u32), tmp.u32 ) };
	// 8259ECEC: D14B0C04  stfs f10, 0xc04(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(3076 as u32), tmp.u32 ) };
	// 8259ECF0: A0E90004  lhz r7, 4(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259ECF4: C12A0008  lfs f9, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259ECF8: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259ECFC: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259ED00: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259ED04: F8E1FFD8  std r7, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.r[7].u64 ) };
	// 8259ED08: C941FFD8  lfd f10, -0x28(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8259ED0C: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259ED10: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259ED14: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259ED18: D14A0008  stfs f10, 8(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8259ED1C: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259ED20: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259ED24: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259ED28: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259ED2C: D12B0800  stfs f9, 0x800(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2048 as u32), tmp.u32 ) };
	// 8259ED30: D14B0804  stfs f10, 0x804(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(2052 as u32), tmp.u32 ) };
	// 8259ED34: A0E90002  lhz r7, 2(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(2 as u32) ) } as u64;
	// 8259ED38: C12A0004  lfs f9, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259ED3C: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259ED40: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259ED44: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259ED48: F8E1FFE0  std r7, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.r[7].u64 ) };
	// 8259ED4C: C941FFE0  lfd f10, -0x20(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 8259ED50: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259ED54: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259ED58: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259ED5C: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259ED60: D14A0004  stfs f10, 4(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259ED64: ED4D02B2  fmuls f10, f13, f10
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259ED68: ED290032  fmuls f9, f9, f0
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259ED6C: ED2902F2  fmuls f9, f9, f11
	ctx.f[9].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259ED70: D12B0400  stfs f9, 0x400(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8259ED74: D14B0404  stfs f10, 0x404(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8259ED78: A0E90000  lhz r7, 0(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259ED7C: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8259ED80: 3929000C  addi r9, r9, 0xc
	ctx.r[9].s64 = ctx.r[9].s64 + 12;
	// 8259ED84: 54E6C63E  rlwinm r6, r7, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 8259ED88: 50E6442E  rlwimi r6, r7, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259ED8C: 7CC70734  extsh r7, r6
	ctx.r[7].s64 = ctx.r[6].s16 as i64;
	// 8259ED90: F8E1FFE8  std r7, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[7].u64 ) };
	// 8259ED94: C941FFE8  lfd f10, -0x18(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8259ED98: FD40569C  fcfid f10, f10
	ctx.f[10].f64 = (ctx.f[10].s64 as f64);
	// 8259ED9C: FD405018  frsp f10, f10
	ctx.f[10].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8259EDA0: ED4A0332  fmuls f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 8259EDA4: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259EDA8: ED2A482A  fadds f9, f10, f9
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64;
	// 8259EDAC: EDAD02B2  fmuls f13, f13, f10
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[10].f64) as f32) as f64);
	// 8259EDB0: ED490032  fmuls f10, f9, f0
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259EDB4: EC07002A  fadds f0, f7, f0
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 8259EDB8: ED4A02F2  fmuls f10, f10, f11
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 8259EDBC: D14B0000  stfs f10, 0(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8259EDC0: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8259EDC4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8259EDC8: 409AFE50  bne cr6, 0x8259ec18
	if !ctx.cr[6].eq {
	pc = 0x8259EC18; continue 'dispatch;
	}
	// 8259EDCC: 8903000D  lbz r8, 0xd(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259EDD0: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EDD4: 5506083E  rotlwi r6, r8, 1
	ctx.r[6].u64 = ((ctx.r[8].u32).rotate_left(1)) as u64;
	// 8259EDD8: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259EDDC: 7D274850  subf r9, r7, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 8259EDE0: 0CC60000  twi 6, r6, 0
	// 8259EDE4: 7D293396  divwu r9, r9, r6
	ctx.r[9].u32 = ctx.r[9].u32 / ctx.r[6].u32;
	// 8259EDE8: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 8259EDEC: 40980008  bge cr6, 0x8259edf4
	if !ctx.cr[6].lt {
	pc = 0x8259EDF4; continue 'dispatch;
	}
	// 8259EDF0: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 8259EDF4: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259EDF8: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259EDFC: 7D675850  subf r11, r7, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8259EE00: 91030008  stw r8, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8259EE04: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259EE08: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 8259EE0C: 41980008  blt cr6, 0x8259ee14
	if ctx.cr[6].lt {
	pc = 0x8259EE14; continue 'dispatch;
	}
	// 8259EE10: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 8259EE14: 9163001C  stw r11, 0x1c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8259EE18: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8259EE1C: 3D000000  lis r8, 0
	ctx.r[8].s64 = 0;
	// 8259EE20: D0030024  stfs f0, 0x24(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 8259EE24: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8259EE28: 6108FF7F  ori r8, r8, 0xff7f
	ctx.r[8].u64 = ctx.r[8].u64 | 65407;
	// 8259EE2C: 38E00080  li r7, 0x80
	ctx.r[7].s64 = 128;
	// 8259EE30: C00B72B8  lfs f0, 0x72b8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(29368 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EE34: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EE38: 3961FFC0  addi r11, r1, -0x40
	ctx.r[11].s64 = ctx.r[1].s64 + -64;
	// 8259EE3C: EDAD0032  fmuls f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8259EE40: FDA0681E  fctiwz f13, f13
	ctx.f[13].s64 = if ctx.f[13].f64 > (i32::MAX as f64) { i32::MAX as i64 } else { ctx.f[13].f64.trunc() as i32 as i64 };
	// 8259EE44: 7DA05FAE  stfiwx f13, 0, r11
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32, tmp.u32) };
	// 8259EE48: 8161FFC0  lwz r11, -0x40(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) } as u64;
	// 8259EE4C: 2F0B7FFF  cmpwi cr6, r11, 0x7fff
	ctx.cr[6].compare_i32(ctx.r[11].s32, 32767, &mut ctx.xer);
	// 8259EE50: 4198000C  blt cr6, 0x8259ee5c
	if ctx.cr[6].lt {
	pc = 0x8259EE5C; continue 'dispatch;
	}
	// 8259EE54: B10A0000  sth r8, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 8259EE58: 48000024  b 0x8259ee7c
	pc = 0x8259EE7C; continue 'dispatch;
	// 8259EE5C: 2F0B8000  cmpwi cr6, r11, -0x8000
	ctx.cr[6].compare_i32(ctx.r[11].s32, -32768, &mut ctx.xer);
	// 8259EE60: 4199000C  bgt cr6, 0x8259ee6c
	if ctx.cr[6].gt {
	pc = 0x8259EE6C; continue 'dispatch;
	}
	// 8259EE64: B0EA0000  sth r7, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8259EE68: 48000014  b 0x8259ee7c
	pc = 0x8259EE7C; continue 'dispatch;
	// 8259EE6C: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8259EE70: 5566C63E  rlwinm r6, r11, 0x18, 0x18, 0x1f
	ctx.r[6].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8259EE74: 5166442E  rlwimi r6, r11, 8, 0x10, 0x17
	ctx.r[6].u64 = (((ctx.r[11].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[6].u64 & 0xFFFFFFFFFFFF00FF);
	// 8259EE78: B0CA0000  sth r6, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 8259EE7C: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8259EE80: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8259EE84: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8259EE88: 409AFFAC  bne cr6, 0x8259ee34
	if !ctx.cr[6].eq {
	pc = 0x8259EE34; continue 'dispatch;
	}
	// 8259EE8C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 8259EE90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259EE98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259EE98 size=216
    let mut pc: u32 = 0x8259EE98;
    'dispatch: loop {
        match pc {
            0x8259EE98 => {
    //   block [0x8259EE98..0x8259EF70)
	// 8259EE98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259EE9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259EEA0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259EEA4: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259EEA8: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259EEAC: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EEB0: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259EEB4: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259EEB8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259EEBC: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259EEC0: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259EEC4: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259EEC8: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259EECC: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EED0: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259EED4: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259EED8: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259EEDC: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259EEE0: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259EEE4: 54CB07BE  clrlwi r11, r6, 0x1e
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000003u64;
	// 8259EEE8: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259EEEC: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259EEF0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259EEF4: 409A0064  bne cr6, 0x8259ef58
	if !ctx.cr[6].eq {
	pc = 0x8259EF58; continue 'dispatch;
	}
	// 8259EEF8: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259EEFC: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EF00: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259EF04: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259EF08: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259EF0C: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259EF10: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259EF14: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259EF18: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259EF1C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259EF20: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259EF24: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259EF28: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259EF2C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259EF30: 40990028  ble cr6, 0x8259ef58
	if !ctx.cr[6].gt {
	pc = 0x8259EF58; continue 'dispatch;
	}
	// 8259EF34: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259EF38: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EF3C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259EF40: 41980018  blt cr6, 0x8259ef58
	if ctx.cr[6].lt {
	pc = 0x8259EF58; continue 'dispatch;
	}
	// 8259EF44: 4BFF3355  bl 0x82592298
	ctx.lr = 0x8259EF48;
	sub_82592298(ctx, base);
	// 8259EF48: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259EF4C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259EF50: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259EF54: 4E800020  blr
	return;
	// 8259EF58: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259EF5C: 4BFF6345  bl 0x825952a0
	ctx.lr = 0x8259EF60;
	sub_825952A0(ctx, base);
	// 8259EF60: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259EF64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259EF68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259EF6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259EF70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259EF70 size=216
    let mut pc: u32 = 0x8259EF70;
    'dispatch: loop {
        match pc {
            0x8259EF70 => {
    //   block [0x8259EF70..0x8259F048)
	// 8259EF70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259EF74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259EF78: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259EF7C: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259EF80: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259EF84: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259EF88: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259EF8C: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259EF90: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259EF94: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259EF98: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259EF9C: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259EFA0: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259EFA4: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259EFA8: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259EFAC: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259EFB0: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259EFB4: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259EFB8: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259EFBC: 54CB07BE  clrlwi r11, r6, 0x1e
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000003u64;
	// 8259EFC0: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259EFC4: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259EFC8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259EFCC: 409A0064  bne cr6, 0x8259f030
	if !ctx.cr[6].eq {
	pc = 0x8259F030; continue 'dispatch;
	}
	// 8259EFD0: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259EFD4: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259EFD8: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259EFDC: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259EFE0: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259EFE4: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259EFE8: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259EFEC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259EFF0: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259EFF4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259EFF8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259EFFC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F000: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F004: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F008: 40990028  ble cr6, 0x8259f030
	if !ctx.cr[6].gt {
	pc = 0x8259F030; continue 'dispatch;
	}
	// 8259F00C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F010: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F014: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F018: 41980018  blt cr6, 0x8259f030
	if ctx.cr[6].lt {
	pc = 0x8259F030; continue 'dispatch;
	}
	// 8259F01C: 4BFF3485  bl 0x825924a0
	ctx.lr = 0x8259F020;
	sub_825924A0(ctx, base);
	// 8259F020: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F024: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F028: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F02C: 4E800020  blr
	return;
	// 8259F030: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F034: 4BFF654D  bl 0x82595580
	ctx.lr = 0x8259F038;
	sub_82595580(ctx, base);
	// 8259F038: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F03C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F040: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F044: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F048(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F048 size=216
    let mut pc: u32 = 0x8259F048;
    'dispatch: loop {
        match pc {
            0x8259F048 => {
    //   block [0x8259F048..0x8259F120)
	// 8259F048: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F04C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F050: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F054: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F058: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F05C: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F060: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F064: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F068: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F06C: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F070: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F074: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F078: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F07C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F080: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F084: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F088: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F08C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F090: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F094: 54CB07BE  clrlwi r11, r6, 0x1e
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000003u64;
	// 8259F098: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F09C: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F0A0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F0A4: 409A0064  bne cr6, 0x8259f108
	if !ctx.cr[6].eq {
	pc = 0x8259F108; continue 'dispatch;
	}
	// 8259F0A8: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F0AC: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F0B0: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F0B4: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F0B8: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F0BC: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F0C0: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F0C4: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F0C8: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F0CC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F0D0: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F0D4: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F0D8: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F0DC: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F0E0: 40990028  ble cr6, 0x8259f108
	if !ctx.cr[6].gt {
	pc = 0x8259F108; continue 'dispatch;
	}
	// 8259F0E4: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F0E8: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F0EC: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F0F0: 41980018  blt cr6, 0x8259f108
	if ctx.cr[6].lt {
	pc = 0x8259F108; continue 'dispatch;
	}
	// 8259F0F4: 4BFF35ED  bl 0x825926e0
	ctx.lr = 0x8259F0F8;
	sub_825926E0(ctx, base);
	// 8259F0F8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F0FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F100: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F104: 4E800020  blr
	return;
	// 8259F108: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F10C: 4BFF679D  bl 0x825958a8
	ctx.lr = 0x8259F110;
	sub_825958A8(ctx, base);
	// 8259F110: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F114: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F118: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F11C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F120 size=216
    let mut pc: u32 = 0x8259F120;
    'dispatch: loop {
        match pc {
            0x8259F120 => {
    //   block [0x8259F120..0x8259F1F8)
	// 8259F120: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F124: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F128: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F12C: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F130: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F134: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F138: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F13C: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F140: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F144: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F148: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F14C: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F150: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F154: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F158: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F15C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F160: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F164: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F168: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F16C: 54CB07BE  clrlwi r11, r6, 0x1e
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000003u64;
	// 8259F170: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F174: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F178: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F17C: 409A0064  bne cr6, 0x8259f1e0
	if !ctx.cr[6].eq {
	pc = 0x8259F1E0; continue 'dispatch;
	}
	// 8259F180: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F184: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F188: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F18C: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F190: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F194: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F198: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F19C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F1A0: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F1A4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F1A8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F1AC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F1B0: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F1B4: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F1B8: 40990028  ble cr6, 0x8259f1e0
	if !ctx.cr[6].gt {
	pc = 0x8259F1E0; continue 'dispatch;
	}
	// 8259F1BC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F1C0: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F1C4: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F1C8: 41980018  blt cr6, 0x8259f1e0
	if ctx.cr[6].lt {
	pc = 0x8259F1E0; continue 'dispatch;
	}
	// 8259F1CC: 4BFF37BD  bl 0x82592988
	ctx.lr = 0x8259F1D0;
	sub_82592988(ctx, base);
	// 8259F1D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F1D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F1D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F1DC: 4E800020  blr
	return;
	// 8259F1E0: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F1E4: 4BFF6ACD  bl 0x82595cb0
	ctx.lr = 0x8259F1E8;
	sub_82595CB0(ctx, base);
	// 8259F1E8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F1EC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F1F0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F1F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F1F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F1F8 size=216
    let mut pc: u32 = 0x8259F1F8;
    'dispatch: loop {
        match pc {
            0x8259F1F8 => {
    //   block [0x8259F1F8..0x8259F2D0)
	// 8259F1F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F1FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F200: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F204: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F208: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F20C: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F210: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F214: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F218: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F21C: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F220: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F224: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F228: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F22C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F230: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F234: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F238: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F23C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F240: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F244: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259F248: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F24C: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F250: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F254: 409A0064  bne cr6, 0x8259f2b8
	if !ctx.cr[6].eq {
	pc = 0x8259F2B8; continue 'dispatch;
	}
	// 8259F258: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F25C: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F260: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F264: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F268: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F26C: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F270: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F274: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F278: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F27C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F280: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F284: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F288: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F28C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F290: 40990028  ble cr6, 0x8259f2b8
	if !ctx.cr[6].gt {
	pc = 0x8259F2B8; continue 'dispatch;
	}
	// 8259F294: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F298: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F29C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F2A0: 41980018  blt cr6, 0x8259f2b8
	if ctx.cr[6].lt {
	pc = 0x8259F2B8; continue 'dispatch;
	}
	// 8259F2A4: 4BFF206D  bl 0x82591310
	ctx.lr = 0x8259F2A8;
	sub_82591310(ctx, base);
	// 8259F2A8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F2AC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F2B0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F2B4: 4E800020  blr
	return;
	// 8259F2B8: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F2BC: 4BFF72A5  bl 0x82596560
	ctx.lr = 0x8259F2C0;
	sub_82596560(ctx, base);
	// 8259F2C0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F2C4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F2C8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F2CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F2D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F2D0 size=216
    let mut pc: u32 = 0x8259F2D0;
    'dispatch: loop {
        match pc {
            0x8259F2D0 => {
    //   block [0x8259F2D0..0x8259F3A8)
	// 8259F2D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F2D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F2D8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F2DC: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F2E0: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F2E4: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F2E8: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F2EC: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F2F0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F2F4: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F2F8: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F2FC: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F300: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F304: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F308: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F30C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F310: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F314: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F318: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F31C: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259F320: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F324: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F328: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F32C: 409A0064  bne cr6, 0x8259f390
	if !ctx.cr[6].eq {
	pc = 0x8259F390; continue 'dispatch;
	}
	// 8259F330: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F334: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F338: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F33C: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F340: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F344: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F348: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F34C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F350: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F354: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F358: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F35C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F360: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F364: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F368: 40990028  ble cr6, 0x8259f390
	if !ctx.cr[6].gt {
	pc = 0x8259F390; continue 'dispatch;
	}
	// 8259F36C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F370: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F374: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F378: 41980018  blt cr6, 0x8259f390
	if ctx.cr[6].lt {
	pc = 0x8259F390; continue 'dispatch;
	}
	// 8259F37C: 4BFF220D  bl 0x82591588
	ctx.lr = 0x8259F380;
	sub_82591588(ctx, base);
	// 8259F380: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F384: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F388: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F38C: 4E800020  blr
	return;
	// 8259F390: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F394: 4BFF74E5  bl 0x82596878
	ctx.lr = 0x8259F398;
	sub_82596878(ctx, base);
	// 8259F398: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F39C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F3A0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F3A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F3A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F3A8 size=216
    let mut pc: u32 = 0x8259F3A8;
    'dispatch: loop {
        match pc {
            0x8259F3A8 => {
    //   block [0x8259F3A8..0x8259F480)
	// 8259F3A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F3AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F3B0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F3B4: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F3B8: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F3BC: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F3C0: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F3C4: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F3C8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F3CC: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F3D0: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F3D4: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F3D8: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F3DC: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F3E0: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F3E4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F3E8: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F3EC: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F3F0: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F3F4: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259F3F8: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F3FC: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F400: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F404: 409A0064  bne cr6, 0x8259f468
	if !ctx.cr[6].eq {
	pc = 0x8259F468; continue 'dispatch;
	}
	// 8259F408: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F40C: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F410: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F414: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F418: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F41C: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F420: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F424: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F428: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F42C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F430: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F434: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F438: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F43C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F440: 40990028  ble cr6, 0x8259f468
	if !ctx.cr[6].gt {
	pc = 0x8259F468; continue 'dispatch;
	}
	// 8259F444: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F448: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F44C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F450: 41980018  blt cr6, 0x8259f468
	if ctx.cr[6].lt {
	pc = 0x8259F468; continue 'dispatch;
	}
	// 8259F454: 4BFF240D  bl 0x82591860
	ctx.lr = 0x8259F458;
	sub_82591860(ctx, base);
	// 8259F458: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F45C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F460: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F464: 4E800020  blr
	return;
	// 8259F468: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F46C: 4BFF77A5  bl 0x82596c10
	ctx.lr = 0x8259F470;
	sub_82596C10(ctx, base);
	// 8259F470: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F474: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F478: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F47C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F480 size=216
    let mut pc: u32 = 0x8259F480;
    'dispatch: loop {
        match pc {
            0x8259F480 => {
    //   block [0x8259F480..0x8259F558)
	// 8259F480: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F484: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F488: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F48C: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F490: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F494: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F498: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F49C: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F4A0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F4A4: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F4A8: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F4AC: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F4B0: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F4B4: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F4B8: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F4BC: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F4C0: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F4C4: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F4C8: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F4CC: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259F4D0: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F4D4: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F4D8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F4DC: 409A0064  bne cr6, 0x8259f540
	if !ctx.cr[6].eq {
	pc = 0x8259F540; continue 'dispatch;
	}
	// 8259F4E0: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F4E4: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F4E8: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F4EC: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F4F0: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F4F4: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F4F8: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F4FC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F500: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F504: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F508: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F50C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F510: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F514: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F518: 40990028  ble cr6, 0x8259f540
	if !ctx.cr[6].gt {
	pc = 0x8259F540; continue 'dispatch;
	}
	// 8259F51C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F520: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F524: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F528: 41980018  blt cr6, 0x8259f540
	if ctx.cr[6].lt {
	pc = 0x8259F540; continue 'dispatch;
	}
	// 8259F52C: 4BFF26E5  bl 0x82591c10
	ctx.lr = 0x8259F530;
	sub_82591C10(ctx, base);
	// 8259F530: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F534: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F538: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F53C: 4E800020  blr
	return;
	// 8259F540: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F544: 4BFF7BA5  bl 0x825970e8
	ctx.lr = 0x8259F548;
	sub_825970E8(ctx, base);
	// 8259F548: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F54C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F550: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F554: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F558 size=220
    let mut pc: u32 = 0x8259F558;
    'dispatch: loop {
        match pc {
            0x8259F558 => {
    //   block [0x8259F558..0x8259F634)
	// 8259F558: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F55C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F560: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8259F564: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F568: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F56C: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F570: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F574: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F578: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F57C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F580: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F584: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F588: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F58C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F590: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F594: 83E70004  lwz r31, 4(r7)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F598: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F59C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F5A0: 7CCB2B78  or r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8259F5A4: 7C8AF850  subf r4, r10, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 8259F5A8: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F5AC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F5B0: 409A0068  bne cr6, 0x8259f618
	if !ctx.cr[6].eq {
	pc = 0x8259F618; continue 'dispatch;
	}
	// 8259F5B4: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F5B8: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F5BC: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F5C0: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F5C4: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F5C8: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F5CC: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F5D0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F5D4: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F5D8: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F5DC: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F5E0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F5E4: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F5E8: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F5EC: 4099002C  ble cr6, 0x8259f618
	if !ctx.cr[6].gt {
	pc = 0x8259F618; continue 'dispatch;
	}
	// 8259F5F0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F5F4: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F5F8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F5FC: 4198001C  blt cr6, 0x8259f618
	if ctx.cr[6].lt {
	pc = 0x8259F618; continue 'dispatch;
	}
	// 8259F600: 4BFF36B1  bl 0x82592cb0
	ctx.lr = 0x8259F604;
	sub_82592CB0(ctx, base);
	// 8259F604: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F608: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F60C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F610: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F614: 4E800020  blr
	return;
	// 8259F618: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F61C: 4BFF84A5  bl 0x82597ac0
	ctx.lr = 0x8259F620;
	sub_82597AC0(ctx, base);
	// 8259F620: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F624: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F628: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F62C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F630: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F638(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F638 size=220
    let mut pc: u32 = 0x8259F638;
    'dispatch: loop {
        match pc {
            0x8259F638 => {
    //   block [0x8259F638..0x8259F714)
	// 8259F638: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F63C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F640: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8259F644: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F648: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F64C: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F650: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F654: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F658: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F65C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F660: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F664: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F668: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F66C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F670: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F674: 83E70004  lwz r31, 4(r7)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F678: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F67C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F680: 7CCB2B78  or r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8259F684: 7C8AF850  subf r4, r10, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 8259F688: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F68C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F690: 409A0068  bne cr6, 0x8259f6f8
	if !ctx.cr[6].eq {
	pc = 0x8259F6F8; continue 'dispatch;
	}
	// 8259F694: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F698: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F69C: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F6A0: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F6A4: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F6A8: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F6AC: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F6B0: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F6B4: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F6B8: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F6BC: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F6C0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F6C4: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F6C8: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F6CC: 4099002C  ble cr6, 0x8259f6f8
	if !ctx.cr[6].gt {
	pc = 0x8259F6F8; continue 'dispatch;
	}
	// 8259F6D0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F6D4: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F6D8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F6DC: 4198001C  blt cr6, 0x8259f6f8
	if ctx.cr[6].lt {
	pc = 0x8259F6F8; continue 'dispatch;
	}
	// 8259F6E0: 4BFF38F9  bl 0x82592fd8
	ctx.lr = 0x8259F6E4;
	sub_82592FD8(ctx, base);
	// 8259F6E4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F6E8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F6EC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F6F0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F6F4: 4E800020  blr
	return;
	// 8259F6F8: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F6FC: 4BFF86FD  bl 0x82597df8
	ctx.lr = 0x8259F700;
	sub_82597DF8(ctx, base);
	// 8259F700: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F704: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F708: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F70C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F710: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F718(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F718 size=220
    let mut pc: u32 = 0x8259F718;
    'dispatch: loop {
        match pc {
            0x8259F718 => {
    //   block [0x8259F718..0x8259F7F4)
	// 8259F718: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F71C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F720: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8259F724: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F728: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F72C: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F730: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F734: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F738: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F73C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F740: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F744: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F748: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F74C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F750: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F754: 83E70004  lwz r31, 4(r7)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F758: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F75C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F760: 7CCB2B78  or r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8259F764: 7C8AF850  subf r4, r10, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 8259F768: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F76C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F770: 409A0068  bne cr6, 0x8259f7d8
	if !ctx.cr[6].eq {
	pc = 0x8259F7D8; continue 'dispatch;
	}
	// 8259F774: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F778: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F77C: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F780: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F784: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F788: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F78C: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F790: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F794: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F798: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F79C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F7A0: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F7A4: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F7A8: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F7AC: 4099002C  ble cr6, 0x8259f7d8
	if !ctx.cr[6].gt {
	pc = 0x8259F7D8; continue 'dispatch;
	}
	// 8259F7B0: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F7B4: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F7B8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F7BC: 4198001C  blt cr6, 0x8259f7d8
	if ctx.cr[6].lt {
	pc = 0x8259F7D8; continue 'dispatch;
	}
	// 8259F7C0: 4BFF3C11  bl 0x825933d0
	ctx.lr = 0x8259F7C4;
	sub_825933D0(ctx, base);
	// 8259F7C4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F7C8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F7CC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F7D0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F7D4: 4E800020  blr
	return;
	// 8259F7D8: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F7DC: 4BFF89FD  bl 0x825981d8
	ctx.lr = 0x8259F7E0;
	sub_825981D8(ctx, base);
	// 8259F7E0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F7E4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F7E8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F7EC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F7F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F7F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F7F8 size=220
    let mut pc: u32 = 0x8259F7F8;
    'dispatch: loop {
        match pc {
            0x8259F7F8 => {
    //   block [0x8259F7F8..0x8259F8D4)
	// 8259F7F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F7FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F800: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8259F804: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F808: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F80C: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F810: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F814: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F818: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F81C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F820: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F824: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F828: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F82C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F830: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F834: 83E70004  lwz r31, 4(r7)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F838: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F83C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F840: 7CCB2B78  or r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8259F844: 7C8AF850  subf r4, r10, r31
	ctx.r[4].s64 = ctx.r[31].s64 - ctx.r[10].s64;
	// 8259F848: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F84C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F850: 409A0068  bne cr6, 0x8259f8b8
	if !ctx.cr[6].eq {
	pc = 0x8259F8B8; continue 'dispatch;
	}
	// 8259F854: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F858: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F85C: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F860: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F864: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F868: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F86C: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F870: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F874: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F878: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F87C: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F880: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F884: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F888: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F88C: 4099002C  ble cr6, 0x8259f8b8
	if !ctx.cr[6].gt {
	pc = 0x8259F8B8; continue 'dispatch;
	}
	// 8259F890: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F894: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F898: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F89C: 4198001C  blt cr6, 0x8259f8b8
	if ctx.cr[6].lt {
	pc = 0x8259F8B8; continue 'dispatch;
	}
	// 8259F8A0: 4BFF40C1  bl 0x82593960
	ctx.lr = 0x8259F8A4;
	sub_82593960(ctx, base);
	// 8259F8A4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F8A8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F8AC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F8B0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F8B4: 4E800020  blr
	return;
	// 8259F8B8: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F8BC: 4BFF8E55  bl 0x82598710
	ctx.lr = 0x8259F8C0;
	sub_82598710(ctx, base);
	// 8259F8C0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F8C4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F8C8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F8CC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8259F8D0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F8D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F8D8 size=216
    let mut pc: u32 = 0x8259F8D8;
    'dispatch: loop {
        match pc {
            0x8259F8D8 => {
    //   block [0x8259F8D8..0x8259F9B0)
	// 8259F8D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F8DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F8E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F8E4: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F8E8: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F8EC: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F8F0: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F8F4: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F8F8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F8FC: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F900: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F904: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F908: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F90C: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F910: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F914: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F918: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F91C: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F920: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F924: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259F928: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259F92C: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259F930: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259F934: 409A0064  bne cr6, 0x8259f998
	if !ctx.cr[6].eq {
	pc = 0x8259F998; continue 'dispatch;
	}
	// 8259F938: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259F93C: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F940: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259F944: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259F948: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259F94C: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259F950: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259F954: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259F958: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259F95C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259F960: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259F964: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259F968: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259F96C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259F970: 40990028  ble cr6, 0x8259f998
	if !ctx.cr[6].gt {
	pc = 0x8259F998; continue 'dispatch;
	}
	// 8259F974: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259F978: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259F97C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259F980: 41980018  blt cr6, 0x8259f998
	if ctx.cr[6].lt {
	pc = 0x8259F998; continue 'dispatch;
	}
	// 8259F984: 4BFF4785  bl 0x82594108
	ctx.lr = 0x8259F988;
	sub_82594108(ctx, base);
	// 8259F988: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F98C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F990: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F994: 4E800020  blr
	return;
	// 8259F998: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259F99C: 4BFF97DD  bl 0x82599178
	ctx.lr = 0x8259F9A0;
	sub_82599178(ctx, base);
	// 8259F9A0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259F9A4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259F9A8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259F9AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259F9B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259F9B0 size=216
    let mut pc: u32 = 0x8259F9B0;
    'dispatch: loop {
        match pc {
            0x8259F9B0 => {
    //   block [0x8259F9B0..0x8259FA88)
	// 8259F9B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259F9B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259F9B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259F9BC: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259F9C0: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259F9C4: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259F9C8: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259F9CC: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259F9D0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259F9D4: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259F9D8: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259F9DC: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259F9E0: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259F9E4: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259F9E8: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259F9EC: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259F9F0: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259F9F4: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259F9F8: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259F9FC: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259FA00: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259FA04: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259FA08: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259FA0C: 409A0064  bne cr6, 0x8259fa70
	if !ctx.cr[6].eq {
	pc = 0x8259FA70; continue 'dispatch;
	}
	// 8259FA10: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259FA14: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FA18: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259FA1C: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259FA20: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259FA24: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259FA28: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259FA2C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259FA30: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259FA34: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259FA38: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259FA3C: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259FA40: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259FA44: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259FA48: 40990028  ble cr6, 0x8259fa70
	if !ctx.cr[6].gt {
	pc = 0x8259FA70; continue 'dispatch;
	}
	// 8259FA4C: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259FA50: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FA54: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259FA58: 41980018  blt cr6, 0x8259fa70
	if ctx.cr[6].lt {
	pc = 0x8259FA70; continue 'dispatch;
	}
	// 8259FA5C: 4BFF493D  bl 0x82594398
	ctx.lr = 0x8259FA60;
	sub_82594398(ctx, base);
	// 8259FA60: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FA64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FA68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FA6C: 4E800020  blr
	return;
	// 8259FA70: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259FA74: 4BFF9A35  bl 0x825994a8
	ctx.lr = 0x8259FA78;
	sub_825994A8(ctx, base);
	// 8259FA78: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FA7C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FA80: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FA84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259FA88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259FA88 size=216
    let mut pc: u32 = 0x8259FA88;
    'dispatch: loop {
        match pc {
            0x8259FA88 => {
    //   block [0x8259FA88..0x8259FB60)
	// 8259FA88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259FA8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259FA90: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259FA94: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259FA98: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259FA9C: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259FAA0: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259FAA4: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259FAA8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259FAAC: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259FAB0: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259FAB4: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259FAB8: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259FABC: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259FAC0: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259FAC4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259FAC8: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259FACC: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259FAD0: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259FAD4: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259FAD8: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259FADC: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259FAE0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259FAE4: 409A0064  bne cr6, 0x8259fb48
	if !ctx.cr[6].eq {
	pc = 0x8259FB48; continue 'dispatch;
	}
	// 8259FAE8: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259FAEC: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FAF0: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259FAF4: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259FAF8: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259FAFC: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259FB00: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259FB04: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259FB08: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259FB0C: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259FB10: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259FB14: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259FB18: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259FB1C: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259FB20: 40990028  ble cr6, 0x8259fb48
	if !ctx.cr[6].gt {
	pc = 0x8259FB48; continue 'dispatch;
	}
	// 8259FB24: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259FB28: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FB2C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259FB30: 41980018  blt cr6, 0x8259fb48
	if ctx.cr[6].lt {
	pc = 0x8259FB48; continue 'dispatch;
	}
	// 8259FB34: 4BFF4B5D  bl 0x82594690
	ctx.lr = 0x8259FB38;
	sub_82594690(ctx, base);
	// 8259FB38: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FB3C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FB40: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FB44: 4E800020  blr
	return;
	// 8259FB48: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259FB4C: 4BFF9D25  bl 0x82599870
	ctx.lr = 0x8259FB50;
	sub_82599870(ctx, base);
	// 8259FB50: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FB54: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FB58: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FB5C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259FB60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259FB60 size=216
    let mut pc: u32 = 0x8259FB60;
    'dispatch: loop {
        match pc {
            0x8259FB60 => {
    //   block [0x8259FB60..0x8259FC38)
	// 8259FB60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259FB64: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8259FB68: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259FB6C: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8259FB70: 8167001C  lwz r11, 0x1c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259FB74: C1A70030  lfs f13, 0x30(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259FB78: 80C70018  lwz r6, 0x18(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259FB7C: 81470008  lwz r10, 8(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259FB80: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259FB84: 8887000D  lbz r4, 0xd(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259FB88: 7CCB3050  subf r6, r11, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8259FB8C: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259FB90: 7D6451D6  mullw r11, r4, r10
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8259FB94: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259FB98: 81270014  lwz r9, 0x14(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259FB9C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259FBA0: 7C8A1850  subf r4, r10, r3
	ctx.r[4].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 8259FBA4: 7C6B4214  add r3, r11, r8
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8259FBA8: 7CA54A14  add r5, r5, r9
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[9].u64;
	// 8259FBAC: 54CB077E  clrlwi r11, r6, 0x1d
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x00000007u64;
	// 8259FBB0: 7D6B2B78  or r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[5].u64;
	// 8259FBB4: 556B073E  clrlwi r11, r11, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000000Fu64;
	// 8259FBB8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8259FBBC: 409A0064  bne cr6, 0x8259fc20
	if !ctx.cr[6].eq {
	pc = 0x8259FC20; continue 'dispatch;
	}
	// 8259FBC0: 7CCB07B4  extsw r11, r6
	ctx.r[11].s64 = ctx.r[6].s32 as i64;
	// 8259FBC4: C007002C  lfs f0, 0x2c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FBC8: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 8259FBCC: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 8259FBD0: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8259FBD4: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259FBD8: C9810050  lfd f12, 0x50(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8259FBDC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259FBE0: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259FBE4: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 8259FBE8: FD806018  frsp f12, f12
	ctx.f[12].f64 = (ctx.f[12].f64 as f32) as f64;
	// 8259FBEC: FD605818  frsp f11, f11
	ctx.f[11].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8259FBF0: EC006B3A  fmadds f0, f0, f12, f13
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 8259FBF4: FF0B0000  fcmpu cr6, f11, f0
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[0].f64);
	// 8259FBF8: 40990028  ble cr6, 0x8259fc20
	if !ctx.cr[6].gt {
	pc = 0x8259FC20; continue 'dispatch;
	}
	// 8259FBFC: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 8259FC00: C00B1FF8  lfs f0, 0x1ff8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8184 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FC04: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8259FC08: 41980018  blt cr6, 0x8259fc20
	if ctx.cr[6].lt {
	pc = 0x8259FC20; continue 'dispatch;
	}
	// 8259FC0C: 4BFF4E4D  bl 0x82594a58
	ctx.lr = 0x8259FC10;
	sub_82594A58(ctx, base);
	// 8259FC10: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FC14: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FC18: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FC1C: 4E800020  blr
	return;
	// 8259FC20: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8259FC24: 4BFFA185  bl 0x82599da8
	ctx.lr = 0x8259FC28;
	sub_82599DA8(ctx, base);
	// 8259FC28: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8259FC2C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8259FC30: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8259FC34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259FC38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259FC38 size=452
    let mut pc: u32 = 0x8259FC38;
    'dispatch: loop {
        match pc {
            0x8259FC38 => {
    //   block [0x8259FC38..0x8259FDFC)
	// 8259FC38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259FC3C: 4BF9547D  bl 0x825350b8
	ctx.lr = 0x8259FC40;
	sub_82535080(ctx, base);
	// 8259FC40: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259FC44: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259FC48: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259FC4C: 8BE3000D  lbz r31, 0xd(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259FC50: 7D2B2850  subf r9, r11, r5
	ctx.r[9].s64 = ctx.r[5].s64 - ctx.r[11].s64;
	// 8259FC54: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259FC58: 83C30018  lwz r30, 0x18(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259FC5C: 7D7F59D6  mullw r11, r31, r11
	ctx.r[11].s64 = (ctx.r[31].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259FC60: 80830000  lwz r4, 0(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259FC64: 83A30014  lwz r29, 0x14(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259FC68: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259FC6C: 7CEAF050  subf r7, r10, r30
	ctx.r[7].s64 = ctx.r[30].s64 - ctx.r[10].s64;
	// 8259FC70: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259FC74: 7D08EA14  add r8, r8, r29
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[29].u64;
	// 8259FC78: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8259FC7C: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 8259FC80: 41980008  blt cr6, 0x8259fc88
	if ctx.cr[6].lt {
	pc = 0x8259FC88; continue 'dispatch;
	}
	// 8259FC84: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 8259FC88: 552A077E  clrlwi r10, r9, 0x1d
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x00000007u64;
	// 8259FC8C: 7D4A4378  or r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[8].u64;
	// 8259FC90: 7D4A5B78  or r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[11].u64;
	// 8259FC94: 554A073E  clrlwi r10, r10, 0x1c
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000000Fu64;
	// 8259FC98: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8259FC9C: 419A0010  beq cr6, 0x8259fcac
	if ctx.cr[6].eq {
	pc = 0x8259FCAC; continue 'dispatch;
	}
	// 8259FCA0: 4BFFA8B9  bl 0x8259a558
	ctx.lr = 0x8259FCA4;
	sub_8259A558(ctx, base);
	// 8259FCA4: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8259FCA8: 4BF95460  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 8259FCAC: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259FCB0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8259FCB4: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259FCB8: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259FCBC: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259FCC0: 419A0018  beq cr6, 0x8259fcd8
	if ctx.cr[6].eq {
	pc = 0x8259FCD8; continue 'dispatch;
	}
	// 8259FCC4: 555C3830  slwi r28, r10, 7
	ctx.r[28].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 8259FCC8: 7C1C5A2C  dcbt r28, r11
	// 8259FCCC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8259FCD0: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259FCD4: 4198FFF0  blt cr6, 0x8259fcc4
	if ctx.cr[6].lt {
	pc = 0x8259FCC4; continue 'dispatch;
	}
	// 8259FCD8: 7CEA07B4  extsw r10, r7
	ctx.r[10].s64 = ctx.r[7].s32 as i64;
	// 8259FCDC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FCE0: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259FCE4: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259FCE8: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259FCEC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8259FCF0: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 8259FCF4: 3B810058  addi r28, r1, 0x58
	ctx.r[28].s64 = ctx.r[1].s64 + 88;
	// 8259FCF8: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 8259FCFC: C9810058  lfd f12, 0x58(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259FD00: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259FD04: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 8259FD08: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 8259FD0C: F8E10060  std r7, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[7].u64 ) };
	// 8259FD10: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8259FE00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8259FE00 size=536
    let mut pc: u32 = 0x8259FE00;
    'dispatch: loop {
        match pc {
            0x8259FE00 => {
    //   block [0x8259FE00..0x825A0018)
	// 8259FE00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8259FE04: 4BF952A9  bl 0x825350ac
	ctx.lr = 0x8259FE08;
	sub_82535080(ctx, base);
	// 8259FE08: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8259FE0C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8259FE10: 83A30004  lwz r29, 4(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8259FE14: 8B63000D  lbz r27, 0xd(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 8259FE18: 7D2BE850  subf r9, r11, r29
	ctx.r[9].s64 = ctx.r[29].s64 - ctx.r[11].s64;
	// 8259FE1C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8259FE20: 83430018  lwz r26, 0x18(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8259FE24: 7D7B59D6  mullw r11, r27, r11
	ctx.r[11].s64 = (ctx.r[27].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8259FE28: 83830000  lwz r28, 0(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8259FE2C: 83230014  lwz r25, 0x14(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8259FE30: 7CEAD050  subf r7, r10, r26
	ctx.r[7].s64 = ctx.r[26].s64 - ctx.r[10].s64;
	// 8259FE34: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8259FE38: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8259FE3C: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8259FE40: 7D48CA14  add r10, r8, r25
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[25].u64;
	// 8259FE44: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8259FE48: 41980008  blt cr6, 0x8259fe50
	if ctx.cr[6].lt {
	pc = 0x8259FE50; continue 'dispatch;
	}
	// 8259FE4C: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 8259FE50: 5528077E  clrlwi r8, r9, 0x1d
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x00000007u64;
	// 8259FE54: 7D085378  or r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[10].u64;
	// 8259FE58: 7D085B78  or r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[11].u64;
	// 8259FE5C: 5508073E  clrlwi r8, r8, 0x1c
	ctx.r[8].u64 = ctx.r[8].u32 as u64 & 0x0000000Fu64;
	// 8259FE60: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8259FE64: 419A0010  beq cr6, 0x8259fe74
	if ctx.cr[6].eq {
	pc = 0x8259FE74; continue 'dispatch;
	}
	// 8259FE68: 4BFFA801  bl 0x8259a668
	ctx.lr = 0x8259FE6C;
	sub_8259A668(ctx, base);
	// 8259FE6C: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8259FE70: 4BF9528C  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
	// 8259FE74: 55261838  slwi r6, r9, 3
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259FE78: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8259FE7C: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 8259FE80: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8259FE84: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8259FE88: 419A0018  beq cr6, 0x8259fea0
	if ctx.cr[6].eq {
	pc = 0x8259FEA0; continue 'dispatch;
	}
	// 8259FE8C: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8259FE90: 7C055A2C  dcbt r5, r11
	// 8259FE94: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 8259FE98: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8259FE9C: 4198FFF0  blt cr6, 0x8259fe8c
	if ctx.cr[6].lt {
	pc = 0x8259FE8C; continue 'dispatch;
	}
	// 8259FEA0: 7CE807B4  extsw r8, r7
	ctx.r[8].s64 = ctx.r[7].s32 as i64;
	// 8259FEA4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8259FEA8: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8259FEAC: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8259FEB0: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 8259FEB4: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8259FEB8: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 8259FEBC: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8259FEC0: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 8259FEC4: C9810058  lfd f12, 0x58(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 8259FEC8: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 8259FECC: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 8259FED0: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 8259FED4: F8E10060  std r7, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[7].u64 ) };
	// 8259FED8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0018(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0018 size=840
    let mut pc: u32 = 0x825A0018;
    'dispatch: loop {
        match pc {
            0x825A0018 => {
    //   block [0x825A0018..0x825A0360)
	// 825A0018: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A001C: 4BF95065  bl 0x82535080
	ctx.lr = 0x825A0020;
	sub_82535080(ctx, base);
	// 825A0020: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A0024: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0028: 81030004  lwz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A002C: 88A3000D  lbz r5, 0xd(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0030: 7D0B4050  subf r8, r11, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 825A0034: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A0038: 7D6559D6  mullw r11, r5, r11
	ctx.r[11].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825A003C: 80C30018  lwz r6, 0x18(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A0040: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A0044: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A0048: 90610114  stw r3, 0x114(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), ctx.r[3].u32 ) };
	// 825A004C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A0050: 5544103A  slwi r4, r10, 2
	ctx.r[4].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 825A0054: 7CCA3050  subf r6, r10, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 825A0058: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 825A005C: 7CE43A14  add r7, r4, r7
	ctx.r[7].u64 = ctx.r[4].u64 + ctx.r[7].u64;
	// 825A0060: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 825A0064: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 825A0068: 41980008  blt cr6, 0x825a0070
	if ctx.cr[6].lt {
	pc = 0x825A0070; continue 'dispatch;
	}
	// 825A006C: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 825A0070: 556A077E  clrlwi r10, r11, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 825A0074: 7D4A3B78  or r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[7].u64;
	// 825A0078: 7D4A4B78  or r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 825A007C: 554A073E  clrlwi r10, r10, 0x1c
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000000Fu64;
	// 825A0080: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A0084: 419A0010  beq cr6, 0x825a0094
	if ctx.cr[6].eq {
	pc = 0x825A0094; continue 'dispatch;
	}
	// 825A0088: 4BFFA839  bl 0x8259a8c0
	ctx.lr = 0x825A008C;
	sub_8259A8C0(ctx, base);
	// 825A008C: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 825A0090: 4BF95040  b 0x825350d0
	sub_825350D0(ctx, base);
	return;
	// 825A0094: 5568083C  slwi r8, r11, 1
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0098: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A009C: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 825A00A0: 55081838  slwi r8, r8, 3
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A00A4: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 825A00A8: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A00AC: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 825A00B0: 419A0018  beq cr6, 0x825a00c8
	if ctx.cr[6].eq {
	pc = 0x825A00C8; continue 'dispatch;
	}
	// 825A00B4: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A00B8: 7C054A2C  dcbt r5, r9
	// 825A00BC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 825A00C0: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A00C4: 4198FFF0  blt cr6, 0x825a00b4
	if ctx.cr[6].lt {
	pc = 0x825A00B4; continue 'dispatch;
	}
	// 825A00C8: 5568083C  slwi r8, r11, 1
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A00CC: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A00D0: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 825A00D4: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A00D8: 7D0807B4  extsw r8, r8
	ctx.r[8].s64 = ctx.r[8].s32 as i64;
	// 825A00DC: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A00E0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A00E4: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A00E8: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 825A00EC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A00F0: F9410058  std r10, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u64 ) };
	// 825A00F4: C9810058  lfd f12, 0x58(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825A00F8: F9010060  std r8, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u64 ) };
	// 825A00FC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 825A0100: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0360(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0360 size=528
    let mut pc: u32 = 0x825A0360;
    'dispatch: loop {
        match pc {
            0x825A0360 => {
    //   block [0x825A0360..0x825A0570)
	// 825A0360: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0364: 4BF94D51  bl 0x825350b4
	ctx.lr = 0x825A0368;
	sub_82535080(ctx, base);
	// 825A0368: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A036C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0370: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A0374: 8BC3000D  lbz r30, 0xd(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0378: 7D2B2050  subf r9, r11, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 825A037C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A0380: 7D7E59D6  mullw r11, r30, r11
	ctx.r[11].s64 = (ctx.r[30].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825A0384: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A0388: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A038C: 83830014  lwz r28, 0x14(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A0390: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A0394: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0398: 7CEAE850  subf r7, r10, r29
	ctx.r[7].s64 = ctx.r[29].s64 - ctx.r[10].s64;
	// 825A039C: 7D4BFA14  add r10, r11, r31
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 825A03A0: 7D68E214  add r11, r8, r28
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[28].u64;
	// 825A03A4: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 825A03A8: 41980008  blt cr6, 0x825a03b0
	if ctx.cr[6].lt {
	pc = 0x825A03B0; continue 'dispatch;
	}
	// 825A03AC: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 825A03B0: 7D285B78  or r8, r9, r11
	ctx.r[8].u64 = ctx.r[9].u64 | ctx.r[11].u64;
	// 825A03B4: 7D085378  or r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[10].u64;
	// 825A03B8: 5508073E  clrlwi r8, r8, 0x1c
	ctx.r[8].u64 = ctx.r[8].u32 as u64 & 0x0000000Fu64;
	// 825A03BC: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 825A03C0: 419A0010  beq cr6, 0x825a03d0
	if ctx.cr[6].eq {
	pc = 0x825A03D0; continue 'dispatch;
	}
	// 825A03C4: 4BFFA78D  bl 0x8259ab50
	ctx.lr = 0x825A03C8;
	sub_8259AB50(ctx, base);
	// 825A03C8: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 825A03CC: 4BF94D38  b 0x82535104
	sub_825350D0(ctx, base);
	return;
	// 825A03D0: 5525083C  slwi r5, r9, 1
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A03D4: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 825A03D8: 38C5007F  addi r6, r5, 0x7f
	ctx.r[6].s64 = ctx.r[5].s64 + 127;
	// 825A03DC: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A03E0: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 825A03E4: 419A0018  beq cr6, 0x825a03fc
	if ctx.cr[6].eq {
	pc = 0x825A03FC; continue 'dispatch;
	}
	// 825A03E8: 551B3830  slwi r27, r8, 7
	ctx.r[27].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 825A03EC: 7C1B522C  dcbt r27, r10
	// 825A03F0: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 825A03F4: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 825A03F8: 4198FFF0  blt cr6, 0x825a03e8
	if ctx.cr[6].lt {
	pc = 0x825A03E8; continue 'dispatch;
	}
	// 825A03FC: 7CE807B4  extsw r8, r7
	ctx.r[8].s64 = ctx.r[7].s32 as i64;
	// 825A0400: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0404: 7CA707B4  extsw r7, r5
	ctx.r[7].s64 = ctx.r[5].s32 as i64;
	// 825A0408: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A040C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A0410: 3B610058  addi r27, r1, 0x58
	ctx.r[27].s64 = ctx.r[1].s64 + 88;
	// 825A0414: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A0418: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A041C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A0420: F9010058  std r8, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[8].u64 ) };
	// 825A0424: C9810058  lfd f12, 0x58(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825A0428: F8E10060  std r7, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[7].u64 ) };
	// 825A042C: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 825A0430: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0570(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0570 size=528
    let mut pc: u32 = 0x825A0570;
    'dispatch: loop {
        match pc {
            0x825A0570 => {
    //   block [0x825A0570..0x825A0780)
	// 825A0570: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0574: 4BF94B45  bl 0x825350b8
	ctx.lr = 0x825A0578;
	sub_82535080(ctx, base);
	// 825A0578: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A057C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0580: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A0584: 8BC3000D  lbz r30, 0xd(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0588: 7D2B2050  subf r9, r11, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 825A058C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A0590: 7D7E59D6  mullw r11, r30, r11
	ctx.r[11].s64 = (ctx.r[30].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825A0594: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A0598: 83E30000  lwz r31, 0(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A059C: 83830014  lwz r28, 0x14(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A05A0: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A05A4: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A05A8: 7CEAE850  subf r7, r10, r29
	ctx.r[7].s64 = ctx.r[29].s64 - ctx.r[10].s64;
	// 825A05AC: 7D4BFA14  add r10, r11, r31
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 825A05B0: 7D68E214  add r11, r8, r28
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[28].u64;
	// 825A05B4: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 825A05B8: 41980008  blt cr6, 0x825a05c0
	if ctx.cr[6].lt {
	pc = 0x825A05C0; continue 'dispatch;
	}
	// 825A05BC: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 825A05C0: 5528077E  clrlwi r8, r9, 0x1d
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x00000007u64;
	// 825A05C4: 7D085B78  or r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[11].u64;
	// 825A05C8: 7D085378  or r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[10].u64;
	// 825A05CC: 5508073E  clrlwi r8, r8, 0x1c
	ctx.r[8].u64 = ctx.r[8].u32 as u64 & 0x0000000Fu64;
	// 825A05D0: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 825A05D4: 419A0010  beq cr6, 0x825a05e4
	if ctx.cr[6].eq {
	pc = 0x825A05E4; continue 'dispatch;
	}
	// 825A05D8: 4BFFA6A9  bl 0x8259ac80
	ctx.lr = 0x825A05DC;
	sub_8259AC80(ctx, base);
	// 825A05DC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A05E0: 4BF94B28  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 825A05E4: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A05E8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 825A05EC: 38C6007F  addi r6, r6, 0x7f
	ctx.r[6].s64 = ctx.r[6].s64 + 127;
	// 825A05F0: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A05F4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 825A05F8: 419A0018  beq cr6, 0x825a0610
	if ctx.cr[6].eq {
	pc = 0x825A0610; continue 'dispatch;
	}
	// 825A05FC: 55053830  slwi r5, r8, 7
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A0600: 7C05522C  dcbt r5, r10
	// 825A0604: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 825A0608: 7F083040  cmplw cr6, r8, r6
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[6].u32, &mut ctx.xer);
	// 825A060C: 4198FFF0  blt cr6, 0x825a05fc
	if ctx.cr[6].lt {
	pc = 0x825A05FC; continue 'dispatch;
	}
	// 825A0610: 7CE807B4  extsw r8, r7
	ctx.r[8].s64 = ctx.r[7].s32 as i64;
	// 825A0614: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0618: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A061C: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A0620: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A0624: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A0628: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 825A062C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A0630: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A0634: F9010060  std r8, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u64 ) };
	// 825A0638: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 825A063C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0780(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0780 size=852
    let mut pc: u32 = 0x825A0780;
    'dispatch: loop {
        match pc {
            0x825A0780 => {
    //   block [0x825A0780..0x825A0AD4)
	// 825A0780: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0784: 4BF948FD  bl 0x82535080
	ctx.lr = 0x825A0788;
	sub_82535080(ctx, base);
	// 825A0788: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A078C: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0790: 81E30004  lwz r15, 4(r3)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A0794: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0798: 7D0B7850  subf r8, r11, r15
	ctx.r[8].s64 = ctx.r[15].s64 - ctx.r[11].s64;
	// 825A079C: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A07A0: 7D6459D6  mullw r11, r4, r11
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825A07A4: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A07A8: 81C30000  lwz r14, 0(r3)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A07AC: 80A30014  lwz r5, 0x14(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A07B0: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A07B4: 7CCA4850  subf r6, r10, r9
	ctx.r[6].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 825A07B8: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A07BC: 7D2B7214  add r9, r11, r14
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[14].u64;
	// 825A07C0: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 825A07C4: 7CE72A14  add r7, r7, r5
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 825A07C8: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 825A07CC: 41980008  blt cr6, 0x825a07d4
	if ctx.cr[6].lt {
	pc = 0x825A07D4; continue 'dispatch;
	}
	// 825A07D0: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 825A07D4: 556A077E  clrlwi r10, r11, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 825A07D8: 7D4A3B78  or r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[7].u64;
	// 825A07DC: 7D4A4B78  or r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 825A07E0: 554A073E  clrlwi r10, r10, 0x1c
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000000Fu64;
	// 825A07E4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A07E8: 419A0010  beq cr6, 0x825a07f8
	if ctx.cr[6].eq {
	pc = 0x825A07F8; continue 'dispatch;
	}
	// 825A07EC: 4BFFA78D  bl 0x8259af78
	ctx.lr = 0x825A07F0;
	sub_8259AF78(ctx, base);
	// 825A07F0: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 825A07F4: 4BF948DC  b 0x825350d0
	sub_825350D0(ctx, base);
	return;
	// 825A07F8: 5568083C  slwi r8, r11, 1
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A07FC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A0800: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 825A0804: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0808: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 825A080C: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0810: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 825A0814: 419A0018  beq cr6, 0x825a082c
	if ctx.cr[6].eq {
	pc = 0x825A082C; continue 'dispatch;
	}
	// 825A0818: 55453830  slwi r5, r10, 7
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A081C: 7C054A2C  dcbt r5, r9
	// 825A0820: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 825A0824: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A0828: 4198FFF0  blt cr6, 0x825a0818
	if ctx.cr[6].lt {
	pc = 0x825A0818; continue 'dispatch;
	}
	// 825A082C: 7CCA07B4  extsw r10, r6
	ctx.r[10].s64 = ctx.r[6].s32 as i64;
	// 825A0830: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0834: 5568083C  slwi r8, r11, 1
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0838: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A083C: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A0840: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A0844: 7D0807B4  extsw r8, r8
	ctx.r[8].s64 = ctx.r[8].s32 as i64;
	// 825A0848: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A084C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A0850: F9410060  std r10, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u64 ) };
	// 825A0854: 39410058  addi r10, r1, 0x58
	ctx.r[10].s64 = ctx.r[1].s64 + 88;
	// 825A0858: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0AD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0AD8 size=688
    let mut pc: u32 = 0x825A0AD8;
    'dispatch: loop {
        match pc {
            0x825A0AD8 => {
    //   block [0x825A0AD8..0x825A0D88)
	// 825A0AD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0ADC: 4BF945D1  bl 0x825350ac
	ctx.lr = 0x825A0AE0;
	sub_82535080(ctx, base);
	// 825A0AE0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A0AE4: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0AE8: 83A30004  lwz r29, 4(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A0AEC: 8B63000D  lbz r27, 0xd(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0AF0: 8143001C  lwz r10, 0x1c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A0AF4: 7D2BE850  subf r9, r11, r29
	ctx.r[9].s64 = ctx.r[29].s64 - ctx.r[11].s64;
	// 825A0AF8: 83430018  lwz r26, 0x18(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A0AFC: 7D7B59D6  mullw r11, r27, r11
	ctx.r[11].s64 = (ctx.r[27].s32 as i64) * (ctx.r[11].s32 as i64);
	// 825A0B00: 83830000  lwz r28, 0(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A0B04: 83230014  lwz r25, 0x14(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A0B08: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0B0C: 7CEAD050  subf r7, r10, r26
	ctx.r[7].s64 = ctx.r[26].s64 - ctx.r[10].s64;
	// 825A0B10: 7D4BE214  add r10, r11, r28
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 825A0B14: 7D08CA14  add r8, r8, r25
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[25].u64;
	// 825A0B18: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 825A0B1C: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 825A0B20: 41980008  blt cr6, 0x825a0b28
	if ctx.cr[6].lt {
	pc = 0x825A0B28; continue 'dispatch;
	}
	// 825A0B24: 7CEB3B78  mr r11, r7
	ctx.r[11].u64 = ctx.r[7].u64;
	// 825A0B28: 7D095378  or r9, r8, r10
	ctx.r[9].u64 = ctx.r[8].u64 | ctx.r[10].u64;
	// 825A0B2C: 5529073E  clrlwi r9, r9, 0x1c
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x0000000Fu64;
	// 825A0B30: 7D295B78  or r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 | ctx.r[11].u64;
	// 825A0B34: 552906FE  clrlwi r9, r9, 0x1b
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x0000001Fu64;
	// 825A0B38: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 825A0B3C: 419A0010  beq cr6, 0x825a0b4c
	if ctx.cr[6].eq {
	pc = 0x825A0B4C; continue 'dispatch;
	}
	// 825A0B40: 4BFFA751  bl 0x8259b290
	ctx.lr = 0x825A0B44;
	sub_8259B290(ctx, base);
	// 825A0B44: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 825A0B48: 4BF945B4  b 0x825350fc
	sub_825350D0(ctx, base);
	return;
	// 825A0B4C: 38CB007F  addi r6, r11, 0x7f
	ctx.r[6].s64 = ctx.r[11].s64 + 127;
	// 825A0B50: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 825A0B54: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A0B58: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 825A0B5C: 419A0018  beq cr6, 0x825a0b74
	if ctx.cr[6].eq {
	pc = 0x825A0B74; continue 'dispatch;
	}
	// 825A0B60: 55253830  slwi r5, r9, 7
	ctx.r[5].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A0B64: 7C05522C  dcbt r5, r10
	// 825A0B68: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 825A0B6C: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 825A0B70: 4198FFF0  blt cr6, 0x825a0b60
	if ctx.cr[6].lt {
	pc = 0x825A0B60; continue 'dispatch;
	}
	// 825A0B74: 7CE907B4  extsw r9, r7
	ctx.r[9].s64 = ctx.r[7].s32 as i64;
	// 825A0B78: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0B7C: 5567083C  slwi r7, r11, 1
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A0B80: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A0B84: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A0B88: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A0B8C: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 825A0B90: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A0B94: F9210060  std r9, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u64 ) };
	// 825A0B98: 39210058  addi r9, r1, 0x58
	ctx.r[9].s64 = ctx.r[1].s64 + 88;
	// 825A0B9C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A0BA0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A0BA4: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 825A0BA8: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825A0BAC: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0D88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0D88 size=620
    let mut pc: u32 = 0x825A0D88;
    'dispatch: loop {
        match pc {
            0x825A0D88 => {
    //   block [0x825A0D88..0x825A0FF4)
	// 825A0D88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0D8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A0D90: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A0D94: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A0D98: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A0D9C: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A0DA0: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A0DA4: 5567103A  slwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A0DA8: 80830004  lwz r4, 4(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A0DAC: 7CAB4850  subf r5, r11, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 825A0DB0: 8BE3000D  lbz r31, 0xd(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A0DB4: 7D2A2050  subf r9, r10, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[10].s64;
	// 825A0DB8: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A0DBC: 7D7F51D6  mullw r11, r31, r10
	ctx.r[11].s64 = (ctx.r[31].s32 as i64) * (ctx.r[10].s32 as i64);
	// 825A0DC0: 80C30014  lwz r6, 0x14(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A0DC4: 7CAA0E70  srawi r10, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[10].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 825A0DC8: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A0DCC: 7D4A0194  addze r10, r10
	tmp.s64 = ctx.r[10].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[10].u32);
	ctx.r[10].s64 = tmp.s64;
	// 825A0DD0: 7CE73214  add r7, r7, r6
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 825A0DD4: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 825A0DD8: 7F095000  cmpw cr6, r9, r10
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[10].s32, &mut ctx.xer);
	// 825A0DDC: 41980008  blt cr6, 0x825a0de4
	if ctx.cr[6].lt {
	pc = 0x825A0DE4; continue 'dispatch;
	}
	// 825A0DE0: 7D495378  mr r9, r10
	ctx.r[9].u64 = ctx.r[10].u64;
	// 825A0DE4: 552A07BE  clrlwi r10, r9, 0x1e
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x00000003u64;
	// 825A0DE8: 7D4A3B78  or r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[7].u64;
	// 825A0DEC: 7D4A5B78  or r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[11].u64;
	// 825A0DF0: 554A073E  clrlwi r10, r10, 0x1c
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000000Fu64;
	// 825A0DF4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A0DF8: 419A001C  beq cr6, 0x825a0e14
	if ctx.cr[6].eq {
	pc = 0x825A0E14; continue 'dispatch;
	}
	// 825A0DFC: 4BFFB40D  bl 0x8259c208
	ctx.lr = 0x825A0E00;
	sub_8259C208(ctx, base);
	// 825A0E00: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 825A0E04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A0E08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A0E0C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A0E10: 4E800020  blr
	return;
	// 825A0E14: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0E18: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A0E1C: 3908007F  addi r8, r8, 0x7f
	ctx.r[8].s64 = ctx.r[8].s64 + 127;
	// 825A0E20: 5508C9FE  srwi r8, r8, 7
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(7);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 825A0E24: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 825A0E28: 419A0018  beq cr6, 0x825a0e40
	if ctx.cr[6].eq {
	pc = 0x825A0E40; continue 'dispatch;
	}
	// 825A0E2C: 55463830  slwi r6, r10, 7
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A0E30: 7C065A2C  dcbt r6, r11
	// 825A0E34: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 825A0E38: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A0E3C: 4198FFF0  blt cr6, 0x825a0e2c
	if ctx.cr[6].lt {
	pc = 0x825A0E2C; continue 'dispatch;
	}
	// 825A0E40: 7CA807B4  extsw r8, r5
	ctx.r[8].s64 = ctx.r[5].s32 as i64;
	// 825A0E44: C1830028  lfs f12, 0x28(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825A0E48: 3D40820D  lis r10, -0x7df3
	ctx.r[10].s64 = -2113077248;
	// 825A0E4C: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 825A0E50: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A0E54: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 825A0E58: F9010060  std r8, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u64 ) };
	// 825A0E5C: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 825A0E60: C00ABFFC  lfs f0, -0x4004(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16388 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0E64: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 825A0E68: D0010070  stfs f0, 0x70(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 825A0E6C: D0010078  stfs f0, 0x78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 825A0E70: C0030024  lfs f0, 0x24(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A0E74: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A0E78: C1AA1850  lfs f13, 0x1850(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(6224 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A0E7C: 552A083C  slwi r10, r9, 1
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 825A0E80: D1A10074  stfs f13, 0x74(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 825A0E84: D1A1007C  stfs f13, 0x7c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 825A0E88: EDAC0028  fsubs f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A0E8C: C1830034  lfs f12, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 825A0E90: 7D4A07B4  extsw r10, r10
	ctx.r[10].s64 = ctx.r[10].s32 as i64;
	// 825A0E94: D181008C  stfs f12, 0x8c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A0FF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A0FF8 size=652
    let mut pc: u32 = 0x825A0FF8;
    'dispatch: loop {
        match pc {
            0x825A0FF8 => {
    //   block [0x825A0FF8..0x825A1284)
	// 825A0FF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A0FFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1000: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1004: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A1008: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A100C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1010: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1014: 7CCB4850  subf r6, r11, r9
	ctx.r[6].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 825A1018: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A101C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A1020: 7D2A2850  subf r9, r10, r5
	ctx.r[9].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 825A1024: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1028: 7D4451D6  mullw r10, r4, r10
	ctx.r[10].s64 = (ctx.r[4].s32 as i64) * (ctx.r[10].s32 as i64);
	// 825A102C: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A1030: 554A083C  slwi r10, r10, 1
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 825A1034: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 825A1038: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 825A103C: 7CC80E70  srawi r8, r6, 1
	ctx.xer.ca = (ctx.r[6].s32 < 0) && ((ctx.r[6].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[6].s32 >> 1) as i64;
	// 825A1040: 7D080194  addze r8, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[8].s64 = tmp.s64;
	// 825A1044: 7F094000  cmpw cr6, r9, r8
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[8].s32, &mut ctx.xer);
	// 825A1048: 40980008  bge cr6, 0x825a1050
	if !ctx.cr[6].lt {
	pc = 0x825A1050; continue 'dispatch;
	}
	// 825A104C: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 825A1050: 5509077E  clrlwi r9, r8, 0x1d
	ctx.r[9].u64 = ctx.r[8].u32 as u64 & 0x00000007u64;
	// 825A1054: 7D295B78  or r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 | ctx.r[11].u64;
	// 825A1058: 7D295378  or r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 | ctx.r[10].u64;
	// 825A105C: 5529073E  clrlwi r9, r9, 0x1c
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x0000000Fu64;
	// 825A1060: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 825A1064: 419A0018  beq cr6, 0x825a107c
	if ctx.cr[6].eq {
	pc = 0x825A107C; continue 'dispatch;
	}
	// 825A1068: 4BFFBAB9  bl 0x8259cb20
	ctx.lr = 0x825A106C;
	sub_8259CB20(ctx, base);
	// 825A106C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A1070: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1074: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1078: 4E800020  blr
	return;
	// 825A107C: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A1080: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 825A1084: 38A7007F  addi r5, r7, 0x7f
	ctx.r[5].s64 = ctx.r[7].s64 + 127;
	// 825A1088: 54A5C9FE  srwi r5, r5, 7
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shr(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A108C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 825A1090: 419A0018  beq cr6, 0x825a10a8
	if ctx.cr[6].eq {
	pc = 0x825A10A8; continue 'dispatch;
	}
	// 825A1094: 55243830  slwi r4, r9, 7
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(7);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 825A1098: 7C04522C  dcbt r4, r10
	// 825A109C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 825A10A0: 7F092840  cmplw cr6, r9, r5
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[5].u32, &mut ctx.xer);
	// 825A10A4: 4198FFF0  blt cr6, 0x825a1094
	if ctx.cr[6].lt {
	pc = 0x825A1094; continue 'dispatch;
	}
	// 825A10A8: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 825A10AC: A0830034  lhz r4, 0x34(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 825A10B0: 7CC907B4  extsw r9, r6
	ctx.r[9].s64 = ctx.r[6].s32 as i64;
	// 825A10B4: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A10B8: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A10BC: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A10C0: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A10C4: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A10C8: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A10CC: F8E10060  std r7, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[7].u64 ) };
	// 825A10D0: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 825A10D4: F9210058  std r9, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[9].u64 ) };
	// 825A10D8: C9810058  lfd f12, 0x58(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825A10DC: FD80669C  fcfid f12, f12
	ctx.f[12].f64 = (ctx.f[12].s64 as f64);
	// 825A10E0: B081007E  sth r4, 0x7e(r1)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[1].u32.wrapping_add(126 as u32), ctx.r[4].u16 ) };
	// 825A10E4: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1288(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x825A1288 size=820
    let mut pc: u32 = 0x825A1288;
    'dispatch: loop {
        match pc {
            0x825A1288 => {
    //   block [0x825A1288..0x825A15BC)
	// 825A1288: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A128C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1290: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1294: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1298: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A129C: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A12A0: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A12A4: 80E30014  lwz r7, 0x14(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A12A8: 7D0B5050  subf r8, r11, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 825A12AC: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A12B0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A12B4: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A12B8: 8883000D  lbz r4, 0xd(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(13 as u32) ) } as u64;
	// 825A12BC: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 825A12C0: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A12C4: 7D070E70  srawi r7, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 825A12C8: 7D492850  subf r10, r9, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[9].s64;
	// 825A12CC: 7D2449D6  mullw r9, r4, r9
	ctx.r[9].s64 = (ctx.r[4].s32 as i64) * (ctx.r[9].s32 as i64);
	// 825A12D0: 7CE70194  addze r7, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[7].s64 = tmp.s64;
	// 825A12D4: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 825A12D8: 7F0A3800  cmpw cr6, r10, r7
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[7].s32, &mut ctx.xer);
	// 825A12DC: 41980008  blt cr6, 0x825a12e4
	if ctx.cr[6].lt {
	pc = 0x825A12E4; continue 'dispatch;
	}
	// 825A12E0: 7CEA3B78  mr r10, r7
	ctx.r[10].u64 = ctx.r[7].u64;
	// 825A12E4: 7D475B78  or r7, r10, r11
	ctx.r[7].u64 = ctx.r[10].u64 | ctx.r[11].u64;
	// 825A12E8: 7CE74B78  or r7, r7, r9
	ctx.r[7].u64 = ctx.r[7].u64 | ctx.r[9].u64;
	// 825A12EC: 54E7073E  clrlwi r7, r7, 0x1c
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x0000000Fu64;
	// 825A12F0: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 825A12F4: 419A000C  beq cr6, 0x825a1300
	if ctx.cr[6].eq {
	pc = 0x825A1300; continue 'dispatch;
	}
	// 825A12F8: 4BFFC459  bl 0x8259d750
	ctx.lr = 0x825A12FC;
	sub_8259D750(ctx, base);
	// 825A12FC: 480002A8  b 0x825a15a4
	pc = 0x825A15A4; continue 'dispatch;
	// 825A1300: 38CA007F  addi r6, r10, 0x7f
	ctx.r[6].s64 = ctx.r[10].s64 + 127;
	// 825A1304: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 825A1308: 54C6C9FE  srwi r6, r6, 7
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shr(7);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 825A130C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 825A1310: 419A0018  beq cr6, 0x825a1328
	if ctx.cr[6].eq {
	pc = 0x825A1328; continue 'dispatch;
	}
	// 825A1314: 54E53830  slwi r5, r7, 7
	ctx.r[5].u32 = ctx.r[7].u32.wrapping_shl(7);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 825A1318: 7C054A2C  dcbt r5, r9
	// 825A131C: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 825A1320: 7F073040  cmplw cr6, r7, r6
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[6].u32, &mut ctx.xer);
	// 825A1324: 4198FFF0  blt cr6, 0x825a1314
	if ctx.cr[6].lt {
	pc = 0x825A1314; continue 'dispatch;
	}
	// 825A1328: 7D0807B4  extsw r8, r8
	ctx.r[8].s64 = ctx.r[8].s32 as i64;
	// 825A132C: C0030024  lfs f0, 0x24(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 825A1330: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 825A1334: C1A30028  lfs f13, 0x28(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 825A1338: EDAD0028  fsubs f13, f13, f0
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 825A133C: 1007030C  vspltisb v0, 7
	for i in 0..16 {
		ctx.v[0].u8[i] = 7 as u8;
	}
	// 825A1340: 7CE707B4  extsw r7, r7
	ctx.r[7].s64 = ctx.r[7].s32 as i64;
	// 825A1344: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 825A1348: 88C30034  lbz r6, 0x34(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 825A134C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A1350: F9010060  std r8, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u64 ) };
	// 825A1354: 39010058  addi r8, r1, 0x58
	ctx.r[8].s64 = ctx.r[1].s64 + 88;
	// 825A1358: 13E00104  vslb v31, v0, v0
	ctx.v[31].u8[0] = ctx.v[0].u8[0] << (ctx.v[0].u8[0] & 0x7);
	ctx.v[31].u8[1] = ctx.v[0].u8[1] << (ctx.v[0].u8[1] & 0x7);
	ctx.v[31].u8[2] = ctx.v[0].u8[2] << (ctx.v[0].u8[2] & 0x7);
	ctx.v[31].u8[3] = ctx.v[0].u8[3] << (ctx.v[0].u8[3] & 0x7);
	ctx.v[31].u8[4] = ctx.v[0].u8[4] << (ctx.v[0].u8[4] & 0x7);
	ctx.v[31].u8[5] = ctx.v[0].u8[5] << (ctx.v[0].u8[5] & 0x7);
	ctx.v[31].u8[6] = ctx.v[0].u8[6] << (ctx.v[0].u8[6] & 0x7);
	ctx.v[31].u8[7] = ctx.v[0].u8[7] << (ctx.v[0].u8[7] & 0x7);
	ctx.v[31].u8[8] = ctx.v[0].u8[8] << (ctx.v[0].u8[8] & 0x7);
	ctx.v[31].u8[9] = ctx.v[0].u8[9] << (ctx.v[0].u8[9] & 0x7);
	ctx.v[31].u8[10] = ctx.v[0].u8[10] << (ctx.v[0].u8[10] & 0x7);
	ctx.v[31].u8[11] = ctx.v[0].u8[11] << (ctx.v[0].u8[11] & 0x7);
	ctx.v[31].u8[12] = ctx.v[0].u8[12] << (ctx.v[0].u8[12] & 0x7);
	ctx.v[31].u8[13] = ctx.v[0].u8[13] << (ctx.v[0].u8[13] & 0x7);
	ctx.v[31].u8[14] = ctx.v[0].u8[14] << (ctx.v[0].u8[14] & 0x7);
	ctx.v[31].u8[15] = ctx.v[0].u8[15] << (ctx.v[0].u8[15] & 0x7);
	// 825A135C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A1360: F8E10058  std r7, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u64 ) };
	// 825A1364: C9610058  lfd f11, 0x58(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 825A1368: FD605E9C  fcfid f11, f11
	ctx.f[11].f64 = (ctx.f[11].s64 as f64);
	// 825A136C: 98C1007F  stb r6, 0x7f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(127 as u32), ctx.r[6].u8 ) };
	// 825A1370: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 825A1374: 38E10070  addi r7, r1, 0x70
	ctx.r[7].s64 = ctx.r[1].s64 + 112;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A15C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A15C0 size=112
    let mut pc: u32 = 0x825A15C0;
    'dispatch: loop {
        match pc {
            0x825A15C0 => {
    //   block [0x825A15C0..0x825A1630)
	// 825A15C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A15C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A15C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A15CC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A15D0: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A15D4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A15D8: 396B6D00  addi r11, r11, 0x6d00
	ctx.r[11].s64 = ctx.r[11].s64 + 27904;
	// 825A15DC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 825A15E0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A15E4: 48001E05  bl 0x825a33e8
	ctx.lr = 0x825A15E8;
	sub_825A33E8(ctx, base);
	// 825A15E8: 817F0044  lwz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A15EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A15F0: 419A0024  beq cr6, 0x825a1614
	if ctx.cr[6].eq {
	pc = 0x825A1614; continue 'dispatch;
	}
	// 825A15F4: 386B0004  addi r3, r11, 4
	ctx.r[3].s64 = ctx.r[11].s64 + 4;
	// 825A15F8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A15FC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 825A1600: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1604: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1608: 4E800421  bctrl
	ctx.lr = 0x825A160C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A160C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 825A1610: 917F0044  stw r11, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 825A1614: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1618: 480016C1  bl 0x825a2cd8
	ctx.lr = 0x825A161C;
	sub_825A2CD8(ctx, base);
	// 825A161C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1620: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1624: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1628: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A162C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1630 size=92
    let mut pc: u32 = 0x825A1630;
    'dispatch: loop {
        match pc {
            0x825A1630 => {
    //   block [0x825A1630..0x825A168C)
	// 825A1630: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1634: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1638: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A163C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1640: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1644: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1648: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A164C: 48002275  bl 0x825a38c0
	ctx.lr = 0x825A1650;
	sub_825A38C0(ctx, base);
	// 825A1650: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A1654: 41980020  blt cr6, 0x825a1674
	if ctx.cr[6].lt {
	pc = 0x825A1674; continue 'dispatch;
	}
	// 825A1658: 807F0044  lwz r3, 0x44(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A165C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 825A1660: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1664: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1668: 816B0018  lwz r11, 0x18(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A166C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1670: 4E800421  bctrl
	ctx.lr = 0x825A1674;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1674: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A1678: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A167C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1680: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1684: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1688: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1690(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1690 size=12
    let mut pc: u32 = 0x825A1690;
    'dispatch: loop {
        match pc {
            0x825A1690 => {
    //   block [0x825A1690..0x825A169C)
	// 825A1690: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1694: 806B3920  lwz r3, 0x3920(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 825A1698: 4BFE9048  b 0x8258a6e0
	sub_8258A6E0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A16A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A16A0 size=128
    let mut pc: u32 = 0x825A16A0;
    'dispatch: loop {
        match pc {
            0x825A16A0 => {
    //   block [0x825A16A0..0x825A1720)
	// 825A16A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A16A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A16A8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A16AC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A16B0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A16B4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 825A16B8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A16BC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A16C0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A16C4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A16C8: 816B0034  lwz r11, 0x34(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 825A16CC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A16D0: 4E800421  bctrl
	ctx.lr = 0x825A16D4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A16D4: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A16D8: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 825A16DC: 41980028  blt cr6, 0x825a1704
	if ctx.cr[6].lt {
	pc = 0x825A1704; continue 'dispatch;
	}
	// 825A16E0: 419A0010  beq cr6, 0x825a16f0
	if ctx.cr[6].eq {
	pc = 0x825A16F0; continue 'dispatch;
	}
	// 825A16E4: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 825A16E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A16EC: 4800001C  b 0x825a1708
	pc = 0x825A1708; continue 'dispatch;
	// 825A16F0: 897F004C  lbz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 825A16F4: 815E007C  lwz r10, 0x7c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(124 as u32) ) } as u64;
	// 825A16F8: 1D6B002C  mulli r11, r11, 0x2c
	ctx.r[11].s64 = ctx.r[11].s64 * 44;
	// 825A16FC: 7C6B5214  add r3, r11, r10
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 825A1700: 48000008  b 0x825a1708
	pc = 0x825A1708; continue 'dispatch;
	// 825A1704: 387E0050  addi r3, r30, 0x50
	ctx.r[3].s64 = ctx.r[30].s64 + 80;
	// 825A1708: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A170C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1710: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1714: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1718: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A171C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1720 size=48
    let mut pc: u32 = 0x825A1720;
    'dispatch: loop {
        match pc {
            0x825A1720 => {
    //   block [0x825A1720..0x825A1750)
	// 825A1720: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1724: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1728: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A172C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1730: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1734: 4BFFFE8D  bl 0x825a15c0
	ctx.lr = 0x825A1738;
	sub_825A15C0(ctx, base);
	// 825A1738: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A173C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1740: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1744: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1748: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A174C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1750(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1750 size=296
    let mut pc: u32 = 0x825A1750;
    'dispatch: loop {
        match pc {
            0x825A1750 => {
    //   block [0x825A1750..0x825A1878)
	// 825A1750: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1754: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1758: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A175C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1760: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1764: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825A1768: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A176C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1770: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 825A1774: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 825A1778: FBCB0008  std r30, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 825A177C: FBCB0010  std r30, 0x10(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u64 ) };
	// 825A1780: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 825A1784: 9BC10060  stb r30, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u8 ) };
	// 825A1788: 99610061  stb r11, 0x61(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(97 as u32), ctx.r[11].u8 ) };
	// 825A178C: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 825A1790: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 825A1794: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 825A1798: 419A001C  beq cr6, 0x825a17b4
	if ctx.cr[6].eq {
	pc = 0x825A17B4; continue 'dispatch;
	}
	// 825A179C: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A17A0: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 825A17A4: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A17A8: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 825A17AC: 81640008  lwz r11, 8(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A17B0: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 825A17B4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 825A17B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A17BC: 48001FCD  bl 0x825a3788
	ctx.lr = 0x825A17C0;
	sub_825A3788(ctx, base);
	// 825A17C0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A17C4: 4198009C  blt cr6, 0x825a1860
	if ctx.cr[6].lt {
	pc = 0x825A1860; continue 'dispatch;
	}
	// 825A17C8: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 825A17CC: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A17D0: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 825A17D4: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 825A17D8: 93CB0008  stw r30, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 825A17DC: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 825A17E0: 93E10054  stw r31, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[31].u32 ) };
	// 825A17E4: 99610050  stb r11, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u8 ) };
	// 825A17E8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A17EC: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A17F0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A17F4: 4E800421  bctrl
	ctx.lr = 0x825A17F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A17F8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A17FC: 419A0014  beq cr6, 0x825a1810
	if ctx.cr[6].eq {
	pc = 0x825A1810; continue 'dispatch;
	}
	// 825A1800: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A1804: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1808: 4BFE0669  bl 0x82581e70
	ctx.lr = 0x825A180C;
	sub_82581E70(ctx, base);
	// 825A180C: 48000008  b 0x825a1814
	pc = 0x825A1814; continue 'dispatch;
	// 825A1810: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A1814: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A1818: 907F0044  stw r3, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[3].u32 ) };
	// 825A181C: 409A0010  bne cr6, 0x825a182c
	if !ctx.cr[6].eq {
	pc = 0x825A182C; continue 'dispatch;
	}
	// 825A1820: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 825A1824: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 825A1828: 48000038  b 0x825a1860
	pc = 0x825A1860; continue 'dispatch;
	// 825A182C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1830: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A1834: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1838: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 825A183C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1840: 4E800421  bctrl
	ctx.lr = 0x825A1844;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1844: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A1848: 41980018  blt cr6, 0x825a1860
	if ctx.cr[6].lt {
	pc = 0x825A1860; continue 'dispatch;
	}
	// 825A184C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1850: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1854: 816B0038  lwz r11, 0x38(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 825A1858: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A185C: 4E800421  bctrl
	ctx.lr = 0x825A1860;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1860: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A1864: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1868: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A186C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1870: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1874: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1878(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1878 size=84
    let mut pc: u32 = 0x825A1878;
    'dispatch: loop {
        match pc {
            0x825A1878 => {
    //   block [0x825A1878..0x825A18CC)
	// 825A1878: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A187C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1880: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1884: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1888: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A188C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A1890: 48001279  bl 0x825a2b08
	ctx.lr = 0x825A1894;
	sub_825A2B08(ctx, base);
	// 825A1894: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1898: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 825A189C: 41980014  blt cr6, 0x825a18b0
	if ctx.cr[6].lt {
	pc = 0x825A18B0; continue 'dispatch;
	}
	// 825A18A0: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 825A18A4: 807E0020  lwz r3, 0x20(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 825A18A8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 825A18AC: 4BFE2E25  bl 0x825846d0
	ctx.lr = 0x825A18B0;
	sub_825846D0(ctx, base);
	// 825A18B0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A18B4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A18B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A18BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A18C0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A18C4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A18C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A18D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A18D0 size=104
    let mut pc: u32 = 0x825A18D0;
    'dispatch: loop {
        match pc {
            0x825A18D0 => {
    //   block [0x825A18D0..0x825A1938)
	// 825A18D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A18D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A18D8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A18DC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A18E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A18E4: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 825A18E8: 556B07FE  clrlwi r11, r11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 825A18EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A18F0: 419A001C  beq cr6, 0x825a190c
	if ctx.cr[6].eq {
	pc = 0x825A190C; continue 'dispatch;
	}
	// 825A18F4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A18F8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A18FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1900: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1904: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1908: 4E800020  blr
	return;
	// 825A190C: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 825A1910: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 825A1914: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 825A1918: 4BFE2DB9  bl 0x825846d0
	ctx.lr = 0x825A191C;
	sub_825846D0(ctx, base);
	// 825A191C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1920: 480018B1  bl 0x825a31d0
	ctx.lr = 0x825A1924;
	sub_825A31D0(ctx, base);
	// 825A1924: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1928: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A192C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1930: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1934: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1938(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1938 size=220
    let mut pc: u32 = 0x825A1938;
    'dispatch: loop {
        match pc {
            0x825A1938 => {
    //   block [0x825A1938..0x825A1A14)
	// 825A1938: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A193C: 4BF9377D  bl 0x825350b8
	ctx.lr = 0x825A1940;
	sub_82535080(ctx, base);
	// 825A1940: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1944: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A1948: 4816C505  bl 0x8270de4c
	ctx.lr = 0x825A194C;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 825A194C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1950: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A1954: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 825A1958: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 825A195C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1960: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A1964: 419A0010  beq cr6, 0x825a1974
	if ctx.cr[6].eq {
	pc = 0x825A1974; continue 'dispatch;
	}
	// 825A1968: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A196C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A1970: 419A001C  beq cr6, 0x825a198c
	if ctx.cr[6].eq {
	pc = 0x825A198C; continue 'dispatch;
	}
	// 825A1974: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1978: 4816BF15  bl 0x8270d88c
	ctx.lr = 0x825A197C;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 825A197C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 825A1980: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 825A1984: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 825A1988: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A198C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 825A1990: 397C0018  addi r11, r28, 0x18
	ctx.r[11].s64 = ctx.r[28].s64 + 24;
	// 825A1994: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A1998: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A199C: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A19A0: 419A0028  beq cr6, 0x825a19c8
	if ctx.cr[6].eq {
	pc = 0x825A19C8; continue 'dispatch;
	}
	// 825A19A4: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A19A8: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A19AC: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A19B0: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A19B4: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 825A19B8: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A19BC: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A19C0: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A19C4: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A19C8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A19CC: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 825A19D0: 419A0038  beq cr6, 0x825a1a08
	if ctx.cr[6].eq {
	pc = 0x825A1A08; continue 'dispatch;
	}
	// 825A19D4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A19D8: 409A0030  bne cr6, 0x825a1a08
	if !ctx.cr[6].eq {
	pc = 0x825A1A08; continue 'dispatch;
	}
	// 825A19DC: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 825A19E0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A19E4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A19E8: 409A0020  bne cr6, 0x825a1a08
	if !ctx.cr[6].eq {
	pc = 0x825A1A08; continue 'dispatch;
	}
	// 825A19EC: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A19F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A19F4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 825A19F8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 825A19FC: 4816BE81  bl 0x8270d87c
	ctx.lr = 0x825A1A00;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 825A1A00: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A1A04: 4816C459  bl 0x8270de5c
	ctx.lr = 0x825A1A08;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 825A1A08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A1A0C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A1A10: 4BF936F8  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1A18 size=148
    let mut pc: u32 = 0x825A1A18;
    'dispatch: loop {
        match pc {
            0x825A1A18 => {
    //   block [0x825A1A18..0x825A1AAC)
	// 825A1A18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1A1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1A20: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1A24: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1A28: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 825A1A2C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A1A30: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 825A1A34: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A1A38: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 825A1A3C: F94B0008  std r10, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u64 ) };
	// 825A1A40: F94B0010  std r10, 0x10(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u64 ) };
	// 825A1A44: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 825A1A48: 99410060  stb r10, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u8 ) };
	// 825A1A4C: 99610061  stb r11, 0x61(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(97 as u32), ctx.r[11].u8 ) };
	// 825A1A50: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 825A1A54: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 825A1A58: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 825A1A5C: 419A001C  beq cr6, 0x825a1a78
	if ctx.cr[6].eq {
	pc = 0x825A1A78; continue 'dispatch;
	}
	// 825A1A60: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1A64: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 825A1A68: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1A6C: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 825A1A70: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1A74: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 825A1A78: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A1A7C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 825A1A80: 48001171  bl 0x825a2bf0
	ctx.lr = 0x825A1A84;
	sub_825A2BF0(ctx, base);
	// 825A1A84: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A1A88: 41980010  blt cr6, 0x825a1a98
	if ctx.cr[6].lt {
	pc = 0x825A1A98; continue 'dispatch;
	}
	// 825A1A8C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A1A90: 396B001C  addi r11, r11, 0x1c
	ctx.r[11].s64 = ctx.r[11].s64 + 28;
	// 825A1A94: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1A98: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A1A9C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1AA0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1AA4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1AA8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1AB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1AB0 size=236
    let mut pc: u32 = 0x825A1AB0;
    'dispatch: loop {
        match pc {
            0x825A1AB0 => {
    //   block [0x825A1AB0..0x825A1B9C)
	// 825A1AB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1AB4: 4BF93601  bl 0x825350b4
	ctx.lr = 0x825A1AB8;
	sub_82535080(ctx, base);
	// 825A1AB8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1ABC: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1AC0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A1AC4: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 825A1AC8: 806B3920  lwz r3, 0x3920(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 825A1ACC: 4BFFFBD5  bl 0x825a16a0
	ctx.lr = 0x825A1AD0;
	sub_825A16A0(ctx, base);
	// 825A1AD0: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 825A1AD4: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 825A1AD8: 419A00B8  beq cr6, 0x825a1b90
	if ctx.cr[6].eq {
	pc = 0x825A1B90; continue 'dispatch;
	}
	// 825A1ADC: 4816C371  bl 0x8270de4c
	ctx.lr = 0x825A1AE0;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 825A1AE0: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1AE4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A1AE8: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 825A1AEC: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 825A1AF0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1AF4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A1AF8: 419A0010  beq cr6, 0x825a1b08
	if ctx.cr[6].eq {
	pc = 0x825A1B08; continue 'dispatch;
	}
	// 825A1AFC: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1B00: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 825A1B04: 419A0018  beq cr6, 0x825a1b1c
	if ctx.cr[6].eq {
	pc = 0x825A1B1C; continue 'dispatch;
	}
	// 825A1B08: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1B0C: 4816BD81  bl 0x8270d88c
	ctx.lr = 0x825A1B10;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 825A1B10: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 825A1B14: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 825A1B18: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1B1C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 825A1B20: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 825A1B24: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A1B28: 815B0028  lwz r10, 0x28(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(40 as u32) ) } as u64;
	// 825A1B2C: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1B30: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 825A1B34: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 825A1B38: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1B3C: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 825A1B40: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A1B44: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1B48: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1B4C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1B50: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A1B54: 419A003C  beq cr6, 0x825a1b90
	if ctx.cr[6].eq {
	pc = 0x825A1B90; continue 'dispatch;
	}
	// 825A1B58: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1B5C: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 825A1B60: 409A0030  bne cr6, 0x825a1b90
	if !ctx.cr[6].eq {
	pc = 0x825A1B90; continue 'dispatch;
	}
	// 825A1B64: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 825A1B68: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A1B6C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A1B70: 409A0020  bne cr6, 0x825a1b90
	if !ctx.cr[6].eq {
	pc = 0x825A1B90; continue 'dispatch;
	}
	// 825A1B74: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A1B78: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1B7C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 825A1B80: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 825A1B84: 4816BCF9  bl 0x8270d87c
	ctx.lr = 0x825A1B88;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 825A1B88: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A1B8C: 4816C2D1  bl 0x8270de5c
	ctx.lr = 0x825A1B90;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 825A1B90: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A1B94: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A1B98: 4BF9356C  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1BA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1BA0 size=264
    let mut pc: u32 = 0x825A1BA0;
    'dispatch: loop {
        match pc {
            0x825A1BA0 => {
    //   block [0x825A1BA0..0x825A1CA8)
	// 825A1BA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1BA4: 4BF93515  bl 0x825350b8
	ctx.lr = 0x825A1BA8;
	sub_82535080(ctx, base);
	// 825A1BA8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1BAC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 825A1BB0: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 825A1BB4: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 825A1BB8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A1BBC: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 825A1BC0: 4BFFFE59  bl 0x825a1a18
	ctx.lr = 0x825A1BC4;
	sub_825A1A18(ctx, base);
	// 825A1BC4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A1BC8: 41980010  blt cr6, 0x825a1bd8
	if ctx.cr[6].lt {
	pc = 0x825A1BD8; continue 'dispatch;
	}
	// 825A1BCC: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 825A1BD0: 388B0048  addi r4, r11, 0x48
	ctx.r[4].s64 = ctx.r[11].s64 + 72;
	// 825A1BD4: 48000008  b 0x825a1bdc
	pc = 0x825A1BDC; continue 'dispatch;
	// 825A1BD8: 80810054  lwz r4, 0x54(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 825A1BDC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A1BE0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A1BE4: 4198009C  blt cr6, 0x825a1c80
	if ctx.cr[6].lt {
	pc = 0x825A1C80; continue 'dispatch;
	}
	// 825A1BE8: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 825A1BEC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 825A1BF0: 60630006  ori r3, r3, 6
	ctx.r[3].u64 = ctx.r[3].u64 | 6;
	// 825A1BF4: 4800052D  bl 0x825a2120
	ctx.lr = 0x825A1BF8;
	sub_825A2120(ctx, base);
	// 825A1BF8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A1BFC: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 825A1C00: 41980080  blt cr6, 0x825a1c80
	if ctx.cr[6].lt {
	pc = 0x825A1C80; continue 'dispatch;
	}
	// 825A1C04: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A1C08: 38800048  li r4, 0x48
	ctx.r[4].s64 = 72;
	// 825A1C0C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1C10: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A1C14: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1C18: 4E800421  bctrl
	ctx.lr = 0x825A1C1C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1C1C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1C20: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 825A1C24: 419A003C  beq cr6, 0x825a1c60
	if ctx.cr[6].eq {
	pc = 0x825A1C60; continue 'dispatch;
	}
	// 825A1C28: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 825A1C2C: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A1C30: 48001309  bl 0x825a2f38
	ctx.lr = 0x825A1C34;
	sub_825A2F38(ctx, base);
	// 825A1C34: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A1C38: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 825A1C3C: 396B6D00  addi r11, r11, 0x6d00
	ctx.r[11].s64 = ctx.r[11].s64 + 27904;
	// 825A1C40: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1C44: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1C48: 4BFFFB09  bl 0x825a1750
	ctx.lr = 0x825A1C4C;
	sub_825A1750(ctx, base);
	// 825A1C4C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A1C50: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 825A1C54: 41980018  blt cr6, 0x825a1c6c
	if ctx.cr[6].lt {
	pc = 0x825A1C6C; continue 'dispatch;
	}
	// 825A1C58: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 825A1C5C: 48000024  b 0x825a1c80
	pc = 0x825A1C80; continue 'dispatch;
	// 825A1C60: 3FC08007  lis r30, -0x7ff9
	ctx.r[30].s64 = -2147024896;
	// 825A1C64: 63DE000E  ori r30, r30, 0xe
	ctx.r[30].u64 = ctx.r[30].u64 | 14;
	// 825A1C68: 48000018  b 0x825a1c80
	pc = 0x825A1C80; continue 'dispatch;
	// 825A1C6C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1C70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1C74: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A1C78: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1C7C: 4E800421  bctrl
	ctx.lr = 0x825A1C80;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1C80: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A1C84: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A1C88: 419A0014  beq cr6, 0x825a1c9c
	if ctx.cr[6].eq {
	pc = 0x825A1C9C; continue 'dispatch;
	}
	// 825A1C8C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1C90: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A1C94: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1C98: 4E800421  bctrl
	ctx.lr = 0x825A1C9C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1C9C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A1CA0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A1CA4: 4BF93464  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1CA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1CA8 size=24
    let mut pc: u32 = 0x825A1CA8;
    'dispatch: loop {
        match pc {
            0x825A1CA8 => {
    //   block [0x825A1CA8..0x825A1CC0)
	// 825A1CA8: 39640003  addi r11, r4, 3
	ctx.r[11].s64 = ctx.r[4].s64 + 3;
	// 825A1CAC: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 825A1CB0: 556B003A  rlwinm r11, r11, 0, 0, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825A1CB4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 825A1CB8: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 825A1CBC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1CC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1CC0 size=116
    let mut pc: u32 = 0x825A1CC0;
    'dispatch: loop {
        match pc {
            0x825A1CC0 => {
    //   block [0x825A1CC0..0x825A1D34)
	// 825A1CC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1CC4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1CC8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1CCC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1CD0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1CD4: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 825A1CD8: 809F0010  lwz r4, 0x10(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 825A1CDC: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 825A1CE0: 409A001C  bne cr6, 0x825a1cfc
	if !ctx.cr[6].eq {
	pc = 0x825A1CFC; continue 'dispatch;
	}
	// 825A1CE4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A1CE8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1CEC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1CF0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1CF4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1CF8: 4E800020  blr
	return;
	// 825A1CFC: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1D00: 90BF000C  stw r5, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 825A1D04: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1D08: 4BFE2BE9  bl 0x825848f0
	ctx.lr = 0x825A1D0C;
	sub_825848F0(ctx, base);
	// 825A1D0C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A1D10: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 825A1D14: 409AFFD0  bne cr6, 0x825a1ce4
	if !ctx.cr[6].eq {
	pc = 0x825A1CE4; continue 'dispatch;
	}
	// 825A1D18: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 825A1D1C: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 825A1D20: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1D24: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1D28: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1D2C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1D30: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1D38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1D38 size=108
    let mut pc: u32 = 0x825A1D38;
    'dispatch: loop {
        match pc {
            0x825A1D38 => {
    //   block [0x825A1D38..0x825A1DA4)
	// 825A1D38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1D3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1D40: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1D44: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1D48: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1D4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1D50: 39440003  addi r10, r4, 3
	ctx.r[10].s64 = ctx.r[4].s64 + 3;
	// 825A1D54: 555E003A  rlwinm r30, r10, 0, 0, 0x1d
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 825A1D58: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1D5C: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 825A1D60: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1D64: 4E800421  bctrl
	ctx.lr = 0x825A1D68;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1D68: 7F1E1840  cmplw cr6, r30, r3
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[3].u32, &mut ctx.xer);
	// 825A1D6C: 4099000C  ble cr6, 0x825a1d78
	if !ctx.cr[6].gt {
	pc = 0x825A1D78; continue 'dispatch;
	}
	// 825A1D70: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A1D74: 48000018  b 0x825a1d8c
	pc = 0x825A1D8C; continue 'dispatch;
	// 825A1D78: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A1D7C: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A1D80: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 825A1D84: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 825A1D88: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 825A1D8C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A1D90: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1D94: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1D98: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1D9C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1DA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1DA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1DA8 size=112
    let mut pc: u32 = 0x825A1DA8;
    'dispatch: loop {
        match pc {
            0x825A1DA8 => {
    //   block [0x825A1DA8..0x825A1E18)
	// 825A1DA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1DAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1DB0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1DB4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1DB8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1DBC: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A1DC0: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A1DC4: 396B6D6C  addi r11, r11, 0x6d6c
	ctx.r[11].s64 = ctx.r[11].s64 + 28012;
	// 825A1DC8: 394A6D58  addi r10, r10, 0x6d58
	ctx.r[10].s64 = ctx.r[10].s64 + 27992;
	// 825A1DCC: 809F0018  lwz r4, 0x18(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A1DD0: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 825A1DD4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1DD8: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A1DDC: 419A001C  beq cr6, 0x825a1df8
	if ctx.cr[6].eq {
	pc = 0x825A1DF8; continue 'dispatch;
	}
	// 825A1DE0: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1DE4: 80BF000C  lwz r5, 0xc(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A1DE8: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1DEC: 4BFE2B15  bl 0x82584900
	ctx.lr = 0x825A1DF0;
	sub_82584900(ctx, base);
	// 825A1DF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 825A1DF4: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 825A1DF8: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A1DFC: 396B62E8  addi r11, r11, 0x62e8
	ctx.r[11].s64 = ctx.r[11].s64 + 25320;
	// 825A1E00: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A1E04: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1E08: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1E0C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1E10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1E14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1E18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1E18 size=8
    let mut pc: u32 = 0x825A1E18;
    'dispatch: loop {
        match pc {
            0x825A1E18 => {
    //   block [0x825A1E18..0x825A1E20)
	// 825A1E18: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 825A1E1C: 4800008C  b 0x825a1ea8
	sub_825A1EA8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1E20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1E20 size=16
    let mut pc: u32 = 0x825A1E20;
    'dispatch: loop {
        match pc {
            0x825A1E20 => {
    //   block [0x825A1E20..0x825A1E30)
	// 825A1E20: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 825A1E24: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A1E28: 7C6A5850  subf r3, r10, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 825A1E2C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1E30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1E30 size=8
    let mut pc: u32 = 0x825A1E30;
    'dispatch: loop {
        match pc {
            0x825A1E30 => {
    //   block [0x825A1E30..0x825A1E38)
	// 825A1E30: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 825A1E34: 480000D4  b 0x825a1f08
	sub_825A1F08(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1E38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A1E38 size=8
    let mut pc: u32 = 0x825A1E38;
    'dispatch: loop {
        match pc {
            0x825A1E38 => {
    //   block [0x825A1E38..0x825A1E40)
	// 825A1E38: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 825A1E3C: 48000144  b 0x825a1f80
	sub_825A1F80(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1E40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1E40 size=100
    let mut pc: u32 = 0x825A1E40;
    'dispatch: loop {
        match pc {
            0x825A1E40 => {
    //   block [0x825A1E40..0x825A1EA4)
	// 825A1E40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1E44: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1E48: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1E4C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1E50: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1E54: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1E58: 3BE3FFFC  addi r31, r3, -4
	ctx.r[31].s64 = ctx.r[3].s64 + -4;
	// 825A1E5C: 83C30008  lwz r30, 8(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A1E60: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 825A1E64: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A1E68: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A1E6C: 4E800421  bctrl
	ctx.lr = 0x825A1E70;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A1E70: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 825A1E74: 419A0018  beq cr6, 0x825a1e8c
	if ctx.cr[6].eq {
	pc = 0x825A1E8C; continue 'dispatch;
	}
	// 825A1E78: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1E7C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 825A1E80: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1E84: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 825A1E88: 4BFE2A79  bl 0x82584900
	ctx.lr = 0x825A1E8C;
	sub_82584900(ctx, base);
	// 825A1E8C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A1E90: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1E94: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1E98: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1E9C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1EA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1EA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1EA8 size=92
    let mut pc: u32 = 0x825A1EA8;
    'dispatch: loop {
        match pc {
            0x825A1EA8 => {
    //   block [0x825A1EA8..0x825A1F04)
	// 825A1EA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1EAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1EB0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1EB4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1EB8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1EBC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1EC0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A1EC4: 4BFFFEE5  bl 0x825a1da8
	ctx.lr = 0x825A1EC8;
	sub_825A1DA8(ctx, base);
	// 825A1EC8: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 825A1ECC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A1ED0: 419A0018  beq cr6, 0x825a1ee8
	if ctx.cr[6].eq {
	pc = 0x825A1EE8; continue 'dispatch;
	}
	// 825A1ED4: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1ED8: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 825A1EDC: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1EE0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 825A1EE4: 4BFE2A1D  bl 0x82584900
	ctx.lr = 0x825A1EE8;
	sub_82584900(ctx, base);
	// 825A1EE8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1EEC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A1EF0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1EF4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1EF8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1EFC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1F00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1F08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1F08 size=116
    let mut pc: u32 = 0x825A1F08;
    'dispatch: loop {
        match pc {
            0x825A1F08 => {
    //   block [0x825A1F08..0x825A1F7C)
	// 825A1F08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1F0C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1F10: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A1F14: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1F18: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1F1C: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A1F20: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A1F24: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1F28: 396B6D6C  addi r11, r11, 0x6d6c
	ctx.r[11].s64 = ctx.r[11].s64 + 28012;
	// 825A1F2C: 394A6D84  addi r10, r10, 0x6d84
	ctx.r[10].s64 = ctx.r[10].s64 + 28036;
	// 825A1F30: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A1F34: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1F38: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A1F3C: 4BFFFE6D  bl 0x825a1da8
	ctx.lr = 0x825A1F40;
	sub_825A1DA8(ctx, base);
	// 825A1F40: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 825A1F44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A1F48: 419A0018  beq cr6, 0x825a1f60
	if ctx.cr[6].eq {
	pc = 0x825A1F60; continue 'dispatch;
	}
	// 825A1F4C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1F50: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 825A1F54: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1F58: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 825A1F5C: 4BFE29A5  bl 0x82584900
	ctx.lr = 0x825A1F60;
	sub_82584900(ctx, base);
	// 825A1F60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1F64: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A1F68: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1F6C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1F70: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A1F74: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1F78: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1F80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1F80 size=80
    let mut pc: u32 = 0x825A1F80;
    'dispatch: loop {
        match pc {
            0x825A1F80 => {
    //   block [0x825A1F80..0x825A1FD0)
	// 825A1F80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1F84: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1F88: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1F8C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1F90: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A1F94: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A1F98: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1F9C: 396B6D6C  addi r11, r11, 0x6d6c
	ctx.r[11].s64 = ctx.r[11].s64 + 28012;
	// 825A1FA0: 394A6D98  addi r10, r10, 0x6d98
	ctx.r[10].s64 = ctx.r[10].s64 + 28056;
	// 825A1FA4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 825A1FA8: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A1FAC: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A1FB0: 913F0018  stw r9, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[9].u32 ) };
	// 825A1FB4: 4BFFFDF5  bl 0x825a1da8
	ctx.lr = 0x825A1FB8;
	sub_825A1DA8(ctx, base);
	// 825A1FB8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A1FBC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A1FC0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A1FC4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A1FC8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A1FCC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A1FD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A1FD0 size=172
    let mut pc: u32 = 0x825A1FD0;
    'dispatch: loop {
        match pc {
            0x825A1FD0 => {
    //   block [0x825A1FD0..0x825A207C)
	// 825A1FD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A1FD4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A1FD8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A1FDC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A1FE0: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A1FE4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A1FE8: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A1FEC: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 825A1FF0: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 825A1FF4: 4BFE28FD  bl 0x825848f0
	ctx.lr = 0x825A1FF8;
	sub_825848F0(ctx, base);
	// 825A1FF8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 825A1FFC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2000: 419A0060  beq cr6, 0x825a2060
	if ctx.cr[6].eq {
	pc = 0x825A2060; continue 'dispatch;
	}
	// 825A2004: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A2008: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 825A200C: 392A62E8  addi r9, r10, 0x62e8
	ctx.r[9].s64 = ctx.r[10].s64 + 25320;
	// 825A2010: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A2014: 390A6D6C  addi r8, r10, 0x6d6c
	ctx.r[8].s64 = ctx.r[10].s64 + 28012;
	// 825A2018: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A201C: 90CB0008  stw r6, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 825A2020: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 825A2024: 38EA6D84  addi r7, r10, 0x6d84
	ctx.r[7].s64 = ctx.r[10].s64 + 28036;
	// 825A2028: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A202C: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 825A2030: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 825A2034: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 825A2038: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 825A203C: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 825A2040: 914B0014  stw r10, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 825A2044: 914B0018  stw r10, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 825A2048: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A204C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A2050: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2054: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2058: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A205C: 4E800020  blr
	return;
	// 825A2060: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 825A2064: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 825A2068: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A206C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2070: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2074: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A2078: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2080(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2080 size=156
    let mut pc: u32 = 0x825A2080;
    'dispatch: loop {
        match pc {
            0x825A2080 => {
    //   block [0x825A2080..0x825A211C)
	// 825A2080: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2084: 4BF93039  bl 0x825350bc
	ctx.lr = 0x825A2088;
	sub_82535080(ctx, base);
	// 825A2088: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A208C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2090: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A2094: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A2098: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 825A209C: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A20A0: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 825A20A4: 389E001C  addi r4, r30, 0x1c
	ctx.r[4].s64 = ctx.r[30].s64 + 28;
	// 825A20A8: 4BFE2849  bl 0x825848f0
	ctx.lr = 0x825A20AC;
	sub_825848F0(ctx, base);
	// 825A20AC: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 825A20B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A20B4: 409A0014  bne cr6, 0x825a20c8
	if !ctx.cr[6].eq {
	pc = 0x825A20C8; continue 'dispatch;
	}
	// 825A20B8: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 825A20BC: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 825A20C0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A20C4: 4BF93048  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
	// 825A20C8: 3D408209  lis r10, -0x7df7
	ctx.r[10].s64 = -2113339392;
	// 825A20CC: 3D208209  lis r9, -0x7df7
	ctx.r[9].s64 = -2113339392;
	// 825A20D0: 394A62E8  addi r10, r10, 0x62e8
	ctx.r[10].s64 = ctx.r[10].s64 + 25320;
	// 825A20D4: 3D008209  lis r8, -0x7df7
	ctx.r[8].s64 = -2113339392;
	// 825A20D8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 825A20DC: 39296D6C  addi r9, r9, 0x6d6c
	ctx.r[9].s64 = ctx.r[9].s64 + 28012;
	// 825A20E0: 39086D98  addi r8, r8, 0x6d98
	ctx.r[8].s64 = ctx.r[8].s64 + 28056;
	// 825A20E4: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A20E8: 38CB001C  addi r6, r11, 0x1c
	ctx.r[6].s64 = ctx.r[11].s64 + 28;
	// 825A20EC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 825A20F0: 90EB0008  stw r7, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 825A20F4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A20F8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 825A20FC: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 825A2100: 93EB000C  stw r31, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 825A2104: 914B0014  stw r10, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 825A2108: 93CB0010  stw r30, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 825A210C: 90CB0018  stw r6, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[6].u32 ) };
	// 825A2110: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2114: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A2118: 4BF92FF4  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2120 size=172
    let mut pc: u32 = 0x825A2120;
    'dispatch: loop {
        match pc {
            0x825A2120 => {
    //   block [0x825A2120..0x825A21CC)
	// 825A2120: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2124: 4BF92F95  bl 0x825350b8
	ctx.lr = 0x825A2128;
	sub_82535080(ctx, base);
	// 825A2128: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A212C: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 825A2130: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A2134: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A2138: 83FC0000  lwz r31, 0(r28)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A213C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 825A2140: 409A0040  bne cr6, 0x825a2180
	if !ctx.cr[6].eq {
	pc = 0x825A2180; continue 'dispatch;
	}
	// 825A2144: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 825A2148: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 825A214C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 825A2150: 419A0010  beq cr6, 0x825a2160
	if ctx.cr[6].eq {
	pc = 0x825A2160; continue 'dispatch;
	}
	// 825A2154: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 825A2158: 4BFFFF29  bl 0x825a2080
	ctx.lr = 0x825A215C;
	sub_825A2080(ctx, base);
	// 825A215C: 4800000C  b 0x825a2168
	pc = 0x825A2168; continue 'dispatch;
	// 825A2160: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 825A2164: 4BFFFE6D  bl 0x825a1fd0
	ctx.lr = 0x825A2168;
	sub_825A1FD0(ctx, base);
	// 825A2168: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A216C: 41980058  blt cr6, 0x825a21c4
	if ctx.cr[6].lt {
	pc = 0x825A21C4; continue 'dispatch;
	}
	// 825A2170: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A2174: 917C0000  stw r11, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2178: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A217C: 4BF92F8C  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 825A2180: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2184: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2188: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A218C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2190: 4E800421  bctrl
	ctx.lr = 0x825A2194;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2194: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2198: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 825A219C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A21A0: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A21A4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A21A8: 4E800421  bctrl
	ctx.lr = 0x825A21AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A21AC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A21B0: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 825A21B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A21B8: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A21BC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A21C0: 4E800421  bctrl
	ctx.lr = 0x825A21C4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A21C4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A21C8: 4BF92F40  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A21D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A21D0 size=60
    let mut pc: u32 = 0x825A21D0;
    'dispatch: loop {
        match pc {
            0x825A21D0 => {
    //   block [0x825A21D0..0x825A220C)
	// 825A21D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A21D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A21D8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A21DC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A21E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A21E4: 48000D55  bl 0x825a2f38
	ctx.lr = 0x825A21E8;
	sub_825A2F38(ctx, base);
	// 825A21E8: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A21EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A21F0: 396B6DB0  addi r11, r11, 0x6db0
	ctx.r[11].s64 = ctx.r[11].s64 + 28080;
	// 825A21F4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A21F8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 825A21FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2200: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2204: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A2208: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2210(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2210 size=80
    let mut pc: u32 = 0x825A2210;
    'dispatch: loop {
        match pc {
            0x825A2210 => {
    //   block [0x825A2210..0x825A2260)
	// 825A2210: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2214: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A2218: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A221C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A2220: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2224: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2228: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 825A222C: 480009AD  bl 0x825a2bd8
	ctx.lr = 0x825A2230;
	sub_825A2BD8(ctx, base);
	// 825A2230: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2234: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 825A2238: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A223C: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 825A2240: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2244: 4E800421  bctrl
	ctx.lr = 0x825A2248;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2248: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A224C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2250: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2254: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A2258: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A225C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2260(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2260 size=180
    let mut pc: u32 = 0x825A2260;
    'dispatch: loop {
        match pc {
            0x825A2260 => {
    //   block [0x825A2260..0x825A2314)
	// 825A2260: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2264: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A2268: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A226C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A2270: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2274: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A2278: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 825A227C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2280: 48000971  bl 0x825a2bf0
	ctx.lr = 0x825A2284;
	sub_825A2BF0(ctx, base);
	// 825A2284: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A2288: 41980074  blt cr6, 0x825a22fc
	if ctx.cr[6].lt {
	pc = 0x825A22FC; continue 'dispatch;
	}
	// 825A228C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 825A2290: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 825A2294: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 825A2298: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 825A229C: F96A0000  std r11, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 825A22A0: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 825A22A4: 895F0019  lbz r10, 0x19(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(25 as u32) ) } as u64;
	// 825A22A8: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 825A22AC: 99610069  stb r11, 0x69(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(105 as u32), ctx.r[11].u8 ) };
	// 825A22B0: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A22B4: 99410068  stb r10, 0x68(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[10].u8 ) };
	// 825A22B8: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 825A22BC: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 825A22C0: 99410060  stb r10, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u8 ) };
	// 825A22C4: 806B003C  lwz r3, 0x3c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 825A22C8: 4BFE9B09  bl 0x8258bdd0
	ctx.lr = 0x825A22CC;
	sub_8258BDD0(ctx, base);
	// 825A22CC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A22D0: 4198002C  blt cr6, 0x825a22fc
	if ctx.cr[6].lt {
	pc = 0x825A22FC; continue 'dispatch;
	}
	// 825A22D4: 897F0018  lbz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A22D8: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A22DC: 5569083E  rotlwi r9, r11, 1
	ctx.r[9].u64 = ((ctx.r[11].u32).rotate_left(1)) as u64;
	// 825A22E0: 7D4B51D6  mullw r10, r11, r10
	ctx.r[10].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 825A22E4: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 825A22E8: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 825A22EC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 825A22F0: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 825A22F4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 825A22F8: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A22FC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A2300: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2304: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2308: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A230C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A2310: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2318(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2318 size=276
    let mut pc: u32 = 0x825A2318;
    'dispatch: loop {
        match pc {
            0x825A2318 => {
    //   block [0x825A2318..0x825A242C)
	// 825A2318: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A231C: 4BF92D9D  bl 0x825350b8
	ctx.lr = 0x825A2320;
	sub_82535080(ctx, base);
	// 825A2320: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2324: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 825A2328: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A232C: 897C0018  lbz r11, 0x18(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A2330: 997F0044  stb r11, 0x44(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[11].u8 ) };
	// 825A2334: 48001455  bl 0x825a3788
	ctx.lr = 0x825A2338;
	sub_825A3788(ctx, base);
	// 825A2338: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A233C: 419800D8  blt cr6, 0x825a2414
	if ctx.cr[6].lt {
	pc = 0x825A2414; continue 'dispatch;
	}
	// 825A2340: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A2344: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A2348: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A234C: 419A0034  beq cr6, 0x825a2380
	if ctx.cr[6].eq {
	pc = 0x825A2380; continue 'dispatch;
	}
	// 825A2350: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 825A2354: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2358: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 825A235C: 5564103A  slwi r4, r11, 2
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 825A2360: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2364: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 825A2368: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A236C: 4E800421  bctrl
	ctx.lr = 0x825A2370;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2370: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 825A2374: 907F0048  stw r3, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[3].u32 ) };
	// 825A2378: 419A00A4  beq cr6, 0x825a241c
	if ctx.cr[6].eq {
	pc = 0x825A241C; continue 'dispatch;
	}
	// 825A237C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A2380: 895F0044  lbz r10, 0x44(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A2384: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 825A2388: 419A006C  beq cr6, 0x825a23f4
	if ctx.cr[6].eq {
	pc = 0x825A23F4; continue 'dispatch;
	}
	// 825A238C: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 825A2390: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 825A2394: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 825A2398: FBCB0008  std r30, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 825A239C: 897C0019  lbz r11, 0x19(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(25 as u32) ) } as u64;
	// 825A23A0: 93E10054  stw r31, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[31].u32 ) };
	// 825A23A4: 9BC10059  stb r30, 0x59(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(89 as u32), ctx.r[30].u8 ) };
	// 825A23A8: 99610058  stb r11, 0x58(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u8 ) };
	// 825A23AC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 825A23B0: 99610050  stb r11, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u8 ) };
	// 825A23B4: 419A0040  beq cr6, 0x825a23f4
	if ctx.cr[6].eq {
	pc = 0x825A23F4; continue 'dispatch;
	}
	// 825A23B8: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 825A23BC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A23C0: 41980054  blt cr6, 0x825a2414
	if ctx.cr[6].lt {
	pc = 0x825A2414; continue 'dispatch;
	}
	// 825A23C4: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A23C8: 38C000FF  li r6, 0xff
	ctx.r[6].s64 = 255;
	// 825A23CC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 825A23D0: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 825A23D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A23D8: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 825A23DC: 480009C5  bl 0x825a2da0
	ctx.lr = 0x825A23E0;
	sub_825A2DA0(ctx, base);
	// 825A23E0: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A23E4: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 825A23E8: 3BBD000C  addi r29, r29, 0xc
	ctx.r[29].s64 = ctx.r[29].s64 + 12;
	// 825A23EC: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A23F0: 4198FFCC  blt cr6, 0x825a23bc
	if ctx.cr[6].lt {
	pc = 0x825A23BC; continue 'dispatch;
	}
	// 825A23F4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A23F8: 4198001C  blt cr6, 0x825a2414
	if ctx.cr[6].lt {
	pc = 0x825A2414; continue 'dispatch;
	}
	// 825A23FC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2400: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2404: 809C001C  lwz r4, 0x1c(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(28 as u32) ) } as u64;
	// 825A2408: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 825A240C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2410: 4E800421  bctrl
	ctx.lr = 0x825A2414;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2414: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A2418: 4BF92CF0  b 0x82535108
	sub_825350D0(ctx, base);
	return;
	// 825A241C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 825A2420: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 825A2424: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A2428: 4BF92CE0  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2430(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2430 size=192
    let mut pc: u32 = 0x825A2430;
    'dispatch: loop {
        match pc {
            0x825A2430 => {
    //   block [0x825A2430..0x825A24F0)
	// 825A2430: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2434: 4BF92C89  bl 0x825350bc
	ctx.lr = 0x825A2438;
	sub_82535080(ctx, base);
	// 825A2438: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A243C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A2440: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A2444: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 825A2448: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 825A244C: 409A000C  bne cr6, 0x825a2458
	if !ctx.cr[6].eq {
	pc = 0x825A2458; continue 'dispatch;
	}
	// 825A2450: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 825A2454: 3BCB4958  addi r30, r11, 0x4958
	ctx.r[30].s64 = ctx.r[11].s64 + 18776;
	// 825A2458: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A245C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2460: 409A0010  bne cr6, 0x825a2470
	if !ctx.cr[6].eq {
	pc = 0x825A2470; continue 'dispatch;
	}
	// 825A2464: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A2468: 816B3920  lwz r11, 0x3920(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 825A246C: 816B0040  lwz r11, 0x40(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 825A2470: 5563003E  slwi r3, r11, 0
	ctx.r[3].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 825A2474: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2478: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A247C: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2480: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2484: 4E800421  bctrl
	ctx.lr = 0x825A2488;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2488: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A248C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2490: 419A000C  beq cr6, 0x825a249c
	if ctx.cr[6].eq {
	pc = 0x825A249C; continue 'dispatch;
	}
	// 825A2494: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 825A2498: 48000038  b 0x825a24d0
	pc = 0x825A24D0; continue 'dispatch;
	// 825A249C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A24A0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A24A4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A24A8: 816B0040  lwz r11, 0x40(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 825A24AC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A24B0: 4E800421  bctrl
	ctx.lr = 0x825A24B4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A24B4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A24B8: 41980030  blt cr6, 0x825a24e8
	if ctx.cr[6].lt {
	pc = 0x825A24E8; continue 'dispatch;
	}
	// 825A24BC: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 825A24C0: 88810051  lbz r4, 0x51(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(81 as u32) ) } as u64;
	// 825A24C4: 887D0035  lbz r3, 0x35(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(53 as u32) ) } as u64;
	// 825A24C8: 4BFE2309  bl 0x825847d0
	ctx.lr = 0x825A24CC;
	sub_825847D0(ctx, base);
	// 825A24CC: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 825A24D0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A24D4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 825A24D8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A24DC: 816A0028  lwz r11, 0x28(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) } as u64;
	// 825A24E0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A24E4: 4E800421  bctrl
	ctx.lr = 0x825A24E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A24E8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A24EC: 4BF92C20  b 0x8253510c
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A24F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A24F0 size=96
    let mut pc: u32 = 0x825A24F0;
    'dispatch: loop {
        match pc {
            0x825A24F0 => {
    //   block [0x825A24F0..0x825A2550)
	// 825A24F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A24F4: 4BF92BC5  bl 0x825350b8
	ctx.lr = 0x825A24F8;
	sub_82535080(ctx, base);
	// 825A24F8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A24FC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A2500: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 825A2504: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 825A2508: 897D0045  lbz r11, 0x45(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A250C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2510: 419A0034  beq cr6, 0x825a2544
	if ctx.cr[6].eq {
	pc = 0x825A2544; continue 'dispatch;
	}
	// 825A2514: 7F9FE378  mr r31, r28
	ctx.r[31].u64 = ctx.r[28].u64;
	// 825A2518: 817D0048  lwz r11, 0x48(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A251C: 7C6BF82E  lwzx r3, r11, r31
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 825A2520: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2524: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2528: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A252C: 4E800421  bctrl
	ctx.lr = 0x825A2530;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2530: 897D0045  lbz r11, 0x45(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A2534: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 825A2538: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 825A253C: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A2540: 4198FFD8  blt cr6, 0x825a2518
	if ctx.cr[6].lt {
	pc = 0x825A2518; continue 'dispatch;
	}
	// 825A2544: 9B9D0045  stb r28, 0x45(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(69 as u32), ctx.r[28].u8 ) };
	// 825A2548: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A254C: 4BF92BBC  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2550(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2550 size=152
    let mut pc: u32 = 0x825A2550;
    'dispatch: loop {
        match pc {
            0x825A2550 => {
    //   block [0x825A2550..0x825A25E8)
	// 825A2550: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2554: 4BF92B61  bl 0x825350b4
	ctx.lr = 0x825A2558;
	sub_82535080(ctx, base);
	// 825A2558: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A255C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A2560: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 825A2564: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 825A2568: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A256C: 897C003D  lbz r11, 0x3d(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 825A2570: 895D0000  lbz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2574: 7D6B58F8  nor r11, r11, r11
	ctx.r[11].u64 = !(ctx.r[11].u64 | ctx.r[11].u64);
	// 825A2578: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 825A257C: 557B07FE  clrlwi r27, r11, 0x1f
	ctx.r[27].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 825A2580: 419A0060  beq cr6, 0x825a25e0
	if ctx.cr[6].eq {
	pc = 0x825A25E0; continue 'dispatch;
	}
	// 825A2584: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A2588: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A258C: 41980054  blt cr6, 0x825a25e0
	if ctx.cr[6].lt {
	pc = 0x825A25E0; continue 'dispatch;
	}
	// 825A2590: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2594: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 825A2598: 813C0048  lwz r9, 0x48(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A259C: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 825A25A0: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A25A4: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A25A8: 554B083E  rotlwi r11, r10, 1
	ctx.r[11].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 825A25AC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 825A25B0: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 825A25B4: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 825A25B8: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A25BC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A25C0: 816B0038  lwz r11, 0x38(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 825A25C4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A25C8: 4E800421  bctrl
	ctx.lr = 0x825A25CC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A25CC: 897D0000  lbz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A25D0: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 825A25D4: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 825A25D8: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A25DC: 4198FFAC  blt cr6, 0x825a2588
	if ctx.cr[6].lt {
	pc = 0x825A2588; continue 'dispatch;
	}
	// 825A25E0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A25E4: 4BF92B20  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A25E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A25E8 size=156
    let mut pc: u32 = 0x825A25E8;
    'dispatch: loop {
        match pc {
            0x825A25E8 => {
    //   block [0x825A25E8..0x825A2684)
	// 825A25E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A25EC: 4BF92ACD  bl 0x825350b8
	ctx.lr = 0x825A25F0;
	sub_82535080(ctx, base);
	// 825A25F0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A25F4: 3D608209  lis r11, -0x7df7
	ctx.r[11].s64 = -2113339392;
	// 825A25F8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A25FC: 396B6DB0  addi r11, r11, 0x6db0
	ctx.r[11].s64 = ctx.r[11].s64 + 28080;
	// 825A2600: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 825A2604: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2608: 48000DE1  bl 0x825a33e8
	ctx.lr = 0x825A260C;
	sub_825A33E8(ctx, base);
	// 825A260C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2610: 4BFFFEE1  bl 0x825a24f0
	ctx.lr = 0x825A2614;
	sub_825A24F0(ctx, base);
	// 825A2614: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A2618: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 825A261C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2620: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 825A2624: 419A0050  beq cr6, 0x825a2674
	if ctx.cr[6].eq {
	pc = 0x825A2674; continue 'dispatch;
	}
	// 825A2628: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 825A262C: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2630: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 825A2634: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2638: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 825A263C: 419A0024  beq cr6, 0x825a2660
	if ctx.cr[6].eq {
	pc = 0x825A2660; continue 'dispatch;
	}
	// 825A2640: 5543003E  slwi r3, r10, 0
	ctx.r[3].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 825A2644: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2648: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A264C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2650: 4E800421  bctrl
	ctx.lr = 0x825A2654;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2654: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2658: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 825A265C: 938B0004  stw r28, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[28].u32 ) };
	// 825A2660: 897F0044  lbz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A2664: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 825A2668: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 825A266C: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A2670: 4198FFBC  blt cr6, 0x825a262c
	if ctx.cr[6].lt {
	pc = 0x825A262C; continue 'dispatch;
	}
	// 825A2674: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2678: 48000661  bl 0x825a2cd8
	ctx.lr = 0x825A267C;
	sub_825A2CD8(ctx, base);
	// 825A267C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A2680: 4BF92A88  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2688(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2688 size=200
    let mut pc: u32 = 0x825A2688;
    'dispatch: loop {
        match pc {
            0x825A2688 => {
    //   block [0x825A2688..0x825A2750)
	// 825A2688: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A268C: 4BF92A25  bl 0x825350b0
	ctx.lr = 0x825A2690;
	sub_82535080(ctx, base);
	// 825A2690: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2694: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A2698: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 825A269C: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 825A26A0: 4BFFFE51  bl 0x825a24f0
	ctx.lr = 0x825A26A4;
	sub_825A24F0(ctx, base);
	// 825A26A4: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 825A26A8: 419A0074  beq cr6, 0x825a271c
	if ctx.cr[6].eq {
	pc = 0x825A271C; continue 'dispatch;
	}
	// 825A26AC: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A26B0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 825A26B4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A26B8: 419A0050  beq cr6, 0x825a2708
	if ctx.cr[6].eq {
	pc = 0x825A2708; continue 'dispatch;
	}
	// 825A26BC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A26C0: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 825A26C4: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 825A26C8: 41980048  blt cr6, 0x825a2710
	if ctx.cr[6].lt {
	pc = 0x825A2710; continue 'dispatch;
	}
	// 825A26CC: 815C0048  lwz r10, 0x48(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A26D0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 825A26D4: 817B0004  lwz r11, 4(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A26D8: 7CAAFA14  add r5, r10, r31
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[31].u64;
	// 825A26DC: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 825A26E0: 4BFFFD51  bl 0x825a2430
	ctx.lr = 0x825A26E4;
	sub_825A2430(ctx, base);
	// 825A26E4: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A26E8: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 825A26EC: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 825A26F0: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 825A26F4: 3BDE0008  addi r30, r30, 8
	ctx.r[30].s64 = ctx.r[30].s64 + 8;
	// 825A26F8: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A26FC: 4198FFC8  blt cr6, 0x825a26c4
	if ctx.cr[6].lt {
	pc = 0x825A26C4; continue 'dispatch;
	}
	// 825A2700: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 825A2704: 4198000C  blt cr6, 0x825a2710
	if ctx.cr[6].lt {
	pc = 0x825A2710; continue 'dispatch;
	}
	// 825A2708: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A270C: 997C0045  stb r11, 0x45(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(69 as u32), ctx.r[11].u8 ) };
	// 825A2710: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 825A2714: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A2718: 4BF929E8  b 0x82535100
	sub_825350D0(ctx, base);
	return;
	// 825A271C: 897C0044  lbz r11, 0x44(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(68 as u32) ) } as u64;
	// 825A2720: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2724: 419AFFEC  beq cr6, 0x825a2710
	if ctx.cr[6].eq {
	pc = 0x825A2710; continue 'dispatch;
	}
	// 825A2728: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 825A272C: 80BC0048  lwz r5, 0x48(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2730: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 825A2734: 4BFFFCFD  bl 0x825a2430
	ctx.lr = 0x825A2738;
	sub_825A2430(ctx, base);
	// 825A2738: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A273C: 4198FFD8  blt cr6, 0x825a2714
	if ctx.cr[6].lt {
	pc = 0x825A2714; continue 'dispatch;
	}
	// 825A2740: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 825A2744: 997C0045  stb r11, 0x45(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(69 as u32), ctx.r[11].u8 ) };
	// 825A2748: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A274C: 4BF929B4  b 0x82535100
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2750(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2750 size=148
    let mut pc: u32 = 0x825A2750;
    'dispatch: loop {
        match pc {
            0x825A2750 => {
    //   block [0x825A2750..0x825A27E4)
	// 825A2750: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2754: 4BF92965  bl 0x825350b8
	ctx.lr = 0x825A2758;
	sub_82535080(ctx, base);
	// 825A2758: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A275C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 825A2760: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 825A2764: 4800115D  bl 0x825a38c0
	ctx.lr = 0x825A2768;
	sub_825A38C0(ctx, base);
	// 825A2768: 897E0045  lbz r11, 0x45(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A276C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 825A2770: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2774: 419A0068  beq cr6, 0x825a27dc
	if ctx.cr[6].eq {
	pc = 0x825A27DC; continue 'dispatch;
	}
	// 825A2778: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 825A277C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A2780: 4198005C  blt cr6, 0x825a27dc
	if ctx.cr[6].lt {
	pc = 0x825A27DC; continue 'dispatch;
	}
	// 825A2784: 817E0048  lwz r11, 0x48(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2788: 7D4BF82E  lwzx r10, r11, r31
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 825A278C: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 825A2790: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2794: 816B0048  lwz r11, 0x48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2798: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A279C: 4E800421  bctrl
	ctx.lr = 0x825A27A0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A27A0: 817E0048  lwz r11, 0x48(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A27A4: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 825A27A8: 809C0000  lwz r4, 0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A27AC: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 825A27B0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A27B4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 825A27B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A27BC: 816A0018  lwz r11, 0x18(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 825A27C0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A27C4: 4E800421  bctrl
	ctx.lr = 0x825A27C8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A27C8: 897E0045  lbz r11, 0x45(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A27CC: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 825A27D0: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 825A27D4: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A27D8: 4198FFA4  blt cr6, 0x825a277c
	if ctx.cr[6].lt {
	pc = 0x825A277C; continue 'dispatch;
	}
	// 825A27DC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A27E0: 4BF92928  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A27E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A27E8 size=320
    let mut pc: u32 = 0x825A27E8;
    'dispatch: loop {
        match pc {
            0x825A27E8 => {
    //   block [0x825A27E8..0x825A2928)
	// 825A27E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A27EC: 4BF928CD  bl 0x825350b8
	ctx.lr = 0x825A27F0;
	sub_82535080(ctx, base);
	// 825A27F0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A27F4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A27F8: 4816B655  bl 0x8270de4c
	ctx.lr = 0x825A27FC;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 825A27FC: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A2800: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A2804: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 825A2808: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 825A280C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2810: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A2814: 419A0010  beq cr6, 0x825a2824
	if ctx.cr[6].eq {
	pc = 0x825A2824; continue 'dispatch;
	}
	// 825A2818: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A281C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A2820: 419A001C  beq cr6, 0x825a283c
	if ctx.cr[6].eq {
	pc = 0x825A283C; continue 'dispatch;
	}
	// 825A2824: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2828: 4816B065  bl 0x8270d88c
	ctx.lr = 0x825A282C;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 825A282C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 825A2830: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 825A2834: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 825A2838: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A283C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 825A2840: 397C0018  addi r11, r28, 0x18
	ctx.r[11].s64 = ctx.r[28].s64 + 24;
	// 825A2844: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A2848: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A284C: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A2850: 419A0028  beq cr6, 0x825a2878
	if ctx.cr[6].eq {
	pc = 0x825A2878; continue 'dispatch;
	}
	// 825A2854: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2858: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 825A285C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2860: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2864: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 825A2868: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A286C: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2870: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2874: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2878: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 825A287C: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 825A2880: 419A0038  beq cr6, 0x825a28b8
	if ctx.cr[6].eq {
	pc = 0x825A28B8; continue 'dispatch;
	}
	// 825A2884: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 825A2888: 409A0030  bne cr6, 0x825a28b8
	if !ctx.cr[6].eq {
	pc = 0x825A28B8; continue 'dispatch;
	}
	// 825A288C: 396AFFFF  addi r11, r10, -1
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	// 825A2890: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A2894: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A2898: 409A0020  bne cr6, 0x825a28b8
	if !ctx.cr[6].eq {
	pc = 0x825A28B8; continue 'dispatch;
	}
	// 825A289C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A28A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A28A4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 825A28A8: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 825A28AC: 4816AFD1  bl 0x8270d87c
	ctx.lr = 0x825A28B0;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 825A28B0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A28B4: 4816B5A9  bl 0x8270de5c
	ctx.lr = 0x825A28B8;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 825A28B8: 897C0045  lbz r11, 0x45(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A28BC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A28C0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A28C4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A28C8: 419A0058  beq cr6, 0x825a2920
	if ctx.cr[6].eq {
	pc = 0x825A2920; continue 'dispatch;
	}
	// 825A28CC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 825A28D0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A28D4: 4198004C  blt cr6, 0x825a2920
	if ctx.cr[6].lt {
	pc = 0x825A2920; continue 'dispatch;
	}
	// 825A28D8: 817C0048  lwz r11, 0x48(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A28DC: 7C6BF82E  lwzx r3, r11, r31
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 825A28E0: 81630028  lwz r11, 0x28(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) } as u64;
	// 825A28E4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A28E8: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 825A28EC: 4182000C  beq 0x825a28f8
	if ctx.cr[0].eq {
	pc = 0x825A28F8; continue 'dispatch;
	}
	// 825A28F0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A28F4: 48000018  b 0x825a290c
	pc = 0x825A290C; continue 'dispatch;
	// 825A28F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A28FC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 825A2900: 816B003C  lwz r11, 0x3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 825A2904: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2908: 4E800421  bctrl
	ctx.lr = 0x825A290C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A290C: 897C0045  lbz r11, 0x45(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A2910: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 825A2914: 3BFF000C  addi r31, r31, 0xc
	ctx.r[31].s64 = ctx.r[31].s64 + 12;
	// 825A2918: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A291C: 4198FFB4  blt cr6, 0x825a28d0
	if ctx.cr[6].lt {
	pc = 0x825A28D0; continue 'dispatch;
	}
	// 825A2920: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 825A2924: 4BF927E4  b 0x82535108
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2928(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2928 size=92
    let mut pc: u32 = 0x825A2928;
    'dispatch: loop {
        match pc {
            0x825A2928 => {
    //   block [0x825A2928..0x825A2984)
	// 825A2928: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A292C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A2930: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 825A2934: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A2938: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A293C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2940: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 825A2944: 4BFFFCA5  bl 0x825a25e8
	ctx.lr = 0x825A2948;
	sub_825A25E8(ctx, base);
	// 825A2948: 57CB07FE  clrlwi r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 825A294C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2950: 419A0018  beq cr6, 0x825a2968
	if ctx.cr[6].eq {
	pc = 0x825A2968; continue 'dispatch;
	}
	// 825A2954: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A2958: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 825A295C: 386B38C8  addi r3, r11, 0x38c8
	ctx.r[3].s64 = ctx.r[11].s64 + 14536;
	// 825A2960: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 825A2964: 4BFE1F9D  bl 0x82584900
	ctx.lr = 0x825A2968;
	sub_82584900(ctx, base);
	// 825A2968: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A296C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A2970: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2974: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2978: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 825A297C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A2980: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2988(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2988 size=384
    let mut pc: u32 = 0x825A2988;
    'dispatch: loop {
        match pc {
            0x825A2988 => {
    //   block [0x825A2988..0x825A2B08)
	// 825A2988: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A298C: 4BF92729  bl 0x825350b4
	ctx.lr = 0x825A2990;
	sub_82535080(ctx, base);
	// 825A2990: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2994: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 825A2998: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A299C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 825A29A0: 897D0045  lbz r11, 0x45(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A29A4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A29A8: 419A0050  beq cr6, 0x825a29f8
	if ctx.cr[6].eq {
	pc = 0x825A29F8; continue 'dispatch;
	}
	// 825A29AC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 825A29B0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A29B4: 4198014C  blt cr6, 0x825a2b00
	if ctx.cr[6].lt {
	pc = 0x825A2B00; continue 'dispatch;
	}
	// 825A29B8: 817D0048  lwz r11, 0x48(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A29BC: 7C6BF02E  lwzx r3, r11, r30
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 825A29C0: 81630028  lwz r11, 0x28(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) } as u64;
	// 825A29C4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 825A29C8: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 825A29CC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A29D0: 816B0038  lwz r11, 0x38(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 825A29D4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A29D8: 4E800421  bctrl
	ctx.lr = 0x825A29DC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A29DC: 897D0045  lbz r11, 0x45(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(69 as u32) ) } as u64;
	// 825A29E0: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 825A29E4: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 825A29E8: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 825A29EC: 4198FFC4  blt cr6, 0x825a29b0
	if ctx.cr[6].lt {
	pc = 0x825A29B0; continue 'dispatch;
	}
	// 825A29F0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 825A29F4: 4198010C  blt cr6, 0x825a2b00
	if ctx.cr[6].lt {
	pc = 0x825A2B00; continue 'dispatch;
	}
	// 825A29F8: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A29FC: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2A00: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 825A2A04: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 825A2A08: 83EB3920  lwz r31, 0x3920(r11)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(14624 as u32) ) } as u64;
	// 825A2A0C: 816A0034  lwz r11, 0x34(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 825A2A10: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2A14: 4E800421  bctrl
	ctx.lr = 0x825A2A18;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2A18: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 825A2A1C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 825A2A20: 4198001C  blt cr6, 0x825a2a3c
	if ctx.cr[6].lt {
	pc = 0x825A2A3C; continue 'dispatch;
	}
	// 825A2A24: 409A00D8  bne cr6, 0x825a2afc
	if !ctx.cr[6].eq {
	pc = 0x825A2AFC; continue 'dispatch;
	}
	// 825A2A28: 897D004C  lbz r11, 0x4c(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(76 as u32) ) } as u64;
	// 825A2A2C: 815F007C  lwz r10, 0x7c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(124 as u32) ) } as u64;
	// 825A2A30: 1D6B002C  mulli r11, r11, 0x2c
	ctx.r[11].s64 = ctx.r[11].s64 * 44;
	// 825A2A34: 7F6B5214  add r27, r11, r10
	ctx.r[27].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 825A2A38: 48000008  b 0x825a2a40
	pc = 0x825A2A40; continue 'dispatch;
	// 825A2A3C: 3B7F0050  addi r27, r31, 0x50
	ctx.r[27].s64 = ctx.r[31].s64 + 80;
	// 825A2A40: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 825A2A44: 419A00B8  beq cr6, 0x825a2afc
	if ctx.cr[6].eq {
	pc = 0x825A2AFC; continue 'dispatch;
	}
	// 825A2A48: 4816B405  bl 0x8270de4c
	ctx.lr = 0x825A2A4C;
	// extern call 0x8270DE4C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 825A2A4C: 3D60829A  lis r11, -0x7d66
	ctx.r[11].s64 = -2103836672;
	// 825A2A50: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 825A2A54: 3BEB38B0  addi r31, r11, 0x38b0
	ctx.r[31].s64 = ctx.r[11].s64 + 14512;
	// 825A2A58: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 825A2A5C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2A60: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A2A64: 419A0010  beq cr6, 0x825a2a74
	if ctx.cr[6].eq {
	pc = 0x825A2A74; continue 'dispatch;
	}
	// 825A2A68: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2A6C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 825A2A70: 419A0018  beq cr6, 0x825a2a88
	if ctx.cr[6].eq {
	pc = 0x825A2A88; continue 'dispatch;
	}
	// 825A2A74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2A78: 4816AE15  bl 0x8270d88c
	ctx.lr = 0x825A2A7C;
	// extern call 0x8270D88C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 825A2A7C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 825A2A80: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 825A2A84: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2A88: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 825A2A8C: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 825A2A90: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A2A94: 815B0028  lwz r10, 0x28(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(40 as u32) ) } as u64;
	// 825A2A98: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2A9C: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 825A2AA0: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 825A2AA4: 810A0004  lwz r8, 4(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2AA8: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 825A2AAC: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A2AB0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2AB4: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2AB8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2ABC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A2AC0: 419A003C  beq cr6, 0x825a2afc
	if ctx.cr[6].eq {
	pc = 0x825A2AFC; continue 'dispatch;
	}
	// 825A2AC4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 825A2AC8: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 825A2ACC: 409A0030  bne cr6, 0x825a2afc
	if !ctx.cr[6].eq {
	pc = 0x825A2AFC; continue 'dispatch;
	}
	// 825A2AD0: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 825A2AD4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 825A2AD8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A2ADC: 409A0020  bne cr6, 0x825a2afc
	if !ctx.cr[6].eq {
	pc = 0x825A2AFC; continue 'dispatch;
	}
	// 825A2AE0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 825A2AE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2AE8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 825A2AEC: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 825A2AF0: 4816AD8D  bl 0x8270d87c
	ctx.lr = 0x825A2AF4;
	// extern call 0x8270D87C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 825A2AF4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 825A2AF8: 4816B365  bl 0x8270de5c
	ctx.lr = 0x825A2AFC;
	// extern call 0x8270DE5C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 825A2AFC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 825A2B00: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 825A2B04: 4BF92600  b 0x82535104
	sub_825350D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2B08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x825A2B08 size=208
    let mut pc: u32 = 0x825A2B08;
    'dispatch: loop {
        match pc {
            0x825A2B08 => {
    //   block [0x825A2B08..0x825A2BD8)
	// 825A2B08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 825A2B0C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 825A2B10: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 825A2B14: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 825A2B18: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2B1C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2B20: 816B0048  lwz r11, 0x48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 825A2B24: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2B28: 4E800421  bctrl
	ctx.lr = 0x825A2B2C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2B2C: 90610054  stw r3, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[3].u32 ) };
	// 825A2B30: 38600003  li r3, 3
	ctx.r[3].s64 = 3;
	// 825A2B34: 4BD4E89D  bl 0x822f13d0
	ctx.lr = 0x825A2B38;
	sub_822F13D0(ctx, base);
	// 825A2B38: 817F002C  lwz r11, 0x2c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) } as u64;
	// 825A2B3C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2B40: 419A0018  beq cr6, 0x825a2b58
	if ctx.cr[6].eq {
	pc = 0x825A2B58; continue 'dispatch;
	}
	// 825A2B44: 815F0030  lwz r10, 0x30(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 825A2B48: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 825A2B4C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 825A2B50: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2B54: 4E800421  bctrl
	ctx.lr = 0x825A2B58;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2B58: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 825A2B5C: 556B077A  rlwinm r11, r11, 0, 0x1d, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 825A2B60: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2B64: 419A001C  beq cr6, 0x825a2b80
	if ctx.cr[6].eq {
	pc = 0x825A2B80; continue 'dispatch;
	}
	// 825A2B68: A17F0040  lhz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 825A2B6C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 825A2B70: 419A004C  beq cr6, 0x825a2bbc
	if ctx.cr[6].eq {
	pc = 0x825A2BBC; continue 'dispatch;
	}
	// 825A2B74: 3D6B0001  addis r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 65536;
	// 825A2B78: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 825A2B7C: B17F0040  sth r11, 0x40(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[11].u16 ) };
	// 825A2B80: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2B84: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 825A2B88: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2B8C: 816B0054  lwz r11, 0x54(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 825A2B90: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2B94: 4E800421  bctrl
	ctx.lr = 0x825A2B98;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2B98: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 825A2B9C: 38600003  li r3, 3
	ctx.r[3].s64 = 3;
	// 825A2BA0: 4BD4E831  bl 0x822f13d0
	ctx.lr = 0x825A2BA4;
	sub_822F13D0(ctx, base);
	// 825A2BA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2BA8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 825A2BAC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 825A2BB0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 825A2BB4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 825A2BB8: 4E800020  blr
	return;
	// 825A2BBC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2BC0: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 825A2BC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 825A2BC8: 816B003C  lwz r11, 0x3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 825A2BCC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 825A2BD0: 4E800421  bctrl
	ctx.lr = 0x825A2BD4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 825A2BD4: 4BFFFFC4  b 0x825a2b98
	pc = 0x825A2B98; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_825A2BD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x825A2BD8 size=24
    let mut pc: u32 = 0x825A2BD8;
    'dispatch: loop {
        match pc {
            0x825A2BD8 => {
    //   block [0x825A2BD8..0x825A2BF0)
	// 825A2BD8: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 825A2BDC: 39430034  addi r10, r3, 0x34
	ctx.r[10].s64 = ctx.r[3].s64 + 52;
	// 825A2BE0: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 825A2BE4: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 825A2BE8: 916A0004  stw r11, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 825A2BEC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}



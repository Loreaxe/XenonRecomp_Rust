pub fn sub_8280B0E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280B0E8 size=128
    let mut pc: u32 = 0x8280B0E8;
    'dispatch: loop {
        match pc {
            0x8280B0E8 => {
    //   block [0x8280B0E8..0x8280B168)
	// 8280B0E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B0EC: 4899D081  bl 0x831a816c
	ctx.lr = 0x8280B0F0;
	sub_831A8130(ctx, base);
	// 8280B0F0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B0F4: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280B0F8: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280B0FC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280B100: 3BEBADDC  addi r31, r11, -0x5224
	ctx.r[31].s64 = ctx.r[11].s64 + -21028;
	// 8280B104: 816AADE4  lwz r11, -0x521c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-21020 as u32) ) } as u64;
	// 8280B108: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8280B10C: 40820024  bne 0x8280b130
	if !ctx.cr[0].eq {
	pc = 0x8280B130; continue 'dispatch;
	}
	// 8280B110: 3D208290  lis r9, -0x7d70
	ctx.r[9].s64 = -2104492032;
	// 8280B114: 3D008281  lis r8, -0x7d7f
	ctx.r[8].s64 = -2105475072;
	// 8280B118: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8280B11C: 3929DD90  addi r9, r9, -0x2270
	ctx.r[9].s64 = ctx.r[9].s64 + -8816;
	// 8280B120: 39089CC0  addi r8, r8, -0x6340
	ctx.r[8].s64 = ctx.r[8].s64 + -25408;
	// 8280B124: 916AADE4  stw r11, -0x521c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-21020 as u32), ctx.r[11].u32 ) };
	// 8280B128: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8280B12C: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8280B130: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8280B134: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8280B138: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B13C: 38DE0008  addi r6, r30, 8
	ctx.r[6].s64 = ctx.r[30].s64 + 8;
	// 8280B140: 9BAB0000  stb r29, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u8 ) };
	// 8280B144: 88E10050  lbz r7, 0x50(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280B148: 4BE49479  bl 0x826545c0
	ctx.lr = 0x8280B14C;
	sub_826545C0(ctx, base);
	// 8280B14C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280B150: 4182000C  beq 0x8280b15c
	if ctx.cr[0].eq {
	pc = 0x8280B15C; continue 'dispatch;
	}
	// 8280B154: 93FE0000  stw r31, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280B158: 48000008  b 0x8280b160
	pc = 0x8280B160; continue 'dispatch;
	// 8280B15C: 93BE0000  stw r29, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8280B160: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280B164: 4899D058  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B168(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B168 size=452
    let mut pc: u32 = 0x8280B168;
    'dispatch: loop {
        match pc {
            0x8280B168 => {
    //   block [0x8280B168..0x8280B32C)
	// 8280B168: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B16C: 4899CFF9  bl 0x831a8164
	ctx.lr = 0x8280B170;
	sub_831A8130(ctx, base);
	// 8280B170: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B174: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B178: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8280B17C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280B180: 4BD06859  bl 0x825119d8
	ctx.lr = 0x8280B184;
	sub_825119D8(ctx, base);
	// 8280B184: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280B188: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280B18C: 3BAB8388  addi r29, r11, -0x7c78
	ctx.r[29].s64 = ctx.r[11].s64 + -31864;
	// 8280B190: 38A00143  li r5, 0x143
	ctx.r[5].s64 = 323;
	// 8280B194: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280B198: 386000A8  li r3, 0xa8
	ctx.r[3].s64 = 168;
	// 8280B19C: 485E724D  bl 0x82df23e8
	ctx.lr = 0x8280B1A0;
	sub_82DF23E8(ctx, base);
	// 8280B1A0: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280B1A4: 41820010  beq 0x8280b1b4
	if ctx.cr[0].eq {
	pc = 0x8280B1B4; continue 'dispatch;
	}
	// 8280B1A8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280B1AC: 4BFC53A5  bl 0x827d0550
	ctx.lr = 0x8280B1B0;
	sub_827D0550(ctx, base);
	// 8280B1B0: 48000008  b 0x8280b1b8
	pc = 0x8280B1B8; continue 'dispatch;
	// 8280B1B4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8280B1B8: 817F0128  lwz r11, 0x128(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) } as u64;
	// 8280B1BC: 907F0128  stw r3, 0x128(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), ctx.r[3].u32 ) };
	// 8280B1C0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280B1C4: 419A001C  beq cr6, 0x8280b1e0
	if ctx.cr[6].eq {
	pc = 0x8280B1E0; continue 'dispatch;
	}
	// 8280B1C8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B1CC: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8280B1D0: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280B1D4: 816A0000  lwz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B1D8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280B1DC: 4E800421  bctrl
	ctx.lr = 0x8280B1E0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280B1E0: 3D608328  lis r11, -0x7cd8
	ctx.r[11].s64 = -2094530560;
	// 8280B1E4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280B1E8: 808BE250  lwz r4, -0x1db0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-7600 as u32) ) } as u64;
	// 8280B1EC: 485E881D  bl 0x82df3a08
	ctx.lr = 0x8280B1F0;
	sub_82DF3A08(ctx, base);
	// 8280B1F0: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280B1F4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280B1F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280B1FC: 4BCFD585  bl 0x82508780
	ctx.lr = 0x8280B200;
	sub_82508780(ctx, base);
	// 8280B200: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280B204: 485E8225  bl 0x82df3428
	ctx.lr = 0x8280B208;
	sub_82DF3428(ctx, base);
	// 8280B208: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280B20C: 389F0028  addi r4, r31, 0x28
	ctx.r[4].s64 = ctx.r[31].s64 + 40;
	// 8280B210: 409A0008  bne cr6, 0x8280b218
	if !ctx.cr[6].eq {
	pc = 0x8280B218; continue 'dispatch;
	}
	// 8280B214: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280B218: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280B21C: 4BCFD585  bl 0x825087a0
	ctx.lr = 0x8280B220;
	sub_825087A0(ctx, base);
	// 8280B220: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B224: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 8280B228: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 8280B22C: 38800060  li r4, 0x60
	ctx.r[4].s64 = 96;
	// 8280B230: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8280B234: 486954FD  bl 0x82ea0730
	ctx.lr = 0x8280B238;
	sub_82EA0730(ctx, base);
	// 8280B238: 3D608332  lis r11, -0x7cce
	ctx.r[11].s64 = -2093875200;
	// 8280B23C: 39400060  li r10, 0x60
	ctx.r[10].s64 = 96;
	// 8280B240: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 8280B244: B1430004  sth r10, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u16 ) };
	// 8280B248: C1BF00F0  lfs f13, 0xf0(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280B24C: C19F00EC  lfs f12, 0xec(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(236 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280B250: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 8280B254: C04BF614  lfs f2, -0x9ec(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2540 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8280B258: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8280B25C: 3969BC40  addi r11, r9, -0x43c0
	ctx.r[11].s64 = ctx.r[9].s64 + -17344;
	// 8280B260: C17F00F4  lfs f11, 0xf4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(244 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8280B264: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 8280B268: D1610064  stfs f11, 0x64(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 8280B26C: 38E10080  addi r7, r1, 0x80
	ctx.r[7].s64 = ctx.r[1].s64 + 128;
	// 8280B270: C00808A4  lfs f0, 0x8a4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B274: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 8280B278: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 8280B27C: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8280B280: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 8280B284: D001006C  stfs f0, 0x6c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 8280B288: EC2D0332  fmuls f1, f13, f12
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[12].f64) as f32) as f64);
	// 8280B28C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280B290: 13C050C7  vcmpequd (lvx128) v30, v0, v10
	tmp.u32 = ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B330 size=240
    let mut pc: u32 = 0x8280B330;
    'dispatch: loop {
        match pc {
            0x8280B330 => {
    //   block [0x8280B330..0x8280B420)
	// 8280B330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B334: 4899CE31  bl 0x831a8164
	ctx.lr = 0x8280B338;
	sub_831A8130(ctx, base);
	// 8280B338: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B33C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B340: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8280B344: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 8280B348: 7D1C4378  mr r28, r8
	ctx.r[28].u64 = ctx.r[8].u64;
	// 8280B34C: 7D3B4B78  mr r27, r9
	ctx.r[27].u64 = ctx.r[9].u64;
	// 8280B350: 4BD06F11  bl 0x82512260
	ctx.lr = 0x8280B354;
	sub_82512260(ctx, base);
	// 8280B354: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280B358: 93BF00E4  stw r29, 0xe4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(228 as u32), ctx.r[29].u32 ) };
	// 8280B35C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280B360: 396B844C  addi r11, r11, -0x7bb4
	ctx.r[11].s64 = ctx.r[11].s64 + -31668;
	// 8280B364: 394A8434  addi r10, r10, -0x7bcc
	ctx.r[10].s64 = ctx.r[10].s64 + -31692;
	// 8280B368: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280B36C: 387F0108  addi r3, r31, 0x108
	ctx.r[3].s64 = ctx.r[31].s64 + 264;
	// 8280B370: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280B374: C01E0000  lfs f0, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B378: D01F00E8  stfs f0, 0xe8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 8280B37C: 389E0020  addi r4, r30, 0x20
	ctx.r[4].s64 = ctx.r[30].s64 + 32;
	// 8280B380: C01E0004  lfs f0, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B384: D01F00EC  stfs f0, 0xec(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 8280B388: C01E0008  lfs f0, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B38C: D01F00F0  stfs f0, 0xf0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(240 as u32), tmp.u32 ) };
	// 8280B390: C01E000C  lfs f0, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B394: D01F00F4  stfs f0, 0xf4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(244 as u32), tmp.u32 ) };
	// 8280B398: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 8280B39C: 917F00F8  stw r11, 0xf8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(248 as u32), ctx.r[11].u32 ) };
	// 8280B3A0: 817E0014  lwz r11, 0x14(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 8280B3A4: 917F00FC  stw r11, 0xfc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(252 as u32), ctx.r[11].u32 ) };
	// 8280B3A8: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B3AC: D01F0100  stfs f0, 0x100(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 8280B3B0: C01E001C  lfs f0, 0x1c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B3B4: D01F0104  stfs f0, 0x104(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 8280B3B8: 485E8849  bl 0x82df3c00
	ctx.lr = 0x8280B3BC;
	sub_82DF3C00(ctx, base);
	// 8280B3BC: 387F010C  addi r3, r31, 0x10c
	ctx.r[3].s64 = ctx.r[31].s64 + 268;
	// 8280B3C0: 389E0024  addi r4, r30, 0x24
	ctx.r[4].s64 = ctx.r[30].s64 + 36;
	// 8280B3C4: 485E883D  bl 0x82df3c00
	ctx.lr = 0x8280B3C8;
	sub_82DF3C00(ctx, base);
	// 8280B3C8: C19E0028  lfs f12, 0x28(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280B3CC: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 8280B3D0: D19F0110  stfs f12, 0x110(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(272 as u32), tmp.u32 ) };
	// 8280B3D4: 3D208200  lis r9, -0x7e00
	ctx.r[9].s64 = -2113929216;
	// 8280B3D8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280B3DC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B3E0: C00A9F78  lfs f0, -0x6088(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-24712 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B3E4: C1A908A4  lfs f13, 0x8a4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(2212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280B3E8: C19E002C  lfs f12, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280B3EC: 939F0118  stw r28, 0x118(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(280 as u32), ctx.r[28].u32 ) };
	// 8280B3F0: D19F0114  stfs f12, 0x114(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(276 as u32), tmp.u32 ) };
	// 8280B3F4: 937F011C  stw r27, 0x11c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(284 as u32), ctx.r[27].u32 ) };
	// 8280B3F8: 917F0120  stw r11, 0x120(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 8280B3FC: 917F0124  stw r11, 0x124(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[11].u32 ) };
	// 8280B400: 917F0128  stw r11, 0x128(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), ctx.r[11].u32 ) };
	// 8280B404: D01F012C  stfs f0, 0x12c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), tmp.u32 ) };
	// 8280B408: D1BF0130  stfs f13, 0x130(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 8280B40C: 917F0138  stw r11, 0x138(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(312 as u32), ctx.r[11].u32 ) };
	// 8280B410: 917F013C  stw r11, 0x13c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(316 as u32), ctx.r[11].u32 ) };
	// 8280B414: 917F0140  stw r11, 0x140(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(320 as u32), ctx.r[11].u32 ) };
	// 8280B418: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280B41C: 4899CD98  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B420(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B420 size=504
    let mut pc: u32 = 0x8280B420;
    'dispatch: loop {
        match pc {
            0x8280B420 => {
    //   block [0x8280B420..0x8280B618)
	// 8280B420: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B424: 4899CD41  bl 0x831a8164
	ctx.lr = 0x8280B428;
	sub_831A8130(ctx, base);
	// 8280B428: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B42C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B430: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8280B434: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280B438: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280B43C: 93A100CC  stw r29, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[29].u32 ) };
	// 8280B440: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 8280B444: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8280B448: 4BD04081  bl 0x8250f4c8
	ctx.lr = 0x8280B44C;
	sub_8250F4C8(ctx, base);
	// 8280B44C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B450: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280B454: 386BFFFC  addi r3, r11, -4
	ctx.r[3].s64 = ctx.r[11].s64 + -4;
	// 8280B458: 409A0008  bne cr6, 0x8280b460
	if !ctx.cr[6].eq {
	pc = 0x8280B460; continue 'dispatch;
	}
	// 8280B45C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8280B460: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280B464: 4BCFD5B5  bl 0x82508a18
	ctx.lr = 0x8280B468;
	sub_82508A18(ctx, base);
	// 8280B468: 7D7D1850  subf r11, r29, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[29].s64;
	// 8280B46C: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280B470: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8280B474: 557BDFFE  rlwinm r27, r11, 0x1b, 0x1f, 0x1f
	ctx.r[27].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8280B478: 485E6819  bl 0x82df1c90
	ctx.lr = 0x8280B47C;
	sub_82DF1C90(ctx, base);
	// 8280B47C: 281B0000  cmplwi r27, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280B480: 418200B0  beq 0x8280b530
	if ctx.cr[0].eq {
	pc = 0x8280B530; continue 'dispatch;
	}
	// 8280B484: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 8280B488: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B48C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280B490: 3B810050  addi r28, r1, 0x50
	ctx.r[28].s64 = ctx.r[1].s64 + 80;
	// 8280B494: 4BD06655  bl 0x82511ae8
	ctx.lr = 0x8280B498;
	sub_82511AE8(ctx, base);
	// 8280B498: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280B49C: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8280B4A0: 388B85E4  addi r4, r11, -0x7a1c
	ctx.r[4].s64 = ctx.r[11].s64 + -31260;
	// 8280B4A4: 38DF00FC  addi r6, r31, 0xfc
	ctx.r[6].s64 = ctx.r[31].s64 + 252;
	// 8280B4A8: 38BF00F8  addi r5, r31, 0xf8
	ctx.r[5].s64 = ctx.r[31].s64 + 248;
	// 8280B4AC: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8280B4B0: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8280B4B4: 7F89E378  mr r9, r28
	ctx.r[9].u64 = ctx.r[28].u64;
	// 8280B4B8: 480973D9  bl 0x828a2890
	ctx.lr = 0x8280B4BC;
	sub_828A2890(ctx, base);
	// 8280B4BC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B4C0: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8280B4C4: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280B4C8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280B4CC: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8280B4D0: 419A0024  beq cr6, 0x8280b4f4
	if ctx.cr[6].eq {
	pc = 0x8280B4F4; continue 'dispatch;
	}
	// 8280B4D4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280B4D8: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280B4DC: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280B4E0: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280B4E4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280B4E8: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280B4EC: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280B4F0: 4082FFE8  bne 0x8280b4d8
	if !ctx.cr[0].eq {
	pc = 0x8280B4D8; continue 'dispatch;
	}
	// 8280B4F4: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280B4F8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280B4FC: 38E10058  addi r7, r1, 0x58
	ctx.r[7].s64 = ctx.r[1].s64 + 88;
	// 8280B500: 388A8388  addi r4, r10, -0x7c78
	ctx.r[4].s64 = ctx.r[10].s64 + -31864;
	// 8280B504: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280B508: 38A001C6  li r5, 0x1c6
	ctx.r[5].s64 = 454;
	// 8280B50C: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280B510: 387F0028  addi r3, r31, 0x28
	ctx.r[3].s64 = ctx.r[31].s64 + 40;
	// 8280B514: 4864D52D  bl 0x82e58a40
	ctx.lr = 0x8280B518;
	sub_82E58A40(ctx, base);
	// 8280B518: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280B51C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280B520: 419A0008  beq cr6, 0x8280b528
	if ctx.cr[6].eq {
	pc = 0x8280B528; continue 'dispatch;
	}
	// 8280B524: 4BAB536D  bl 0x822c0890
	ctx.lr = 0x8280B528;
	sub_822C0890(ctx, base);
	// 8280B528: 80610074  lwz r3, 0x74(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 8280B52C: 480000D8  b 0x8280b604
	pc = 0x8280B604; continue 'dispatch;
	// 8280B530: 817F0138  lwz r11, 0x138(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280B534: 815F013C  lwz r10, 0x13c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(316 as u32) ) } as u64;
	// 8280B538: 48000014  b 0x8280b54c
	pc = 0x8280B54C; continue 'dispatch;
	// 8280B53C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B540: 7F09E840  cmplw cr6, r9, r29
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8280B544: 419A0010  beq cr6, 0x8280b554
	if ctx.cr[6].eq {
	pc = 0x8280B554; continue 'dispatch;
	}
	// 8280B548: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280B54C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8280B550: 409AFFEC  bne cr6, 0x8280b53c
	if !ctx.cr[6].eq {
	pc = 0x8280B53C; continue 'dispatch;
	}
	// 8280B554: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8280B558: 409A00B8  bne cr6, 0x8280b610
	if !ctx.cr[6].eq {
	pc = 0x8280B610; continue 'dispatch;
	}
	// 8280B55C: 388100CC  addi r4, r1, 0xcc
	ctx.r[4].s64 = ctx.r[1].s64 + 204;
	// 8280B560: 387F0134  addi r3, r31, 0x134
	ctx.r[3].s64 = ctx.r[31].s64 + 308;
	// 8280B564: 4BCADBAD  bl 0x824b9110
	ctx.lr = 0x8280B568;
	sub_824B9110(ctx, base);
	// 8280B568: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 8280B56C: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280B570: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280B574: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 8280B578: 388A85E4  addi r4, r10, -0x7a1c
	ctx.r[4].s64 = ctx.r[10].s64 + -31260;
	// 8280B57C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 8280B580: 7F87E378  mr r7, r28
	ctx.r[7].u64 = ctx.r[28].u64;
	// 8280B584: 38DF00FC  addi r6, r31, 0xfc
	ctx.r[6].s64 = ctx.r[31].s64 + 252;
	// 8280B588: 38BF00F8  addi r5, r31, 0xf8
	ctx.r[5].s64 = ctx.r[31].s64 + 248;
	// 8280B58C: 38610078  addi r3, r1, 0x78
	ctx.r[3].s64 = ctx.r[1].s64 + 120;
	// 8280B590: 48097301  bl 0x828a2890
	ctx.lr = 0x8280B594;
	sub_828A2890(ctx, base);
	// 8280B594: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B598: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8280B59C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280B5A0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280B5A4: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8280B5A8: 419A0024  beq cr6, 0x8280b5cc
	if ctx.cr[6].eq {
	pc = 0x8280B5CC; continue 'dispatch;
	}
	// 8280B5AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280B5B0: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280B5B4: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280B5B8: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280B5BC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280B5C0: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280B5C4: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280B5C8: 4082FFE8  bne 0x8280b5b0
	if !ctx.cr[0].eq {
	pc = 0x8280B5B0; continue 'dispatch;
	}
	// 8280B5CC: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280B5D0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280B5D4: 38E10060  addi r7, r1, 0x60
	ctx.r[7].s64 = ctx.r[1].s64 + 96;
	// 8280B5D8: 388A8388  addi r4, r10, -0x7c78
	ctx.r[4].s64 = ctx.r[10].s64 + -31864;
	// 8280B5DC: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280B5E0: 38A001CD  li r5, 0x1cd
	ctx.r[5].s64 = 461;
	// 8280B5E4: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280B5E8: 387F0028  addi r3, r31, 0x28
	ctx.r[3].s64 = ctx.r[31].s64 + 40;
	// 8280B5EC: 4864D455  bl 0x82e58a40
	ctx.lr = 0x8280B5F0;
	sub_82E58A40(ctx, base);
	// 8280B5F0: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8280B5F4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280B5F8: 419A0008  beq cr6, 0x8280b600
	if ctx.cr[6].eq {
	pc = 0x8280B600; continue 'dispatch;
	}
	// 8280B5FC: 4BAB5295  bl 0x822c0890
	ctx.lr = 0x8280B600;
	sub_822C0890(ctx, base);
	// 8280B600: 8061007C  lwz r3, 0x7c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 8280B604: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280B608: 419A0008  beq cr6, 0x8280b610
	if ctx.cr[6].eq {
	pc = 0x8280B610; continue 'dispatch;
	}
	// 8280B60C: 4BAB5285  bl 0x822c0890
	ctx.lr = 0x8280B610;
	sub_822C0890(ctx, base);
	// 8280B610: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8280B614: 4899CBA0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B618 size=108
    let mut pc: u32 = 0x8280B618;
    'dispatch: loop {
        match pc {
            0x8280B618 => {
    //   block [0x8280B618..0x8280B684)
	// 8280B618: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B61C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280B620: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280B624: DBE1FFE8  stfd f31, -0x18(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.f[31].u64 ) };
	// 8280B628: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B62C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B630: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 8280B634: 4BFFFCFD  bl 0x8280b330
	ctx.lr = 0x8280B638;
	sub_8280B330(ctx, base);
	// 8280B638: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280B63C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280B640: D3FF0148  stfs f31, 0x148(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), tmp.u32 ) };
	// 8280B644: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 8280B648: 394A84AC  addi r10, r10, -0x7b54
	ctx.r[10].s64 = ctx.r[10].s64 + -31572;
	// 8280B64C: 39298494  addi r9, r9, -0x7b6c
	ctx.r[9].s64 = ctx.r[9].s64 + -31596;
	// 8280B650: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8280B654: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B658: D01F014C  stfs f0, 0x14c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), tmp.u32 ) };
	// 8280B65C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8280B660: 913F0028  stw r9, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[9].u32 ) };
	// 8280B664: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B668: 911F0144  stw r8, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[8].u32 ) };
	// 8280B66C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280B670: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280B674: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280B678: CBE1FFE8  lfd f31, -0x18(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280B67C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280B680: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B688(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B688 size=604
    let mut pc: u32 = 0x8280B688;
    'dispatch: loop {
        match pc {
            0x8280B688 => {
    //   block [0x8280B688..0x8280B8E4)
	// 8280B688: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B68C: 4899CAD1  bl 0x831a815c
	ctx.lr = 0x8280B690;
	sub_831A8130(ctx, base);
	// 8280B690: DBE1FFB8  stfd f31, -0x48(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[31].u64 ) };
	// 8280B694: 9421FEE0  stwu r1, -0x120(r1)
	ea = ctx.r[1].u32.wrapping_add(-288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B698: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B69C: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8280B6A0: 807F0128  lwz r3, 0x128(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) } as u64;
	// 8280B6A4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280B6A8: 419A0230  beq cr6, 0x8280b8d8
	if ctx.cr[6].eq {
	pc = 0x8280B8D8; continue 'dispatch;
	}
	// 8280B6AC: 809F0144  lwz r4, 0x144(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280B6B0: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8280B6B4: 419A0070  beq cr6, 0x8280b724
	if ctx.cr[6].eq {
	pc = 0x8280B724; continue 'dispatch;
	}
	// 8280B6B8: C01F0148  lfs f0, 0x148(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B6BC: C1BF00E8  lfs f13, 0xe8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(232 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280B6C0: EC200372  fmuls f1, f0, f13
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 8280B6C4: 4BFC4015  bl 0x827cf6d8
	ctx.lr = 0x8280B6C8;
	sub_827CF6D8(ctx, base);
	// 8280B6C8: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280B6CC: C1BF00F0  lfs f13, 0xf0(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280B6D0: C00B9450  lfs f0, -0x6bb0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B6D4: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 8280B6D8: 4098004C  bge cr6, 0x8280b724
	if !ctx.cr[6].lt {
	pc = 0x8280B724; continue 'dispatch;
	}
	// 8280B6DC: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280B6E0: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280B6E4: C00B9524  lfs f0, -0x6adc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280B6E8: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8280B6EC: C1AA08A4  lfs f13, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280B6F0: D01F014C  stfs f0, 0x14c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), tmp.u32 ) };
	// 8280B6F4: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8280B6F8: 41990008  bgt cr6, 0x8280b700
	if ctx.cr[6].gt {
	pc = 0x8280B700; continue 'dispatch;
	}
	// 8280B6FC: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 8280B700: D01F014C  stfs f0, 0x14c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), tmp.u32 ) };
	// 8280B704: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280B708: 809F0144  lwz r4, 0x144(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280B70C: FC200090  fmr f1, f0
	ctx.f[1].f64 = ctx.f[0].f64;
	// 8280B710: 807F0128  lwz r3, 0x128(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) } as u64;
	// 8280B714: C08B08A8  lfs f4, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8280B718: FC602090  fmr f3, f4
	ctx.f[3].f64 = ctx.f[4].f64;
	// 8280B71C: FC402090  fmr f2, f4
	ctx.f[2].f64 = ctx.f[4].f64;
	// 8280B720: 4BFC4021  bl 0x827cf740
	ctx.lr = 0x8280B724;
	sub_827CF740(ctx, base);
	// 8280B724: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280B728: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280B72C: 3BAB9BC9  addi r29, r11, -0x6437
	ctx.r[29].s64 = ctx.r[11].s64 + -25655;
	// 8280B730: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280B734: 485E82D5  bl 0x82df3a08
	ctx.lr = 0x8280B738;
	sub_82DF3A08(ctx, base);
	// 8280B738: 3BDF0108  addi r30, r31, 0x108
	ctx.r[30].s64 = ctx.r[31].s64 + 264;
	// 8280B73C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280B740: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280B744: 485E7B5D  bl 0x82df32a0
	ctx.lr = 0x8280B748;
	sub_82DF32A0(ctx, base);
	// 8280B748: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280B74C: 41820014  beq 0x8280b760
	if ctx.cr[0].eq {
	pc = 0x8280B760; continue 'dispatch;
	}
	// 8280B750: 817F0144  lwz r11, 0x144(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280B754: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280B758: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8280B75C: 419A0008  beq cr6, 0x8280b764
	if ctx.cr[6].eq {
	pc = 0x8280B764; continue 'dispatch;
	}
	// 8280B760: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 8280B764: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280B768: 557C063E  clrlwi r28, r11, 0x18
	ctx.r[28].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 8280B76C: 485E7CBD  bl 0x82df3428
	ctx.lr = 0x8280B770;
	sub_82DF3428(ctx, base);
	// 8280B770: 281C0000  cmplwi r28, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280B774: 41820164  beq 0x8280b8d8
	if ctx.cr[0].eq {
	pc = 0x8280B8D8; continue 'dispatch;
	}
	// 8280B778: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 8280B77C: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 8280B780: 396B6880  addi r11, r11, 0x6880
	ctx.r[11].s64 = ctx.r[11].s64 + 26752;
	// 8280B784: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8280B788: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 8280B78C: 38E10090  addi r7, r1, 0x90
	ctx.r[7].s64 = ctx.r[1].s64 + 144;
	// 8280B790: 38C100A0  addi r6, r1, 0xa0
	ctx.r[6].s64 = ctx.r[1].s64 + 160;
	// 8280B794: 38A100B0  addi r5, r1, 0xb0
	ctx.r[5].s64 = ctx.r[1].s64 + 176;
	// 8280B798: 13E05C07  vcmpneb. (lvlx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280B79C: 388100C0  addi r4, r1, 0xc0
	ctx.r[4].s64 = ctx.r[1].s64 + 192;
	// 8280B7A0: 13CA5C07  vcmpneb. (lvlx128) v30, v10, v11
	tmp.u32 = ctx.r[10].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280B7A4: 13A95C07  vcmpneb. (lvlx128) v29, v9, v11
	tmp.u32 = ctx.r[9].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280B7A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B7AC: 13885C07  vcmpneb. (lvlx128) v28, v8, v11
	tmp.u32 = ctx.r[8].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B8E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280B8E8 size=72
    let mut pc: u32 = 0x8280B8E8;
    'dispatch: loop {
        match pc {
            0x8280B8E8 => {
    //   block [0x8280B8E8..0x8280B930)
	// 8280B8E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B8EC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280B8F0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280B8F4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B8F8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280B8FC: 4BFEDA45  bl 0x827f9340
	ctx.lr = 0x8280B900;
	sub_827F9340(ctx, base);
	// 8280B900: 3D608202  lis r11, -0x7dfe
	ctx.r[11].s64 = -2113798144;
	// 8280B904: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B908: C02B66D4  lfs f1, 0x66d4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26324 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280B90C: 4BAE1B05  bl 0x822ed410
	ctx.lr = 0x8280B910;
	sub_822ED410(ctx, base);
	// 8280B910: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280B914: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B918: 4BC83A31  bl 0x8248f348
	ctx.lr = 0x8280B91C;
	sub_8248F348(ctx, base);
	// 8280B91C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280B920: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280B924: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280B928: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280B92C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B930(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280B930 size=12
    let mut pc: u32 = 0x8280B930;
    'dispatch: loop {
        match pc {
            0x8280B930 => {
    //   block [0x8280B930..0x8280B93C)
	// 8280B930: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280B934: 386B84F4  addi r3, r11, -0x7b0c
	ctx.r[3].s64 = ctx.r[11].s64 + -31500;
	// 8280B938: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280B940 size=84
    let mut pc: u32 = 0x8280B940;
    'dispatch: loop {
        match pc {
            0x8280B940 => {
    //   block [0x8280B940..0x8280B994)
	// 8280B940: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B944: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280B948: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280B94C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280B950: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B954: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280B958: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280B95C: 4BFEDB65  bl 0x827f94c0
	ctx.lr = 0x8280B960;
	sub_827F94C0(ctx, base);
	// 8280B960: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280B964: 4182000C  beq 0x8280b970
	if ctx.cr[0].eq {
	pc = 0x8280B970; continue 'dispatch;
	}
	// 8280B968: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280B96C: 4BC839DD  bl 0x8248f348
	ctx.lr = 0x8280B970;
	sub_8248F348(ctx, base);
	// 8280B970: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280B974: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280B978: 4BFEDE31  bl 0x827f97a8
	ctx.lr = 0x8280B97C;
	sub_827F97A8(ctx, base);
	// 8280B97C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280B980: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280B984: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280B988: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280B98C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280B990: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280B998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280B998 size=136
    let mut pc: u32 = 0x8280B998;
    'dispatch: loop {
        match pc {
            0x8280B998 => {
    //   block [0x8280B998..0x8280BA20)
	// 8280B998: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280B99C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280B9A0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280B9A4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280B9A8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280B9AC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280B9B0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280B9B4: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 8280B9B8: 409A0020  bne cr6, 0x8280b9d8
	if !ctx.cr[6].eq {
	pc = 0x8280B9D8; continue 'dispatch;
	}
	// 8280B9BC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280B9C0: 419A0048  beq cr6, 0x8280ba08
	if ctx.cr[6].eq {
	pc = 0x8280BA08; continue 'dispatch;
	}
	// 8280B9C4: E97E0000  ld r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	// 8280B9C8: F97F0000  std r11, 0(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 8280B9CC: E97E0008  ld r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	// 8280B9D0: F97F0008  std r11, 8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8280B9D4: 48000034  b 0x8280ba08
	pc = 0x8280BA08; continue 'dispatch;
	// 8280B9D8: 2F050001  cmpwi cr6, r5, 1
	ctx.cr[6].compare_i32(ctx.r[5].s32, 1, &mut ctx.xer);
	// 8280B9DC: 419A002C  beq cr6, 0x8280ba08
	if ctx.cr[6].eq {
	pc = 0x8280BA08; continue 'dispatch;
	}
	// 8280B9E0: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280B9E4: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280B9E8: 388BE8D8  addi r4, r11, -0x1728
	ctx.r[4].s64 = ctx.r[11].s64 + -5928;
	// 8280B9EC: 4899C70D  bl 0x831a80f8
	ctx.lr = 0x8280B9F0;
	sub_831A80F8(ctx, base);
	// 8280B9F0: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280B9F4: 4182000C  beq 0x8280ba00
	if ctx.cr[0].eq {
	pc = 0x8280BA00; continue 'dispatch;
	}
	// 8280B9F8: 93DF0000  stw r30, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280B9FC: 4800000C  b 0x8280ba08
	pc = 0x8280BA08; continue 'dispatch;
	// 8280BA00: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280BA04: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BA08: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280BA0C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BA10: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BA14: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280BA18: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BA1C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BA20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BA20 size=100
    let mut pc: u32 = 0x8280BA20;
    'dispatch: loop {
        match pc {
            0x8280BA20 => {
    //   block [0x8280BA20..0x8280BA84)
	// 8280BA20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BA24: 4899C749  bl 0x831a816c
	ctx.lr = 0x8280BA28;
	sub_831A8130(ctx, base);
	// 8280BA28: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BA2C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280BA30: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280BA34: 3BFD0138  addi r31, r29, 0x138
	ctx.r[31].s64 = ctx.r[29].s64 + 312;
	// 8280BA38: 817D0138  lwz r11, 0x138(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280BA3C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280BA40: 419A0030  beq cr6, 0x8280ba70
	if ctx.cr[6].eq {
	pc = 0x8280BA70; continue 'dispatch;
	}
	// 8280BA44: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BA48: 4BCFEF09  bl 0x8250a950
	ctx.lr = 0x8280BA4C;
	sub_8250A950(ctx, base);
	// 8280BA4C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280BA50: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280BA54: 386BFF40  addi r3, r11, -0xc0
	ctx.r[3].s64 = ctx.r[11].s64 + -192;
	// 8280BA58: 409A0008  bne cr6, 0x8280ba60
	if !ctx.cr[6].eq {
	pc = 0x8280BA60; continue 'dispatch;
	}
	// 8280BA5C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8280BA60: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BA64: 4BFC7F9D  bl 0x827d3a00
	ctx.lr = 0x8280BA68;
	sub_827D3A00(ctx, base);
	// 8280BA68: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BA6C: 485E6225  bl 0x82df1c90
	ctx.lr = 0x8280BA70;
	sub_82DF1C90(ctx, base);
	// 8280BA70: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280BA74: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280BA78: 4BFF88B1  bl 0x82804328
	ctx.lr = 0x8280BA7C;
	sub_82804328(ctx, base);
	// 8280BA7C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280BA80: 4899C73C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BA88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280BA88 size=68
    let mut pc: u32 = 0x8280BA88;
    'dispatch: loop {
        match pc {
            0x8280BA88 => {
    //   block [0x8280BA88..0x8280BACC)
	// 8280BA88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BA8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BA90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280BA94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BA98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BA9C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BAA0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280BAA4: 4BFED945  bl 0x827f93e8
	ctx.lr = 0x8280BAA8;
	sub_827F93E8(ctx, base);
	// 8280BAA8: C03E0000  lfs f1, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280BAAC: 807F0128  lwz r3, 0x128(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) } as u64;
	// 8280BAB0: 483A9A41  bl 0x82bb54f0
	ctx.lr = 0x8280BAB4;
	sub_82BB54F0(ctx, base);
	// 8280BAB4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280BAB8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BABC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BAC0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280BAC4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BAC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BAD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BAD0 size=96
    let mut pc: u32 = 0x8280BAD0;
    'dispatch: loop {
        match pc {
            0x8280BAD0 => {
    //   block [0x8280BAD0..0x8280BB30)
	// 8280BAD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BAD4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BAD8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280BADC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BAE0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BAE4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BAE8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280BAEC: 57CB063F  clrlwi. r11, r30, 0x18
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280BAF0: 807F0138  lwz r3, 0x138(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280BAF4: 41820018  beq 0x8280bb0c
	if ctx.cr[0].eq {
	pc = 0x8280BB0C; continue 'dispatch;
	}
	// 8280BAF8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BAFC: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8280BB00: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280BB04: 4E800421  bctrl
	ctx.lr = 0x8280BB08;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280BB08: 4800000C  b 0x8280bb14
	pc = 0x8280BB14; continue 'dispatch;
	// 8280BB0C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280BB10: 48675C31  bl 0x82e81740
	ctx.lr = 0x8280BB14;
	sub_82E81740(ctx, base);
	// 8280BB14: 9BDF015C  stb r30, 0x15c(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(348 as u32), ctx.r[30].u8 ) };
	// 8280BB18: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280BB1C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BB20: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BB24: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280BB28: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BB2C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BB30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BB30 size=196
    let mut pc: u32 = 0x8280BB30;
    'dispatch: loop {
        match pc {
            0x8280BB30 => {
    //   block [0x8280BB30..0x8280BBF4)
	// 8280BB30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BB34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BB38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280BB3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BB40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BB44: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280BB48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280BB4C: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 8280BB50: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280BB54: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BB58: 4BAB4DE1  bl 0x822c0938
	ctx.lr = 0x8280BB5C;
	sub_822C0938(ctx, base);
	// 8280BB5C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280BB60: 41820028  beq 0x8280bb88
	if ctx.cr[0].eq {
	pc = 0x8280BB88; continue 'dispatch;
	}
	// 8280BB64: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BB68: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 8280BB6C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280BB70: 392B8500  addi r9, r11, -0x7b00
	ctx.r[9].s64 = ctx.r[11].s64 + -31488;
	// 8280BB74: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8280BB78: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280BB7C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8280BB80: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8280BB84: 48000008  b 0x8280bb8c
	pc = 0x8280BB8C; continue 'dispatch;
	// 8280BB88: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280BB8C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BB90: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280BB94: 409A0044  bne cr6, 0x8280bbd8
	if !ctx.cr[6].eq {
	pc = 0x8280BBD8; continue 'dispatch;
	}
	// 8280BB98: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280BB9C: 419A001C  beq cr6, 0x8280bbb8
	if ctx.cr[6].eq {
	pc = 0x8280BBB8; continue 'dispatch;
	}
	// 8280BBA0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BBA4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280BBA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280BBAC: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BBB0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280BBB4: 4E800421  bctrl
	ctx.lr = 0x8280BBB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280BBB8: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280BBBC: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280BBC0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BBC4: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 8280BBC8: 816BE888  lwz r11, -0x1778(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-6008 as u32) ) } as u64;
	// 8280BBCC: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280BBD0: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280BBD4: 4BAB442D  bl 0x822c0000
	ctx.lr = 0x8280BBD8;
	sub_822C0000(ctx, base);
	// 8280BBD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BBDC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280BBE0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BBE4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BBE8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280BBEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BBF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BBF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BBF8 size=72
    let mut pc: u32 = 0x8280BBF8;
    'dispatch: loop {
        match pc {
            0x8280BBF8 => {
    //   block [0x8280BBF8..0x8280BC40)
	// 8280BBF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BBFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BC00: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BC04: 2F050003  cmpwi cr6, r5, 3
	ctx.cr[6].compare_i32(ctx.r[5].s32, 3, &mut ctx.xer);
	// 8280BC08: 419A001C  beq cr6, 0x8280bc24
	if ctx.cr[6].eq {
	pc = 0x8280BC24; continue 'dispatch;
	}
	// 8280BC0C: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8280BC10: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8280BC14: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8280BC18: 88C10050  lbz r6, 0x50(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280BC1C: 4BFFFD7D  bl 0x8280b998
	ctx.lr = 0x8280BC20;
	sub_8280B998(ctx, base);
	// 8280BC20: 48000010  b 0x8280bc30
	pc = 0x8280BC30; continue 'dispatch;
	// 8280BC24: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280BC28: 396BE8D8  addi r11, r11, -0x1728
	ctx.r[11].s64 = ctx.r[11].s64 + -5928;
	// 8280BC2C: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BC30: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280BC34: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BC38: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BC3C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BC40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BC40 size=84
    let mut pc: u32 = 0x8280BC40;
    'dispatch: loop {
        match pc {
            0x8280BC40 => {
    //   block [0x8280BC40..0x8280BC94)
	// 8280BC40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BC44: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BC48: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BC4C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BC50: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8280BC54: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BC58: 392B0004  addi r9, r11, 4
	ctx.r[9].s64 = ctx.r[11].s64 + 4;
	// 8280BC5C: 395F0004  addi r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 4;
	// 8280BC60: 38890004  addi r4, r9, 4
	ctx.r[4].s64 = ctx.r[9].s64 + 4;
	// 8280BC64: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BC68: 386A0004  addi r3, r10, 4
	ctx.r[3].s64 = ctx.r[10].s64 + 4;
	// 8280BC6C: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8280BC70: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280BC74: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280BC78: 4BAB87E9  bl 0x822c4460
	ctx.lr = 0x8280BC7C;
	sub_822C4460(ctx, base);
	// 8280BC7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280BC80: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280BC84: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BC88: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BC8C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BC90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BC98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BC98 size=224
    let mut pc: u32 = 0x8280BC98;
    'dispatch: loop {
        match pc {
            0x8280BC98 => {
    //   block [0x8280BC98..0x8280BD78)
	// 8280BC98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BC9C: 4899C4D1  bl 0x831a816c
	ctx.lr = 0x8280BCA0;
	sub_831A8130(ctx, base);
	// 8280BCA0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BCA4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280BCA8: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8280BCAC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280BCB0: 4861EE39  bl 0x82e2aae8
	ctx.lr = 0x8280BCB4;
	sub_82E2AAE8(ctx, base);
	// 8280BCB4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BCB8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BCBC: 388B8558  addi r4, r11, -0x7aa8
	ctx.r[4].s64 = ctx.r[11].s64 + -31400;
	// 8280BCC0: 485E7D49  bl 0x82df3a08
	ctx.lr = 0x8280BCC4;
	sub_82DF3A08(ctx, base);
	// 8280BCC4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280BCC8: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280BCCC: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280BCD0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280BCD4: 4862319D  bl 0x82e2ee70
	ctx.lr = 0x8280BCD8;
	sub_82E2EE70(ctx, base);
	// 8280BCD8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BCDC: 485E774D  bl 0x82df3428
	ctx.lr = 0x8280BCE0;
	sub_82DF3428(ctx, base);
	// 8280BCE0: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280BCE4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280BCE8: 419A0060  beq cr6, 0x8280bd48
	if ctx.cr[6].eq {
	pc = 0x8280BD48; continue 'dispatch;
	}
	// 8280BCEC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BCF0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280BCF4: 388B8510  addi r4, r11, -0x7af0
	ctx.r[4].s64 = ctx.r[11].s64 + -31472;
	// 8280BCF8: 38A000B9  li r5, 0xb9
	ctx.r[5].s64 = 185;
	// 8280BCFC: 38600098  li r3, 0x98
	ctx.r[3].s64 = 152;
	// 8280BD00: 485E66E9  bl 0x82df23e8
	ctx.lr = 0x8280BD04;
	sub_82DF23E8(ctx, base);
	// 8280BD04: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280BD08: 41820014  beq 0x8280bd1c
	if ctx.cr[0].eq {
	pc = 0x8280BD1C; continue 'dispatch;
	}
	// 8280BD0C: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 8280BD10: 4860AB81  bl 0x82e16890
	ctx.lr = 0x8280BD14;
	sub_82E16890(ctx, base);
	// 8280BD14: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BD18: 48000008  b 0x8280bd20
	pc = 0x8280BD20; continue 'dispatch;
	// 8280BD1C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280BD20: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280BD24: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 8280BD28: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BD2C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BD30: 4BB4D389  bl 0x823590b8
	ctx.lr = 0x8280BD34;
	sub_823590B8(ctx, base);
	// 8280BD34: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280BD38: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BD3C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BD40: 4BAB42C1  bl 0x822c0000
	ctx.lr = 0x8280BD44;
	sub_822C0000(ctx, base);
	// 8280BD44: 48000010  b 0x8280bd54
	pc = 0x8280BD54; continue 'dispatch;
	// 8280BD48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280BD4C: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BD50: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280BD54: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280BD58: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280BD5C: 419A0008  beq cr6, 0x8280bd64
	if ctx.cr[6].eq {
	pc = 0x8280BD64; continue 'dispatch;
	}
	// 8280BD60: 4BAB4B31  bl 0x822c0890
	ctx.lr = 0x8280BD64;
	sub_822C0890(ctx, base);
	// 8280BD64: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280BD68: 4861ED99  bl 0x82e2ab00
	ctx.lr = 0x8280BD6C;
	sub_82E2AB00(ctx, base);
	// 8280BD6C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280BD70: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280BD74: 4899C448  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BD78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BD78 size=216
    let mut pc: u32 = 0x8280BD78;
    'dispatch: loop {
        match pc {
            0x8280BD78 => {
    //   block [0x8280BD78..0x8280BE50)
	// 8280BD78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BD7C: 4899C3F1  bl 0x831a816c
	ctx.lr = 0x8280BD80;
	sub_831A8130(ctx, base);
	// 8280BD80: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BD84: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280BD88: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280BD8C: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8280BD90: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280BD94: 4BADB475  bl 0x822e7208
	ctx.lr = 0x8280BD98;
	sub_822E7208(ctx, base);
	// 8280BD98: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BD9C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BDA0: 388B8558  addi r4, r11, -0x7aa8
	ctx.r[4].s64 = ctx.r[11].s64 + -31400;
	// 8280BDA4: 485E7C65  bl 0x82df3a08
	ctx.lr = 0x8280BDA8;
	sub_82DF3A08(ctx, base);
	// 8280BDA8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280BDAC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280BDB0: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280BDB4: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280BDB8: 4BADB5D9  bl 0x822e7390
	ctx.lr = 0x8280BDBC;
	sub_822E7390(ctx, base);
	// 8280BDBC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BDC0: 485E7669  bl 0x82df3428
	ctx.lr = 0x8280BDC4;
	sub_82DF3428(ctx, base);
	// 8280BDC4: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280BDC8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280BDCC: 419A0054  beq cr6, 0x8280be20
	if ctx.cr[6].eq {
	pc = 0x8280BE20; continue 'dispatch;
	}
	// 8280BDD0: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280BDD4: 3BBF0028  addi r29, r31, 0x28
	ctx.r[29].s64 = ctx.r[31].s64 + 40;
	// 8280BDD8: 409A0008  bne cr6, 0x8280bde0
	if !ctx.cr[6].eq {
	pc = 0x8280BDE0; continue 'dispatch;
	}
	// 8280BDDC: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8280BDE0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BDE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280BDE8: 816B0048  lwz r11, 0x48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 8280BDEC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280BDF0: 4E800421  bctrl
	ctx.lr = 0x8280BDF4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280BDF4: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280BDF8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BDFC: 485E7C0D  bl 0x82df3a08
	ctx.lr = 0x8280BE00;
	sub_82DF3A08(ctx, base);
	// 8280BE00: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280BE04: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280BE08: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280BE0C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BE10: 4BAE28C9  bl 0x822ee6d8
	ctx.lr = 0x8280BE14;
	sub_822EE6D8(ctx, base);
	// 8280BE14: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BE18: 485E7611  bl 0x82df3428
	ctx.lr = 0x8280BE1C;
	sub_82DF3428(ctx, base);
	// 8280BE1C: 48000010  b 0x8280be2c
	pc = 0x8280BE2C; continue 'dispatch;
	// 8280BE20: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280BE24: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BE28: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280BE2C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280BE30: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280BE34: 419A0008  beq cr6, 0x8280be3c
	if ctx.cr[6].eq {
	pc = 0x8280BE3C; continue 'dispatch;
	}
	// 8280BE38: 4BAB4A59  bl 0x822c0890
	ctx.lr = 0x8280BE3C;
	sub_822C0890(ctx, base);
	// 8280BE3C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280BE40: 4BADB3E1  bl 0x822e7220
	ctx.lr = 0x8280BE44;
	sub_822E7220(ctx, base);
	// 8280BE44: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BE48: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280BE4C: 4899C370  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BE50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BE50 size=64
    let mut pc: u32 = 0x8280BE50;
    'dispatch: loop {
        match pc {
            0x8280BE50 => {
    //   block [0x8280BE50..0x8280BE90)
	// 8280BE50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BE54: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BE58: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BE5C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BE60: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280BE64: 38AB856C  addi r5, r11, -0x7a94
	ctx.r[5].s64 = ctx.r[11].s64 + -31380;
	// 8280BE68: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280BE6C: 4BD0630D  bl 0x82512178
	ctx.lr = 0x8280BE70;
	sub_82512178(ctx, base);
	// 8280BE70: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8280BE74: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280BE78: 419A0008  beq cr6, 0x8280be80
	if ctx.cr[6].eq {
	pc = 0x8280BE80; continue 'dispatch;
	}
	// 8280BE7C: 4BAB4A15  bl 0x822c0890
	ctx.lr = 0x8280BE80;
	sub_822C0890(ctx, base);
	// 8280BE80: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280BE84: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BE88: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BE8C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BE90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BE90 size=140
    let mut pc: u32 = 0x8280BE90;
    'dispatch: loop {
        match pc {
            0x8280BE90 => {
    //   block [0x8280BE90..0x8280BF1C)
	// 8280BE90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BE94: 4899C2D5  bl 0x831a8168
	ctx.lr = 0x8280BE98;
	sub_831A8130(ctx, base);
	// 8280BE98: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BE9C: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280BEA0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8280BEA4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280BEA8: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280BEAC: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8280BEB0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280BEB4: 388BA66C  addi r4, r11, -0x5994
	ctx.r[4].s64 = ctx.r[11].s64 + -22932;
	// 8280BEB8: 38A00089  li r5, 0x89
	ctx.r[5].s64 = 137;
	// 8280BEBC: 38600070  li r3, 0x70
	ctx.r[3].s64 = 112;
	// 8280BEC0: 485E6529  bl 0x82df23e8
	ctx.lr = 0x8280BEC4;
	sub_82DF23E8(ctx, base);
	// 8280BEC4: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280BEC8: 41820020  beq 0x8280bee8
	if ctx.cr[0].eq {
	pc = 0x8280BEE8; continue 'dispatch;
	}
	// 8280BECC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8280BED0: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BED4: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280BED8: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8280BEDC: 48346465  bl 0x82b52340
	ctx.lr = 0x8280BEE0;
	sub_82B52340(ctx, base);
	// 8280BEE0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BEE4: 48000008  b 0x8280beec
	pc = 0x8280BEEC; continue 'dispatch;
	// 8280BEE8: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280BEEC: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280BEF0: 3BDC0004  addi r30, r28, 4
	ctx.r[30].s64 = ctx.r[28].s64 + 4;
	// 8280BEF4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BEF8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BEFC: 4BB4D5A5  bl 0x823594a0
	ctx.lr = 0x8280BF00;
	sub_823594A0(ctx, base);
	// 8280BF00: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280BF04: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BF08: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280BF0C: 4BAB40F5  bl 0x822c0000
	ctx.lr = 0x8280BF10;
	sub_822C0000(ctx, base);
	// 8280BF10: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8280BF14: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280BF18: 4899C2A0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BF20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BF20 size=84
    let mut pc: u32 = 0x8280BF20;
    'dispatch: loop {
        match pc {
            0x8280BF20 => {
    //   block [0x8280BF20..0x8280BF74)
	// 8280BF20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BF24: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BF28: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280BF2C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BF30: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BF34: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280BF38: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280BF3C: 807E0120  lwz r3, 0x120(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280BF40: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280BF44: 419A000C  beq cr6, 0x8280bf50
	if ctx.cr[6].eq {
	pc = 0x8280BF50; continue 'dispatch;
	}
	// 8280BF48: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280BF4C: 4BC8603D  bl 0x82491f88
	ctx.lr = 0x8280BF50;
	sub_82491F88(ctx, base);
	// 8280BF50: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280BF54: 387E0150  addi r3, r30, 0x150
	ctx.r[3].s64 = ctx.r[30].s64 + 336;
	// 8280BF58: 4BFFFCE9  bl 0x8280bc40
	ctx.lr = 0x8280BF5C;
	sub_8280BC40(ctx, base);
	// 8280BF5C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280BF60: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BF64: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BF68: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280BF6C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BF70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BF78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BF78 size=84
    let mut pc: u32 = 0x8280BF78;
    'dispatch: loop {
        match pc {
            0x8280BF78 => {
    //   block [0x8280BF78..0x8280BFCC)
	// 8280BF78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BF7C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BF80: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BF84: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BF88: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8280BF8C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BF90: 3D408338  lis r10, -0x7cc8
	ctx.r[10].s64 = -2093481984;
	// 8280BF94: 3D208336  lis r9, -0x7cca
	ctx.r[9].s64 = -2093613056;
	// 8280BF98: 38AA6910  addi r5, r10, 0x6910
	ctx.r[5].s64 = ctx.r[10].s64 + 26896;
	// 8280BF9C: 816B6734  lwz r11, 0x6734(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26420 as u32) ) } as u64;
	// 8280BFA0: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 8280BFA4: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 8280BFA8: 3889861C  addi r4, r9, -0x79e4
	ctx.r[4].s64 = ctx.r[9].s64 + -31204;
	// 8280BFAC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BFB0: 4BFFFEE1  bl 0x8280be90
	ctx.lr = 0x8280BFB4;
	sub_8280BE90(ctx, base);
	// 8280BFB4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280BFB8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280BFBC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280BFC0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280BFC4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280BFC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280BFD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280BFD0 size=160
    let mut pc: u32 = 0x8280BFD0;
    'dispatch: loop {
        match pc {
            0x8280BFD0 => {
    //   block [0x8280BFD0..0x8280C070)
	// 8280BFD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280BFD4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280BFD8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280BFDC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280BFE0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280BFE4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280BFE8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280BFEC: 396B859C  addi r11, r11, -0x7a64
	ctx.r[11].s64 = ctx.r[11].s64 + -31332;
	// 8280BFF0: 394A8588  addi r10, r10, -0x7a78
	ctx.r[10].s64 = ctx.r[10].s64 + -31352;
	// 8280BFF4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280BFF8: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280BFFC: 807F0158  lwz r3, 0x158(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(344 as u32) ) } as u64;
	// 8280C000: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C004: 419A0008  beq cr6, 0x8280c00c
	if ctx.cr[6].eq {
	pc = 0x8280C00C; continue 'dispatch;
	}
	// 8280C008: 4BAB4889  bl 0x822c0890
	ctx.lr = 0x8280C00C;
	sub_822C0890(ctx, base);
	// 8280C00C: 387F0140  addi r3, r31, 0x140
	ctx.r[3].s64 = ctx.r[31].s64 + 320;
	// 8280C010: 4BC5DFF1  bl 0x8246a000
	ctx.lr = 0x8280C014;
	sub_8246A000(ctx, base);
	// 8280C014: 807F013C  lwz r3, 0x13c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(316 as u32) ) } as u64;
	// 8280C018: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C01C: 419A0008  beq cr6, 0x8280c024
	if ctx.cr[6].eq {
	pc = 0x8280C024; continue 'dispatch;
	}
	// 8280C020: 4BAB4871  bl 0x822c0890
	ctx.lr = 0x8280C024;
	sub_822C0890(ctx, base);
	// 8280C024: 807F0134  lwz r3, 0x134(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(308 as u32) ) } as u64;
	// 8280C028: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C02C: 419A0008  beq cr6, 0x8280c034
	if ctx.cr[6].eq {
	pc = 0x8280C034; continue 'dispatch;
	}
	// 8280C030: 4BAB4861  bl 0x822c0890
	ctx.lr = 0x8280C034;
	sub_822C0890(ctx, base);
	// 8280C034: 807F012C  lwz r3, 0x12c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(300 as u32) ) } as u64;
	// 8280C038: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C03C: 419A0008  beq cr6, 0x8280c044
	if ctx.cr[6].eq {
	pc = 0x8280C044; continue 'dispatch;
	}
	// 8280C040: 4BAB4851  bl 0x822c0890
	ctx.lr = 0x8280C044;
	sub_822C0890(ctx, base);
	// 8280C044: 807F0124  lwz r3, 0x124(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 8280C048: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C04C: 419A0008  beq cr6, 0x8280c054
	if ctx.cr[6].eq {
	pc = 0x8280C054; continue 'dispatch;
	}
	// 8280C050: 4BAB4841  bl 0x822c0890
	ctx.lr = 0x8280C054;
	sub_822C0890(ctx, base);
	// 8280C054: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C058: 4BFEDB01  bl 0x827f9b58
	ctx.lr = 0x8280C05C;
	sub_827F9B58(ctx, base);
	// 8280C05C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280C060: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280C064: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280C068: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280C06C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C070(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280C070 size=8
    let mut pc: u32 = 0x8280C070;
    'dispatch: loop {
        match pc {
            0x8280C070 => {
    //   block [0x8280C070..0x8280C078)
	// 8280C070: 3863FFD8  addi r3, r3, -0x28
	ctx.r[3].s64 = ctx.r[3].s64 + -40;
	// 8280C074: 48000194  b 0x8280c208
	sub_8280C208(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C078(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C078 size=68
    let mut pc: u32 = 0x8280C078;
    'dispatch: loop {
        match pc {
            0x8280C078 => {
    //   block [0x8280C078..0x8280C0BC)
	// 8280C078: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C07C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280C080: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280C084: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C088: 88840018  lbz r4, 0x18(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280C08C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C090: 4BFFFA41  bl 0x8280bad0
	ctx.lr = 0x8280C094;
	sub_8280BAD0(ctx, base);
	// 8280C094: 389F0140  addi r4, r31, 0x140
	ctx.r[4].s64 = ctx.r[31].s64 + 320;
	// 8280C098: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280C09C: 80DF0148  lwz r6, 0x148(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 8280C0A0: 80BF0144  lwz r5, 0x144(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280C0A4: 4BAFC6C5  bl 0x82308768
	ctx.lr = 0x8280C0A8;
	sub_82308768(ctx, base);
	// 8280C0A8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280C0AC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280C0B0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280C0B4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280C0B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C0C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C0C0 size=100
    let mut pc: u32 = 0x8280C0C0;
    'dispatch: loop {
        match pc {
            0x8280C0C0 => {
    //   block [0x8280C0C0..0x8280C124)
	// 8280C0C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C0C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280C0C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280C0CC: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C0D0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C0D4: 389F0140  addi r4, r31, 0x140
	ctx.r[4].s64 = ctx.r[31].s64 + 320;
	// 8280C0D8: 817F0144  lwz r11, 0x144(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280C0DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280C0E0: 419A0024  beq cr6, 0x8280c104
	if ctx.cr[6].eq {
	pc = 0x8280C104; continue 'dispatch;
	}
	// 8280C0E4: 81440008  lwz r10, 8(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280C0E8: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 8280C0EC: 7D6B1671  srawi. r11, r11, 2
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 2) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 2) as i64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C0F0: 41820014  beq 0x8280c104
	if ctx.cr[0].eq {
	pc = 0x8280C104; continue 'dispatch;
	}
	// 8280C0F4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280C0F8: 80A40004  lwz r5, 4(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280C0FC: 5546003E  slwi r6, r10, 0
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8280C100: 4BAFC669  bl 0x82308768
	ctx.lr = 0x8280C104;
	sub_82308768(ctx, base);
	// 8280C104: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280C108: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C10C: 4BFFF9C5  bl 0x8280bad0
	ctx.lr = 0x8280C110;
	sub_8280BAD0(ctx, base);
	// 8280C110: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280C114: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280C118: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280C11C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280C120: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C128(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C128 size=220
    let mut pc: u32 = 0x8280C128;
    'dispatch: loop {
        match pc {
            0x8280C128 => {
    //   block [0x8280C128..0x8280C204)
	// 8280C128: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C12C: 4899C03D  bl 0x831a8168
	ctx.lr = 0x8280C130;
	sub_831A8130(ctx, base);
	// 8280C130: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C134: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 8280C138: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280C13C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280C140: 579D063F  clrlwi. r29, r28, 0x18
	ctx.r[29].u64 = ctx.r[28].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280C144: 41820038  beq 0x8280c17c
	if ctx.cr[0].eq {
	pc = 0x8280C17C; continue 'dispatch;
	}
	// 8280C148: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C14C: 4899D83D  bl 0x831a9988
	ctx.lr = 0x8280C150;
	sub_831A9988(ctx, base);
	// 8280C150: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280C154: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280C158: 386BE6C0  addi r3, r11, -0x1940
	ctx.r[3].s64 = ctx.r[11].s64 + -6464;
	// 8280C15C: 4899BF9D  bl 0x831a80f8
	ctx.lr = 0x8280C160;
	sub_831A80F8(ctx, base);
	// 8280C160: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C164: 41820018  beq 0x8280c17c
	if ctx.cr[0].eq {
	pc = 0x8280C17C; continue 'dispatch;
	}
	// 8280C168: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C16C: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8280C170: 4BFFFF09  bl 0x8280c078
	ctx.lr = 0x8280C174;
	sub_8280C078(ctx, base);
	// 8280C174: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8280C178: 48000084  b 0x8280c1fc
	pc = 0x8280C1FC; continue 'dispatch;
	// 8280C17C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8280C180: 419A006C  beq cr6, 0x8280c1ec
	if ctx.cr[6].eq {
	pc = 0x8280C1EC; continue 'dispatch;
	}
	// 8280C184: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C188: 4899D801  bl 0x831a9988
	ctx.lr = 0x8280C18C;
	sub_831A9988(ctx, base);
	// 8280C18C: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280C190: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280C194: 386BD5B0  addi r3, r11, -0x2a50
	ctx.r[3].s64 = ctx.r[11].s64 + -10832;
	// 8280C198: 4899BF61  bl 0x831a80f8
	ctx.lr = 0x8280C19C;
	sub_831A80F8(ctx, base);
	// 8280C19C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C1A0: 41820014  beq 0x8280c1b4
	if ctx.cr[0].eq {
	pc = 0x8280C1B4; continue 'dispatch;
	}
	// 8280C1A4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C1A8: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8280C1AC: 4BFFFF15  bl 0x8280c0c0
	ctx.lr = 0x8280C1B0;
	sub_8280C0C0(ctx, base);
	// 8280C1B0: 4BFFFFC4  b 0x8280c174
	pc = 0x8280C174; continue 'dispatch;
	// 8280C1B4: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8280C1B8: 419A0034  beq cr6, 0x8280c1ec
	if ctx.cr[6].eq {
	pc = 0x8280C1EC; continue 'dispatch;
	}
	// 8280C1BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C1C0: 4899D7C9  bl 0x831a9988
	ctx.lr = 0x8280C1C4;
	sub_831A9988(ctx, base);
	// 8280C1C4: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280C1C8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280C1CC: 386BD1B0  addi r3, r11, -0x2e50
	ctx.r[3].s64 = ctx.r[11].s64 + -11856;
	// 8280C1D0: 4899BF29  bl 0x831a80f8
	ctx.lr = 0x8280C1D4;
	sub_831A80F8(ctx, base);
	// 8280C1D4: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C1D8: 41820014  beq 0x8280c1ec
	if ctx.cr[0].eq {
	pc = 0x8280C1EC; continue 'dispatch;
	}
	// 8280C1DC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C1E0: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8280C1E4: 4BFFF75D  bl 0x8280b940
	ctx.lr = 0x8280C1E8;
	sub_8280B940(ctx, base);
	// 8280C1E8: 4BFFFF8C  b 0x8280c174
	pc = 0x8280C174; continue 'dispatch;
	// 8280C1EC: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8280C1F0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C1F4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280C1F8: 4BFED849  bl 0x827f9a40
	ctx.lr = 0x8280C1FC;
	sub_827F9A40(ctx, base);
	// 8280C1FC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280C200: 4899BFB8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C208(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C208 size=76
    let mut pc: u32 = 0x8280C208;
    'dispatch: loop {
        match pc {
            0x8280C208 => {
    //   block [0x8280C208..0x8280C254)
	// 8280C208: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C20C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280C210: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280C214: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280C218: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C21C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C220: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280C224: 4BFFFDAD  bl 0x8280bfd0
	ctx.lr = 0x8280C228;
	sub_8280BFD0(ctx, base);
	// 8280C228: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C22C: 4182000C  beq 0x8280c238
	if ctx.cr[0].eq {
	pc = 0x8280C238; continue 'dispatch;
	}
	// 8280C230: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C234: 485E61A5  bl 0x82df23d8
	ctx.lr = 0x8280C238;
	sub_82DF23D8(ctx, base);
	// 8280C238: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C23C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280C240: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280C244: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280C248: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280C24C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280C250: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C258(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C258 size=128
    let mut pc: u32 = 0x8280C258;
    'dispatch: loop {
        match pc {
            0x8280C258 => {
    //   block [0x8280C258..0x8280C2D8)
	// 8280C258: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C25C: 4899BF11  bl 0x831a816c
	ctx.lr = 0x8280C260;
	sub_831A8130(ctx, base);
	// 8280C260: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C264: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280C268: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280C26C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280C270: 3BEBADE8  addi r31, r11, -0x5218
	ctx.r[31].s64 = ctx.r[11].s64 + -21016;
	// 8280C274: 816AADF0  lwz r11, -0x5210(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-21008 as u32) ) } as u64;
	// 8280C278: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8280C27C: 40820024  bne 0x8280c2a0
	if !ctx.cr[0].eq {
	pc = 0x8280C2A0; continue 'dispatch;
	}
	// 8280C280: 3D208271  lis r9, -0x7d8f
	ctx.r[9].s64 = -2106523648;
	// 8280C284: 3D008281  lis r8, -0x7d7f
	ctx.r[8].s64 = -2105475072;
	// 8280C288: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8280C28C: 39298E48  addi r9, r9, -0x71b8
	ctx.r[9].s64 = ctx.r[9].s64 + -29112;
	// 8280C290: 3908BBF8  addi r8, r8, -0x4408
	ctx.r[8].s64 = ctx.r[8].s64 + -17416;
	// 8280C294: 916AADF0  stw r11, -0x5210(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-21008 as u32), ctx.r[11].u32 ) };
	// 8280C298: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8280C29C: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8280C2A0: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8280C2A4: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8280C2A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C2AC: 38DE0008  addi r6, r30, 8
	ctx.r[6].s64 = ctx.r[30].s64 + 8;
	// 8280C2B0: 9BAB0000  stb r29, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u8 ) };
	// 8280C2B4: 88E10050  lbz r7, 0x50(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280C2B8: 4BE48309  bl 0x826545c0
	ctx.lr = 0x8280C2BC;
	sub_826545C0(ctx, base);
	// 8280C2BC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C2C0: 4182000C  beq 0x8280c2cc
	if ctx.cr[0].eq {
	pc = 0x8280C2CC; continue 'dispatch;
	}
	// 8280C2C4: 93FE0000  stw r31, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280C2C8: 48000008  b 0x8280c2d0
	pc = 0x8280C2D0; continue 'dispatch;
	// 8280C2CC: 93BE0000  stw r29, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8280C2D0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280C2D4: 4899BEE8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C2D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280C2D8 size=964
    let mut pc: u32 = 0x8280C2D8;
    'dispatch: loop {
        match pc {
            0x8280C2D8 => {
    //   block [0x8280C2D8..0x8280C69C)
	// 8280C2D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C2DC: 4899BE85  bl 0x831a8160
	ctx.lr = 0x8280C2E0;
	sub_831A8130(ctx, base);
	// 8280C2E0: 9421FEB0  stwu r1, -0x150(r1)
	ea = ctx.r[1].u32.wrapping_add(-336 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C2E4: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8280C2E8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C2EC: 7F5CD378  mr r28, r26
	ctx.r[28].u64 = ctx.r[26].u64;
	// 8280C2F0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280C2F4: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 8280C2F8: 93810050  stw r28, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[28].u32 ) };
	// 8280C2FC: 4BFED235  bl 0x827f9530
	ctx.lr = 0x8280C300;
	sub_827F9530(ctx, base);
	// 8280C300: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280C304: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 8280C308: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 8280C30C: 38800060  li r4, 0x60
	ctx.r[4].s64 = 96;
	// 8280C310: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8280C314: 4869441D  bl 0x82ea0730
	ctx.lr = 0x8280C318;
	sub_82EA0730(ctx, base);
	// 8280C318: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280C31C: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 8280C320: 396B8610  addi r11, r11, -0x79f0
	ctx.r[11].s64 = ctx.r[11].s64 + -31216;
	// 8280C324: 394A28F0  addi r10, r10, 0x28f0
	ctx.r[10].s64 = ctx.r[10].s64 + 10480;
	// 8280C328: 392100C0  addi r9, r1, 0xc0
	ctx.r[9].s64 = ctx.r[1].s64 + 192;
	// 8280C32C: 39010100  addi r8, r1, 0x100
	ctx.r[8].s64 = ctx.r[1].s64 + 256;
	// 8280C330: 38E00060  li r7, 0x60
	ctx.r[7].s64 = 96;
	// 8280C334: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280C338: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280C33C: 13C050C7  vcmpequd (lvx128) v30, v0, v10
	tmp.u32 = ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280C340: B0E30004  sth r7, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[7].u16 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C6A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C6A0 size=140
    let mut pc: u32 = 0x8280C6A0;
    'dispatch: loop {
        match pc {
            0x8280C6A0 => {
    //   block [0x8280C6A0..0x8280C72C)
	// 8280C6A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C6A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280C6A8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280C6AC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280C6B0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C6B4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C6B8: 4BFED561  bl 0x827f9c18
	ctx.lr = 0x8280C6BC;
	sub_827F9C18(ctx, base);
	// 8280C6BC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280C6C0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280C6C4: 396B859C  addi r11, r11, -0x7a64
	ctx.r[11].s64 = ctx.r[11].s64 + -31332;
	// 8280C6C8: 394A8588  addi r10, r10, -0x7a78
	ctx.r[10].s64 = ctx.r[10].s64 + -31352;
	// 8280C6CC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8280C6D0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280C6D4: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280C6D8: 387F0150  addi r3, r31, 0x150
	ctx.r[3].s64 = ctx.r[31].s64 + 336;
	// 8280C6DC: 93DF0120  stw r30, 0x120(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), ctx.r[30].u32 ) };
	// 8280C6E0: 93DF0124  stw r30, 0x124(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[30].u32 ) };
	// 8280C6E4: 93DF0128  stw r30, 0x128(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), ctx.r[30].u32 ) };
	// 8280C6E8: 93DF012C  stw r30, 0x12c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), ctx.r[30].u32 ) };
	// 8280C6EC: 93DF0130  stw r30, 0x130(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), ctx.r[30].u32 ) };
	// 8280C6F0: 93DF0134  stw r30, 0x134(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(308 as u32), ctx.r[30].u32 ) };
	// 8280C6F4: 93DF0138  stw r30, 0x138(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(312 as u32), ctx.r[30].u32 ) };
	// 8280C6F8: 93DF013C  stw r30, 0x13c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(316 as u32), ctx.r[30].u32 ) };
	// 8280C6FC: 93DF0144  stw r30, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[30].u32 ) };
	// 8280C700: 93DF0148  stw r30, 0x148(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), ctx.r[30].u32 ) };
	// 8280C704: 93DF014C  stw r30, 0x14c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), ctx.r[30].u32 ) };
	// 8280C708: 4BFFF871  bl 0x8280bf78
	ctx.lr = 0x8280C70C;
	sub_8280BF78(ctx, base);
	// 8280C70C: 9BDF015C  stb r30, 0x15c(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(348 as u32), ctx.r[30].u8 ) };
	// 8280C710: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C714: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280C718: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280C71C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280C720: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280C724: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280C728: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C730(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280C730 size=304
    let mut pc: u32 = 0x8280C730;
    'dispatch: loop {
        match pc {
            0x8280C730 => {
    //   block [0x8280C730..0x8280C860)
	// 8280C730: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C734: 4899BA35  bl 0x831a8168
	ctx.lr = 0x8280C738;
	sub_831A8130(ctx, base);
	// 8280C738: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C73C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C740: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8280C744: 3BDF0140  addi r30, r31, 0x140
	ctx.r[30].s64 = ctx.r[31].s64 + 320;
	// 8280C748: 938100AC  stw r28, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[28].u32 ) };
	// 8280C74C: 817F0144  lwz r11, 0x144(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 8280C750: 815F0148  lwz r10, 0x148(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 8280C754: 48000014  b 0x8280c768
	pc = 0x8280C768; continue 'dispatch;
	// 8280C758: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280C75C: 7F09E040  cmplw cr6, r9, r28
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[28].u32, &mut ctx.xer);
	// 8280C760: 419A00F8  beq cr6, 0x8280c858
	if ctx.cr[6].eq {
	pc = 0x8280C858; continue 'dispatch;
	}
	// 8280C764: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280C768: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8280C76C: 409AFFEC  bne cr6, 0x8280c758
	if !ctx.cr[6].eq {
	pc = 0x8280C758; continue 'dispatch;
	}
	// 8280C770: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280C774: 556B063F  clrlwi. r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280C778: 408200D8  bne 0x8280c850
	if !ctx.cr[0].eq {
	pc = 0x8280C850; continue 'dispatch;
	}
	// 8280C77C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280C780: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280C784: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280C788: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280C78C: 4BFFF705  bl 0x8280be90
	ctx.lr = 0x8280C790;
	sub_8280BE90(ctx, base);
	// 8280C790: 81610060  lwz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 8280C794: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280C798: 83A10064  lwz r29, 0x64(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8280C79C: 419A00A4  beq cr6, 0x8280c840
	if ctx.cr[6].eq {
	pc = 0x8280C840; continue 'dispatch;
	}
	// 8280C7A0: 815F0154  lwz r10, 0x154(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(340 as u32) ) } as u64;
	// 8280C7A4: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8280C7A8: 814A0060  lwz r10, 0x60(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(96 as u32) ) } as u64;
	// 8280C7AC: 914B0060  stw r10, 0x60(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 8280C7B0: 815F0154  lwz r10, 0x154(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(340 as u32) ) } as u64;
	// 8280C7B4: 814A0020  lwz r10, 0x20(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 8280C7B8: 914B0020  stw r10, 0x20(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), ctx.r[10].u32 ) };
	// 8280C7BC: 815F0154  lwz r10, 0x154(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(340 as u32) ) } as u64;
	// 8280C7C0: 814A0018  lwz r10, 0x18(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280C7C4: 914B0018  stw r10, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[10].u32 ) };
	// 8280C7C8: 815F0154  lwz r10, 0x154(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(340 as u32) ) } as u64;
	// 8280C7CC: 814A001C  lwz r10, 0x1c(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) } as u64;
	// 8280C7D0: 914B001C  stw r10, 0x1c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 8280C7D4: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8280C7D8: 93A1005C  stw r29, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[29].u32 ) };
	// 8280C7DC: 419A0024  beq cr6, 0x8280c800
	if ctx.cr[6].eq {
	pc = 0x8280C800; continue 'dispatch;
	}
	// 8280C7E0: 397D0004  addi r11, r29, 4
	ctx.r[11].s64 = ctx.r[29].s64 + 4;
	// 8280C7E4: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280C7E8: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280C7EC: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280C7F0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280C7F4: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280C7F8: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280C7FC: 4082FFE8  bne 0x8280c7e4
	if !ctx.cr[0].eq {
	pc = 0x8280C7E4; continue 'dispatch;
	}
	// 8280C800: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280C804: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280C808: 38E10058  addi r7, r1, 0x58
	ctx.r[7].s64 = ctx.r[1].s64 + 88;
	// 8280C80C: 388A8510  addi r4, r10, -0x7af0
	ctx.r[4].s64 = ctx.r[10].s64 + -31472;
	// 8280C810: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8280C814: 38A0012D  li r5, 0x12d
	ctx.r[5].s64 = 301;
	// 8280C818: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280C81C: 387F0028  addi r3, r31, 0x28
	ctx.r[3].s64 = ctx.r[31].s64 + 40;
	// 8280C820: 4864C221  bl 0x82e58a40
	ctx.lr = 0x8280C824;
	sub_82E58A40(ctx, base);
	// 8280C824: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280C828: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280C82C: 419A0008  beq cr6, 0x8280c834
	if ctx.cr[6].eq {
	pc = 0x8280C834; continue 'dispatch;
	}
	// 8280C830: 4BAB4061  bl 0x822c0890
	ctx.lr = 0x8280C834;
	sub_822C0890(ctx, base);
	// 8280C834: 388100AC  addi r4, r1, 0xac
	ctx.r[4].s64 = ctx.r[1].s64 + 172;
	// 8280C838: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280C83C: 4BCAC8D5  bl 0x824b9110
	ctx.lr = 0x8280C840;
	sub_824B9110(ctx, base);
	// 8280C840: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 8280C844: 419A000C  beq cr6, 0x8280c850
	if ctx.cr[6].eq {
	pc = 0x8280C850; continue 'dispatch;
	}
	// 8280C848: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280C84C: 4BAB4045  bl 0x822c0890
	ctx.lr = 0x8280C850;
	sub_822C0890(ctx, base);
	// 8280C850: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280C854: 4899B964  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8280C858: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8280C85C: 4BFFFF18  b 0x8280c774
	pc = 0x8280C774; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C860(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280C860 size=120
    let mut pc: u32 = 0x8280C860;
    'dispatch: loop {
        match pc {
            0x8280C860 => {
    //   block [0x8280C860..0x8280C8D8)
	// 8280C860: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C864: 4899B909  bl 0x831a816c
	ctx.lr = 0x8280C868;
	sub_831A8130(ctx, base);
	// 8280C868: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C86C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280C870: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280C874: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280C878: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280C87C: 388B8510  addi r4, r11, -0x7af0
	ctx.r[4].s64 = ctx.r[11].s64 + -31472;
	// 8280C880: 38A0004D  li r5, 0x4d
	ctx.r[5].s64 = 77;
	// 8280C884: 38600160  li r3, 0x160
	ctx.r[3].s64 = 352;
	// 8280C888: 485E5B61  bl 0x82df23e8
	ctx.lr = 0x8280C88C;
	sub_82DF23E8(ctx, base);
	// 8280C88C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280C890: 41820014  beq 0x8280c8a4
	if ctx.cr[0].eq {
	pc = 0x8280C8A4; continue 'dispatch;
	}
	// 8280C894: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C898: 4BFFFE09  bl 0x8280c6a0
	ctx.lr = 0x8280C89C;
	sub_8280C6A0(ctx, base);
	// 8280C89C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280C8A0: 48000008  b 0x8280c8a8
	pc = 0x8280C8A8; continue 'dispatch;
	// 8280C8A4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280C8A8: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280C8AC: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 8280C8B0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C8B4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280C8B8: 4BFFF279  bl 0x8280bb30
	ctx.lr = 0x8280C8BC;
	sub_8280BB30(ctx, base);
	// 8280C8BC: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280C8C0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C8C4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280C8C8: 4BAB3739  bl 0x822c0000
	ctx.lr = 0x8280C8CC;
	sub_822C0000(ctx, base);
	// 8280C8CC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280C8D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280C8D4: 4899B8E8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280C8D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280C8D8 size=484
    let mut pc: u32 = 0x8280C8D8;
    'dispatch: loop {
        match pc {
            0x8280C8D8 => {
    //   block [0x8280C8D8..0x8280CABC)
	// 8280C8D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280C8DC: 4899B881  bl 0x831a815c
	ctx.lr = 0x8280C8E0;
	sub_831A8130(ctx, base);
	// 8280C8E0: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280C8E4: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8280C8E8: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280C8EC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280C8F0: 4BC59BE9  bl 0x824664d8
	ctx.lr = 0x8280C8F4;
	sub_824664D8(ctx, base);
	// 8280C8F4: 817B0120  lwz r11, 0x120(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280C8F8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8280C8FC: C01F0030  lfs f0, 0x30(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280C900: C1BF0034  lfs f13, 0x34(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280C904: 9061006C  stw r3, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[3].u32 ) };
	// 8280C908: C19F0038  lfs f12, 0x38(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280C90C: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 8280C910: C17F003C  lfs f11, 0x3c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8280C914: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280C918: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8280C91C: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 8280C920: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 8280C924: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 8280C928: 419A0024  beq cr6, 0x8280c94c
	if ctx.cr[6].eq {
	pc = 0x8280C94C; continue 'dispatch;
	}
	// 8280C92C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280C930: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8280C934: 4BC8565D  bl 0x82491f90
	ctx.lr = 0x8280C938;
	sub_82491F90(ctx, base);
	// 8280C938: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8280C93C: 38810068  addi r4, r1, 0x68
	ctx.r[4].s64 = ctx.r[1].s64 + 104;
	// 8280C940: 807B0120  lwz r3, 0x120(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280C944: 4BC8560D  bl 0x82491f50
	ctx.lr = 0x8280C948;
	sub_82491F50(ctx, base);
	// 8280C948: 8061006C  lwz r3, 0x6c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8280C94C: 83230000  lwz r25, 0(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280C950: 7F191840  cmplw cr6, r25, r3
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[3].u32, &mut ctx.xer);
	// 8280C954: 419A0148  beq cr6, 0x8280ca9c
	if ctx.cr[6].eq {
	pc = 0x8280CA9C; continue 'dispatch;
	}
	// 8280C958: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280C95C: 3D408338  lis r10, -0x7cc8
	ctx.r[10].s64 = -2093481984;
	// 8280C960: 3F408208  lis r26, -0x7df8
	ctx.r[26].s64 = -2113404928;
	// 8280C964: 3BAB8510  addi r29, r11, -0x7af0
	ctx.r[29].s64 = ctx.r[11].s64 + -31472;
	// 8280C968: 3B8A6910  addi r28, r10, 0x6910
	ctx.r[28].s64 = ctx.r[10].s64 + 26896;
	// 8280C96C: 80790008  lwz r3, 8(r25)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280C970: 4BFCD661  bl 0x827d9fd0
	ctx.lr = 0x8280C974;
	sub_827D9FD0(ctx, base);
	// 8280C974: 7C7F1B79  or. r31, r3, r3
	ctx.r[31].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8280C978: 41820114  beq 0x8280ca8c
	if ctx.cr[0].eq {
	pc = 0x8280CA8C; continue 'dispatch;
	}
	// 8280C97C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280C980: 487FC639  bl 0x83008fb8
	ctx.lr = 0x8280C984;
	sub_83008FB8(ctx, base);
	// 8280C984: 39610090  addi r11, r1, 0x90
	ctx.r[11].s64 = ctx.r[1].s64 + 144;
	// 8280C988: 39410090  addi r10, r1, 0x90
	ctx.r[10].s64 = ctx.r[1].s64 + 144;
	// 8280C98C: 13E0E0C7  vcmpequd (lvx128) v31, v0, v28
	tmp.u32 = ctx.r[28].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280C990: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280C994: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280C998: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280C99C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CAC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CAC0 size=72
    let mut pc: u32 = 0x8280CAC0;
    'dispatch: loop {
        match pc {
            0x8280CAC0 => {
    //   block [0x8280CAC0..0x8280CB08)
	// 8280CAC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CAC4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CAC8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CACC: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CAD0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280CAD4: 897F015C  lbz r11, 0x15c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(348 as u32) ) } as u64;
	// 8280CAD8: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280CADC: 41820018  beq 0x8280caf4
	if ctx.cr[0].eq {
	pc = 0x8280CAF4; continue 'dispatch;
	}
	// 8280CAE0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280CAE4: 4BD052B5  bl 0x82511d98
	ctx.lr = 0x8280CAE8;
	sub_82511D98(ctx, base);
	// 8280CAE8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280CAEC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CAF0: 4BFFFDE9  bl 0x8280c8d8
	ctx.lr = 0x8280CAF4;
	sub_8280C8D8(ctx, base);
	// 8280CAF4: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8280CAF8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CAFC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CB00: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280CB04: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CB08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280CB08 size=8
    let mut pc: u32 = 0x8280CB08;
    'dispatch: loop {
        match pc {
            0x8280CB08 => {
    //   block [0x8280CB08..0x8280CB10)
	// 8280CB08: 38630140  addi r3, r3, 0x140
	ctx.r[3].s64 = ctx.r[3].s64 + 320;
	// 8280CB0C: 485F9A14  b 0x82e06520
	sub_82E06520(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CB10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CB10 size=136
    let mut pc: u32 = 0x8280CB10;
    'dispatch: loop {
        match pc {
            0x8280CB10 => {
    //   block [0x8280CB10..0x8280CB98)
	// 8280CB10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CB14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CB18: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280CB1C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CB20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CB24: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280CB28: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280CB2C: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 8280CB30: 409A0020  bne cr6, 0x8280cb50
	if !ctx.cr[6].eq {
	pc = 0x8280CB50; continue 'dispatch;
	}
	// 8280CB34: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280CB38: 419A0048  beq cr6, 0x8280cb80
	if ctx.cr[6].eq {
	pc = 0x8280CB80; continue 'dispatch;
	}
	// 8280CB3C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CB40: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280CB44: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280CB48: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280CB4C: 48000034  b 0x8280cb80
	pc = 0x8280CB80; continue 'dispatch;
	// 8280CB50: 2F050001  cmpwi cr6, r5, 1
	ctx.cr[6].compare_i32(ctx.r[5].s32, 1, &mut ctx.xer);
	// 8280CB54: 419A002C  beq cr6, 0x8280cb80
	if ctx.cr[6].eq {
	pc = 0x8280CB80; continue 'dispatch;
	}
	// 8280CB58: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280CB5C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CB60: 388BEAB0  addi r4, r11, -0x1550
	ctx.r[4].s64 = ctx.r[11].s64 + -5456;
	// 8280CB64: 4899B595  bl 0x831a80f8
	ctx.lr = 0x8280CB68;
	sub_831A80F8(ctx, base);
	// 8280CB68: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280CB6C: 4182000C  beq 0x8280cb78
	if ctx.cr[0].eq {
	pc = 0x8280CB78; continue 'dispatch;
	}
	// 8280CB70: 93DF0000  stw r30, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280CB74: 4800000C  b 0x8280cb80
	pc = 0x8280CB80; continue 'dispatch;
	// 8280CB78: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280CB7C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280CB80: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280CB84: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CB88: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CB8C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280CB90: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280CB94: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CB98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CB98 size=152
    let mut pc: u32 = 0x8280CB98;
    'dispatch: loop {
        match pc {
            0x8280CB98 => {
    //   block [0x8280CB98..0x8280CC30)
	// 8280CB98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CB9C: 4899B5D1  bl 0x831a816c
	ctx.lr = 0x8280CBA0;
	sub_831A8130(ctx, base);
	// 8280CBA0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CBA4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280CBA8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8280CBAC: 3BFE0008  addi r31, r30, 8
	ctx.r[31].s64 = ctx.r[30].s64 + 8;
	// 8280CBB0: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280CBB4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280CBB8: 419A0030  beq cr6, 0x8280cbe8
	if ctx.cr[6].eq {
	pc = 0x8280CBE8; continue 'dispatch;
	}
	// 8280CBBC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280CBC0: 4BCFDD91  bl 0x8250a950
	ctx.lr = 0x8280CBC4;
	sub_8250A950(ctx, base);
	// 8280CBC4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CBC8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280CBCC: 386BFF40  addi r3, r11, -0xc0
	ctx.r[3].s64 = ctx.r[11].s64 + -192;
	// 8280CBD0: 409A0008  bne cr6, 0x8280cbd8
	if !ctx.cr[6].eq {
	pc = 0x8280CBD8; continue 'dispatch;
	}
	// 8280CBD4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8280CBD8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280CBDC: 4BFC6E25  bl 0x827d3a00
	ctx.lr = 0x8280CBE0;
	sub_827D3A00(ctx, base);
	// 8280CBE0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280CBE4: 485E50AD  bl 0x82df1c90
	ctx.lr = 0x8280CBE8;
	sub_82DF1C90(ctx, base);
	// 8280CBE8: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 8280CBEC: 3BFE0010  addi r31, r30, 0x10
	ctx.r[31].s64 = ctx.r[30].s64 + 16;
	// 8280CBF0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280CBF4: 419A0034  beq cr6, 0x8280cc28
	if ctx.cr[6].eq {
	pc = 0x8280CC28; continue 'dispatch;
	}
	// 8280CBF8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280CBFC: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280CC00: 4BCFDD51  bl 0x8250a950
	ctx.lr = 0x8280CC04;
	sub_8250A950(ctx, base);
	// 8280CC04: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CC08: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280CC0C: 386BFF40  addi r3, r11, -0xc0
	ctx.r[3].s64 = ctx.r[11].s64 + -192;
	// 8280CC10: 409A0008  bne cr6, 0x8280cc18
	if !ctx.cr[6].eq {
	pc = 0x8280CC18; continue 'dispatch;
	}
	// 8280CC14: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8280CC18: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280CC1C: 4BFC6DE5  bl 0x827d3a00
	ctx.lr = 0x8280CC20;
	sub_827D3A00(ctx, base);
	// 8280CC20: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280CC24: 485E506D  bl 0x82df1c90
	ctx.lr = 0x8280CC28;
	sub_82DF1C90(ctx, base);
	// 8280CC28: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280CC2C: 4899B590  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CC30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CC30 size=196
    let mut pc: u32 = 0x8280CC30;
    'dispatch: loop {
        match pc {
            0x8280CC30 => {
    //   block [0x8280CC30..0x8280CCF4)
	// 8280CC30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CC34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CC38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280CC3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CC40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CC44: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280CC48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280CC4C: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 8280CC50: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280CC54: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280CC58: 4BAB3CE1  bl 0x822c0938
	ctx.lr = 0x8280CC5C;
	sub_822C0938(ctx, base);
	// 8280CC5C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280CC60: 41820028  beq 0x8280cc88
	if ctx.cr[0].eq {
	pc = 0x8280CC88; continue 'dispatch;
	}
	// 8280CC64: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280CC68: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 8280CC6C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280CC70: 392B8628  addi r9, r11, -0x79d8
	ctx.r[9].s64 = ctx.r[11].s64 + -31192;
	// 8280CC74: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8280CC78: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280CC7C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8280CC80: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8280CC84: 48000008  b 0x8280cc8c
	pc = 0x8280CC8C; continue 'dispatch;
	// 8280CC88: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280CC8C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280CC90: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280CC94: 409A0044  bne cr6, 0x8280ccd8
	if !ctx.cr[6].eq {
	pc = 0x8280CCD8; continue 'dispatch;
	}
	// 8280CC98: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280CC9C: 419A001C  beq cr6, 0x8280ccb8
	if ctx.cr[6].eq {
	pc = 0x8280CCB8; continue 'dispatch;
	}
	// 8280CCA0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CCA4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280CCA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CCAC: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CCB0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280CCB4: 4E800421  bctrl
	ctx.lr = 0x8280CCB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280CCB8: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280CCBC: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280CCC0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280CCC4: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 8280CCC8: 816BE990  lwz r11, -0x1670(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-5744 as u32) ) } as u64;
	// 8280CCCC: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280CCD0: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280CCD4: 4BAB332D  bl 0x822c0000
	ctx.lr = 0x8280CCD8;
	sub_822C0000(ctx, base);
	// 8280CCD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280CCDC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280CCE0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CCE4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CCE8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280CCEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280CCF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CCF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CCF8 size=80
    let mut pc: u32 = 0x8280CCF8;
    'dispatch: loop {
        match pc {
            0x8280CCF8 => {
    //   block [0x8280CCF8..0x8280CD48)
	// 8280CCF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CCFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CD00: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280CD04: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CD08: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CD0C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280CD10: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280CD14: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280CD18: 4866ED51  bl 0x82e7ba68
	ctx.lr = 0x8280CD1C;
	sub_82E7BA68(ctx, base);
	// 8280CD1C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280CD20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CD24: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8280CD28: 4BAB7BD9  bl 0x822c4900
	ctx.lr = 0x8280CD2C;
	sub_822C4900(ctx, base);
	// 8280CD2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CD30: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8280CD34: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CD38: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CD3C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280CD40: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280CD44: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CD48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CD48 size=116
    let mut pc: u32 = 0x8280CD48;
    'dispatch: loop {
        match pc {
            0x8280CD48 => {
    //   block [0x8280CD48..0x8280CDBC)
	// 8280CD48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CD4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CD50: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280CD54: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CD58: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CD5C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280CD60: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280CD64: 807F0128  lwz r3, 0x128(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) } as u64;
	// 8280CD68: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280CD6C: 419A0008  beq cr6, 0x8280cd74
	if ctx.cr[6].eq {
	pc = 0x8280CD74; continue 'dispatch;
	}
	// 8280CD70: 4BFFFE29  bl 0x8280cb98
	ctx.lr = 0x8280CD74;
	sub_8280CB98(ctx, base);
	// 8280CD74: 807F0130  lwz r3, 0x130(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280CD78: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280CD7C: 419A000C  beq cr6, 0x8280cd88
	if ctx.cr[6].eq {
	pc = 0x8280CD88; continue 'dispatch;
	}
	// 8280CD80: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280CD84: 4BFFFE15  bl 0x8280cb98
	ctx.lr = 0x8280CD88;
	sub_8280CB98(ctx, base);
	// 8280CD88: 807F0138  lwz r3, 0x138(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280CD8C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280CD90: 419A0008  beq cr6, 0x8280cd98
	if ctx.cr[6].eq {
	pc = 0x8280CD98; continue 'dispatch;
	}
	// 8280CD94: 48339935  bl 0x82b466c8
	ctx.lr = 0x8280CD98;
	sub_82B466C8(ctx, base);
	// 8280CD98: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280CD9C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CDA0: 4BFF0259  bl 0x827fcff8
	ctx.lr = 0x8280CDA4;
	sub_827FCFF8(ctx, base);
	// 8280CDA4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280CDA8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CDAC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CDB0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280CDB4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280CDB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CDC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280CDC0 size=424
    let mut pc: u32 = 0x8280CDC0;
    'dispatch: loop {
        match pc {
            0x8280CDC0 => {
    //   block [0x8280CDC0..0x8280CF68)
	// 8280CDC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CDC4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CDC8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280CDCC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280CDD0: 9421FEC0  stwu r1, -0x140(r1)
	ea = ctx.r[1].u32.wrapping_add(-320 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CDD4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280CDD8: D021016C  stfs f1, 0x16c(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), tmp.u32 ) };
	// 8280CDDC: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280CDE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280CDE4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280CDE8: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280CDEC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280CDF0: 4E800421  bctrl
	ctx.lr = 0x8280CDF4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280CDF4: 39600030  li r11, 0x30
	ctx.r[11].s64 = 48;
	// 8280CDF8: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 8280CDFC: 13A01C07  vcmpneb. (lvlx128) v29, v0, v3
	tmp.u32 = ctx.r[3].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280CE00: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CF68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280CF68 size=72
    let mut pc: u32 = 0x8280CF68;
    'dispatch: loop {
        match pc {
            0x8280CF68 => {
    //   block [0x8280CF68..0x8280CFB0)
	// 8280CF68: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CF6C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280CF70: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CF74: 2F050003  cmpwi cr6, r5, 3
	ctx.cr[6].compare_i32(ctx.r[5].s32, 3, &mut ctx.xer);
	// 8280CF78: 419A001C  beq cr6, 0x8280cf94
	if ctx.cr[6].eq {
	pc = 0x8280CF94; continue 'dispatch;
	}
	// 8280CF7C: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8280CF80: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8280CF84: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8280CF88: 88C10050  lbz r6, 0x50(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280CF8C: 4BFFFB85  bl 0x8280cb10
	ctx.lr = 0x8280CF90;
	sub_8280CB10(ctx, base);
	// 8280CF90: 48000010  b 0x8280cfa0
	pc = 0x8280CFA0; continue 'dispatch;
	// 8280CF94: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280CF98: 396BEAB0  addi r11, r11, -0x1550
	ctx.r[11].s64 = ctx.r[11].s64 + -5456;
	// 8280CF9C: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280CFA0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280CFA4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280CFA8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280CFAC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280CFB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280CFB0 size=220
    let mut pc: u32 = 0x8280CFB0;
    'dispatch: loop {
        match pc {
            0x8280CFB0 => {
    //   block [0x8280CFB0..0x8280D08C)
	// 8280CFB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280CFB4: 4899B1A5  bl 0x831a8158
	ctx.lr = 0x8280CFB8;
	sub_831A8130(ctx, base);
	// 8280CFB8: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280CFBC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280CFC0: 7C992378  mr r25, r4
	ctx.r[25].u64 = ctx.r[4].u64;
	// 8280CFC4: 4BF7810D  bl 0x827850d0
	ctx.lr = 0x8280CFC8;
	sub_827850D0(ctx, base);
	// 8280CFC8: 3D608203  lis r11, -0x7dfd
	ctx.r[11].s64 = -2113732608;
	// 8280CFCC: C1990000  lfs f12, 0(r25)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280CFD0: C17E0184  lfs f11, 0x184(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(388 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8280CFD4: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280CFD8: 3B5E0184  addi r26, r30, 0x184
	ctx.r[26].s64 = ctx.r[30].s64 + 388;
	// 8280CFDC: C00B7BC8  lfs f0, 0x7bc8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(31688 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280CFE0: EC0C583A  fmadds f0, f12, f0, f11
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64 + ctx.f[11].f64) as f32) as f64);
	// 8280CFE4: C1AA8620  lfs f13, -0x79e0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-31200 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280CFE8: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 8280CFEC: 41980008  blt cr6, 0x8280cff4
	if ctx.cr[6].lt {
	pc = 0x8280CFF4; continue 'dispatch;
	}
	// 8280CFF0: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 8280CFF4: 83FE0138  lwz r31, 0x138(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280CFF8: D01A0000  stfs f0, 0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8280CFFC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280D000: 419A0018  beq cr6, 0x8280d018
	if ctx.cr[6].eq {
	pc = 0x8280D018; continue 'dispatch;
	}
	// 8280D004: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D008: 4BD04AE1  bl 0x82511ae8
	ctx.lr = 0x8280D00C;
	sub_82511AE8(ctx, base);
	// 8280D00C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280D010: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D014: 48339B95  bl 0x82b46ba8
	ctx.lr = 0x8280D018;
	sub_82B46BA8(ctx, base);
	// 8280D018: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280D01C: 3BFE00F8  addi r31, r30, 0xf8
	ctx.r[31].s64 = ctx.r[30].s64 + 248;
	// 8280D020: 3B9E0160  addi r28, r30, 0x160
	ctx.r[28].s64 = ctx.r[30].s64 + 352;
	// 8280D024: 3BA00002  li r29, 2
	ctx.r[29].s64 = 2;
	// 8280D028: 3B6BE9A0  addi r27, r11, -0x1660
	ctx.r[27].s64 = ctx.r[11].s64 + -5728;
	// 8280D02C: 13E0D407  vcmpneb. (lvlx128) v31, v0, v26
	tmp.u32 = ctx.r[26].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280D030: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D090(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280D090 size=20
    let mut pc: u32 = 0x8280D090;
    'dispatch: loop {
        match pc {
            0x8280D090 => {
    //   block [0x8280D090..0x8280D0A4)
	// 8280D090: 8164015C  lwz r11, 0x15c(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(348 as u32) ) } as u64;
	// 8280D094: 39240158  addi r9, r4, 0x158
	ctx.r[9].s64 = ctx.r[4].s64 + 344;
	// 8280D098: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D09C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8280D0A0: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D0A4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8280D0A4 size=84
    let mut pc: u32 = 0x8280D0A4;
    'dispatch: loop {
        match pc {
            0x8280D0A4 => {
    //   block [0x8280D0A4..0x8280D0F8)
	// 8280D0A4: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280D0A8: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280D0AC: D001FFFC  stfs f0, -4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8280D0B0: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280D0B4: 3901FFF0  addi r8, r1, -0x10
	ctx.r[8].s64 = ctx.r[1].s64 + -16;
	// 8280D0B8: C0030018  lfs f0, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280D0BC: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 8280D0C0: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280D0C4: EC0D0032  fmuls f0, f13, f0
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8280D0C8: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280D0CC: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280D0D0: D181FFF0  stfs f12, -0x10(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 8280D0D4: D001FFF8  stfs f0, -8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8280D0D8: D1A1FFF4  stfs f13, -0xc(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 8280D0DC: 13E040C7  vcmpequd (lvx128) v31, v0, v8
	tmp.u32 = ctx.r[8].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D0F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D0F8 size=308
    let mut pc: u32 = 0x8280D0F8;
    'dispatch: loop {
        match pc {
            0x8280D0F8 => {
    //   block [0x8280D0F8..0x8280D22C)
	// 8280D0F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D0FC: 4899B06D  bl 0x831a8168
	ctx.lr = 0x8280D100;
	sub_831A8130(ctx, base);
	// 8280D100: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D104: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280D108: 80840000  lwz r4, 0(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D10C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280D110: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 8280D114: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8280D118: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 8280D11C: 4861D9CD  bl 0x82e2aae8
	ctx.lr = 0x8280D120;
	sub_82E2AAE8(ctx, base);
	// 8280D120: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8280D124: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280D128: 485E68E1  bl 0x82df3a08
	ctx.lr = 0x8280D12C;
	sub_82DF3A08(ctx, base);
	// 8280D12C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280D130: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280D134: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280D138: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280D13C: 48621D35  bl 0x82e2ee70
	ctx.lr = 0x8280D140;
	sub_82E2EE70(ctx, base);
	// 8280D140: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280D144: 485E62E5  bl 0x82df3428
	ctx.lr = 0x8280D148;
	sub_82DF3428(ctx, base);
	// 8280D148: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280D14C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D150: 419A009C  beq cr6, 0x8280d1ec
	if ctx.cr[6].eq {
	pc = 0x8280D1EC; continue 'dispatch;
	}
	// 8280D154: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D158: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280D15C: 388B8658  addi r4, r11, -0x79a8
	ctx.r[4].s64 = ctx.r[11].s64 + -31144;
	// 8280D160: 38A000D3  li r5, 0xd3
	ctx.r[5].s64 = 211;
	// 8280D164: 38600098  li r3, 0x98
	ctx.r[3].s64 = 152;
	// 8280D168: 485E5281  bl 0x82df23e8
	ctx.lr = 0x8280D16C;
	sub_82DF23E8(ctx, base);
	// 8280D16C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280D170: 41820014  beq 0x8280d184
	if ctx.cr[0].eq {
	pc = 0x8280D184; continue 'dispatch;
	}
	// 8280D174: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 8280D178: 48609719  bl 0x82e16890
	ctx.lr = 0x8280D17C;
	sub_82E16890(ctx, base);
	// 8280D17C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280D180: 48000008  b 0x8280d188
	pc = 0x8280D188; continue 'dispatch;
	// 8280D184: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280D188: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D18C: 4BB501E5  bl 0x8235d370
	ctx.lr = 0x8280D190;
	sub_8235D370(ctx, base);
	// 8280D190: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8280D194: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 8280D198: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280D19C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280D1A0: 808B7058  lwz r4, 0x7058(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28760 as u32) ) } as u64;
	// 8280D1A4: 4BD039B5  bl 0x82510b58
	ctx.lr = 0x8280D1A8;
	sub_82510B58(ctx, base);
	// 8280D1A8: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D1AC: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D1B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D1B4: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280D1B8: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280D1BC: 419A0024  beq cr6, 0x8280d1e0
	if ctx.cr[6].eq {
	pc = 0x8280D1E0; continue 'dispatch;
	}
	// 8280D1C0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D1C4: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D1C8: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D1CC: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D1D0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D1D4: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D1D8: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D1DC: 4082FFE8  bne 0x8280d1c4
	if !ctx.cr[0].eq {
	pc = 0x8280D1C4; continue 'dispatch;
	}
	// 8280D1E0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280D1E4: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D1E8: 48607EC9  bl 0x82e150b0
	ctx.lr = 0x8280D1EC;
	sub_82E150B0(ctx, base);
	// 8280D1EC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280D1F0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D1F4: 419A0008  beq cr6, 0x8280d1fc
	if ctx.cr[6].eq {
	pc = 0x8280D1FC; continue 'dispatch;
	}
	// 8280D1F8: 4BAB3699  bl 0x822c0890
	ctx.lr = 0x8280D1FC;
	sub_822C0890(ctx, base);
	// 8280D1FC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280D200: 4861D901  bl 0x82e2ab00
	ctx.lr = 0x8280D204;
	sub_82E2AB00(ctx, base);
	// 8280D204: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D208: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D20C: 419A0008  beq cr6, 0x8280d214
	if ctx.cr[6].eq {
	pc = 0x8280D214; continue 'dispatch;
	}
	// 8280D210: 4BAB3681  bl 0x822c0890
	ctx.lr = 0x8280D214;
	sub_822C0890(ctx, base);
	// 8280D214: 807E0004  lwz r3, 4(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D218: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D21C: 419A0008  beq cr6, 0x8280d224
	if ctx.cr[6].eq {
	pc = 0x8280D224; continue 'dispatch;
	}
	// 8280D220: 4BAB3671  bl 0x822c0890
	ctx.lr = 0x8280D224;
	sub_822C0890(ctx, base);
	// 8280D224: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280D228: 4899AF90  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D230(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280D230 size=244
    let mut pc: u32 = 0x8280D230;
    'dispatch: loop {
        match pc {
            0x8280D230 => {
    //   block [0x8280D230..0x8280D324)
	// 8280D230: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D234: 4899AF35  bl 0x831a8168
	ctx.lr = 0x8280D238;
	sub_831A8130(ctx, base);
	// 8280D238: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D23C: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280D240: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280D244: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280D248: 3BEBADF4  addi r31, r11, -0x520c
	ctx.r[31].s64 = ctx.r[11].s64 + -21004;
	// 8280D24C: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8280D250: 816AADF8  lwz r11, -0x5208(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-21000 as u32) ) } as u64;
	// 8280D254: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8280D258: 40820018  bne 0x8280d270
	if !ctx.cr[0].eq {
	pc = 0x8280D270; continue 'dispatch;
	}
	// 8280D25C: 3D208336  lis r9, -0x7cca
	ctx.r[9].s64 = -2093613056;
	// 8280D260: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8280D264: 916AADF8  stw r11, -0x5208(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-21000 as u32), ctx.r[11].u32 ) };
	// 8280D268: 81698614  lwz r11, -0x79ec(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-31212 as u32) ) } as u64;
	// 8280D26C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280D270: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 8280D274: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D278: 3B8B6910  addi r28, r11, 0x6910
	ctx.r[28].s64 = ctx.r[11].s64 + 26896;
	// 8280D27C: 4BD0486D  bl 0x82511ae8
	ctx.lr = 0x8280D280;
	sub_82511AE8(ctx, base);
	// 8280D280: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8280D284: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D288: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280D28C: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8280D290: 4BFFEC01  bl 0x8280be90
	ctx.lr = 0x8280D294;
	sub_8280BE90(ctx, base);
	// 8280D294: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D298: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280D29C: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D2A0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D2A4: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280D2A8: 419A0024  beq cr6, 0x8280d2cc
	if ctx.cr[6].eq {
	pc = 0x8280D2CC; continue 'dispatch;
	}
	// 8280D2AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D2B0: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D2B4: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D2B8: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D2BC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D2C0: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D2C4: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D2C8: 4082FFE8  bne 0x8280d2b0
	if !ctx.cr[0].eq {
	pc = 0x8280D2B0; continue 'dispatch;
	}
	// 8280D2CC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280D2D0: 3BE10050  addi r31, r1, 0x50
	ctx.r[31].s64 = ctx.r[1].s64 + 80;
	// 8280D2D4: 487FAE55  bl 0x83008128
	ctx.lr = 0x8280D2D8;
	sub_83008128(ctx, base);
	// 8280D2D8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280D2DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280D2E0: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8280D2E4: 388A8658  addi r4, r10, -0x79a8
	ctx.r[4].s64 = ctx.r[10].s64 + -31144;
	// 8280D2E8: 38A0010D  li r5, 0x10d
	ctx.r[5].s64 = 269;
	// 8280D2EC: 387E0028  addi r3, r30, 0x28
	ctx.r[3].s64 = ctx.r[30].s64 + 40;
	// 8280D2F0: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280D2F4: 7FE7FB78  mr r7, r31
	ctx.r[7].u64 = ctx.r[31].u64;
	// 8280D2F8: 4864B749  bl 0x82e58a40
	ctx.lr = 0x8280D2FC;
	sub_82E58A40(ctx, base);
	// 8280D2FC: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8280D300: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D304: 419A0008  beq cr6, 0x8280d30c
	if ctx.cr[6].eq {
	pc = 0x8280D30C; continue 'dispatch;
	}
	// 8280D308: 4BAB3589  bl 0x822c0890
	ctx.lr = 0x8280D30C;
	sub_822C0890(ctx, base);
	// 8280D30C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280D310: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D314: 419A0008  beq cr6, 0x8280d31c
	if ctx.cr[6].eq {
	pc = 0x8280D31C; continue 'dispatch;
	}
	// 8280D318: 4BAB3579  bl 0x822c0890
	ctx.lr = 0x8280D31C;
	sub_822C0890(ctx, base);
	// 8280D31C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280D320: 4899AE98  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D328(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280D328 size=124
    let mut pc: u32 = 0x8280D328;
    'dispatch: loop {
        match pc {
            0x8280D328 => {
    //   block [0x8280D328..0x8280D3A4)
	// 8280D328: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D32C: 4899AE41  bl 0x831a816c
	ctx.lr = 0x8280D330;
	sub_831A8130(ctx, base);
	// 8280D330: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D334: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280D338: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8280D33C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D340: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8280D344: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280D348: 93DF0000  stw r30, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280D34C: 388B8658  addi r4, r11, -0x79a8
	ctx.r[4].s64 = ctx.r[11].s64 + -31144;
	// 8280D350: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280D354: 38A00119  li r5, 0x119
	ctx.r[5].s64 = 281;
	// 8280D358: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 8280D35C: 386000E0  li r3, 0xe0
	ctx.r[3].s64 = 224;
	// 8280D360: 93DF000C  stw r30, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[30].u32 ) };
	// 8280D364: 93DF0010  stw r30, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 8280D368: 93DF0014  stw r30, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[30].u32 ) };
	// 8280D36C: D03F0018  stfs f1, 0x18(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 8280D370: 485E5079  bl 0x82df23e8
	ctx.lr = 0x8280D374;
	sub_82DF23E8(ctx, base);
	// 8280D374: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280D378: 41820014  beq 0x8280d38c
	if ctx.cr[0].eq {
	pc = 0x8280D38C; continue 'dispatch;
	}
	// 8280D37C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280D380: 48605D71  bl 0x82e130f0
	ctx.lr = 0x8280D384;
	sub_82E130F0(ctx, base);
	// 8280D384: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280D388: 48000008  b 0x8280d390
	pc = 0x8280D390; continue 'dispatch;
	// 8280D38C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280D390: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D394: 4BAD49BD  bl 0x822e1d50
	ctx.lr = 0x8280D398;
	sub_822E1D50(ctx, base);
	// 8280D398: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D39C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280D3A0: 4899AE1C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D3A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D3A8 size=188
    let mut pc: u32 = 0x8280D3A8;
    'dispatch: loop {
        match pc {
            0x8280D3A8 => {
    //   block [0x8280D3A8..0x8280D464)
	// 8280D3A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D3AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280D3B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280D3B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280D3B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D3BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280D3C0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280D3C4: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 8280D3C8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280D3CC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280D3D0: 4BAB3569  bl 0x822c0938
	ctx.lr = 0x8280D3D4;
	sub_822C0938(ctx, base);
	// 8280D3D4: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280D3D8: 41820028  beq 0x8280d400
	if ctx.cr[0].eq {
	pc = 0x8280D400; continue 'dispatch;
	}
	// 8280D3DC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D3E0: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 8280D3E4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280D3E8: 392B8648  addi r9, r11, -0x79b8
	ctx.r[9].s64 = ctx.r[11].s64 + -31160;
	// 8280D3EC: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8280D3F0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280D3F4: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8280D3F8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8280D3FC: 48000008  b 0x8280d404
	pc = 0x8280D404; continue 'dispatch;
	// 8280D400: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280D404: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280D408: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D40C: 409A003C  bne cr6, 0x8280d448
	if !ctx.cr[6].eq {
	pc = 0x8280D448; continue 'dispatch;
	}
	// 8280D410: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280D414: 419A0014  beq cr6, 0x8280d428
	if ctx.cr[6].eq {
	pc = 0x8280D428; continue 'dispatch;
	}
	// 8280D418: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D41C: 4BAE44D5  bl 0x822f18f0
	ctx.lr = 0x8280D420;
	sub_822F18F0(ctx, base);
	// 8280D420: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D424: 4BAB2E45  bl 0x822c0268
	ctx.lr = 0x8280D428;
	sub_822C0268(ctx, base);
	// 8280D428: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280D42C: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280D430: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280D434: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 8280D438: 816BE990  lwz r11, -0x1670(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-5744 as u32) ) } as u64;
	// 8280D43C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280D440: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280D444: 4BAB2BBD  bl 0x822c0000
	ctx.lr = 0x8280D448;
	sub_822C0000(ctx, base);
	// 8280D448: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D44C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280D450: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280D454: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280D458: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280D45C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280D460: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D468(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D468 size=64
    let mut pc: u32 = 0x8280D468;
    'dispatch: loop {
        match pc {
            0x8280D468 => {
    //   block [0x8280D468..0x8280D4A8)
	// 8280D468: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D46C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280D470: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280D474: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D478: 83E3000C  lwz r31, 0xc(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8280D47C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280D480: 419A0014  beq cr6, 0x8280d494
	if ctx.cr[6].eq {
	pc = 0x8280D494; continue 'dispatch;
	}
	// 8280D484: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D488: 4BAE4469  bl 0x822f18f0
	ctx.lr = 0x8280D48C;
	sub_822F18F0(ctx, base);
	// 8280D48C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D490: 4BAB2DD9  bl 0x822c0268
	ctx.lr = 0x8280D494;
	sub_822C0268(ctx, base);
	// 8280D494: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280D498: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280D49C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280D4A0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280D4A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D4A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D4A8 size=164
    let mut pc: u32 = 0x8280D4A8;
    'dispatch: loop {
        match pc {
            0x8280D4A8 => {
    //   block [0x8280D4A8..0x8280D54C)
	// 8280D4A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D4AC: 4899ACBD  bl 0x831a8168
	ctx.lr = 0x8280D4B0;
	sub_831A8130(ctx, base);
	// 8280D4B0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D4B4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8280D4B8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280D4BC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280D4C0: 57BC063F  clrlwi. r28, r29, 0x18
	ctx.r[28].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 8280D4C4: 41820038  beq 0x8280d4fc
	if ctx.cr[0].eq {
	pc = 0x8280D4FC; continue 'dispatch;
	}
	// 8280D4C8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D4CC: 4899C4BD  bl 0x831a9988
	ctx.lr = 0x8280D4D0;
	sub_831A9988(ctx, base);
	// 8280D4D0: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280D4D4: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280D4D8: 386BE224  addi r3, r11, -0x1ddc
	ctx.r[3].s64 = ctx.r[11].s64 + -7644;
	// 8280D4DC: 4899AC1D  bl 0x831a80f8
	ctx.lr = 0x8280D4E0;
	sub_831A80F8(ctx, base);
	// 8280D4E0: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280D4E4: 41820018  beq 0x8280d4fc
	if ctx.cr[0].eq {
	pc = 0x8280D4FC; continue 'dispatch;
	}
	// 8280D4E8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D4EC: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8280D4F0: 4BFFF619  bl 0x8280cb08
	ctx.lr = 0x8280D4F4;
	sub_8280CB08(ctx, base);
	// 8280D4F4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8280D4F8: 4800004C  b 0x8280d544
	pc = 0x8280D544; continue 'dispatch;
	// 8280D4FC: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 8280D500: 419A0034  beq cr6, 0x8280d534
	if ctx.cr[6].eq {
	pc = 0x8280D534; continue 'dispatch;
	}
	// 8280D504: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D508: 4899C481  bl 0x831a9988
	ctx.lr = 0x8280D50C;
	sub_831A9988(ctx, base);
	// 8280D50C: 3D608325  lis r11, -0x7cdb
	ctx.r[11].s64 = -2094727168;
	// 8280D510: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280D514: 386B3644  addi r3, r11, 0x3644
	ctx.r[3].s64 = ctx.r[11].s64 + 13892;
	// 8280D518: 4899ABE1  bl 0x831a80f8
	ctx.lr = 0x8280D51C;
	sub_831A80F8(ctx, base);
	// 8280D51C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280D520: 41820014  beq 0x8280d534
	if ctx.cr[0].eq {
	pc = 0x8280D534; continue 'dispatch;
	}
	// 8280D524: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D528: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8280D52C: 4BFFFD05  bl 0x8280d230
	ctx.lr = 0x8280D530;
	sub_8280D230(ctx, base);
	// 8280D530: 4BFFFFC4  b 0x8280d4f4
	pc = 0x8280D4F4; continue 'dispatch;
	// 8280D534: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8280D538: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D53C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D540: 4BFEFD49  bl 0x827fd288
	ctx.lr = 0x8280D544;
	sub_827FD288(ctx, base);
	// 8280D544: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280D548: 4899AC70  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D550(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D550 size=400
    let mut pc: u32 = 0x8280D550;
    'dispatch: loop {
        match pc {
            0x8280D550 => {
    //   block [0x8280D550..0x8280D6E0)
	// 8280D550: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D554: 4899AC19  bl 0x831a816c
	ctx.lr = 0x8280D558;
	sub_831A8130(ctx, base);
	// 8280D558: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D55C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280D560: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8280D564: 4BFEFA05  bl 0x827fcf68
	ctx.lr = 0x8280D568;
	sub_827FCF68(ctx, base);
	// 8280D568: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280D56C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D570: 83DF00E8  lwz r30, 0xe8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(232 as u32) ) } as u64;
	// 8280D574: 4BD04BA5  bl 0x82512118
	ctx.lr = 0x8280D578;
	sub_82512118(ctx, base);
	// 8280D578: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280D57C: 80630000  lwz r3, 0(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D580: 486058B1  bl 0x82e12e30
	ctx.lr = 0x8280D584;
	sub_82E12E30(ctx, base);
	// 8280D584: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8280D588: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D58C: 419A0008  beq cr6, 0x8280d594
	if ctx.cr[6].eq {
	pc = 0x8280D594; continue 'dispatch;
	}
	// 8280D590: 4BAB3301  bl 0x822c0890
	ctx.lr = 0x8280D594;
	sub_822C0890(ctx, base);
	// 8280D594: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D598: 83DF00F0  lwz r30, 0xf0(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) } as u64;
	// 8280D59C: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280D5A0: 4BD04B79  bl 0x82512118
	ctx.lr = 0x8280D5A4;
	sub_82512118(ctx, base);
	// 8280D5A4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280D5A8: 80630000  lwz r3, 0(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D5AC: 48605885  bl 0x82e12e30
	ctx.lr = 0x8280D5B0;
	sub_82E12E30(ctx, base);
	// 8280D5B0: 8061006C  lwz r3, 0x6c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8280D5B4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D5B8: 419A0008  beq cr6, 0x8280d5c0
	if ctx.cr[6].eq {
	pc = 0x8280D5C0; continue 'dispatch;
	}
	// 8280D5BC: 4BAB32D5  bl 0x822c0890
	ctx.lr = 0x8280D5C0;
	sub_822C0890(ctx, base);
	// 8280D5C0: 817F010C  lwz r11, 0x10c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) } as u64;
	// 8280D5C4: 815F0108  lwz r10, 0x108(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(264 as u32) ) } as u64;
	// 8280D5C8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D5CC: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280D5D0: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280D5D4: 419A0024  beq cr6, 0x8280d5f8
	if ctx.cr[6].eq {
	pc = 0x8280D5F8; continue 'dispatch;
	}
	// 8280D5D8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D5DC: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D5E0: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D5E4: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D5E8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D5EC: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D5F0: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D5F4: 4082FFE8  bne 0x8280d5dc
	if !ctx.cr[0].eq {
	pc = 0x8280D5DC; continue 'dispatch;
	}
	// 8280D5F8: 817F011C  lwz r11, 0x11c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(284 as u32) ) } as u64;
	// 8280D5FC: 815F0118  lwz r10, 0x118(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(280 as u32) ) } as u64;
	// 8280D600: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D604: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8280D608: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8280D60C: 419A0024  beq cr6, 0x8280d630
	if ctx.cr[6].eq {
	pc = 0x8280D630; continue 'dispatch;
	}
	// 8280D610: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D614: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D618: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D61C: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D620: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D624: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D628: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D62C: 4082FFE8  bne 0x8280d614
	if !ctx.cr[0].eq {
	pc = 0x8280D614; continue 'dispatch;
	}
	// 8280D630: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D634: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 8280D638: 3BCB86A4  addi r30, r11, -0x795c
	ctx.r[30].s64 = ctx.r[11].s64 + -31068;
	// 8280D63C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8280D640: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 8280D644: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280D648: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D64C: 4BFFFAAD  bl 0x8280d0f8
	ctx.lr = 0x8280D650;
	sub_8280D0F8(ctx, base);
	// 8280D650: 817F0114  lwz r11, 0x114(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(276 as u32) ) } as u64;
	// 8280D654: 815F0110  lwz r10, 0x110(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(272 as u32) ) } as u64;
	// 8280D658: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D65C: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8280D660: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8280D664: 419A0024  beq cr6, 0x8280d688
	if ctx.cr[6].eq {
	pc = 0x8280D688; continue 'dispatch;
	}
	// 8280D668: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D66C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D670: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D674: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D678: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D67C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D680: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D684: 4082FFE8  bne 0x8280d66c
	if !ctx.cr[0].eq {
	pc = 0x8280D66C; continue 'dispatch;
	}
	// 8280D688: 817F0124  lwz r11, 0x124(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 8280D68C: 815F0120  lwz r10, 0x120(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280D690: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D694: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280D698: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280D69C: 419A0024  beq cr6, 0x8280d6c0
	if ctx.cr[6].eq {
	pc = 0x8280D6C0; continue 'dispatch;
	}
	// 8280D6A0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D6A4: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280D6A8: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D6AC: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280D6B0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280D6B4: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280D6B8: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280D6BC: 4082FFE8  bne 0x8280d6a4
	if !ctx.cr[0].eq {
	pc = 0x8280D6A4; continue 'dispatch;
	}
	// 8280D6C0: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 8280D6C4: 38C10058  addi r6, r1, 0x58
	ctx.r[6].s64 = ctx.r[1].s64 + 88;
	// 8280D6C8: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280D6CC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280D6D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D6D4: 4BFFFA25  bl 0x8280d0f8
	ctx.lr = 0x8280D6D8;
	sub_8280D0F8(ctx, base);
	// 8280D6D8: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280D6DC: 4899AAE0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D6E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D6E0 size=136
    let mut pc: u32 = 0x8280D6E0;
    'dispatch: loop {
        match pc {
            0x8280D6E0 => {
    //   block [0x8280D6E0..0x8280D768)
	// 8280D6E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D6E4: 4899AA89  bl 0x831a816c
	ctx.lr = 0x8280D6E8;
	sub_831A8130(ctx, base);
	// 8280D6E8: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8280D6EC: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D6F0: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D6F4: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 8280D6F8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280D6FC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280D700: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280D704: 388B8658  addi r4, r11, -0x79a8
	ctx.r[4].s64 = ctx.r[11].s64 + -31144;
	// 8280D708: 38A000DF  li r5, 0xdf
	ctx.r[5].s64 = 223;
	// 8280D70C: 3860001C  li r3, 0x1c
	ctx.r[3].s64 = 28;
	// 8280D710: 4BAB2CC9  bl 0x822c03d8
	ctx.lr = 0x8280D714;
	sub_822C03D8(ctx, base);
	// 8280D714: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280D718: 41820018  beq 0x8280d730
	if ctx.cr[0].eq {
	pc = 0x8280D730; continue 'dispatch;
	}
	// 8280D71C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D720: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 8280D724: 4BFFFC05  bl 0x8280d328
	ctx.lr = 0x8280D728;
	sub_8280D328(ctx, base);
	// 8280D728: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280D72C: 48000008  b 0x8280d734
	pc = 0x8280D734; continue 'dispatch;
	// 8280D730: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280D734: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280D738: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 8280D73C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D740: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D744: 4BFFFC65  bl 0x8280d3a8
	ctx.lr = 0x8280D748;
	sub_8280D3A8(ctx, base);
	// 8280D748: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280D74C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280D750: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D754: 4BAB28AD  bl 0x822c0000
	ctx.lr = 0x8280D758;
	sub_822C0000(ctx, base);
	// 8280D758: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280D75C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280D760: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 8280D764: 4899AA58  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D768(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D768 size=128
    let mut pc: u32 = 0x8280D768;
    'dispatch: loop {
        match pc {
            0x8280D768 => {
    //   block [0x8280D768..0x8280D7E8)
	// 8280D768: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D76C: 4899AA01  bl 0x831a816c
	ctx.lr = 0x8280D770;
	sub_831A8130(ctx, base);
	// 8280D770: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D774: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280D778: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280D77C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280D780: 3BEBADFC  addi r31, r11, -0x5204
	ctx.r[31].s64 = ctx.r[11].s64 + -20996;
	// 8280D784: 816AAE04  lwz r11, -0x51fc(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20988 as u32) ) } as u64;
	// 8280D788: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8280D78C: 40820024  bne 0x8280d7b0
	if !ctx.cr[0].eq {
	pc = 0x8280D7B0; continue 'dispatch;
	}
	// 8280D790: 3D208256  lis r9, -0x7daa
	ctx.r[9].s64 = -2108293120;
	// 8280D794: 3D008281  lis r8, -0x7d7f
	ctx.r[8].s64 = -2105475072;
	// 8280D798: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8280D79C: 3929DA70  addi r9, r9, -0x2590
	ctx.r[9].s64 = ctx.r[9].s64 + -9616;
	// 8280D7A0: 3908CF68  addi r8, r8, -0x3098
	ctx.r[8].s64 = ctx.r[8].s64 + -12440;
	// 8280D7A4: 916AAE04  stw r11, -0x51fc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-20988 as u32), ctx.r[11].u32 ) };
	// 8280D7A8: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 8280D7AC: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8280D7B0: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 8280D7B4: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8280D7B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D7BC: 38BE0008  addi r5, r30, 8
	ctx.r[5].s64 = ctx.r[30].s64 + 8;
	// 8280D7C0: 9BAB0000  stb r29, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u8 ) };
	// 8280D7C4: 88C10050  lbz r6, 0x50(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8280D7C8: 4BDC5159  bl 0x825d2920
	ctx.lr = 0x8280D7CC;
	sub_825D2920(ctx, base);
	// 8280D7CC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280D7D0: 4182000C  beq 0x8280d7dc
	if ctx.cr[0].eq {
	pc = 0x8280D7DC; continue 'dispatch;
	}
	// 8280D7D4: 93FE0000  stw r31, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280D7D8: 48000008  b 0x8280d7e0
	pc = 0x8280D7E0; continue 'dispatch;
	// 8280D7DC: 93BE0000  stw r29, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 8280D7E0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280D7E4: 4899A9D8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D7E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D7E8 size=144
    let mut pc: u32 = 0x8280D7E8;
    'dispatch: loop {
        match pc {
            0x8280D7E8 => {
    //   block [0x8280D7E8..0x8280D878)
	// 8280D7E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D7EC: 4899A979  bl 0x831a8164
	ctx.lr = 0x8280D7F0;
	sub_831A8130(ctx, base);
	// 8280D7F0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D7F4: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8280D7F8: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8280D7FC: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D800: 83CB0000  lwz r30, 0(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D804: 48000064  b 0x8280d868
	pc = 0x8280D868; continue 'dispatch;
	// 8280D808: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280D80C: 3BAB0108  addi r29, r11, 0x108
	ctx.r[29].s64 = ctx.r[11].s64 + 264;
	// 8280D810: 816B010C  lwz r11, 0x10c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(268 as u32) ) } as u64;
	// 8280D814: 83EB0000  lwz r31, 0(r11)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D818: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8280D81C: 419A0044  beq cr6, 0x8280d860
	if ctx.cr[6].eq {
	pc = 0x8280D860; continue 'dispatch;
	}
	// 8280D820: 3D608281  lis r11, -0x7d7f
	ctx.r[11].s64 = -2105475072;
	// 8280D824: 93610054  stw r27, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[27].u32 ) };
	// 8280D828: 396BD090  addi r11, r11, -0x2f70
	ctx.r[11].s64 = ctx.r[11].s64 + -12144;
	// 8280D82C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280D830: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280D834: E8810050  ld r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8280D838: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280D83C: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8280D840: 4BFFFF29  bl 0x8280d768
	ctx.lr = 0x8280D844;
	sub_8280D768(ctx, base);
	// 8280D844: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280D848: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280D84C: 4BE7C5FD  bl 0x82689e48
	ctx.lr = 0x8280D850;
	sub_82689E48(ctx, base);
	// 8280D850: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D854: 83FF0000  lwz r31, 0(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D858: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8280D85C: 409AFFD4  bne cr6, 0x8280d830
	if !ctx.cr[6].eq {
	pc = 0x8280D830; continue 'dispatch;
	}
	// 8280D860: 83DE0000  lwz r30, 0(r30)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D864: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D868: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8280D86C: 409AFF9C  bne cr6, 0x8280d808
	if !ctx.cr[6].eq {
	pc = 0x8280D808; continue 'dispatch;
	}
	// 8280D870: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8280D874: 4899A940  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D878(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D878 size=292
    let mut pc: u32 = 0x8280D878;
    'dispatch: loop {
        match pc {
            0x8280D878 => {
    //   block [0x8280D878..0x8280D99C)
	// 8280D878: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D87C: 4899A8F1  bl 0x831a816c
	ctx.lr = 0x8280D880;
	sub_831A8130(ctx, base);
	// 8280D880: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D884: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280D888: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D88C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280D890: 396B86CC  addi r11, r11, -0x7934
	ctx.r[11].s64 = ctx.r[11].s64 + -31028;
	// 8280D894: 394A86B8  addi r10, r10, -0x7948
	ctx.r[10].s64 = ctx.r[10].s64 + -31048;
	// 8280D898: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280D89C: 3BDF0140  addi r30, r31, 0x140
	ctx.r[30].s64 = ctx.r[31].s64 + 320;
	// 8280D8A0: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280D8A4: 387E0010  addi r3, r30, 0x10
	ctx.r[3].s64 = ctx.r[30].s64 + 16;
	// 8280D8A8: 4BCA39F9  bl 0x824b12a0
	ctx.lr = 0x8280D8AC;
	sub_824B12A0(ctx, base);
	// 8280D8AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280D8B0: 4BCA39F1  bl 0x824b12a0
	ctx.lr = 0x8280D8B4;
	sub_824B12A0(ctx, base);
	// 8280D8B4: 807F013C  lwz r3, 0x13c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(316 as u32) ) } as u64;
	// 8280D8B8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D8BC: 419A0008  beq cr6, 0x8280d8c4
	if ctx.cr[6].eq {
	pc = 0x8280D8C4; continue 'dispatch;
	}
	// 8280D8C0: 4BAB2FD1  bl 0x822c0890
	ctx.lr = 0x8280D8C4;
	sub_822C0890(ctx, base);
	// 8280D8C4: 397F0138  addi r11, r31, 0x138
	ctx.r[11].s64 = ctx.r[31].s64 + 312;
	// 8280D8C8: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8280D8CC: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8280D8D0: 3BDEFFF8  addi r30, r30, -8
	ctx.r[30].s64 = ctx.r[30].s64 + -8;
	// 8280D8D4: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D8D8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D8DC: 419A0008  beq cr6, 0x8280d8e4
	if ctx.cr[6].eq {
	pc = 0x8280D8E4; continue 'dispatch;
	}
	// 8280D8E0: 4BAB2FB1  bl 0x822c0890
	ctx.lr = 0x8280D8E4;
	sub_822C0890(ctx, base);
	// 8280D8E4: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280D8E8: 4080FFE8  bge 0x8280d8d0
	if !ctx.cr[0].lt {
	pc = 0x8280D8D0; continue 'dispatch;
	}
	// 8280D8EC: 397F0128  addi r11, r31, 0x128
	ctx.r[11].s64 = ctx.r[31].s64 + 296;
	// 8280D8F0: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8280D8F4: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8280D8F8: 3BDEFFF8  addi r30, r30, -8
	ctx.r[30].s64 = ctx.r[30].s64 + -8;
	// 8280D8FC: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D900: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D904: 419A0008  beq cr6, 0x8280d90c
	if ctx.cr[6].eq {
	pc = 0x8280D90C; continue 'dispatch;
	}
	// 8280D908: 4BAB2F89  bl 0x822c0890
	ctx.lr = 0x8280D90C;
	sub_822C0890(ctx, base);
	// 8280D90C: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280D910: 4080FFE8  bge 0x8280d8f8
	if !ctx.cr[0].lt {
	pc = 0x8280D8F8; continue 'dispatch;
	}
	// 8280D914: 397F0118  addi r11, r31, 0x118
	ctx.r[11].s64 = ctx.r[31].s64 + 280;
	// 8280D918: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8280D91C: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8280D920: 3BDEFFF8  addi r30, r30, -8
	ctx.r[30].s64 = ctx.r[30].s64 + -8;
	// 8280D924: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D928: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D92C: 419A0008  beq cr6, 0x8280d934
	if ctx.cr[6].eq {
	pc = 0x8280D934; continue 'dispatch;
	}
	// 8280D930: 4BAB2F61  bl 0x822c0890
	ctx.lr = 0x8280D934;
	sub_822C0890(ctx, base);
	// 8280D934: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280D938: 4080FFE8  bge 0x8280d920
	if !ctx.cr[0].lt {
	pc = 0x8280D920; continue 'dispatch;
	}
	// 8280D93C: 397F0108  addi r11, r31, 0x108
	ctx.r[11].s64 = ctx.r[31].s64 + 264;
	// 8280D940: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8280D944: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8280D948: 3BDEFFF8  addi r30, r30, -8
	ctx.r[30].s64 = ctx.r[30].s64 + -8;
	// 8280D94C: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D950: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D954: 419A0008  beq cr6, 0x8280d95c
	if ctx.cr[6].eq {
	pc = 0x8280D95C; continue 'dispatch;
	}
	// 8280D958: 4BAB2F39  bl 0x822c0890
	ctx.lr = 0x8280D95C;
	sub_822C0890(ctx, base);
	// 8280D95C: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280D960: 4080FFE8  bge 0x8280d948
	if !ctx.cr[0].lt {
	pc = 0x8280D948; continue 'dispatch;
	}
	// 8280D964: 397F00F8  addi r11, r31, 0xf8
	ctx.r[11].s64 = ctx.r[31].s64 + 248;
	// 8280D968: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 8280D96C: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8280D970: 3BDEFFF8  addi r30, r30, -8
	ctx.r[30].s64 = ctx.r[30].s64 + -8;
	// 8280D974: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D978: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280D97C: 419A0008  beq cr6, 0x8280d984
	if ctx.cr[6].eq {
	pc = 0x8280D984; continue 'dispatch;
	}
	// 8280D980: 4BAB2F11  bl 0x822c0890
	ctx.lr = 0x8280D984;
	sub_822C0890(ctx, base);
	// 8280D984: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8280D988: 4080FFE8  bge 0x8280d970
	if !ctx.cr[0].lt {
	pc = 0x8280D970; continue 'dispatch;
	}
	// 8280D98C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280D990: 4BFEF779  bl 0x827fd108
	ctx.lr = 0x8280D994;
	sub_827FD108(ctx, base);
	// 8280D994: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280D998: 4899A824  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D9A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280D9A0 size=8
    let mut pc: u32 = 0x8280D9A0;
    'dispatch: loop {
        match pc {
            0x8280D9A0 => {
    //   block [0x8280D9A0..0x8280D9A8)
	// 8280D9A0: 3863FFD8  addi r3, r3, -0x28
	ctx.r[3].s64 = ctx.r[3].s64 + -40;
	// 8280D9A4: 480001FC  b 0x8280dba0
	sub_8280DBA0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280D9A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280D9A8 size=504
    let mut pc: u32 = 0x8280D9A8;
    'dispatch: loop {
        match pc {
            0x8280D9A8 => {
    //   block [0x8280D9A8..0x8280DBA0)
	// 8280D9A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280D9AC: 4899A7BD  bl 0x831a8168
	ctx.lr = 0x8280D9B0;
	sub_831A8130(ctx, base);
	// 8280D9B0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280D9B4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280D9B8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8280D9BC: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D9C0: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8280D9C4: 419A01D4  beq cr6, 0x8280db98
	if ctx.cr[6].eq {
	pc = 0x8280DB98; continue 'dispatch;
	}
	// 8280D9C8: 80650000  lwz r3, 0(r5)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D9CC: 48605465  bl 0x82e12e30
	ctx.lr = 0x8280D9D0;
	sub_82E12E30(ctx, base);
	// 8280D9D0: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280D9D4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280D9D8: 388B8720  addi r4, r11, -0x78e0
	ctx.r[4].s64 = ctx.r[11].s64 + -30944;
	// 8280D9DC: 485E602D  bl 0x82df3a08
	ctx.lr = 0x8280D9E0;
	sub_82DF3A08(ctx, base);
	// 8280D9E0: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280D9E4: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280D9E8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280D9EC: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8280D9F0: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8280D9F4: 419A0024  beq cr6, 0x8280da18
	if ctx.cr[6].eq {
	pc = 0x8280DA18; continue 'dispatch;
	}
	// 8280D9F8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280D9FC: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280DA00: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280DA04: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280DA08: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280DA0C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280DA10: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280DA14: 4082FFE8  bne 0x8280d9fc
	if !ctx.cr[0].eq {
	pc = 0x8280D9FC; continue 'dispatch;
	}
	// 8280DA18: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8280DA1C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8280DA20: 4BCFCF31  bl 0x8250a950
	ctx.lr = 0x8280DA24;
	sub_8250A950(ctx, base);
	// 8280DA24: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DA28: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280DA2C: 388BFF40  addi r4, r11, -0xc0
	ctx.r[4].s64 = ctx.r[11].s64 + -192;
	// 8280DA30: 409A0008  bne cr6, 0x8280da38
	if !ctx.cr[6].eq {
	pc = 0x8280DA38; continue 'dispatch;
	}
	// 8280DA34: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280DA38: 38E00007  li r7, 7
	ctx.r[7].s64 = 7;
	// 8280DA3C: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 8280DA40: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8280DA44: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280DA48: 4BFC7269  bl 0x827d4cb0
	ctx.lr = 0x8280DA4C;
	sub_827D4CB0(ctx, base);
	// 8280DA4C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280DA50: 3BFE0008  addi r31, r30, 8
	ctx.r[31].s64 = ctx.r[30].s64 + 8;
	// 8280DA54: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 8280DA58: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 8280DA5C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DA60: 917E0008  stw r11, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8280DA64: 4BAB69FD  bl 0x822c4460
	ctx.lr = 0x8280DA68;
	sub_822C4460(ctx, base);
	// 8280DA68: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280DA6C: 8061006C  lwz r3, 0x6c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 8280DA70: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8280DA74: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280DA78: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8280DA7C: 697D0001  xori r29, r11, 1
	ctx.r[29].u64 = ctx.r[11].u64 ^ 1;
	// 8280DA80: 419A0008  beq cr6, 0x8280da88
	if ctx.cr[6].eq {
	pc = 0x8280DA88; continue 'dispatch;
	}
	// 8280DA84: 4BAB2E0D  bl 0x822c0890
	ctx.lr = 0x8280DA88;
	sub_822C0890(ctx, base);
	// 8280DA88: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8280DA8C: 485E4205  bl 0x82df1c90
	ctx.lr = 0x8280DA90;
	sub_82DF1C90(ctx, base);
	// 8280DA90: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280DA94: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280DA98: 419A0008  beq cr6, 0x8280daa0
	if ctx.cr[6].eq {
	pc = 0x8280DAA0; continue 'dispatch;
	}
	// 8280DA9C: 4BAB2DF5  bl 0x822c0890
	ctx.lr = 0x8280DAA0;
	sub_822C0890(ctx, base);
	// 8280DAA0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280DAA4: 485E5985  bl 0x82df3428
	ctx.lr = 0x8280DAA8;
	sub_82DF3428(ctx, base);
	// 8280DAA8: 57AB063F  clrlwi. r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280DAAC: 41820018  beq 0x8280dac4
	if ctx.cr[0].eq {
	pc = 0x8280DAC4; continue 'dispatch;
	}
	// 8280DAB0: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DAB4: 4867193D  bl 0x82e7f3f0
	ctx.lr = 0x8280DAB8;
	sub_82E7F3F0(ctx, base);
	// 8280DAB8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280DABC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280DAC0: 4BFFFD29  bl 0x8280d7e8
	ctx.lr = 0x8280DAC4;
	sub_8280D7E8(ctx, base);
	// 8280DAC4: 817E0010  lwz r11, 0x10(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 8280DAC8: 3BFE0010  addi r31, r30, 0x10
	ctx.r[31].s64 = ctx.r[30].s64 + 16;
	// 8280DACC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280DAD0: 409A00C8  bne cr6, 0x8280db98
	if !ctx.cr[6].eq {
	pc = 0x8280DB98; continue 'dispatch;
	}
	// 8280DAD4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280DAD8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280DADC: 388B8708  addi r4, r11, -0x78f8
	ctx.r[4].s64 = ctx.r[11].s64 + -30968;
	// 8280DAE0: 485E5F29  bl 0x82df3a08
	ctx.lr = 0x8280DAE4;
	sub_82DF3A08(ctx, base);
	// 8280DAE4: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280DAE8: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DAEC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280DAF0: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 8280DAF4: 91410060  stw r10, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 8280DAF8: 419A0024  beq cr6, 0x8280db1c
	if ctx.cr[6].eq {
	pc = 0x8280DB1C; continue 'dispatch;
	}
	// 8280DAFC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8280DB00: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 8280DB04: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280DB08: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 8280DB0C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8280DB10: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 8280DB14: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8280DB18: 4082FFE8  bne 0x8280db00
	if !ctx.cr[0].eq {
	pc = 0x8280DB00; continue 'dispatch;
	}
	// 8280DB1C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8280DB20: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 8280DB24: 4BCFCE2D  bl 0x8250a950
	ctx.lr = 0x8280DB28;
	sub_8250A950(ctx, base);
	// 8280DB28: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DB2C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280DB30: 388BFF40  addi r4, r11, -0xc0
	ctx.r[4].s64 = ctx.r[11].s64 + -192;
	// 8280DB34: 409A0008  bne cr6, 0x8280db3c
	if !ctx.cr[6].eq {
	pc = 0x8280DB3C; continue 'dispatch;
	}
	// 8280DB38: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280DB3C: 38E00007  li r7, 7
	ctx.r[7].s64 = 7;
	// 8280DB40: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 8280DB44: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 8280DB48: 38610078  addi r3, r1, 0x78
	ctx.r[3].s64 = ctx.r[1].s64 + 120;
	// 8280DB4C: 4BFC7165  bl 0x827d4cb0
	ctx.lr = 0x8280DB50;
	sub_827D4CB0(ctx, base);
	// 8280DB50: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280DB54: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 8280DB58: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 8280DB5C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DB60: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280DB64: 4BAB68FD  bl 0x822c4460
	ctx.lr = 0x8280DB68;
	sub_822C4460(ctx, base);
	// 8280DB68: 8061007C  lwz r3, 0x7c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 8280DB6C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280DB70: 419A0008  beq cr6, 0x8280db78
	if ctx.cr[6].eq {
	pc = 0x8280DB78; continue 'dispatch;
	}
	// 8280DB74: 4BAB2D1D  bl 0x822c0890
	ctx.lr = 0x8280DB78;
	sub_822C0890(ctx, base);
	// 8280DB78: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 8280DB7C: 485E4115  bl 0x82df1c90
	ctx.lr = 0x8280DB80;
	sub_82DF1C90(ctx, base);
	// 8280DB80: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8280DB84: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280DB88: 419A0008  beq cr6, 0x8280db90
	if ctx.cr[6].eq {
	pc = 0x8280DB90; continue 'dispatch;
	}
	// 8280DB8C: 4BAB2D05  bl 0x822c0890
	ctx.lr = 0x8280DB90;
	sub_822C0890(ctx, base);
	// 8280DB90: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280DB94: 485E5895  bl 0x82df3428
	ctx.lr = 0x8280DB98;
	sub_82DF3428(ctx, base);
	// 8280DB98: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8280DB9C: 4899A61C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280DBA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280DBA0 size=76
    let mut pc: u32 = 0x8280DBA0;
    'dispatch: loop {
        match pc {
            0x8280DBA0 => {
    //   block [0x8280DBA0..0x8280DBEC)
	// 8280DBA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280DBA4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280DBA8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280DBAC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280DBB0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280DBB4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280DBB8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280DBBC: 4BFFFCBD  bl 0x8280d878
	ctx.lr = 0x8280DBC0;
	sub_8280D878(ctx, base);
	// 8280DBC0: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280DBC4: 4182000C  beq 0x8280dbd0
	if ctx.cr[0].eq {
	pc = 0x8280DBD0; continue 'dispatch;
	}
	// 8280DBC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280DBCC: 485E480D  bl 0x82df23d8
	ctx.lr = 0x8280DBD0;
	sub_82DF23D8(ctx, base);
	// 8280DBD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280DBD4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280DBD8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280DBDC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280DBE0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280DBE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280DBE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280DBF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280DBF0 size=960
    let mut pc: u32 = 0x8280DBF0;
    'dispatch: loop {
        match pc {
            0x8280DBF0 => {
    //   block [0x8280DBF0..0x8280DFB0)
	// 8280DBF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280DBF4: 4899A579  bl 0x831a816c
	ctx.lr = 0x8280DBF8;
	sub_831A8130(ctx, base);
	// 8280DBF8: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 8280DBFC: 9421FEE0  stwu r1, -0x120(r1)
	ea = ctx.r[1].u32.wrapping_add(-288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280DC00: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280DC04: 807F00E8  lwz r3, 0xe8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(232 as u32) ) } as u64;
	// 8280DC08: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DC0C: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8280DC10: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280DC14: 4E800421  bctrl
	ctx.lr = 0x8280DC18;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280DC18: 817F00F0  lwz r11, 0xf0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) } as u64;
	// 8280DC1C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8280DC20: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8280DC24: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280DC28: C00A0030  lfs f0, 0x30(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280DC2C: C1AA0034  lfs f13, 0x34(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8280DC30: C18A0038  lfs f12, 0x38(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8280DC34: C16A003C  lfs f11, 0x3c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(60 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8280DC38: 8169000C  lwz r11, 0xc(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 8280DC3C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8280DC40: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8280DC44: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 8280DC48: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 8280DC4C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280DC50: 4E800421  bctrl
	ctx.lr = 0x8280DC54;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280DC54: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 8280DC58: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280DFB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280DFB0 size=212
    let mut pc: u32 = 0x8280DFB0;
    'dispatch: loop {
        match pc {
            0x8280DFB0 => {
    //   block [0x8280DFB0..0x8280E084)
	// 8280DFB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280DFB4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280DFB8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280DFBC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280DFC0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280DFC4: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8280DFC8: F8810090  std r4, 0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[4].u64 ) };
	// 8280DFCC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280DFD0: F8A10098  std r5, 0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[5].u64 ) };
	// 8280DFD4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280DFD8: 388B5D9C  addi r4, r11, 0x5d9c
	ctx.r[4].s64 = ctx.r[11].s64 + 23964;
	// 8280DFDC: 38A0002B  li r5, 0x2b
	ctx.r[5].s64 = 43;
	// 8280DFE0: 38600018  li r3, 0x18
	ctx.r[3].s64 = 24;
	// 8280DFE4: 4BAB23F5  bl 0x822c03d8
	ctx.lr = 0x8280DFE8;
	sub_822C03D8(ctx, base);
	// 8280DFE8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280DFEC: 41820040  beq 0x8280e02c
	if ctx.cr[0].eq {
	pc = 0x8280E02C; continue 'dispatch;
	}
	// 8280DFF0: 39610090  addi r11, r1, 0x90
	ctx.r[11].s64 = ctx.r[1].s64 + 144;
	// 8280DFF4: 39230008  addi r9, r3, 8
	ctx.r[9].s64 = ctx.r[3].s64 + 8;
	// 8280DFF8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280DFFC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E000: 394A863C  addi r10, r10, -0x79c4
	ctx.r[10].s64 = ctx.r[10].s64 + -31172;
	// 8280E004: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E008: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8280E00C: 80EB0008  lwz r7, 8(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8280E010: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8280E014: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8280E018: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8280E01C: 9103000C  stw r8, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 8280E020: 90E30010  stw r7, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8280E024: 91630014  stw r11, 0x14(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8280E028: 48000008  b 0x8280e030
	pc = 0x8280E030; continue 'dispatch;
	// 8280E02C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280E030: 93E10050  stw r31, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[31].u32 ) };
	// 8280E034: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280E038: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280E03C: 4BFFEBF5  bl 0x8280cc30
	ctx.lr = 0x8280E040;
	sub_8280CC30(ctx, base);
	// 8280E040: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280E044: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280E048: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280E04C: 4BAB1FB5  bl 0x822c0000
	ctx.lr = 0x8280E050;
	sub_822C0000(ctx, base);
	// 8280E050: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 8280E054: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280E058: 483A50B1  bl 0x82bb3108
	ctx.lr = 0x8280E05C;
	sub_82BB3108(ctx, base);
	// 8280E05C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8280E060: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E064: 419A0008  beq cr6, 0x8280e06c
	if ctx.cr[6].eq {
	pc = 0x8280E06C; continue 'dispatch;
	}
	// 8280E068: 4BAB2829  bl 0x822c0890
	ctx.lr = 0x8280E06C;
	sub_822C0890(ctx, base);
	// 8280E06C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280E070: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E074: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E078: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280E07C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E080: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E088(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280E088 size=904
    let mut pc: u32 = 0x8280E088;
    'dispatch: loop {
        match pc {
            0x8280E088 => {
    //   block [0x8280E088..0x8280E410)
	// 8280E088: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E08C: 4899A0B9  bl 0x831a8144
	ctx.lr = 0x8280E090;
	sub_831A8130(ctx, base);
	// 8280E090: 9421FEC0  stwu r1, -0x140(r1)
	ea = ctx.r[1].u32.wrapping_add(-320 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E094: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8280E098: 7CB72B78  mr r23, r5
	ctx.r[23].u64 = ctx.r[5].u64;
	// 8280E09C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8280E0A0: 389D0010  addi r4, r29, 0x10
	ctx.r[4].s64 = ctx.r[29].s64 + 16;
	// 8280E0A4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E0A8: 4BFEEFB9  bl 0x827fd060
	ctx.lr = 0x8280E0AC;
	sub_827FD060(ctx, base);
	// 8280E0AC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E0B0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280E0B4: 396B86CC  addi r11, r11, -0x7934
	ctx.r[11].s64 = ctx.r[11].s64 + -31028;
	// 8280E0B8: 394A86B8  addi r10, r10, -0x7948
	ctx.r[10].s64 = ctx.r[10].s64 + -31048;
	// 8280E0BC: 3A7F00E8  addi r19, r31, 0xe8
	ctx.r[19].s64 = ctx.r[31].s64 + 232;
	// 8280E0C0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280E0C4: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280E0C8: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E0CC: 7E6B9B78  mr r11, r19
	ctx.r[11].u64 = ctx.r[19].u64;
	// 8280E0D0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8280E0D4: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280E0D8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8280E0DC: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280E0E0: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8280E0E4: 4080FFF0  bge 0x8280e0d4
	if !ctx.cr[0].lt {
	pc = 0x8280E0D4; continue 'dispatch;
	}
	// 8280E0E8: 3ABF00F8  addi r21, r31, 0xf8
	ctx.r[21].s64 = ctx.r[31].s64 + 248;
	// 8280E0EC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E0F0: 7EABAB78  mr r11, r21
	ctx.r[11].u64 = ctx.r[21].u64;
	// 8280E0F4: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280E0F8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8280E0FC: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280E100: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8280E104: 4080FFF0  bge 0x8280e0f4
	if !ctx.cr[0].lt {
	pc = 0x8280E0F4; continue 'dispatch;
	}
	// 8280E108: 3A9F0108  addi r20, r31, 0x108
	ctx.r[20].s64 = ctx.r[31].s64 + 264;
	// 8280E10C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E110: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 8280E114: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280E118: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8280E11C: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280E120: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8280E124: 4080FFF0  bge 0x8280e114
	if !ctx.cr[0].lt {
	pc = 0x8280E114; continue 'dispatch;
	}
	// 8280E128: 397F0118  addi r11, r31, 0x118
	ctx.r[11].s64 = ctx.r[31].s64 + 280;
	// 8280E12C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E130: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280E134: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8280E138: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280E13C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8280E140: 4080FFF0  bge 0x8280e130
	if !ctx.cr[0].lt {
	pc = 0x8280E130; continue 'dispatch;
	}
	// 8280E144: 397F0128  addi r11, r31, 0x128
	ctx.r[11].s64 = ctx.r[31].s64 + 296;
	// 8280E148: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E14C: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8280E150: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8280E154: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8280E158: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8280E15C: 4080FFF0  bge 0x8280e14c
	if !ctx.cr[0].lt {
	pc = 0x8280E14C; continue 'dispatch;
	}
	// 8280E160: 3D608203  lis r11, -0x7dfd
	ctx.r[11].s64 = -2113732608;
	// 8280E164: 93DF0138  stw r30, 0x138(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(312 as u32), ctx.r[30].u32 ) };
	// 8280E168: 93DF013C  stw r30, 0x13c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(316 as u32), ctx.r[30].u32 ) };
	// 8280E16C: 3B5700C0  addi r26, r23, 0xc0
	ctx.r[26].s64 = ctx.r[23].s64 + 192;
	// 8280E170: 93DF0144  stw r30, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[30].u32 ) };
	// 8280E174: 3B7D0020  addi r27, r29, 0x20
	ctx.r[27].s64 = ctx.r[29].s64 + 32;
	// 8280E178: 93DF0148  stw r30, 0x148(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), ctx.r[30].u32 ) };
	// 8280E17C: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 8280E180: 93DF014C  stw r30, 0x14c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), ctx.r[30].u32 ) };
	// 8280E184: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 8280E188: C00B7BC8  lfs f0, 0x7bc8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(31688 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280E18C: 93DF0154  stw r30, 0x154(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(340 as u32), ctx.r[30].u32 ) };
	// 8280E190: 93DF0158  stw r30, 0x158(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(344 as u32), ctx.r[30].u32 ) };
	// 8280E194: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8280E198: 93DF015C  stw r30, 0x15c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(348 as u32), ctx.r[30].u32 ) };
	// 8280E19C: D01F0184  stfs f0, 0x184(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(388 as u32), tmp.u32 ) };
	// 8280E1A0: 3B9F0140  addi r28, r31, 0x140
	ctx.r[28].s64 = ctx.r[31].s64 + 320;
	// 8280E1A4: 3B1F0184  addi r24, r31, 0x184
	ctx.r[24].s64 = ctx.r[31].s64 + 388;
	// 8280E1A8: 4BFFEB51  bl 0x8280ccf8
	ctx.lr = 0x8280E1AC;
	sub_8280CCF8(ctx, base);
	// 8280E1AC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E1B0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E1B4: 3BAB8658  addi r29, r11, -0x79a8
	ctx.r[29].s64 = ctx.r[11].s64 + -31144;
	// 8280E1B8: 38A00048  li r5, 0x48
	ctx.r[5].s64 = 72;
	// 8280E1BC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280E1C0: 386000E0  li r3, 0xe0
	ctx.r[3].s64 = 224;
	// 8280E1C4: 485E4225  bl 0x82df23e8
	ctx.lr = 0x8280E1C8;
	sub_82DF23E8(ctx, base);
	// 8280E1C8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E1CC: 41820014  beq 0x8280e1e0
	if ctx.cr[0].eq {
	pc = 0x8280E1E0; continue 'dispatch;
	}
	// 8280E1D0: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 8280E1D4: 48604F1D  bl 0x82e130f0
	ctx.lr = 0x8280E1D8;
	sub_82E130F0(ctx, base);
	// 8280E1D8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E1DC: 48000008  b 0x8280e1e4
	pc = 0x8280E1E4; continue 'dispatch;
	// 8280E1E0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E1E4: 7E639B78  mr r3, r19
	ctx.r[3].u64 = ctx.r[19].u64;
	// 8280E1E8: 4BAD3B69  bl 0x822e1d50
	ctx.lr = 0x8280E1EC;
	sub_822E1D50(ctx, base);
	// 8280E1EC: 3B370080  addi r25, r23, 0x80
	ctx.r[25].s64 = ctx.r[23].s64 + 128;
	// 8280E1F0: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 8280E1F4: 7F25CB78  mr r5, r25
	ctx.r[5].u64 = ctx.r[25].u64;
	// 8280E1F8: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8280E1FC: 4BFFEAFD  bl 0x8280ccf8
	ctx.lr = 0x8280E200;
	sub_8280CCF8(ctx, base);
	// 8280E200: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280E204: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E208: 38A0004C  li r5, 0x4c
	ctx.r[5].s64 = 76;
	// 8280E20C: 386000E0  li r3, 0xe0
	ctx.r[3].s64 = 224;
	// 8280E210: 485E41D9  bl 0x82df23e8
	ctx.lr = 0x8280E214;
	sub_82DF23E8(ctx, base);
	// 8280E214: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E218: 41820014  beq 0x8280e22c
	if ctx.cr[0].eq {
	pc = 0x8280E22C; continue 'dispatch;
	}
	// 8280E21C: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 8280E220: 48604ED1  bl 0x82e130f0
	ctx.lr = 0x8280E224;
	sub_82E130F0(ctx, base);
	// 8280E224: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E228: 48000008  b 0x8280e230
	pc = 0x8280E230; continue 'dispatch;
	// 8280E22C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E230: 3ADF00F0  addi r22, r31, 0xf0
	ctx.r[22].s64 = ctx.r[31].s64 + 240;
	// 8280E234: 7EC3B378  mr r3, r22
	ctx.r[3].u64 = ctx.r[22].u64;
	// 8280E238: 4BAD3B19  bl 0x822e1d50
	ctx.lr = 0x8280E23C;
	sub_822E1D50(ctx, base);
	// 8280E23C: 38B70040  addi r5, r23, 0x40
	ctx.r[5].s64 = ctx.r[23].s64 + 64;
	// 8280E240: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 8280E244: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8280E248: 4BFFEAB1  bl 0x8280ccf8
	ctx.lr = 0x8280E24C;
	sub_8280CCF8(ctx, base);
	// 8280E24C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280E250: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E254: 38A00050  li r5, 0x50
	ctx.r[5].s64 = 80;
	// 8280E258: 386000E0  li r3, 0xe0
	ctx.r[3].s64 = 224;
	// 8280E25C: 485E418D  bl 0x82df23e8
	ctx.lr = 0x8280E260;
	sub_82DF23E8(ctx, base);
	// 8280E260: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E264: 41820014  beq 0x8280e278
	if ctx.cr[0].eq {
	pc = 0x8280E278; continue 'dispatch;
	}
	// 8280E268: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 8280E26C: 48604E85  bl 0x82e130f0
	ctx.lr = 0x8280E270;
	sub_82E130F0(ctx, base);
	// 8280E270: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E274: 48000008  b 0x8280e27c
	pc = 0x8280E27C; continue 'dispatch;
	// 8280E278: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E27C: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 8280E280: 4BAD3AD1  bl 0x822e1d50
	ctx.lr = 0x8280E284;
	sub_822E1D50(ctx, base);
	// 8280E284: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 8280E288: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 8280E28C: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
	// 8280E290: 4BFFEA69  bl 0x8280ccf8
	ctx.lr = 0x8280E294;
	sub_8280CCF8(ctx, base);
	// 8280E294: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280E298: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E29C: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 8280E2A0: 386000E0  li r3, 0xe0
	ctx.r[3].s64 = 224;
	// 8280E2A4: 485E4145  bl 0x82df23e8
	ctx.lr = 0x8280E2A8;
	sub_82DF23E8(ctx, base);
	// 8280E2A8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E2AC: 41820014  beq 0x8280e2c0
	if ctx.cr[0].eq {
	pc = 0x8280E2C0; continue 'dispatch;
	}
	// 8280E2B0: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 8280E2B4: 48604E3D  bl 0x82e130f0
	ctx.lr = 0x8280E2B8;
	sub_82E130F0(ctx, base);
	// 8280E2B8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E2BC: 48000008  b 0x8280e2c4
	pc = 0x8280E2C4; continue 'dispatch;
	// 8280E2C0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E2C4: 3B7F0100  addi r27, r31, 0x100
	ctx.r[27].s64 = ctx.r[31].s64 + 256;
	// 8280E2C8: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8280E2CC: 4BAD3A85  bl 0x822e1d50
	ctx.lr = 0x8280E2D0;
	sub_822E1D50(ctx, base);
	// 8280E2D0: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280E2D4: 13C0C407  vcmpneb. (lvlx128) v30, v0, v24
	tmp.u32 = ctx.r[24].u32;
	// load shuffled into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8280E2D8: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 8280E2DC: 3B4BE9A0  addi r26, r11, -0x1660
	ctx.r[26].s64 = ctx.r[11].s64 + -5728;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E410(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E410 size=12
    let mut pc: u32 = 0x8280E410;
    'dispatch: loop {
        match pc {
            0x8280E410 => {
    //   block [0x8280E410..0x8280E41C)
	// 8280E410: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E414: 386B88CC  addi r3, r11, -0x7734
	ctx.r[3].s64 = ctx.r[11].s64 + -30516;
	// 8280E418: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E420(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E420 size=8
    let mut pc: u32 = 0x8280E420;
    'dispatch: loop {
        match pc {
            0x8280E420 => {
    //   block [0x8280E420..0x8280E428)
	// 8280E420: 80840018  lwz r4, 0x18(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280E424: 4BFEAFAC  b 0x827f93d0
	sub_827F93D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E428(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280E428 size=112
    let mut pc: u32 = 0x8280E428;
    'dispatch: loop {
        match pc {
            0x8280E428 => {
    //   block [0x8280E428..0x8280E498)
	// 8280E428: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E42C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E430: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E434: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E438: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 8280E43C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280E440: 3D208336  lis r9, -0x7cca
	ctx.r[9].s64 = -2093613056;
	// 8280E444: 816AAE0C  lwz r11, -0x51f4(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20980 as u32) ) } as u64;
	// 8280E448: 556807FF  clrlwi. r8, r11, 0x1f
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8280E44C: 4082001C  bne 0x8280e468
	if !ctx.cr[0].eq {
	pc = 0x8280E468; continue 'dispatch;
	}
	// 8280E450: 3D008335  lis r8, -0x7ccb
	ctx.r[8].s64 = -2093678592;
	// 8280E454: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8280E458: 916AAE0C  stw r11, -0x51f4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-20980 as u32), ctx.r[11].u32 ) };
	// 8280E45C: 8088681C  lwz r4, 0x681c(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(26652 as u32) ) } as u64;
	// 8280E460: 9089AE08  stw r4, -0x51f8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-20984 as u32), ctx.r[4].u32 ) };
	// 8280E464: 48000008  b 0x8280e46c
	pc = 0x8280E46C; continue 'dispatch;
	// 8280E468: 8089AE08  lwz r4, -0x51f8(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-20984 as u32) ) } as u64;
	// 8280E46C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E470: 4BC80F31  bl 0x8248f3a0
	ctx.lr = 0x8280E474;
	sub_8248F3A0(ctx, base);
	// 8280E474: 3D608202  lis r11, -0x7dfe
	ctx.r[11].s64 = -2113798144;
	// 8280E478: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E47C: C02B66D4  lfs f1, 0x66d4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26324 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280E480: 4BADEF91  bl 0x822ed410
	ctx.lr = 0x8280E484;
	sub_822ED410(ctx, base);
	// 8280E484: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280E488: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E48C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E490: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E494: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E498(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E498 size=20
    let mut pc: u32 = 0x8280E498;
    'dispatch: loop {
        match pc {
            0x8280E498 => {
    //   block [0x8280E498..0x8280E4AC)
	// 8280E498: 89640018  lbz r11, 0x18(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280E49C: 99630138  stb r11, 0x138(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(312 as u32), ctx.r[11].u8 ) };
	// 8280E4A0: 89640018  lbz r11, 0x18(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280E4A4: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E4A8: 4D820020  beqlr
	if ctx.cr[0].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E4AC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E4AC size=12
    let mut pc: u32 = 0x8280E4AC;
    'dispatch: loop {
        match pc {
            0x8280E4AC => {
    //   block [0x8280E4AC..0x8280E4B8)
	// 8280E4AC: 80630130  lwz r3, 0x130(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280E4B0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E4B4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E4B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E4B8 size=8
    let mut pc: u32 = 0x8280E4B8;
    'dispatch: loop {
        match pc {
            0x8280E4B8 => {
    //   block [0x8280E4B8..0x8280E4C0)
	// 8280E4B8: 48151098  b 0x8295f550
	sub_8295F550(ctx, base);
	return;
	// 8280E4BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E4C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8280E4C0 size=12
    let mut pc: u32 = 0x8280E4C0;
    'dispatch: loop {
        match pc {
            0x8280E4C0 => {
    //   block [0x8280E4C0..0x8280E4CC)
	// 8280E4C0: C024001C  lfs f1, 0x1c(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280E4C4: 80630120  lwz r3, 0x120(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280E4C8: 4BFDBEA0  b 0x827ea368
	sub_827EA368(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E4D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E4D0 size=196
    let mut pc: u32 = 0x8280E4D0;
    'dispatch: loop {
        match pc {
            0x8280E4D0 => {
    //   block [0x8280E4D0..0x8280E594)
	// 8280E4D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E4D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E4D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280E4DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E4E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E4E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280E4E8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280E4EC: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 8280E4F0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280E4F4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280E4F8: 4BAB2441  bl 0x822c0938
	ctx.lr = 0x8280E4FC;
	sub_822C0938(ctx, base);
	// 8280E4FC: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E500: 41820028  beq 0x8280e528
	if ctx.cr[0].eq {
	pc = 0x8280E528; continue 'dispatch;
	}
	// 8280E504: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E508: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 8280E50C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E510: 392B88D8  addi r9, r11, -0x7728
	ctx.r[9].s64 = ctx.r[11].s64 + -30504;
	// 8280E514: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8280E518: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280E51C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8280E520: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8280E524: 48000008  b 0x8280e52c
	pc = 0x8280E52C; continue 'dispatch;
	// 8280E528: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280E52C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280E530: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E534: 409A0044  bne cr6, 0x8280e578
	if !ctx.cr[6].eq {
	pc = 0x8280E578; continue 'dispatch;
	}
	// 8280E538: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280E53C: 419A001C  beq cr6, 0x8280e558
	if ctx.cr[6].eq {
	pc = 0x8280E558; continue 'dispatch;
	}
	// 8280E540: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E544: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8280E548: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E54C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E550: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280E554: 4E800421  bctrl
	ctx.lr = 0x8280E558;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280E558: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280E55C: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280E560: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E564: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 8280E568: 816BED00  lwz r11, -0x1300(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4864 as u32) ) } as u64;
	// 8280E56C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 8280E570: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8280E574: 4BAB1A8D  bl 0x822c0000
	ctx.lr = 0x8280E578;
	sub_822C0000(ctx, base);
	// 8280E578: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280E57C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280E580: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E584: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E588: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280E58C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E590: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E598 size=120
    let mut pc: u32 = 0x8280E598;
    'dispatch: loop {
        match pc {
            0x8280E598 => {
    //   block [0x8280E598..0x8280E610)
	// 8280E598: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E59C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E5A0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E5A4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E5A8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E5AC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E5B0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280E5B4: 396B8904  addi r11, r11, -0x76fc
	ctx.r[11].s64 = ctx.r[11].s64 + -30460;
	// 8280E5B8: 394A88EC  addi r10, r10, -0x7714
	ctx.r[10].s64 = ctx.r[10].s64 + -30484;
	// 8280E5BC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280E5C0: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280E5C4: 807F0134  lwz r3, 0x134(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(308 as u32) ) } as u64;
	// 8280E5C8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E5CC: 419A0008  beq cr6, 0x8280e5d4
	if ctx.cr[6].eq {
	pc = 0x8280E5D4; continue 'dispatch;
	}
	// 8280E5D0: 4BAB22C1  bl 0x822c0890
	ctx.lr = 0x8280E5D4;
	sub_822C0890(ctx, base);
	// 8280E5D4: 807F012C  lwz r3, 0x12c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(300 as u32) ) } as u64;
	// 8280E5D8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E5DC: 419A0008  beq cr6, 0x8280e5e4
	if ctx.cr[6].eq {
	pc = 0x8280E5E4; continue 'dispatch;
	}
	// 8280E5E0: 4BAB22B1  bl 0x822c0890
	ctx.lr = 0x8280E5E4;
	sub_822C0890(ctx, base);
	// 8280E5E4: 807F0124  lwz r3, 0x124(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 8280E5E8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E5EC: 419A0008  beq cr6, 0x8280e5f4
	if ctx.cr[6].eq {
	pc = 0x8280E5F4; continue 'dispatch;
	}
	// 8280E5F0: 4BAB22A1  bl 0x822c0890
	ctx.lr = 0x8280E5F4;
	sub_822C0890(ctx, base);
	// 8280E5F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E5F8: 4BFEB561  bl 0x827f9b58
	ctx.lr = 0x8280E5FC;
	sub_827F9B58(ctx, base);
	// 8280E5FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8280E600: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E604: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E608: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E60C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8280E610 size=8
    let mut pc: u32 = 0x8280E610;
    'dispatch: loop {
        match pc {
            0x8280E610 => {
    //   block [0x8280E610..0x8280E618)
	// 8280E610: 3863FFD8  addi r3, r3, -0x28
	ctx.r[3].s64 = ctx.r[3].s64 + -40;
	// 8280E614: 4800029C  b 0x8280e8b0
	sub_8280E8B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E618 size=208
    let mut pc: u32 = 0x8280E618;
    'dispatch: loop {
        match pc {
            0x8280E618 => {
    //   block [0x8280E618..0x8280E6E8)
	// 8280E618: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E61C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E620: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280E624: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E628: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E62C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E630: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280E634: 4BFEADB5  bl 0x827f93e8
	ctx.lr = 0x8280E638;
	sub_827F93E8(ctx, base);
	// 8280E638: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E63C: 807F0120  lwz r3, 0x120(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280E640: 4BFDBB51  bl 0x827ea190
	ctx.lr = 0x8280E644;
	sub_827EA190(ctx, base);
	// 8280E644: 897F0138  lbz r11, 0x138(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280E648: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E64C: 41820084  beq 0x8280e6d0
	if ctx.cr[0].eq {
	pc = 0x8280E6D0; continue 'dispatch;
	}
	// 8280E650: 817F0130  lwz r11, 0x130(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280E654: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E658: 419A0078  beq cr6, 0x8280e6d0
	if ctx.cr[6].eq {
	pc = 0x8280E6D0; continue 'dispatch;
	}
	// 8280E65C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E660: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E664: 388B88CC  addi r4, r11, -0x7734
	ctx.r[4].s64 = ctx.r[11].s64 + -30516;
	// 8280E668: 485E53A1  bl 0x82df3a08
	ctx.lr = 0x8280E66C;
	sub_82DF3A08(ctx, base);
	// 8280E66C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E670: 4BFEACE1  bl 0x827f9350
	ctx.lr = 0x8280E674;
	sub_827F9350(ctx, base);
	// 8280E674: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280E678: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280E67C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280E680: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E684: 486069AD  bl 0x82e15030
	ctx.lr = 0x8280E688;
	sub_82E15030(ctx, base);
	// 8280E688: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E68C: 485E4D9D  bl 0x82df3428
	ctx.lr = 0x8280E690;
	sub_82DF3428(ctx, base);
	// 8280E690: 80610058  lwz r3, 0x58(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280E694: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 8280E698: 3BCB6910  addi r30, r11, 0x6910
	ctx.r[30].s64 = ctx.r[11].s64 + 26896;
	// 8280E69C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E6A0: 83FF0130  lwz r31, 0x130(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280E6A4: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8280E6A8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280E6AC: 4E800421  bctrl
	ctx.lr = 0x8280E6B0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280E6B0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E6B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E6B8: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8280E6BC: 48151165  bl 0x8295f820
	ctx.lr = 0x8280E6C0;
	sub_8295F820(ctx, base);
	// 8280E6C0: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280E6C4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E6C8: 419A0008  beq cr6, 0x8280e6d0
	if ctx.cr[6].eq {
	pc = 0x8280E6D0; continue 'dispatch;
	}
	// 8280E6CC: 4BAB21C5  bl 0x822c0890
	ctx.lr = 0x8280E6D0;
	sub_822C0890(ctx, base);
	// 8280E6D0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280E6D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E6D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E6DC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280E6E0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E6E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E6E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280E6E8 size=336
    let mut pc: u32 = 0x8280E6E8;
    'dispatch: loop {
        match pc {
            0x8280E6E8 => {
    //   block [0x8280E6E8..0x8280E838)
	// 8280E6E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E6EC: 48999A7D  bl 0x831a8168
	ctx.lr = 0x8280E6F0;
	sub_831A8130(ctx, base);
	// 8280E6F0: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E6F4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E6F8: 807F00E4  lwz r3, 0xe4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(228 as u32) ) } as u64;
	// 8280E6FC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E700: 419A0130  beq cr6, 0x8280e830
	if ctx.cr[6].eq {
	pc = 0x8280E830; continue 'dispatch;
	}
	// 8280E704: 89640018  lbz r11, 0x18(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280E708: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E70C: 8164001C  lwz r11, 0x1c(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) } as u64;
	// 8280E710: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E714: 418200CC  beq 0x8280e7e0
	if ctx.cr[0].eq {
	pc = 0x8280E7E0; continue 'dispatch;
	}
	// 8280E718: 409A0010  bne cr6, 0x8280e728
	if !ctx.cr[6].eq {
	pc = 0x8280E728; continue 'dispatch;
	}
	// 8280E71C: 809F014C  lwz r4, 0x14c(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(332 as u32) ) } as u64;
	// 8280E720: 4BFC0F59  bl 0x827cf678
	ctx.lr = 0x8280E724;
	sub_827CF678(ctx, base);
	// 8280E724: 4800010C  b 0x8280e830
	pc = 0x8280E830; continue 'dispatch;
	// 8280E728: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8280E72C: 409A0104  bne cr6, 0x8280e830
	if !ctx.cr[6].eq {
	pc = 0x8280E830; continue 'dispatch;
	}
	// 8280E730: 817F0148  lwz r11, 0x148(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 8280E734: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 8280E738: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280E73C: 394AECD8  addi r10, r10, -0x1328
	ctx.r[10].s64 = ctx.r[10].s64 + -4904;
	// 8280E740: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8280E744: 7C8B502E  lwzx r4, r11, r10
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 8280E748: 485E52C1  bl 0x82df3a08
	ctx.lr = 0x8280E74C;
	sub_82DF3A08(ctx, base);
	// 8280E74C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E750: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E754: 388B895C  addi r4, r11, -0x76a4
	ctx.r[4].s64 = ctx.r[11].s64 + -30372;
	// 8280E758: 485E52B1  bl 0x82df3a08
	ctx.lr = 0x8280E75C;
	sub_82DF3A08(ctx, base);
	// 8280E75C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E760: 4BFEABF1  bl 0x827f9350
	ctx.lr = 0x8280E764;
	sub_827F9350(ctx, base);
	// 8280E764: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8280E768: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280E76C: 83DF00E4  lwz r30, 0xe4(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(228 as u32) ) } as u64;
	// 8280E770: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280E774: 3BA10054  addi r29, r1, 0x54
	ctx.r[29].s64 = ctx.r[1].s64 + 84;
	// 8280E778: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E77C: 486068B5  bl 0x82e15030
	ctx.lr = 0x8280E780;
	sub_82E15030(ctx, base);
	// 8280E780: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8280E784: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280E788: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 8280E78C: 4BD00D3D  bl 0x8250f4c8
	ctx.lr = 0x8280E790;
	sub_8250F4C8(ctx, base);
	// 8280E790: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8280E794: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280E798: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280E79C: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8280E7A0: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280E7A4: 39000007  li r8, 7
	ctx.r[8].s64 = 7;
	// 8280E7A8: C02B08A8  lfs f1, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280E7AC: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8280E7B0: 4BFC1B89  bl 0x827d0338
	ctx.lr = 0x8280E7B4;
	sub_827D0338(ctx, base);
	// 8280E7B4: 8161005C  lwz r11, 0x5c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280E7B8: 907F0150  stw r3, 0x150(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(336 as u32), ctx.r[3].u32 ) };
	// 8280E7BC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E7C0: 419A000C  beq cr6, 0x8280e7cc
	if ctx.cr[6].eq {
	pc = 0x8280E7CC; continue 'dispatch;
	}
	// 8280E7C4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8280E7C8: 4BAB20C9  bl 0x822c0890
	ctx.lr = 0x8280E7CC;
	sub_822C0890(ctx, base);
	// 8280E7CC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E7D0: 485E4C59  bl 0x82df3428
	ctx.lr = 0x8280E7D4;
	sub_82DF3428(ctx, base);
	// 8280E7D4: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280E7D8: 485E4C51  bl 0x82df3428
	ctx.lr = 0x8280E7DC;
	sub_82DF3428(ctx, base);
	// 8280E7DC: 48000054  b 0x8280e830
	pc = 0x8280E830; continue 'dispatch;
	// 8280E7E0: 409A0014  bne cr6, 0x8280e7f4
	if !ctx.cr[6].eq {
	pc = 0x8280E7F4; continue 'dispatch;
	}
	// 8280E7E4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8280E7E8: 809F014C  lwz r4, 0x14c(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(332 as u32) ) } as u64;
	// 8280E7EC: 4BFC0E25  bl 0x827cf610
	ctx.lr = 0x8280E7F0;
	sub_827CF610(ctx, base);
	// 8280E7F0: 48000040  b 0x8280e830
	pc = 0x8280E830; continue 'dispatch;
	// 8280E7F4: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8280E7F8: 409A0038  bne cr6, 0x8280e830
	if !ctx.cr[6].eq {
	pc = 0x8280E830; continue 'dispatch;
	}
	// 8280E7FC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280E800: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280E804: 4BD00CC5  bl 0x8250f4c8
	ctx.lr = 0x8280E808;
	sub_8250F4C8(ctx, base);
	// 8280E808: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280E80C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E810: 388BFFFC  addi r4, r11, -4
	ctx.r[4].s64 = ctx.r[11].s64 + -4;
	// 8280E814: 409A0008  bne cr6, 0x8280e81c
	if !ctx.cr[6].eq {
	pc = 0x8280E81C; continue 'dispatch;
	}
	// 8280E818: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8280E81C: 80BF0150  lwz r5, 0x150(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(336 as u32) ) } as u64;
	// 8280E820: 807F00E4  lwz r3, 0xe4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(228 as u32) ) } as u64;
	// 8280E824: 4BFC157D  bl 0x827cfda0
	ctx.lr = 0x8280E828;
	sub_827CFDA0(ctx, base);
	// 8280E828: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280E82C: 485E3465  bl 0x82df1c90
	ctx.lr = 0x8280E830;
	sub_82DF1C90(ctx, base);
	// 8280E830: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8280E834: 48999984  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E838 size=116
    let mut pc: u32 = 0x8280E838;
    'dispatch: loop {
        match pc {
            0x8280E838 => {
    //   block [0x8280E838..0x8280E8AC)
	// 8280E838: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E83C: 48999931  bl 0x831a816c
	ctx.lr = 0x8280E840;
	sub_831A8130(ctx, base);
	// 8280E840: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E844: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E848: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280E84C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8280E850: 4BFEB3C9  bl 0x827f9c18
	ctx.lr = 0x8280E854;
	sub_827F9C18(ctx, base);
	// 8280E854: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E858: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280E85C: 392B8904  addi r9, r11, -0x76fc
	ctx.r[9].s64 = ctx.r[11].s64 + -30460;
	// 8280E860: 394A88EC  addi r10, r10, -0x7714
	ctx.r[10].s64 = ctx.r[10].s64 + -30484;
	// 8280E864: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280E868: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8280E86C: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8280E870: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8280E874: 917F0120  stw r11, 0x120(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 8280E878: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E87C: 917F0124  stw r11, 0x124(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[11].u32 ) };
	// 8280E880: 917F0128  stw r11, 0x128(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), ctx.r[11].u32 ) };
	// 8280E884: 917F012C  stw r11, 0x12c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), ctx.r[11].u32 ) };
	// 8280E888: 917F0130  stw r11, 0x130(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), ctx.r[11].u32 ) };
	// 8280E88C: 917F0134  stw r11, 0x134(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(308 as u32), ctx.r[11].u32 ) };
	// 8280E890: 997F0138  stb r11, 0x138(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(312 as u32), ctx.r[11].u8 ) };
	// 8280E894: 93DF013C  stw r30, 0x13c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(316 as u32), ctx.r[30].u32 ) };
	// 8280E898: 915F0140  stw r10, 0x140(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(320 as u32), ctx.r[10].u32 ) };
	// 8280E89C: 915F0144  stw r10, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[10].u32 ) };
	// 8280E8A0: 93BF0148  stw r29, 0x148(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), ctx.r[29].u32 ) };
	// 8280E8A4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280E8A8: 48999914  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E8B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E8B0 size=76
    let mut pc: u32 = 0x8280E8B0;
    'dispatch: loop {
        match pc {
            0x8280E8B0 => {
    //   block [0x8280E8B0..0x8280E8FC)
	// 8280E8B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E8B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E8B8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280E8BC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E8C0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E8C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E8C8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280E8CC: 4BFFFCCD  bl 0x8280e598
	ctx.lr = 0x8280E8D0;
	sub_8280E598(ctx, base);
	// 8280E8D0: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8280E8D4: 4182000C  beq 0x8280e8e0
	if ctx.cr[0].eq {
	pc = 0x8280E8E0; continue 'dispatch;
	}
	// 8280E8D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E8DC: 485E3AFD  bl 0x82df23d8
	ctx.lr = 0x8280E8E0;
	sub_82DF23D8(ctx, base);
	// 8280E8E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E8E4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280E8E8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E8EC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E8F0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280E8F4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E8F8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E900(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E900 size=96
    let mut pc: u32 = 0x8280E900;
    'dispatch: loop {
        match pc {
            0x8280E900 => {
    //   block [0x8280E900..0x8280E960)
	// 8280E900: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E904: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280E908: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280E90C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280E910: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E914: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E918: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8280E91C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280E920: 397F0130  addi r11, r31, 0x130
	ctx.r[11].s64 = ctx.r[31].s64 + 304;
	// 8280E924: 915F0130  stw r10, 0x130(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), ctx.r[10].u32 ) };
	// 8280E928: 807F0134  lwz r3, 0x134(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(308 as u32) ) } as u64;
	// 8280E92C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280E930: 915F0134  stw r10, 0x134(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(308 as u32), ctx.r[10].u32 ) };
	// 8280E934: 419A0008  beq cr6, 0x8280e93c
	if ctx.cr[6].eq {
	pc = 0x8280E93C; continue 'dispatch;
	}
	// 8280E938: 4BAB1F59  bl 0x822c0890
	ctx.lr = 0x8280E93C;
	sub_822C0890(ctx, base);
	// 8280E93C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8280E940: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280E944: 4BFF59E5  bl 0x82804328
	ctx.lr = 0x8280E948;
	sub_82804328(ctx, base);
	// 8280E948: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8280E94C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280E950: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280E954: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8280E958: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280E95C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280E960(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280E960 size=240
    let mut pc: u32 = 0x8280E960;
    'dispatch: loop {
        match pc {
            0x8280E960 => {
    //   block [0x8280E960..0x8280EA50)
	// 8280E960: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280E964: 48999809  bl 0x831a816c
	ctx.lr = 0x8280E968;
	sub_831A8130(ctx, base);
	// 8280E968: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280E96C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280E970: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280E974: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8280E978: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280E97C: 4861C16D  bl 0x82e2aae8
	ctx.lr = 0x8280E980;
	sub_82E2AAE8(ctx, base);
	// 8280E980: 815F0148  lwz r10, 0x148(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 8280E984: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280E988: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8280E98C: 396BED6C  addi r11, r11, -0x1294
	ctx.r[11].s64 = ctx.r[11].s64 + -4756;
	// 8280E990: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E994: 7C8A582E  lwzx r4, r10, r11
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8280E998: 485E5071  bl 0x82df3a08
	ctx.lr = 0x8280E99C;
	sub_82DF3A08(ctx, base);
	// 8280E99C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E9A0: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280E9A4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280E9A8: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280E9AC: 486204C5  bl 0x82e2ee70
	ctx.lr = 0x8280E9B0;
	sub_82E2EE70(ctx, base);
	// 8280E9B0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280E9B4: 485E4A75  bl 0x82df3428
	ctx.lr = 0x8280E9B8;
	sub_82DF3428(ctx, base);
	// 8280E9B8: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280E9BC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280E9C0: 419A0060  beq cr6, 0x8280ea20
	if ctx.cr[6].eq {
	pc = 0x8280EA20; continue 'dispatch;
	}
	// 8280E9C4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280E9C8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280E9CC: 388B8968  addi r4, r11, -0x7698
	ctx.r[4].s64 = ctx.r[11].s64 + -30360;
	// 8280E9D0: 38A000FF  li r5, 0xff
	ctx.r[5].s64 = 255;
	// 8280E9D4: 38600098  li r3, 0x98
	ctx.r[3].s64 = 152;
	// 8280E9D8: 485E3A11  bl 0x82df23e8
	ctx.lr = 0x8280E9DC;
	sub_82DF23E8(ctx, base);
	// 8280E9DC: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280E9E0: 41820014  beq 0x8280e9f4
	if ctx.cr[0].eq {
	pc = 0x8280E9F4; continue 'dispatch;
	}
	// 8280E9E4: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 8280E9E8: 48607EA9  bl 0x82e16890
	ctx.lr = 0x8280E9EC;
	sub_82E16890(ctx, base);
	// 8280E9EC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280E9F0: 48000008  b 0x8280e9f8
	pc = 0x8280E9F8; continue 'dispatch;
	// 8280E9F4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280E9F8: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280E9FC: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 8280EA00: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EA04: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EA08: 4BB4A6B1  bl 0x823590b8
	ctx.lr = 0x8280EA0C;
	sub_823590B8(ctx, base);
	// 8280EA0C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280EA10: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EA14: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EA18: 4BAB15E9  bl 0x822c0000
	ctx.lr = 0x8280EA1C;
	sub_822C0000(ctx, base);
	// 8280EA1C: 48000010  b 0x8280ea2c
	pc = 0x8280EA2C; continue 'dispatch;
	// 8280EA20: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280EA24: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280EA28: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280EA2C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280EA30: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280EA34: 419A0008  beq cr6, 0x8280ea3c
	if ctx.cr[6].eq {
	pc = 0x8280EA3C; continue 'dispatch;
	}
	// 8280EA38: 4BAB1E59  bl 0x822c0890
	ctx.lr = 0x8280EA3C;
	sub_822C0890(ctx, base);
	// 8280EA3C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280EA40: 4861C0C1  bl 0x82e2ab00
	ctx.lr = 0x8280EA44;
	sub_82E2AB00(ctx, base);
	// 8280EA44: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8280EA48: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280EA4C: 48999770  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280EA50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280EA50 size=216
    let mut pc: u32 = 0x8280EA50;
    'dispatch: loop {
        match pc {
            0x8280EA50 => {
    //   block [0x8280EA50..0x8280EB28)
	// 8280EA50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280EA54: 48999719  bl 0x831a816c
	ctx.lr = 0x8280EA58;
	sub_831A8130(ctx, base);
	// 8280EA58: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280EA5C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8280EA60: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280EA64: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8280EA68: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280EA6C: 4BAD879D  bl 0x822e7208
	ctx.lr = 0x8280EA70;
	sub_822E7208(ctx, base);
	// 8280EA70: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280EA74: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280EA78: 388B87A8  addi r4, r11, -0x7858
	ctx.r[4].s64 = ctx.r[11].s64 + -30808;
	// 8280EA7C: 485E4F8D  bl 0x82df3a08
	ctx.lr = 0x8280EA80;
	sub_82DF3A08(ctx, base);
	// 8280EA80: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280EA84: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280EA88: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280EA8C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280EA90: 4BAD8901  bl 0x822e7390
	ctx.lr = 0x8280EA94;
	sub_822E7390(ctx, base);
	// 8280EA94: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280EA98: 485E4991  bl 0x82df3428
	ctx.lr = 0x8280EA9C;
	sub_82DF3428(ctx, base);
	// 8280EA9C: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280EAA0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8280EAA4: 419A0054  beq cr6, 0x8280eaf8
	if ctx.cr[6].eq {
	pc = 0x8280EAF8; continue 'dispatch;
	}
	// 8280EAA8: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8280EAAC: 3BBF0028  addi r29, r31, 0x28
	ctx.r[29].s64 = ctx.r[31].s64 + 40;
	// 8280EAB0: 409A0008  bne cr6, 0x8280eab8
	if !ctx.cr[6].eq {
	pc = 0x8280EAB8; continue 'dispatch;
	}
	// 8280EAB4: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8280EAB8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8280EABC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8280EAC0: 816B0048  lwz r11, 0x48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 8280EAC4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8280EAC8: 4E800421  bctrl
	ctx.lr = 0x8280EACC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8280EACC: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280EAD0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280EAD4: 485E4F35  bl 0x82df3a08
	ctx.lr = 0x8280EAD8;
	sub_82DF3A08(ctx, base);
	// 8280EAD8: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280EADC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8280EAE0: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8280EAE4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EAE8: 4BADFBF1  bl 0x822ee6d8
	ctx.lr = 0x8280EAEC;
	sub_822EE6D8(ctx, base);
	// 8280EAEC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8280EAF0: 485E4939  bl 0x82df3428
	ctx.lr = 0x8280EAF4;
	sub_82DF3428(ctx, base);
	// 8280EAF4: 48000010  b 0x8280eb04
	pc = 0x8280EB04; continue 'dispatch;
	// 8280EAF8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8280EAFC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8280EB00: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8280EB04: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280EB08: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280EB0C: 419A0008  beq cr6, 0x8280eb14
	if ctx.cr[6].eq {
	pc = 0x8280EB14; continue 'dispatch;
	}
	// 8280EB10: 4BAB1D81  bl 0x822c0890
	ctx.lr = 0x8280EB14;
	sub_822C0890(ctx, base);
	// 8280EB14: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280EB18: 4BAD8709  bl 0x822e7220
	ctx.lr = 0x8280EB1C;
	sub_822E7220(ctx, base);
	// 8280EB1C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EB20: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8280EB24: 48999698  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280EB28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280EB28 size=136
    let mut pc: u32 = 0x8280EB28;
    'dispatch: loop {
        match pc {
            0x8280EB28 => {
    //   block [0x8280EB28..0x8280EBB0)
	// 8280EB28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280EB2C: 4899963D  bl 0x831a8168
	ctx.lr = 0x8280EB30;
	sub_831A8130(ctx, base);
	// 8280EB30: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280EB34: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280EB38: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8280EB3C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8280EB40: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8280EB44: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8280EB48: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280EB4C: 388B8968  addi r4, r11, -0x7698
	ctx.r[4].s64 = ctx.r[11].s64 + -30360;
	// 8280EB50: 38A00059  li r5, 0x59
	ctx.r[5].s64 = 89;
	// 8280EB54: 38600154  li r3, 0x154
	ctx.r[3].s64 = 340;
	// 8280EB58: 485E3891  bl 0x82df23e8
	ctx.lr = 0x8280EB5C;
	sub_82DF23E8(ctx, base);
	// 8280EB5C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280EB60: 4182001C  beq 0x8280eb7c
	if ctx.cr[0].eq {
	pc = 0x8280EB7C; continue 'dispatch;
	}
	// 8280EB64: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 8280EB68: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8280EB6C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EB70: 4BFFFCC9  bl 0x8280e838
	ctx.lr = 0x8280EB74;
	sub_8280E838(ctx, base);
	// 8280EB74: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280EB78: 48000008  b 0x8280eb80
	pc = 0x8280EB80; continue 'dispatch;
	// 8280EB7C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280EB80: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8280EB84: 3BDC0004  addi r30, r28, 4
	ctx.r[30].s64 = ctx.r[28].s64 + 4;
	// 8280EB88: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EB8C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EB90: 4BFFF941  bl 0x8280e4d0
	ctx.lr = 0x8280EB94;
	sub_8280E4D0(ctx, base);
	// 8280EB94: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8280EB98: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EB9C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EBA0: 4BAB1461  bl 0x822c0000
	ctx.lr = 0x8280EBA4;
	sub_822C0000(ctx, base);
	// 8280EBA4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8280EBA8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280EBAC: 4899960C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280EBB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280EBB0 size=388
    let mut pc: u32 = 0x8280EBB0;
    'dispatch: loop {
        match pc {
            0x8280EBB0 => {
    //   block [0x8280EBB0..0x8280ED34)
	// 8280EBB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280EBB4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280EBB8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8280EBBC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280EBC0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280EBC4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280EBC8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8280EBCC: 897F0138  lbz r11, 0x138(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(312 as u32) ) } as u64;
	// 8280EBD0: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280EBD4: 41820148  beq 0x8280ed1c
	if ctx.cr[0].eq {
	pc = 0x8280ED1C; continue 'dispatch;
	}
	// 8280EBD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8280EBDC: 487F954D  bl 0x83008128
	ctx.lr = 0x8280EBE0;
	sub_83008128(ctx, base);
	// 8280EBE0: 817F013C  lwz r11, 0x13c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(316 as u32) ) } as u64;
	// 8280EBE4: 7F035840  cmplw cr6, r3, r11
	ctx.cr[6].compare_u32(ctx.r[3].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8280EBE8: 419A0134  beq cr6, 0x8280ed1c
	if ctx.cr[6].eq {
	pc = 0x8280ED1C; continue 'dispatch;
	}
	// 8280EBEC: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 8280EBF0: 895E001C  lbz r10, 0x1c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 8280EBF4: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 8280EBF8: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 8280EBFC: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280EC00: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280ED38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8280ED38 size=180
    let mut pc: u32 = 0x8280ED38;
    'dispatch: loop {
        match pc {
            0x8280ED38 => {
    //   block [0x8280ED38..0x8280EDEC)
	// 8280ED38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280ED3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8280ED40: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8280ED44: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280ED48: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8280ED4C: 81640018  lwz r11, 0x18(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8280ED50: 38BF0140  addi r5, r31, 0x140
	ctx.r[5].s64 = ctx.r[31].s64 + 320;
	// 8280ED54: 38DF0144  addi r6, r31, 0x144
	ctx.r[6].s64 = ctx.r[31].s64 + 324;
	// 8280ED58: 815F0130  lwz r10, 0x130(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280ED5C: 917F0140  stw r11, 0x140(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(320 as u32), ctx.r[11].u32 ) };
	// 8280ED60: 8164001C  lwz r11, 0x1c(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) } as u64;
	// 8280ED64: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8280ED68: 917F0144  stw r11, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[11].u32 ) };
	// 8280ED6C: 419A006C  beq cr6, 0x8280edd8
	if ctx.cr[6].eq {
	pc = 0x8280EDD8; continue 'dispatch;
	}
	// 8280ED70: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 8280ED74: 3D408338  lis r10, -0x7cc8
	ctx.r[10].s64 = -2093481984;
	// 8280ED78: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8280ED7C: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 8280ED80: 38EA6910  addi r7, r10, 0x6910
	ctx.r[7].s64 = ctx.r[10].s64 + 26896;
	// 8280ED84: 388B85E4  addi r4, r11, -0x7a1c
	ctx.r[4].s64 = ctx.r[11].s64 + -31260;
	// 8280ED88: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 8280ED8C: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 8280ED90: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280ED94: 48093AFD  bl 0x828a2890
	ctx.lr = 0x8280ED98;
	sub_828A2890(ctx, base);
	// 8280ED98: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8280ED9C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8280EDA0: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8280EDA4: 808B681C  lwz r4, 0x681c(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26652 as u32) ) } as u64;
	// 8280EDA8: 481506C1  bl 0x8295f468
	ctx.lr = 0x8280EDAC;
	sub_8295F468(ctx, base);
	// 8280EDAC: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8280EDB0: 807F0130  lwz r3, 0x130(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 8280EDB4: 481506F5  bl 0x8295f4a8
	ctx.lr = 0x8280EDB8;
	sub_8295F4A8(ctx, base);
	// 8280EDB8: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8280EDBC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280EDC0: 419A0008  beq cr6, 0x8280edc8
	if ctx.cr[6].eq {
	pc = 0x8280EDC8; continue 'dispatch;
	}
	// 8280EDC4: 4BAB1ACD  bl 0x822c0890
	ctx.lr = 0x8280EDC8;
	sub_822C0890(ctx, base);
	// 8280EDC8: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8280EDCC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8280EDD0: 419A0008  beq cr6, 0x8280edd8
	if ctx.cr[6].eq {
	pc = 0x8280EDD8; continue 'dispatch;
	}
	// 8280EDD4: 4BAB1ABD  bl 0x822c0890
	ctx.lr = 0x8280EDD8;
	sub_822C0890(ctx, base);
	// 8280EDD8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8280EDDC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8280EDE0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8280EDE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8280EDE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8280EDF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8280EDF0 size=5064
    let mut pc: u32 = 0x8280EDF0;
    'dispatch: loop {
        match pc {
            0x8280EDF0 => {
    //   block [0x8280EDF0..0x828101B8)
	// 8280EDF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8280EDF4: 48999365  bl 0x831a8158
	ctx.lr = 0x8280EDF8;
	sub_831A8130(ctx, base);
	// 8280EDF8: DBC1FFA8  stfd f30, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[30].u64 ) };
	// 8280EDFC: DBE1FFB0  stfd f31, -0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), ctx.f[31].u64 ) };
	// 8280EE00: 9421F160  stwu r1, -0xea0(r1)
	ea = ctx.r[1].u32.wrapping_add(-3744 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8280EE04: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280EE08: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8280EE0C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8280EE10: 388B8968  addi r4, r11, -0x7698
	ctx.r[4].s64 = ctx.r[11].s64 + -30360;
	// 8280EE14: 38A00188  li r5, 0x188
	ctx.r[5].s64 = 392;
	// 8280EE18: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 8280EE1C: 4BAB15BD  bl 0x822c03d8
	ctx.lr = 0x8280EE20;
	sub_822C03D8(ctx, base);
	// 8280EE20: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8280EE24: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8280EE28: 41820010  beq 0x8280ee38
	if ctx.cr[0].eq {
	pc = 0x8280EE38; continue 'dispatch;
	}
	// 8280EE2C: 4BFDBE85  bl 0x827eacb0
	ctx.lr = 0x8280EE30;
	sub_827EACB0(ctx, base);
	// 8280EE30: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280EE34: 48000008  b 0x8280ee3c
	pc = 0x8280EE3C; continue 'dispatch;
	// 8280EE38: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8280EE3C: 387D0120  addi r3, r29, 0x120
	ctx.r[3].s64 = ctx.r[29].s64 + 288;
	// 8280EE40: 4BFEC511  bl 0x827fb350
	ctx.lr = 0x8280EE44;
	sub_827FB350(ctx, base);
	// 8280EE44: 815D0148  lwz r10, 0x148(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(328 as u32) ) } as u64;
	// 8280EE48: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8280EE4C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8280EE50: 396BECEC  addi r11, r11, -0x1314
	ctx.r[11].s64 = ctx.r[11].s64 + -4884;
	// 8280EE54: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280EE58: 7C8A582E  lwzx r4, r10, r11
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8280EE5C: 485E4BAD  bl 0x82df3a08
	ctx.lr = 0x8280EE60;
	sub_82DF3A08(ctx, base);
	// 8280EE60: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8280EE64: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280EE68: 3BC10054  addi r30, r1, 0x54
	ctx.r[30].s64 = ctx.r[1].s64 + 84;
	// 8280EE6C: 839D0120  lwz r28, 0x120(r29)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 8280EE70: 4BD00659  bl 0x8250f4c8
	ctx.lr = 0x8280EE74;
	sub_8250F4C8(ctx, base);
	// 8280EE74: 3F608200  lis r27, -0x7e00
	ctx.r[27].s64 = -2113929216;
	// 8280EE78: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8280EE7C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8280EE80: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8280EE84: C03B08A8  lfs f1, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8280EE88: 4BFDBAE1  bl 0x827ea968
	ctx.lr = 0x8280EE8C;
	sub_827EA968(ctx, base);
	// 8280EE8C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8280EE90: 485E2E01  bl 0x82df1c90
	ctx.lr = 0x8280EE94;
	sub_82DF1C90(ctx, base);
	// 8280EE94: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8280EE98: 485E4591  bl 0x82df3428
	ctx.lr = 0x8280EE9C;
	sub_82DF3428(ctx, base);
	// 8280EE9C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280EEA0: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8280EEA4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280EEA8: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 8280EEAC: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 8280EEB0: 3D008208  lis r8, -0x7df8
	ctx.r[8].s64 = -2113404928;
	// 8280EEB4: 9BE1007C  stb r31, 0x7c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[31].u8 ) };
	// 8280EEB8: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 8280EEBC: 39088CA8  addi r8, r8, -0x7358
	ctx.r[8].s64 = ctx.r[8].s64 + -29528;
	// 8280EEC0: C3CA08A4  lfs f30, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8280EEC4: 93C1006C  stw r30, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[30].u32 ) };
	// 8280EEC8: C3E99534  lfs f31, -0x6acc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27340 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8280EECC: 91010064  stw r8, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[8].u32 ) };
	// 8280EED0: D3C10070  stfs f30, 0x70(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8280EED4: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 8280EED8: D3E10074  stfs f31, 0x74(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 8280EEDC: D3E10078  stfs f31, 0x78(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 8280EEE0: 816BA020  lwz r11, -0x5fe0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24544 as u32) ) } as u64;
	// 8280EEE4: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 8280EEE8: 485EF9E1  bl 0x82dfe8c8
	ctx.lr = 0x8280EEEC;
	sub_82DFE8C8(ctx, base);
	// 8280EEEC: 38610088  addi r3, r1, 0x88
	ctx.r[3].s64 = ctx.r[1].s64 + 136;
	// 8280EEF0: 485EF9D9  bl 0x82dfe8c8
	ctx.lr = 0x8280EEF4;
	sub_82DFE8C8(ctx, base);
	// 8280EEF4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280EEF8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280EEFC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280EF00: D0010098  stfs f0, 0x98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 8280EF04: 93C1009C  stw r30, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[30].u32 ) };
	// 8280EF08: 394A8C94  addi r10, r10, -0x736c
	ctx.r[10].s64 = ctx.r[10].s64 + -29548;
	// 8280EF0C: D3C100A0  stfs f30, 0xa0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 8280EF10: D3E100A4  stfs f31, 0xa4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 8280EF14: 9BE100AC  stb r31, 0xac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[31].u8 ) };
	// 8280EF18: D3E100A8  stfs f31, 0xa8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 8280EF1C: 91410094  stw r10, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[10].u32 ) };
	// 8280EF20: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 8280EF24: 816BA024  lwz r11, -0x5fdc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24540 as u32) ) } as u64;
	// 8280EF28: 91610090  stw r11, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 8280EF2C: 485EF99D  bl 0x82dfe8c8
	ctx.lr = 0x8280EF30;
	sub_82DFE8C8(ctx, base);
	// 8280EF30: 386100B8  addi r3, r1, 0xb8
	ctx.r[3].s64 = ctx.r[1].s64 + 184;
	// 8280EF34: 485EF995  bl 0x82dfe8c8
	ctx.lr = 0x8280EF38;
	sub_82DFE8C8(ctx, base);
	// 8280EF38: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280EF3C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280EF40: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280EF44: D00100C8  stfs f0, 0xc8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 8280EF48: 93C100CC  stw r30, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[30].u32 ) };
	// 8280EF4C: 3B8A8C80  addi r28, r10, -0x7380
	ctx.r[28].s64 = ctx.r[10].s64 + -29568;
	// 8280EF50: D3C100D0  stfs f30, 0xd0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 8280EF54: D3E100D4  stfs f31, 0xd4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 8280EF58: 9BE100DC  stb r31, 0xdc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[31].u8 ) };
	// 8280EF5C: D3E100D8  stfs f31, 0xd8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 8280EF60: 938100C4  stw r28, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[28].u32 ) };
	// 8280EF64: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 8280EF68: 816BA03C  lwz r11, -0x5fc4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24516 as u32) ) } as u64;
	// 8280EF6C: 916100C0  stw r11, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 8280EF70: 485EF959  bl 0x82dfe8c8
	ctx.lr = 0x8280EF74;
	sub_82DFE8C8(ctx, base);
	// 8280EF74: 386100E8  addi r3, r1, 0xe8
	ctx.r[3].s64 = ctx.r[1].s64 + 232;
	// 8280EF78: 485EF951  bl 0x82dfe8c8
	ctx.lr = 0x8280EF7C;
	sub_82DFE8C8(ctx, base);
	// 8280EF7C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280EF80: 816BA040  lwz r11, -0x5fc0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24512 as u32) ) } as u64;
	// 8280EF84: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280EF88: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280EF8C: 93C100FC  stw r30, 0xfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(252 as u32), ctx.r[30].u32 ) };
	// 8280EF90: 3B4A8C68  addi r26, r10, -0x7398
	ctx.r[26].s64 = ctx.r[10].s64 + -29592;
	// 8280EF94: D00100F8  stfs f0, 0xf8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), tmp.u32 ) };
	// 8280EF98: D3C10100  stfs f30, 0x100(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 8280EF9C: 9BE1010C  stb r31, 0x10c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(268 as u32), ctx.r[31].u8 ) };
	// 8280EFA0: D3E10104  stfs f31, 0x104(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 8280EFA4: 934100F4  stw r26, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[26].u32 ) };
	// 8280EFA8: D3E10108  stfs f31, 0x108(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 8280EFAC: 916100F0  stw r11, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[11].u32 ) };
	// 8280EFB0: 38610110  addi r3, r1, 0x110
	ctx.r[3].s64 = ctx.r[1].s64 + 272;
	// 8280EFB4: 485EF915  bl 0x82dfe8c8
	ctx.lr = 0x8280EFB8;
	sub_82DFE8C8(ctx, base);
	// 8280EFB8: 38610118  addi r3, r1, 0x118
	ctx.r[3].s64 = ctx.r[1].s64 + 280;
	// 8280EFBC: 485EF90D  bl 0x82dfe8c8
	ctx.lr = 0x8280EFC0;
	sub_82DFE8C8(ctx, base);
	// 8280EFC0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280EFC4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280EFC8: 93810124  stw r28, 0x124(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(292 as u32), ctx.r[28].u32 ) };
	// 8280EFCC: D0010128  stfs f0, 0x128(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 8280EFD0: 93C1012C  stw r30, 0x12c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(300 as u32), ctx.r[30].u32 ) };
	// 8280EFD4: D3C10130  stfs f30, 0x130(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 8280EFD8: 9BE1013C  stb r31, 0x13c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[31].u8 ) };
	// 8280EFDC: D3E10134  stfs f31, 0x134(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), tmp.u32 ) };
	// 8280EFE0: 38610140  addi r3, r1, 0x140
	ctx.r[3].s64 = ctx.r[1].s64 + 320;
	// 8280EFE4: D3E10138  stfs f31, 0x138(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), tmp.u32 ) };
	// 8280EFE8: 816BA044  lwz r11, -0x5fbc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24508 as u32) ) } as u64;
	// 8280EFEC: 91610120  stw r11, 0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 8280EFF0: 485EF8D9  bl 0x82dfe8c8
	ctx.lr = 0x8280EFF4;
	sub_82DFE8C8(ctx, base);
	// 8280EFF4: 38610148  addi r3, r1, 0x148
	ctx.r[3].s64 = ctx.r[1].s64 + 328;
	// 8280EFF8: 485EF8D1  bl 0x82dfe8c8
	ctx.lr = 0x8280EFFC;
	sub_82DFE8C8(ctx, base);
	// 8280EFFC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F000: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F004: 93C1015C  stw r30, 0x15c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), ctx.r[30].u32 ) };
	// 8280F008: D0010158  stfs f0, 0x158(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), tmp.u32 ) };
	// 8280F00C: 93410154  stw r26, 0x154(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), ctx.r[26].u32 ) };
	// 8280F010: D3C10160  stfs f30, 0x160(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 8280F014: 9BE1016C  stb r31, 0x16c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), ctx.r[31].u8 ) };
	// 8280F018: D3E10164  stfs f31, 0x164(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), tmp.u32 ) };
	// 8280F01C: 38610170  addi r3, r1, 0x170
	ctx.r[3].s64 = ctx.r[1].s64 + 368;
	// 8280F020: D3E10168  stfs f31, 0x168(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), tmp.u32 ) };
	// 8280F024: 816BA048  lwz r11, -0x5fb8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24504 as u32) ) } as u64;
	// 8280F028: 91610150  stw r11, 0x150(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[11].u32 ) };
	// 8280F02C: 485EF89D  bl 0x82dfe8c8
	ctx.lr = 0x8280F030;
	sub_82DFE8C8(ctx, base);
	// 8280F030: 38610178  addi r3, r1, 0x178
	ctx.r[3].s64 = ctx.r[1].s64 + 376;
	// 8280F034: 485EF895  bl 0x82dfe8c8
	ctx.lr = 0x8280F038;
	sub_82DFE8C8(ctx, base);
	// 8280F038: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F03C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F040: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F044: D0010188  stfs f0, 0x188(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), tmp.u32 ) };
	// 8280F048: 93C1018C  stw r30, 0x18c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), ctx.r[30].u32 ) };
	// 8280F04C: 3B8A8C5C  addi r28, r10, -0x73a4
	ctx.r[28].s64 = ctx.r[10].s64 + -29604;
	// 8280F050: D3C10190  stfs f30, 0x190(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), tmp.u32 ) };
	// 8280F054: D3E10194  stfs f31, 0x194(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), tmp.u32 ) };
	// 8280F058: 9BE1019C  stb r31, 0x19c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), ctx.r[31].u8 ) };
	// 8280F05C: D3E10198  stfs f31, 0x198(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), tmp.u32 ) };
	// 8280F060: 93810184  stw r28, 0x184(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(388 as u32), ctx.r[28].u32 ) };
	// 8280F064: 386101A0  addi r3, r1, 0x1a0
	ctx.r[3].s64 = ctx.r[1].s64 + 416;
	// 8280F068: 816BA04C  lwz r11, -0x5fb4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24500 as u32) ) } as u64;
	// 8280F06C: 91610180  stw r11, 0x180(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[11].u32 ) };
	// 8280F070: 485EF859  bl 0x82dfe8c8
	ctx.lr = 0x8280F074;
	sub_82DFE8C8(ctx, base);
	// 8280F074: 386101A8  addi r3, r1, 0x1a8
	ctx.r[3].s64 = ctx.r[1].s64 + 424;
	// 8280F078: 485EF851  bl 0x82dfe8c8
	ctx.lr = 0x8280F07C;
	sub_82DFE8C8(ctx, base);
	// 8280F07C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F080: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F084: 93C101BC  stw r30, 0x1bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(444 as u32), ctx.r[30].u32 ) };
	// 8280F088: D00101B8  stfs f0, 0x1b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), tmp.u32 ) };
	// 8280F08C: 938101B4  stw r28, 0x1b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(436 as u32), ctx.r[28].u32 ) };
	// 8280F090: D3C101C0  stfs f30, 0x1c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), tmp.u32 ) };
	// 8280F094: 9BE101CC  stb r31, 0x1cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(460 as u32), ctx.r[31].u8 ) };
	// 8280F098: D3E101C4  stfs f31, 0x1c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(452 as u32), tmp.u32 ) };
	// 8280F09C: 386101D0  addi r3, r1, 0x1d0
	ctx.r[3].s64 = ctx.r[1].s64 + 464;
	// 8280F0A0: D3E101C8  stfs f31, 0x1c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), tmp.u32 ) };
	// 8280F0A4: 816BA050  lwz r11, -0x5fb0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24496 as u32) ) } as u64;
	// 8280F0A8: 916101B0  stw r11, 0x1b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), ctx.r[11].u32 ) };
	// 8280F0AC: 485EF81D  bl 0x82dfe8c8
	ctx.lr = 0x8280F0B0;
	sub_82DFE8C8(ctx, base);
	// 8280F0B0: 386101D8  addi r3, r1, 0x1d8
	ctx.r[3].s64 = ctx.r[1].s64 + 472;
	// 8280F0B4: 485EF815  bl 0x82dfe8c8
	ctx.lr = 0x8280F0B8;
	sub_82DFE8C8(ctx, base);
	// 8280F0B8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F0BC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F0C0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F0C4: 816BA054  lwz r11, -0x5fac(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24492 as u32) ) } as u64;
	// 8280F0C8: 394A8C4C  addi r10, r10, -0x73b4
	ctx.r[10].s64 = ctx.r[10].s64 + -29620;
	// 8280F0CC: D00101E8  stfs f0, 0x1e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), tmp.u32 ) };
	// 8280F0D0: 93E101EC  stw r31, 0x1ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(492 as u32), ctx.r[31].u32 ) };
	// 8280F0D4: D3C101F0  stfs f30, 0x1f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), tmp.u32 ) };
	// 8280F0D8: 9BE101FC  stb r31, 0x1fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(508 as u32), ctx.r[31].u8 ) };
	// 8280F0DC: D3E101F4  stfs f31, 0x1f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(500 as u32), tmp.u32 ) };
	// 8280F0E0: 914101E4  stw r10, 0x1e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(484 as u32), ctx.r[10].u32 ) };
	// 8280F0E4: D3E101F8  stfs f31, 0x1f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(504 as u32), tmp.u32 ) };
	// 8280F0E8: 38610200  addi r3, r1, 0x200
	ctx.r[3].s64 = ctx.r[1].s64 + 512;
	// 8280F0EC: 916101E0  stw r11, 0x1e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(480 as u32), ctx.r[11].u32 ) };
	// 8280F0F0: 485EF7D9  bl 0x82dfe8c8
	ctx.lr = 0x8280F0F4;
	sub_82DFE8C8(ctx, base);
	// 8280F0F4: 38610208  addi r3, r1, 0x208
	ctx.r[3].s64 = ctx.r[1].s64 + 520;
	// 8280F0F8: 485EF7D1  bl 0x82dfe8c8
	ctx.lr = 0x8280F0FC;
	sub_82DFE8C8(ctx, base);
	// 8280F0FC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F100: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F104: 93C1021C  stw r30, 0x21c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(540 as u32), ctx.r[30].u32 ) };
	// 8280F108: D0010218  stfs f0, 0x218(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(536 as u32), tmp.u32 ) };
	// 8280F10C: 93810214  stw r28, 0x214(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(532 as u32), ctx.r[28].u32 ) };
	// 8280F110: D3C10220  stfs f30, 0x220(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(544 as u32), tmp.u32 ) };
	// 8280F114: 9BE1022C  stb r31, 0x22c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(556 as u32), ctx.r[31].u8 ) };
	// 8280F118: D3E10224  stfs f31, 0x224(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(548 as u32), tmp.u32 ) };
	// 8280F11C: 38610230  addi r3, r1, 0x230
	ctx.r[3].s64 = ctx.r[1].s64 + 560;
	// 8280F120: D3E10228  stfs f31, 0x228(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(552 as u32), tmp.u32 ) };
	// 8280F124: 816BA05C  lwz r11, -0x5fa4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24484 as u32) ) } as u64;
	// 8280F128: 91610210  stw r11, 0x210(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(528 as u32), ctx.r[11].u32 ) };
	// 8280F12C: 485EF79D  bl 0x82dfe8c8
	ctx.lr = 0x8280F130;
	sub_82DFE8C8(ctx, base);
	// 8280F130: 38610238  addi r3, r1, 0x238
	ctx.r[3].s64 = ctx.r[1].s64 + 568;
	// 8280F134: 485EF795  bl 0x82dfe8c8
	ctx.lr = 0x8280F138;
	sub_82DFE8C8(ctx, base);
	// 8280F138: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F13C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F140: 93C1024C  stw r30, 0x24c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(588 as u32), ctx.r[30].u32 ) };
	// 8280F144: D0010248  stfs f0, 0x248(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(584 as u32), tmp.u32 ) };
	// 8280F148: 93810244  stw r28, 0x244(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(580 as u32), ctx.r[28].u32 ) };
	// 8280F14C: D3C10250  stfs f30, 0x250(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(592 as u32), tmp.u32 ) };
	// 8280F150: 9BE1025C  stb r31, 0x25c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(604 as u32), ctx.r[31].u8 ) };
	// 8280F154: D3E10254  stfs f31, 0x254(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(596 as u32), tmp.u32 ) };
	// 8280F158: 38610260  addi r3, r1, 0x260
	ctx.r[3].s64 = ctx.r[1].s64 + 608;
	// 8280F15C: D3E10258  stfs f31, 0x258(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(600 as u32), tmp.u32 ) };
	// 8280F160: 816BA060  lwz r11, -0x5fa0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24480 as u32) ) } as u64;
	// 8280F164: 91610240  stw r11, 0x240(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(576 as u32), ctx.r[11].u32 ) };
	// 8280F168: 485EF761  bl 0x82dfe8c8
	ctx.lr = 0x8280F16C;
	sub_82DFE8C8(ctx, base);
	// 8280F16C: 38610268  addi r3, r1, 0x268
	ctx.r[3].s64 = ctx.r[1].s64 + 616;
	// 8280F170: 485EF759  bl 0x82dfe8c8
	ctx.lr = 0x8280F174;
	sub_82DFE8C8(ctx, base);
	// 8280F174: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F178: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F17C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F180: D0010278  stfs f0, 0x278(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(632 as u32), tmp.u32 ) };
	// 8280F184: 93C1027C  stw r30, 0x27c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(636 as u32), ctx.r[30].u32 ) };
	// 8280F188: 394A8C38  addi r10, r10, -0x73c8
	ctx.r[10].s64 = ctx.r[10].s64 + -29640;
	// 8280F18C: D3C10280  stfs f30, 0x280(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(640 as u32), tmp.u32 ) };
	// 8280F190: D3E10284  stfs f31, 0x284(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(644 as u32), tmp.u32 ) };
	// 8280F194: 9BE1028C  stb r31, 0x28c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(652 as u32), ctx.r[31].u8 ) };
	// 8280F198: D3E10288  stfs f31, 0x288(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(648 as u32), tmp.u32 ) };
	// 8280F19C: 91410274  stw r10, 0x274(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(628 as u32), ctx.r[10].u32 ) };
	// 8280F1A0: 38610290  addi r3, r1, 0x290
	ctx.r[3].s64 = ctx.r[1].s64 + 656;
	// 8280F1A4: 816BA064  lwz r11, -0x5f9c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24476 as u32) ) } as u64;
	// 8280F1A8: 91610270  stw r11, 0x270(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(624 as u32), ctx.r[11].u32 ) };
	// 8280F1AC: 485EF71D  bl 0x82dfe8c8
	ctx.lr = 0x8280F1B0;
	sub_82DFE8C8(ctx, base);
	// 8280F1B0: 38610298  addi r3, r1, 0x298
	ctx.r[3].s64 = ctx.r[1].s64 + 664;
	// 8280F1B4: 485EF715  bl 0x82dfe8c8
	ctx.lr = 0x8280F1B8;
	sub_82DFE8C8(ctx, base);
	// 8280F1B8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F1BC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F1C0: 93C102AC  stw r30, 0x2ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(684 as u32), ctx.r[30].u32 ) };
	// 8280F1C4: D00102A8  stfs f0, 0x2a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(680 as u32), tmp.u32 ) };
	// 8280F1C8: 938102A4  stw r28, 0x2a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(676 as u32), ctx.r[28].u32 ) };
	// 8280F1CC: D3C102B0  stfs f30, 0x2b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(688 as u32), tmp.u32 ) };
	// 8280F1D0: 9BE102BC  stb r31, 0x2bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(700 as u32), ctx.r[31].u8 ) };
	// 8280F1D4: D3E102B4  stfs f31, 0x2b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(692 as u32), tmp.u32 ) };
	// 8280F1D8: 386102C0  addi r3, r1, 0x2c0
	ctx.r[3].s64 = ctx.r[1].s64 + 704;
	// 8280F1DC: D3E102B8  stfs f31, 0x2b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(696 as u32), tmp.u32 ) };
	// 8280F1E0: 816BA068  lwz r11, -0x5f98(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24472 as u32) ) } as u64;
	// 8280F1E4: 916102A0  stw r11, 0x2a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(672 as u32), ctx.r[11].u32 ) };
	// 8280F1E8: 485EF6E1  bl 0x82dfe8c8
	ctx.lr = 0x8280F1EC;
	sub_82DFE8C8(ctx, base);
	// 8280F1EC: 386102C8  addi r3, r1, 0x2c8
	ctx.r[3].s64 = ctx.r[1].s64 + 712;
	// 8280F1F0: 485EF6D9  bl 0x82dfe8c8
	ctx.lr = 0x8280F1F4;
	sub_82DFE8C8(ctx, base);
	// 8280F1F4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F1F8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F1FC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F200: 394A8C24  addi r10, r10, -0x73dc
	ctx.r[10].s64 = ctx.r[10].s64 + -29660;
	// 8280F204: 816BA06C  lwz r11, -0x5f94(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24468 as u32) ) } as u64;
	// 8280F208: D00102D8  stfs f0, 0x2d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(728 as u32), tmp.u32 ) };
	// 8280F20C: 93C102DC  stw r30, 0x2dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(732 as u32), ctx.r[30].u32 ) };
	// 8280F210: D3C102E0  stfs f30, 0x2e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(736 as u32), tmp.u32 ) };
	// 8280F214: 914102D4  stw r10, 0x2d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(724 as u32), ctx.r[10].u32 ) };
	// 8280F218: D3E102E4  stfs f31, 0x2e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(740 as u32), tmp.u32 ) };
	// 8280F21C: 9BE102EC  stb r31, 0x2ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(748 as u32), ctx.r[31].u8 ) };
	// 8280F220: D3E102E8  stfs f31, 0x2e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(744 as u32), tmp.u32 ) };
	// 8280F224: 916102D0  stw r11, 0x2d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(720 as u32), ctx.r[11].u32 ) };
	// 8280F228: 386102F0  addi r3, r1, 0x2f0
	ctx.r[3].s64 = ctx.r[1].s64 + 752;
	// 8280F22C: 485EF69D  bl 0x82dfe8c8
	ctx.lr = 0x8280F230;
	sub_82DFE8C8(ctx, base);
	// 8280F230: 386102F8  addi r3, r1, 0x2f8
	ctx.r[3].s64 = ctx.r[1].s64 + 760;
	// 8280F234: 485EF695  bl 0x82dfe8c8
	ctx.lr = 0x8280F238;
	sub_82DFE8C8(ctx, base);
	// 8280F238: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F23C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F240: 93C1030C  stw r30, 0x30c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(780 as u32), ctx.r[30].u32 ) };
	// 8280F244: D0010308  stfs f0, 0x308(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(776 as u32), tmp.u32 ) };
	// 8280F248: 93810304  stw r28, 0x304(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(772 as u32), ctx.r[28].u32 ) };
	// 8280F24C: D3C10310  stfs f30, 0x310(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(784 as u32), tmp.u32 ) };
	// 8280F250: 9BE1031C  stb r31, 0x31c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(796 as u32), ctx.r[31].u8 ) };
	// 8280F254: D3E10314  stfs f31, 0x314(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(788 as u32), tmp.u32 ) };
	// 8280F258: 38610320  addi r3, r1, 0x320
	ctx.r[3].s64 = ctx.r[1].s64 + 800;
	// 8280F25C: D3E10318  stfs f31, 0x318(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(792 as u32), tmp.u32 ) };
	// 8280F260: 816BA070  lwz r11, -0x5f90(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24464 as u32) ) } as u64;
	// 8280F264: 91610300  stw r11, 0x300(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(768 as u32), ctx.r[11].u32 ) };
	// 8280F268: 485EF661  bl 0x82dfe8c8
	ctx.lr = 0x8280F26C;
	sub_82DFE8C8(ctx, base);
	// 8280F26C: 38610328  addi r3, r1, 0x328
	ctx.r[3].s64 = ctx.r[1].s64 + 808;
	// 8280F270: 485EF659  bl 0x82dfe8c8
	ctx.lr = 0x8280F274;
	sub_82DFE8C8(ctx, base);
	// 8280F274: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F278: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F27C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F280: D0010338  stfs f0, 0x338(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(824 as u32), tmp.u32 ) };
	// 8280F284: 93C1033C  stw r30, 0x33c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(828 as u32), ctx.r[30].u32 ) };
	// 8280F288: 394A8C10  addi r10, r10, -0x73f0
	ctx.r[10].s64 = ctx.r[10].s64 + -29680;
	// 8280F28C: D3C10340  stfs f30, 0x340(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(832 as u32), tmp.u32 ) };
	// 8280F290: D3E10344  stfs f31, 0x344(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(836 as u32), tmp.u32 ) };
	// 8280F294: 9BE1034C  stb r31, 0x34c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(844 as u32), ctx.r[31].u8 ) };
	// 8280F298: D3E10348  stfs f31, 0x348(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(840 as u32), tmp.u32 ) };
	// 8280F29C: 91410334  stw r10, 0x334(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(820 as u32), ctx.r[10].u32 ) };
	// 8280F2A0: 38610350  addi r3, r1, 0x350
	ctx.r[3].s64 = ctx.r[1].s64 + 848;
	// 8280F2A4: 816BA074  lwz r11, -0x5f8c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24460 as u32) ) } as u64;
	// 8280F2A8: 91610330  stw r11, 0x330(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(816 as u32), ctx.r[11].u32 ) };
	// 8280F2AC: 485EF61D  bl 0x82dfe8c8
	ctx.lr = 0x8280F2B0;
	sub_82DFE8C8(ctx, base);
	// 8280F2B0: 38610358  addi r3, r1, 0x358
	ctx.r[3].s64 = ctx.r[1].s64 + 856;
	// 8280F2B4: 485EF615  bl 0x82dfe8c8
	ctx.lr = 0x8280F2B8;
	sub_82DFE8C8(ctx, base);
	// 8280F2B8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F2BC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F2C0: 93C1036C  stw r30, 0x36c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(876 as u32), ctx.r[30].u32 ) };
	// 8280F2C4: D0010368  stfs f0, 0x368(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(872 as u32), tmp.u32 ) };
	// 8280F2C8: 93810364  stw r28, 0x364(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(868 as u32), ctx.r[28].u32 ) };
	// 8280F2CC: D3C10370  stfs f30, 0x370(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(880 as u32), tmp.u32 ) };
	// 8280F2D0: 9BE1037C  stb r31, 0x37c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(892 as u32), ctx.r[31].u8 ) };
	// 8280F2D4: D3E10374  stfs f31, 0x374(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(884 as u32), tmp.u32 ) };
	// 8280F2D8: 38610380  addi r3, r1, 0x380
	ctx.r[3].s64 = ctx.r[1].s64 + 896;
	// 8280F2DC: D3E10378  stfs f31, 0x378(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(888 as u32), tmp.u32 ) };
	// 8280F2E0: 816BA078  lwz r11, -0x5f88(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24456 as u32) ) } as u64;
	// 8280F2E4: 91610360  stw r11, 0x360(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(864 as u32), ctx.r[11].u32 ) };
	// 8280F2E8: 485EF5E1  bl 0x82dfe8c8
	ctx.lr = 0x8280F2EC;
	sub_82DFE8C8(ctx, base);
	// 8280F2EC: 38610388  addi r3, r1, 0x388
	ctx.r[3].s64 = ctx.r[1].s64 + 904;
	// 8280F2F0: 485EF5D9  bl 0x82dfe8c8
	ctx.lr = 0x8280F2F4;
	sub_82DFE8C8(ctx, base);
	// 8280F2F4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F2F8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F2FC: 93E1039C  stw r31, 0x39c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(924 as u32), ctx.r[31].u32 ) };
	// 8280F300: D0010398  stfs f0, 0x398(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(920 as u32), tmp.u32 ) };
	// 8280F304: 93810394  stw r28, 0x394(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(916 as u32), ctx.r[28].u32 ) };
	// 8280F308: D3C103A0  stfs f30, 0x3a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(928 as u32), tmp.u32 ) };
	// 8280F30C: 9BE103AC  stb r31, 0x3ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(940 as u32), ctx.r[31].u8 ) };
	// 8280F310: D3E103A4  stfs f31, 0x3a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(932 as u32), tmp.u32 ) };
	// 8280F314: 386103B0  addi r3, r1, 0x3b0
	ctx.r[3].s64 = ctx.r[1].s64 + 944;
	// 8280F318: D3E103A8  stfs f31, 0x3a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(936 as u32), tmp.u32 ) };
	// 8280F31C: 816BA07C  lwz r11, -0x5f84(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24452 as u32) ) } as u64;
	// 8280F320: 91610390  stw r11, 0x390(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(912 as u32), ctx.r[11].u32 ) };
	// 8280F324: 485EF5A5  bl 0x82dfe8c8
	ctx.lr = 0x8280F328;
	sub_82DFE8C8(ctx, base);
	// 8280F328: 386103B8  addi r3, r1, 0x3b8
	ctx.r[3].s64 = ctx.r[1].s64 + 952;
	// 8280F32C: 485EF59D  bl 0x82dfe8c8
	ctx.lr = 0x8280F330;
	sub_82DFE8C8(ctx, base);
	// 8280F330: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F334: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F338: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F33C: D00103C8  stfs f0, 0x3c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(968 as u32), tmp.u32 ) };
	// 8280F340: D3C103D0  stfs f30, 0x3d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(976 as u32), tmp.u32 ) };
	// 8280F344: 394A8BFC  addi r10, r10, -0x7404
	ctx.r[10].s64 = ctx.r[10].s64 + -29700;
	// 8280F348: 816BA028  lwz r11, -0x5fd8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24536 as u32) ) } as u64;
	// 8280F34C: D3E103D4  stfs f31, 0x3d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(980 as u32), tmp.u32 ) };
	// 8280F350: 93C103CC  stw r30, 0x3cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(972 as u32), ctx.r[30].u32 ) };
	// 8280F354: D3E103D8  stfs f31, 0x3d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(984 as u32), tmp.u32 ) };
	// 8280F358: 914103C4  stw r10, 0x3c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(964 as u32), ctx.r[10].u32 ) };
	// 8280F35C: 9BE103DC  stb r31, 0x3dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(988 as u32), ctx.r[31].u8 ) };
	// 8280F360: 386103E0  addi r3, r1, 0x3e0
	ctx.r[3].s64 = ctx.r[1].s64 + 992;
	// 8280F364: 916103C0  stw r11, 0x3c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(960 as u32), ctx.r[11].u32 ) };
	// 8280F368: 485EF561  bl 0x82dfe8c8
	ctx.lr = 0x8280F36C;
	sub_82DFE8C8(ctx, base);
	// 8280F36C: 386103E8  addi r3, r1, 0x3e8
	ctx.r[3].s64 = ctx.r[1].s64 + 1000;
	// 8280F370: 485EF559  bl 0x82dfe8c8
	ctx.lr = 0x8280F374;
	sub_82DFE8C8(ctx, base);
	// 8280F374: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F378: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F37C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F380: D00103F8  stfs f0, 0x3f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1016 as u32), tmp.u32 ) };
	// 8280F384: 93C103FC  stw r30, 0x3fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1020 as u32), ctx.r[30].u32 ) };
	// 8280F388: 394A8BE4  addi r10, r10, -0x741c
	ctx.r[10].s64 = ctx.r[10].s64 + -29724;
	// 8280F38C: D3C10400  stfs f30, 0x400(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 8280F390: D3E10404  stfs f31, 0x404(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 8280F394: 9BE1040C  stb r31, 0x40c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1036 as u32), ctx.r[31].u8 ) };
	// 8280F398: D3E10408  stfs f31, 0x408(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1032 as u32), tmp.u32 ) };
	// 8280F39C: 914103F4  stw r10, 0x3f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1012 as u32), ctx.r[10].u32 ) };
	// 8280F3A0: 38610410  addi r3, r1, 0x410
	ctx.r[3].s64 = ctx.r[1].s64 + 1040;
	// 8280F3A4: 816BA02C  lwz r11, -0x5fd4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24532 as u32) ) } as u64;
	// 8280F3A8: 916103F0  stw r11, 0x3f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1008 as u32), ctx.r[11].u32 ) };
	// 8280F3AC: 485EF51D  bl 0x82dfe8c8
	ctx.lr = 0x8280F3B0;
	sub_82DFE8C8(ctx, base);
	// 8280F3B0: 38610418  addi r3, r1, 0x418
	ctx.r[3].s64 = ctx.r[1].s64 + 1048;
	// 8280F3B4: 485EF515  bl 0x82dfe8c8
	ctx.lr = 0x8280F3B8;
	sub_82DFE8C8(ctx, base);
	// 8280F3B8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F3BC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F3C0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F3C4: D0010428  stfs f0, 0x428(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1064 as u32), tmp.u32 ) };
	// 8280F3C8: 93C1042C  stw r30, 0x42c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1068 as u32), ctx.r[30].u32 ) };
	// 8280F3CC: 394A8BD0  addi r10, r10, -0x7430
	ctx.r[10].s64 = ctx.r[10].s64 + -29744;
	// 8280F3D0: D3C10430  stfs f30, 0x430(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1072 as u32), tmp.u32 ) };
	// 8280F3D4: D3E10434  stfs f31, 0x434(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1076 as u32), tmp.u32 ) };
	// 8280F3D8: 9BE1043C  stb r31, 0x43c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1084 as u32), ctx.r[31].u8 ) };
	// 8280F3DC: D3E10438  stfs f31, 0x438(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1080 as u32), tmp.u32 ) };
	// 8280F3E0: 91410424  stw r10, 0x424(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1060 as u32), ctx.r[10].u32 ) };
	// 8280F3E4: 38610440  addi r3, r1, 0x440
	ctx.r[3].s64 = ctx.r[1].s64 + 1088;
	// 8280F3E8: 816BA030  lwz r11, -0x5fd0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24528 as u32) ) } as u64;
	// 8280F3EC: 91610420  stw r11, 0x420(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1056 as u32), ctx.r[11].u32 ) };
	// 8280F3F0: 485EF4D9  bl 0x82dfe8c8
	ctx.lr = 0x8280F3F4;
	sub_82DFE8C8(ctx, base);
	// 8280F3F4: 38610448  addi r3, r1, 0x448
	ctx.r[3].s64 = ctx.r[1].s64 + 1096;
	// 8280F3F8: 485EF4D1  bl 0x82dfe8c8
	ctx.lr = 0x8280F3FC;
	sub_82DFE8C8(ctx, base);
	// 8280F3FC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F400: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F404: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F408: D0010458  stfs f0, 0x458(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1112 as u32), tmp.u32 ) };
	// 8280F40C: 93C1045C  stw r30, 0x45c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1116 as u32), ctx.r[30].u32 ) };
	// 8280F410: 394A8BB8  addi r10, r10, -0x7448
	ctx.r[10].s64 = ctx.r[10].s64 + -29768;
	// 8280F414: D3C10460  stfs f30, 0x460(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1120 as u32), tmp.u32 ) };
	// 8280F418: D3E10464  stfs f31, 0x464(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1124 as u32), tmp.u32 ) };
	// 8280F41C: 9BE1046C  stb r31, 0x46c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1132 as u32), ctx.r[31].u8 ) };
	// 8280F420: D3E10468  stfs f31, 0x468(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1128 as u32), tmp.u32 ) };
	// 8280F424: 91410454  stw r10, 0x454(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1108 as u32), ctx.r[10].u32 ) };
	// 8280F428: 38610470  addi r3, r1, 0x470
	ctx.r[3].s64 = ctx.r[1].s64 + 1136;
	// 8280F42C: 816BA034  lwz r11, -0x5fcc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24524 as u32) ) } as u64;
	// 8280F430: 91610450  stw r11, 0x450(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1104 as u32), ctx.r[11].u32 ) };
	// 8280F434: 485EF495  bl 0x82dfe8c8
	ctx.lr = 0x8280F438;
	sub_82DFE8C8(ctx, base);
	// 8280F438: 38610478  addi r3, r1, 0x478
	ctx.r[3].s64 = ctx.r[1].s64 + 1144;
	// 8280F43C: 485EF48D  bl 0x82dfe8c8
	ctx.lr = 0x8280F440;
	sub_82DFE8C8(ctx, base);
	// 8280F440: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F444: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F448: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F44C: D0010488  stfs f0, 0x488(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1160 as u32), tmp.u32 ) };
	// 8280F450: 93C1048C  stw r30, 0x48c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1164 as u32), ctx.r[30].u32 ) };
	// 8280F454: 394A8BA4  addi r10, r10, -0x745c
	ctx.r[10].s64 = ctx.r[10].s64 + -29788;
	// 8280F458: D3C10490  stfs f30, 0x490(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1168 as u32), tmp.u32 ) };
	// 8280F45C: D3E10494  stfs f31, 0x494(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1172 as u32), tmp.u32 ) };
	// 8280F460: 9BE1049C  stb r31, 0x49c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1180 as u32), ctx.r[31].u8 ) };
	// 8280F464: D3E10498  stfs f31, 0x498(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1176 as u32), tmp.u32 ) };
	// 8280F468: 91410484  stw r10, 0x484(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1156 as u32), ctx.r[10].u32 ) };
	// 8280F46C: 386104A0  addi r3, r1, 0x4a0
	ctx.r[3].s64 = ctx.r[1].s64 + 1184;
	// 8280F470: 816BA038  lwz r11, -0x5fc8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24520 as u32) ) } as u64;
	// 8280F474: 91610480  stw r11, 0x480(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1152 as u32), ctx.r[11].u32 ) };
	// 8280F478: 485EF451  bl 0x82dfe8c8
	ctx.lr = 0x8280F47C;
	sub_82DFE8C8(ctx, base);
	// 8280F47C: 386104A8  addi r3, r1, 0x4a8
	ctx.r[3].s64 = ctx.r[1].s64 + 1192;
	// 8280F480: 485EF449  bl 0x82dfe8c8
	ctx.lr = 0x8280F484;
	sub_82DFE8C8(ctx, base);
	// 8280F484: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F488: D00104B8  stfs f0, 0x4b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1208 as u32), tmp.u32 ) };
	// 8280F48C: 3F40832D  lis r26, -0x7cd3
	ctx.r[26].s64 = -2094202880;
	// 8280F490: 817AF3F8  lwz r11, -0xc08(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-3080 as u32) ) } as u64;
	// 8280F494: D3C104C0  stfs f30, 0x4c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1216 as u32), tmp.u32 ) };
	// 8280F498: D3E104C4  stfs f31, 0x4c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1220 as u32), tmp.u32 ) };
	// 8280F49C: 938104B4  stw r28, 0x4b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1204 as u32), ctx.r[28].u32 ) };
	// 8280F4A0: D3E104C8  stfs f31, 0x4c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1224 as u32), tmp.u32 ) };
	// 8280F4A4: 93E104BC  stw r31, 0x4bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1212 as u32), ctx.r[31].u32 ) };
	// 8280F4A8: 9BE104CC  stb r31, 0x4cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1228 as u32), ctx.r[31].u8 ) };
	// 8280F4AC: 386104D0  addi r3, r1, 0x4d0
	ctx.r[3].s64 = ctx.r[1].s64 + 1232;
	// 8280F4B0: 916104B0  stw r11, 0x4b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1200 as u32), ctx.r[11].u32 ) };
	// 8280F4B4: 485EF415  bl 0x82dfe8c8
	ctx.lr = 0x8280F4B8;
	sub_82DFE8C8(ctx, base);
	// 8280F4B8: 386104D8  addi r3, r1, 0x4d8
	ctx.r[3].s64 = ctx.r[1].s64 + 1240;
	// 8280F4BC: 485EF40D  bl 0x82dfe8c8
	ctx.lr = 0x8280F4C0;
	sub_82DFE8C8(ctx, base);
	// 8280F4C0: 3F20832D  lis r25, -0x7cd3
	ctx.r[25].s64 = -2094202880;
	// 8280F4C4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8280F4C8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F4CC: D00104E8  stfs f0, 0x4e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1256 as u32), tmp.u32 ) };
	// 8280F4D0: 93E104EC  stw r31, 0x4ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1260 as u32), ctx.r[31].u32 ) };
	// 8280F4D4: 394B8B98  addi r10, r11, -0x7468
	ctx.r[10].s64 = ctx.r[11].s64 + -29800;
	// 8280F4D8: D3C104F0  stfs f30, 0x4f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1264 as u32), tmp.u32 ) };
	// 8280F4DC: D3E104F4  stfs f31, 0x4f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1268 as u32), tmp.u32 ) };
	// 8280F4E0: 9BE104FC  stb r31, 0x4fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1276 as u32), ctx.r[31].u8 ) };
	// 8280F4E4: D3E104F8  stfs f31, 0x4f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1272 as u32), tmp.u32 ) };
	// 8280F4E8: 914104E4  stw r10, 0x4e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1252 as u32), ctx.r[10].u32 ) };
	// 8280F4EC: 38610500  addi r3, r1, 0x500
	ctx.r[3].s64 = ctx.r[1].s64 + 1280;
	// 8280F4F0: 8179F3FC  lwz r11, -0xc04(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(-3076 as u32) ) } as u64;
	// 8280F4F4: 916104E0  stw r11, 0x4e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1248 as u32), ctx.r[11].u32 ) };
	// 8280F4F8: 485EF3D1  bl 0x82dfe8c8
	ctx.lr = 0x8280F4FC;
	sub_82DFE8C8(ctx, base);
	// 8280F4FC: 38610508  addi r3, r1, 0x508
	ctx.r[3].s64 = ctx.r[1].s64 + 1288;
	// 8280F500: 485EF3C9  bl 0x82dfe8c8
	ctx.lr = 0x8280F504;
	sub_82DFE8C8(ctx, base);
	// 8280F504: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F508: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F50C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F510: D0010518  stfs f0, 0x518(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1304 as u32), tmp.u32 ) };
	// 8280F514: 93E1051C  stw r31, 0x51c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1308 as u32), ctx.r[31].u32 ) };
	// 8280F518: 394A8B88  addi r10, r10, -0x7478
	ctx.r[10].s64 = ctx.r[10].s64 + -29816;
	// 8280F51C: D3C10520  stfs f30, 0x520(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1312 as u32), tmp.u32 ) };
	// 8280F520: D3E10524  stfs f31, 0x524(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1316 as u32), tmp.u32 ) };
	// 8280F524: 9BE1052C  stb r31, 0x52c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1324 as u32), ctx.r[31].u8 ) };
	// 8280F528: D3E10528  stfs f31, 0x528(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1320 as u32), tmp.u32 ) };
	// 8280F52C: 91410514  stw r10, 0x514(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1300 as u32), ctx.r[10].u32 ) };
	// 8280F530: 38610530  addi r3, r1, 0x530
	ctx.r[3].s64 = ctx.r[1].s64 + 1328;
	// 8280F534: 816BF40C  lwz r11, -0xbf4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3060 as u32) ) } as u64;
	// 8280F538: 91610510  stw r11, 0x510(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1296 as u32), ctx.r[11].u32 ) };
	// 8280F53C: 485EF38D  bl 0x82dfe8c8
	ctx.lr = 0x8280F540;
	sub_82DFE8C8(ctx, base);
	// 8280F540: 38610538  addi r3, r1, 0x538
	ctx.r[3].s64 = ctx.r[1].s64 + 1336;
	// 8280F544: 485EF385  bl 0x82dfe8c8
	ctx.lr = 0x8280F548;
	sub_82DFE8C8(ctx, base);
	// 8280F548: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F54C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F550: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F554: D0010548  stfs f0, 0x548(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1352 as u32), tmp.u32 ) };
	// 8280F558: 93C1054C  stw r30, 0x54c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1356 as u32), ctx.r[30].u32 ) };
	// 8280F55C: 394A8B78  addi r10, r10, -0x7488
	ctx.r[10].s64 = ctx.r[10].s64 + -29832;
	// 8280F560: D3C10550  stfs f30, 0x550(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1360 as u32), tmp.u32 ) };
	// 8280F564: D3E10554  stfs f31, 0x554(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1364 as u32), tmp.u32 ) };
	// 8280F568: 9BE1055C  stb r31, 0x55c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1372 as u32), ctx.r[31].u8 ) };
	// 8280F56C: D3E10558  stfs f31, 0x558(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1368 as u32), tmp.u32 ) };
	// 8280F570: 91410544  stw r10, 0x544(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1348 as u32), ctx.r[10].u32 ) };
	// 8280F574: 38610560  addi r3, r1, 0x560
	ctx.r[3].s64 = ctx.r[1].s64 + 1376;
	// 8280F578: 816BF410  lwz r11, -0xbf0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3056 as u32) ) } as u64;
	// 8280F57C: 91610540  stw r11, 0x540(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1344 as u32), ctx.r[11].u32 ) };
	// 8280F580: 485EF349  bl 0x82dfe8c8
	ctx.lr = 0x8280F584;
	sub_82DFE8C8(ctx, base);
	// 8280F584: 38610568  addi r3, r1, 0x568
	ctx.r[3].s64 = ctx.r[1].s64 + 1384;
	// 8280F588: 485EF341  bl 0x82dfe8c8
	ctx.lr = 0x8280F58C;
	sub_82DFE8C8(ctx, base);
	// 8280F58C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F590: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F594: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F598: D0010578  stfs f0, 0x578(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1400 as u32), tmp.u32 ) };
	// 8280F59C: 93C1057C  stw r30, 0x57c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1404 as u32), ctx.r[30].u32 ) };
	// 8280F5A0: 394A8B68  addi r10, r10, -0x7498
	ctx.r[10].s64 = ctx.r[10].s64 + -29848;
	// 8280F5A4: D3C10580  stfs f30, 0x580(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1408 as u32), tmp.u32 ) };
	// 8280F5A8: D3E10584  stfs f31, 0x584(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1412 as u32), tmp.u32 ) };
	// 8280F5AC: 9BE1058C  stb r31, 0x58c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1420 as u32), ctx.r[31].u8 ) };
	// 8280F5B0: D3E10588  stfs f31, 0x588(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1416 as u32), tmp.u32 ) };
	// 8280F5B4: 91410574  stw r10, 0x574(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1396 as u32), ctx.r[10].u32 ) };
	// 8280F5B8: 38610590  addi r3, r1, 0x590
	ctx.r[3].s64 = ctx.r[1].s64 + 1424;
	// 8280F5BC: 816BF404  lwz r11, -0xbfc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3068 as u32) ) } as u64;
	// 8280F5C0: 91610570  stw r11, 0x570(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1392 as u32), ctx.r[11].u32 ) };
	// 8280F5C4: 485EF305  bl 0x82dfe8c8
	ctx.lr = 0x8280F5C8;
	sub_82DFE8C8(ctx, base);
	// 8280F5C8: 38610598  addi r3, r1, 0x598
	ctx.r[3].s64 = ctx.r[1].s64 + 1432;
	// 8280F5CC: 485EF2FD  bl 0x82dfe8c8
	ctx.lr = 0x8280F5D0;
	sub_82DFE8C8(ctx, base);
	// 8280F5D0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F5D4: 816BF408  lwz r11, -0xbf8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3064 as u32) ) } as u64;
	// 8280F5D8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F5DC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F5E0: 93C105AC  stw r30, 0x5ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1452 as u32), ctx.r[30].u32 ) };
	// 8280F5E4: 394A8B5C  addi r10, r10, -0x74a4
	ctx.r[10].s64 = ctx.r[10].s64 + -29860;
	// 8280F5E8: D00105A8  stfs f0, 0x5a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1448 as u32), tmp.u32 ) };
	// 8280F5EC: D3C105B0  stfs f30, 0x5b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1456 as u32), tmp.u32 ) };
	// 8280F5F0: 9BE105BC  stb r31, 0x5bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1468 as u32), ctx.r[31].u8 ) };
	// 8280F5F4: D3E105B4  stfs f31, 0x5b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1460 as u32), tmp.u32 ) };
	// 8280F5F8: 914105A4  stw r10, 0x5a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1444 as u32), ctx.r[10].u32 ) };
	// 8280F5FC: D3E105B8  stfs f31, 0x5b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1464 as u32), tmp.u32 ) };
	// 8280F600: 916105A0  stw r11, 0x5a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1440 as u32), ctx.r[11].u32 ) };
	// 8280F604: 386105C0  addi r3, r1, 0x5c0
	ctx.r[3].s64 = ctx.r[1].s64 + 1472;
	// 8280F608: 485EF2C1  bl 0x82dfe8c8
	ctx.lr = 0x8280F60C;
	sub_82DFE8C8(ctx, base);
	// 8280F60C: 386105C8  addi r3, r1, 0x5c8
	ctx.r[3].s64 = ctx.r[1].s64 + 1480;
	// 8280F610: 485EF2B9  bl 0x82dfe8c8
	ctx.lr = 0x8280F614;
	sub_82DFE8C8(ctx, base);
	// 8280F614: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F618: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F61C: 938105D4  stw r28, 0x5d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1492 as u32), ctx.r[28].u32 ) };
	// 8280F620: D00105D8  stfs f0, 0x5d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1496 as u32), tmp.u32 ) };
	// 8280F624: 93C105DC  stw r30, 0x5dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1500 as u32), ctx.r[30].u32 ) };
	// 8280F628: D3C105E0  stfs f30, 0x5e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1504 as u32), tmp.u32 ) };
	// 8280F62C: 9BE105EC  stb r31, 0x5ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1516 as u32), ctx.r[31].u8 ) };
	// 8280F630: D3E105E4  stfs f31, 0x5e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1508 as u32), tmp.u32 ) };
	// 8280F634: 386105F0  addi r3, r1, 0x5f0
	ctx.r[3].s64 = ctx.r[1].s64 + 1520;
	// 8280F638: D3E105E8  stfs f31, 0x5e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1512 as u32), tmp.u32 ) };
	// 8280F63C: 816BF400  lwz r11, -0xc00(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3072 as u32) ) } as u64;
	// 8280F640: 916105D0  stw r11, 0x5d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1488 as u32), ctx.r[11].u32 ) };
	// 8280F644: 485EF285  bl 0x82dfe8c8
	ctx.lr = 0x8280F648;
	sub_82DFE8C8(ctx, base);
	// 8280F648: 386105F8  addi r3, r1, 0x5f8
	ctx.r[3].s64 = ctx.r[1].s64 + 1528;
	// 8280F64C: 485EF27D  bl 0x82dfe8c8
	ctx.lr = 0x8280F650;
	sub_82DFE8C8(ctx, base);
	// 8280F650: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F654: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F658: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F65C: D0010608  stfs f0, 0x608(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1544 as u32), tmp.u32 ) };
	// 8280F660: 93C1060C  stw r30, 0x60c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1548 as u32), ctx.r[30].u32 ) };
	// 8280F664: 3B0A8B48  addi r24, r10, -0x74b8
	ctx.r[24].s64 = ctx.r[10].s64 + -29880;
	// 8280F668: D3C10610  stfs f30, 0x610(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1552 as u32), tmp.u32 ) };
	// 8280F66C: D3E10614  stfs f31, 0x614(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1556 as u32), tmp.u32 ) };
	// 8280F670: 9BE1061C  stb r31, 0x61c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1564 as u32), ctx.r[31].u8 ) };
	// 8280F674: D3E10618  stfs f31, 0x618(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1560 as u32), tmp.u32 ) };
	// 8280F678: 93010604  stw r24, 0x604(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1540 as u32), ctx.r[24].u32 ) };
	// 8280F67C: 38610620  addi r3, r1, 0x620
	ctx.r[3].s64 = ctx.r[1].s64 + 1568;
	// 8280F680: 816BF488  lwz r11, -0xb78(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2936 as u32) ) } as u64;
	// 8280F684: 91610600  stw r11, 0x600(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1536 as u32), ctx.r[11].u32 ) };
	// 8280F688: 485EF241  bl 0x82dfe8c8
	ctx.lr = 0x8280F68C;
	sub_82DFE8C8(ctx, base);
	// 8280F68C: 38610628  addi r3, r1, 0x628
	ctx.r[3].s64 = ctx.r[1].s64 + 1576;
	// 8280F690: 485EF239  bl 0x82dfe8c8
	ctx.lr = 0x8280F694;
	sub_82DFE8C8(ctx, base);
	// 8280F694: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F698: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F69C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F6A0: D0010638  stfs f0, 0x638(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1592 as u32), tmp.u32 ) };
	// 8280F6A4: 93E1063C  stw r31, 0x63c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1596 as u32), ctx.r[31].u32 ) };
	// 8280F6A8: 394A8B34  addi r10, r10, -0x74cc
	ctx.r[10].s64 = ctx.r[10].s64 + -29900;
	// 8280F6AC: D3C10640  stfs f30, 0x640(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1600 as u32), tmp.u32 ) };
	// 8280F6B0: D3E10644  stfs f31, 0x644(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1604 as u32), tmp.u32 ) };
	// 8280F6B4: 9BE1064C  stb r31, 0x64c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1612 as u32), ctx.r[31].u8 ) };
	// 8280F6B8: D3E10648  stfs f31, 0x648(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1608 as u32), tmp.u32 ) };
	// 8280F6BC: 91410634  stw r10, 0x634(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1588 as u32), ctx.r[10].u32 ) };
	// 8280F6C0: 38610650  addi r3, r1, 0x650
	ctx.r[3].s64 = ctx.r[1].s64 + 1616;
	// 8280F6C4: 816BF48C  lwz r11, -0xb74(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2932 as u32) ) } as u64;
	// 8280F6C8: 91610630  stw r11, 0x630(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1584 as u32), ctx.r[11].u32 ) };
	// 8280F6CC: 485EF1FD  bl 0x82dfe8c8
	ctx.lr = 0x8280F6D0;
	sub_82DFE8C8(ctx, base);
	// 8280F6D0: 38610658  addi r3, r1, 0x658
	ctx.r[3].s64 = ctx.r[1].s64 + 1624;
	// 8280F6D4: 485EF1F5  bl 0x82dfe8c8
	ctx.lr = 0x8280F6D8;
	sub_82DFE8C8(ctx, base);
	// 8280F6D8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F6DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F6E0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F6E4: D0010668  stfs f0, 0x668(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1640 as u32), tmp.u32 ) };
	// 8280F6E8: 93C1066C  stw r30, 0x66c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1644 as u32), ctx.r[30].u32 ) };
	// 8280F6EC: 394A8B20  addi r10, r10, -0x74e0
	ctx.r[10].s64 = ctx.r[10].s64 + -29920;
	// 8280F6F0: D3C10670  stfs f30, 0x670(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1648 as u32), tmp.u32 ) };
	// 8280F6F4: D3E10674  stfs f31, 0x674(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1652 as u32), tmp.u32 ) };
	// 8280F6F8: 9BE1067C  stb r31, 0x67c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1660 as u32), ctx.r[31].u8 ) };
	// 8280F6FC: D3E10678  stfs f31, 0x678(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1656 as u32), tmp.u32 ) };
	// 8280F700: 91410664  stw r10, 0x664(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1636 as u32), ctx.r[10].u32 ) };
	// 8280F704: 38610680  addi r3, r1, 0x680
	ctx.r[3].s64 = ctx.r[1].s64 + 1664;
	// 8280F708: 816BF490  lwz r11, -0xb70(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2928 as u32) ) } as u64;
	// 8280F70C: 91610660  stw r11, 0x660(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1632 as u32), ctx.r[11].u32 ) };
	// 8280F710: 485EF1B9  bl 0x82dfe8c8
	ctx.lr = 0x8280F714;
	sub_82DFE8C8(ctx, base);
	// 8280F714: 38610688  addi r3, r1, 0x688
	ctx.r[3].s64 = ctx.r[1].s64 + 1672;
	// 8280F718: 485EF1B1  bl 0x82dfe8c8
	ctx.lr = 0x8280F71C;
	sub_82DFE8C8(ctx, base);
	// 8280F71C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F720: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F724: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F728: D0010698  stfs f0, 0x698(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1688 as u32), tmp.u32 ) };
	// 8280F72C: 93C1069C  stw r30, 0x69c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1692 as u32), ctx.r[30].u32 ) };
	// 8280F730: 394A8B0C  addi r10, r10, -0x74f4
	ctx.r[10].s64 = ctx.r[10].s64 + -29940;
	// 8280F734: D3C106A0  stfs f30, 0x6a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1696 as u32), tmp.u32 ) };
	// 8280F738: D3E106A4  stfs f31, 0x6a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1700 as u32), tmp.u32 ) };
	// 8280F73C: 9BE106AC  stb r31, 0x6ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1708 as u32), ctx.r[31].u8 ) };
	// 8280F740: D3E106A8  stfs f31, 0x6a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1704 as u32), tmp.u32 ) };
	// 8280F744: 91410694  stw r10, 0x694(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1684 as u32), ctx.r[10].u32 ) };
	// 8280F748: 386106B0  addi r3, r1, 0x6b0
	ctx.r[3].s64 = ctx.r[1].s64 + 1712;
	// 8280F74C: 816BF494  lwz r11, -0xb6c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2924 as u32) ) } as u64;
	// 8280F750: 91610690  stw r11, 0x690(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1680 as u32), ctx.r[11].u32 ) };
	// 8280F754: 485EF175  bl 0x82dfe8c8
	ctx.lr = 0x8280F758;
	sub_82DFE8C8(ctx, base);
	// 8280F758: 386106B8  addi r3, r1, 0x6b8
	ctx.r[3].s64 = ctx.r[1].s64 + 1720;
	// 8280F75C: 485EF16D  bl 0x82dfe8c8
	ctx.lr = 0x8280F760;
	sub_82DFE8C8(ctx, base);
	// 8280F760: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F764: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F768: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F76C: D00106C8  stfs f0, 0x6c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1736 as u32), tmp.u32 ) };
	// 8280F770: 93C106CC  stw r30, 0x6cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1740 as u32), ctx.r[30].u32 ) };
	// 8280F774: 394A8AF8  addi r10, r10, -0x7508
	ctx.r[10].s64 = ctx.r[10].s64 + -29960;
	// 8280F778: D3C106D0  stfs f30, 0x6d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1744 as u32), tmp.u32 ) };
	// 8280F77C: D3E106D4  stfs f31, 0x6d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1748 as u32), tmp.u32 ) };
	// 8280F780: 9BE106DC  stb r31, 0x6dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1756 as u32), ctx.r[31].u8 ) };
	// 8280F784: D3E106D8  stfs f31, 0x6d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1752 as u32), tmp.u32 ) };
	// 8280F788: 914106C4  stw r10, 0x6c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1732 as u32), ctx.r[10].u32 ) };
	// 8280F78C: 386106E0  addi r3, r1, 0x6e0
	ctx.r[3].s64 = ctx.r[1].s64 + 1760;
	// 8280F790: 816BF498  lwz r11, -0xb68(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2920 as u32) ) } as u64;
	// 8280F794: 916106C0  stw r11, 0x6c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1728 as u32), ctx.r[11].u32 ) };
	// 8280F798: 485EF131  bl 0x82dfe8c8
	ctx.lr = 0x8280F79C;
	sub_82DFE8C8(ctx, base);
	// 8280F79C: 386106E8  addi r3, r1, 0x6e8
	ctx.r[3].s64 = ctx.r[1].s64 + 1768;
	// 8280F7A0: 485EF129  bl 0x82dfe8c8
	ctx.lr = 0x8280F7A4;
	sub_82DFE8C8(ctx, base);
	// 8280F7A4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F7A8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F7AC: 93C106FC  stw r30, 0x6fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1788 as u32), ctx.r[30].u32 ) };
	// 8280F7B0: D00106F8  stfs f0, 0x6f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1784 as u32), tmp.u32 ) };
	// 8280F7B4: 930106F4  stw r24, 0x6f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1780 as u32), ctx.r[24].u32 ) };
	// 8280F7B8: D3C10700  stfs f30, 0x700(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1792 as u32), tmp.u32 ) };
	// 8280F7BC: 9BE1070C  stb r31, 0x70c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1804 as u32), ctx.r[31].u8 ) };
	// 8280F7C0: D3E10704  stfs f31, 0x704(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1796 as u32), tmp.u32 ) };
	// 8280F7C4: 38610710  addi r3, r1, 0x710
	ctx.r[3].s64 = ctx.r[1].s64 + 1808;
	// 8280F7C8: D3E10708  stfs f31, 0x708(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1800 as u32), tmp.u32 ) };
	// 8280F7CC: 816BF49C  lwz r11, -0xb64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2916 as u32) ) } as u64;
	// 8280F7D0: 916106F0  stw r11, 0x6f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1776 as u32), ctx.r[11].u32 ) };
	// 8280F7D4: 485EF0F5  bl 0x82dfe8c8
	ctx.lr = 0x8280F7D8;
	sub_82DFE8C8(ctx, base);
	// 8280F7D8: 38610718  addi r3, r1, 0x718
	ctx.r[3].s64 = ctx.r[1].s64 + 1816;
	// 8280F7DC: 485EF0ED  bl 0x82dfe8c8
	ctx.lr = 0x8280F7E0;
	sub_82DFE8C8(ctx, base);
	// 8280F7E0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F7E4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F7E8: 93C1072C  stw r30, 0x72c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1836 as u32), ctx.r[30].u32 ) };
	// 8280F7EC: D0010728  stfs f0, 0x728(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1832 as u32), tmp.u32 ) };
	// 8280F7F0: 93810724  stw r28, 0x724(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1828 as u32), ctx.r[28].u32 ) };
	// 8280F7F4: D3C10730  stfs f30, 0x730(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1840 as u32), tmp.u32 ) };
	// 8280F7F8: 9BE1073C  stb r31, 0x73c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1852 as u32), ctx.r[31].u8 ) };
	// 8280F7FC: D3E10734  stfs f31, 0x734(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1844 as u32), tmp.u32 ) };
	// 8280F800: 38610740  addi r3, r1, 0x740
	ctx.r[3].s64 = ctx.r[1].s64 + 1856;
	// 8280F804: D3E10738  stfs f31, 0x738(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1848 as u32), tmp.u32 ) };
	// 8280F808: 816BF46C  lwz r11, -0xb94(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2964 as u32) ) } as u64;
	// 8280F80C: 91610720  stw r11, 0x720(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1824 as u32), ctx.r[11].u32 ) };
	// 8280F810: 485EF0B9  bl 0x82dfe8c8
	ctx.lr = 0x8280F814;
	sub_82DFE8C8(ctx, base);
	// 8280F814: 38610748  addi r3, r1, 0x748
	ctx.r[3].s64 = ctx.r[1].s64 + 1864;
	// 8280F818: 485EF0B1  bl 0x82dfe8c8
	ctx.lr = 0x8280F81C;
	sub_82DFE8C8(ctx, base);
	// 8280F81C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F820: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F824: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F828: D0010758  stfs f0, 0x758(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1880 as u32), tmp.u32 ) };
	// 8280F82C: 93E1075C  stw r31, 0x75c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1884 as u32), ctx.r[31].u32 ) };
	// 8280F830: 394A8AEC  addi r10, r10, -0x7514
	ctx.r[10].s64 = ctx.r[10].s64 + -29972;
	// 8280F834: D3C10760  stfs f30, 0x760(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1888 as u32), tmp.u32 ) };
	// 8280F838: D3E10764  stfs f31, 0x764(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1892 as u32), tmp.u32 ) };
	// 8280F83C: 9BE1076C  stb r31, 0x76c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1900 as u32), ctx.r[31].u8 ) };
	// 8280F840: D3E10768  stfs f31, 0x768(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1896 as u32), tmp.u32 ) };
	// 8280F844: 91410754  stw r10, 0x754(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1876 as u32), ctx.r[10].u32 ) };
	// 8280F848: 38610770  addi r3, r1, 0x770
	ctx.r[3].s64 = ctx.r[1].s64 + 1904;
	// 8280F84C: 816BF470  lwz r11, -0xb90(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2960 as u32) ) } as u64;
	// 8280F850: 91610750  stw r11, 0x750(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1872 as u32), ctx.r[11].u32 ) };
	// 8280F854: 485EF075  bl 0x82dfe8c8
	ctx.lr = 0x8280F858;
	sub_82DFE8C8(ctx, base);
	// 8280F858: 38610778  addi r3, r1, 0x778
	ctx.r[3].s64 = ctx.r[1].s64 + 1912;
	// 8280F85C: 485EF06D  bl 0x82dfe8c8
	ctx.lr = 0x8280F860;
	sub_82DFE8C8(ctx, base);
	// 8280F860: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F864: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F868: 93C1078C  stw r30, 0x78c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1932 as u32), ctx.r[30].u32 ) };
	// 8280F86C: D0010788  stfs f0, 0x788(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1928 as u32), tmp.u32 ) };
	// 8280F870: 93810784  stw r28, 0x784(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1924 as u32), ctx.r[28].u32 ) };
	// 8280F874: D3C10790  stfs f30, 0x790(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1936 as u32), tmp.u32 ) };
	// 8280F878: 9BE1079C  stb r31, 0x79c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1948 as u32), ctx.r[31].u8 ) };
	// 8280F87C: D3E10794  stfs f31, 0x794(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1940 as u32), tmp.u32 ) };
	// 8280F880: 386107A0  addi r3, r1, 0x7a0
	ctx.r[3].s64 = ctx.r[1].s64 + 1952;
	// 8280F884: D3E10798  stfs f31, 0x798(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1944 as u32), tmp.u32 ) };
	// 8280F888: 816BF474  lwz r11, -0xb8c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2956 as u32) ) } as u64;
	// 8280F88C: 91610780  stw r11, 0x780(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1920 as u32), ctx.r[11].u32 ) };
	// 8280F890: 485EF039  bl 0x82dfe8c8
	ctx.lr = 0x8280F894;
	sub_82DFE8C8(ctx, base);
	// 8280F894: 386107A8  addi r3, r1, 0x7a8
	ctx.r[3].s64 = ctx.r[1].s64 + 1960;
	// 8280F898: 485EF031  bl 0x82dfe8c8
	ctx.lr = 0x8280F89C;
	sub_82DFE8C8(ctx, base);
	// 8280F89C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F8A0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F8A4: 93C107BC  stw r30, 0x7bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1980 as u32), ctx.r[30].u32 ) };
	// 8280F8A8: D00107B8  stfs f0, 0x7b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1976 as u32), tmp.u32 ) };
	// 8280F8AC: 938107B4  stw r28, 0x7b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1972 as u32), ctx.r[28].u32 ) };
	// 8280F8B0: D3C107C0  stfs f30, 0x7c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1984 as u32), tmp.u32 ) };
	// 8280F8B4: 9BE107CC  stb r31, 0x7cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1996 as u32), ctx.r[31].u8 ) };
	// 8280F8B8: D3E107C4  stfs f31, 0x7c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1988 as u32), tmp.u32 ) };
	// 8280F8BC: 386107D0  addi r3, r1, 0x7d0
	ctx.r[3].s64 = ctx.r[1].s64 + 2000;
	// 8280F8C0: D3E107C8  stfs f31, 0x7c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1992 as u32), tmp.u32 ) };
	// 8280F8C4: 816BF478  lwz r11, -0xb88(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2952 as u32) ) } as u64;
	// 8280F8C8: 916107B0  stw r11, 0x7b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1968 as u32), ctx.r[11].u32 ) };
	// 8280F8CC: 485EEFFD  bl 0x82dfe8c8
	ctx.lr = 0x8280F8D0;
	sub_82DFE8C8(ctx, base);
	// 8280F8D0: 386107D8  addi r3, r1, 0x7d8
	ctx.r[3].s64 = ctx.r[1].s64 + 2008;
	// 8280F8D4: 485EEFF5  bl 0x82dfe8c8
	ctx.lr = 0x8280F8D8;
	sub_82DFE8C8(ctx, base);
	// 8280F8D8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F8DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F8E0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F8E4: D00107E8  stfs f0, 0x7e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2024 as u32), tmp.u32 ) };
	// 8280F8E8: 93E107EC  stw r31, 0x7ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2028 as u32), ctx.r[31].u32 ) };
	// 8280F8EC: 394A8AD8  addi r10, r10, -0x7528
	ctx.r[10].s64 = ctx.r[10].s64 + -29992;
	// 8280F8F0: D3C107F0  stfs f30, 0x7f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2032 as u32), tmp.u32 ) };
	// 8280F8F4: D3E107F4  stfs f31, 0x7f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2036 as u32), tmp.u32 ) };
	// 8280F8F8: 9BE107FC  stb r31, 0x7fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2044 as u32), ctx.r[31].u8 ) };
	// 8280F8FC: D3E107F8  stfs f31, 0x7f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2040 as u32), tmp.u32 ) };
	// 8280F900: 914107E4  stw r10, 0x7e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2020 as u32), ctx.r[10].u32 ) };
	// 8280F904: 38610800  addi r3, r1, 0x800
	ctx.r[3].s64 = ctx.r[1].s64 + 2048;
	// 8280F908: 816BF468  lwz r11, -0xb98(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2968 as u32) ) } as u64;
	// 8280F90C: 916107E0  stw r11, 0x7e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2016 as u32), ctx.r[11].u32 ) };
	// 8280F910: 485EEFB9  bl 0x82dfe8c8
	ctx.lr = 0x8280F914;
	sub_82DFE8C8(ctx, base);
	// 8280F914: 38610808  addi r3, r1, 0x808
	ctx.r[3].s64 = ctx.r[1].s64 + 2056;
	// 8280F918: 485EEFB1  bl 0x82dfe8c8
	ctx.lr = 0x8280F91C;
	sub_82DFE8C8(ctx, base);
	// 8280F91C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F920: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F924: 93C1081C  stw r30, 0x81c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2076 as u32), ctx.r[30].u32 ) };
	// 8280F928: D0010818  stfs f0, 0x818(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2072 as u32), tmp.u32 ) };
	// 8280F92C: 93810814  stw r28, 0x814(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2068 as u32), ctx.r[28].u32 ) };
	// 8280F930: D3C10820  stfs f30, 0x820(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2080 as u32), tmp.u32 ) };
	// 8280F934: 9BE1082C  stb r31, 0x82c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2092 as u32), ctx.r[31].u8 ) };
	// 8280F938: D3E10824  stfs f31, 0x824(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2084 as u32), tmp.u32 ) };
	// 8280F93C: 38610830  addi r3, r1, 0x830
	ctx.r[3].s64 = ctx.r[1].s64 + 2096;
	// 8280F940: D3E10828  stfs f31, 0x828(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2088 as u32), tmp.u32 ) };
	// 8280F944: 816BF47C  lwz r11, -0xb84(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2948 as u32) ) } as u64;
	// 8280F948: 91610810  stw r11, 0x810(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2064 as u32), ctx.r[11].u32 ) };
	// 8280F94C: 485EEF7D  bl 0x82dfe8c8
	ctx.lr = 0x8280F950;
	sub_82DFE8C8(ctx, base);
	// 8280F950: 38610838  addi r3, r1, 0x838
	ctx.r[3].s64 = ctx.r[1].s64 + 2104;
	// 8280F954: 485EEF75  bl 0x82dfe8c8
	ctx.lr = 0x8280F958;
	sub_82DFE8C8(ctx, base);
	// 8280F958: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F95C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F960: 93C1084C  stw r30, 0x84c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2124 as u32), ctx.r[30].u32 ) };
	// 8280F964: D0010848  stfs f0, 0x848(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2120 as u32), tmp.u32 ) };
	// 8280F968: 93810844  stw r28, 0x844(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2116 as u32), ctx.r[28].u32 ) };
	// 8280F96C: D3C10850  stfs f30, 0x850(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2128 as u32), tmp.u32 ) };
	// 8280F970: 9BE1085C  stb r31, 0x85c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2140 as u32), ctx.r[31].u8 ) };
	// 8280F974: D3E10854  stfs f31, 0x854(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2132 as u32), tmp.u32 ) };
	// 8280F978: 38610860  addi r3, r1, 0x860
	ctx.r[3].s64 = ctx.r[1].s64 + 2144;
	// 8280F97C: D3E10858  stfs f31, 0x858(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2136 as u32), tmp.u32 ) };
	// 8280F980: 816BF480  lwz r11, -0xb80(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2944 as u32) ) } as u64;
	// 8280F984: 91610840  stw r11, 0x840(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2112 as u32), ctx.r[11].u32 ) };
	// 8280F988: 485EEF41  bl 0x82dfe8c8
	ctx.lr = 0x8280F98C;
	sub_82DFE8C8(ctx, base);
	// 8280F98C: 38610868  addi r3, r1, 0x868
	ctx.r[3].s64 = ctx.r[1].s64 + 2152;
	// 8280F990: 485EEF39  bl 0x82dfe8c8
	ctx.lr = 0x8280F994;
	sub_82DFE8C8(ctx, base);
	// 8280F994: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F998: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F99C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F9A0: 816BF45C  lwz r11, -0xba4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2980 as u32) ) } as u64;
	// 8280F9A4: 394A8AC4  addi r10, r10, -0x753c
	ctx.r[10].s64 = ctx.r[10].s64 + -30012;
	// 8280F9A8: D0010878  stfs f0, 0x878(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2168 as u32), tmp.u32 ) };
	// 8280F9AC: 93C1087C  stw r30, 0x87c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2172 as u32), ctx.r[30].u32 ) };
	// 8280F9B0: D3C10880  stfs f30, 0x880(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2176 as u32), tmp.u32 ) };
	// 8280F9B4: 9BE1088C  stb r31, 0x88c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2188 as u32), ctx.r[31].u8 ) };
	// 8280F9B8: D3E10884  stfs f31, 0x884(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2180 as u32), tmp.u32 ) };
	// 8280F9BC: 91410874  stw r10, 0x874(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2164 as u32), ctx.r[10].u32 ) };
	// 8280F9C0: D3E10888  stfs f31, 0x888(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2184 as u32), tmp.u32 ) };
	// 8280F9C4: 38610890  addi r3, r1, 0x890
	ctx.r[3].s64 = ctx.r[1].s64 + 2192;
	// 8280F9C8: 91610870  stw r11, 0x870(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2160 as u32), ctx.r[11].u32 ) };
	// 8280F9CC: 485EEEFD  bl 0x82dfe8c8
	ctx.lr = 0x8280F9D0;
	sub_82DFE8C8(ctx, base);
	// 8280F9D0: 38610898  addi r3, r1, 0x898
	ctx.r[3].s64 = ctx.r[1].s64 + 2200;
	// 8280F9D4: 485EEEF5  bl 0x82dfe8c8
	ctx.lr = 0x8280F9D8;
	sub_82DFE8C8(ctx, base);
	// 8280F9D8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280F9DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280F9E0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280F9E4: D00108A8  stfs f0, 0x8a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2216 as u32), tmp.u32 ) };
	// 8280F9E8: 93C108AC  stw r30, 0x8ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2220 as u32), ctx.r[30].u32 ) };
	// 8280F9EC: 394A8AB0  addi r10, r10, -0x7550
	ctx.r[10].s64 = ctx.r[10].s64 + -30032;
	// 8280F9F0: D3C108B0  stfs f30, 0x8b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2224 as u32), tmp.u32 ) };
	// 8280F9F4: D3E108B4  stfs f31, 0x8b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2228 as u32), tmp.u32 ) };
	// 8280F9F8: 9BE108BC  stb r31, 0x8bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2236 as u32), ctx.r[31].u8 ) };
	// 8280F9FC: D3E108B8  stfs f31, 0x8b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2232 as u32), tmp.u32 ) };
	// 8280FA00: 914108A4  stw r10, 0x8a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2212 as u32), ctx.r[10].u32 ) };
	// 8280FA04: 386108C0  addi r3, r1, 0x8c0
	ctx.r[3].s64 = ctx.r[1].s64 + 2240;
	// 8280FA08: 816BF460  lwz r11, -0xba0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2976 as u32) ) } as u64;
	// 8280FA0C: 916108A0  stw r11, 0x8a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2208 as u32), ctx.r[11].u32 ) };
	// 8280FA10: 485EEEB9  bl 0x82dfe8c8
	ctx.lr = 0x8280FA14;
	sub_82DFE8C8(ctx, base);
	// 8280FA14: 386108C8  addi r3, r1, 0x8c8
	ctx.r[3].s64 = ctx.r[1].s64 + 2248;
	// 8280FA18: 485EEEB1  bl 0x82dfe8c8
	ctx.lr = 0x8280FA1C;
	sub_82DFE8C8(ctx, base);
	// 8280FA1C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FA20: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FA24: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FA28: D00108D8  stfs f0, 0x8d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2264 as u32), tmp.u32 ) };
	// 8280FA2C: 93C108DC  stw r30, 0x8dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2268 as u32), ctx.r[30].u32 ) };
	// 8280FA30: 394A8AA0  addi r10, r10, -0x7560
	ctx.r[10].s64 = ctx.r[10].s64 + -30048;
	// 8280FA34: D3C108E0  stfs f30, 0x8e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2272 as u32), tmp.u32 ) };
	// 8280FA38: D3E108E4  stfs f31, 0x8e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2276 as u32), tmp.u32 ) };
	// 8280FA3C: 9BE108EC  stb r31, 0x8ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2284 as u32), ctx.r[31].u8 ) };
	// 8280FA40: D3E108E8  stfs f31, 0x8e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2280 as u32), tmp.u32 ) };
	// 8280FA44: 914108D4  stw r10, 0x8d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2260 as u32), ctx.r[10].u32 ) };
	// 8280FA48: 386108F0  addi r3, r1, 0x8f0
	ctx.r[3].s64 = ctx.r[1].s64 + 2288;
	// 8280FA4C: 816BF424  lwz r11, -0xbdc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3036 as u32) ) } as u64;
	// 8280FA50: 916108D0  stw r11, 0x8d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2256 as u32), ctx.r[11].u32 ) };
	// 8280FA54: 485EEE75  bl 0x82dfe8c8
	ctx.lr = 0x8280FA58;
	sub_82DFE8C8(ctx, base);
	// 8280FA58: 386108F8  addi r3, r1, 0x8f8
	ctx.r[3].s64 = ctx.r[1].s64 + 2296;
	// 8280FA5C: 485EEE6D  bl 0x82dfe8c8
	ctx.lr = 0x8280FA60;
	sub_82DFE8C8(ctx, base);
	// 8280FA60: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FA64: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FA68: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FA6C: D0010908  stfs f0, 0x908(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2312 as u32), tmp.u32 ) };
	// 8280FA70: 93C1090C  stw r30, 0x90c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2316 as u32), ctx.r[30].u32 ) };
	// 8280FA74: 394A8A8C  addi r10, r10, -0x7574
	ctx.r[10].s64 = ctx.r[10].s64 + -30068;
	// 8280FA78: D3C10910  stfs f30, 0x910(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2320 as u32), tmp.u32 ) };
	// 8280FA7C: D3E10914  stfs f31, 0x914(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2324 as u32), tmp.u32 ) };
	// 8280FA80: 9BE1091C  stb r31, 0x91c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2332 as u32), ctx.r[31].u8 ) };
	// 8280FA84: D3E10918  stfs f31, 0x918(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2328 as u32), tmp.u32 ) };
	// 8280FA88: 91410904  stw r10, 0x904(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2308 as u32), ctx.r[10].u32 ) };
	// 8280FA8C: 38610920  addi r3, r1, 0x920
	ctx.r[3].s64 = ctx.r[1].s64 + 2336;
	// 8280FA90: 816BF428  lwz r11, -0xbd8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3032 as u32) ) } as u64;
	// 8280FA94: 91610900  stw r11, 0x900(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2304 as u32), ctx.r[11].u32 ) };
	// 8280FA98: 485EEE31  bl 0x82dfe8c8
	ctx.lr = 0x8280FA9C;
	sub_82DFE8C8(ctx, base);
	// 8280FA9C: 38610928  addi r3, r1, 0x928
	ctx.r[3].s64 = ctx.r[1].s64 + 2344;
	// 8280FAA0: 485EEE29  bl 0x82dfe8c8
	ctx.lr = 0x8280FAA4;
	sub_82DFE8C8(ctx, base);
	// 8280FAA4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FAA8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FAAC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FAB0: D0010938  stfs f0, 0x938(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2360 as u32), tmp.u32 ) };
	// 8280FAB4: 93E1093C  stw r31, 0x93c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2364 as u32), ctx.r[31].u32 ) };
	// 8280FAB8: 394A8A74  addi r10, r10, -0x758c
	ctx.r[10].s64 = ctx.r[10].s64 + -30092;
	// 8280FABC: D3C10940  stfs f30, 0x940(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2368 as u32), tmp.u32 ) };
	// 8280FAC0: D3E10944  stfs f31, 0x944(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2372 as u32), tmp.u32 ) };
	// 8280FAC4: 9BE1094C  stb r31, 0x94c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2380 as u32), ctx.r[31].u8 ) };
	// 8280FAC8: D3E10948  stfs f31, 0x948(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2376 as u32), tmp.u32 ) };
	// 8280FACC: 91410934  stw r10, 0x934(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2356 as u32), ctx.r[10].u32 ) };
	// 8280FAD0: 38610950  addi r3, r1, 0x950
	ctx.r[3].s64 = ctx.r[1].s64 + 2384;
	// 8280FAD4: 816BF42C  lwz r11, -0xbd4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3028 as u32) ) } as u64;
	// 8280FAD8: 91610930  stw r11, 0x930(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2352 as u32), ctx.r[11].u32 ) };
	// 8280FADC: 485EEDED  bl 0x82dfe8c8
	ctx.lr = 0x8280FAE0;
	sub_82DFE8C8(ctx, base);
	// 8280FAE0: 38610958  addi r3, r1, 0x958
	ctx.r[3].s64 = ctx.r[1].s64 + 2392;
	// 8280FAE4: 485EEDE5  bl 0x82dfe8c8
	ctx.lr = 0x8280FAE8;
	sub_82DFE8C8(ctx, base);
	// 8280FAE8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FAEC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FAF0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FAF4: D0010968  stfs f0, 0x968(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2408 as u32), tmp.u32 ) };
	// 8280FAF8: 93C1096C  stw r30, 0x96c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2412 as u32), ctx.r[30].u32 ) };
	// 8280FAFC: 394A8A60  addi r10, r10, -0x75a0
	ctx.r[10].s64 = ctx.r[10].s64 + -30112;
	// 8280FB00: D3C10970  stfs f30, 0x970(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2416 as u32), tmp.u32 ) };
	// 8280FB04: D3E10974  stfs f31, 0x974(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2420 as u32), tmp.u32 ) };
	// 8280FB08: 9BE1097C  stb r31, 0x97c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2428 as u32), ctx.r[31].u8 ) };
	// 8280FB0C: D3E10978  stfs f31, 0x978(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2424 as u32), tmp.u32 ) };
	// 8280FB10: 91410964  stw r10, 0x964(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2404 as u32), ctx.r[10].u32 ) };
	// 8280FB14: 38610980  addi r3, r1, 0x980
	ctx.r[3].s64 = ctx.r[1].s64 + 2432;
	// 8280FB18: 816BF444  lwz r11, -0xbbc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3004 as u32) ) } as u64;
	// 8280FB1C: 91610960  stw r11, 0x960(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2400 as u32), ctx.r[11].u32 ) };
	// 8280FB20: 485EEDA9  bl 0x82dfe8c8
	ctx.lr = 0x8280FB24;
	sub_82DFE8C8(ctx, base);
	// 8280FB24: 38610988  addi r3, r1, 0x988
	ctx.r[3].s64 = ctx.r[1].s64 + 2440;
	// 8280FB28: 485EEDA1  bl 0x82dfe8c8
	ctx.lr = 0x8280FB2C;
	sub_82DFE8C8(ctx, base);
	// 8280FB2C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FB30: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FB34: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FB38: D0010998  stfs f0, 0x998(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2456 as u32), tmp.u32 ) };
	// 8280FB3C: 93C1099C  stw r30, 0x99c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2460 as u32), ctx.r[30].u32 ) };
	// 8280FB40: 394A8A44  addi r10, r10, -0x75bc
	ctx.r[10].s64 = ctx.r[10].s64 + -30140;
	// 8280FB44: D3C109A0  stfs f30, 0x9a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2464 as u32), tmp.u32 ) };
	// 8280FB48: D3E109A4  stfs f31, 0x9a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2468 as u32), tmp.u32 ) };
	// 8280FB4C: 9BE109AC  stb r31, 0x9ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2476 as u32), ctx.r[31].u8 ) };
	// 8280FB50: D3E109A8  stfs f31, 0x9a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2472 as u32), tmp.u32 ) };
	// 8280FB54: 91410994  stw r10, 0x994(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2452 as u32), ctx.r[10].u32 ) };
	// 8280FB58: 386109B0  addi r3, r1, 0x9b0
	ctx.r[3].s64 = ctx.r[1].s64 + 2480;
	// 8280FB5C: 816BF448  lwz r11, -0xbb8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3000 as u32) ) } as u64;
	// 8280FB60: 91610990  stw r11, 0x990(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2448 as u32), ctx.r[11].u32 ) };
	// 8280FB64: 485EED65  bl 0x82dfe8c8
	ctx.lr = 0x8280FB68;
	sub_82DFE8C8(ctx, base);
	// 8280FB68: 386109B8  addi r3, r1, 0x9b8
	ctx.r[3].s64 = ctx.r[1].s64 + 2488;
	// 8280FB6C: 485EED5D  bl 0x82dfe8c8
	ctx.lr = 0x8280FB70;
	sub_82DFE8C8(ctx, base);
	// 8280FB70: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FB74: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FB78: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FB7C: D00109C8  stfs f0, 0x9c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2504 as u32), tmp.u32 ) };
	// 8280FB80: 93C109CC  stw r30, 0x9cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2508 as u32), ctx.r[30].u32 ) };
	// 8280FB84: 394A8A2C  addi r10, r10, -0x75d4
	ctx.r[10].s64 = ctx.r[10].s64 + -30164;
	// 8280FB88: D3C109D0  stfs f30, 0x9d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2512 as u32), tmp.u32 ) };
	// 8280FB8C: D3E109D4  stfs f31, 0x9d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2516 as u32), tmp.u32 ) };
	// 8280FB90: 9BE109DC  stb r31, 0x9dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2524 as u32), ctx.r[31].u8 ) };
	// 8280FB94: D3E109D8  stfs f31, 0x9d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2520 as u32), tmp.u32 ) };
	// 8280FB98: 914109C4  stw r10, 0x9c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2500 as u32), ctx.r[10].u32 ) };
	// 8280FB9C: 386109E0  addi r3, r1, 0x9e0
	ctx.r[3].s64 = ctx.r[1].s64 + 2528;
	// 8280FBA0: 816BF430  lwz r11, -0xbd0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3024 as u32) ) } as u64;
	// 8280FBA4: 916109C0  stw r11, 0x9c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2496 as u32), ctx.r[11].u32 ) };
	// 8280FBA8: 485EED21  bl 0x82dfe8c8
	ctx.lr = 0x8280FBAC;
	sub_82DFE8C8(ctx, base);
	// 8280FBAC: 386109E8  addi r3, r1, 0x9e8
	ctx.r[3].s64 = ctx.r[1].s64 + 2536;
	// 8280FBB0: 485EED19  bl 0x82dfe8c8
	ctx.lr = 0x8280FBB4;
	sub_82DFE8C8(ctx, base);
	// 8280FBB4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FBB8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FBBC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FBC0: D00109F8  stfs f0, 0x9f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2552 as u32), tmp.u32 ) };
	// 8280FBC4: 93E109FC  stw r31, 0x9fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2556 as u32), ctx.r[31].u32 ) };
	// 8280FBC8: 394A8A18  addi r10, r10, -0x75e8
	ctx.r[10].s64 = ctx.r[10].s64 + -30184;
	// 8280FBCC: D3C10A00  stfs f30, 0xa00(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2560 as u32), tmp.u32 ) };
	// 8280FBD0: D3E10A04  stfs f31, 0xa04(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2564 as u32), tmp.u32 ) };
	// 8280FBD4: 9BE10A0C  stb r31, 0xa0c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2572 as u32), ctx.r[31].u8 ) };
	// 8280FBD8: D3E10A08  stfs f31, 0xa08(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2568 as u32), tmp.u32 ) };
	// 8280FBDC: 914109F4  stw r10, 0x9f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2548 as u32), ctx.r[10].u32 ) };
	// 8280FBE0: 38610A10  addi r3, r1, 0xa10
	ctx.r[3].s64 = ctx.r[1].s64 + 2576;
	// 8280FBE4: 816BF434  lwz r11, -0xbcc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3020 as u32) ) } as u64;
	// 8280FBE8: 916109F0  stw r11, 0x9f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2544 as u32), ctx.r[11].u32 ) };
	// 8280FBEC: 485EECDD  bl 0x82dfe8c8
	ctx.lr = 0x8280FBF0;
	sub_82DFE8C8(ctx, base);
	// 8280FBF0: 38610A18  addi r3, r1, 0xa18
	ctx.r[3].s64 = ctx.r[1].s64 + 2584;
	// 8280FBF4: 485EECD5  bl 0x82dfe8c8
	ctx.lr = 0x8280FBF8;
	sub_82DFE8C8(ctx, base);
	// 8280FBF8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FBFC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FC00: 93C10A2C  stw r30, 0xa2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2604 as u32), ctx.r[30].u32 ) };
	// 8280FC04: D0010A28  stfs f0, 0xa28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2600 as u32), tmp.u32 ) };
	// 8280FC08: 93810A24  stw r28, 0xa24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2596 as u32), ctx.r[28].u32 ) };
	// 8280FC0C: D3C10A30  stfs f30, 0xa30(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2608 as u32), tmp.u32 ) };
	// 8280FC10: 9BE10A3C  stb r31, 0xa3c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2620 as u32), ctx.r[31].u8 ) };
	// 8280FC14: D3E10A34  stfs f31, 0xa34(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2612 as u32), tmp.u32 ) };
	// 8280FC18: 38610A40  addi r3, r1, 0xa40
	ctx.r[3].s64 = ctx.r[1].s64 + 2624;
	// 8280FC1C: D3E10A38  stfs f31, 0xa38(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2616 as u32), tmp.u32 ) };
	// 8280FC20: 816BF438  lwz r11, -0xbc8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3016 as u32) ) } as u64;
	// 8280FC24: 91610A20  stw r11, 0xa20(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2592 as u32), ctx.r[11].u32 ) };
	// 8280FC28: 485EECA1  bl 0x82dfe8c8
	ctx.lr = 0x8280FC2C;
	sub_82DFE8C8(ctx, base);
	// 8280FC2C: 38610A48  addi r3, r1, 0xa48
	ctx.r[3].s64 = ctx.r[1].s64 + 2632;
	// 8280FC30: 485EEC99  bl 0x82dfe8c8
	ctx.lr = 0x8280FC34;
	sub_82DFE8C8(ctx, base);
	// 8280FC34: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FC38: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FC3C: 93C10A5C  stw r30, 0xa5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2652 as u32), ctx.r[30].u32 ) };
	// 8280FC40: D0010A58  stfs f0, 0xa58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2648 as u32), tmp.u32 ) };
	// 8280FC44: 93810A54  stw r28, 0xa54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2644 as u32), ctx.r[28].u32 ) };
	// 8280FC48: D3C10A60  stfs f30, 0xa60(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2656 as u32), tmp.u32 ) };
	// 8280FC4C: 9BE10A6C  stb r31, 0xa6c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2668 as u32), ctx.r[31].u8 ) };
	// 8280FC50: D3E10A64  stfs f31, 0xa64(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2660 as u32), tmp.u32 ) };
	// 8280FC54: 38610A70  addi r3, r1, 0xa70
	ctx.r[3].s64 = ctx.r[1].s64 + 2672;
	// 8280FC58: D3E10A68  stfs f31, 0xa68(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2664 as u32), tmp.u32 ) };
	// 8280FC5C: 816BF43C  lwz r11, -0xbc4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3012 as u32) ) } as u64;
	// 8280FC60: 91610A50  stw r11, 0xa50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2640 as u32), ctx.r[11].u32 ) };
	// 8280FC64: 485EEC65  bl 0x82dfe8c8
	ctx.lr = 0x8280FC68;
	sub_82DFE8C8(ctx, base);
	// 8280FC68: 38610A78  addi r3, r1, 0xa78
	ctx.r[3].s64 = ctx.r[1].s64 + 2680;
	// 8280FC6C: 485EEC5D  bl 0x82dfe8c8
	ctx.lr = 0x8280FC70;
	sub_82DFE8C8(ctx, base);
	// 8280FC70: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FC74: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FC78: 93810A84  stw r28, 0xa84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2692 as u32), ctx.r[28].u32 ) };
	// 8280FC7C: D0010A88  stfs f0, 0xa88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2696 as u32), tmp.u32 ) };
	// 8280FC80: 93C10A8C  stw r30, 0xa8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2700 as u32), ctx.r[30].u32 ) };
	// 8280FC84: D3C10A90  stfs f30, 0xa90(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2704 as u32), tmp.u32 ) };
	// 8280FC88: 9BE10A9C  stb r31, 0xa9c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2716 as u32), ctx.r[31].u8 ) };
	// 8280FC8C: D3E10A94  stfs f31, 0xa94(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2708 as u32), tmp.u32 ) };
	// 8280FC90: 38610AA0  addi r3, r1, 0xaa0
	ctx.r[3].s64 = ctx.r[1].s64 + 2720;
	// 8280FC94: D3E10A98  stfs f31, 0xa98(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2712 as u32), tmp.u32 ) };
	// 8280FC98: 816BF44C  lwz r11, -0xbb4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2996 as u32) ) } as u64;
	// 8280FC9C: 91610A80  stw r11, 0xa80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2688 as u32), ctx.r[11].u32 ) };
	// 8280FCA0: 485EEC29  bl 0x82dfe8c8
	ctx.lr = 0x8280FCA4;
	sub_82DFE8C8(ctx, base);
	// 8280FCA4: 38610AA8  addi r3, r1, 0xaa8
	ctx.r[3].s64 = ctx.r[1].s64 + 2728;
	// 8280FCA8: 485EEC21  bl 0x82dfe8c8
	ctx.lr = 0x8280FCAC;
	sub_82DFE8C8(ctx, base);
	// 8280FCAC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FCB0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8280FCB4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FCB8: D0010AB8  stfs f0, 0xab8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2744 as u32), tmp.u32 ) };
	// 8280FCBC: 93C10ABC  stw r30, 0xabc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2748 as u32), ctx.r[30].u32 ) };
	// 8280FCC0: 394A8A04  addi r10, r10, -0x75fc
	ctx.r[10].s64 = ctx.r[10].s64 + -30204;
	// 8280FCC4: D3C10AC0  stfs f30, 0xac0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2752 as u32), tmp.u32 ) };
	// 8280FCC8: D3E10AC4  stfs f31, 0xac4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2756 as u32), tmp.u32 ) };
	// 8280FCCC: 9BE10ACC  stb r31, 0xacc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2764 as u32), ctx.r[31].u8 ) };
	// 8280FCD0: D3E10AC8  stfs f31, 0xac8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2760 as u32), tmp.u32 ) };
	// 8280FCD4: 91410AB4  stw r10, 0xab4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2740 as u32), ctx.r[10].u32 ) };
	// 8280FCD8: 38610AD0  addi r3, r1, 0xad0
	ctx.r[3].s64 = ctx.r[1].s64 + 2768;
	// 8280FCDC: 816BF454  lwz r11, -0xbac(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2988 as u32) ) } as u64;
	// 8280FCE0: 91610AB0  stw r11, 0xab0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2736 as u32), ctx.r[11].u32 ) };
	// 8280FCE4: 485EEBE5  bl 0x82dfe8c8
	ctx.lr = 0x8280FCE8;
	sub_82DFE8C8(ctx, base);
	// 8280FCE8: 38610AD8  addi r3, r1, 0xad8
	ctx.r[3].s64 = ctx.r[1].s64 + 2776;
	// 8280FCEC: 485EEBDD  bl 0x82dfe8c8
	ctx.lr = 0x8280FCF0;
	sub_82DFE8C8(ctx, base);
	// 8280FCF0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FCF4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FCF8: 93C10AEC  stw r30, 0xaec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2796 as u32), ctx.r[30].u32 ) };
	// 8280FCFC: D0010AE8  stfs f0, 0xae8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2792 as u32), tmp.u32 ) };
	// 8280FD00: 93810AE4  stw r28, 0xae4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2788 as u32), ctx.r[28].u32 ) };
	// 8280FD04: D3C10AF0  stfs f30, 0xaf0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2800 as u32), tmp.u32 ) };
	// 8280FD08: 9BE10AFC  stb r31, 0xafc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2812 as u32), ctx.r[31].u8 ) };
	// 8280FD0C: D3E10AF4  stfs f31, 0xaf4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2804 as u32), tmp.u32 ) };
	// 8280FD10: 38610B00  addi r3, r1, 0xb00
	ctx.r[3].s64 = ctx.r[1].s64 + 2816;
	// 8280FD14: D3E10AF8  stfs f31, 0xaf8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2808 as u32), tmp.u32 ) };
	// 8280FD18: 816BF484  lwz r11, -0xb7c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2940 as u32) ) } as u64;
	// 8280FD1C: 91610AE0  stw r11, 0xae0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2784 as u32), ctx.r[11].u32 ) };
	// 8280FD20: 485EEBA9  bl 0x82dfe8c8
	ctx.lr = 0x8280FD24;
	sub_82DFE8C8(ctx, base);
	// 8280FD24: 38610B08  addi r3, r1, 0xb08
	ctx.r[3].s64 = ctx.r[1].s64 + 2824;
	// 8280FD28: 485EEBA1  bl 0x82dfe8c8
	ctx.lr = 0x8280FD2C;
	sub_82DFE8C8(ctx, base);
	// 8280FD2C: 3F00832D  lis r24, -0x7cd3
	ctx.r[24].s64 = -2094202880;
	// 8280FD30: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FD34: 93C10B1C  stw r30, 0xb1c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2844 as u32), ctx.r[30].u32 ) };
	// 8280FD38: D0010B18  stfs f0, 0xb18(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2840 as u32), tmp.u32 ) };
	// 8280FD3C: 93810B14  stw r28, 0xb14(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2836 as u32), ctx.r[28].u32 ) };
	// 8280FD40: D3C10B20  stfs f30, 0xb20(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2848 as u32), tmp.u32 ) };
	// 8280FD44: 9BE10B2C  stb r31, 0xb2c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2860 as u32), ctx.r[31].u8 ) };
	// 8280FD48: D3E10B24  stfs f31, 0xb24(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2852 as u32), tmp.u32 ) };
	// 8280FD4C: 38610B30  addi r3, r1, 0xb30
	ctx.r[3].s64 = ctx.r[1].s64 + 2864;
	// 8280FD50: 8178F420  lwz r11, -0xbe0(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(-3040 as u32) ) } as u64;
	// 8280FD54: D3E10B28  stfs f31, 0xb28(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2856 as u32), tmp.u32 ) };
	// 8280FD58: 91610B10  stw r11, 0xb10(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2832 as u32), ctx.r[11].u32 ) };
	// 8280FD5C: 485EEB6D  bl 0x82dfe8c8
	ctx.lr = 0x8280FD60;
	sub_82DFE8C8(ctx, base);
	// 8280FD60: 38610B38  addi r3, r1, 0xb38
	ctx.r[3].s64 = ctx.r[1].s64 + 2872;
	// 8280FD64: 485EEB65  bl 0x82dfe8c8
	ctx.lr = 0x8280FD68;
	sub_82DFE8C8(ctx, base);
	// 8280FD68: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FD6C: 816BF464  lwz r11, -0xb9c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2972 as u32) ) } as u64;
	// 8280FD70: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FD74: D0010B48  stfs f0, 0xb48(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2888 as u32), tmp.u32 ) };
	// 8280FD78: 93C10B4C  stw r30, 0xb4c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2892 as u32), ctx.r[30].u32 ) };
	// 8280FD7C: D3C10B50  stfs f30, 0xb50(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2896 as u32), tmp.u32 ) };
	// 8280FD80: 93810B44  stw r28, 0xb44(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2884 as u32), ctx.r[28].u32 ) };
	// 8280FD84: D3E10B54  stfs f31, 0xb54(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2900 as u32), tmp.u32 ) };
	// 8280FD88: 9BE10B5C  stb r31, 0xb5c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2908 as u32), ctx.r[31].u8 ) };
	// 8280FD8C: D3E10B58  stfs f31, 0xb58(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2904 as u32), tmp.u32 ) };
	// 8280FD90: 38610B60  addi r3, r1, 0xb60
	ctx.r[3].s64 = ctx.r[1].s64 + 2912;
	// 8280FD94: 91610B40  stw r11, 0xb40(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2880 as u32), ctx.r[11].u32 ) };
	// 8280FD98: 485EEB31  bl 0x82dfe8c8
	ctx.lr = 0x8280FD9C;
	sub_82DFE8C8(ctx, base);
	// 8280FD9C: 38610B68  addi r3, r1, 0xb68
	ctx.r[3].s64 = ctx.r[1].s64 + 2920;
	// 8280FDA0: 485EEB29  bl 0x82dfe8c8
	ctx.lr = 0x8280FDA4;
	sub_82DFE8C8(ctx, base);
	// 8280FDA4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FDA8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FDAC: 93C10B7C  stw r30, 0xb7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2940 as u32), ctx.r[30].u32 ) };
	// 8280FDB0: D0010B78  stfs f0, 0xb78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2936 as u32), tmp.u32 ) };
	// 8280FDB4: 93810B74  stw r28, 0xb74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2932 as u32), ctx.r[28].u32 ) };
	// 8280FDB8: D3C10B80  stfs f30, 0xb80(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2944 as u32), tmp.u32 ) };
	// 8280FDBC: 9BE10B8C  stb r31, 0xb8c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2956 as u32), ctx.r[31].u8 ) };
	// 8280FDC0: D3E10B84  stfs f31, 0xb84(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2948 as u32), tmp.u32 ) };
	// 8280FDC4: 38610B90  addi r3, r1, 0xb90
	ctx.r[3].s64 = ctx.r[1].s64 + 2960;
	// 8280FDC8: D3E10B88  stfs f31, 0xb88(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2952 as u32), tmp.u32 ) };
	// 8280FDCC: 816BF4A0  lwz r11, -0xb60(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2912 as u32) ) } as u64;
	// 8280FDD0: 91610B70  stw r11, 0xb70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2928 as u32), ctx.r[11].u32 ) };
	// 8280FDD4: 485EEAF5  bl 0x82dfe8c8
	ctx.lr = 0x8280FDD8;
	sub_82DFE8C8(ctx, base);
	// 8280FDD8: 38610B98  addi r3, r1, 0xb98
	ctx.r[3].s64 = ctx.r[1].s64 + 2968;
	// 8280FDDC: 485EEAED  bl 0x82dfe8c8
	ctx.lr = 0x8280FDE0;
	sub_82DFE8C8(ctx, base);
	// 8280FDE0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FDE4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FDE8: 93810BA4  stw r28, 0xba4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2980 as u32), ctx.r[28].u32 ) };
	// 8280FDEC: D0010BA8  stfs f0, 0xba8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2984 as u32), tmp.u32 ) };
	// 8280FDF0: 93C10BAC  stw r30, 0xbac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2988 as u32), ctx.r[30].u32 ) };
	// 8280FDF4: D3C10BB0  stfs f30, 0xbb0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2992 as u32), tmp.u32 ) };
	// 8280FDF8: 9BE10BBC  stb r31, 0xbbc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3004 as u32), ctx.r[31].u8 ) };
	// 8280FDFC: D3E10BB4  stfs f31, 0xbb4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2996 as u32), tmp.u32 ) };
	// 8280FE00: 38610BC0  addi r3, r1, 0xbc0
	ctx.r[3].s64 = ctx.r[1].s64 + 3008;
	// 8280FE04: D3E10BB8  stfs f31, 0xbb8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3000 as u32), tmp.u32 ) };
	// 8280FE08: 816BF4A8  lwz r11, -0xb58(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2904 as u32) ) } as u64;
	// 8280FE0C: 91610BA0  stw r11, 0xba0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2976 as u32), ctx.r[11].u32 ) };
	// 8280FE10: 485EEAB9  bl 0x82dfe8c8
	ctx.lr = 0x8280FE14;
	sub_82DFE8C8(ctx, base);
	// 8280FE14: 38610BC8  addi r3, r1, 0xbc8
	ctx.r[3].s64 = ctx.r[1].s64 + 3016;
	// 8280FE18: 485EEAB1  bl 0x82dfe8c8
	ctx.lr = 0x8280FE1C;
	sub_82DFE8C8(ctx, base);
	// 8280FE1C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FE20: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FE24: 93C10BDC  stw r30, 0xbdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3036 as u32), ctx.r[30].u32 ) };
	// 8280FE28: D0010BD8  stfs f0, 0xbd8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3032 as u32), tmp.u32 ) };
	// 8280FE2C: 93810BD4  stw r28, 0xbd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3028 as u32), ctx.r[28].u32 ) };
	// 8280FE30: D3C10BE0  stfs f30, 0xbe0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3040 as u32), tmp.u32 ) };
	// 8280FE34: 9BE10BEC  stb r31, 0xbec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3052 as u32), ctx.r[31].u8 ) };
	// 8280FE38: D3E10BE4  stfs f31, 0xbe4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3044 as u32), tmp.u32 ) };
	// 8280FE3C: 38610BF0  addi r3, r1, 0xbf0
	ctx.r[3].s64 = ctx.r[1].s64 + 3056;
	// 8280FE40: D3E10BE8  stfs f31, 0xbe8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3048 as u32), tmp.u32 ) };
	// 8280FE44: 816BF4B0  lwz r11, -0xb50(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2896 as u32) ) } as u64;
	// 8280FE48: 91610BD0  stw r11, 0xbd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3024 as u32), ctx.r[11].u32 ) };
	// 8280FE4C: 485EEA7D  bl 0x82dfe8c8
	ctx.lr = 0x8280FE50;
	sub_82DFE8C8(ctx, base);
	// 8280FE50: 38610BF8  addi r3, r1, 0xbf8
	ctx.r[3].s64 = ctx.r[1].s64 + 3064;
	// 8280FE54: 485EEA75  bl 0x82dfe8c8
	ctx.lr = 0x8280FE58;
	sub_82DFE8C8(ctx, base);
	// 8280FE58: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FE5C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FE60: 93E10C0C  stw r31, 0xc0c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3084 as u32), ctx.r[31].u32 ) };
	// 8280FE64: D0010C08  stfs f0, 0xc08(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3080 as u32), tmp.u32 ) };
	// 8280FE68: 93810C04  stw r28, 0xc04(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3076 as u32), ctx.r[28].u32 ) };
	// 8280FE6C: D3C10C10  stfs f30, 0xc10(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3088 as u32), tmp.u32 ) };
	// 8280FE70: 9BE10C1C  stb r31, 0xc1c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3100 as u32), ctx.r[31].u8 ) };
	// 8280FE74: D3E10C14  stfs f31, 0xc14(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3092 as u32), tmp.u32 ) };
	// 8280FE78: 38610C20  addi r3, r1, 0xc20
	ctx.r[3].s64 = ctx.r[1].s64 + 3104;
	// 8280FE7C: D3E10C18  stfs f31, 0xc18(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3096 as u32), tmp.u32 ) };
	// 8280FE80: 816BF4B4  lwz r11, -0xb4c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2892 as u32) ) } as u64;
	// 8280FE84: 91610C00  stw r11, 0xc00(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3072 as u32), ctx.r[11].u32 ) };
	// 8280FE88: 485EEA41  bl 0x82dfe8c8
	ctx.lr = 0x8280FE8C;
	sub_82DFE8C8(ctx, base);
	// 8280FE8C: 38610C28  addi r3, r1, 0xc28
	ctx.r[3].s64 = ctx.r[1].s64 + 3112;
	// 8280FE90: 485EEA39  bl 0x82dfe8c8
	ctx.lr = 0x8280FE94;
	sub_82DFE8C8(ctx, base);
	// 8280FE94: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FE98: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FE9C: D0010C38  stfs f0, 0xc38(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3128 as u32), tmp.u32 ) };
	// 8280FEA0: D3C10C40  stfs f30, 0xc40(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3136 as u32), tmp.u32 ) };
	// 8280FEA4: D3E10C44  stfs f31, 0xc44(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3140 as u32), tmp.u32 ) };
	// 8280FEA8: D3E10C48  stfs f31, 0xc48(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3144 as u32), tmp.u32 ) };
	// 8280FEAC: 816BF4B8  lwz r11, -0xb48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2888 as u32) ) } as u64;
	// 8280FEB0: 93C10C3C  stw r30, 0xc3c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3132 as u32), ctx.r[30].u32 ) };
	// 8280FEB4: 38610C50  addi r3, r1, 0xc50
	ctx.r[3].s64 = ctx.r[1].s64 + 3152;
	// 8280FEB8: 93810C34  stw r28, 0xc34(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3124 as u32), ctx.r[28].u32 ) };
	// 8280FEBC: 9BE10C4C  stb r31, 0xc4c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3148 as u32), ctx.r[31].u8 ) };
	// 8280FEC0: 91610C30  stw r11, 0xc30(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3120 as u32), ctx.r[11].u32 ) };
	// 8280FEC4: 485EEA05  bl 0x82dfe8c8
	ctx.lr = 0x8280FEC8;
	sub_82DFE8C8(ctx, base);
	// 8280FEC8: 38610C58  addi r3, r1, 0xc58
	ctx.r[3].s64 = ctx.r[1].s64 + 3160;
	// 8280FECC: 485EE9FD  bl 0x82dfe8c8
	ctx.lr = 0x8280FED0;
	sub_82DFE8C8(ctx, base);
	// 8280FED0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FED4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FED8: 93E10C6C  stw r31, 0xc6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3180 as u32), ctx.r[31].u32 ) };
	// 8280FEDC: D0010C68  stfs f0, 0xc68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3176 as u32), tmp.u32 ) };
	// 8280FEE0: 93810C64  stw r28, 0xc64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3172 as u32), ctx.r[28].u32 ) };
	// 8280FEE4: D3C10C70  stfs f30, 0xc70(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3184 as u32), tmp.u32 ) };
	// 8280FEE8: 9BE10C7C  stb r31, 0xc7c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3196 as u32), ctx.r[31].u8 ) };
	// 8280FEEC: D3E10C74  stfs f31, 0xc74(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3188 as u32), tmp.u32 ) };
	// 8280FEF0: 38610C80  addi r3, r1, 0xc80
	ctx.r[3].s64 = ctx.r[1].s64 + 3200;
	// 8280FEF4: D3E10C78  stfs f31, 0xc78(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3192 as u32), tmp.u32 ) };
	// 8280FEF8: 816BF4BC  lwz r11, -0xb44(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2884 as u32) ) } as u64;
	// 8280FEFC: 91610C60  stw r11, 0xc60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3168 as u32), ctx.r[11].u32 ) };
	// 8280FF00: 485EE9C9  bl 0x82dfe8c8
	ctx.lr = 0x8280FF04;
	sub_82DFE8C8(ctx, base);
	// 8280FF04: 38610C88  addi r3, r1, 0xc88
	ctx.r[3].s64 = ctx.r[1].s64 + 3208;
	// 8280FF08: 485EE9C1  bl 0x82dfe8c8
	ctx.lr = 0x8280FF0C;
	sub_82DFE8C8(ctx, base);
	// 8280FF0C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FF10: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FF14: 93810C94  stw r28, 0xc94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3220 as u32), ctx.r[28].u32 ) };
	// 8280FF18: D0010C98  stfs f0, 0xc98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3224 as u32), tmp.u32 ) };
	// 8280FF1C: 93C10C9C  stw r30, 0xc9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3228 as u32), ctx.r[30].u32 ) };
	// 8280FF20: D3C10CA0  stfs f30, 0xca0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3232 as u32), tmp.u32 ) };
	// 8280FF24: 9BE10CAC  stb r31, 0xcac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3244 as u32), ctx.r[31].u8 ) };
	// 8280FF28: D3E10CA4  stfs f31, 0xca4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3236 as u32), tmp.u32 ) };
	// 8280FF2C: 38610CB0  addi r3, r1, 0xcb0
	ctx.r[3].s64 = ctx.r[1].s64 + 3248;
	// 8280FF30: D3E10CA8  stfs f31, 0xca8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3240 as u32), tmp.u32 ) };
	// 8280FF34: 816BF4C0  lwz r11, -0xb40(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2880 as u32) ) } as u64;
	// 8280FF38: 91610C90  stw r11, 0xc90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3216 as u32), ctx.r[11].u32 ) };
	// 8280FF3C: 485EE98D  bl 0x82dfe8c8
	ctx.lr = 0x8280FF40;
	sub_82DFE8C8(ctx, base);
	// 8280FF40: 38610CB8  addi r3, r1, 0xcb8
	ctx.r[3].s64 = ctx.r[1].s64 + 3256;
	// 8280FF44: 485EE985  bl 0x82dfe8c8
	ctx.lr = 0x8280FF48;
	sub_82DFE8C8(ctx, base);
	// 8280FF48: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FF4C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FF50: 93C10CCC  stw r30, 0xccc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3276 as u32), ctx.r[30].u32 ) };
	// 8280FF54: D0010CC8  stfs f0, 0xcc8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3272 as u32), tmp.u32 ) };
	// 8280FF58: 93810CC4  stw r28, 0xcc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3268 as u32), ctx.r[28].u32 ) };
	// 8280FF5C: D3C10CD0  stfs f30, 0xcd0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3280 as u32), tmp.u32 ) };
	// 8280FF60: 9BE10CDC  stb r31, 0xcdc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3292 as u32), ctx.r[31].u8 ) };
	// 8280FF64: D3E10CD4  stfs f31, 0xcd4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3284 as u32), tmp.u32 ) };
	// 8280FF68: 38610CE0  addi r3, r1, 0xce0
	ctx.r[3].s64 = ctx.r[1].s64 + 3296;
	// 8280FF6C: D3E10CD8  stfs f31, 0xcd8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3288 as u32), tmp.u32 ) };
	// 8280FF70: 816BF4C4  lwz r11, -0xb3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2876 as u32) ) } as u64;
	// 8280FF74: 91610CC0  stw r11, 0xcc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3264 as u32), ctx.r[11].u32 ) };
	// 8280FF78: 485EE951  bl 0x82dfe8c8
	ctx.lr = 0x8280FF7C;
	sub_82DFE8C8(ctx, base);
	// 8280FF7C: 38610CE8  addi r3, r1, 0xce8
	ctx.r[3].s64 = ctx.r[1].s64 + 3304;
	// 8280FF80: 485EE949  bl 0x82dfe8c8
	ctx.lr = 0x8280FF84;
	sub_82DFE8C8(ctx, base);
	// 8280FF84: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FF88: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FF8C: 93C10CFC  stw r30, 0xcfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3324 as u32), ctx.r[30].u32 ) };
	// 8280FF90: D0010CF8  stfs f0, 0xcf8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3320 as u32), tmp.u32 ) };
	// 8280FF94: 93810CF4  stw r28, 0xcf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3316 as u32), ctx.r[28].u32 ) };
	// 8280FF98: D3C10D00  stfs f30, 0xd00(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3328 as u32), tmp.u32 ) };
	// 8280FF9C: 9BE10D0C  stb r31, 0xd0c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3340 as u32), ctx.r[31].u8 ) };
	// 8280FFA0: D3E10D04  stfs f31, 0xd04(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3332 as u32), tmp.u32 ) };
	// 8280FFA4: 38610D10  addi r3, r1, 0xd10
	ctx.r[3].s64 = ctx.r[1].s64 + 3344;
	// 8280FFA8: D3E10D08  stfs f31, 0xd08(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3336 as u32), tmp.u32 ) };
	// 8280FFAC: 816BF4C8  lwz r11, -0xb38(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2872 as u32) ) } as u64;
	// 8280FFB0: 91610CF0  stw r11, 0xcf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3312 as u32), ctx.r[11].u32 ) };
	// 8280FFB4: 485EE915  bl 0x82dfe8c8
	ctx.lr = 0x8280FFB8;
	sub_82DFE8C8(ctx, base);
	// 8280FFB8: 38610D18  addi r3, r1, 0xd18
	ctx.r[3].s64 = ctx.r[1].s64 + 3352;
	// 8280FFBC: 485EE90D  bl 0x82dfe8c8
	ctx.lr = 0x8280FFC0;
	sub_82DFE8C8(ctx, base);
	// 8280FFC0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8280FFC4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8280FFC8: 93E10D2C  stw r31, 0xd2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3372 as u32), ctx.r[31].u32 ) };
	// 8280FFCC: D0010D28  stfs f0, 0xd28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3368 as u32), tmp.u32 ) };
	// 8280FFD0: 93810D24  stw r28, 0xd24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3364 as u32), ctx.r[28].u32 ) };
	// 8280FFD4: D3C10D30  stfs f30, 0xd30(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3376 as u32), tmp.u32 ) };
	// 8280FFD8: 9BE10D3C  stb r31, 0xd3c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3388 as u32), ctx.r[31].u8 ) };
	// 8280FFDC: D3E10D34  stfs f31, 0xd34(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3380 as u32), tmp.u32 ) };
	// 8280FFE0: 38610D40  addi r3, r1, 0xd40
	ctx.r[3].s64 = ctx.r[1].s64 + 3392;
	// 8280FFE4: D3E10D38  stfs f31, 0xd38(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3384 as u32), tmp.u32 ) };
	// 8280FFE8: 816BF4CC  lwz r11, -0xb34(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2868 as u32) ) } as u64;
	// 8280FFEC: 91610D20  stw r11, 0xd20(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3360 as u32), ctx.r[11].u32 ) };
	// 8280FFF0: 485EE8D9  bl 0x82dfe8c8
	ctx.lr = 0x8280FFF4;
	sub_82DFE8C8(ctx, base);
	// 8280FFF4: 38610D48  addi r3, r1, 0xd48
	ctx.r[3].s64 = ctx.r[1].s64 + 3400;
	// 8280FFF8: 485EE8D1  bl 0x82dfe8c8
	ctx.lr = 0x8280FFFC;
	sub_82DFE8C8(ctx, base);
	// 8280FFFC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810000: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810004: 93C10D5C  stw r30, 0xd5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3420 as u32), ctx.r[30].u32 ) };
	// 82810008: D0010D58  stfs f0, 0xd58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3416 as u32), tmp.u32 ) };
	// 8281000C: 93810D54  stw r28, 0xd54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3412 as u32), ctx.r[28].u32 ) };
	// 82810010: D3C10D60  stfs f30, 0xd60(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3424 as u32), tmp.u32 ) };
	// 82810014: 9BE10D6C  stb r31, 0xd6c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3436 as u32), ctx.r[31].u8 ) };
	// 82810018: D3E10D64  stfs f31, 0xd64(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3428 as u32), tmp.u32 ) };
	// 8281001C: 38610D70  addi r3, r1, 0xd70
	ctx.r[3].s64 = ctx.r[1].s64 + 3440;
	// 82810020: D3E10D68  stfs f31, 0xd68(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3432 as u32), tmp.u32 ) };
	// 82810024: 816BF4D0  lwz r11, -0xb30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2864 as u32) ) } as u64;
	// 82810028: 91610D50  stw r11, 0xd50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3408 as u32), ctx.r[11].u32 ) };
	// 8281002C: 485EE89D  bl 0x82dfe8c8
	ctx.lr = 0x82810030;
	sub_82DFE8C8(ctx, base);
	// 82810030: 38610D78  addi r3, r1, 0xd78
	ctx.r[3].s64 = ctx.r[1].s64 + 3448;
	// 82810034: 485EE895  bl 0x82dfe8c8
	ctx.lr = 0x82810038;
	sub_82DFE8C8(ctx, base);
	// 82810038: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8281003C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810040: 93810D84  stw r28, 0xd84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3460 as u32), ctx.r[28].u32 ) };
	// 82810044: 396B89F0  addi r11, r11, -0x7610
	ctx.r[11].s64 = ctx.r[11].s64 + -30224;
	// 82810048: D0010D88  stfs f0, 0xd88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3464 as u32), tmp.u32 ) };
	// 8281004C: D3C10D90  stfs f30, 0xd90(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3472 as u32), tmp.u32 ) };
	// 82810050: 93C10D8C  stw r30, 0xd8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3468 as u32), ctx.r[30].u32 ) };
	// 82810054: D3E10D94  stfs f31, 0xd94(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3476 as u32), tmp.u32 ) };
	// 82810058: 91610D80  stw r11, 0xd80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3456 as u32), ctx.r[11].u32 ) };
	// 8281005C: D3E10D98  stfs f31, 0xd98(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3480 as u32), tmp.u32 ) };
	// 82810060: 9BE10D9C  stb r31, 0xd9c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3484 as u32), ctx.r[31].u8 ) };
	// 82810064: 38610DA0  addi r3, r1, 0xda0
	ctx.r[3].s64 = ctx.r[1].s64 + 3488;
	// 82810068: 485EE861  bl 0x82dfe8c8
	ctx.lr = 0x8281006C;
	sub_82DFE8C8(ctx, base);
	// 8281006C: 38610DA8  addi r3, r1, 0xda8
	ctx.r[3].s64 = ctx.r[1].s64 + 3496;
	// 82810070: 485EE859  bl 0x82dfe8c8
	ctx.lr = 0x82810074;
	sub_82DFE8C8(ctx, base);
	// 82810074: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82810078: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281007C: 93810DB4  stw r28, 0xdb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3508 as u32), ctx.r[28].u32 ) };
	// 82810080: 396B89DC  addi r11, r11, -0x7624
	ctx.r[11].s64 = ctx.r[11].s64 + -30244;
	// 82810084: D0010DB8  stfs f0, 0xdb8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3512 as u32), tmp.u32 ) };
	// 82810088: D3C10DC0  stfs f30, 0xdc0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3520 as u32), tmp.u32 ) };
	// 8281008C: 93C10DBC  stw r30, 0xdbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3516 as u32), ctx.r[30].u32 ) };
	// 82810090: D3E10DC4  stfs f31, 0xdc4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3524 as u32), tmp.u32 ) };
	// 82810094: 91610DB0  stw r11, 0xdb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3504 as u32), ctx.r[11].u32 ) };
	// 82810098: D3E10DC8  stfs f31, 0xdc8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3528 as u32), tmp.u32 ) };
	// 8281009C: 9BE10DCC  stb r31, 0xdcc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3532 as u32), ctx.r[31].u8 ) };
	// 828100A0: 38610DD0  addi r3, r1, 0xdd0
	ctx.r[3].s64 = ctx.r[1].s64 + 3536;
	// 828100A4: 485EE825  bl 0x82dfe8c8
	ctx.lr = 0x828100A8;
	sub_82DFE8C8(ctx, base);
	// 828100A8: 38610DD8  addi r3, r1, 0xdd8
	ctx.r[3].s64 = ctx.r[1].s64 + 3544;
	// 828100AC: 485EE81D  bl 0x82dfe8c8
	ctx.lr = 0x828100B0;
	sub_82DFE8C8(ctx, base);
	// 828100B0: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828100B4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828100B8: 93810DE4  stw r28, 0xde4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3556 as u32), ctx.r[28].u32 ) };
	// 828100BC: 396B89C8  addi r11, r11, -0x7638
	ctx.r[11].s64 = ctx.r[11].s64 + -30264;
	// 828100C0: D0010DE8  stfs f0, 0xde8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3560 as u32), tmp.u32 ) };
	// 828100C4: D3C10DF0  stfs f30, 0xdf0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3568 as u32), tmp.u32 ) };
	// 828100C8: 93C10DEC  stw r30, 0xdec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3564 as u32), ctx.r[30].u32 ) };
	// 828100CC: D3E10DF4  stfs f31, 0xdf4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3572 as u32), tmp.u32 ) };
	// 828100D0: 91610DE0  stw r11, 0xde0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3552 as u32), ctx.r[11].u32 ) };
	// 828100D4: D3E10DF8  stfs f31, 0xdf8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3576 as u32), tmp.u32 ) };
	// 828100D8: 9BE10DFC  stb r31, 0xdfc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3580 as u32), ctx.r[31].u8 ) };
	// 828100DC: 38610E00  addi r3, r1, 0xe00
	ctx.r[3].s64 = ctx.r[1].s64 + 3584;
	// 828100E0: 485EE7E9  bl 0x82dfe8c8
	ctx.lr = 0x828100E4;
	sub_82DFE8C8(ctx, base);
	// 828100E4: 38610E08  addi r3, r1, 0xe08
	ctx.r[3].s64 = ctx.r[1].s64 + 3592;
	// 828100E8: 485EE7E1  bl 0x82dfe8c8
	ctx.lr = 0x828100EC;
	sub_82DFE8C8(ctx, base);
	// 828100EC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828100F0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828100F4: 93810E14  stw r28, 0xe14(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3604 as u32), ctx.r[28].u32 ) };
	// 828100F8: 396B89B0  addi r11, r11, -0x7650
	ctx.r[11].s64 = ctx.r[11].s64 + -30288;
	// 828100FC: D0010E18  stfs f0, 0xe18(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3608 as u32), tmp.u32 ) };
	// 82810100: D3C10E20  stfs f30, 0xe20(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3616 as u32), tmp.u32 ) };
	// 82810104: 93C10E1C  stw r30, 0xe1c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3612 as u32), ctx.r[30].u32 ) };
	// 82810108: D3E10E24  stfs f31, 0xe24(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3620 as u32), tmp.u32 ) };
	// 8281010C: 91610E10  stw r11, 0xe10(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3600 as u32), ctx.r[11].u32 ) };
	// 82810110: D3E10E28  stfs f31, 0xe28(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3624 as u32), tmp.u32 ) };
	// 82810114: 9BE10E2C  stb r31, 0xe2c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3628 as u32), ctx.r[31].u8 ) };
	// 82810118: 38610E30  addi r3, r1, 0xe30
	ctx.r[3].s64 = ctx.r[1].s64 + 3632;
	// 8281011C: 485EE7AD  bl 0x82dfe8c8
	ctx.lr = 0x82810120;
	sub_82DFE8C8(ctx, base);
	// 82810120: 38610E38  addi r3, r1, 0xe38
	ctx.r[3].s64 = ctx.r[1].s64 + 3640;
	// 82810124: 485EE7A5  bl 0x82dfe8c8
	ctx.lr = 0x82810128;
	sub_82DFE8C8(ctx, base);
	// 82810128: 38A0004A  li r5, 0x4a
	ctx.r[5].s64 = 74;
	// 8281012C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82810130: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 82810134: 4BFDA58D  bl 0x827ea6c0
	ctx.lr = 0x82810138;
	sub_827EA6C0(ctx, base);
	// 82810138: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8281013C: 4BFE9215  bl 0x827f9350
	ctx.lr = 0x82810140;
	sub_827F9350(ctx, base);
	// 82810140: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82810144: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 82810148: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281014C: 4BFDA57D  bl 0x827ea6c8
	ctx.lr = 0x82810150;
	sub_827EA6C8(ctx, base);
	// 82810150: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82810154: 809AF3F8  lwz r4, -0xc08(r26)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-3080 as u32) ) } as u64;
	// 82810158: 485E38B1  bl 0x82df3a08
	ctx.lr = 0x8281015C;
	sub_82DF3A08(ctx, base);
	// 8281015C: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82810160: 8098F420  lwz r4, -0xbe0(r24)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(-3040 as u32) ) } as u64;
	// 82810164: 485E38A5  bl 0x82df3a08
	ctx.lr = 0x82810168;
	sub_82DF3A08(ctx, base);
	// 82810168: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8281016C: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 82810170: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 82810174: 4BFDA1AD  bl 0x827ea320
	ctx.lr = 0x82810178;
	sub_827EA320(ctx, base);
	// 82810178: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 8281017C: 485E32AD  bl 0x82df3428
	ctx.lr = 0x82810180;
	sub_82DF3428(ctx, base);
	// 82810180: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82810184: 485E32A5  bl 0x82df3428
	ctx.lr = 0x82810188;
	sub_82DF3428(ctx, base);
	// 82810188: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8281018C: 8099F3FC  lwz r4, -0xc04(r25)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(-3076 as u32) ) } as u64;
	// 82810190: 485E3879  bl 0x82df3a08
	ctx.lr = 0x82810194;
	sub_82DF3A08(ctx, base);
	// 82810194: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82810198: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 8281019C: 4BFDA345  bl 0x827ea4e0
	ctx.lr = 0x828101A0;
	sub_827EA4E0(ctx, base);
	// 828101A0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828101A4: 485E3285  bl 0x82df3428
	ctx.lr = 0x828101A8;
	sub_82DF3428(ctx, base);
	// 828101A8: 38210EA0  addi r1, r1, 0xea0
	ctx.r[1].s64 = ctx.r[1].s64 + 3744;
	// 828101AC: CBC1FFA8  lfd f30, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 828101B0: CBE1FFB0  lfd f31, -0x50(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-80 as u32) ) };
	// 828101B4: 48997FF4  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828101B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828101B8 size=4700
    let mut pc: u32 = 0x828101B8;
    'dispatch: loop {
        match pc {
            0x828101B8 => {
    //   block [0x828101B8..0x82811414)
	// 828101B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828101BC: 48997FA1  bl 0x831a815c
	ctx.lr = 0x828101C0;
	sub_831A8130(ctx, base);
	// 828101C0: DBC1FFB0  stfd f30, -0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), ctx.f[30].u64 ) };
	// 828101C4: DBE1FFB8  stfd f31, -0x48(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[31].u64 ) };
	// 828101C8: 9421F260  stwu r1, -0xda0(r1)
	ea = ctx.r[1].u32.wrapping_add(-3488 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828101CC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828101D0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 828101D4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828101D8: 388B8968  addi r4, r11, -0x7698
	ctx.r[4].s64 = ctx.r[11].s64 + -30360;
	// 828101DC: 38A001E9  li r5, 0x1e9
	ctx.r[5].s64 = 489;
	// 828101E0: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 828101E4: 4BAB01F5  bl 0x822c03d8
	ctx.lr = 0x828101E8;
	sub_822C03D8(ctx, base);
	// 828101E8: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 828101EC: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828101F0: 41820010  beq 0x82810200
	if ctx.cr[0].eq {
	pc = 0x82810200; continue 'dispatch;
	}
	// 828101F4: 4BFDAABD  bl 0x827eacb0
	ctx.lr = 0x828101F8;
	sub_827EACB0(ctx, base);
	// 828101F8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828101FC: 48000008  b 0x82810204
	pc = 0x82810204; continue 'dispatch;
	// 82810200: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82810204: 387D0120  addi r3, r29, 0x120
	ctx.r[3].s64 = ctx.r[29].s64 + 288;
	// 82810208: 4BFEB149  bl 0x827fb350
	ctx.lr = 0x8281020C;
	sub_827FB350(ctx, base);
	// 8281020C: 815D0148  lwz r10, 0x148(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(328 as u32) ) } as u64;
	// 82810210: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82810214: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82810218: 396BECEC  addi r11, r11, -0x1314
	ctx.r[11].s64 = ctx.r[11].s64 + -4884;
	// 8281021C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82810220: 7C8A582E  lwzx r4, r10, r11
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82810224: 485E37E5  bl 0x82df3a08
	ctx.lr = 0x82810228;
	sub_82DF3A08(ctx, base);
	// 82810228: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8281022C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82810230: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82810234: 839D0120  lwz r28, 0x120(r29)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 82810238: 4BCFF291  bl 0x8250f4c8
	ctx.lr = 0x8281023C;
	sub_8250F4C8(ctx, base);
	// 8281023C: 3F608200  lis r27, -0x7e00
	ctx.r[27].s64 = -2113929216;
	// 82810240: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82810244: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82810248: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8281024C: C03B08A8  lfs f1, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82810250: 4BFDA719  bl 0x827ea968
	ctx.lr = 0x82810254;
	sub_827EA968(ctx, base);
	// 82810254: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82810258: 485E1A39  bl 0x82df1c90
	ctx.lr = 0x8281025C;
	sub_82DF1C90(ctx, base);
	// 8281025C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82810260: 485E31C9  bl 0x82df3428
	ctx.lr = 0x82810264;
	sub_82DF3428(ctx, base);
	// 82810264: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810268: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 8281026C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810270: 3D208201  lis r9, -0x7dff
	ctx.r[9].s64 = -2113863680;
	// 82810274: D0010068  stfs f0, 0x68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82810278: 3D008208  lis r8, -0x7df8
	ctx.r[8].s64 = -2113404928;
	// 8281027C: 9BE1007C  stb r31, 0x7c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[31].u8 ) };
	// 82810280: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82810284: 39088E44  addi r8, r8, -0x71bc
	ctx.r[8].s64 = ctx.r[8].s64 + -29116;
	// 82810288: C3CA08A4  lfs f30, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8281028C: 93C1006C  stw r30, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[30].u32 ) };
	// 82810290: C3E99534  lfs f31, -0x6acc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-27340 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82810294: 91010064  stw r8, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[8].u32 ) };
	// 82810298: D3C10070  stfs f30, 0x70(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 8281029C: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 828102A0: D3E10074  stfs f31, 0x74(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 828102A4: D3E10078  stfs f31, 0x78(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 828102A8: 816BA020  lwz r11, -0x5fe0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24544 as u32) ) } as u64;
	// 828102AC: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 828102B0: 485EE619  bl 0x82dfe8c8
	ctx.lr = 0x828102B4;
	sub_82DFE8C8(ctx, base);
	// 828102B4: 38610088  addi r3, r1, 0x88
	ctx.r[3].s64 = ctx.r[1].s64 + 136;
	// 828102B8: 485EE611  bl 0x82dfe8c8
	ctx.lr = 0x828102BC;
	sub_82DFE8C8(ctx, base);
	// 828102BC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828102C0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828102C4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828102C8: D0010098  stfs f0, 0x98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 828102CC: 93C1009C  stw r30, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[30].u32 ) };
	// 828102D0: 394A8E30  addi r10, r10, -0x71d0
	ctx.r[10].s64 = ctx.r[10].s64 + -29136;
	// 828102D4: D3C100A0  stfs f30, 0xa0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 828102D8: D3E100A4  stfs f31, 0xa4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 828102DC: 9BE100AC  stb r31, 0xac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[31].u8 ) };
	// 828102E0: D3E100A8  stfs f31, 0xa8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 828102E4: 91410094  stw r10, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[10].u32 ) };
	// 828102E8: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 828102EC: 816BA024  lwz r11, -0x5fdc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24540 as u32) ) } as u64;
	// 828102F0: 91610090  stw r11, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 828102F4: 485EE5D5  bl 0x82dfe8c8
	ctx.lr = 0x828102F8;
	sub_82DFE8C8(ctx, base);
	// 828102F8: 386100B8  addi r3, r1, 0xb8
	ctx.r[3].s64 = ctx.r[1].s64 + 184;
	// 828102FC: 485EE5CD  bl 0x82dfe8c8
	ctx.lr = 0x82810300;
	sub_82DFE8C8(ctx, base);
	// 82810300: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810304: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810308: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281030C: D00100C8  stfs f0, 0xc8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 82810310: 93C100CC  stw r30, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[30].u32 ) };
	// 82810314: 3B8A8E1C  addi r28, r10, -0x71e4
	ctx.r[28].s64 = ctx.r[10].s64 + -29156;
	// 82810318: D3C100D0  stfs f30, 0xd0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 8281031C: D3E100D4  stfs f31, 0xd4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 82810320: 9BE100DC  stb r31, 0xdc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[31].u8 ) };
	// 82810324: D3E100D8  stfs f31, 0xd8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 82810328: 938100C4  stw r28, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[28].u32 ) };
	// 8281032C: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 82810330: 816BA03C  lwz r11, -0x5fc4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24516 as u32) ) } as u64;
	// 82810334: 916100C0  stw r11, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 82810338: 485EE591  bl 0x82dfe8c8
	ctx.lr = 0x8281033C;
	sub_82DFE8C8(ctx, base);
	// 8281033C: 386100E8  addi r3, r1, 0xe8
	ctx.r[3].s64 = ctx.r[1].s64 + 232;
	// 82810340: 485EE589  bl 0x82dfe8c8
	ctx.lr = 0x82810344;
	sub_82DFE8C8(ctx, base);
	// 82810344: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810348: 816BA040  lwz r11, -0x5fc0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24512 as u32) ) } as u64;
	// 8281034C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810350: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810354: 93C100FC  stw r30, 0xfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(252 as u32), ctx.r[30].u32 ) };
	// 82810358: 3B4A8E04  addi r26, r10, -0x71fc
	ctx.r[26].s64 = ctx.r[10].s64 + -29180;
	// 8281035C: D00100F8  stfs f0, 0xf8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), tmp.u32 ) };
	// 82810360: D3C10100  stfs f30, 0x100(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 82810364: 9BE1010C  stb r31, 0x10c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(268 as u32), ctx.r[31].u8 ) };
	// 82810368: D3E10104  stfs f31, 0x104(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 8281036C: 934100F4  stw r26, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[26].u32 ) };
	// 82810370: D3E10108  stfs f31, 0x108(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 82810374: 916100F0  stw r11, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[11].u32 ) };
	// 82810378: 38610110  addi r3, r1, 0x110
	ctx.r[3].s64 = ctx.r[1].s64 + 272;
	// 8281037C: 485EE54D  bl 0x82dfe8c8
	ctx.lr = 0x82810380;
	sub_82DFE8C8(ctx, base);
	// 82810380: 38610118  addi r3, r1, 0x118
	ctx.r[3].s64 = ctx.r[1].s64 + 280;
	// 82810384: 485EE545  bl 0x82dfe8c8
	ctx.lr = 0x82810388;
	sub_82DFE8C8(ctx, base);
	// 82810388: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281038C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810390: 93810124  stw r28, 0x124(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(292 as u32), ctx.r[28].u32 ) };
	// 82810394: D0010128  stfs f0, 0x128(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 82810398: 93C1012C  stw r30, 0x12c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(300 as u32), ctx.r[30].u32 ) };
	// 8281039C: D3C10130  stfs f30, 0x130(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 828103A0: 9BE1013C  stb r31, 0x13c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[31].u8 ) };
	// 828103A4: D3E10134  stfs f31, 0x134(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), tmp.u32 ) };
	// 828103A8: 38610140  addi r3, r1, 0x140
	ctx.r[3].s64 = ctx.r[1].s64 + 320;
	// 828103AC: D3E10138  stfs f31, 0x138(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), tmp.u32 ) };
	// 828103B0: 816BA044  lwz r11, -0x5fbc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24508 as u32) ) } as u64;
	// 828103B4: 91610120  stw r11, 0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 828103B8: 485EE511  bl 0x82dfe8c8
	ctx.lr = 0x828103BC;
	sub_82DFE8C8(ctx, base);
	// 828103BC: 38610148  addi r3, r1, 0x148
	ctx.r[3].s64 = ctx.r[1].s64 + 328;
	// 828103C0: 485EE509  bl 0x82dfe8c8
	ctx.lr = 0x828103C4;
	sub_82DFE8C8(ctx, base);
	// 828103C4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828103C8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828103CC: 93C1015C  stw r30, 0x15c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), ctx.r[30].u32 ) };
	// 828103D0: D0010158  stfs f0, 0x158(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), tmp.u32 ) };
	// 828103D4: 93410154  stw r26, 0x154(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), ctx.r[26].u32 ) };
	// 828103D8: D3C10160  stfs f30, 0x160(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 828103DC: 9BE1016C  stb r31, 0x16c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), ctx.r[31].u8 ) };
	// 828103E0: D3E10164  stfs f31, 0x164(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), tmp.u32 ) };
	// 828103E4: 38610170  addi r3, r1, 0x170
	ctx.r[3].s64 = ctx.r[1].s64 + 368;
	// 828103E8: D3E10168  stfs f31, 0x168(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), tmp.u32 ) };
	// 828103EC: 816BA048  lwz r11, -0x5fb8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24504 as u32) ) } as u64;
	// 828103F0: 91610150  stw r11, 0x150(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[11].u32 ) };
	// 828103F4: 485EE4D5  bl 0x82dfe8c8
	ctx.lr = 0x828103F8;
	sub_82DFE8C8(ctx, base);
	// 828103F8: 38610178  addi r3, r1, 0x178
	ctx.r[3].s64 = ctx.r[1].s64 + 376;
	// 828103FC: 485EE4CD  bl 0x82dfe8c8
	ctx.lr = 0x82810400;
	sub_82DFE8C8(ctx, base);
	// 82810400: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810404: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810408: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281040C: D0010188  stfs f0, 0x188(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), tmp.u32 ) };
	// 82810410: 93C1018C  stw r30, 0x18c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), ctx.r[30].u32 ) };
	// 82810414: 3B8A8DF8  addi r28, r10, -0x7208
	ctx.r[28].s64 = ctx.r[10].s64 + -29192;
	// 82810418: D3C10190  stfs f30, 0x190(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), tmp.u32 ) };
	// 8281041C: D3E10194  stfs f31, 0x194(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), tmp.u32 ) };
	// 82810420: 9BE1019C  stb r31, 0x19c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), ctx.r[31].u8 ) };
	// 82810424: D3E10198  stfs f31, 0x198(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), tmp.u32 ) };
	// 82810428: 93810184  stw r28, 0x184(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(388 as u32), ctx.r[28].u32 ) };
	// 8281042C: 386101A0  addi r3, r1, 0x1a0
	ctx.r[3].s64 = ctx.r[1].s64 + 416;
	// 82810430: 816BA04C  lwz r11, -0x5fb4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24500 as u32) ) } as u64;
	// 82810434: 91610180  stw r11, 0x180(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[11].u32 ) };
	// 82810438: 485EE491  bl 0x82dfe8c8
	ctx.lr = 0x8281043C;
	sub_82DFE8C8(ctx, base);
	// 8281043C: 386101A8  addi r3, r1, 0x1a8
	ctx.r[3].s64 = ctx.r[1].s64 + 424;
	// 82810440: 485EE489  bl 0x82dfe8c8
	ctx.lr = 0x82810444;
	sub_82DFE8C8(ctx, base);
	// 82810444: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810448: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8281044C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810450: D00101B8  stfs f0, 0x1b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), tmp.u32 ) };
	// 82810454: 93E101BC  stw r31, 0x1bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(444 as u32), ctx.r[31].u32 ) };
	// 82810458: 394A8DE8  addi r10, r10, -0x7218
	ctx.r[10].s64 = ctx.r[10].s64 + -29208;
	// 8281045C: D3C101C0  stfs f30, 0x1c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), tmp.u32 ) };
	// 82810460: D3E101C4  stfs f31, 0x1c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(452 as u32), tmp.u32 ) };
	// 82810464: 9BE101CC  stb r31, 0x1cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(460 as u32), ctx.r[31].u8 ) };
	// 82810468: D3E101C8  stfs f31, 0x1c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), tmp.u32 ) };
	// 8281046C: 914101B4  stw r10, 0x1b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(436 as u32), ctx.r[10].u32 ) };
	// 82810470: 386101D0  addi r3, r1, 0x1d0
	ctx.r[3].s64 = ctx.r[1].s64 + 464;
	// 82810474: 816BA054  lwz r11, -0x5fac(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24492 as u32) ) } as u64;
	// 82810478: 916101B0  stw r11, 0x1b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), ctx.r[11].u32 ) };
	// 8281047C: 485EE44D  bl 0x82dfe8c8
	ctx.lr = 0x82810480;
	sub_82DFE8C8(ctx, base);
	// 82810480: 386101D8  addi r3, r1, 0x1d8
	ctx.r[3].s64 = ctx.r[1].s64 + 472;
	// 82810484: 485EE445  bl 0x82dfe8c8
	ctx.lr = 0x82810488;
	sub_82DFE8C8(ctx, base);
	// 82810488: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281048C: 816BA05C  lwz r11, -0x5fa4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24484 as u32) ) } as u64;
	// 82810490: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810494: D00101E8  stfs f0, 0x1e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), tmp.u32 ) };
	// 82810498: 93C101EC  stw r30, 0x1ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(492 as u32), ctx.r[30].u32 ) };
	// 8281049C: D3C101F0  stfs f30, 0x1f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), tmp.u32 ) };
	// 828104A0: 938101E4  stw r28, 0x1e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(484 as u32), ctx.r[28].u32 ) };
	// 828104A4: D3E101F4  stfs f31, 0x1f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(500 as u32), tmp.u32 ) };
	// 828104A8: 9BE101FC  stb r31, 0x1fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(508 as u32), ctx.r[31].u8 ) };
	// 828104AC: D3E101F8  stfs f31, 0x1f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(504 as u32), tmp.u32 ) };
	// 828104B0: 38610200  addi r3, r1, 0x200
	ctx.r[3].s64 = ctx.r[1].s64 + 512;
	// 828104B4: 916101E0  stw r11, 0x1e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(480 as u32), ctx.r[11].u32 ) };
	// 828104B8: 485EE411  bl 0x82dfe8c8
	ctx.lr = 0x828104BC;
	sub_82DFE8C8(ctx, base);
	// 828104BC: 38610208  addi r3, r1, 0x208
	ctx.r[3].s64 = ctx.r[1].s64 + 520;
	// 828104C0: 485EE409  bl 0x82dfe8c8
	ctx.lr = 0x828104C4;
	sub_82DFE8C8(ctx, base);
	// 828104C4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828104C8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828104CC: 93C1021C  stw r30, 0x21c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(540 as u32), ctx.r[30].u32 ) };
	// 828104D0: D0010218  stfs f0, 0x218(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(536 as u32), tmp.u32 ) };
	// 828104D4: 93810214  stw r28, 0x214(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(532 as u32), ctx.r[28].u32 ) };
	// 828104D8: D3C10220  stfs f30, 0x220(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(544 as u32), tmp.u32 ) };
	// 828104DC: 9BE1022C  stb r31, 0x22c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(556 as u32), ctx.r[31].u8 ) };
	// 828104E0: D3E10224  stfs f31, 0x224(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(548 as u32), tmp.u32 ) };
	// 828104E4: 38610230  addi r3, r1, 0x230
	ctx.r[3].s64 = ctx.r[1].s64 + 560;
	// 828104E8: D3E10228  stfs f31, 0x228(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(552 as u32), tmp.u32 ) };
	// 828104EC: 816BA060  lwz r11, -0x5fa0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24480 as u32) ) } as u64;
	// 828104F0: 91610210  stw r11, 0x210(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(528 as u32), ctx.r[11].u32 ) };
	// 828104F4: 485EE3D5  bl 0x82dfe8c8
	ctx.lr = 0x828104F8;
	sub_82DFE8C8(ctx, base);
	// 828104F8: 38610238  addi r3, r1, 0x238
	ctx.r[3].s64 = ctx.r[1].s64 + 568;
	// 828104FC: 485EE3CD  bl 0x82dfe8c8
	ctx.lr = 0x82810500;
	sub_82DFE8C8(ctx, base);
	// 82810500: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810504: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810508: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281050C: D0010248  stfs f0, 0x248(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(584 as u32), tmp.u32 ) };
	// 82810510: 93C1024C  stw r30, 0x24c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(588 as u32), ctx.r[30].u32 ) };
	// 82810514: 394A8DD4  addi r10, r10, -0x722c
	ctx.r[10].s64 = ctx.r[10].s64 + -29228;
	// 82810518: D3C10250  stfs f30, 0x250(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(592 as u32), tmp.u32 ) };
	// 8281051C: D3E10254  stfs f31, 0x254(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(596 as u32), tmp.u32 ) };
	// 82810520: 9BE1025C  stb r31, 0x25c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(604 as u32), ctx.r[31].u8 ) };
	// 82810524: D3E10258  stfs f31, 0x258(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(600 as u32), tmp.u32 ) };
	// 82810528: 91410244  stw r10, 0x244(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(580 as u32), ctx.r[10].u32 ) };
	// 8281052C: 38610260  addi r3, r1, 0x260
	ctx.r[3].s64 = ctx.r[1].s64 + 608;
	// 82810530: 816BA064  lwz r11, -0x5f9c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24476 as u32) ) } as u64;
	// 82810534: 91610240  stw r11, 0x240(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(576 as u32), ctx.r[11].u32 ) };
	// 82810538: 485EE391  bl 0x82dfe8c8
	ctx.lr = 0x8281053C;
	sub_82DFE8C8(ctx, base);
	// 8281053C: 38610268  addi r3, r1, 0x268
	ctx.r[3].s64 = ctx.r[1].s64 + 616;
	// 82810540: 485EE389  bl 0x82dfe8c8
	ctx.lr = 0x82810544;
	sub_82DFE8C8(ctx, base);
	// 82810544: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810548: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281054C: 93C1027C  stw r30, 0x27c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(636 as u32), ctx.r[30].u32 ) };
	// 82810550: D0010278  stfs f0, 0x278(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(632 as u32), tmp.u32 ) };
	// 82810554: 93810274  stw r28, 0x274(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(628 as u32), ctx.r[28].u32 ) };
	// 82810558: D3C10280  stfs f30, 0x280(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(640 as u32), tmp.u32 ) };
	// 8281055C: 9BE1028C  stb r31, 0x28c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(652 as u32), ctx.r[31].u8 ) };
	// 82810560: D3E10284  stfs f31, 0x284(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(644 as u32), tmp.u32 ) };
	// 82810564: 38610290  addi r3, r1, 0x290
	ctx.r[3].s64 = ctx.r[1].s64 + 656;
	// 82810568: D3E10288  stfs f31, 0x288(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(648 as u32), tmp.u32 ) };
	// 8281056C: 816BA068  lwz r11, -0x5f98(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24472 as u32) ) } as u64;
	// 82810570: 91610270  stw r11, 0x270(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(624 as u32), ctx.r[11].u32 ) };
	// 82810574: 485EE355  bl 0x82dfe8c8
	ctx.lr = 0x82810578;
	sub_82DFE8C8(ctx, base);
	// 82810578: 38610298  addi r3, r1, 0x298
	ctx.r[3].s64 = ctx.r[1].s64 + 664;
	// 8281057C: 485EE34D  bl 0x82dfe8c8
	ctx.lr = 0x82810580;
	sub_82DFE8C8(ctx, base);
	// 82810580: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810584: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810588: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281058C: D00102A8  stfs f0, 0x2a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(680 as u32), tmp.u32 ) };
	// 82810590: 93C102AC  stw r30, 0x2ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(684 as u32), ctx.r[30].u32 ) };
	// 82810594: 394A8DC0  addi r10, r10, -0x7240
	ctx.r[10].s64 = ctx.r[10].s64 + -29248;
	// 82810598: D3C102B0  stfs f30, 0x2b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(688 as u32), tmp.u32 ) };
	// 8281059C: D3E102B4  stfs f31, 0x2b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(692 as u32), tmp.u32 ) };
	// 828105A0: 9BE102BC  stb r31, 0x2bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(700 as u32), ctx.r[31].u8 ) };
	// 828105A4: D3E102B8  stfs f31, 0x2b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(696 as u32), tmp.u32 ) };
	// 828105A8: 914102A4  stw r10, 0x2a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(676 as u32), ctx.r[10].u32 ) };
	// 828105AC: 386102C0  addi r3, r1, 0x2c0
	ctx.r[3].s64 = ctx.r[1].s64 + 704;
	// 828105B0: 816BA06C  lwz r11, -0x5f94(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24468 as u32) ) } as u64;
	// 828105B4: 916102A0  stw r11, 0x2a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(672 as u32), ctx.r[11].u32 ) };
	// 828105B8: 485EE311  bl 0x82dfe8c8
	ctx.lr = 0x828105BC;
	sub_82DFE8C8(ctx, base);
	// 828105BC: 386102C8  addi r3, r1, 0x2c8
	ctx.r[3].s64 = ctx.r[1].s64 + 712;
	// 828105C0: 485EE309  bl 0x82dfe8c8
	ctx.lr = 0x828105C4;
	sub_82DFE8C8(ctx, base);
	// 828105C4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828105C8: D00102D8  stfs f0, 0x2d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(728 as u32), tmp.u32 ) };
	// 828105CC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828105D0: 816BA070  lwz r11, -0x5f90(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24464 as u32) ) } as u64;
	// 828105D4: D3C102E0  stfs f30, 0x2e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(736 as u32), tmp.u32 ) };
	// 828105D8: D3E102E4  stfs f31, 0x2e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(740 as u32), tmp.u32 ) };
	// 828105DC: 93C102DC  stw r30, 0x2dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(732 as u32), ctx.r[30].u32 ) };
	// 828105E0: D3E102E8  stfs f31, 0x2e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(744 as u32), tmp.u32 ) };
	// 828105E4: 938102D4  stw r28, 0x2d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(724 as u32), ctx.r[28].u32 ) };
	// 828105E8: 9BE102EC  stb r31, 0x2ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(748 as u32), ctx.r[31].u8 ) };
	// 828105EC: 386102F0  addi r3, r1, 0x2f0
	ctx.r[3].s64 = ctx.r[1].s64 + 752;
	// 828105F0: 916102D0  stw r11, 0x2d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(720 as u32), ctx.r[11].u32 ) };
	// 828105F4: 485EE2D5  bl 0x82dfe8c8
	ctx.lr = 0x828105F8;
	sub_82DFE8C8(ctx, base);
	// 828105F8: 386102F8  addi r3, r1, 0x2f8
	ctx.r[3].s64 = ctx.r[1].s64 + 760;
	// 828105FC: 485EE2CD  bl 0x82dfe8c8
	ctx.lr = 0x82810600;
	sub_82DFE8C8(ctx, base);
	// 82810600: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810604: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810608: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281060C: D0010308  stfs f0, 0x308(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(776 as u32), tmp.u32 ) };
	// 82810610: 93C1030C  stw r30, 0x30c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(780 as u32), ctx.r[30].u32 ) };
	// 82810614: 394A8DAC  addi r10, r10, -0x7254
	ctx.r[10].s64 = ctx.r[10].s64 + -29268;
	// 82810618: D3C10310  stfs f30, 0x310(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(784 as u32), tmp.u32 ) };
	// 8281061C: D3E10314  stfs f31, 0x314(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(788 as u32), tmp.u32 ) };
	// 82810620: 9BE1031C  stb r31, 0x31c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(796 as u32), ctx.r[31].u8 ) };
	// 82810624: D3E10318  stfs f31, 0x318(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(792 as u32), tmp.u32 ) };
	// 82810628: 91410304  stw r10, 0x304(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(772 as u32), ctx.r[10].u32 ) };
	// 8281062C: 38610320  addi r3, r1, 0x320
	ctx.r[3].s64 = ctx.r[1].s64 + 800;
	// 82810630: 816BA074  lwz r11, -0x5f8c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24460 as u32) ) } as u64;
	// 82810634: 91610300  stw r11, 0x300(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(768 as u32), ctx.r[11].u32 ) };
	// 82810638: 485EE291  bl 0x82dfe8c8
	ctx.lr = 0x8281063C;
	sub_82DFE8C8(ctx, base);
	// 8281063C: 38610328  addi r3, r1, 0x328
	ctx.r[3].s64 = ctx.r[1].s64 + 808;
	// 82810640: 485EE289  bl 0x82dfe8c8
	ctx.lr = 0x82810644;
	sub_82DFE8C8(ctx, base);
	// 82810644: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810648: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281064C: 93C1033C  stw r30, 0x33c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(828 as u32), ctx.r[30].u32 ) };
	// 82810650: D0010338  stfs f0, 0x338(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(824 as u32), tmp.u32 ) };
	// 82810654: 93810334  stw r28, 0x334(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(820 as u32), ctx.r[28].u32 ) };
	// 82810658: D3C10340  stfs f30, 0x340(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(832 as u32), tmp.u32 ) };
	// 8281065C: 9BE1034C  stb r31, 0x34c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(844 as u32), ctx.r[31].u8 ) };
	// 82810660: D3E10344  stfs f31, 0x344(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(836 as u32), tmp.u32 ) };
	// 82810664: 38610350  addi r3, r1, 0x350
	ctx.r[3].s64 = ctx.r[1].s64 + 848;
	// 82810668: D3E10348  stfs f31, 0x348(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(840 as u32), tmp.u32 ) };
	// 8281066C: 816BA078  lwz r11, -0x5f88(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24456 as u32) ) } as u64;
	// 82810670: 91610330  stw r11, 0x330(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(816 as u32), ctx.r[11].u32 ) };
	// 82810674: 485EE255  bl 0x82dfe8c8
	ctx.lr = 0x82810678;
	sub_82DFE8C8(ctx, base);
	// 82810678: 38610358  addi r3, r1, 0x358
	ctx.r[3].s64 = ctx.r[1].s64 + 856;
	// 8281067C: 485EE24D  bl 0x82dfe8c8
	ctx.lr = 0x82810680;
	sub_82DFE8C8(ctx, base);
	// 82810680: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810684: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810688: 93E1036C  stw r31, 0x36c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(876 as u32), ctx.r[31].u32 ) };
	// 8281068C: D0010368  stfs f0, 0x368(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(872 as u32), tmp.u32 ) };
	// 82810690: 93810364  stw r28, 0x364(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(868 as u32), ctx.r[28].u32 ) };
	// 82810694: D3C10370  stfs f30, 0x370(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(880 as u32), tmp.u32 ) };
	// 82810698: 9BE1037C  stb r31, 0x37c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(892 as u32), ctx.r[31].u8 ) };
	// 8281069C: D3E10374  stfs f31, 0x374(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(884 as u32), tmp.u32 ) };
	// 828106A0: 38610380  addi r3, r1, 0x380
	ctx.r[3].s64 = ctx.r[1].s64 + 896;
	// 828106A4: D3E10378  stfs f31, 0x378(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(888 as u32), tmp.u32 ) };
	// 828106A8: 816BA07C  lwz r11, -0x5f84(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24452 as u32) ) } as u64;
	// 828106AC: 91610360  stw r11, 0x360(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(864 as u32), ctx.r[11].u32 ) };
	// 828106B0: 485EE219  bl 0x82dfe8c8
	ctx.lr = 0x828106B4;
	sub_82DFE8C8(ctx, base);
	// 828106B4: 38610388  addi r3, r1, 0x388
	ctx.r[3].s64 = ctx.r[1].s64 + 904;
	// 828106B8: 485EE211  bl 0x82dfe8c8
	ctx.lr = 0x828106BC;
	sub_82DFE8C8(ctx, base);
	// 828106BC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828106C0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828106C4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828106C8: D0010398  stfs f0, 0x398(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(920 as u32), tmp.u32 ) };
	// 828106CC: 93C1039C  stw r30, 0x39c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(924 as u32), ctx.r[30].u32 ) };
	// 828106D0: 394A8BFC  addi r10, r10, -0x7404
	ctx.r[10].s64 = ctx.r[10].s64 + -29700;
	// 828106D4: D3C103A0  stfs f30, 0x3a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(928 as u32), tmp.u32 ) };
	// 828106D8: D3E103A4  stfs f31, 0x3a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(932 as u32), tmp.u32 ) };
	// 828106DC: 9BE103AC  stb r31, 0x3ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(940 as u32), ctx.r[31].u8 ) };
	// 828106E0: D3E103A8  stfs f31, 0x3a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(936 as u32), tmp.u32 ) };
	// 828106E4: 91410394  stw r10, 0x394(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(916 as u32), ctx.r[10].u32 ) };
	// 828106E8: 386103B0  addi r3, r1, 0x3b0
	ctx.r[3].s64 = ctx.r[1].s64 + 944;
	// 828106EC: 816BA028  lwz r11, -0x5fd8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24536 as u32) ) } as u64;
	// 828106F0: 91610390  stw r11, 0x390(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(912 as u32), ctx.r[11].u32 ) };
	// 828106F4: 485EE1D5  bl 0x82dfe8c8
	ctx.lr = 0x828106F8;
	sub_82DFE8C8(ctx, base);
	// 828106F8: 386103B8  addi r3, r1, 0x3b8
	ctx.r[3].s64 = ctx.r[1].s64 + 952;
	// 828106FC: 485EE1CD  bl 0x82dfe8c8
	ctx.lr = 0x82810700;
	sub_82DFE8C8(ctx, base);
	// 82810700: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810704: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810708: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281070C: 394A8BE4  addi r10, r10, -0x741c
	ctx.r[10].s64 = ctx.r[10].s64 + -29724;
	// 82810710: 816BA02C  lwz r11, -0x5fd4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24532 as u32) ) } as u64;
	// 82810714: D00103C8  stfs f0, 0x3c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(968 as u32), tmp.u32 ) };
	// 82810718: 93C103CC  stw r30, 0x3cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(972 as u32), ctx.r[30].u32 ) };
	// 8281071C: D3C103D0  stfs f30, 0x3d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(976 as u32), tmp.u32 ) };
	// 82810720: 914103C4  stw r10, 0x3c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(964 as u32), ctx.r[10].u32 ) };
	// 82810724: D3E103D4  stfs f31, 0x3d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(980 as u32), tmp.u32 ) };
	// 82810728: 9BE103DC  stb r31, 0x3dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(988 as u32), ctx.r[31].u8 ) };
	// 8281072C: D3E103D8  stfs f31, 0x3d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(984 as u32), tmp.u32 ) };
	// 82810730: 916103C0  stw r11, 0x3c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(960 as u32), ctx.r[11].u32 ) };
	// 82810734: 386103E0  addi r3, r1, 0x3e0
	ctx.r[3].s64 = ctx.r[1].s64 + 992;
	// 82810738: 485EE191  bl 0x82dfe8c8
	ctx.lr = 0x8281073C;
	sub_82DFE8C8(ctx, base);
	// 8281073C: 386103E8  addi r3, r1, 0x3e8
	ctx.r[3].s64 = ctx.r[1].s64 + 1000;
	// 82810740: 485EE189  bl 0x82dfe8c8
	ctx.lr = 0x82810744;
	sub_82DFE8C8(ctx, base);
	// 82810744: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810748: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8281074C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810750: D00103F8  stfs f0, 0x3f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1016 as u32), tmp.u32 ) };
	// 82810754: 93C103FC  stw r30, 0x3fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1020 as u32), ctx.r[30].u32 ) };
	// 82810758: 394A8BD0  addi r10, r10, -0x7430
	ctx.r[10].s64 = ctx.r[10].s64 + -29744;
	// 8281075C: D3C10400  stfs f30, 0x400(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 82810760: D3E10404  stfs f31, 0x404(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 82810764: 9BE1040C  stb r31, 0x40c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1036 as u32), ctx.r[31].u8 ) };
	// 82810768: D3E10408  stfs f31, 0x408(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1032 as u32), tmp.u32 ) };
	// 8281076C: 914103F4  stw r10, 0x3f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1012 as u32), ctx.r[10].u32 ) };
	// 82810770: 38610410  addi r3, r1, 0x410
	ctx.r[3].s64 = ctx.r[1].s64 + 1040;
	// 82810774: 816BA030  lwz r11, -0x5fd0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24528 as u32) ) } as u64;
	// 82810778: 916103F0  stw r11, 0x3f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1008 as u32), ctx.r[11].u32 ) };
	// 8281077C: 485EE14D  bl 0x82dfe8c8
	ctx.lr = 0x82810780;
	sub_82DFE8C8(ctx, base);
	// 82810780: 38610418  addi r3, r1, 0x418
	ctx.r[3].s64 = ctx.r[1].s64 + 1048;
	// 82810784: 485EE145  bl 0x82dfe8c8
	ctx.lr = 0x82810788;
	sub_82DFE8C8(ctx, base);
	// 82810788: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281078C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810790: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810794: D0010428  stfs f0, 0x428(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1064 as u32), tmp.u32 ) };
	// 82810798: 93C1042C  stw r30, 0x42c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1068 as u32), ctx.r[30].u32 ) };
	// 8281079C: 394A8BB8  addi r10, r10, -0x7448
	ctx.r[10].s64 = ctx.r[10].s64 + -29768;
	// 828107A0: D3C10430  stfs f30, 0x430(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1072 as u32), tmp.u32 ) };
	// 828107A4: D3E10434  stfs f31, 0x434(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1076 as u32), tmp.u32 ) };
	// 828107A8: 9BE1043C  stb r31, 0x43c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1084 as u32), ctx.r[31].u8 ) };
	// 828107AC: D3E10438  stfs f31, 0x438(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1080 as u32), tmp.u32 ) };
	// 828107B0: 91410424  stw r10, 0x424(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1060 as u32), ctx.r[10].u32 ) };
	// 828107B4: 38610440  addi r3, r1, 0x440
	ctx.r[3].s64 = ctx.r[1].s64 + 1088;
	// 828107B8: 816BA034  lwz r11, -0x5fcc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24524 as u32) ) } as u64;
	// 828107BC: 91610420  stw r11, 0x420(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1056 as u32), ctx.r[11].u32 ) };
	// 828107C0: 485EE109  bl 0x82dfe8c8
	ctx.lr = 0x828107C4;
	sub_82DFE8C8(ctx, base);
	// 828107C4: 38610448  addi r3, r1, 0x448
	ctx.r[3].s64 = ctx.r[1].s64 + 1096;
	// 828107C8: 485EE101  bl 0x82dfe8c8
	ctx.lr = 0x828107CC;
	sub_82DFE8C8(ctx, base);
	// 828107CC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828107D0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828107D4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828107D8: D0010458  stfs f0, 0x458(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1112 as u32), tmp.u32 ) };
	// 828107DC: 93C1045C  stw r30, 0x45c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1116 as u32), ctx.r[30].u32 ) };
	// 828107E0: 394A8BA4  addi r10, r10, -0x745c
	ctx.r[10].s64 = ctx.r[10].s64 + -29788;
	// 828107E4: D3C10460  stfs f30, 0x460(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1120 as u32), tmp.u32 ) };
	// 828107E8: D3E10464  stfs f31, 0x464(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1124 as u32), tmp.u32 ) };
	// 828107EC: 9BE1046C  stb r31, 0x46c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1132 as u32), ctx.r[31].u8 ) };
	// 828107F0: D3E10468  stfs f31, 0x468(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1128 as u32), tmp.u32 ) };
	// 828107F4: 91410454  stw r10, 0x454(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1108 as u32), ctx.r[10].u32 ) };
	// 828107F8: 38610470  addi r3, r1, 0x470
	ctx.r[3].s64 = ctx.r[1].s64 + 1136;
	// 828107FC: 816BA038  lwz r11, -0x5fc8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24520 as u32) ) } as u64;
	// 82810800: 91610450  stw r11, 0x450(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1104 as u32), ctx.r[11].u32 ) };
	// 82810804: 485EE0C5  bl 0x82dfe8c8
	ctx.lr = 0x82810808;
	sub_82DFE8C8(ctx, base);
	// 82810808: 38610478  addi r3, r1, 0x478
	ctx.r[3].s64 = ctx.r[1].s64 + 1144;
	// 8281080C: 485EE0BD  bl 0x82dfe8c8
	ctx.lr = 0x82810810;
	sub_82DFE8C8(ctx, base);
	// 82810810: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810814: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810818: 93E1048C  stw r31, 0x48c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1164 as u32), ctx.r[31].u32 ) };
	// 8281081C: D0010488  stfs f0, 0x488(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1160 as u32), tmp.u32 ) };
	// 82810820: 93810484  stw r28, 0x484(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1156 as u32), ctx.r[28].u32 ) };
	// 82810824: D3C10490  stfs f30, 0x490(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1168 as u32), tmp.u32 ) };
	// 82810828: 9BE1049C  stb r31, 0x49c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1180 as u32), ctx.r[31].u8 ) };
	// 8281082C: D3E10494  stfs f31, 0x494(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1172 as u32), tmp.u32 ) };
	// 82810830: 386104A0  addi r3, r1, 0x4a0
	ctx.r[3].s64 = ctx.r[1].s64 + 1184;
	// 82810834: D3E10498  stfs f31, 0x498(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1176 as u32), tmp.u32 ) };
	// 82810838: 816BF3F8  lwz r11, -0xc08(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3080 as u32) ) } as u64;
	// 8281083C: 91610480  stw r11, 0x480(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1152 as u32), ctx.r[11].u32 ) };
	// 82810840: 485EE089  bl 0x82dfe8c8
	ctx.lr = 0x82810844;
	sub_82DFE8C8(ctx, base);
	// 82810844: 386104A8  addi r3, r1, 0x4a8
	ctx.r[3].s64 = ctx.r[1].s64 + 1192;
	// 82810848: 485EE081  bl 0x82dfe8c8
	ctx.lr = 0x8281084C;
	sub_82DFE8C8(ctx, base);
	// 8281084C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810850: 3F40832D  lis r26, -0x7cd3
	ctx.r[26].s64 = -2094202880;
	// 82810854: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82810858: 394B8DA0  addi r10, r11, -0x7260
	ctx.r[10].s64 = ctx.r[11].s64 + -29280;
	// 8281085C: 817AF3FC  lwz r11, -0xc04(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-3076 as u32) ) } as u64;
	// 82810860: D00104B8  stfs f0, 0x4b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1208 as u32), tmp.u32 ) };
	// 82810864: 93E104BC  stw r31, 0x4bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1212 as u32), ctx.r[31].u32 ) };
	// 82810868: D3C104C0  stfs f30, 0x4c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1216 as u32), tmp.u32 ) };
	// 8281086C: 9BE104CC  stb r31, 0x4cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1228 as u32), ctx.r[31].u8 ) };
	// 82810870: D3E104C4  stfs f31, 0x4c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1220 as u32), tmp.u32 ) };
	// 82810874: 914104B4  stw r10, 0x4b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1204 as u32), ctx.r[10].u32 ) };
	// 82810878: D3E104C8  stfs f31, 0x4c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1224 as u32), tmp.u32 ) };
	// 8281087C: 386104D0  addi r3, r1, 0x4d0
	ctx.r[3].s64 = ctx.r[1].s64 + 1232;
	// 82810880: 916104B0  stw r11, 0x4b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1200 as u32), ctx.r[11].u32 ) };
	// 82810884: 485EE045  bl 0x82dfe8c8
	ctx.lr = 0x82810888;
	sub_82DFE8C8(ctx, base);
	// 82810888: 386104D8  addi r3, r1, 0x4d8
	ctx.r[3].s64 = ctx.r[1].s64 + 1240;
	// 8281088C: 485EE03D  bl 0x82dfe8c8
	ctx.lr = 0x82810890;
	sub_82DFE8C8(ctx, base);
	// 82810890: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810894: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810898: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281089C: D00104E8  stfs f0, 0x4e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1256 as u32), tmp.u32 ) };
	// 828108A0: 93E104EC  stw r31, 0x4ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1260 as u32), ctx.r[31].u32 ) };
	// 828108A4: 394A8D90  addi r10, r10, -0x7270
	ctx.r[10].s64 = ctx.r[10].s64 + -29296;
	// 828108A8: D3C104F0  stfs f30, 0x4f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1264 as u32), tmp.u32 ) };
	// 828108AC: D3E104F4  stfs f31, 0x4f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1268 as u32), tmp.u32 ) };
	// 828108B0: 9BE104FC  stb r31, 0x4fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1276 as u32), ctx.r[31].u8 ) };
	// 828108B4: D3E104F8  stfs f31, 0x4f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1272 as u32), tmp.u32 ) };
	// 828108B8: 914104E4  stw r10, 0x4e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1252 as u32), ctx.r[10].u32 ) };
	// 828108BC: 38610500  addi r3, r1, 0x500
	ctx.r[3].s64 = ctx.r[1].s64 + 1280;
	// 828108C0: 816BF40C  lwz r11, -0xbf4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3060 as u32) ) } as u64;
	// 828108C4: 916104E0  stw r11, 0x4e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1248 as u32), ctx.r[11].u32 ) };
	// 828108C8: 485EE001  bl 0x82dfe8c8
	ctx.lr = 0x828108CC;
	sub_82DFE8C8(ctx, base);
	// 828108CC: 38610508  addi r3, r1, 0x508
	ctx.r[3].s64 = ctx.r[1].s64 + 1288;
	// 828108D0: 485EDFF9  bl 0x82dfe8c8
	ctx.lr = 0x828108D4;
	sub_82DFE8C8(ctx, base);
	// 828108D4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828108D8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828108DC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828108E0: D0010518  stfs f0, 0x518(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1304 as u32), tmp.u32 ) };
	// 828108E4: 93C1051C  stw r30, 0x51c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1308 as u32), ctx.r[30].u32 ) };
	// 828108E8: 394A8D80  addi r10, r10, -0x7280
	ctx.r[10].s64 = ctx.r[10].s64 + -29312;
	// 828108EC: D3C10520  stfs f30, 0x520(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1312 as u32), tmp.u32 ) };
	// 828108F0: D3E10524  stfs f31, 0x524(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1316 as u32), tmp.u32 ) };
	// 828108F4: 9BE1052C  stb r31, 0x52c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1324 as u32), ctx.r[31].u8 ) };
	// 828108F8: D3E10528  stfs f31, 0x528(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1320 as u32), tmp.u32 ) };
	// 828108FC: 91410514  stw r10, 0x514(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1300 as u32), ctx.r[10].u32 ) };
	// 82810900: 38610530  addi r3, r1, 0x530
	ctx.r[3].s64 = ctx.r[1].s64 + 1328;
	// 82810904: 816BF410  lwz r11, -0xbf0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3056 as u32) ) } as u64;
	// 82810908: 91610510  stw r11, 0x510(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1296 as u32), ctx.r[11].u32 ) };
	// 8281090C: 485EDFBD  bl 0x82dfe8c8
	ctx.lr = 0x82810910;
	sub_82DFE8C8(ctx, base);
	// 82810910: 38610538  addi r3, r1, 0x538
	ctx.r[3].s64 = ctx.r[1].s64 + 1336;
	// 82810914: 485EDFB5  bl 0x82dfe8c8
	ctx.lr = 0x82810918;
	sub_82DFE8C8(ctx, base);
	// 82810918: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281091C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810920: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810924: D0010548  stfs f0, 0x548(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1352 as u32), tmp.u32 ) };
	// 82810928: 93C1054C  stw r30, 0x54c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1356 as u32), ctx.r[30].u32 ) };
	// 8281092C: 394A8D70  addi r10, r10, -0x7290
	ctx.r[10].s64 = ctx.r[10].s64 + -29328;
	// 82810930: D3C10550  stfs f30, 0x550(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1360 as u32), tmp.u32 ) };
	// 82810934: D3E10554  stfs f31, 0x554(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1364 as u32), tmp.u32 ) };
	// 82810938: 9BE1055C  stb r31, 0x55c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1372 as u32), ctx.r[31].u8 ) };
	// 8281093C: D3E10558  stfs f31, 0x558(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1368 as u32), tmp.u32 ) };
	// 82810940: 91410544  stw r10, 0x544(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1348 as u32), ctx.r[10].u32 ) };
	// 82810944: 38610560  addi r3, r1, 0x560
	ctx.r[3].s64 = ctx.r[1].s64 + 1376;
	// 82810948: 816BF404  lwz r11, -0xbfc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3068 as u32) ) } as u64;
	// 8281094C: 91610540  stw r11, 0x540(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1344 as u32), ctx.r[11].u32 ) };
	// 82810950: 485EDF79  bl 0x82dfe8c8
	ctx.lr = 0x82810954;
	sub_82DFE8C8(ctx, base);
	// 82810954: 38610568  addi r3, r1, 0x568
	ctx.r[3].s64 = ctx.r[1].s64 + 1384;
	// 82810958: 485EDF71  bl 0x82dfe8c8
	ctx.lr = 0x8281095C;
	sub_82DFE8C8(ctx, base);
	// 8281095C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810960: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810964: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810968: D0010578  stfs f0, 0x578(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1400 as u32), tmp.u32 ) };
	// 8281096C: 93C1057C  stw r30, 0x57c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1404 as u32), ctx.r[30].u32 ) };
	// 82810970: 394A8D64  addi r10, r10, -0x729c
	ctx.r[10].s64 = ctx.r[10].s64 + -29340;
	// 82810974: D3C10580  stfs f30, 0x580(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1408 as u32), tmp.u32 ) };
	// 82810978: D3E10584  stfs f31, 0x584(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1412 as u32), tmp.u32 ) };
	// 8281097C: 9BE1058C  stb r31, 0x58c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1420 as u32), ctx.r[31].u8 ) };
	// 82810980: D3E10588  stfs f31, 0x588(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1416 as u32), tmp.u32 ) };
	// 82810984: 91410574  stw r10, 0x574(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1396 as u32), ctx.r[10].u32 ) };
	// 82810988: 38610590  addi r3, r1, 0x590
	ctx.r[3].s64 = ctx.r[1].s64 + 1424;
	// 8281098C: 816BF408  lwz r11, -0xbf8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3064 as u32) ) } as u64;
	// 82810990: 91610570  stw r11, 0x570(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1392 as u32), ctx.r[11].u32 ) };
	// 82810994: 485EDF35  bl 0x82dfe8c8
	ctx.lr = 0x82810998;
	sub_82DFE8C8(ctx, base);
	// 82810998: 38610598  addi r3, r1, 0x598
	ctx.r[3].s64 = ctx.r[1].s64 + 1432;
	// 8281099C: 485EDF2D  bl 0x82dfe8c8
	ctx.lr = 0x828109A0;
	sub_82DFE8C8(ctx, base);
	// 828109A0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828109A4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828109A8: 93C105AC  stw r30, 0x5ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1452 as u32), ctx.r[30].u32 ) };
	// 828109AC: D00105A8  stfs f0, 0x5a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1448 as u32), tmp.u32 ) };
	// 828109B0: 938105A4  stw r28, 0x5a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1444 as u32), ctx.r[28].u32 ) };
	// 828109B4: D3C105B0  stfs f30, 0x5b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1456 as u32), tmp.u32 ) };
	// 828109B8: 9BE105BC  stb r31, 0x5bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1468 as u32), ctx.r[31].u8 ) };
	// 828109BC: D3E105B4  stfs f31, 0x5b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1460 as u32), tmp.u32 ) };
	// 828109C0: 386105C0  addi r3, r1, 0x5c0
	ctx.r[3].s64 = ctx.r[1].s64 + 1472;
	// 828109C4: D3E105B8  stfs f31, 0x5b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1464 as u32), tmp.u32 ) };
	// 828109C8: 816BF400  lwz r11, -0xc00(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3072 as u32) ) } as u64;
	// 828109CC: 916105A0  stw r11, 0x5a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1440 as u32), ctx.r[11].u32 ) };
	// 828109D0: 485EDEF9  bl 0x82dfe8c8
	ctx.lr = 0x828109D4;
	sub_82DFE8C8(ctx, base);
	// 828109D4: 386105C8  addi r3, r1, 0x5c8
	ctx.r[3].s64 = ctx.r[1].s64 + 1480;
	// 828109D8: 485EDEF1  bl 0x82dfe8c8
	ctx.lr = 0x828109DC;
	sub_82DFE8C8(ctx, base);
	// 828109DC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828109E0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828109E4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828109E8: D00105D8  stfs f0, 0x5d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1496 as u32), tmp.u32 ) };
	// 828109EC: 93C105DC  stw r30, 0x5dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1500 as u32), ctx.r[30].u32 ) };
	// 828109F0: 3B2A8D50  addi r25, r10, -0x72b0
	ctx.r[25].s64 = ctx.r[10].s64 + -29360;
	// 828109F4: D3C105E0  stfs f30, 0x5e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1504 as u32), tmp.u32 ) };
	// 828109F8: D3E105E4  stfs f31, 0x5e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1508 as u32), tmp.u32 ) };
	// 828109FC: 9BE105EC  stb r31, 0x5ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1516 as u32), ctx.r[31].u8 ) };
	// 82810A00: D3E105E8  stfs f31, 0x5e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1512 as u32), tmp.u32 ) };
	// 82810A04: 932105D4  stw r25, 0x5d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1492 as u32), ctx.r[25].u32 ) };
	// 82810A08: 386105F0  addi r3, r1, 0x5f0
	ctx.r[3].s64 = ctx.r[1].s64 + 1520;
	// 82810A0C: 816BF488  lwz r11, -0xb78(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2936 as u32) ) } as u64;
	// 82810A10: 916105D0  stw r11, 0x5d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1488 as u32), ctx.r[11].u32 ) };
	// 82810A14: 485EDEB5  bl 0x82dfe8c8
	ctx.lr = 0x82810A18;
	sub_82DFE8C8(ctx, base);
	// 82810A18: 386105F8  addi r3, r1, 0x5f8
	ctx.r[3].s64 = ctx.r[1].s64 + 1528;
	// 82810A1C: 485EDEAD  bl 0x82dfe8c8
	ctx.lr = 0x82810A20;
	sub_82DFE8C8(ctx, base);
	// 82810A20: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810A24: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810A28: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810A2C: D0010608  stfs f0, 0x608(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1544 as u32), tmp.u32 ) };
	// 82810A30: 93E1060C  stw r31, 0x60c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1548 as u32), ctx.r[31].u32 ) };
	// 82810A34: 394A8D3C  addi r10, r10, -0x72c4
	ctx.r[10].s64 = ctx.r[10].s64 + -29380;
	// 82810A38: D3C10610  stfs f30, 0x610(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1552 as u32), tmp.u32 ) };
	// 82810A3C: D3E10614  stfs f31, 0x614(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1556 as u32), tmp.u32 ) };
	// 82810A40: 9BE1061C  stb r31, 0x61c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1564 as u32), ctx.r[31].u8 ) };
	// 82810A44: D3E10618  stfs f31, 0x618(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1560 as u32), tmp.u32 ) };
	// 82810A48: 91410604  stw r10, 0x604(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1540 as u32), ctx.r[10].u32 ) };
	// 82810A4C: 38610620  addi r3, r1, 0x620
	ctx.r[3].s64 = ctx.r[1].s64 + 1568;
	// 82810A50: 816BF48C  lwz r11, -0xb74(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2932 as u32) ) } as u64;
	// 82810A54: 91610600  stw r11, 0x600(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1536 as u32), ctx.r[11].u32 ) };
	// 82810A58: 485EDE71  bl 0x82dfe8c8
	ctx.lr = 0x82810A5C;
	sub_82DFE8C8(ctx, base);
	// 82810A5C: 38610628  addi r3, r1, 0x628
	ctx.r[3].s64 = ctx.r[1].s64 + 1576;
	// 82810A60: 485EDE69  bl 0x82dfe8c8
	ctx.lr = 0x82810A64;
	sub_82DFE8C8(ctx, base);
	// 82810A64: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810A68: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810A6C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810A70: D0010638  stfs f0, 0x638(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1592 as u32), tmp.u32 ) };
	// 82810A74: 93C1063C  stw r30, 0x63c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1596 as u32), ctx.r[30].u32 ) };
	// 82810A78: 394A8D28  addi r10, r10, -0x72d8
	ctx.r[10].s64 = ctx.r[10].s64 + -29400;
	// 82810A7C: D3C10640  stfs f30, 0x640(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1600 as u32), tmp.u32 ) };
	// 82810A80: D3E10644  stfs f31, 0x644(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1604 as u32), tmp.u32 ) };
	// 82810A84: 9BE1064C  stb r31, 0x64c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1612 as u32), ctx.r[31].u8 ) };
	// 82810A88: D3E10648  stfs f31, 0x648(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1608 as u32), tmp.u32 ) };
	// 82810A8C: 91410634  stw r10, 0x634(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1588 as u32), ctx.r[10].u32 ) };
	// 82810A90: 38610650  addi r3, r1, 0x650
	ctx.r[3].s64 = ctx.r[1].s64 + 1616;
	// 82810A94: 816BF490  lwz r11, -0xb70(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2928 as u32) ) } as u64;
	// 82810A98: 91610630  stw r11, 0x630(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1584 as u32), ctx.r[11].u32 ) };
	// 82810A9C: 485EDE2D  bl 0x82dfe8c8
	ctx.lr = 0x82810AA0;
	sub_82DFE8C8(ctx, base);
	// 82810AA0: 38610658  addi r3, r1, 0x658
	ctx.r[3].s64 = ctx.r[1].s64 + 1624;
	// 82810AA4: 485EDE25  bl 0x82dfe8c8
	ctx.lr = 0x82810AA8;
	sub_82DFE8C8(ctx, base);
	// 82810AA8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82810AAC: 3D40832D  lis r10, -0x7cd3
	ctx.r[10].s64 = -2094202880;
	// 82810AB0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810AB4: 396B8D14  addi r11, r11, -0x72ec
	ctx.r[11].s64 = ctx.r[11].s64 + -29420;
	// 82810AB8: D0010668  stfs f0, 0x668(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1640 as u32), tmp.u32 ) };
	// 82810ABC: D3C10670  stfs f30, 0x670(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1648 as u32), tmp.u32 ) };
	// 82810AC0: 93C1066C  stw r30, 0x66c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1644 as u32), ctx.r[30].u32 ) };
	// 82810AC4: 91610664  stw r11, 0x664(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1636 as u32), ctx.r[11].u32 ) };
	// 82810AC8: D3E10674  stfs f31, 0x674(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1652 as u32), tmp.u32 ) };
	// 82810ACC: D3E10678  stfs f31, 0x678(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1656 as u32), tmp.u32 ) };
	// 82810AD0: 38610680  addi r3, r1, 0x680
	ctx.r[3].s64 = ctx.r[1].s64 + 1664;
	// 82810AD4: 9BE1067C  stb r31, 0x67c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1660 as u32), ctx.r[31].u8 ) };
	// 82810AD8: 816AF494  lwz r11, -0xb6c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-2924 as u32) ) } as u64;
	// 82810ADC: 91610660  stw r11, 0x660(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1632 as u32), ctx.r[11].u32 ) };
	// 82810AE0: 485EDDE9  bl 0x82dfe8c8
	ctx.lr = 0x82810AE4;
	sub_82DFE8C8(ctx, base);
	// 82810AE4: 38610688  addi r3, r1, 0x688
	ctx.r[3].s64 = ctx.r[1].s64 + 1672;
	// 82810AE8: 485EDDE1  bl 0x82dfe8c8
	ctx.lr = 0x82810AEC;
	sub_82DFE8C8(ctx, base);
	// 82810AEC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810AF0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810AF4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810AF8: D0010698  stfs f0, 0x698(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1688 as u32), tmp.u32 ) };
	// 82810AFC: 93C1069C  stw r30, 0x69c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1692 as u32), ctx.r[30].u32 ) };
	// 82810B00: 394A8D00  addi r10, r10, -0x7300
	ctx.r[10].s64 = ctx.r[10].s64 + -29440;
	// 82810B04: D3C106A0  stfs f30, 0x6a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1696 as u32), tmp.u32 ) };
	// 82810B08: D3E106A4  stfs f31, 0x6a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1700 as u32), tmp.u32 ) };
	// 82810B0C: 9BE106AC  stb r31, 0x6ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1708 as u32), ctx.r[31].u8 ) };
	// 82810B10: D3E106A8  stfs f31, 0x6a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1704 as u32), tmp.u32 ) };
	// 82810B14: 91410694  stw r10, 0x694(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1684 as u32), ctx.r[10].u32 ) };
	// 82810B18: 386106B0  addi r3, r1, 0x6b0
	ctx.r[3].s64 = ctx.r[1].s64 + 1712;
	// 82810B1C: 816BF498  lwz r11, -0xb68(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2920 as u32) ) } as u64;
	// 82810B20: 91610690  stw r11, 0x690(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1680 as u32), ctx.r[11].u32 ) };
	// 82810B24: 485EDDA5  bl 0x82dfe8c8
	ctx.lr = 0x82810B28;
	sub_82DFE8C8(ctx, base);
	// 82810B28: 386106B8  addi r3, r1, 0x6b8
	ctx.r[3].s64 = ctx.r[1].s64 + 1720;
	// 82810B2C: 485EDD9D  bl 0x82dfe8c8
	ctx.lr = 0x82810B30;
	sub_82DFE8C8(ctx, base);
	// 82810B30: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810B34: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810B38: 93C106CC  stw r30, 0x6cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1740 as u32), ctx.r[30].u32 ) };
	// 82810B3C: D00106C8  stfs f0, 0x6c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1736 as u32), tmp.u32 ) };
	// 82810B40: 932106C4  stw r25, 0x6c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1732 as u32), ctx.r[25].u32 ) };
	// 82810B44: D3C106D0  stfs f30, 0x6d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1744 as u32), tmp.u32 ) };
	// 82810B48: 9BE106DC  stb r31, 0x6dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1756 as u32), ctx.r[31].u8 ) };
	// 82810B4C: D3E106D4  stfs f31, 0x6d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1748 as u32), tmp.u32 ) };
	// 82810B50: 386106E0  addi r3, r1, 0x6e0
	ctx.r[3].s64 = ctx.r[1].s64 + 1760;
	// 82810B54: D3E106D8  stfs f31, 0x6d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1752 as u32), tmp.u32 ) };
	// 82810B58: 816BF49C  lwz r11, -0xb64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2916 as u32) ) } as u64;
	// 82810B5C: 916106C0  stw r11, 0x6c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1728 as u32), ctx.r[11].u32 ) };
	// 82810B60: 485EDD69  bl 0x82dfe8c8
	ctx.lr = 0x82810B64;
	sub_82DFE8C8(ctx, base);
	// 82810B64: 386106E8  addi r3, r1, 0x6e8
	ctx.r[3].s64 = ctx.r[1].s64 + 1768;
	// 82810B68: 485EDD61  bl 0x82dfe8c8
	ctx.lr = 0x82810B6C;
	sub_82DFE8C8(ctx, base);
	// 82810B6C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810B70: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810B74: 93C106FC  stw r30, 0x6fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1788 as u32), ctx.r[30].u32 ) };
	// 82810B78: D00106F8  stfs f0, 0x6f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1784 as u32), tmp.u32 ) };
	// 82810B7C: 938106F4  stw r28, 0x6f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1780 as u32), ctx.r[28].u32 ) };
	// 82810B80: D3C10700  stfs f30, 0x700(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1792 as u32), tmp.u32 ) };
	// 82810B84: 9BE1070C  stb r31, 0x70c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1804 as u32), ctx.r[31].u8 ) };
	// 82810B88: D3E10704  stfs f31, 0x704(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1796 as u32), tmp.u32 ) };
	// 82810B8C: 38610710  addi r3, r1, 0x710
	ctx.r[3].s64 = ctx.r[1].s64 + 1808;
	// 82810B90: D3E10708  stfs f31, 0x708(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1800 as u32), tmp.u32 ) };
	// 82810B94: 816BF46C  lwz r11, -0xb94(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2964 as u32) ) } as u64;
	// 82810B98: 916106F0  stw r11, 0x6f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1776 as u32), ctx.r[11].u32 ) };
	// 82810B9C: 485EDD2D  bl 0x82dfe8c8
	ctx.lr = 0x82810BA0;
	sub_82DFE8C8(ctx, base);
	// 82810BA0: 38610718  addi r3, r1, 0x718
	ctx.r[3].s64 = ctx.r[1].s64 + 1816;
	// 82810BA4: 485EDD25  bl 0x82dfe8c8
	ctx.lr = 0x82810BA8;
	sub_82DFE8C8(ctx, base);
	// 82810BA8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810BAC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810BB0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810BB4: D0010728  stfs f0, 0x728(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1832 as u32), tmp.u32 ) };
	// 82810BB8: 93E1072C  stw r31, 0x72c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1836 as u32), ctx.r[31].u32 ) };
	// 82810BBC: 3B2A8CF4  addi r25, r10, -0x730c
	ctx.r[25].s64 = ctx.r[10].s64 + -29452;
	// 82810BC0: D3C10730  stfs f30, 0x730(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1840 as u32), tmp.u32 ) };
	// 82810BC4: D3E10734  stfs f31, 0x734(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1844 as u32), tmp.u32 ) };
	// 82810BC8: 9BE1073C  stb r31, 0x73c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1852 as u32), ctx.r[31].u8 ) };
	// 82810BCC: D3E10738  stfs f31, 0x738(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1848 as u32), tmp.u32 ) };
	// 82810BD0: 93210724  stw r25, 0x724(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1828 as u32), ctx.r[25].u32 ) };
	// 82810BD4: 38610740  addi r3, r1, 0x740
	ctx.r[3].s64 = ctx.r[1].s64 + 1856;
	// 82810BD8: 816BF470  lwz r11, -0xb90(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2960 as u32) ) } as u64;
	// 82810BDC: 91610720  stw r11, 0x720(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1824 as u32), ctx.r[11].u32 ) };
	// 82810BE0: 485EDCE9  bl 0x82dfe8c8
	ctx.lr = 0x82810BE4;
	sub_82DFE8C8(ctx, base);
	// 82810BE4: 38610748  addi r3, r1, 0x748
	ctx.r[3].s64 = ctx.r[1].s64 + 1864;
	// 82810BE8: 485EDCE1  bl 0x82dfe8c8
	ctx.lr = 0x82810BEC;
	sub_82DFE8C8(ctx, base);
	// 82810BEC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810BF0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810BF4: 93C1075C  stw r30, 0x75c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1884 as u32), ctx.r[30].u32 ) };
	// 82810BF8: D0010758  stfs f0, 0x758(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1880 as u32), tmp.u32 ) };
	// 82810BFC: 93810754  stw r28, 0x754(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1876 as u32), ctx.r[28].u32 ) };
	// 82810C00: D3C10760  stfs f30, 0x760(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1888 as u32), tmp.u32 ) };
	// 82810C04: 9BE1076C  stb r31, 0x76c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1900 as u32), ctx.r[31].u8 ) };
	// 82810C08: D3E10764  stfs f31, 0x764(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1892 as u32), tmp.u32 ) };
	// 82810C0C: 38610770  addi r3, r1, 0x770
	ctx.r[3].s64 = ctx.r[1].s64 + 1904;
	// 82810C10: D3E10768  stfs f31, 0x768(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1896 as u32), tmp.u32 ) };
	// 82810C14: 816BF474  lwz r11, -0xb8c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2956 as u32) ) } as u64;
	// 82810C18: 91610750  stw r11, 0x750(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1872 as u32), ctx.r[11].u32 ) };
	// 82810C1C: 485EDCAD  bl 0x82dfe8c8
	ctx.lr = 0x82810C20;
	sub_82DFE8C8(ctx, base);
	// 82810C20: 38610778  addi r3, r1, 0x778
	ctx.r[3].s64 = ctx.r[1].s64 + 1912;
	// 82810C24: 485EDCA5  bl 0x82dfe8c8
	ctx.lr = 0x82810C28;
	sub_82DFE8C8(ctx, base);
	// 82810C28: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810C2C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810C30: 93C1078C  stw r30, 0x78c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1932 as u32), ctx.r[30].u32 ) };
	// 82810C34: D0010788  stfs f0, 0x788(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1928 as u32), tmp.u32 ) };
	// 82810C38: 93810784  stw r28, 0x784(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1924 as u32), ctx.r[28].u32 ) };
	// 82810C3C: D3C10790  stfs f30, 0x790(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1936 as u32), tmp.u32 ) };
	// 82810C40: 9BE1079C  stb r31, 0x79c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1948 as u32), ctx.r[31].u8 ) };
	// 82810C44: D3E10794  stfs f31, 0x794(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1940 as u32), tmp.u32 ) };
	// 82810C48: 386107A0  addi r3, r1, 0x7a0
	ctx.r[3].s64 = ctx.r[1].s64 + 1952;
	// 82810C4C: D3E10798  stfs f31, 0x798(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1944 as u32), tmp.u32 ) };
	// 82810C50: 816BF478  lwz r11, -0xb88(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2952 as u32) ) } as u64;
	// 82810C54: 91610780  stw r11, 0x780(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1920 as u32), ctx.r[11].u32 ) };
	// 82810C58: 485EDC71  bl 0x82dfe8c8
	ctx.lr = 0x82810C5C;
	sub_82DFE8C8(ctx, base);
	// 82810C5C: 386107A8  addi r3, r1, 0x7a8
	ctx.r[3].s64 = ctx.r[1].s64 + 1960;
	// 82810C60: 485EDC69  bl 0x82dfe8c8
	ctx.lr = 0x82810C64;
	sub_82DFE8C8(ctx, base);
	// 82810C64: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810C68: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810C6C: 93E107BC  stw r31, 0x7bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1980 as u32), ctx.r[31].u32 ) };
	// 82810C70: D00107B8  stfs f0, 0x7b8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1976 as u32), tmp.u32 ) };
	// 82810C74: 938107B4  stw r28, 0x7b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1972 as u32), ctx.r[28].u32 ) };
	// 82810C78: D3C107C0  stfs f30, 0x7c0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1984 as u32), tmp.u32 ) };
	// 82810C7C: 9BE107CC  stb r31, 0x7cc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(1996 as u32), ctx.r[31].u8 ) };
	// 82810C80: D3E107C4  stfs f31, 0x7c4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1988 as u32), tmp.u32 ) };
	// 82810C84: 386107D0  addi r3, r1, 0x7d0
	ctx.r[3].s64 = ctx.r[1].s64 + 2000;
	// 82810C88: D3E107C8  stfs f31, 0x7c8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1992 as u32), tmp.u32 ) };
	// 82810C8C: 816BF468  lwz r11, -0xb98(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2968 as u32) ) } as u64;
	// 82810C90: 916107B0  stw r11, 0x7b0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(1968 as u32), ctx.r[11].u32 ) };
	// 82810C94: 485EDC35  bl 0x82dfe8c8
	ctx.lr = 0x82810C98;
	sub_82DFE8C8(ctx, base);
	// 82810C98: 386107D8  addi r3, r1, 0x7d8
	ctx.r[3].s64 = ctx.r[1].s64 + 2008;
	// 82810C9C: 485EDC2D  bl 0x82dfe8c8
	ctx.lr = 0x82810CA0;
	sub_82DFE8C8(ctx, base);
	// 82810CA0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810CA4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810CA8: 93C107EC  stw r30, 0x7ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2028 as u32), ctx.r[30].u32 ) };
	// 82810CAC: D00107E8  stfs f0, 0x7e8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2024 as u32), tmp.u32 ) };
	// 82810CB0: 932107E4  stw r25, 0x7e4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2020 as u32), ctx.r[25].u32 ) };
	// 82810CB4: D3C107F0  stfs f30, 0x7f0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2032 as u32), tmp.u32 ) };
	// 82810CB8: 9BE107FC  stb r31, 0x7fc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2044 as u32), ctx.r[31].u8 ) };
	// 82810CBC: D3E107F4  stfs f31, 0x7f4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2036 as u32), tmp.u32 ) };
	// 82810CC0: 38610800  addi r3, r1, 0x800
	ctx.r[3].s64 = ctx.r[1].s64 + 2048;
	// 82810CC4: D3E107F8  stfs f31, 0x7f8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2040 as u32), tmp.u32 ) };
	// 82810CC8: 816BF47C  lwz r11, -0xb84(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2948 as u32) ) } as u64;
	// 82810CCC: 916107E0  stw r11, 0x7e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2016 as u32), ctx.r[11].u32 ) };
	// 82810CD0: 485EDBF9  bl 0x82dfe8c8
	ctx.lr = 0x82810CD4;
	sub_82DFE8C8(ctx, base);
	// 82810CD4: 38610808  addi r3, r1, 0x808
	ctx.r[3].s64 = ctx.r[1].s64 + 2056;
	// 82810CD8: 485EDBF1  bl 0x82dfe8c8
	ctx.lr = 0x82810CDC;
	sub_82DFE8C8(ctx, base);
	// 82810CDC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810CE0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810CE4: 93C1081C  stw r30, 0x81c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2076 as u32), ctx.r[30].u32 ) };
	// 82810CE8: D0010818  stfs f0, 0x818(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2072 as u32), tmp.u32 ) };
	// 82810CEC: 93810814  stw r28, 0x814(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2068 as u32), ctx.r[28].u32 ) };
	// 82810CF0: D3C10820  stfs f30, 0x820(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2080 as u32), tmp.u32 ) };
	// 82810CF4: 9BE1082C  stb r31, 0x82c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2092 as u32), ctx.r[31].u8 ) };
	// 82810CF8: D3E10824  stfs f31, 0x824(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2084 as u32), tmp.u32 ) };
	// 82810CFC: 38610830  addi r3, r1, 0x830
	ctx.r[3].s64 = ctx.r[1].s64 + 2096;
	// 82810D00: D3E10828  stfs f31, 0x828(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2088 as u32), tmp.u32 ) };
	// 82810D04: 816BF480  lwz r11, -0xb80(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2944 as u32) ) } as u64;
	// 82810D08: 91610810  stw r11, 0x810(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2064 as u32), ctx.r[11].u32 ) };
	// 82810D0C: 485EDBBD  bl 0x82dfe8c8
	ctx.lr = 0x82810D10;
	sub_82DFE8C8(ctx, base);
	// 82810D10: 38610838  addi r3, r1, 0x838
	ctx.r[3].s64 = ctx.r[1].s64 + 2104;
	// 82810D14: 485EDBB5  bl 0x82dfe8c8
	ctx.lr = 0x82810D18;
	sub_82DFE8C8(ctx, base);
	// 82810D18: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810D1C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810D20: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810D24: D0010848  stfs f0, 0x848(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2120 as u32), tmp.u32 ) };
	// 82810D28: 93C1084C  stw r30, 0x84c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2124 as u32), ctx.r[30].u32 ) };
	// 82810D2C: 394A8CE0  addi r10, r10, -0x7320
	ctx.r[10].s64 = ctx.r[10].s64 + -29472;
	// 82810D30: D3C10850  stfs f30, 0x850(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2128 as u32), tmp.u32 ) };
	// 82810D34: D3E10854  stfs f31, 0x854(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2132 as u32), tmp.u32 ) };
	// 82810D38: 9BE1085C  stb r31, 0x85c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2140 as u32), ctx.r[31].u8 ) };
	// 82810D3C: D3E10858  stfs f31, 0x858(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2136 as u32), tmp.u32 ) };
	// 82810D40: 91410844  stw r10, 0x844(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2116 as u32), ctx.r[10].u32 ) };
	// 82810D44: 38610860  addi r3, r1, 0x860
	ctx.r[3].s64 = ctx.r[1].s64 + 2144;
	// 82810D48: 816BF45C  lwz r11, -0xba4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2980 as u32) ) } as u64;
	// 82810D4C: 91610840  stw r11, 0x840(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2112 as u32), ctx.r[11].u32 ) };
	// 82810D50: 485EDB79  bl 0x82dfe8c8
	ctx.lr = 0x82810D54;
	sub_82DFE8C8(ctx, base);
	// 82810D54: 38610868  addi r3, r1, 0x868
	ctx.r[3].s64 = ctx.r[1].s64 + 2152;
	// 82810D58: 485EDB71  bl 0x82dfe8c8
	ctx.lr = 0x82810D5C;
	sub_82DFE8C8(ctx, base);
	// 82810D5C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810D60: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810D64: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810D68: 816BF460  lwz r11, -0xba0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2976 as u32) ) } as u64;
	// 82810D6C: 394A8CCC  addi r10, r10, -0x7334
	ctx.r[10].s64 = ctx.r[10].s64 + -29492;
	// 82810D70: D0010878  stfs f0, 0x878(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2168 as u32), tmp.u32 ) };
	// 82810D74: 93C1087C  stw r30, 0x87c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2172 as u32), ctx.r[30].u32 ) };
	// 82810D78: D3C10880  stfs f30, 0x880(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2176 as u32), tmp.u32 ) };
	// 82810D7C: 9BE1088C  stb r31, 0x88c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2188 as u32), ctx.r[31].u8 ) };
	// 82810D80: D3E10884  stfs f31, 0x884(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2180 as u32), tmp.u32 ) };
	// 82810D84: 91410874  stw r10, 0x874(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2164 as u32), ctx.r[10].u32 ) };
	// 82810D88: D3E10888  stfs f31, 0x888(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2184 as u32), tmp.u32 ) };
	// 82810D8C: 38610890  addi r3, r1, 0x890
	ctx.r[3].s64 = ctx.r[1].s64 + 2192;
	// 82810D90: 91610870  stw r11, 0x870(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2160 as u32), ctx.r[11].u32 ) };
	// 82810D94: 485EDB35  bl 0x82dfe8c8
	ctx.lr = 0x82810D98;
	sub_82DFE8C8(ctx, base);
	// 82810D98: 38610898  addi r3, r1, 0x898
	ctx.r[3].s64 = ctx.r[1].s64 + 2200;
	// 82810D9C: 485EDB2D  bl 0x82dfe8c8
	ctx.lr = 0x82810DA0;
	sub_82DFE8C8(ctx, base);
	// 82810DA0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810DA4: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810DA8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810DAC: D00108A8  stfs f0, 0x8a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2216 as u32), tmp.u32 ) };
	// 82810DB0: 93C108AC  stw r30, 0x8ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2220 as u32), ctx.r[30].u32 ) };
	// 82810DB4: 394A8AA0  addi r10, r10, -0x7560
	ctx.r[10].s64 = ctx.r[10].s64 + -30048;
	// 82810DB8: D3C108B0  stfs f30, 0x8b0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2224 as u32), tmp.u32 ) };
	// 82810DBC: D3E108B4  stfs f31, 0x8b4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2228 as u32), tmp.u32 ) };
	// 82810DC0: 9BE108BC  stb r31, 0x8bc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2236 as u32), ctx.r[31].u8 ) };
	// 82810DC4: D3E108B8  stfs f31, 0x8b8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2232 as u32), tmp.u32 ) };
	// 82810DC8: 914108A4  stw r10, 0x8a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2212 as u32), ctx.r[10].u32 ) };
	// 82810DCC: 386108C0  addi r3, r1, 0x8c0
	ctx.r[3].s64 = ctx.r[1].s64 + 2240;
	// 82810DD0: 816BF424  lwz r11, -0xbdc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3036 as u32) ) } as u64;
	// 82810DD4: 916108A0  stw r11, 0x8a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2208 as u32), ctx.r[11].u32 ) };
	// 82810DD8: 485EDAF1  bl 0x82dfe8c8
	ctx.lr = 0x82810DDC;
	sub_82DFE8C8(ctx, base);
	// 82810DDC: 386108C8  addi r3, r1, 0x8c8
	ctx.r[3].s64 = ctx.r[1].s64 + 2248;
	// 82810DE0: 485EDAE9  bl 0x82dfe8c8
	ctx.lr = 0x82810DE4;
	sub_82DFE8C8(ctx, base);
	// 82810DE4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810DE8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810DEC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810DF0: D00108D8  stfs f0, 0x8d8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2264 as u32), tmp.u32 ) };
	// 82810DF4: 93C108DC  stw r30, 0x8dc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2268 as u32), ctx.r[30].u32 ) };
	// 82810DF8: 394A8A8C  addi r10, r10, -0x7574
	ctx.r[10].s64 = ctx.r[10].s64 + -30068;
	// 82810DFC: D3C108E0  stfs f30, 0x8e0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2272 as u32), tmp.u32 ) };
	// 82810E00: D3E108E4  stfs f31, 0x8e4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2276 as u32), tmp.u32 ) };
	// 82810E04: 9BE108EC  stb r31, 0x8ec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2284 as u32), ctx.r[31].u8 ) };
	// 82810E08: D3E108E8  stfs f31, 0x8e8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2280 as u32), tmp.u32 ) };
	// 82810E0C: 914108D4  stw r10, 0x8d4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2260 as u32), ctx.r[10].u32 ) };
	// 82810E10: 386108F0  addi r3, r1, 0x8f0
	ctx.r[3].s64 = ctx.r[1].s64 + 2288;
	// 82810E14: 816BF428  lwz r11, -0xbd8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3032 as u32) ) } as u64;
	// 82810E18: 916108D0  stw r11, 0x8d0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2256 as u32), ctx.r[11].u32 ) };
	// 82810E1C: 485EDAAD  bl 0x82dfe8c8
	ctx.lr = 0x82810E20;
	sub_82DFE8C8(ctx, base);
	// 82810E20: 386108F8  addi r3, r1, 0x8f8
	ctx.r[3].s64 = ctx.r[1].s64 + 2296;
	// 82810E24: 485EDAA5  bl 0x82dfe8c8
	ctx.lr = 0x82810E28;
	sub_82DFE8C8(ctx, base);
	// 82810E28: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810E2C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810E30: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810E34: D0010908  stfs f0, 0x908(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2312 as u32), tmp.u32 ) };
	// 82810E38: 93E1090C  stw r31, 0x90c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2316 as u32), ctx.r[31].u32 ) };
	// 82810E3C: 394A8A74  addi r10, r10, -0x758c
	ctx.r[10].s64 = ctx.r[10].s64 + -30092;
	// 82810E40: D3C10910  stfs f30, 0x910(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2320 as u32), tmp.u32 ) };
	// 82810E44: D3E10914  stfs f31, 0x914(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2324 as u32), tmp.u32 ) };
	// 82810E48: 9BE1091C  stb r31, 0x91c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2332 as u32), ctx.r[31].u8 ) };
	// 82810E4C: D3E10918  stfs f31, 0x918(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2328 as u32), tmp.u32 ) };
	// 82810E50: 91410904  stw r10, 0x904(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2308 as u32), ctx.r[10].u32 ) };
	// 82810E54: 38610920  addi r3, r1, 0x920
	ctx.r[3].s64 = ctx.r[1].s64 + 2336;
	// 82810E58: 816BF42C  lwz r11, -0xbd4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3028 as u32) ) } as u64;
	// 82810E5C: 91610900  stw r11, 0x900(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2304 as u32), ctx.r[11].u32 ) };
	// 82810E60: 485EDA69  bl 0x82dfe8c8
	ctx.lr = 0x82810E64;
	sub_82DFE8C8(ctx, base);
	// 82810E64: 38610928  addi r3, r1, 0x928
	ctx.r[3].s64 = ctx.r[1].s64 + 2344;
	// 82810E68: 485EDA61  bl 0x82dfe8c8
	ctx.lr = 0x82810E6C;
	sub_82DFE8C8(ctx, base);
	// 82810E6C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810E70: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810E74: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810E78: D0010938  stfs f0, 0x938(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2360 as u32), tmp.u32 ) };
	// 82810E7C: 93C1093C  stw r30, 0x93c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2364 as u32), ctx.r[30].u32 ) };
	// 82810E80: 394A8A60  addi r10, r10, -0x75a0
	ctx.r[10].s64 = ctx.r[10].s64 + -30112;
	// 82810E84: D3C10940  stfs f30, 0x940(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2368 as u32), tmp.u32 ) };
	// 82810E88: D3E10944  stfs f31, 0x944(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2372 as u32), tmp.u32 ) };
	// 82810E8C: 9BE1094C  stb r31, 0x94c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2380 as u32), ctx.r[31].u8 ) };
	// 82810E90: D3E10948  stfs f31, 0x948(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2376 as u32), tmp.u32 ) };
	// 82810E94: 91410934  stw r10, 0x934(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2356 as u32), ctx.r[10].u32 ) };
	// 82810E98: 38610950  addi r3, r1, 0x950
	ctx.r[3].s64 = ctx.r[1].s64 + 2384;
	// 82810E9C: 816BF444  lwz r11, -0xbbc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3004 as u32) ) } as u64;
	// 82810EA0: 91610930  stw r11, 0x930(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2352 as u32), ctx.r[11].u32 ) };
	// 82810EA4: 485EDA25  bl 0x82dfe8c8
	ctx.lr = 0x82810EA8;
	sub_82DFE8C8(ctx, base);
	// 82810EA8: 38610958  addi r3, r1, 0x958
	ctx.r[3].s64 = ctx.r[1].s64 + 2392;
	// 82810EAC: 485EDA1D  bl 0x82dfe8c8
	ctx.lr = 0x82810EB0;
	sub_82DFE8C8(ctx, base);
	// 82810EB0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810EB4: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810EB8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810EBC: D0010968  stfs f0, 0x968(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2408 as u32), tmp.u32 ) };
	// 82810EC0: 93C1096C  stw r30, 0x96c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2412 as u32), ctx.r[30].u32 ) };
	// 82810EC4: 394A8A44  addi r10, r10, -0x75bc
	ctx.r[10].s64 = ctx.r[10].s64 + -30140;
	// 82810EC8: D3C10970  stfs f30, 0x970(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2416 as u32), tmp.u32 ) };
	// 82810ECC: D3E10974  stfs f31, 0x974(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2420 as u32), tmp.u32 ) };
	// 82810ED0: 9BE1097C  stb r31, 0x97c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2428 as u32), ctx.r[31].u8 ) };
	// 82810ED4: D3E10978  stfs f31, 0x978(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2424 as u32), tmp.u32 ) };
	// 82810ED8: 91410964  stw r10, 0x964(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2404 as u32), ctx.r[10].u32 ) };
	// 82810EDC: 38610980  addi r3, r1, 0x980
	ctx.r[3].s64 = ctx.r[1].s64 + 2432;
	// 82810EE0: 816BF448  lwz r11, -0xbb8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3000 as u32) ) } as u64;
	// 82810EE4: 91610960  stw r11, 0x960(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2400 as u32), ctx.r[11].u32 ) };
	// 82810EE8: 485ED9E1  bl 0x82dfe8c8
	ctx.lr = 0x82810EEC;
	sub_82DFE8C8(ctx, base);
	// 82810EEC: 38610988  addi r3, r1, 0x988
	ctx.r[3].s64 = ctx.r[1].s64 + 2440;
	// 82810EF0: 485ED9D9  bl 0x82dfe8c8
	ctx.lr = 0x82810EF4;
	sub_82DFE8C8(ctx, base);
	// 82810EF4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810EF8: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810EFC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810F00: D0010998  stfs f0, 0x998(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2456 as u32), tmp.u32 ) };
	// 82810F04: 93C1099C  stw r30, 0x99c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2460 as u32), ctx.r[30].u32 ) };
	// 82810F08: 394A8A2C  addi r10, r10, -0x75d4
	ctx.r[10].s64 = ctx.r[10].s64 + -30164;
	// 82810F0C: D3C109A0  stfs f30, 0x9a0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2464 as u32), tmp.u32 ) };
	// 82810F10: D3E109A4  stfs f31, 0x9a4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2468 as u32), tmp.u32 ) };
	// 82810F14: 9BE109AC  stb r31, 0x9ac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2476 as u32), ctx.r[31].u8 ) };
	// 82810F18: D3E109A8  stfs f31, 0x9a8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2472 as u32), tmp.u32 ) };
	// 82810F1C: 91410994  stw r10, 0x994(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2452 as u32), ctx.r[10].u32 ) };
	// 82810F20: 386109B0  addi r3, r1, 0x9b0
	ctx.r[3].s64 = ctx.r[1].s64 + 2480;
	// 82810F24: 816BF430  lwz r11, -0xbd0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3024 as u32) ) } as u64;
	// 82810F28: 91610990  stw r11, 0x990(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2448 as u32), ctx.r[11].u32 ) };
	// 82810F2C: 485ED99D  bl 0x82dfe8c8
	ctx.lr = 0x82810F30;
	sub_82DFE8C8(ctx, base);
	// 82810F30: 386109B8  addi r3, r1, 0x9b8
	ctx.r[3].s64 = ctx.r[1].s64 + 2488;
	// 82810F34: 485ED995  bl 0x82dfe8c8
	ctx.lr = 0x82810F38;
	sub_82DFE8C8(ctx, base);
	// 82810F38: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810F3C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82810F40: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810F44: D00109C8  stfs f0, 0x9c8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2504 as u32), tmp.u32 ) };
	// 82810F48: 93E109CC  stw r31, 0x9cc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2508 as u32), ctx.r[31].u32 ) };
	// 82810F4C: 394A8A18  addi r10, r10, -0x75e8
	ctx.r[10].s64 = ctx.r[10].s64 + -30184;
	// 82810F50: D3C109D0  stfs f30, 0x9d0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2512 as u32), tmp.u32 ) };
	// 82810F54: D3E109D4  stfs f31, 0x9d4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2516 as u32), tmp.u32 ) };
	// 82810F58: 9BE109DC  stb r31, 0x9dc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2524 as u32), ctx.r[31].u8 ) };
	// 82810F5C: D3E109D8  stfs f31, 0x9d8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2520 as u32), tmp.u32 ) };
	// 82810F60: 914109C4  stw r10, 0x9c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2500 as u32), ctx.r[10].u32 ) };
	// 82810F64: 386109E0  addi r3, r1, 0x9e0
	ctx.r[3].s64 = ctx.r[1].s64 + 2528;
	// 82810F68: 816BF434  lwz r11, -0xbcc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3020 as u32) ) } as u64;
	// 82810F6C: 916109C0  stw r11, 0x9c0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2496 as u32), ctx.r[11].u32 ) };
	// 82810F70: 485ED959  bl 0x82dfe8c8
	ctx.lr = 0x82810F74;
	sub_82DFE8C8(ctx, base);
	// 82810F74: 386109E8  addi r3, r1, 0x9e8
	ctx.r[3].s64 = ctx.r[1].s64 + 2536;
	// 82810F78: 485ED951  bl 0x82dfe8c8
	ctx.lr = 0x82810F7C;
	sub_82DFE8C8(ctx, base);
	// 82810F7C: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810F80: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810F84: 938109F4  stw r28, 0x9f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2548 as u32), ctx.r[28].u32 ) };
	// 82810F88: D00109F8  stfs f0, 0x9f8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2552 as u32), tmp.u32 ) };
	// 82810F8C: 93C109FC  stw r30, 0x9fc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2556 as u32), ctx.r[30].u32 ) };
	// 82810F90: D3C10A00  stfs f30, 0xa00(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2560 as u32), tmp.u32 ) };
	// 82810F94: 9BE10A0C  stb r31, 0xa0c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2572 as u32), ctx.r[31].u8 ) };
	// 82810F98: D3E10A04  stfs f31, 0xa04(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2564 as u32), tmp.u32 ) };
	// 82810F9C: 38610A10  addi r3, r1, 0xa10
	ctx.r[3].s64 = ctx.r[1].s64 + 2576;
	// 82810FA0: D3E10A08  stfs f31, 0xa08(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2568 as u32), tmp.u32 ) };
	// 82810FA4: 816BF438  lwz r11, -0xbc8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3016 as u32) ) } as u64;
	// 82810FA8: 916109F0  stw r11, 0x9f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2544 as u32), ctx.r[11].u32 ) };
	// 82810FAC: 485ED91D  bl 0x82dfe8c8
	ctx.lr = 0x82810FB0;
	sub_82DFE8C8(ctx, base);
	// 82810FB0: 38610A18  addi r3, r1, 0xa18
	ctx.r[3].s64 = ctx.r[1].s64 + 2584;
	// 82810FB4: 485ED915  bl 0x82dfe8c8
	ctx.lr = 0x82810FB8;
	sub_82DFE8C8(ctx, base);
	// 82810FB8: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810FBC: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810FC0: 93C10A2C  stw r30, 0xa2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2604 as u32), ctx.r[30].u32 ) };
	// 82810FC4: D0010A28  stfs f0, 0xa28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2600 as u32), tmp.u32 ) };
	// 82810FC8: 93810A24  stw r28, 0xa24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2596 as u32), ctx.r[28].u32 ) };
	// 82810FCC: D3C10A30  stfs f30, 0xa30(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2608 as u32), tmp.u32 ) };
	// 82810FD0: 9BE10A3C  stb r31, 0xa3c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2620 as u32), ctx.r[31].u8 ) };
	// 82810FD4: D3E10A34  stfs f31, 0xa34(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2612 as u32), tmp.u32 ) };
	// 82810FD8: 38610A40  addi r3, r1, 0xa40
	ctx.r[3].s64 = ctx.r[1].s64 + 2624;
	// 82810FDC: D3E10A38  stfs f31, 0xa38(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2616 as u32), tmp.u32 ) };
	// 82810FE0: 816BF43C  lwz r11, -0xbc4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3012 as u32) ) } as u64;
	// 82810FE4: 91610A20  stw r11, 0xa20(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2592 as u32), ctx.r[11].u32 ) };
	// 82810FE8: 485ED8E1  bl 0x82dfe8c8
	ctx.lr = 0x82810FEC;
	sub_82DFE8C8(ctx, base);
	// 82810FEC: 38610A48  addi r3, r1, 0xa48
	ctx.r[3].s64 = ctx.r[1].s64 + 2632;
	// 82810FF0: 485ED8D9  bl 0x82dfe8c8
	ctx.lr = 0x82810FF4;
	sub_82DFE8C8(ctx, base);
	// 82810FF4: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82810FF8: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82810FFC: 93C10A5C  stw r30, 0xa5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2652 as u32), ctx.r[30].u32 ) };
	// 82811000: D0010A58  stfs f0, 0xa58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2648 as u32), tmp.u32 ) };
	// 82811004: 93810A54  stw r28, 0xa54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2644 as u32), ctx.r[28].u32 ) };
	// 82811008: D3C10A60  stfs f30, 0xa60(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2656 as u32), tmp.u32 ) };
	// 8281100C: 9BE10A6C  stb r31, 0xa6c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2668 as u32), ctx.r[31].u8 ) };
	// 82811010: D3E10A64  stfs f31, 0xa64(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2660 as u32), tmp.u32 ) };
	// 82811014: 38610A70  addi r3, r1, 0xa70
	ctx.r[3].s64 = ctx.r[1].s64 + 2672;
	// 82811018: D3E10A68  stfs f31, 0xa68(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2664 as u32), tmp.u32 ) };
	// 8281101C: 816BF44C  lwz r11, -0xbb4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2996 as u32) ) } as u64;
	// 82811020: 91610A50  stw r11, 0xa50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2640 as u32), ctx.r[11].u32 ) };
	// 82811024: 485ED8A5  bl 0x82dfe8c8
	ctx.lr = 0x82811028;
	sub_82DFE8C8(ctx, base);
	// 82811028: 38610A78  addi r3, r1, 0xa78
	ctx.r[3].s64 = ctx.r[1].s64 + 2680;
	// 8281102C: 485ED89D  bl 0x82dfe8c8
	ctx.lr = 0x82811030;
	sub_82DFE8C8(ctx, base);
	// 82811030: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811034: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811038: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281103C: D0010A88  stfs f0, 0xa88(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2696 as u32), tmp.u32 ) };
	// 82811040: 93C10A8C  stw r30, 0xa8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2700 as u32), ctx.r[30].u32 ) };
	// 82811044: 394A8CB8  addi r10, r10, -0x7348
	ctx.r[10].s64 = ctx.r[10].s64 + -29512;
	// 82811048: D3C10A90  stfs f30, 0xa90(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2704 as u32), tmp.u32 ) };
	// 8281104C: D3E10A94  stfs f31, 0xa94(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2708 as u32), tmp.u32 ) };
	// 82811050: 9BE10A9C  stb r31, 0xa9c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2716 as u32), ctx.r[31].u8 ) };
	// 82811054: D3E10A98  stfs f31, 0xa98(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2712 as u32), tmp.u32 ) };
	// 82811058: 91410A84  stw r10, 0xa84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2692 as u32), ctx.r[10].u32 ) };
	// 8281105C: 38610AA0  addi r3, r1, 0xaa0
	ctx.r[3].s64 = ctx.r[1].s64 + 2720;
	// 82811060: 816BF454  lwz r11, -0xbac(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2988 as u32) ) } as u64;
	// 82811064: 91610A80  stw r11, 0xa80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2688 as u32), ctx.r[11].u32 ) };
	// 82811068: 485ED861  bl 0x82dfe8c8
	ctx.lr = 0x8281106C;
	sub_82DFE8C8(ctx, base);
	// 8281106C: 38610AA8  addi r3, r1, 0xaa8
	ctx.r[3].s64 = ctx.r[1].s64 + 2728;
	// 82811070: 485ED859  bl 0x82dfe8c8
	ctx.lr = 0x82811074;
	sub_82DFE8C8(ctx, base);
	// 82811074: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811078: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281107C: 93C10ABC  stw r30, 0xabc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2748 as u32), ctx.r[30].u32 ) };
	// 82811080: D0010AB8  stfs f0, 0xab8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2744 as u32), tmp.u32 ) };
	// 82811084: 93810AB4  stw r28, 0xab4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2740 as u32), ctx.r[28].u32 ) };
	// 82811088: D3C10AC0  stfs f30, 0xac0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2752 as u32), tmp.u32 ) };
	// 8281108C: 9BE10ACC  stb r31, 0xacc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2764 as u32), ctx.r[31].u8 ) };
	// 82811090: D3E10AC4  stfs f31, 0xac4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2756 as u32), tmp.u32 ) };
	// 82811094: 38610AD0  addi r3, r1, 0xad0
	ctx.r[3].s64 = ctx.r[1].s64 + 2768;
	// 82811098: D3E10AC8  stfs f31, 0xac8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2760 as u32), tmp.u32 ) };
	// 8281109C: 816BF484  lwz r11, -0xb7c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2940 as u32) ) } as u64;
	// 828110A0: 91610AB0  stw r11, 0xab0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2736 as u32), ctx.r[11].u32 ) };
	// 828110A4: 485ED825  bl 0x82dfe8c8
	ctx.lr = 0x828110A8;
	sub_82DFE8C8(ctx, base);
	// 828110A8: 38610AD8  addi r3, r1, 0xad8
	ctx.r[3].s64 = ctx.r[1].s64 + 2776;
	// 828110AC: 485ED81D  bl 0x82dfe8c8
	ctx.lr = 0x828110B0;
	sub_82DFE8C8(ctx, base);
	// 828110B0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828110B4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828110B8: 93C10AEC  stw r30, 0xaec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2796 as u32), ctx.r[30].u32 ) };
	// 828110BC: D0010AE8  stfs f0, 0xae8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2792 as u32), tmp.u32 ) };
	// 828110C0: 93810AE4  stw r28, 0xae4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2788 as u32), ctx.r[28].u32 ) };
	// 828110C4: D3C10AF0  stfs f30, 0xaf0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2800 as u32), tmp.u32 ) };
	// 828110C8: 9BE10AFC  stb r31, 0xafc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2812 as u32), ctx.r[31].u8 ) };
	// 828110CC: D3E10AF4  stfs f31, 0xaf4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2804 as u32), tmp.u32 ) };
	// 828110D0: 38610B00  addi r3, r1, 0xb00
	ctx.r[3].s64 = ctx.r[1].s64 + 2816;
	// 828110D4: D3E10AF8  stfs f31, 0xaf8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2808 as u32), tmp.u32 ) };
	// 828110D8: 816BF420  lwz r11, -0xbe0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3040 as u32) ) } as u64;
	// 828110DC: 91610AE0  stw r11, 0xae0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2784 as u32), ctx.r[11].u32 ) };
	// 828110E0: 485ED7E9  bl 0x82dfe8c8
	ctx.lr = 0x828110E4;
	sub_82DFE8C8(ctx, base);
	// 828110E4: 38610B08  addi r3, r1, 0xb08
	ctx.r[3].s64 = ctx.r[1].s64 + 2824;
	// 828110E8: 485ED7E1  bl 0x82dfe8c8
	ctx.lr = 0x828110EC;
	sub_82DFE8C8(ctx, base);
	// 828110EC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828110F0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828110F4: 93C10B1C  stw r30, 0xb1c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2844 as u32), ctx.r[30].u32 ) };
	// 828110F8: D0010B18  stfs f0, 0xb18(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2840 as u32), tmp.u32 ) };
	// 828110FC: 93810B14  stw r28, 0xb14(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2836 as u32), ctx.r[28].u32 ) };
	// 82811100: D3C10B20  stfs f30, 0xb20(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2848 as u32), tmp.u32 ) };
	// 82811104: 9BE10B2C  stb r31, 0xb2c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2860 as u32), ctx.r[31].u8 ) };
	// 82811108: D3E10B24  stfs f31, 0xb24(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2852 as u32), tmp.u32 ) };
	// 8281110C: 38610B30  addi r3, r1, 0xb30
	ctx.r[3].s64 = ctx.r[1].s64 + 2864;
	// 82811110: D3E10B28  stfs f31, 0xb28(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2856 as u32), tmp.u32 ) };
	// 82811114: 816BF464  lwz r11, -0xb9c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2972 as u32) ) } as u64;
	// 82811118: 91610B10  stw r11, 0xb10(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2832 as u32), ctx.r[11].u32 ) };
	// 8281111C: 485ED7AD  bl 0x82dfe8c8
	ctx.lr = 0x82811120;
	sub_82DFE8C8(ctx, base);
	// 82811120: 38610B38  addi r3, r1, 0xb38
	ctx.r[3].s64 = ctx.r[1].s64 + 2872;
	// 82811124: 485ED7A5  bl 0x82dfe8c8
	ctx.lr = 0x82811128;
	sub_82DFE8C8(ctx, base);
	// 82811128: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281112C: D0010B48  stfs f0, 0xb48(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2888 as u32), tmp.u32 ) };
	// 82811130: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811134: 816BF4A0  lwz r11, -0xb60(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2912 as u32) ) } as u64;
	// 82811138: D3C10B50  stfs f30, 0xb50(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2896 as u32), tmp.u32 ) };
	// 8281113C: D3E10B54  stfs f31, 0xb54(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2900 as u32), tmp.u32 ) };
	// 82811140: 93C10B4C  stw r30, 0xb4c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2892 as u32), ctx.r[30].u32 ) };
	// 82811144: D3E10B58  stfs f31, 0xb58(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2904 as u32), tmp.u32 ) };
	// 82811148: 93810B44  stw r28, 0xb44(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2884 as u32), ctx.r[28].u32 ) };
	// 8281114C: 9BE10B5C  stb r31, 0xb5c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2908 as u32), ctx.r[31].u8 ) };
	// 82811150: 38610B60  addi r3, r1, 0xb60
	ctx.r[3].s64 = ctx.r[1].s64 + 2912;
	// 82811154: 91610B40  stw r11, 0xb40(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2880 as u32), ctx.r[11].u32 ) };
	// 82811158: 485ED771  bl 0x82dfe8c8
	ctx.lr = 0x8281115C;
	sub_82DFE8C8(ctx, base);
	// 8281115C: 38610B68  addi r3, r1, 0xb68
	ctx.r[3].s64 = ctx.r[1].s64 + 2920;
	// 82811160: 485ED769  bl 0x82dfe8c8
	ctx.lr = 0x82811164;
	sub_82DFE8C8(ctx, base);
	// 82811164: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811168: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281116C: 93C10B7C  stw r30, 0xb7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2940 as u32), ctx.r[30].u32 ) };
	// 82811170: D0010B78  stfs f0, 0xb78(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2936 as u32), tmp.u32 ) };
	// 82811174: 93810B74  stw r28, 0xb74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2932 as u32), ctx.r[28].u32 ) };
	// 82811178: D3C10B80  stfs f30, 0xb80(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2944 as u32), tmp.u32 ) };
	// 8281117C: 9BE10B8C  stb r31, 0xb8c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(2956 as u32), ctx.r[31].u8 ) };
	// 82811180: D3E10B84  stfs f31, 0xb84(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2948 as u32), tmp.u32 ) };
	// 82811184: 38610B90  addi r3, r1, 0xb90
	ctx.r[3].s64 = ctx.r[1].s64 + 2960;
	// 82811188: D3E10B88  stfs f31, 0xb88(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2952 as u32), tmp.u32 ) };
	// 8281118C: 816BF4A8  lwz r11, -0xb58(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2904 as u32) ) } as u64;
	// 82811190: 91610B70  stw r11, 0xb70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2928 as u32), ctx.r[11].u32 ) };
	// 82811194: 485ED735  bl 0x82dfe8c8
	ctx.lr = 0x82811198;
	sub_82DFE8C8(ctx, base);
	// 82811198: 38610B98  addi r3, r1, 0xb98
	ctx.r[3].s64 = ctx.r[1].s64 + 2968;
	// 8281119C: 485ED72D  bl 0x82dfe8c8
	ctx.lr = 0x828111A0;
	sub_82DFE8C8(ctx, base);
	// 828111A0: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828111A4: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828111A8: 93C10BAC  stw r30, 0xbac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2988 as u32), ctx.r[30].u32 ) };
	// 828111AC: D0010BA8  stfs f0, 0xba8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2984 as u32), tmp.u32 ) };
	// 828111B0: 93810BA4  stw r28, 0xba4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2980 as u32), ctx.r[28].u32 ) };
	// 828111B4: D3C10BB0  stfs f30, 0xbb0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2992 as u32), tmp.u32 ) };
	// 828111B8: 9BE10BBC  stb r31, 0xbbc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3004 as u32), ctx.r[31].u8 ) };
	// 828111BC: D3E10BB4  stfs f31, 0xbb4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2996 as u32), tmp.u32 ) };
	// 828111C0: 38610BC0  addi r3, r1, 0xbc0
	ctx.r[3].s64 = ctx.r[1].s64 + 3008;
	// 828111C4: D3E10BB8  stfs f31, 0xbb8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3000 as u32), tmp.u32 ) };
	// 828111C8: 816BF4B0  lwz r11, -0xb50(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2896 as u32) ) } as u64;
	// 828111CC: 91610BA0  stw r11, 0xba0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(2976 as u32), ctx.r[11].u32 ) };
	// 828111D0: 485ED6F9  bl 0x82dfe8c8
	ctx.lr = 0x828111D4;
	sub_82DFE8C8(ctx, base);
	// 828111D4: 38610BC8  addi r3, r1, 0xbc8
	ctx.r[3].s64 = ctx.r[1].s64 + 3016;
	// 828111D8: 485ED6F1  bl 0x82dfe8c8
	ctx.lr = 0x828111DC;
	sub_82DFE8C8(ctx, base);
	// 828111DC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828111E0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828111E4: 93E10BDC  stw r31, 0xbdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3036 as u32), ctx.r[31].u32 ) };
	// 828111E8: D0010BD8  stfs f0, 0xbd8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3032 as u32), tmp.u32 ) };
	// 828111EC: 93810BD4  stw r28, 0xbd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3028 as u32), ctx.r[28].u32 ) };
	// 828111F0: D3C10BE0  stfs f30, 0xbe0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3040 as u32), tmp.u32 ) };
	// 828111F4: 9BE10BEC  stb r31, 0xbec(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3052 as u32), ctx.r[31].u8 ) };
	// 828111F8: D3E10BE4  stfs f31, 0xbe4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3044 as u32), tmp.u32 ) };
	// 828111FC: 38610BF0  addi r3, r1, 0xbf0
	ctx.r[3].s64 = ctx.r[1].s64 + 3056;
	// 82811200: D3E10BE8  stfs f31, 0xbe8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3048 as u32), tmp.u32 ) };
	// 82811204: 816BF4B4  lwz r11, -0xb4c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2892 as u32) ) } as u64;
	// 82811208: 91610BD0  stw r11, 0xbd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3024 as u32), ctx.r[11].u32 ) };
	// 8281120C: 485ED6BD  bl 0x82dfe8c8
	ctx.lr = 0x82811210;
	sub_82DFE8C8(ctx, base);
	// 82811210: 38610BF8  addi r3, r1, 0xbf8
	ctx.r[3].s64 = ctx.r[1].s64 + 3064;
	// 82811214: 485ED6B5  bl 0x82dfe8c8
	ctx.lr = 0x82811218;
	sub_82DFE8C8(ctx, base);
	// 82811218: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281121C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811220: 93C10C0C  stw r30, 0xc0c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3084 as u32), ctx.r[30].u32 ) };
	// 82811224: D0010C08  stfs f0, 0xc08(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3080 as u32), tmp.u32 ) };
	// 82811228: 93810C04  stw r28, 0xc04(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3076 as u32), ctx.r[28].u32 ) };
	// 8281122C: D3C10C10  stfs f30, 0xc10(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3088 as u32), tmp.u32 ) };
	// 82811230: 9BE10C1C  stb r31, 0xc1c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3100 as u32), ctx.r[31].u8 ) };
	// 82811234: D3E10C14  stfs f31, 0xc14(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3092 as u32), tmp.u32 ) };
	// 82811238: 38610C20  addi r3, r1, 0xc20
	ctx.r[3].s64 = ctx.r[1].s64 + 3104;
	// 8281123C: D3E10C18  stfs f31, 0xc18(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3096 as u32), tmp.u32 ) };
	// 82811240: 816BF4B8  lwz r11, -0xb48(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2888 as u32) ) } as u64;
	// 82811244: 91610C00  stw r11, 0xc00(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3072 as u32), ctx.r[11].u32 ) };
	// 82811248: 485ED681  bl 0x82dfe8c8
	ctx.lr = 0x8281124C;
	sub_82DFE8C8(ctx, base);
	// 8281124C: 38610C28  addi r3, r1, 0xc28
	ctx.r[3].s64 = ctx.r[1].s64 + 3112;
	// 82811250: 485ED679  bl 0x82dfe8c8
	ctx.lr = 0x82811254;
	sub_82DFE8C8(ctx, base);
	// 82811254: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811258: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281125C: 93E10C3C  stw r31, 0xc3c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3132 as u32), ctx.r[31].u32 ) };
	// 82811260: D0010C38  stfs f0, 0xc38(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3128 as u32), tmp.u32 ) };
	// 82811264: 93810C34  stw r28, 0xc34(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3124 as u32), ctx.r[28].u32 ) };
	// 82811268: D3C10C40  stfs f30, 0xc40(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3136 as u32), tmp.u32 ) };
	// 8281126C: D3E10C44  stfs f31, 0xc44(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3140 as u32), tmp.u32 ) };
	// 82811270: D3E10C48  stfs f31, 0xc48(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3144 as u32), tmp.u32 ) };
	// 82811274: 816BF4BC  lwz r11, -0xb44(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2884 as u32) ) } as u64;
	// 82811278: 9BE10C4C  stb r31, 0xc4c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3148 as u32), ctx.r[31].u8 ) };
	// 8281127C: 38610C50  addi r3, r1, 0xc50
	ctx.r[3].s64 = ctx.r[1].s64 + 3152;
	// 82811280: 91610C30  stw r11, 0xc30(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3120 as u32), ctx.r[11].u32 ) };
	// 82811284: 485ED645  bl 0x82dfe8c8
	ctx.lr = 0x82811288;
	sub_82DFE8C8(ctx, base);
	// 82811288: 38610C58  addi r3, r1, 0xc58
	ctx.r[3].s64 = ctx.r[1].s64 + 3160;
	// 8281128C: 485ED63D  bl 0x82dfe8c8
	ctx.lr = 0x82811290;
	sub_82DFE8C8(ctx, base);
	// 82811290: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811294: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811298: 93C10C6C  stw r30, 0xc6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3180 as u32), ctx.r[30].u32 ) };
	// 8281129C: D0010C68  stfs f0, 0xc68(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3176 as u32), tmp.u32 ) };
	// 828112A0: 93810C64  stw r28, 0xc64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3172 as u32), ctx.r[28].u32 ) };
	// 828112A4: D3C10C70  stfs f30, 0xc70(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3184 as u32), tmp.u32 ) };
	// 828112A8: 9BE10C7C  stb r31, 0xc7c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3196 as u32), ctx.r[31].u8 ) };
	// 828112AC: D3E10C74  stfs f31, 0xc74(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3188 as u32), tmp.u32 ) };
	// 828112B0: 38610C80  addi r3, r1, 0xc80
	ctx.r[3].s64 = ctx.r[1].s64 + 3200;
	// 828112B4: D3E10C78  stfs f31, 0xc78(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3192 as u32), tmp.u32 ) };
	// 828112B8: 816BF4C0  lwz r11, -0xb40(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2880 as u32) ) } as u64;
	// 828112BC: 91610C60  stw r11, 0xc60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3168 as u32), ctx.r[11].u32 ) };
	// 828112C0: 485ED609  bl 0x82dfe8c8
	ctx.lr = 0x828112C4;
	sub_82DFE8C8(ctx, base);
	// 828112C4: 38610C88  addi r3, r1, 0xc88
	ctx.r[3].s64 = ctx.r[1].s64 + 3208;
	// 828112C8: 485ED601  bl 0x82dfe8c8
	ctx.lr = 0x828112CC;
	sub_82DFE8C8(ctx, base);
	// 828112CC: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 828112D0: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828112D4: 93810C94  stw r28, 0xc94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3220 as u32), ctx.r[28].u32 ) };
	// 828112D8: D0010C98  stfs f0, 0xc98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3224 as u32), tmp.u32 ) };
	// 828112DC: 93C10C9C  stw r30, 0xc9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3228 as u32), ctx.r[30].u32 ) };
	// 828112E0: D3C10CA0  stfs f30, 0xca0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3232 as u32), tmp.u32 ) };
	// 828112E4: 9BE10CAC  stb r31, 0xcac(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3244 as u32), ctx.r[31].u8 ) };
	// 828112E8: D3E10CA4  stfs f31, 0xca4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3236 as u32), tmp.u32 ) };
	// 828112EC: 38610CB0  addi r3, r1, 0xcb0
	ctx.r[3].s64 = ctx.r[1].s64 + 3248;
	// 828112F0: D3E10CA8  stfs f31, 0xca8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3240 as u32), tmp.u32 ) };
	// 828112F4: 816BF4C4  lwz r11, -0xb3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2876 as u32) ) } as u64;
	// 828112F8: 91610C90  stw r11, 0xc90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3216 as u32), ctx.r[11].u32 ) };
	// 828112FC: 485ED5CD  bl 0x82dfe8c8
	ctx.lr = 0x82811300;
	sub_82DFE8C8(ctx, base);
	// 82811300: 38610CB8  addi r3, r1, 0xcb8
	ctx.r[3].s64 = ctx.r[1].s64 + 3256;
	// 82811304: 485ED5C5  bl 0x82dfe8c8
	ctx.lr = 0x82811308;
	sub_82DFE8C8(ctx, base);
	// 82811308: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 8281130C: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811310: 93C10CCC  stw r30, 0xccc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3276 as u32), ctx.r[30].u32 ) };
	// 82811314: D0010CC8  stfs f0, 0xcc8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3272 as u32), tmp.u32 ) };
	// 82811318: 93810CC4  stw r28, 0xcc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3268 as u32), ctx.r[28].u32 ) };
	// 8281131C: D3C10CD0  stfs f30, 0xcd0(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3280 as u32), tmp.u32 ) };
	// 82811320: 9BE10CDC  stb r31, 0xcdc(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3292 as u32), ctx.r[31].u8 ) };
	// 82811324: D3E10CD4  stfs f31, 0xcd4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3284 as u32), tmp.u32 ) };
	// 82811328: 38610CE0  addi r3, r1, 0xce0
	ctx.r[3].s64 = ctx.r[1].s64 + 3296;
	// 8281132C: D3E10CD8  stfs f31, 0xcd8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3288 as u32), tmp.u32 ) };
	// 82811330: 816BF4C8  lwz r11, -0xb38(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2872 as u32) ) } as u64;
	// 82811334: 91610CC0  stw r11, 0xcc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3264 as u32), ctx.r[11].u32 ) };
	// 82811338: 485ED591  bl 0x82dfe8c8
	ctx.lr = 0x8281133C;
	sub_82DFE8C8(ctx, base);
	// 8281133C: 38610CE8  addi r3, r1, 0xce8
	ctx.r[3].s64 = ctx.r[1].s64 + 3304;
	// 82811340: 485ED589  bl 0x82dfe8c8
	ctx.lr = 0x82811344;
	sub_82DFE8C8(ctx, base);
	// 82811344: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811348: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281134C: 93E10CFC  stw r31, 0xcfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3324 as u32), ctx.r[31].u32 ) };
	// 82811350: D0010CF8  stfs f0, 0xcf8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3320 as u32), tmp.u32 ) };
	// 82811354: 93810CF4  stw r28, 0xcf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3316 as u32), ctx.r[28].u32 ) };
	// 82811358: D3C10D00  stfs f30, 0xd00(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3328 as u32), tmp.u32 ) };
	// 8281135C: 9BE10D0C  stb r31, 0xd0c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3340 as u32), ctx.r[31].u8 ) };
	// 82811360: D3E10D04  stfs f31, 0xd04(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3332 as u32), tmp.u32 ) };
	// 82811364: 38610D10  addi r3, r1, 0xd10
	ctx.r[3].s64 = ctx.r[1].s64 + 3344;
	// 82811368: D3E10D08  stfs f31, 0xd08(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3336 as u32), tmp.u32 ) };
	// 8281136C: 816BF4CC  lwz r11, -0xb34(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2868 as u32) ) } as u64;
	// 82811370: 91610CF0  stw r11, 0xcf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3312 as u32), ctx.r[11].u32 ) };
	// 82811374: 485ED555  bl 0x82dfe8c8
	ctx.lr = 0x82811378;
	sub_82DFE8C8(ctx, base);
	// 82811378: 38610D18  addi r3, r1, 0xd18
	ctx.r[3].s64 = ctx.r[1].s64 + 3352;
	// 8281137C: 485ED54D  bl 0x82dfe8c8
	ctx.lr = 0x82811380;
	sub_82DFE8C8(ctx, base);
	// 82811380: 3D60832D  lis r11, -0x7cd3
	ctx.r[11].s64 = -2094202880;
	// 82811384: C01B08A8  lfs f0, 0x8a8(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811388: 93C10D2C  stw r30, 0xd2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3372 as u32), ctx.r[30].u32 ) };
	// 8281138C: D0010D28  stfs f0, 0xd28(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3368 as u32), tmp.u32 ) };
	// 82811390: 93810D24  stw r28, 0xd24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3364 as u32), ctx.r[28].u32 ) };
	// 82811394: D3C10D30  stfs f30, 0xd30(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3376 as u32), tmp.u32 ) };
	// 82811398: 9BE10D3C  stb r31, 0xd3c(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(3388 as u32), ctx.r[31].u8 ) };
	// 8281139C: D3E10D34  stfs f31, 0xd34(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3380 as u32), tmp.u32 ) };
	// 828113A0: 38610D40  addi r3, r1, 0xd40
	ctx.r[3].s64 = ctx.r[1].s64 + 3392;
	// 828113A4: D3E10D38  stfs f31, 0xd38(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3384 as u32), tmp.u32 ) };
	// 828113A8: 816BF4D0  lwz r11, -0xb30(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-2864 as u32) ) } as u64;
	// 828113AC: 91610D20  stw r11, 0xd20(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(3360 as u32), ctx.r[11].u32 ) };
	// 828113B0: 485ED519  bl 0x82dfe8c8
	ctx.lr = 0x828113B4;
	sub_82DFE8C8(ctx, base);
	// 828113B4: 38610D48  addi r3, r1, 0xd48
	ctx.r[3].s64 = ctx.r[1].s64 + 3400;
	// 828113B8: 485ED511  bl 0x82dfe8c8
	ctx.lr = 0x828113BC;
	sub_82DFE8C8(ctx, base);
	// 828113BC: 38A00045  li r5, 0x45
	ctx.r[5].s64 = 69;
	// 828113C0: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 828113C4: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 828113C8: 4BFD92F9  bl 0x827ea6c0
	ctx.lr = 0x828113CC;
	sub_827EA6C0(ctx, base);
	// 828113CC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 828113D0: 4BFE7F81  bl 0x827f9350
	ctx.lr = 0x828113D4;
	sub_827F9350(ctx, base);
	// 828113D4: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 828113D8: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 828113DC: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 828113E0: 4BFD92E9  bl 0x827ea6c8
	ctx.lr = 0x828113E4;
	sub_827EA6C8(ctx, base);
	// 828113E4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828113E8: 809AF3FC  lwz r4, -0xc04(r26)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-3076 as u32) ) } as u64;
	// 828113EC: 485E261D  bl 0x82df3a08
	ctx.lr = 0x828113F0;
	sub_82DF3A08(ctx, base);
	// 828113F0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 828113F4: 807D0120  lwz r3, 0x120(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(288 as u32) ) } as u64;
	// 828113F8: 4BFD90E9  bl 0x827ea4e0
	ctx.lr = 0x828113FC;
	sub_827EA4E0(ctx, base);
	// 828113FC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82811400: 485E2029  bl 0x82df3428
	ctx.lr = 0x82811404;
	sub_82DF3428(ctx, base);
	// 82811404: 38210DA0  addi r1, r1, 0xda0
	ctx.r[1].s64 = ctx.r[1].s64 + 3488;
	// 82811408: CBC1FFB0  lfd f30, -0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-80 as u32) ) };
	// 8281140C: CBE1FFB8  lfd f31, -0x48(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-72 as u32) ) };
	// 82811410: 48996D9C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811418(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811418 size=556
    let mut pc: u32 = 0x82811418;
    'dispatch: loop {
        match pc {
            0x82811418 => {
    //   block [0x82811418..0x82811644)
	// 82811418: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281141C: 48996D4D  bl 0x831a8168
	ctx.lr = 0x82811420;
	sub_831A8130(ctx, base);
	// 82811420: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811424: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82811428: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8281142C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82811430: 579D063F  clrlwi. r29, r28, 0x18
	ctx.r[29].u64 = ctx.r[28].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82811434: 41820038  beq 0x8281146c
	if ctx.cr[0].eq {
	pc = 0x8281146C; continue 'dispatch;
	}
	// 82811438: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281143C: 4899854D  bl 0x831a9988
	ctx.lr = 0x82811440;
	sub_831A9988(ctx, base);
	// 82811440: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82811444: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82811448: 386BD5B0  addi r3, r11, -0x2a50
	ctx.r[3].s64 = ctx.r[11].s64 + -10832;
	// 8281144C: 48996CAD  bl 0x831a80f8
	ctx.lr = 0x82811450;
	sub_831A80F8(ctx, base);
	// 82811450: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811454: 41820018  beq 0x8281146c
	if ctx.cr[0].eq {
	pc = 0x8281146C; continue 'dispatch;
	}
	// 82811458: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8281145C: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 82811460: 4BE50299  bl 0x826616f8
	ctx.lr = 0x82811464;
	sub_826616F8(ctx, base);
	// 82811464: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82811468: 480001D4  b 0x8281163c
	pc = 0x8281163C; continue 'dispatch;
	// 8281146C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82811470: 419A01BC  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 82811474: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811478: 48998511  bl 0x831a9988
	ctx.lr = 0x8281147C;
	sub_831A9988(ctx, base);
	// 8281147C: 3D608325  lis r11, -0x7cdb
	ctx.r[11].s64 = -2094727168;
	// 82811480: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82811484: 386B3644  addi r3, r11, 0x3644
	ctx.r[3].s64 = ctx.r[11].s64 + 13892;
	// 82811488: 48996C71  bl 0x831a80f8
	ctx.lr = 0x8281148C;
	sub_831A80F8(ctx, base);
	// 8281148C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811490: 41820014  beq 0x828114a4
	if ctx.cr[0].eq {
	pc = 0x828114A4; continue 'dispatch;
	}
	// 82811494: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811498: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8281149C: 4BFD9B25  bl 0x827eafc0
	ctx.lr = 0x828114A0;
	sub_827EAFC0(ctx, base);
	// 828114A0: 4BFFFFC4  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 828114A4: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 828114A8: 419A0184  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 828114AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828114B0: 489984D9  bl 0x831a9988
	ctx.lr = 0x828114B4;
	sub_831A9988(ctx, base);
	// 828114B4: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828114B8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828114BC: 386BD510  addi r3, r11, -0x2af0
	ctx.r[3].s64 = ctx.r[11].s64 + -10992;
	// 828114C0: 48996C39  bl 0x831a80f8
	ctx.lr = 0x828114C4;
	sub_831A80F8(ctx, base);
	// 828114C4: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828114C8: 41820014  beq 0x828114dc
	if ctx.cr[0].eq {
	pc = 0x828114DC; continue 'dispatch;
	}
	// 828114CC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828114D0: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 828114D4: 4BFFD865  bl 0x8280ed38
	ctx.lr = 0x828114D8;
	sub_8280ED38(ctx, base);
	// 828114D8: 4BFFFF8C  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 828114DC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 828114E0: 419A014C  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 828114E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828114E8: 489984A1  bl 0x831a9988
	ctx.lr = 0x828114EC;
	sub_831A9988(ctx, base);
	// 828114EC: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828114F0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828114F4: 386BD4DC  addi r3, r11, -0x2b24
	ctx.r[3].s64 = ctx.r[11].s64 + -11044;
	// 828114F8: 48996C01  bl 0x831a80f8
	ctx.lr = 0x828114FC;
	sub_831A80F8(ctx, base);
	// 828114FC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811500: 41820014  beq 0x82811514
	if ctx.cr[0].eq {
	pc = 0x82811514; continue 'dispatch;
	}
	// 82811504: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811508: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8281150C: 4BFFCF8D  bl 0x8280e498
	ctx.lr = 0x82811510;
	sub_8280E498(ctx, base);
	// 82811510: 4BFFFF54  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 82811514: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82811518: 419A0114  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 8281151C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811520: 48998469  bl 0x831a9988
	ctx.lr = 0x82811524;
	sub_831A9988(ctx, base);
	// 82811524: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82811528: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8281152C: 386BD170  addi r3, r11, -0x2e90
	ctx.r[3].s64 = ctx.r[11].s64 + -11920;
	// 82811530: 48996BC9  bl 0x831a80f8
	ctx.lr = 0x82811534;
	sub_831A80F8(ctx, base);
	// 82811534: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811538: 41820014  beq 0x8281154c
	if ctx.cr[0].eq {
	pc = 0x8281154C; continue 'dispatch;
	}
	// 8281153C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811540: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 82811544: 4BFFCEDD  bl 0x8280e420
	ctx.lr = 0x82811548;
	sub_8280E420(ctx, base);
	// 82811548: 4BFFFF1C  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 8281154C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82811550: 419A00DC  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 82811554: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811558: 48998431  bl 0x831a9988
	ctx.lr = 0x8281155C;
	sub_831A9988(ctx, base);
	// 8281155C: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82811560: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82811564: 386BD1B0  addi r3, r11, -0x2e50
	ctx.r[3].s64 = ctx.r[11].s64 + -11856;
	// 82811568: 48996B91  bl 0x831a80f8
	ctx.lr = 0x8281156C;
	sub_831A80F8(ctx, base);
	// 8281156C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811570: 41820014  beq 0x82811584
	if ctx.cr[0].eq {
	pc = 0x82811584; continue 'dispatch;
	}
	// 82811574: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811578: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 8281157C: 480BD6AD  bl 0x828cec28
	ctx.lr = 0x82811580;
	sub_828CEC28(ctx, base);
	// 82811580: 4BFFFEE4  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 82811584: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82811588: 419A00A4  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 8281158C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811590: 489983F9  bl 0x831a9988
	ctx.lr = 0x82811594;
	sub_831A9988(ctx, base);
	// 82811594: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82811598: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8281159C: 386BED80  addi r3, r11, -0x1280
	ctx.r[3].s64 = ctx.r[11].s64 + -4736;
	// 828115A0: 48996B59  bl 0x831a80f8
	ctx.lr = 0x828115A4;
	sub_831A80F8(ctx, base);
	// 828115A4: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828115A8: 41820014  beq 0x828115bc
	if ctx.cr[0].eq {
	pc = 0x828115BC; continue 'dispatch;
	}
	// 828115AC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828115B0: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 828115B4: 4BFFCF0D  bl 0x8280e4c0
	ctx.lr = 0x828115B8;
	sub_8280E4C0(ctx, base);
	// 828115B8: 4BFFFEAC  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 828115BC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 828115C0: 419A006C  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 828115C4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828115C8: 489983C1  bl 0x831a9988
	ctx.lr = 0x828115CC;
	sub_831A9988(ctx, base);
	// 828115CC: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828115D0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828115D4: 386BE0F4  addi r3, r11, -0x1f0c
	ctx.r[3].s64 = ctx.r[11].s64 + -7948;
	// 828115D8: 48996B21  bl 0x831a80f8
	ctx.lr = 0x828115DC;
	sub_831A80F8(ctx, base);
	// 828115DC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828115E0: 41820014  beq 0x828115f4
	if ctx.cr[0].eq {
	pc = 0x828115F4; continue 'dispatch;
	}
	// 828115E4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828115E8: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 828115EC: 4BFFD0FD  bl 0x8280e6e8
	ctx.lr = 0x828115F0;
	sub_8280E6E8(ctx, base);
	// 828115F0: 4BFFFE74  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 828115F4: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 828115F8: 419A0034  beq cr6, 0x8281162c
	if ctx.cr[6].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 828115FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811600: 48998389  bl 0x831a9988
	ctx.lr = 0x82811604;
	sub_831A9988(ctx, base);
	// 82811604: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82811608: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8281160C: 386BE6C0  addi r3, r11, -0x1940
	ctx.r[3].s64 = ctx.r[11].s64 + -6464;
	// 82811610: 48996AE9  bl 0x831a80f8
	ctx.lr = 0x82811614;
	sub_831A80F8(ctx, base);
	// 82811614: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811618: 41820014  beq 0x8281162c
	if ctx.cr[0].eq {
	pc = 0x8281162C; continue 'dispatch;
	}
	// 8281161C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811620: 387EFFD8  addi r3, r30, -0x28
	ctx.r[3].s64 = ctx.r[30].s64 + -40;
	// 82811624: 4BAAE9DD  bl 0x822c0000
	ctx.lr = 0x82811628;
	sub_822C0000(ctx, base);
	// 82811628: 4BFFFE3C  b 0x82811464
	pc = 0x82811464; continue 'dispatch;
	// 8281162C: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82811630: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811634: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82811638: 4BFE8409  bl 0x827f9a40
	ctx.lr = 0x8281163C;
	sub_827F9A40(ctx, base);
	// 8281163C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82811640: 48996B78  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82811648 size=844
    let mut pc: u32 = 0x82811648;
    'dispatch: loop {
        match pc {
            0x82811648 => {
    //   block [0x82811648..0x82811994)
	// 82811648: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281164C: 48996B0D  bl 0x831a8158
	ctx.lr = 0x82811650;
	sub_831A8130(ctx, base);
	// 82811650: DBE1FFB0  stfd f31, -0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-80 as u32), ctx.f[31].u64 ) };
	// 82811654: 9421FEA0  stwu r1, -0x160(r1)
	ea = ctx.r[1].u32.wrapping_add(-352 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811658: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281165C: 4BFE7ED5  bl 0x827f9530
	ctx.lr = 0x82811660;
	sub_827F9530(ctx, base);
	// 82811660: 817F0148  lwz r11, 0x148(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 82811664: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811668: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8281166C: 409A000C  bne cr6, 0x82811678
	if !ctx.cr[6].eq {
	pc = 0x82811678; continue 'dispatch;
	}
	// 82811670: 4BFFEB49  bl 0x828101b8
	ctx.lr = 0x82811674;
	sub_828101B8(ctx, base);
	// 82811674: 48000008  b 0x8281167c
	pc = 0x8281167C; continue 'dispatch;
	// 82811678: 4BFFD779  bl 0x8280edf0
	ctx.lr = 0x8281167C;
	sub_8280EDF0(ctx, base);
	// 8281167C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811680: 4BD01419  bl 0x82512a98
	ctx.lr = 0x82811684;
	sub_82512A98(ctx, base);
	// 82811684: 834D0000  lwz r26, 0(r13)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811688: 3B200014  li r25, 0x14
	ctx.r[25].s64 = 20;
	// 8281168C: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 82811690: 38800060  li r4, 0x60
	ctx.r[4].s64 = 96;
	// 82811694: 7C79D02E  lwzx r3, r25, r26
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[26].u32)) } as u64;
	// 82811698: 4868F099  bl 0x82ea0730
	ctx.lr = 0x8281169C;
	sub_82EA0730(ctx, base);
	// 8281169C: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 828116A0: 3D408207  lis r10, -0x7df9
	ctx.r[10].s64 = -2113470464;
	// 828116A4: 3B6BBC40  addi r27, r11, -0x43c0
	ctx.r[27].s64 = ctx.r[11].s64 + -17344;
	// 828116A8: 394AA4B0  addi r10, r10, -0x5b50
	ctx.r[10].s64 = ctx.r[10].s64 + -23376;
	// 828116AC: 392100C0  addi r9, r1, 0xc0
	ctx.r[9].s64 = ctx.r[1].s64 + 192;
	// 828116B0: 39010090  addi r8, r1, 0x90
	ctx.r[8].s64 = ctx.r[1].s64 + 144;
	// 828116B4: 38E00060  li r7, 0x60
	ctx.r[7].s64 = 96;
	// 828116B8: 13E0D8C7  vcmpequd (lvx128) v31, v0, v27
	tmp.u32 = ctx.r[27].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828116BC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828116C0: 13C050C7  vcmpequd (lvx128) v30, v0, v10
	tmp.u32 = ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828116C4: B0E30004  sth r7, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[7].u16 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811998 size=72
    let mut pc: u32 = 0x82811998;
    'dispatch: loop {
        match pc {
            0x82811998 => {
    //   block [0x82811998..0x828119E0)
	// 82811998: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281199C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828119A0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828119A4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828119A8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828119AC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828119B0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828119B4: 387F00C0  addi r3, r31, 0xc0
	ctx.r[3].s64 = ctx.r[31].s64 + 192;
	// 828119B8: 4864ACE1  bl 0x82e5c698
	ctx.lr = 0x828119BC;
	sub_82E5C698(ctx, base);
	// 828119BC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828119C0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828119C4: 4BAAE63D  bl 0x822c0000
	ctx.lr = 0x828119C8;
	sub_822C0000(ctx, base);
	// 828119C8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828119CC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828119D0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828119D4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 828119D8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828119DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828119E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828119E0 size=108
    let mut pc: u32 = 0x828119E0;
    'dispatch: loop {
        match pc {
            0x828119E0 => {
    //   block [0x828119E0..0x82811A4C)
	// 828119E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828119E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828119E8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828119EC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828119F0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828119F4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828119F8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828119FC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811A00: 396B8E6C  addi r11, r11, -0x7194
	ctx.r[11].s64 = ctx.r[11].s64 + -29076;
	// 82811A04: 394A8E58  addi r10, r10, -0x71a8
	ctx.r[10].s64 = ctx.r[10].s64 + -29096;
	// 82811A08: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82811A0C: 3BDF00C0  addi r30, r31, 0xc0
	ctx.r[30].s64 = ctx.r[31].s64 + 192;
	// 82811A10: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 82811A14: 807F0124  lwz r3, 0x124(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(292 as u32) ) } as u64;
	// 82811A18: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811A1C: 419A0008  beq cr6, 0x82811a24
	if ctx.cr[6].eq {
	pc = 0x82811A24; continue 'dispatch;
	}
	// 82811A20: 4BAAEE71  bl 0x822c0890
	ctx.lr = 0x82811A24;
	sub_822C0890(ctx, base);
	// 82811A24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82811A28: 4864BE21  bl 0x82e5d848
	ctx.lr = 0x82811A2C;
	sub_82E5D848(ctx, base);
	// 82811A2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811A30: 4BCFF769  bl 0x82511198
	ctx.lr = 0x82811A34;
	sub_82511198(ctx, base);
	// 82811A34: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82811A38: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82811A3C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82811A40: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82811A44: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82811A48: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811A50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82811A50 size=8
    let mut pc: u32 = 0x82811A50;
    'dispatch: loop {
        match pc {
            0x82811A50 => {
    //   block [0x82811A50..0x82811A58)
	// 82811A50: 3863FFD8  addi r3, r3, -0x28
	ctx.r[3].s64 = ctx.r[3].s64 + -40;
	// 82811A54: 48000114  b 0x82811b68
	sub_82811B68(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811A58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82811A58 size=148
    let mut pc: u32 = 0x82811A58;
    'dispatch: loop {
        match pc {
            0x82811A58 => {
    //   block [0x82811A58..0x82811AEC)
	// 82811A58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811A5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82811A60: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811A64: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82811A68: 81440000  lwz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811A6C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811A70: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82811A74: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82811A78: 419A0024  beq cr6, 0x82811a9c
	if ctx.cr[6].eq {
	pc = 0x82811A9C; continue 'dispatch;
	}
	// 82811A7C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82811A80: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82811A84: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811A88: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82811A8C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82811A90: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82811A94: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811A98: 4082FFE8  bne 0x82811a80
	if !ctx.cr[0].eq {
	pc = 0x82811A80; continue 'dispatch;
	}
	// 82811A9C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82811AA0: 388300C0  addi r4, r3, 0xc0
	ctx.r[4].s64 = ctx.r[3].s64 + 192;
	// 82811AA4: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82811AA8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82811AAC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82811AB0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82811AB4: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82811AB8: 4864CCC9  bl 0x82e5e780
	ctx.lr = 0x82811ABC;
	sub_82E5E780(ctx, base);
	// 82811ABC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82811AC0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811AC4: 419A0008  beq cr6, 0x82811acc
	if ctx.cr[6].eq {
	pc = 0x82811ACC; continue 'dispatch;
	}
	// 82811AC8: 4BAAEDC9  bl 0x822c0890
	ctx.lr = 0x82811ACC;
	sub_822C0890(ctx, base);
	// 82811ACC: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82811AD0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811AD4: 419A0008  beq cr6, 0x82811adc
	if ctx.cr[6].eq {
	pc = 0x82811ADC; continue 'dispatch;
	}
	// 82811AD8: 4BAAEDB9  bl 0x822c0890
	ctx.lr = 0x82811ADC;
	sub_822C0890(ctx, base);
	// 82811ADC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82811AE0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82811AE4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82811AE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811AF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811AF0 size=120
    let mut pc: u32 = 0x82811AF0;
    'dispatch: loop {
        match pc {
            0x82811AF0 => {
    //   block [0x82811AF0..0x82811B68)
	// 82811AF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811AF4: 48996679  bl 0x831a816c
	ctx.lr = 0x82811AF8;
	sub_831A8130(ctx, base);
	// 82811AF8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811AFC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82811B00: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82811B04: 4BCFF5ED  bl 0x825110f0
	ctx.lr = 0x82811B08;
	sub_825110F0(ctx, base);
	// 82811B08: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82811B0C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811B10: 396B8E6C  addi r11, r11, -0x7194
	ctx.r[11].s64 = ctx.r[11].s64 + -29076;
	// 82811B14: 394A8E58  addi r10, r10, -0x71a8
	ctx.r[10].s64 = ctx.r[10].s64 + -29096;
	// 82811B18: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82811B1C: 3BDF00C0  addi r30, r31, 0xc0
	ctx.r[30].s64 = ctx.r[31].s64 + 192;
	// 82811B20: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 82811B24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82811B28: 4864BDA9  bl 0x82e5d8d0
	ctx.lr = 0x82811B2C;
	sub_82E5D8D0(ctx, base);
	// 82811B2C: 3D408207  lis r10, -0x7df9
	ctx.r[10].s64 = -2113470464;
	// 82811B30: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82811B34: 394A5DA0  addi r10, r10, 0x5da0
	ctx.r[10].s64 = ctx.r[10].s64 + 23968;
	// 82811B38: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82811B3C: 915F00C0  stw r10, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[10].u32 ) };
	// 82811B40: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82811B44: 917F0120  stw r11, 0x120(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), ctx.r[11].u32 ) };
	// 82811B48: 917F0124  stw r11, 0x124(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), ctx.r[11].u32 ) };
	// 82811B4C: 817F00C0  lwz r11, 0xc0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 82811B50: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82811B54: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82811B58: 4E800421  bctrl
	ctx.lr = 0x82811B5C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82811B5C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811B60: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82811B64: 48996658  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811B68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811B68 size=76
    let mut pc: u32 = 0x82811B68;
    'dispatch: loop {
        match pc {
            0x82811B68 => {
    //   block [0x82811B68..0x82811BB4)
	// 82811B68: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811B6C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82811B70: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82811B74: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82811B78: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811B7C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82811B80: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82811B84: 4BFFFE5D  bl 0x828119e0
	ctx.lr = 0x82811B88;
	sub_828119E0(ctx, base);
	// 82811B88: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811B8C: 4182000C  beq 0x82811b98
	if ctx.cr[0].eq {
	pc = 0x82811B98; continue 'dispatch;
	}
	// 82811B90: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811B94: 485E0845  bl 0x82df23d8
	ctx.lr = 0x82811B98;
	sub_82DF23D8(ctx, base);
	// 82811B98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811B9C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82811BA0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82811BA4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82811BA8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82811BAC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82811BB0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811BB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82811BB8 size=252
    let mut pc: u32 = 0x82811BB8;
    'dispatch: loop {
        match pc {
            0x82811BB8 => {
    //   block [0x82811BB8..0x82811CB4)
	// 82811BB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811BBC: 489965AD  bl 0x831a8168
	ctx.lr = 0x82811BC0;
	sub_831A8130(ctx, base);
	// 82811BC0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811BC4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82811BC8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82811BCC: 3BFE00C0  addi r31, r30, 0xc0
	ctx.r[31].s64 = ctx.r[30].s64 + 192;
	// 82811BD0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82811BD4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811BD8: 48648949  bl 0x82e5a520
	ctx.lr = 0x82811BDC;
	sub_82E5A520(ctx, base);
	// 82811BDC: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811BE0: 8161005C  lwz r11, 0x5c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82811BE4: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 82811BE8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811BEC: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 82811BF0: 695C0001  xori r28, r10, 1
	ctx.r[28].u64 = ctx.r[10].u64 ^ 1;
	// 82811BF4: 419A000C  beq cr6, 0x82811c00
	if ctx.cr[6].eq {
	pc = 0x82811C00; continue 'dispatch;
	}
	// 82811BF8: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82811BFC: 4BAAEC95  bl 0x822c0890
	ctx.lr = 0x82811C00;
	sub_822C0890(ctx, base);
	// 82811C00: 578B063F  clrlwi. r11, r28, 0x18
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811C04: 41820014  beq 0x82811c18
	if ctx.cr[0].eq {
	pc = 0x82811C18; continue 'dispatch;
	}
	// 82811C08: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82811C0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811C10: 4BFDA689  bl 0x827ec298
	ctx.lr = 0x82811C14;
	sub_827EC298(ctx, base);
	// 82811C14: 48000098  b 0x82811cac
	pc = 0x82811CAC; continue 'dispatch;
	// 82811C18: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82811C1C: 4BDC6435  bl 0x825d8050
	ctx.lr = 0x82811C20;
	sub_825D8050(ctx, base);
	// 82811C20: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811C24: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82811C28: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82811C2C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811C30: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82811C34: 419A0024  beq cr6, 0x82811c58
	if ctx.cr[6].eq {
	pc = 0x82811C58; continue 'dispatch;
	}
	// 82811C38: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82811C3C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82811C40: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811C44: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82811C48: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82811C4C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82811C50: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811C54: 4082FFE8  bne 0x82811c3c
	if !ctx.cr[0].eq {
	pc = 0x82811C3C; continue 'dispatch;
	}
	// 82811C58: 3BFE0028  addi r31, r30, 0x28
	ctx.r[31].s64 = ctx.r[30].s64 + 40;
	// 82811C5C: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82811C60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811C64: 487F7355  bl 0x83008fb8
	ctx.lr = 0x82811C68;
	sub_83008FB8(ctx, base);
	// 82811C68: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82811C6C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811C70: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82811C74: 388A8E98  addi r4, r10, -0x7168
	ctx.r[4].s64 = ctx.r[10].s64 + -29032;
	// 82811C78: 38A00047  li r5, 0x47
	ctx.r[5].s64 = 71;
	// 82811C7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811C80: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82811C84: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82811C88: 48646DB9  bl 0x82e58a40
	ctx.lr = 0x82811C8C;
	sub_82E58A40(ctx, base);
	// 82811C8C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82811C90: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811C94: 419A0008  beq cr6, 0x82811c9c
	if ctx.cr[6].eq {
	pc = 0x82811C9C; continue 'dispatch;
	}
	// 82811C98: 4BAAEBF9  bl 0x822c0890
	ctx.lr = 0x82811C9C;
	sub_822C0890(ctx, base);
	// 82811C9C: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 82811CA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811CA4: 419A0008  beq cr6, 0x82811cac
	if ctx.cr[6].eq {
	pc = 0x82811CAC; continue 'dispatch;
	}
	// 82811CA8: 4BAAEBE9  bl 0x822c0890
	ctx.lr = 0x82811CAC;
	sub_822C0890(ctx, base);
	// 82811CAC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82811CB0: 48996508  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811CB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82811CB8 size=252
    let mut pc: u32 = 0x82811CB8;
    'dispatch: loop {
        match pc {
            0x82811CB8 => {
    //   block [0x82811CB8..0x82811DB4)
	// 82811CB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811CBC: 489964AD  bl 0x831a8168
	ctx.lr = 0x82811CC0;
	sub_831A8130(ctx, base);
	// 82811CC0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811CC4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82811CC8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82811CCC: 3BFE00C0  addi r31, r30, 0xc0
	ctx.r[31].s64 = ctx.r[30].s64 + 192;
	// 82811CD0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82811CD4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811CD8: 48648849  bl 0x82e5a520
	ctx.lr = 0x82811CDC;
	sub_82E5A520(ctx, base);
	// 82811CDC: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811CE0: 8161005C  lwz r11, 0x5c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82811CE4: 7D4A0034  cntlzw r10, r10
	ctx.r[10].u64 = if ctx.r[10].u32 == 0 { 32 } else { ctx.r[10].u32.leading_zeros() as u64 };
	// 82811CE8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811CEC: 554ADFFE  rlwinm r10, r10, 0x1b, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 82811CF0: 695C0001  xori r28, r10, 1
	ctx.r[28].u64 = ctx.r[10].u64 ^ 1;
	// 82811CF4: 419A000C  beq cr6, 0x82811d00
	if ctx.cr[6].eq {
	pc = 0x82811D00; continue 'dispatch;
	}
	// 82811CF8: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82811CFC: 4BAAEB95  bl 0x822c0890
	ctx.lr = 0x82811D00;
	sub_822C0890(ctx, base);
	// 82811D00: 578B063F  clrlwi. r11, r28, 0x18
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82811D04: 41820014  beq 0x82811d18
	if ctx.cr[0].eq {
	pc = 0x82811D18; continue 'dispatch;
	}
	// 82811D08: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82811D0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811D10: 4864B381  bl 0x82e5d090
	ctx.lr = 0x82811D14;
	sub_82E5D090(ctx, base);
	// 82811D14: 48000098  b 0x82811dac
	pc = 0x82811DAC; continue 'dispatch;
	// 82811D18: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82811D1C: 4BDC6335  bl 0x825d8050
	ctx.lr = 0x82811D20;
	sub_825D8050(ctx, base);
	// 82811D20: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811D24: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82811D28: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82811D2C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811D30: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82811D34: 419A0024  beq cr6, 0x82811d58
	if ctx.cr[6].eq {
	pc = 0x82811D58; continue 'dispatch;
	}
	// 82811D38: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82811D3C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82811D40: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811D44: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82811D48: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82811D4C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82811D50: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82811D54: 4082FFE8  bne 0x82811d3c
	if !ctx.cr[0].eq {
	pc = 0x82811D3C; continue 'dispatch;
	}
	// 82811D58: 3BFE0028  addi r31, r30, 0x28
	ctx.r[31].s64 = ctx.r[30].s64 + 40;
	// 82811D5C: 3BC10050  addi r30, r1, 0x50
	ctx.r[30].s64 = ctx.r[1].s64 + 80;
	// 82811D60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811D64: 487F7255  bl 0x83008fb8
	ctx.lr = 0x82811D68;
	sub_83008FB8(ctx, base);
	// 82811D68: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82811D6C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811D70: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82811D74: 388A8E98  addi r4, r10, -0x7168
	ctx.r[4].s64 = ctx.r[10].s64 + -29032;
	// 82811D78: 38A00056  li r5, 0x56
	ctx.r[5].s64 = 86;
	// 82811D7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811D80: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82811D84: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82811D88: 48646CB9  bl 0x82e58a40
	ctx.lr = 0x82811D8C;
	sub_82E58A40(ctx, base);
	// 82811D8C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82811D90: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811D94: 419A0008  beq cr6, 0x82811d9c
	if ctx.cr[6].eq {
	pc = 0x82811D9C; continue 'dispatch;
	}
	// 82811D98: 4BAAEAF9  bl 0x822c0890
	ctx.lr = 0x82811D9C;
	sub_822C0890(ctx, base);
	// 82811D9C: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 82811DA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811DA4: 419A0008  beq cr6, 0x82811dac
	if ctx.cr[6].eq {
	pc = 0x82811DAC; continue 'dispatch;
	}
	// 82811DA8: 4BAAEAE9  bl 0x822c0890
	ctx.lr = 0x82811DAC;
	sub_822C0890(ctx, base);
	// 82811DAC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82811DB0: 48996408  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811DB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82811DB8 size=4
    let mut pc: u32 = 0x82811DB8;
    'dispatch: loop {
        match pc {
            0x82811DB8 => {
    //   block [0x82811DB8..0x82811DBC)
	// 82811DB8: 4BF73318  b 0x827850d0
	sub_827850D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811DC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82811DC0 size=8
    let mut pc: u32 = 0x82811DC0;
    'dispatch: loop {
        match pc {
            0x82811DC0 => {
    //   block [0x82811DC0..0x82811DC8)
	// 82811DC0: 806300F8  lwz r3, 0xf8(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(248 as u32) ) } as u64;
	// 82811DC4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811DC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811DC8 size=100
    let mut pc: u32 = 0x82811DC8;
    'dispatch: loop {
        match pc {
            0x82811DC8 => {
    //   block [0x82811DC8..0x82811E2C)
	// 82811DC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811DCC: 489963A1  bl 0x831a816c
	ctx.lr = 0x82811DD0;
	sub_831A8130(ctx, base);
	// 82811DD0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811DD4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82811DD8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82811DDC: 3BFD00FC  addi r31, r29, 0xfc
	ctx.r[31].s64 = ctx.r[29].s64 + 252;
	// 82811DE0: 817D00FC  lwz r11, 0xfc(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(252 as u32) ) } as u64;
	// 82811DE4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811DE8: 419A0030  beq cr6, 0x82811e18
	if ctx.cr[6].eq {
	pc = 0x82811E18; continue 'dispatch;
	}
	// 82811DEC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82811DF0: 4BCF8B61  bl 0x8250a950
	ctx.lr = 0x82811DF4;
	sub_8250A950(ctx, base);
	// 82811DF4: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82811DF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811DFC: 386BFF40  addi r3, r11, -0xc0
	ctx.r[3].s64 = ctx.r[11].s64 + -192;
	// 82811E00: 409A0008  bne cr6, 0x82811e08
	if !ctx.cr[6].eq {
	pc = 0x82811E08; continue 'dispatch;
	}
	// 82811E04: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82811E08: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82811E0C: 4BFC1BF5  bl 0x827d3a00
	ctx.lr = 0x82811E10;
	sub_827D3A00(ctx, base);
	// 82811E10: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82811E14: 485DFE7D  bl 0x82df1c90
	ctx.lr = 0x82811E18;
	sub_82DF1C90(ctx, base);
	// 82811E18: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82811E1C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82811E20: 4BFEB1D9  bl 0x827fcff8
	ctx.lr = 0x82811E24;
	sub_827FCFF8(ctx, base);
	// 82811E24: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82811E28: 48996394  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811E30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82811E30 size=216
    let mut pc: u32 = 0x82811E30;
    'dispatch: loop {
        match pc {
            0x82811E30 => {
    //   block [0x82811E30..0x82811F08)
	// 82811E30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811E34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82811E38: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82811E3C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811E40: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82811E44: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811E48: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 82811E4C: 419A0080  beq cr6, 0x82811ecc
	if ctx.cr[6].eq {
	pc = 0x82811ECC; continue 'dispatch;
	}
	// 82811E50: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 82811E54: 409A0078  bne cr6, 0x82811ecc
	if !ctx.cr[6].eq {
	pc = 0x82811ECC; continue 'dispatch;
	}
	// 82811E58: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82811E5C: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 82811E60: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 82811E64: 38800040  li r4, 0x40
	ctx.r[4].s64 = 64;
	// 82811E68: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82811E6C: 4868E8C5  bl 0x82ea0730
	ctx.lr = 0x82811E70;
	sub_82EA0730(ctx, base);
	// 82811E70: 39600040  li r11, 0x40
	ctx.r[11].s64 = 64;
	// 82811E74: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 82811E78: B1630004  sth r11, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u16 ) };
	// 82811E7C: C03F0004  lfs f1, 4(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82811E80: 3D208200  lis r9, -0x7e00
	ctx.r[9].s64 = -2113929216;
	// 82811E84: C01F0008  lfs f0, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811E88: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82811E8C: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82811E90: 396ABC40  addi r11, r10, -0x43c0
	ctx.r[11].s64 = ctx.r[10].s64 + -17344;
	// 82811E94: C00908A4  lfs f0, 0x8a4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82811E98: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82811E9C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82811EA0: 38E10060  addi r7, r1, 0x60
	ctx.r[7].s64 = ctx.r[1].s64 + 96;
	// 82811EA4: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82811EA8: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82811EAC: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 82811EB0: 13C040C7  vcmpequd (lvx128) v30, v0, v8
	tmp.u32 = ctx.r[8].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82811EB4: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 82811EB8: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811F08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811F08 size=136
    let mut pc: u32 = 0x82811F08;
    'dispatch: loop {
        match pc {
            0x82811F08 => {
    //   block [0x82811F08..0x82811F90)
	// 82811F08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811F0C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82811F10: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82811F14: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811F18: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82811F1C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82811F20: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82811F24: 396B8F0C  addi r11, r11, -0x70f4
	ctx.r[11].s64 = ctx.r[11].s64 + -28916;
	// 82811F28: 394A8EF8  addi r10, r10, -0x7108
	ctx.r[10].s64 = ctx.r[10].s64 + -28936;
	// 82811F2C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82811F30: 387F0104  addi r3, r31, 0x104
	ctx.r[3].s64 = ctx.r[31].s64 + 260;
	// 82811F34: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 82811F38: 485E14F1  bl 0x82df3428
	ctx.lr = 0x82811F3C;
	sub_82DF3428(ctx, base);
	// 82811F3C: 807F0100  lwz r3, 0x100(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(256 as u32) ) } as u64;
	// 82811F40: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811F44: 419A0008  beq cr6, 0x82811f4c
	if ctx.cr[6].eq {
	pc = 0x82811F4C; continue 'dispatch;
	}
	// 82811F48: 4BAAE949  bl 0x822c0890
	ctx.lr = 0x82811F4C;
	sub_822C0890(ctx, base);
	// 82811F4C: 387F00F4  addi r3, r31, 0xf4
	ctx.r[3].s64 = ctx.r[31].s64 + 244;
	// 82811F50: 485E14D9  bl 0x82df3428
	ctx.lr = 0x82811F54;
	sub_82DF3428(ctx, base);
	// 82811F54: 807F00F0  lwz r3, 0xf0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) } as u64;
	// 82811F58: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811F5C: 419A0008  beq cr6, 0x82811f64
	if ctx.cr[6].eq {
	pc = 0x82811F64; continue 'dispatch;
	}
	// 82811F60: 4BAD6309  bl 0x822e8268
	ctx.lr = 0x82811F64;
	sub_822E8268(ctx, base);
	// 82811F64: 807F00EC  lwz r3, 0xec(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(236 as u32) ) } as u64;
	// 82811F68: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82811F6C: 419A0008  beq cr6, 0x82811f74
	if ctx.cr[6].eq {
	pc = 0x82811F74; continue 'dispatch;
	}
	// 82811F70: 4BAAE921  bl 0x822c0890
	ctx.lr = 0x82811F74;
	sub_822C0890(ctx, base);
	// 82811F74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82811F78: 4BFEB191  bl 0x827fd108
	ctx.lr = 0x82811F7C;
	sub_827FD108(ctx, base);
	// 82811F7C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82811F80: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82811F84: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82811F88: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82811F8C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811F90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82811F90 size=8
    let mut pc: u32 = 0x82811F90;
    'dispatch: loop {
        match pc {
            0x82811F90 => {
    //   block [0x82811F90..0x82811F98)
	// 82811F90: 3863FFD8  addi r3, r3, -0x28
	ctx.r[3].s64 = ctx.r[3].s64 + -40;
	// 82811F94: 48000164  b 0x828120f8
	sub_828120F8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82811F98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82811F98 size=196
    let mut pc: u32 = 0x82811F98;
    'dispatch: loop {
        match pc {
            0x82811F98 => {
    //   block [0x82811F98..0x8281205C)
	// 82811F98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82811F9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82811FA0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82811FA4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82811FA8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82811FAC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82811FB0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82811FB4: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 82811FB8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82811FBC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82811FC0: 4BAAE979  bl 0x822c0938
	ctx.lr = 0x82811FC4;
	sub_822C0938(ctx, base);
	// 82811FC4: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82811FC8: 41820028  beq 0x82811ff0
	if ctx.cr[0].eq {
	pc = 0x82811FF0; continue 'dispatch;
	}
	// 82811FCC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82811FD0: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 82811FD4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82811FD8: 392B8EE4  addi r9, r11, -0x711c
	ctx.r[9].s64 = ctx.r[11].s64 + -28956;
	// 82811FDC: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82811FE0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82811FE4: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82811FE8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82811FEC: 48000008  b 0x82811ff4
	pc = 0x82811FF4; continue 'dispatch;
	// 82811FF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82811FF4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82811FF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82811FFC: 409A0044  bne cr6, 0x82812040
	if !ctx.cr[6].eq {
	pc = 0x82812040; continue 'dispatch;
	}
	// 82812000: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82812004: 419A001C  beq cr6, 0x82812020
	if ctx.cr[6].eq {
	pc = 0x82812020; continue 'dispatch;
	}
	// 82812008: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281200C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82812010: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812014: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812018: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281201C: 4E800421  bctrl
	ctx.lr = 0x82812020;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82812020: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82812024: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82812028: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8281202C: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82812030: 816BEDD4  lwz r11, -0x122c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4652 as u32) ) } as u64;
	// 82812034: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82812038: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8281203C: 4BAADFC5  bl 0x822c0000
	ctx.lr = 0x82812040;
	sub_822C0000(ctx, base);
	// 82812040: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82812044: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812048: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281204C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812050: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812054: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812058: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812060(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812060 size=148
    let mut pc: u32 = 0x82812060;
    'dispatch: loop {
        match pc {
            0x82812060 => {
    //   block [0x82812060..0x828120F4)
	// 82812060: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812064: 48996109  bl 0x831a816c
	ctx.lr = 0x82812068;
	sub_831A8130(ctx, base);
	// 82812068: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281206C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82812070: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82812074: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 82812078: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281207C: 4BFEAFE5  bl 0x827fd060
	ctx.lr = 0x82812080;
	sub_827FD060(ctx, base);
	// 82812080: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812084: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82812088: 396B8F0C  addi r11, r11, -0x70f4
	ctx.r[11].s64 = ctx.r[11].s64 + -28916;
	// 8281208C: 394A8EF8  addi r10, r10, -0x7108
	ctx.r[10].s64 = ctx.r[10].s64 + -28936;
	// 82812090: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82812094: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82812098: 915F0028  stw r10, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[10].u32 ) };
	// 8281209C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828120A0: 93BF00E8  stw r29, 0xe8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(232 as u32), ctx.r[29].u32 ) };
	// 828120A4: 93BF00EC  stw r29, 0xec(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(236 as u32), ctx.r[29].u32 ) };
	// 828120A8: 4BFFFD89  bl 0x82811e30
	ctx.lr = 0x828120AC;
	sub_82811E30(ctx, base);
	// 828120AC: 907F00F0  stw r3, 0xf0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(240 as u32), ctx.r[3].u32 ) };
	// 828120B0: 387F00F4  addi r3, r31, 0xf4
	ctx.r[3].s64 = ctx.r[31].s64 + 244;
	// 828120B4: 389E000C  addi r4, r30, 0xc
	ctx.r[4].s64 = ctx.r[30].s64 + 12;
	// 828120B8: 485E1B49  bl 0x82df3c00
	ctx.lr = 0x828120BC;
	sub_82DF3C00(ctx, base);
	// 828120BC: 817E001C  lwz r11, 0x1c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 828120C0: 387F0104  addi r3, r31, 0x104
	ctx.r[3].s64 = ctx.r[31].s64 + 260;
	// 828120C4: 389E0010  addi r4, r30, 0x10
	ctx.r[4].s64 = ctx.r[30].s64 + 16;
	// 828120C8: 917F00F8  stw r11, 0xf8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(248 as u32), ctx.r[11].u32 ) };
	// 828120CC: 93BF00FC  stw r29, 0xfc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(252 as u32), ctx.r[29].u32 ) };
	// 828120D0: 93BF0100  stw r29, 0x100(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(256 as u32), ctx.r[29].u32 ) };
	// 828120D4: 485E1B2D  bl 0x82df3c00
	ctx.lr = 0x828120D8;
	sub_82DF3C00(ctx, base);
	// 828120D8: C01E0004  lfs f0, 4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828120DC: D01F0108  stfs f0, 0x108(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 828120E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828120E4: C01E0018  lfs f0, 0x18(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828120E8: D01F010C  stfs f0, 0x10c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), tmp.u32 ) };
	// 828120EC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828120F0: 489960CC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828120F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828120F8 size=76
    let mut pc: u32 = 0x828120F8;
    'dispatch: loop {
        match pc {
            0x828120F8 => {
    //   block [0x828120F8..0x82812144)
	// 828120F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828120FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812100: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812104: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812108: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281210C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812110: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812114: 4BFFFDF5  bl 0x82811f08
	ctx.lr = 0x82812118;
	sub_82811F08(ctx, base);
	// 82812118: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281211C: 4182000C  beq 0x82812128
	if ctx.cr[0].eq {
	pc = 0x82812128; continue 'dispatch;
	}
	// 82812120: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812124: 485E02B5  bl 0x82df23d8
	ctx.lr = 0x82812128;
	sub_82DF23D8(ctx, base);
	// 82812128: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281212C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812130: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812134: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812138: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281213C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812140: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812148(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812148 size=16
    let mut pc: u32 = 0x82812148;
    'dispatch: loop {
        match pc {
            0x82812148 => {
    //   block [0x82812148..0x82812158)
	// 82812148: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8281214C: 388300F0  addi r4, r3, 0xf0
	ctx.r[4].s64 = ctx.r[3].s64 + 240;
	// 82812150: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 82812154: 4BAD4AFC  b 0x822e6c50
	sub_822E6C50(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812158(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812158 size=108
    let mut pc: u32 = 0x82812158;
    'dispatch: loop {
        match pc {
            0x82812158 => {
    //   block [0x82812158..0x828121C4)
	// 82812158: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281215C: 48996011  bl 0x831a816c
	ctx.lr = 0x82812160;
	sub_831A8130(ctx, base);
	// 82812160: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812164: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82812168: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8281216C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82812170: 57CB063F  clrlwi. r11, r30, 0x18
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812174: 41820038  beq 0x828121ac
	if ctx.cr[0].eq {
	pc = 0x828121AC; continue 'dispatch;
	}
	// 82812178: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281217C: 4899780D  bl 0x831a9988
	ctx.lr = 0x82812180;
	sub_831A9988(ctx, base);
	// 82812180: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82812184: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82812188: 386BEE20  addi r3, r11, -0x11e0
	ctx.r[3].s64 = ctx.r[11].s64 + -4576;
	// 8281218C: 48995F6D  bl 0x831a80f8
	ctx.lr = 0x82812190;
	sub_831A80F8(ctx, base);
	// 82812190: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812194: 41820018  beq 0x828121ac
	if ctx.cr[0].eq {
	pc = 0x828121AC; continue 'dispatch;
	}
	// 82812198: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8281219C: 387DFFD8  addi r3, r29, -0x28
	ctx.r[3].s64 = ctx.r[29].s64 + -40;
	// 828121A0: 4BFFFFA9  bl 0x82812148
	ctx.lr = 0x828121A4;
	sub_82812148(ctx, base);
	// 828121A4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 828121A8: 48000014  b 0x828121bc
	pc = 0x828121BC; continue 'dispatch;
	// 828121AC: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 828121B0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828121B4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 828121B8: 4BFEB0D1  bl 0x827fd288
	ctx.lr = 0x828121BC;
	sub_827FD288(ctx, base);
	// 828121BC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828121C0: 48995FFC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828121C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828121C8 size=128
    let mut pc: u32 = 0x828121C8;
    'dispatch: loop {
        match pc {
            0x828121C8 => {
    //   block [0x828121C8..0x82812248)
	// 828121C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828121CC: 48995FA1  bl 0x831a816c
	ctx.lr = 0x828121D0;
	sub_831A8130(ctx, base);
	// 828121D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828121D4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828121D8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 828121DC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 828121E0: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 828121E4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828121E8: 388B8F50  addi r4, r11, -0x70b0
	ctx.r[4].s64 = ctx.r[11].s64 + -28848;
	// 828121EC: 38A00033  li r5, 0x33
	ctx.r[5].s64 = 51;
	// 828121F0: 38600110  li r3, 0x110
	ctx.r[3].s64 = 272;
	// 828121F4: 485E01F5  bl 0x82df23e8
	ctx.lr = 0x828121F8;
	sub_82DF23E8(ctx, base);
	// 828121F8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828121FC: 41820018  beq 0x82812214
	if ctx.cr[0].eq {
	pc = 0x82812214; continue 'dispatch;
	}
	// 82812200: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82812204: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82812208: 4BFFFE59  bl 0x82812060
	ctx.lr = 0x8281220C;
	sub_82812060(ctx, base);
	// 8281220C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812210: 48000008  b 0x82812218
	pc = 0x82812218; continue 'dispatch;
	// 82812214: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82812218: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8281221C: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 82812220: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82812224: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82812228: 4BFFFD71  bl 0x82811f98
	ctx.lr = 0x8281222C;
	sub_82811F98(ctx, base);
	// 8281222C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82812230: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82812234: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82812238: 4BAADDC9  bl 0x822c0000
	ctx.lr = 0x8281223C;
	sub_822C0000(ctx, base);
	// 8281223C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82812240: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812244: 48995F78  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812248(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812248 size=420
    let mut pc: u32 = 0x82812248;
    'dispatch: loop {
        match pc {
            0x82812248 => {
    //   block [0x82812248..0x828123EC)
	// 82812248: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281224C: 48995F21  bl 0x831a816c
	ctx.lr = 0x82812250;
	sub_831A8130(ctx, base);
	// 82812250: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812254: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812258: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8281225C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82812260: 4BFEAD09  bl 0x827fcf68
	ctx.lr = 0x82812264;
	sub_827FCF68(ctx, base);
	// 82812264: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82812268: 809D0000  lwz r4, 0(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281226C: 4861887D  bl 0x82e2aae8
	ctx.lr = 0x82812270;
	sub_82E2AAE8(ctx, base);
	// 82812270: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82812274: 38BF00F4  addi r5, r31, 0xf4
	ctx.r[5].s64 = ctx.r[31].s64 + 244;
	// 82812278: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 8281227C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82812280: 4861CBF1  bl 0x82e2ee70
	ctx.lr = 0x82812284;
	sub_82E2EE70(ctx, base);
	// 82812284: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82812288: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8281228C: 419A007C  beq cr6, 0x82812308
	if ctx.cr[6].eq {
	pc = 0x82812308; continue 'dispatch;
	}
	// 82812290: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812294: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82812298: 388B8F50  addi r4, r11, -0x70b0
	ctx.r[4].s64 = ctx.r[11].s64 + -28848;
	// 8281229C: 38A00065  li r5, 0x65
	ctx.r[5].s64 = 101;
	// 828122A0: 38600098  li r3, 0x98
	ctx.r[3].s64 = 152;
	// 828122A4: 485E0145  bl 0x82df23e8
	ctx.lr = 0x828122A8;
	sub_82DF23E8(ctx, base);
	// 828122A8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828122AC: 41820014  beq 0x828122c0
	if ctx.cr[0].eq {
	pc = 0x828122C0; continue 'dispatch;
	}
	// 828122B0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 828122B4: 486045DD  bl 0x82e16890
	ctx.lr = 0x828122B8;
	sub_82E16890(ctx, base);
	// 828122B8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828122BC: 48000008  b 0x828122c4
	pc = 0x828122C4; continue 'dispatch;
	// 828122C0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 828122C4: 3BDF00E8  addi r30, r31, 0xe8
	ctx.r[30].s64 = ctx.r[31].s64 + 232;
	// 828122C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828122CC: 4BB4B0A5  bl 0x8235d370
	ctx.lr = 0x828122D0;
	sub_8235D370(ctx, base);
	// 828122D0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828122D4: 38610078  addi r3, r1, 0x78
	ctx.r[3].s64 = ctx.r[1].s64 + 120;
	// 828122D8: 83BF00E8  lwz r29, 0xe8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(232 as u32) ) } as u64;
	// 828122DC: 4BCFFE3D  bl 0x82512118
	ctx.lr = 0x828122E0;
	sub_82512118(ctx, base);
	// 828122E0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828122E4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 828122E8: 48602DC9  bl 0x82e150b0
	ctx.lr = 0x828122EC;
	sub_82E150B0(ctx, base);
	// 828122EC: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 828122F0: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 828122F4: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 828122F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828122FC: 808B7058  lwz r4, 0x7058(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28760 as u32) ) } as u64;
	// 82812300: 4BCFE859  bl 0x82510b58
	ctx.lr = 0x82812304;
	sub_82510B58(ctx, base);
	// 82812304: 480000A0  b 0x828123a4
	pc = 0x828123A4; continue 'dispatch;
	// 82812308: 3BBF0104  addi r29, r31, 0x104
	ctx.r[29].s64 = ctx.r[31].s64 + 260;
	// 8281230C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82812310: 485E1899  bl 0x82df3ba8
	ctx.lr = 0x82812314;
	sub_82DF3BA8(ctx, base);
	// 82812314: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812318: 4082008C  bne 0x828123a4
	if !ctx.cr[0].eq {
	pc = 0x828123A4; continue 'dispatch;
	}
	// 8281231C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82812320: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82812324: 4BCF862D  bl 0x8250a950
	ctx.lr = 0x82812328;
	sub_8250A950(ctx, base);
	// 82812328: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8281232C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82812330: 3BCBFF40  addi r30, r11, -0xc0
	ctx.r[30].s64 = ctx.r[11].s64 + -192;
	// 82812334: 409A0008  bne cr6, 0x8281233c
	if !ctx.cr[6].eq {
	pc = 0x8281233C; continue 'dispatch;
	}
	// 82812338: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8281233C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82812340: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82812344: 4BCFFDD5  bl 0x82512118
	ctx.lr = 0x82812348;
	sub_82512118(ctx, base);
	// 82812348: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8281234C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82812350: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 82812354: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82812358: 38E00008  li r7, 8
	ctx.r[7].s64 = 8;
	// 8281235C: 4BFC2955  bl 0x827d4cb0
	ctx.lr = 0x82812360;
	sub_827D4CB0(ctx, base);
	// 82812360: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82812364: 395F00FC  addi r10, r31, 0xfc
	ctx.r[10].s64 = ctx.r[31].s64 + 252;
	// 82812368: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 8281236C: 386A0004  addi r3, r10, 4
	ctx.r[3].s64 = ctx.r[10].s64 + 4;
	// 82812370: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812374: 917F00FC  stw r11, 0xfc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(252 as u32), ctx.r[11].u32 ) };
	// 82812378: 4BAB20E9  bl 0x822c4460
	ctx.lr = 0x8281237C;
	sub_822C4460(ctx, base);
	// 8281237C: 8061006C  lwz r3, 0x6c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 82812380: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82812384: 419A0008  beq cr6, 0x8281238c
	if ctx.cr[6].eq {
	pc = 0x8281238C; continue 'dispatch;
	}
	// 82812388: 4BAAE509  bl 0x822c0890
	ctx.lr = 0x8281238C;
	sub_822C0890(ctx, base);
	// 8281238C: 80610074  lwz r3, 0x74(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 82812390: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82812394: 419A0008  beq cr6, 0x8281239c
	if ctx.cr[6].eq {
	pc = 0x8281239C; continue 'dispatch;
	}
	// 82812398: 4BAAE4F9  bl 0x822c0890
	ctx.lr = 0x8281239C;
	sub_822C0890(ctx, base);
	// 8281239C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 828123A0: 485DF8F1  bl 0x82df1c90
	ctx.lr = 0x828123A4;
	sub_82DF1C90(ctx, base);
	// 828123A4: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 828123A8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828123AC: 419A0008  beq cr6, 0x828123b4
	if ctx.cr[6].eq {
	pc = 0x828123B4; continue 'dispatch;
	}
	// 828123B0: 4BAAE4E1  bl 0x822c0890
	ctx.lr = 0x828123B4;
	sub_822C0890(ctx, base);
	// 828123B4: 807F00FC  lwz r3, 0xfc(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(252 as u32) ) } as u64;
	// 828123B8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828123BC: 419A0020  beq cr6, 0x828123dc
	if ctx.cr[6].eq {
	pc = 0x828123DC; continue 'dispatch;
	}
	// 828123C0: C01F010C  lfs f0, 0x10c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828123C4: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 828123C8: C1BF0108  lfs f13, 0x108(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(264 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 828123CC: EDA00372  fmuls f13, f0, f13
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 828123D0: C00B9524  lfs f0, -0x6adc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828123D4: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 828123D8: 4866F119  bl 0x82e814f0
	ctx.lr = 0x828123DC;
	sub_82E814F0(ctx, base);
	// 828123DC: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 828123E0: 48618721  bl 0x82e2ab00
	ctx.lr = 0x828123E4;
	sub_82E2AB00(ctx, base);
	// 828123E4: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 828123E8: 48995DD4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828123F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828123F0 size=132
    let mut pc: u32 = 0x828123F0;
    'dispatch: loop {
        match pc {
            0x828123F0 => {
    //   block [0x828123F0..0x82812474)
	// 828123F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828123F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828123F8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828123FC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812400: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812404: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812408: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281240C: 389E000C  addi r4, r30, 0xc
	ctx.r[4].s64 = ctx.r[30].s64 + 12;
	// 82812410: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 82812414: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812418: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8281241C: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82812420: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82812424: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82812428: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8281242C: 485E17D5  bl 0x82df3c00
	ctx.lr = 0x82812430;
	sub_82DF3C00(ctx, base);
	// 82812430: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 82812434: 389E0010  addi r4, r30, 0x10
	ctx.r[4].s64 = ctx.r[30].s64 + 16;
	// 82812438: 485E17C9  bl 0x82df3c00
	ctx.lr = 0x8281243C;
	sub_82DF3C00(ctx, base);
	// 8281243C: 387F0014  addi r3, r31, 0x14
	ctx.r[3].s64 = ctx.r[31].s64 + 20;
	// 82812440: 389E0014  addi r4, r30, 0x14
	ctx.r[4].s64 = ctx.r[30].s64 + 20;
	// 82812444: 485E17BD  bl 0x82df3c00
	ctx.lr = 0x82812448;
	sub_82DF3C00(ctx, base);
	// 82812448: C01E0018  lfs f0, 0x18(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281244C: D01F0018  stfs f0, 0x18(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82812450: 817E001C  lwz r11, 0x1c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 82812454: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 82812458: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281245C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812460: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812464: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812468: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281246C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812470: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812478(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812478 size=8
    let mut pc: u32 = 0x82812478;
    'dispatch: loop {
        match pc {
            0x82812478 => {
    //   block [0x82812478..0x82812480)
	// 82812478: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 8281247C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812480 size=96
    let mut pc: u32 = 0x82812480;
    'dispatch: loop {
        match pc {
            0x82812480 => {
    //   block [0x82812480..0x828124E0)
	// 82812480: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812484: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812488: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8281248C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812490: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812494: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82812498: C1BF0038  lfs f13, 0x38(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8281249C: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828124A0: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 828124A4: 419A0024  beq cr6, 0x828124c8
	if ctx.cr[6].eq {
	pc = 0x828124C8; continue 'dispatch;
	}
	// 828124A8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 828124AC: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 828124B0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828124B4: 4E800421  bctrl
	ctx.lr = 0x828124B8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828124B8: C01F0038  lfs f0, 0x38(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828124BC: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 828124C0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 828124C4: 41990008  bgt cr6, 0x828124cc
	if ctx.cr[6].gt {
	pc = 0x828124CC; continue 'dispatch;
	}
	// 828124C8: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 828124CC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828124D0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828124D4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828124D8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828124DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828124E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828124E0 size=92
    let mut pc: u32 = 0x828124E0;
    'dispatch: loop {
        match pc {
            0x828124E0 => {
    //   block [0x828124E0..0x8281253C)
	// 828124E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828124E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828124E8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828124EC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828124F0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828124F4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 828124F8: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 828124FC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82812500: 4E800421  bctrl
	ctx.lr = 0x82812504;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82812504: C01F002C  lfs f0, 0x2c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82812508: FF000800  fcmpu cr6, f0, f1
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[1].f64);
	// 8281250C: 40980018  bge cr6, 0x82812524
	if !ctx.cr[6].lt {
	pc = 0x82812524; continue 'dispatch;
	}
	// 82812510: C1BF0030  lfs f13, 0x30(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82812514: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82812518: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 8281251C: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82812520: 41980008  blt cr6, 0x82812528
	if ctx.cr[6].lt {
	pc = 0x82812528; continue 'dispatch;
	}
	// 82812524: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82812528: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8281252C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812530: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812534: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812538: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812540(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812540 size=76
    let mut pc: u32 = 0x82812540;
    'dispatch: loop {
        match pc {
            0x82812540 => {
    //   block [0x82812540..0x8281258C)
	// 82812540: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812544: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812548: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8281254C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812550: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812554: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812558: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8281255C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82812560: 4E800421  bctrl
	ctx.lr = 0x82812564;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82812564: C01F0034  lfs f0, 0x34(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82812568: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 8281256C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82812570: 41980008  blt cr6, 0x82812578
	if ctx.cr[6].lt {
	pc = 0x82812578; continue 'dispatch;
	}
	// 82812574: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82812578: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8281257C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812580: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812584: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812588: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812590(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812590 size=8
    let mut pc: u32 = 0x82812590;
    'dispatch: loop {
        match pc {
            0x82812590 => {
    //   block [0x82812590..0x82812598)
	// 82812590: 38630058  addi r3, r3, 0x58
	ctx.r[3].s64 = ctx.r[3].s64 + 88;
	// 82812594: 4805057C  b 0x82862b10
	sub_82862B10(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812598 size=40
    let mut pc: u32 = 0x82812598;
    'dispatch: loop {
        match pc {
            0x82812598 => {
    //   block [0x82812598..0x828125C0)
	// 82812598: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281259C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828125A0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828125A4: 38630058  addi r3, r3, 0x58
	ctx.r[3].s64 = ctx.r[3].s64 + 88;
	// 828125A8: 481FE2C9  bl 0x82a10870
	ctx.lr = 0x828125AC;
	sub_82A10870(ctx, base);
	// 828125AC: 4BFDB285  bl 0x827ed830
	ctx.lr = 0x828125B0;
	sub_827ED830(ctx, base);
	// 828125B0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828125B4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828125B8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828125BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828125C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828125C0 size=72
    let mut pc: u32 = 0x828125C0;
    'dispatch: loop {
        match pc {
            0x828125C0 => {
    //   block [0x828125C0..0x82812608)
	// 828125C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828125C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828125C8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828125CC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828125D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828125D4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828125D8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828125DC: 4BCFE12D  bl 0x82510708
	ctx.lr = 0x828125E0;
	sub_82510708(ctx, base);
	// 828125E0: C01E0000  lfs f0, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828125E4: C1BF00D8  lfs f13, 0xd8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(216 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 828125E8: EC00682A  fadds f0, f0, f13
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 828125EC: D01F00D8  stfs f0, 0xd8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 828125F0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828125F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828125F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828125FC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812600: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812604: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82812608 size=8
    let mut pc: u32 = 0x82812608;
    'dispatch: loop {
        match pc {
            0x82812608 => {
    //   block [0x82812608..0x82812610)
	// 82812608: C0230130  lfs f1, 0x130(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(304 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8281260C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812610 size=8
    let mut pc: u32 = 0x82812610;
    'dispatch: loop {
        match pc {
            0x82812610 => {
    //   block [0x82812610..0x82812618)
	// 82812610: 80630118  lwz r3, 0x118(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(280 as u32) ) } as u64;
	// 82812614: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812618 size=192
    let mut pc: u32 = 0x82812618;
    'dispatch: loop {
        match pc {
            0x82812618 => {
    //   block [0x82812618..0x828126D8)
	// 82812618: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281261C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812620: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812624: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812628: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281262C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812630: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812634: 4BFFFDBD  bl 0x828123f0
	ctx.lr = 0x82812638;
	sub_828123F0(ctx, base);
	// 82812638: C01E0020  lfs f0, 0x20(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281263C: 387F0038  addi r3, r31, 0x38
	ctx.r[3].s64 = ctx.r[31].s64 + 56;
	// 82812640: D01F0020  stfs f0, 0x20(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82812644: 389E0038  addi r4, r30, 0x38
	ctx.r[4].s64 = ctx.r[30].s64 + 56;
	// 82812648: C01E0024  lfs f0, 0x24(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281264C: D01F0024  stfs f0, 0x24(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82812650: C01E0028  lfs f0, 0x28(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82812654: D01F0028  stfs f0, 0x28(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82812658: C01E002C  lfs f0, 0x2c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(44 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281265C: D01F002C  stfs f0, 0x2c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 82812660: C01E0030  lfs f0, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82812664: D01F0030  stfs f0, 0x30(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 82812668: C01E0034  lfs f0, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281266C: D01F0034  stfs f0, 0x34(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 82812670: 485E1591  bl 0x82df3c00
	ctx.lr = 0x82812674;
	sub_82DF3C00(ctx, base);
	// 82812674: 387F003C  addi r3, r31, 0x3c
	ctx.r[3].s64 = ctx.r[31].s64 + 60;
	// 82812678: 389E003C  addi r4, r30, 0x3c
	ctx.r[4].s64 = ctx.r[30].s64 + 60;
	// 8281267C: 485E1585  bl 0x82df3c00
	ctx.lr = 0x82812680;
	sub_82DF3C00(ctx, base);
	// 82812680: 387F0040  addi r3, r31, 0x40
	ctx.r[3].s64 = ctx.r[31].s64 + 64;
	// 82812684: 389E0040  addi r4, r30, 0x40
	ctx.r[4].s64 = ctx.r[30].s64 + 64;
	// 82812688: 485E1579  bl 0x82df3c00
	ctx.lr = 0x8281268C;
	sub_82DF3C00(ctx, base);
	// 8281268C: 387F0044  addi r3, r31, 0x44
	ctx.r[3].s64 = ctx.r[31].s64 + 68;
	// 82812690: 389E0044  addi r4, r30, 0x44
	ctx.r[4].s64 = ctx.r[30].s64 + 68;
	// 82812694: 485E156D  bl 0x82df3c00
	ctx.lr = 0x82812698;
	sub_82DF3C00(ctx, base);
	// 82812698: 387F0048  addi r3, r31, 0x48
	ctx.r[3].s64 = ctx.r[31].s64 + 72;
	// 8281269C: 389E0048  addi r4, r30, 0x48
	ctx.r[4].s64 = ctx.r[30].s64 + 72;
	// 828126A0: 485E1561  bl 0x82df3c00
	ctx.lr = 0x828126A4;
	sub_82DF3C00(ctx, base);
	// 828126A4: 387F004C  addi r3, r31, 0x4c
	ctx.r[3].s64 = ctx.r[31].s64 + 76;
	// 828126A8: 389E004C  addi r4, r30, 0x4c
	ctx.r[4].s64 = ctx.r[30].s64 + 76;
	// 828126AC: 485E1555  bl 0x82df3c00
	ctx.lr = 0x828126B0;
	sub_82DF3C00(ctx, base);
	// 828126B0: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 828126B4: 389E0050  addi r4, r30, 0x50
	ctx.r[4].s64 = ctx.r[30].s64 + 80;
	// 828126B8: 485E1549  bl 0x82df3c00
	ctx.lr = 0x828126BC;
	sub_82DF3C00(ctx, base);
	// 828126BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828126C0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828126C4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828126C8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828126CC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 828126D0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828126D4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828126D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828126D8 size=24
    let mut pc: u32 = 0x828126D8;
    'dispatch: loop {
        match pc {
            0x828126D8 => {
    //   block [0x828126D8..0x828126F0)
	// 828126D8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 828126DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828126E0: 386B0004  addi r3, r11, 4
	ctx.r[3].s64 = ctx.r[11].s64 + 4;
	// 828126E4: 394A8F98  addi r10, r10, -0x7068
	ctx.r[10].s64 = ctx.r[10].s64 + -28776;
	// 828126E8: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 828126EC: 4BFE3E94  b 0x827f6580
	sub_827F6580(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828126F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828126F0 size=164
    let mut pc: u32 = 0x828126F0;
    'dispatch: loop {
        match pc {
            0x828126F0 => {
    //   block [0x828126F0..0x82812794)
	// 828126F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828126F4: 48995A71  bl 0x831a8164
	ctx.lr = 0x828126F8;
	sub_831A8130(ctx, base);
	// 828126F8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828126FC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82812700: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82812704: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82812708: 37DDFFA8  addic. r30, r29, -0x58
	ctx.xer.ca = (ctx.r[29].u32 > (!(-88 as u32)));
	ctx.r[30].s64 = ctx.r[29].s64 + -88;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8281270C: 7FBCEB78  mr r28, r29
	ctx.r[28].u64 = ctx.r[29].u64;
	// 82812710: 40820008  bne 0x82812718
	if !ctx.cr[0].eq {
	pc = 0x82812718; continue 'dispatch;
	}
	// 82812714: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 82812718: 3D608328  lis r11, -0x7cd8
	ctx.r[11].s64 = -2094530560;
	// 8281271C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82812720: 808BE250  lwz r4, -0x1db0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-7600 as u32) ) } as u64;
	// 82812724: 485E12E5  bl 0x82df3a08
	ctx.lr = 0x82812728;
	sub_82DF3A08(ctx, base);
	// 82812728: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8281272C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82812730: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812734: 4BCF604D  bl 0x82508780
	ctx.lr = 0x82812738;
	sub_82508780(ctx, base);
	// 82812738: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8281273C: 485E0CED  bl 0x82df3428
	ctx.lr = 0x82812740;
	sub_82DF3428(ctx, base);
	// 82812740: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82812744: 389D0028  addi r4, r29, 0x28
	ctx.r[4].s64 = ctx.r[29].s64 + 40;
	// 82812748: 409A0008  bne cr6, 0x82812750
	if !ctx.cr[6].eq {
	pc = 0x82812750; continue 'dispatch;
	}
	// 8281274C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82812750: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812754: 4BCF604D  bl 0x825087a0
	ctx.lr = 0x82812758;
	sub_825087A0(ctx, base);
	// 82812758: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8281275C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812760: 4BCF62B9  bl 0x82508a18
	ctx.lr = 0x82812764;
	sub_82508A18(ctx, base);
	// 82812764: 907D00C0  stw r3, 0xc0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(192 as u32), ctx.r[3].u32 ) };
	// 82812768: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281276C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82812770: 386BFF6C  addi r3, r11, -0x94
	ctx.r[3].s64 = ctx.r[11].s64 + -148;
	// 82812774: 409A0008  bne cr6, 0x8281277c
	if !ctx.cr[6].eq {
	pc = 0x8281277C; continue 'dispatch;
	}
	// 82812778: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8281277C: 4BD1590D  bl 0x82528088
	ctx.lr = 0x82812780;
	sub_82528088(ctx, base);
	// 82812780: 396000C8  li r11, 0xc8
	ctx.r[11].s64 = 200;
	// 82812784: 13E018C7  vcmpequd (lvx128) v31, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812798(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82812798 size=52
    let mut pc: u32 = 0x82812798;
    'dispatch: loop {
        match pc {
            0x82812798 => {
    //   block [0x82812798..0x828127CC)
	// 82812798: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8281279C: 13E028C7  vcmpequd (lvx128) v31, v0, v5
	tmp.u32 = ctx.r[5].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828127A0: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828127D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828127D0 size=64
    let mut pc: u32 = 0x828127D0;
    'dispatch: loop {
        match pc {
            0x828127D0 => {
    //   block [0x828127D0..0x82812810)
	// 828127D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828127D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828127D8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828127DC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828127E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828127E4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828127E8: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 828127EC: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 828127F0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828127F4: 4BFFFE25  bl 0x82812618
	ctx.lr = 0x828127F8;
	sub_82812618(ctx, base);
	// 828127F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828127FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82812800: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812804: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812808: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8281280C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812810(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812810 size=92
    let mut pc: u32 = 0x82812810;
    'dispatch: loop {
        match pc {
            0x82812810 => {
    //   block [0x82812810..0x8281286C)
	// 82812810: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812814: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812818: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8281281C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812820: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812824: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812828: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8281282C: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 82812830: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 82812834: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812838: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8281283C: 4BFE3D45  bl 0x827f6580
	ctx.lr = 0x82812840;
	sub_827F6580(ctx, base);
	// 82812840: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812844: 4182000C  beq 0x82812850
	if ctx.cr[0].eq {
	pc = 0x82812850; continue 'dispatch;
	}
	// 82812848: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281284C: 4BAADA1D  bl 0x822c0268
	ctx.lr = 0x82812850;
	sub_822C0268(ctx, base);
	// 82812850: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812854: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812858: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281285C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812860: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812864: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812868: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812870 size=96
    let mut pc: u32 = 0x82812870;
    'dispatch: loop {
        match pc {
            0x82812870 => {
    //   block [0x82812870..0x828128D0)
	// 82812870: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812874: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812878: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8281287C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812880: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812884: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812888: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 8281288C: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 82812890: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82812894: 4BFFFD85  bl 0x82812618
	ctx.lr = 0x82812898;
	sub_82812618(ctx, base);
	// 82812898: 387F0058  addi r3, r31, 0x58
	ctx.r[3].s64 = ctx.r[31].s64 + 88;
	// 8281289C: 4805027D  bl 0x82862b18
	ctx.lr = 0x828128A0;
	sub_82862B18(ctx, base);
	// 828128A0: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828128A4: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828128A8: 396B8FEC  addi r11, r11, -0x7014
	ctx.r[11].s64 = ctx.r[11].s64 + -28692;
	// 828128AC: 394A8FAC  addi r10, r10, -0x7054
	ctx.r[10].s64 = ctx.r[10].s64 + -28756;
	// 828128B0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828128B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828128B8: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 828128BC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828128C0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828128C4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828128C8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828128CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828128D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828128D0 size=8
    let mut pc: u32 = 0x828128D0;
    'dispatch: loop {
        match pc {
            0x828128D0 => {
    //   block [0x828128D0..0x828128D8)
	// 828128D0: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 828128D4: 48000054  b 0x82812928
	sub_82812928(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828128D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828128D8 size=80
    let mut pc: u32 = 0x828128D8;
    'dispatch: loop {
        match pc {
            0x828128D8 => {
    //   block [0x828128D8..0x82812928)
	// 828128D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828128DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828128E0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828128E4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828128E8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828128EC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 828128F0: 387F0058  addi r3, r31, 0x58
	ctx.r[3].s64 = ctx.r[31].s64 + 88;
	// 828128F4: 409A0008  bne cr6, 0x828128fc
	if !ctx.cr[6].eq {
	pc = 0x828128FC; continue 'dispatch;
	}
	// 828128F8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 828128FC: 48649C8D  bl 0x82e5c588
	ctx.lr = 0x82812900;
	sub_82E5C588(ctx, base);
	// 82812900: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812904: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 82812908: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 8281290C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82812910: 4BFE3C71  bl 0x827f6580
	ctx.lr = 0x82812914;
	sub_827F6580(ctx, base);
	// 82812914: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82812918: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281291C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812920: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812924: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812928(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812928 size=76
    let mut pc: u32 = 0x82812928;
    'dispatch: loop {
        match pc {
            0x82812928 => {
    //   block [0x82812928..0x82812974)
	// 82812928: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281292C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812930: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812934: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812938: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281293C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812940: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812944: 4BFFFF95  bl 0x828128d8
	ctx.lr = 0x82812948;
	sub_828128D8(ctx, base);
	// 82812948: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281294C: 4182000C  beq 0x82812958
	if ctx.cr[0].eq {
	pc = 0x82812958; continue 'dispatch;
	}
	// 82812950: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812954: 485DFA85  bl 0x82df23d8
	ctx.lr = 0x82812958;
	sub_82DF23D8(ctx, base);
	// 82812958: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281295C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812960: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812964: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812968: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281296C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812970: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812978 size=152
    let mut pc: u32 = 0x82812978;
    'dispatch: loop {
        match pc {
            0x82812978 => {
    //   block [0x82812978..0x82812A10)
	// 82812978: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281297C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812980: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812984: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812988: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281298C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812990: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 82812994: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 82812998: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8281299C: 4BFFFC7D  bl 0x82812618
	ctx.lr = 0x828129A0;
	sub_82812618(ctx, base);
	// 828129A0: 387F0058  addi r3, r31, 0x58
	ctx.r[3].s64 = ctx.r[31].s64 + 88;
	// 828129A4: 4BCFE74D  bl 0x825110f0
	ctx.lr = 0x828129A8;
	sub_825110F0(ctx, base);
	// 828129A8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828129AC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828129B0: 396B9040  addi r11, r11, -0x6fc0
	ctx.r[11].s64 = ctx.r[11].s64 + -28608;
	// 828129B4: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 828129B8: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 828129BC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828129C0: 3CE08208  lis r7, -0x7df8
	ctx.r[7].s64 = -2113404928;
	// 828129C4: 394A9014  addi r10, r10, -0x6fec
	ctx.r[10].s64 = ctx.r[10].s64 + -28652;
	// 828129C8: 39299000  addi r9, r9, -0x7000
	ctx.r[9].s64 = ctx.r[9].s64 + -28672;
	// 828129CC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 828129D0: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 828129D4: C00808A4  lfs f0, 0x8a4(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828129D8: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 828129DC: C1A78FF8  lfs f13, -0x7008(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-28680 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 828129E0: 917F0118  stw r11, 0x118(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(280 as u32), ctx.r[11].u32 ) };
	// 828129E4: D01F0120  stfs f0, 0x120(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(288 as u32), tmp.u32 ) };
	// 828129E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828129EC: D1BF0124  stfs f13, 0x124(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(292 as u32), tmp.u32 ) };
	// 828129F0: D01F0128  stfs f0, 0x128(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 828129F4: D01F012C  stfs f0, 0x12c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), tmp.u32 ) };
	// 828129F8: D01F0130  stfs f0, 0x130(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 828129FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82812A00: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812A04: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812A08: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812A0C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812A10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812A10 size=8
    let mut pc: u32 = 0x82812A10;
    'dispatch: loop {
        match pc {
            0x82812A10 => {
    //   block [0x82812A10..0x82812A18)
	// 82812A10: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 82812A14: 4800005C  b 0x82812a70
	sub_82812A70(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812A18 size=8
    let mut pc: u32 = 0x82812A18;
    'dispatch: loop {
        match pc {
            0x82812A18 => {
    //   block [0x82812A18..0x82812A20)
	// 82812A18: 3863FF80  addi r3, r3, -0x80
	ctx.r[3].s64 = ctx.r[3].s64 + -128;
	// 82812A1C: 48000054  b 0x82812a70
	sub_82812A70(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812A20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812A20 size=80
    let mut pc: u32 = 0x82812A20;
    'dispatch: loop {
        match pc {
            0x82812A20 => {
    //   block [0x82812A20..0x82812A70)
	// 82812A20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812A24: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812A28: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812A2C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812A30: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812A34: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82812A38: 387F0058  addi r3, r31, 0x58
	ctx.r[3].s64 = ctx.r[31].s64 + 88;
	// 82812A3C: 409A0008  bne cr6, 0x82812a44
	if !ctx.cr[6].eq {
	pc = 0x82812A44; continue 'dispatch;
	}
	// 82812A40: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82812A44: 4BCFE755  bl 0x82511198
	ctx.lr = 0x82812A48;
	sub_82511198(ctx, base);
	// 82812A48: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812A4C: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 82812A50: 396B8F98  addi r11, r11, -0x7068
	ctx.r[11].s64 = ctx.r[11].s64 + -28776;
	// 82812A54: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82812A58: 4BFE3B29  bl 0x827f6580
	ctx.lr = 0x82812A5C;
	sub_827F6580(ctx, base);
	// 82812A5C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82812A60: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812A64: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812A68: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812A6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812A70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812A70 size=76
    let mut pc: u32 = 0x82812A70;
    'dispatch: loop {
        match pc {
            0x82812A70 => {
    //   block [0x82812A70..0x82812ABC)
	// 82812A70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812A74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812A78: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812A7C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812A80: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812A84: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812A88: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82812A8C: 4BFFFF95  bl 0x82812a20
	ctx.lr = 0x82812A90;
	sub_82812A20(ctx, base);
	// 82812A90: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812A94: 4182000C  beq 0x82812aa0
	if ctx.cr[0].eq {
	pc = 0x82812AA0; continue 'dispatch;
	}
	// 82812A98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812A9C: 485DF93D  bl 0x82df23d8
	ctx.lr = 0x82812AA0;
	sub_82DF23D8(ctx, base);
	// 82812AA0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812AA4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812AA8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812AAC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812AB0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812AB4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812AB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812AC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812AC0 size=404
    let mut pc: u32 = 0x82812AC0;
    'dispatch: loop {
        match pc {
            0x82812AC0 => {
    //   block [0x82812AC0..0x82812C54)
	// 82812AC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812AC4: 489956A9  bl 0x831a816c
	ctx.lr = 0x82812AC8;
	sub_831A8130(ctx, base);
	// 82812AC8: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 82812ACC: 9421FEE0  stwu r1, -0x120(r1)
	ea = ctx.r[1].u32.wrapping_add(-288 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812AD0: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82812AD4: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82812AD8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82812ADC: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82812AE0: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82812AE4: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 82812AE8: C01F0000  lfs f0, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82812AEC: C1BF0004  lfs f13, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82812AF0: C19F0008  lfs f12, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82812AF4: C17F000C  lfs f11, 0xc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82812AF8: D0010060  stfs f0, 0x60(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 82812AFC: D1A10064  stfs f13, 0x64(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82812B00: D1810068  stfs f12, 0x68(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82812B04: D161006C  stfs f11, 0x6c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 82812B08: 48669391  bl 0x82e7be98
	ctx.lr = 0x82812B0C;
	sub_82E7BE98(ctx, base);
	// 82812B0C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82812B10: 38BE0010  addi r5, r30, 0x10
	ctx.r[5].s64 = ctx.r[30].s64 + 16;
	// 82812B14: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82812B18: 486691B1  bl 0x82e7bcc8
	ctx.lr = 0x82812B1C;
	sub_82E7BCC8(ctx, base);
	// 82812B1C: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 82812B20: 13C0E8C7  vcmpequd (lvx128) v30, v0, v29
	tmp.u32 = ctx.r[29].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82812B24: 39410080  addi r10, r1, 0x80
	ctx.r[10].s64 = ctx.r[1].s64 + 128;
	// 82812B28: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 82812B2C: 38A10080  addi r5, r1, 0x80
	ctx.r[5].s64 = ctx.r[1].s64 + 128;
	// 82812B30: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 82812B34: 13FF58C7  vcmpequd (lvx128) v31, v31, v11
	tmp.u32 = ctx.r[31].u32 + ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82812B38: 38610090  addi r3, r1, 0x90
	ctx.r[3].s64 = ctx.r[1].s64 + 144;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812C58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812C58 size=120
    let mut pc: u32 = 0x82812C58;
    'dispatch: loop {
        match pc {
            0x82812C58 => {
    //   block [0x82812C58..0x82812CD0)
	// 82812C58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812C5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812C60: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812C64: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812C68: 394100DC  addi r10, r1, 0xdc
	ctx.r[10].s64 = ctx.r[1].s64 + 220;
	// 82812C6C: D02100DC  stfs f1, 0xdc(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 82812C70: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82812C74: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 82812C78: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82812C7C: 7CC43378  mr r4, r6
	ctx.r[4].u64 = ctx.r[6].u64;
	// 82812C80: 13E05407  vcmpneb. (lvlx128) v31, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812CD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812CD0 size=136
    let mut pc: u32 = 0x82812CD0;
    'dispatch: loop {
        match pc {
            0x82812CD0 => {
    //   block [0x82812CD0..0x82812D58)
	// 82812CD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812CD4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812CD8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812CDC: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812CE0: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 82812CE4: 13E020C7  vcmpequd (lvx128) v31, v0, v4
	tmp.u32 = ctx.r[4].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82812CE8: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82812CEC: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82812CF0: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82812CF4: 38860010  addi r4, r6, 0x10
	ctx.r[4].s64 = ctx.r[6].s64 + 16;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812D58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812D58 size=192
    let mut pc: u32 = 0x82812D58;
    'dispatch: loop {
        match pc {
            0x82812D58 => {
    //   block [0x82812D58..0x82812E18)
	// 82812D58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812D5C: 4899540D  bl 0x831a8168
	ctx.lr = 0x82812D60;
	sub_831A8130(ctx, base);
	// 82812D60: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812D64: 3D608328  lis r11, -0x7cd8
	ctx.r[11].s64 = -2094530560;
	// 82812D68: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82812D6C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82812D70: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82812D74: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82812D78: 808BE250  lwz r4, -0x1db0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-7600 as u32) ) } as u64;
	// 82812D7C: 7CDF3378  mr r31, r6
	ctx.r[31].u64 = ctx.r[6].u64;
	// 82812D80: 485E0C89  bl 0x82df3a08
	ctx.lr = 0x82812D84;
	sub_82DF3A08(ctx, base);
	// 82812D84: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82812D88: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82812D8C: 80BF0000  lwz r5, 0(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812D90: 4BCF59F1  bl 0x82508780
	ctx.lr = 0x82812D94;
	sub_82508780(ctx, base);
	// 82812D94: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82812D98: 485E0691  bl 0x82df3428
	ctx.lr = 0x82812D9C;
	sub_82DF3428(ctx, base);
	// 82812D9C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82812DA0: 38DE0058  addi r6, r30, 0x58
	ctx.r[6].s64 = ctx.r[30].s64 + 88;
	// 82812DA4: 409A0008  bne cr6, 0x82812dac
	if !ctx.cr[6].eq {
	pc = 0x82812DAC; continue 'dispatch;
	}
	// 82812DA8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82812DAC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82812DB0: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812DB4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82812DB8: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82812DBC: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82812DC0: 419A0024  beq cr6, 0x82812de4
	if ctx.cr[6].eq {
	pc = 0x82812DE4; continue 'dispatch;
	}
	// 82812DC4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82812DC8: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82812DCC: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82812DD0: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82812DD4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82812DD8: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82812DDC: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82812DE0: 4082FFE8  bne 0x82812dc8
	if !ctx.cr[0].eq {
	pc = 0x82812DC8; continue 'dispatch;
	}
	// 82812DE4: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82812DE8: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82812DEC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82812DF0: 4BCFA719  bl 0x8250d508
	ctx.lr = 0x82812DF4;
	sub_8250D508(ctx, base);
	// 82812DF4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82812DF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82812DFC: 388B0028  addi r4, r11, 0x28
	ctx.r[4].s64 = ctx.r[11].s64 + 40;
	// 82812E00: 409A0008  bne cr6, 0x82812e08
	if !ctx.cr[6].eq {
	pc = 0x82812E08; continue 'dispatch;
	}
	// 82812E04: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82812E08: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82812E0C: 4BCF5995  bl 0x825087a0
	ctx.lr = 0x82812E10;
	sub_825087A0(ctx, base);
	// 82812E10: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82812E14: 489953A4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812E18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812E18 size=60
    let mut pc: u32 = 0x82812E18;
    'dispatch: loop {
        match pc {
            0x82812E18 => {
    //   block [0x82812E18..0x82812E54)
	// 82812E18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812E1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812E20: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812E24: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812E28: 7CAB2B78  mr r11, r5
	ctx.r[11].u64 = ctx.r[5].u64;
	// 82812E2C: 80A400C8  lwz r5, 0xc8(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(200 as u32) ) } as u64;
	// 82812E30: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812E34: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82812E38: 4BFDBBB1  bl 0x827ee9e8
	ctx.lr = 0x82812E3C;
	sub_827EE9E8(ctx, base);
	// 82812E3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812E40: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82812E44: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812E48: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812E4C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812E50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812E58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812E58 size=116
    let mut pc: u32 = 0x82812E58;
    'dispatch: loop {
        match pc {
            0x82812E58 => {
    //   block [0x82812E58..0x82812ECC)
	// 82812E58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812E5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812E60: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812E64: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812E68: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812E6C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82812E70: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82812E74: 387EFFA8  addi r3, r30, -0x58
	ctx.r[3].s64 = ctx.r[30].s64 + -88;
	// 82812E78: 4BFFF609  bl 0x82812480
	ctx.lr = 0x82812E7C;
	sub_82812480(ctx, base);
	// 82812E7C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812E80: 40820008  bne 0x82812e88
	if !ctx.cr[0].eq {
	pc = 0x82812E88; continue 'dispatch;
	}
	// 82812E84: 3BE00001  li r31, 1
	ctx.r[31].s64 = 1;
	// 82812E88: 897E00EC  lbz r11, 0xec(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(236 as u32) ) } as u64;
	// 82812E8C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82812E90: 409A0008  bne cr6, 0x82812e98
	if !ctx.cr[6].eq {
	pc = 0x82812E98; continue 'dispatch;
	}
	// 82812E94: 63FF0002  ori r31, r31, 2
	ctx.r[31].u64 = ctx.r[31].u64 | 2;
	// 82812E98: 57EB07FF  clrlwi. r11, r31, 0x1f
	ctx.r[11].u64 = ctx.r[31].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82812E9C: 40820014  bne 0x82812eb0
	if !ctx.cr[0].eq {
	pc = 0x82812EB0; continue 'dispatch;
	}
	// 82812EA0: 897E00ED  lbz r11, 0xed(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(237 as u32) ) } as u64;
	// 82812EA4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82812EA8: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82812EAC: 41820008  beq 0x82812eb4
	if ctx.cr[0].eq {
	pc = 0x82812EB4; continue 'dispatch;
	}
	// 82812EB0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82812EB4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812EB8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812EBC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812EC0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812EC4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812EC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812ED0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82812ED0 size=116
    let mut pc: u32 = 0x82812ED0;
    'dispatch: loop {
        match pc {
            0x82812ED0 => {
    //   block [0x82812ED0..0x82812F44)
	// 82812ED0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812ED4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82812ED8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82812EDC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82812EE0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812EE4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82812EE8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82812EEC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82812EF0: 396B9094  addi r11, r11, -0x6f6c
	ctx.r[11].s64 = ctx.r[11].s64 + -28524;
	// 82812EF4: 394A9054  addi r10, r10, -0x6fac
	ctx.r[10].s64 = ctx.r[10].s64 + -28588;
	// 82812EF8: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82812EFC: 3BDF0058  addi r30, r31, 0x58
	ctx.r[30].s64 = ctx.r[31].s64 + 88;
	// 82812F00: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82812F04: 807F00C4  lwz r3, 0xc4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 82812F08: 4BAAD361  bl 0x822c0268
	ctx.lr = 0x82812F0C;
	sub_822C0268(ctx, base);
	// 82812F0C: 807F00C0  lwz r3, 0xc0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 82812F10: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82812F14: 419A0008  beq cr6, 0x82812f1c
	if ctx.cr[6].eq {
	pc = 0x82812F1C; continue 'dispatch;
	}
	// 82812F18: 4BAAD979  bl 0x822c0890
	ctx.lr = 0x82812F1C;
	sub_822C0890(ctx, base);
	// 82812F1C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82812F20: 48649669  bl 0x82e5c588
	ctx.lr = 0x82812F24;
	sub_82E5C588(ctx, base);
	// 82812F24: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82812F28: 4BFFF7B1  bl 0x828126d8
	ctx.lr = 0x82812F2C;
	sub_828126D8(ctx, base);
	// 82812F2C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82812F30: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82812F34: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82812F38: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82812F3C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82812F40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812F48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82812F48 size=8
    let mut pc: u32 = 0x82812F48;
    'dispatch: loop {
        match pc {
            0x82812F48 => {
    //   block [0x82812F48..0x82812F50)
	// 82812F48: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 82812F4C: 4800018C  b 0x828130d8
	sub_828130D8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82812F50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82812F50 size=184
    let mut pc: u32 = 0x82812F50;
    'dispatch: loop {
        match pc {
            0x82812F50 => {
    //   block [0x82812F50..0x82813008)
	// 82812F50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82812F54: 48995219  bl 0x831a816c
	ctx.lr = 0x82812F58;
	sub_831A8130(ctx, base);
	// 82812F58: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82812F5C: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82812F60: 806300BC  lwz r3, 0xbc(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(188 as u32) ) } as u64;
	// 82812F64: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82812F68: 3BFD0010  addi r31, r29, 0x10
	ctx.r[31].s64 = ctx.r[29].s64 + 16;
	// 82812F6C: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 82812F70: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82812F74: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 82812F78: 13C0F0C7  vcmpequd (lvx128) v30, v0, v30
	tmp.u32 = ctx.r[30].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82812F7C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82812F80: 13E0F8C7  vcmpequd (lvx128) v31, v0, v31
	tmp.u32 = ctx.r[31].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82812F84: 38C10070  addi r6, r1, 0x70
	ctx.r[6].s64 = ctx.r[1].s64 + 112;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813008(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813008 size=208
    let mut pc: u32 = 0x82813008;
    'dispatch: loop {
        match pc {
            0x82813008 => {
    //   block [0x82813008..0x828130D8)
	// 82813008: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281300C: 4899515D  bl 0x831a8168
	ctx.lr = 0x82813010;
	sub_831A8130(ctx, base);
	// 82813010: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813014: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82813018: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8281301C: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82813020: 4BFFF851  bl 0x82812870
	ctx.lr = 0x82813024;
	sub_82812870(ctx, base);
	// 82813024: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813028: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8281302C: 396B9094  addi r11, r11, -0x6f6c
	ctx.r[11].s64 = ctx.r[11].s64 + -28524;
	// 82813030: 394A9054  addi r10, r10, -0x6fac
	ctx.r[10].s64 = ctx.r[10].s64 + -28588;
	// 82813034: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82813038: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8281303C: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82813040: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813044: 93DF00BC  stw r30, 0xbc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(188 as u32), ctx.r[30].u32 ) };
	// 82813048: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8281304C: 93DF00C0  stw r30, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[30].u32 ) };
	// 82813050: 388B90A8  addi r4, r11, -0x6f58
	ctx.r[4].s64 = ctx.r[11].s64 + -28504;
	// 82813054: 38A0003E  li r5, 0x3e
	ctx.r[5].s64 = 62;
	// 82813058: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 8281305C: 4BAAD37D  bl 0x822c03d8
	ctx.lr = 0x82813060;
	sub_822C03D8(ctx, base);
	// 82813060: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82813064: 41820020  beq 0x82813084
	if ctx.cr[0].eq {
	pc = 0x82813084; continue 'dispatch;
	}
	// 82813068: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8281306C: C03D0024  lfs f1, 0x24(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(36 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82813070: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 82813074: 38ABEF00  addi r5, r11, -0x1100
	ctx.r[5].s64 = ctx.r[11].s64 + -4352;
	// 82813078: 388AEEF0  addi r4, r10, -0x1110
	ctx.r[4].s64 = ctx.r[10].s64 + -4368;
	// 8281307C: 4BFFF71D  bl 0x82812798
	ctx.lr = 0x82813080;
	sub_82812798(ctx, base);
	// 82813080: 48000008  b 0x82813088
	pc = 0x82813088; continue 'dispatch;
	// 82813084: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813088: 907F00C4  stw r3, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[3].u32 ) };
	// 8281308C: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82813090: 815C0000  lwz r10, 0(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813094: 392000D0  li r9, 0xd0
	ctx.r[9].s64 = 208;
	// 82813098: 915F00C8  stw r10, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[10].u32 ) };
	// 8281309C: 38AB6910  addi r5, r11, 0x6910
	ctx.r[5].s64 = ctx.r[11].s64 + 26896;
	// 828130A0: 13E028C7  vcmpequd (lvx128) v31, v0, v5
	tmp.u32 = ctx.r[5].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828130A4: 3D608332  lis r11, -0x7cce
	ctx.r[11].s64 = -2093875200;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828130D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828130D8 size=76
    let mut pc: u32 = 0x828130D8;
    'dispatch: loop {
        match pc {
            0x828130D8 => {
    //   block [0x828130D8..0x82813124)
	// 828130D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828130DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828130E0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828130E4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828130E8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828130EC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828130F0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828130F4: 4BFFFDDD  bl 0x82812ed0
	ctx.lr = 0x828130F8;
	sub_82812ED0(ctx, base);
	// 828130F8: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828130FC: 4182000C  beq 0x82813108
	if ctx.cr[0].eq {
	pc = 0x82813108; continue 'dispatch;
	}
	// 82813100: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813104: 485DF2D5  bl 0x82df23d8
	ctx.lr = 0x82813108;
	sub_82DF23D8(ctx, base);
	// 82813108: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281310C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813110: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813114: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813118: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281311C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813120: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813128(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813128 size=552
    let mut pc: u32 = 0x82813128;
    'dispatch: loop {
        match pc {
            0x82813128 => {
    //   block [0x82813128..0x82813350)
	// 82813128: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281312C: 48995039  bl 0x831a8164
	ctx.lr = 0x82813130;
	sub_831A8130(ctx, base);
	// 82813130: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 82813134: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813138: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281313C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82813140: D3E10114  stfs f31, 0x114(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), tmp.u32 ) };
	// 82813144: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82813148: 3BBFFFA8  addi r29, r31, -0x58
	ctx.r[29].s64 = ctx.r[31].s64 + -88;
	// 8281314C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82813150: 4BFFF329  bl 0x82812478
	ctx.lr = 0x82813154;
	sub_82812478(ctx, base);
	// 82813154: 817F0070  lwz r11, 0x70(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(112 as u32) ) } as u64;
	// 82813158: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8281315C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82813160: 419A01E4  beq cr6, 0x82813344
	if ctx.cr[6].eq {
	pc = 0x82813344; continue 'dispatch;
	}
	// 82813164: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813168: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8281316C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82813170: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82813174: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82813178: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281317C: 4E800421  bctrl
	ctx.lr = 0x82813180;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82813180: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82813184: 4800723D  bl 0x8281a3c0
	ctx.lr = 0x82813188;
	sub_8281A3C0(ctx, base);
	// 82813188: 7C7E1B79  or. r30, r3, r3
	ctx.r[30].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8281318C: 41820080  beq 0x8281320c
	if ctx.cr[0].eq {
	pc = 0x8281320C; continue 'dispatch;
	}
	// 82813190: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82813194: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82813198: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 8281319C: 4BAE0B0D  bl 0x822f3ca8
	ctx.lr = 0x828131A0;
	sub_822F3CA8(ctx, base);
	// 828131A0: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828131A4: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 828131A8: 38CBEF00  addi r6, r11, -0x1100
	ctx.r[6].s64 = ctx.r[11].s64 + -4352;
	// 828131AC: 388AEEF0  addi r4, r10, -0x1110
	ctx.r[4].s64 = ctx.r[10].s64 + -4368;
	// 828131B0: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 828131B4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828131B8: 48669EA9  bl 0x82e7d060
	ctx.lr = 0x828131BC;
	sub_82E7D060(ctx, base);
	// 828131BC: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 828131C0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828131C4: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 828131C8: 4BAE0AA1  bl 0x822f3c68
	ctx.lr = 0x828131CC;
	sub_822F3C68(ctx, base);
	// 828131CC: 3BDF0088  addi r30, r31, 0x88
	ctx.r[30].s64 = ctx.r[31].s64 + 136;
	// 828131D0: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 828131D4: 13E018C7  vcmpequd (lvx128) v31, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828131D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813350(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813350 size=372
    let mut pc: u32 = 0x82813350;
    'dispatch: loop {
        match pc {
            0x82813350 => {
    //   block [0x82813350..0x828134C4)
	// 82813350: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813354: 48994E0D  bl 0x831a8160
	ctx.lr = 0x82813358;
	sub_831A8130(ctx, base);
	// 82813358: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281335C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82813360: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813364: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 82813368: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 8281336C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82813370: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 82813374: 38800020  li r4, 0x20
	ctx.r[4].s64 = 32;
	// 82813378: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8281337C: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82813380: 4868D3B1  bl 0x82ea0730
	ctx.lr = 0x82813384;
	sub_82EA0730(ctx, base);
	// 82813384: 39600020  li r11, 0x20
	ctx.r[11].s64 = 32;
	// 82813388: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 8281338C: B1630004  sth r11, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u16 ) };
	// 82813390: C02A9450  lfs f1, -0x6bb0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82813394: 48706E5D  bl 0x82f1a1f0
	ctx.lr = 0x82813398;
	sub_82F1A1F0(ctx, base);
	// 82813398: 90610050  stw r3, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u32 ) };
	// 8281339C: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 828133A0: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 828133A4: 808B67CC  lwz r4, 0x67cc(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26572 as u32) ) } as u64;
	// 828133A8: 4BAD1B89  bl 0x822e4f30
	ctx.lr = 0x828133AC;
	sub_822E4F30(ctx, base);
	// 828133AC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828133B0: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 828133B4: 4BAD1B0D  bl 0x822e4ec0
	ctx.lr = 0x828133B8;
	sub_822E4EC0(ctx, base);
	// 828133B8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 828133BC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828133C0: E89F0000  ld r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	// 828133C4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 828133C8: E8630000  ld r3, 0(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	// 828133CC: 4BC78EBD  bl 0x8248c288
	ctx.lr = 0x828133D0;
	sub_8248C288(ctx, base);
	// 828133D0: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828133D4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 828133D8: 388B90A8  addi r4, r11, -0x6f58
	ctx.r[4].s64 = ctx.r[11].s64 + -28504;
	// 828133DC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828133E0: 38A00058  li r5, 0x58
	ctx.r[5].s64 = 88;
	// 828133E4: 38600008  li r3, 8
	ctx.r[3].s64 = 8;
	// 828133E8: 4BAACFF1  bl 0x822c03d8
	ctx.lr = 0x828133EC;
	sub_822C03D8(ctx, base);
	// 828133EC: 7C7F1B79  or. r31, r3, r3
	ctx.r[31].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 828133F0: 4182003C  beq 0x8281342c
	if ctx.cr[0].eq {
	pc = 0x8281342C; continue 'dispatch;
	}
	// 828133F4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 828133F8: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 828133FC: 3B410050  addi r26, r1, 0x50
	ctx.r[26].s64 = ctx.r[1].s64 + 80;
	// 82813400: 4BFDA419  bl 0x827ed818
	ctx.lr = 0x82813404;
	sub_827ED818(ctx, base);
	// 82813404: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82813408: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 8281340C: 4BCFC10D  bl 0x8250f518
	ctx.lr = 0x82813410;
	sub_8250F518(ctx, base);
	// 82813410: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82813414: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813418: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 8281341C: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82813420: 4BC7EDD1  bl 0x824921f0
	ctx.lr = 0x82813424;
	sub_824921F0(ctx, base);
	// 82813424: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82813428: 48000008  b 0x82813430
	pc = 0x82813430; continue 'dispatch;
	// 8281342C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82813430: 387B0064  addi r3, r27, 0x64
	ctx.r[3].s64 = ctx.r[27].s64 + 100;
	// 82813434: 4BAD19B5  bl 0x822e4de8
	ctx.lr = 0x82813438;
	sub_822E4DE8(ctx, base);
	// 82813438: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281343C: 4182000C  beq 0x82813448
	if ctx.cr[0].eq {
	pc = 0x82813448; continue 'dispatch;
	}
	// 82813440: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82813444: 485DE84D  bl 0x82df1c90
	ctx.lr = 0x82813448;
	sub_82DF1C90(ctx, base);
	// 82813448: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8281344C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813450: 419A0008  beq cr6, 0x82813458
	if ctx.cr[6].eq {
	pc = 0x82813458; continue 'dispatch;
	}
	// 82813454: 4BAD4E15  bl 0x822e8268
	ctx.lr = 0x82813458;
	sub_822E8268(ctx, base);
	// 82813458: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8281345C: 48006F65  bl 0x8281a3c0
	ctx.lr = 0x82813460;
	sub_8281A3C0(ctx, base);
	// 82813460: 7C641B79  or. r4, r3, r3
	ctx.r[4].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82813464: 41820058  beq 0x828134bc
	if ctx.cr[0].eq {
	pc = 0x828134BC; continue 'dispatch;
	}
	// 82813468: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8281346C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82813470: 4BAE0839  bl 0x822f3ca8
	ctx.lr = 0x82813474;
	sub_822F3CA8(ctx, base);
	// 82813474: 13E018C7  vcmpequd (lvx128) v31, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828134C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828134C8 size=72
    let mut pc: u32 = 0x828134C8;
    'dispatch: loop {
        match pc {
            0x828134C8 => {
    //   block [0x828134C8..0x82813510)
	// 828134C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828134CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828134D0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828134D4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828134D8: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 828134DC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 828134E0: 4BFFEFA1  bl 0x82812480
	ctx.lr = 0x828134E4;
	sub_82812480(ctx, base);
	// 828134E4: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828134E8: 40820008  bne 0x828134f0
	if !ctx.cr[0].eq {
	pc = 0x828134F0; continue 'dispatch;
	}
	// 828134EC: 3BE00001  li r31, 1
	ctx.r[31].s64 = 1;
	// 828134F0: 7FEB0034  cntlzw r11, r31
	ctx.r[11].u64 = if ctx.r[31].u32 == 0 { 32 } else { ctx.r[31].u32.leading_zeros() as u64 };
	// 828134F4: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 828134F8: 69630001  xori r3, r11, 1
	ctx.r[3].u64 = ctx.r[11].u64 ^ 1;
	// 828134FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82813500: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813504: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813508: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8281350C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813510(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813510 size=136
    let mut pc: u32 = 0x82813510;
    'dispatch: loop {
        match pc {
            0x82813510 => {
    //   block [0x82813510..0x82813598)
	// 82813510: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813514: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82813518: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8281351C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82813520: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813524: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813528: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8281352C: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 82813530: 409A0020  bne cr6, 0x82813550
	if !ctx.cr[6].eq {
	pc = 0x82813550; continue 'dispatch;
	}
	// 82813534: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82813538: 419A0048  beq cr6, 0x82813580
	if ctx.cr[6].eq {
	pc = 0x82813580; continue 'dispatch;
	}
	// 8281353C: E97E0000  ld r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	// 82813540: F97F0000  std r11, 0(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 82813544: E97E0008  ld r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	// 82813548: F97F0008  std r11, 8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 8281354C: 48000034  b 0x82813580
	pc = 0x82813580; continue 'dispatch;
	// 82813550: 2F050001  cmpwi cr6, r5, 1
	ctx.cr[6].compare_i32(ctx.r[5].s32, 1, &mut ctx.xer);
	// 82813554: 419A002C  beq cr6, 0x82813580
	if ctx.cr[6].eq {
	pc = 0x82813580; continue 'dispatch;
	}
	// 82813558: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8281355C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813560: 388BF010  addi r4, r11, -0xff0
	ctx.r[4].s64 = ctx.r[11].s64 + -4080;
	// 82813564: 48994B95  bl 0x831a80f8
	ctx.lr = 0x82813568;
	sub_831A80F8(ctx, base);
	// 82813568: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281356C: 4182000C  beq 0x82813578
	if ctx.cr[0].eq {
	pc = 0x82813578; continue 'dispatch;
	}
	// 82813570: 93DF0000  stw r30, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 82813574: 4800000C  b 0x82813580
	pc = 0x82813580; continue 'dispatch;
	// 82813578: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8281357C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813580: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813584: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813588: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8281358C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82813590: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813594: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813598 size=96
    let mut pc: u32 = 0x82813598;
    'dispatch: loop {
        match pc {
            0x82813598 => {
    //   block [0x82813598..0x828135F8)
	// 82813598: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281359C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828135A0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828135A4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828135A8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828135AC: 806400C8  lwz r3, 0xc8(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(200 as u32) ) } as u64;
	// 828135B0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 828135B4: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 828135B8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828135BC: 4E800421  bctrl
	ctx.lr = 0x828135C0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828135C0: C0030030  lfs f0, 0x30(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828135C4: C1A30034  lfs f13, 0x34(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 828135C8: C1830038  lfs f12, 0x38(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 828135CC: C163003C  lfs f11, 0x3c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(60 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 828135D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828135D4: D01F0000  stfs f0, 0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 828135D8: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 828135DC: D19F0008  stfs f12, 8(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 828135E0: D17F000C  stfs f11, 0xc(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 828135E4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828135E8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828135EC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828135F0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828135F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828135F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828135F8 size=76
    let mut pc: u32 = 0x828135F8;
    'dispatch: loop {
        match pc {
            0x828135F8 => {
    //   block [0x828135F8..0x82813644)
	// 828135F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828135FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82813600: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82813604: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813608: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281360C: 806400C8  lwz r3, 0xc8(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(200 as u32) ) } as u64;
	// 82813610: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813614: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82813618: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281361C: 4E800421  bctrl
	ctx.lr = 0x82813620;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82813620: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82813624: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813628: 486697E1  bl 0x82e7ce08
	ctx.lr = 0x8281362C;
	sub_82E7CE08(ctx, base);
	// 8281362C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813630: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82813634: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813638: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8281363C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813640: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82813648 size=16
    let mut pc: u32 = 0x82813648;
    'dispatch: loop {
        match pc {
            0x82813648 => {
    //   block [0x82813648..0x82813658)
	// 82813648: 39600100  li r11, 0x100
	ctx.r[11].s64 = 256;
	// 8281364C: 13E020C7  vcmpequd (lvx128) v31, v0, v4
	tmp.u32 = ctx.r[4].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813658 size=100
    let mut pc: u32 = 0x82813658;
    'dispatch: loop {
        match pc {
            0x82813658 => {
    //   block [0x82813658..0x828136BC)
	// 82813658: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281365C: 48994B11  bl 0x831a816c
	ctx.lr = 0x82813660;
	sub_831A8130(ctx, base);
	// 82813660: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813664: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813668: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8281366C: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813670: 4BAD2751  bl 0x822e5dc0
	ctx.lr = 0x82813674;
	sub_822E5DC0(ctx, base);
	// 82813674: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82813678: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8281367C: 419A000C  beq cr6, 0x82813688
	if ctx.cr[6].eq {
	pc = 0x82813688; continue 'dispatch;
	}
	// 82813680: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813684: 486BB17D  bl 0x82ece800
	ctx.lr = 0x82813688;
	sub_82ECE800(ctx, base);
	// 82813688: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281368C: 4BAD2735  bl 0x822e5dc0
	ctx.lr = 0x82813690;
	sub_822E5DC0(ctx, base);
	// 82813690: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813694: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82813698: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8281369C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828136A0: 4E800421  bctrl
	ctx.lr = 0x828136A4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828136A4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 828136A8: 419A000C  beq cr6, 0x828136b4
	if ctx.cr[6].eq {
	pc = 0x828136B4; continue 'dispatch;
	}
	// 828136AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828136B0: 486B9959  bl 0x82ecd008
	ctx.lr = 0x828136B4;
	sub_82ECD008(ctx, base);
	// 828136B4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828136B8: 48994B04  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828136C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828136C0 size=196
    let mut pc: u32 = 0x828136C0;
    'dispatch: loop {
        match pc {
            0x828136C0 => {
    //   block [0x828136C0..0x82813784)
	// 828136C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828136C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828136C8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828136CC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828136D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828136D4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 828136D8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 828136DC: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 828136E0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 828136E4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828136E8: 4BAAD251  bl 0x822c0938
	ctx.lr = 0x828136EC;
	sub_822C0938(ctx, base);
	// 828136EC: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828136F0: 41820028  beq 0x82813718
	if ctx.cr[0].eq {
	pc = 0x82813718; continue 'dispatch;
	}
	// 828136F4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828136F8: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 828136FC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82813700: 392B9108  addi r9, r11, -0x6ef8
	ctx.r[9].s64 = ctx.r[11].s64 + -28408;
	// 82813704: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82813708: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8281370C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82813710: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82813714: 48000008  b 0x8281371c
	pc = 0x8281371C; continue 'dispatch;
	// 82813718: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8281371C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813720: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82813724: 409A0044  bne cr6, 0x82813768
	if !ctx.cr[6].eq {
	pc = 0x82813768; continue 'dispatch;
	}
	// 82813728: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8281372C: 419A001C  beq cr6, 0x82813748
	if ctx.cr[6].eq {
	pc = 0x82813748; continue 'dispatch;
	}
	// 82813730: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813734: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82813738: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281373C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813740: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82813744: 4E800421  bctrl
	ctx.lr = 0x82813748;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82813748: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8281374C: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82813750: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82813754: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82813758: 816BEF40  lwz r11, -0x10c0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4288 as u32) ) } as u64;
	// 8281375C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82813760: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82813764: 4BAAC89D  bl 0x822c0000
	ctx.lr = 0x82813768;
	sub_822C0000(ctx, base);
	// 82813768: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8281376C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813770: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813774: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813778: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281377C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813780: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813788 size=72
    let mut pc: u32 = 0x82813788;
    'dispatch: loop {
        match pc {
            0x82813788 => {
    //   block [0x82813788..0x828137D0)
	// 82813788: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281378C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82813790: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813794: 2F050003  cmpwi cr6, r5, 3
	ctx.cr[6].compare_i32(ctx.r[5].s32, 3, &mut ctx.xer);
	// 82813798: 419A001C  beq cr6, 0x828137b4
	if ctx.cr[6].eq {
	pc = 0x828137B4; continue 'dispatch;
	}
	// 8281379C: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 828137A0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 828137A4: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 828137A8: 88C10050  lbz r6, 0x50(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 828137AC: 4BFFFD65  bl 0x82813510
	ctx.lr = 0x828137B0;
	sub_82813510(ctx, base);
	// 828137B0: 48000010  b 0x828137c0
	pc = 0x828137C0; continue 'dispatch;
	// 828137B4: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828137B8: 396BF010  addi r11, r11, -0xff0
	ctx.r[11].s64 = ctx.r[11].s64 + -4080;
	// 828137BC: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828137C0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828137C4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828137C8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828137CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828137D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828137D0 size=272
    let mut pc: u32 = 0x828137D0;
    'dispatch: loop {
        match pc {
            0x828137D0 => {
    //   block [0x828137D0..0x828138E0)
	// 828137D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828137D4: 48994999  bl 0x831a816c
	ctx.lr = 0x828137D8;
	sub_831A8130(ctx, base);
	// 828137D8: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 828137DC: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828137E0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 828137E4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 828137E8: 4BFFEC91  bl 0x82812478
	ctx.lr = 0x828137EC;
	sub_82812478(ctx, base);
	// 828137EC: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 828137F0: C1A30004  lfs f13, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 828137F4: 807E00D8  lwz r3, 0xd8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(216 as u32) ) } as u64;
	// 828137F8: C00B9524  lfs f0, -0x6adc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828137FC: EFED0032  fmuls f31, f13, f0
	ctx.f[31].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82813800: 4BFE1BD1  bl 0x827f53d0
	ctx.lr = 0x82813804;
	sub_827F53D0(ctx, base);
	// 82813804: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813808: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8281380C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82813810: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82813814: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82813818: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281381C: 4E800421  bctrl
	ctx.lr = 0x82813820;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82813820: 13C018C7  vcmpequd (lvx128) v30, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82813824: 13E0E8C7  vcmpequd (lvx128) v31, v0, v29
	tmp.u32 = ctx.r[29].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828138E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828138E0 size=112
    let mut pc: u32 = 0x828138E0;
    'dispatch: loop {
        match pc {
            0x828138E0 => {
    //   block [0x828138E0..0x82813950)
	// 828138E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828138E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828138E8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828138EC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828138F0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828138F4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828138F8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828138FC: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82813900: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82813904: 4BFFFDBD  bl 0x828136c0
	ctx.lr = 0x82813908;
	sub_828136C0(ctx, base);
	// 82813908: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8281390C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82813910: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82813914: 4BAAC6ED  bl 0x822c0000
	ctx.lr = 0x82813918;
	sub_822C0000(ctx, base);
	// 82813918: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8281391C: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82813920: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813924: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82813928: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8281392C: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82813930: 419A0008  beq cr6, 0x82813938
	if ctx.cr[6].eq {
	pc = 0x82813938; continue 'dispatch;
	}
	// 82813934: 4BAACF5D  bl 0x822c0890
	ctx.lr = 0x82813938;
	sub_822C0890(ctx, base);
	// 82813938: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8281393C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813940: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813944: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82813948: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8281394C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813950(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813950 size=168
    let mut pc: u32 = 0x82813950;
    'dispatch: loop {
        match pc {
            0x82813950 => {
    //   block [0x82813950..0x828139F8)
	// 82813950: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813954: 48994819  bl 0x831a816c
	ctx.lr = 0x82813958;
	sub_831A8130(ctx, base);
	// 82813958: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281395C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813960: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82813964: 4BFD9EB5  bl 0x827ed818
	ctx.lr = 0x82813968;
	sub_827ED818(ctx, base);
	// 82813968: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8281396C: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82813970: 4BCFBB59  bl 0x8250f4c8
	ctx.lr = 0x82813974;
	sub_8250F4C8(ctx, base);
	// 82813974: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813978: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8281397C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82813980: 388BFFFC  addi r4, r11, -4
	ctx.r[4].s64 = ctx.r[11].s64 + -4;
	// 82813984: 409A0008  bne cr6, 0x8281398c
	if !ctx.cr[6].eq {
	pc = 0x8281398C; continue 'dispatch;
	}
	// 82813988: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8281398C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82813990: 4BCF6FC1  bl 0x8250a950
	ctx.lr = 0x82813994;
	sub_8250A950(ctx, base);
	// 82813994: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82813998: 485DE2F9  bl 0x82df1c90
	ctx.lr = 0x8281399C;
	sub_82DF1C90(ctx, base);
	// 8281399C: 83FE0124  lwz r31, 0x124(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(292 as u32) ) } as u64;
	// 828139A0: 4800003C  b 0x828139dc
	pc = 0x828139DC; continue 'dispatch;
	// 828139A4: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 828139A8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 828139AC: 386BFF40  addi r3, r11, -0xc0
	ctx.r[3].s64 = ctx.r[11].s64 + -192;
	// 828139B0: 409A0008  bne cr6, 0x828139b8
	if !ctx.cr[6].eq {
	pc = 0x828139B8; continue 'dispatch;
	}
	// 828139B4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 828139B8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 828139BC: 4BFC0045  bl 0x827d3a00
	ctx.lr = 0x828139C0;
	sub_827D3A00(ctx, base);
	// 828139C0: 93BF0000  stw r29, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 828139C4: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 828139C8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828139CC: 93BF0004  stw r29, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 828139D0: 419A0008  beq cr6, 0x828139d8
	if ctx.cr[6].eq {
	pc = 0x828139D8; continue 'dispatch;
	}
	// 828139D4: 4BAACEBD  bl 0x822c0890
	ctx.lr = 0x828139D8;
	sub_822C0890(ctx, base);
	// 828139D8: 3BFF0008  addi r31, r31, 8
	ctx.r[31].s64 = ctx.r[31].s64 + 8;
	// 828139DC: 817E0128  lwz r11, 0x128(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(296 as u32) ) } as u64;
	// 828139E0: 7F1F5840  cmplw cr6, r31, r11
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[11].u32, &mut ctx.xer);
	// 828139E4: 409AFFC0  bne cr6, 0x828139a4
	if !ctx.cr[6].eq {
	pc = 0x828139A4; continue 'dispatch;
	}
	// 828139E8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828139EC: 485DE2A5  bl 0x82df1c90
	ctx.lr = 0x828139F0;
	sub_82DF1C90(ctx, base);
	// 828139F0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 828139F4: 489947C8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828139F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828139F8 size=160
    let mut pc: u32 = 0x828139F8;
    'dispatch: loop {
        match pc {
            0x828139F8 => {
    //   block [0x828139F8..0x82813A98)
	// 828139F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828139FC: 48994765  bl 0x831a8160
	ctx.lr = 0x82813A00;
	sub_831A8130(ctx, base);
	// 82813A00: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813A04: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813A08: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 82813A0C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813A10: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82813A14: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82813A18: 935E0000  stw r26, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 82813A1C: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 82813A20: 935E0004  stw r26, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[26].u32 ) };
	// 82813A24: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82813A28: 388B9150  addi r4, r11, -0x6eb0
	ctx.r[4].s64 = ctx.r[11].s64 + -28336;
	// 82813A2C: 38A001A1  li r5, 0x1a1
	ctx.r[5].s64 = 417;
	// 82813A30: 38600060  li r3, 0x60
	ctx.r[3].s64 = 96;
	// 82813A34: 485DE9B5  bl 0x82df23e8
	ctx.lr = 0x82813A38;
	sub_82DF23E8(ctx, base);
	// 82813A38: 7C7F1B79  or. r31, r3, r3
	ctx.r[31].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82813A3C: 41820028  beq 0x82813a64
	if ctx.cr[0].eq {
	pc = 0x82813A64; continue 'dispatch;
	}
	// 82813A40: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82813A44: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82813A48: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813A4C: 4BADC1FD  bl 0x822efc48
	ctx.lr = 0x82813A50;
	sub_822EFC48(ctx, base);
	// 82813A50: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813A54: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82813A58: 396B911C  addi r11, r11, -0x6ee4
	ctx.r[11].s64 = ctx.r[11].s64 + -28388;
	// 82813A5C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813A60: 48000008  b 0x82813a68
	pc = 0x82813A68; continue 'dispatch;
	// 82813A64: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 82813A68: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813A6C: 4BFFFE75  bl 0x828138e0
	ctx.lr = 0x82813A70;
	sub_828138E0(ctx, base);
	// 82813A70: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813A74: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813A78: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82813A7C: 386BFF6C  addi r3, r11, -0x94
	ctx.r[3].s64 = ctx.r[11].s64 + -148;
	// 82813A80: 409A0008  bne cr6, 0x82813a88
	if !ctx.cr[6].eq {
	pc = 0x82813A88; continue 'dispatch;
	}
	// 82813A84: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 82813A88: 4BD14569  bl 0x82527ff0
	ctx.lr = 0x82813A8C;
	sub_82527FF0(ctx, base);
	// 82813A8C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813A90: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82813A94: 4899471C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813A98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813A98 size=184
    let mut pc: u32 = 0x82813A98;
    'dispatch: loop {
        match pc {
            0x82813A98 => {
    //   block [0x82813A98..0x82813B50)
	// 82813A98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813A9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82813AA0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82813AA4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82813AA8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813AAC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813AB0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82813AB4: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 82813AB8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82813ABC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813AC0: 4BAACE79  bl 0x822c0938
	ctx.lr = 0x82813AC4;
	sub_822C0938(ctx, base);
	// 82813AC4: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82813AC8: 41820028  beq 0x82813af0
	if ctx.cr[0].eq {
	pc = 0x82813AF0; continue 'dispatch;
	}
	// 82813ACC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813AD0: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 82813AD4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82813AD8: 392B90F4  addi r9, r11, -0x6f0c
	ctx.r[9].s64 = ctx.r[11].s64 + -28428;
	// 82813ADC: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82813AE0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82813AE4: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82813AE8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82813AEC: 48000008  b 0x82813af4
	pc = 0x82813AF4; continue 'dispatch;
	// 82813AF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82813AF4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813AF8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82813AFC: 409A0038  bne cr6, 0x82813b34
	if !ctx.cr[6].eq {
	pc = 0x82813B34; continue 'dispatch;
	}
	// 82813B00: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82813B04: 419A0010  beq cr6, 0x82813b14
	if ctx.cr[6].eq {
	pc = 0x82813B14; continue 'dispatch;
	}
	// 82813B08: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82813B0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813B10: 48277AB1  bl 0x82a8b5c0
	ctx.lr = 0x82813B14;
	sub_82A8B5C0(ctx, base);
	// 82813B14: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82813B18: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82813B1C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82813B20: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82813B24: 816BEF40  lwz r11, -0x10c0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4288 as u32) ) } as u64;
	// 82813B28: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82813B2C: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82813B30: 4BAAC4D1  bl 0x822c0000
	ctx.lr = 0x82813B34;
	sub_822C0000(ctx, base);
	// 82813B34: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813B38: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813B3C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813B40: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813B44: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82813B48: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813B4C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813B50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813B50 size=112
    let mut pc: u32 = 0x82813B50;
    'dispatch: loop {
        match pc {
            0x82813B50 => {
    //   block [0x82813B50..0x82813BC0)
	// 82813B50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813B54: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82813B58: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82813B5C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82813B60: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813B64: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82813B68: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82813B6C: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82813B70: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82813B74: 4BFFFF25  bl 0x82813a98
	ctx.lr = 0x82813B78;
	sub_82813A98(ctx, base);
	// 82813B78: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82813B7C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82813B80: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82813B84: 4BAAC47D  bl 0x822c0000
	ctx.lr = 0x82813B88;
	sub_822C0000(ctx, base);
	// 82813B88: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82813B8C: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82813B90: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813B94: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82813B98: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813B9C: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82813BA0: 419A0008  beq cr6, 0x82813ba8
	if ctx.cr[6].eq {
	pc = 0x82813BA8; continue 'dispatch;
	}
	// 82813BA4: 4BAACCED  bl 0x822c0890
	ctx.lr = 0x82813BA8;
	sub_822C0890(ctx, base);
	// 82813BA8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813BAC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82813BB0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82813BB4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82813BB8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82813BBC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813BC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813BC0 size=128
    let mut pc: u32 = 0x82813BC0;
    'dispatch: loop {
        match pc {
            0x82813BC0 => {
    //   block [0x82813BC0..0x82813C40)
	// 82813BC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813BC4: 489945A9  bl 0x831a816c
	ctx.lr = 0x82813BC8;
	sub_831A8130(ctx, base);
	// 82813BC8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813BCC: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 82813BD0: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 82813BD4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813BD8: 3BEBAE10  addi r31, r11, -0x51f0
	ctx.r[31].s64 = ctx.r[11].s64 + -20976;
	// 82813BDC: 816AAE18  lwz r11, -0x51e8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20968 as u32) ) } as u64;
	// 82813BE0: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82813BE4: 40820024  bne 0x82813c08
	if !ctx.cr[0].eq {
	pc = 0x82813C08; continue 'dispatch;
	}
	// 82813BE8: 3D208290  lis r9, -0x7d70
	ctx.r[9].s64 = -2104492032;
	// 82813BEC: 3D008281  lis r8, -0x7d7f
	ctx.r[8].s64 = -2105475072;
	// 82813BF0: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 82813BF4: 3929DD90  addi r9, r9, -0x2270
	ctx.r[9].s64 = ctx.r[9].s64 + -8816;
	// 82813BF8: 39083788  addi r8, r8, 0x3788
	ctx.r[8].s64 = ctx.r[8].s64 + 14216;
	// 82813BFC: 916AAE18  stw r11, -0x51e8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-20968 as u32), ctx.r[11].u32 ) };
	// 82813C00: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82813C04: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82813C08: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 82813C0C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82813C10: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813C14: 38DE0008  addi r6, r30, 8
	ctx.r[6].s64 = ctx.r[30].s64 + 8;
	// 82813C18: 9BAB0000  stb r29, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u8 ) };
	// 82813C1C: 88E10050  lbz r7, 0x50(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82813C20: 4BE409A1  bl 0x826545c0
	ctx.lr = 0x82813C24;
	sub_826545C0(ctx, base);
	// 82813C24: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82813C28: 4182000C  beq 0x82813c34
	if ctx.cr[0].eq {
	pc = 0x82813C34; continue 'dispatch;
	}
	// 82813C2C: 93FE0000  stw r31, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 82813C30: 48000008  b 0x82813c38
	pc = 0x82813C38; continue 'dispatch;
	// 82813C34: 93BE0000  stw r29, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 82813C38: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82813C3C: 48994580  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813C40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82813C40 size=208
    let mut pc: u32 = 0x82813C40;
    'dispatch: loop {
        match pc {
            0x82813C40 => {
    //   block [0x82813C40..0x82813D10)
	// 82813C40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813C44: 48994529  bl 0x831a816c
	ctx.lr = 0x82813C48;
	sub_831A8130(ctx, base);
	// 82813C48: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813C4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82813C50: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813C54: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82813C58: 396B91DC  addi r11, r11, -0x6e24
	ctx.r[11].s64 = ctx.r[11].s64 + -28196;
	// 82813C5C: 394A919C  addi r10, r10, -0x6e64
	ctx.r[10].s64 = ctx.r[10].s64 + -28260;
	// 82813C60: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813C64: 387F0178  addi r3, r31, 0x178
	ctx.r[3].s64 = ctx.r[31].s64 + 376;
	// 82813C68: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82813C6C: 3BBF0058  addi r29, r31, 0x58
	ctx.r[29].s64 = ctx.r[31].s64 + 88;
	// 82813C70: 4BC9D631  bl 0x824b12a0
	ctx.lr = 0x82813C74;
	sub_824B12A0(ctx, base);
	// 82813C74: 387F0124  addi r3, r31, 0x124
	ctx.r[3].s64 = ctx.r[31].s64 + 292;
	// 82813C78: 4BFE2909  bl 0x827f6580
	ctx.lr = 0x82813C7C;
	sub_827F6580(ctx, base);
	// 82813C7C: 387F0114  addi r3, r31, 0x114
	ctx.r[3].s64 = ctx.r[31].s64 + 276;
	// 82813C80: 4BC56381  bl 0x8246a000
	ctx.lr = 0x82813C84;
	sub_8246A000(ctx, base);
	// 82813C84: 807F0110  lwz r3, 0x110(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(272 as u32) ) } as u64;
	// 82813C88: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813C8C: 419A0008  beq cr6, 0x82813c94
	if ctx.cr[6].eq {
	pc = 0x82813C94; continue 'dispatch;
	}
	// 82813C90: 4BAD45D9  bl 0x822e8268
	ctx.lr = 0x82813C94;
	sub_822E8268(ctx, base);
	// 82813C94: 387F00E0  addi r3, r31, 0xe0
	ctx.r[3].s64 = ctx.r[31].s64 + 224;
	// 82813C98: 485DF791  bl 0x82df3428
	ctx.lr = 0x82813C9C;
	sub_82DF3428(ctx, base);
	// 82813C9C: 807F00DC  lwz r3, 0xdc(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(220 as u32) ) } as u64;
	// 82813CA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813CA4: 419A0008  beq cr6, 0x82813cac
	if ctx.cr[6].eq {
	pc = 0x82813CAC; continue 'dispatch;
	}
	// 82813CA8: 4BAACBE9  bl 0x822c0890
	ctx.lr = 0x82813CAC;
	sub_822C0890(ctx, base);
	// 82813CAC: 807F00D4  lwz r3, 0xd4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(212 as u32) ) } as u64;
	// 82813CB0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813CB4: 419A0008  beq cr6, 0x82813cbc
	if ctx.cr[6].eq {
	pc = 0x82813CBC; continue 'dispatch;
	}
	// 82813CB8: 4BAACBD9  bl 0x822c0890
	ctx.lr = 0x82813CBC;
	sub_822C0890(ctx, base);
	// 82813CBC: 807F00CC  lwz r3, 0xcc(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(204 as u32) ) } as u64;
	// 82813CC0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813CC4: 419A0008  beq cr6, 0x82813ccc
	if ctx.cr[6].eq {
	pc = 0x82813CCC; continue 'dispatch;
	}
	// 82813CC8: 4BAACBC9  bl 0x822c0890
	ctx.lr = 0x82813CCC;
	sub_822C0890(ctx, base);
	// 82813CCC: 83DF00C4  lwz r30, 0xc4(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 82813CD0: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82813CD4: 419A0014  beq cr6, 0x82813ce8
	if ctx.cr[6].eq {
	pc = 0x82813CE8; continue 'dispatch;
	}
	// 82813CD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813CDC: 4BC7D4ED  bl 0x824911c8
	ctx.lr = 0x82813CE0;
	sub_824911C8(ctx, base);
	// 82813CE0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82813CE4: 4BAAC585  bl 0x822c0268
	ctx.lr = 0x82813CE8;
	sub_822C0268(ctx, base);
	// 82813CE8: 807F00C0  lwz r3, 0xc0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 82813CEC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813CF0: 419A0008  beq cr6, 0x82813cf8
	if ctx.cr[6].eq {
	pc = 0x82813CF8; continue 'dispatch;
	}
	// 82813CF4: 4BAACB9D  bl 0x822c0890
	ctx.lr = 0x82813CF8;
	sub_822C0890(ctx, base);
	// 82813CF8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82813CFC: 4864888D  bl 0x82e5c588
	ctx.lr = 0x82813D00;
	sub_82E5C588(ctx, base);
	// 82813D00: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82813D04: 4BFFE9D5  bl 0x828126d8
	ctx.lr = 0x82813D08;
	sub_828126D8(ctx, base);
	// 82813D08: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82813D0C: 489944B0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813D10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813D10 size=184
    let mut pc: u32 = 0x82813D10;
    'dispatch: loop {
        match pc {
            0x82813D10 => {
    //   block [0x82813D10..0x82813DC8)
	// 82813D10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813D14: 48994459  bl 0x831a816c
	ctx.lr = 0x82813D18;
	sub_831A8130(ctx, base);
	// 82813D18: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813D1C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82813D20: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82813D24: 4BFFEB4D  bl 0x82812870
	ctx.lr = 0x82813D28;
	sub_82812870(ctx, base);
	// 82813D28: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813D2C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82813D30: 396B91DC  addi r11, r11, -0x6e24
	ctx.r[11].s64 = ctx.r[11].s64 + -28196;
	// 82813D34: 394A919C  addi r10, r10, -0x6e64
	ctx.r[10].s64 = ctx.r[10].s64 + -28260;
	// 82813D38: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82813D3C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82813D40: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82813D44: 387F00E0  addi r3, r31, 0xe0
	ctx.r[3].s64 = ctx.r[31].s64 + 224;
	// 82813D48: 93DF00BC  stw r30, 0xbc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(188 as u32), ctx.r[30].u32 ) };
	// 82813D4C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82813D50: 93DF00C0  stw r30, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[30].u32 ) };
	// 82813D54: 93DF00C4  stw r30, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[30].u32 ) };
	// 82813D58: 93DF00C8  stw r30, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[30].u32 ) };
	// 82813D5C: 93DF00CC  stw r30, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[30].u32 ) };
	// 82813D60: 93DF00D0  stw r30, 0xd0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[30].u32 ) };
	// 82813D64: 93DF00D4  stw r30, 0xd4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(212 as u32), ctx.r[30].u32 ) };
	// 82813D68: 93DF00D8  stw r30, 0xd8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(216 as u32), ctx.r[30].u32 ) };
	// 82813D6C: 93DF00DC  stw r30, 0xdc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(220 as u32), ctx.r[30].u32 ) };
	// 82813D70: 485DFE91  bl 0x82df3c00
	ctx.lr = 0x82813D74;
	sub_82DF3C00(ctx, base);
	// 82813D74: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82813D78: 394000F0  li r10, 0xf0
	ctx.r[10].s64 = 240;
	// 82813D7C: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 82813D80: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 82813D84: 39000100  li r8, 0x100
	ctx.r[8].s64 = 256;
	// 82813D88: 387F0124  addi r3, r31, 0x124
	ctx.r[3].s64 = ctx.r[31].s64 + 292;
	// 82813D8C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813DC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813DC8 size=164
    let mut pc: u32 = 0x82813DC8;
    'dispatch: loop {
        match pc {
            0x82813DC8 => {
    //   block [0x82813DC8..0x82813E6C)
	// 82813DC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813DCC: 4899439D  bl 0x831a8168
	ctx.lr = 0x82813DD0;
	sub_831A8130(ctx, base);
	// 82813DD0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813DD4: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 82813DD8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82813DDC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82813DE0: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82813DE4: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82813DE8: 808B677C  lwz r4, 0x677c(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(26492 as u32) ) } as u64;
	// 82813DEC: 4BAD1145  bl 0x822e4f30
	ctx.lr = 0x82813DF0;
	sub_822E4F30(ctx, base);
	// 82813DF0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82813DF4: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82813DF8: 4BAD10C9  bl 0x822e4ec0
	ctx.lr = 0x82813DFC;
	sub_822E4EC0(ctx, base);
	// 82813DFC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82813E00: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82813E04: E89C0000  ld r4, 0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	// 82813E08: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82813E0C: E8630000  ld r3, 0(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	// 82813E10: 4BC78479  bl 0x8248c288
	ctx.lr = 0x82813E14;
	sub_8248C288(ctx, base);
	// 82813E14: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82813E18: 813E00C4  lwz r9, 0xc4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(196 as u32) ) } as u64;
	// 82813E1C: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82813E20: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 82813E24: 3BC10070  addi r30, r1, 0x70
	ctx.r[30].s64 = ctx.r[1].s64 + 112;
	// 82813E28: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 82813E2C: 7FE7FB78  mr r7, r31
	ctx.r[7].u64 = ctx.r[31].u64;
	// 82813E30: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82813E34: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82813E38: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813E70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813E70 size=380
    let mut pc: u32 = 0x82813E70;
    'dispatch: loop {
        match pc {
            0x82813E70 => {
    //   block [0x82813E70..0x82813FEC)
	// 82813E70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813E74: 489942ED  bl 0x831a8160
	ctx.lr = 0x82813E78;
	sub_831A8130(ctx, base);
	// 82813E78: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 82813E7C: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82813E80: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82813E84: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82813E88: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 82813E8C: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82813E90: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 82813E94: 3BDF0100  addi r30, r31, 0x100
	ctx.r[30].s64 = ctx.r[31].s64 + 256;
	// 82813E98: 807F00D8  lwz r3, 0xd8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(216 as u32) ) } as u64;
	// 82813E9C: 4BFE1535  bl 0x827f53d0
	ctx.lr = 0x82813EA0;
	sub_827F53D0(ctx, base);
	// 82813EA0: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 82813EA4: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 82813EA8: 388B8614  addi r4, r11, -0x79ec
	ctx.r[4].s64 = ctx.r[11].s64 + -31212;
	// 82813EAC: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 82813EB0: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 82813EB4: 4BFF7FDD  bl 0x8280be90
	ctx.lr = 0x82813EB8;
	sub_8280BE90(ctx, base);
	// 82813EB8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82813EBC: 3861005C  addi r3, r1, 0x5c
	ctx.r[3].s64 = ctx.r[1].s64 + 92;
	// 82813EC0: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 82813EC4: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813EC8: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 82813ECC: 4BAB0595  bl 0x822c4460
	ctx.lr = 0x82813ED0;
	sub_822C4460(ctx, base);
	// 82813ED0: 8061006C  lwz r3, 0x6c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 82813ED4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813ED8: 419A0008  beq cr6, 0x82813ee0
	if ctx.cr[6].eq {
	pc = 0x82813EE0; continue 'dispatch;
	}
	// 82813EDC: 4BAAC9B5  bl 0x822c0890
	ctx.lr = 0x82813EE0;
	sub_822C0890(ctx, base);
	// 82813EE0: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82813EE4: 8361005C  lwz r27, 0x5c(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82813EE8: 83CB0000  lwz r30, 0(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813EEC: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82813EF0: 419A00D8  beq cr6, 0x82813fc8
	if ctx.cr[6].eq {
	pc = 0x82813FC8; continue 'dispatch;
	}
	// 82813EF4: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82813EF8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82813EFC: 3BAB9150  addi r29, r11, -0x6eb0
	ctx.r[29].s64 = ctx.r[11].s64 + -28336;
	// 82813F00: C3EA08A4  lfs f31, 0x8a4(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82813F04: 807E0008  lwz r3, 8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82813F08: 4BFC60C9  bl 0x827d9fd0
	ctx.lr = 0x82813F0C;
	sub_827D9FD0(ctx, base);
	// 82813F0C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82813F10: 418200A8  beq 0x82813fb8
	if ctx.cr[0].eq {
	pc = 0x82813FB8; continue 'dispatch;
	}
	// 82813F14: 487F50A5  bl 0x83008fb8
	ctx.lr = 0x82813F18;
	sub_83008FB8(ctx, base);
	// 82813F18: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82813F1C: 815F011C  lwz r10, 0x11c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(284 as u32) ) } as u64;
	// 82813F20: 817F0118  lwz r11, 0x118(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(280 as u32) ) } as u64;
	// 82813F24: 90C10050  stw r6, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[6].u32 ) };
	// 82813F28: 48000014  b 0x82813f3c
	pc = 0x82813F3C; continue 'dispatch;
	// 82813F2C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813F30: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 82813F34: 419A00B0  beq cr6, 0x82813fe4
	if ctx.cr[6].eq {
	pc = 0x82813FE4; continue 'dispatch;
	}
	// 82813F38: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82813F3C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82813F40: 4198FFEC  blt cr6, 0x82813f2c
	if ctx.cr[6].lt {
	pc = 0x82813F2C; continue 'dispatch;
	}
	// 82813F44: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82813F48: 556B063F  clrlwi. r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82813F4C: 4082006C  bne 0x82813fb8
	if !ctx.cr[0].eq {
	pc = 0x82813FB8; continue 'dispatch;
	}
	// 82813F50: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82813F54: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 82813F58: 93610064  stw r27, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[27].u32 ) };
	// 82813F5C: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82813F60: 419A0024  beq cr6, 0x82813f84
	if ctx.cr[6].eq {
	pc = 0x82813F84; continue 'dispatch;
	}
	// 82813F64: 397B0004  addi r11, r27, 4
	ctx.r[11].s64 = ctx.r[27].s64 + 4;
	// 82813F68: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82813F6C: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82813F70: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82813F74: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82813F78: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82813F7C: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82813F80: 4082FFE8  bne 0x82813f68
	if !ctx.cr[0].eq {
	pc = 0x82813F68; continue 'dispatch;
	}
	// 82813F84: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82813F88: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82813F8C: 38E10060  addi r7, r1, 0x60
	ctx.r[7].s64 = ctx.r[1].s64 + 96;
	// 82813F90: 38A0015B  li r5, 0x15b
	ctx.r[5].s64 = 347;
	// 82813F94: 387A0028  addi r3, r26, 0x28
	ctx.r[3].s64 = ctx.r[26].s64 + 40;
	// 82813F98: 48644AA9  bl 0x82e58a40
	ctx.lr = 0x82813F9C;
	sub_82E58A40(ctx, base);
	// 82813F9C: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 82813FA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82813FA4: 419A0008  beq cr6, 0x82813fac
	if ctx.cr[6].eq {
	pc = 0x82813FAC; continue 'dispatch;
	}
	// 82813FA8: 4BAAC8E9  bl 0x822c0890
	ctx.lr = 0x82813FAC;
	sub_822C0890(ctx, base);
	// 82813FAC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82813FB0: 387F0114  addi r3, r31, 0x114
	ctx.r[3].s64 = ctx.r[31].s64 + 276;
	// 82813FB4: 4BCA515D  bl 0x824b9110
	ctx.lr = 0x82813FB8;
	sub_824B9110(ctx, base);
	// 82813FB8: 83DE0000  lwz r30, 0(r30)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82813FBC: 817C0004  lwz r11, 4(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82813FC0: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82813FC4: 409AFF40  bne cr6, 0x82813f04
	if !ctx.cr[6].eq {
	pc = 0x82813F04; continue 'dispatch;
	}
	// 82813FC8: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 82813FCC: 419A000C  beq cr6, 0x82813fd8
	if ctx.cr[6].eq {
	pc = 0x82813FD8; continue 'dispatch;
	}
	// 82813FD0: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82813FD4: 4BAAC8BD  bl 0x822c0890
	ctx.lr = 0x82813FD8;
	sub_822C0890(ctx, base);
	// 82813FD8: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 82813FDC: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 82813FE0: 489941D0  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 82813FE4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82813FE8: 4BFFFF60  b 0x82813f48
	pc = 0x82813F48; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82813FF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82813FF0 size=1796
    let mut pc: u32 = 0x82813FF0;
    'dispatch: loop {
        match pc {
            0x82813FF0 => {
    //   block [0x82813FF0..0x828146F4)
	// 82813FF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82813FF4: 48994155  bl 0x831a8148
	ctx.lr = 0x82813FF8;
	sub_831A8130(ctx, base);
	// 82813FF8: DBE1FF90  stfd f31, -0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-112 as u32), ctx.f[31].u64 ) };
	// 82813FFC: 9421FE50  stwu r1, -0x1b0(r1)
	ea = ctx.r[1].u32.wrapping_add(-432 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814000: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82814004: 3A800000  li r20, 0
	ctx.r[20].s64 = 0;
	// 82814008: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 8281400C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814010: 39400098  li r10, 0x98
	ctx.r[10].s64 = 152;
	// 82814014: 7E9AA378  mr r26, r20
	ctx.r[26].u64 = ctx.r[20].u64;
	// 82814018: 3ABF0120  addi r21, r31, 0x120
	ctx.r[21].s64 = ctx.r[31].s64 + 288;
	// 8281401C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82814020: 93410058  stw r26, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[26].u32 ) };
	// 82814024: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828146F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828146F8 size=456
    let mut pc: u32 = 0x828146F8;
    'dispatch: loop {
        match pc {
            0x828146F8 => {
    //   block [0x828146F8..0x828148C0)
	// 828146F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828146FC: 48993A65  bl 0x831a8160
	ctx.lr = 0x82814700;
	sub_831A8130(ctx, base);
	// 82814700: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814704: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814708: D02100E4  stfs f1, 0xe4(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 8281470C: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82814710: 3BBFFFA8  addi r29, r31, -0x58
	ctx.r[29].s64 = ctx.r[31].s64 + -88;
	// 82814714: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82814718: 4BFFDD61  bl 0x82812478
	ctx.lr = 0x8281471C;
	sub_82812478(ctx, base);
	// 8281471C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82814720: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82814724: 4BC51DB5  bl 0x824664d8
	ctx.lr = 0x82814728;
	sub_824664D8(ctx, base);
	// 82814728: 817F0070  lwz r11, 0x70(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(112 as u32) ) } as u64;
	// 8281472C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82814730: 90610054  stw r3, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[3].u32 ) };
	// 82814734: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82814738: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 8281473C: 419A0054  beq cr6, 0x82814790
	if ctx.cr[6].eq {
	pc = 0x82814790; continue 'dispatch;
	}
	// 82814740: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82814744: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82814748: 83DF0078  lwz r30, 0x78(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) } as u64;
	// 8281474C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82814750: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82814754: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82814758: 4E800421  bctrl
	ctx.lr = 0x8281475C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8281475C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82814760: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82814764: 4BD76705  bl 0x8258ae68
	ctx.lr = 0x82814768;
	sub_8258AE68(ctx, base);
	// 82814768: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281476C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82814770: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82814774: 816B0014  lwz r11, 0x14(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82814778: 83DF0078  lwz r30, 0x78(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) } as u64;
	// 8281477C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82814780: 4E800421  bctrl
	ctx.lr = 0x82814784;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82814784: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82814788: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8281478C: 4BD76725  bl 0x8258aeb0
	ctx.lr = 0x82814790;
	sub_8258AEB0(ctx, base);
	// 82814790: 807F0078  lwz r3, 0x78(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) } as u64;
	// 82814794: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814798: 419A00E0  beq cr6, 0x82814878
	if ctx.cr[6].eq {
	pc = 0x82814878; continue 'dispatch;
	}
	// 8281479C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 828147A0: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 828147A4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828147A8: 4E800421  bctrl
	ctx.lr = 0x828147AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828147AC: 817F0078  lwz r11, 0x78(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) } as u64;
	// 828147B0: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 828147B4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 828147B8: 4BFE0C19  bl 0x827f53d0
	ctx.lr = 0x828147BC;
	sub_827F53D0(ctx, base);
	// 828147BC: 39600020  li r11, 0x20
	ctx.r[11].s64 = 32;
	// 828147C0: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 828147C4: 392100E4  addi r9, r1, 0xe4
	ctx.r[9].s64 = ctx.r[1].s64 + 228;
	// 828147C8: 394AEF50  addi r10, r10, -0x10b0
	ctx.r[10].s64 = ctx.r[10].s64 + -4272;
	// 828147CC: 3BDF0098  addi r30, r31, 0x98
	ctx.r[30].s64 = ctx.r[31].s64 + 152;
	// 828147D0: 13FC5C07  vcmpneb. (lvlx128) v31, v28, v11
	tmp.u32 = ctx.r[28].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828147D4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828148C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828148C0 size=8
    let mut pc: u32 = 0x828148C0;
    'dispatch: loop {
        match pc {
            0x828148C0 => {
    //   block [0x828148C0..0x828148C8)
	// 828148C0: 80630164  lwz r3, 0x164(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(356 as u32) ) } as u64;
	// 828148C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828148C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828148C8 size=164
    let mut pc: u32 = 0x828148C8;
    'dispatch: loop {
        match pc {
            0x828148C8 => {
    //   block [0x828148C8..0x8281496C)
	// 828148C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828148CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828148D0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828148D4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828148D8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828148DC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828148E0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828148E4: 817F010C  lwz r11, 0x10c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) } as u64;
	// 828148E8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 828148EC: 409A0034  bne cr6, 0x82814920
	if !ctx.cr[6].eq {
	pc = 0x82814920; continue 'dispatch;
	}
	// 828148F0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828148F4: 4BCFABD5  bl 0x8250f4c8
	ctx.lr = 0x828148F8;
	sub_8250F4C8(ctx, base);
	// 828148F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 828148FC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82814900: 386BFFFC  addi r3, r11, -4
	ctx.r[3].s64 = ctx.r[11].s64 + -4;
	// 82814904: 409A0008  bne cr6, 0x8281490c
	if !ctx.cr[6].eq {
	pc = 0x8281490C; continue 'dispatch;
	}
	// 82814908: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8281490C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82814910: 4BCF4109  bl 0x82508a18
	ctx.lr = 0x82814914;
	sub_82508A18(ctx, base);
	// 82814914: 907F010C  stw r3, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[3].u32 ) };
	// 82814918: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8281491C: 485DD375  bl 0x82df1c90
	ctx.lr = 0x82814920;
	sub_82DF1C90(ctx, base);
	// 82814920: 817F010C  lwz r11, 0x10c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(268 as u32) ) } as u64;
	// 82814924: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82814928: 419A002C  beq cr6, 0x82814954
	if ctx.cr[6].eq {
	pc = 0x82814954; continue 'dispatch;
	}
	// 8281492C: 817FFFA8  lwz r11, -0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-88 as u32) ) } as u64;
	// 82814930: 389FFFA8  addi r4, r31, -0x58
	ctx.r[4].s64 = ctx.r[31].s64 + -88;
	// 82814934: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82814938: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8281493C: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82814940: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82814944: 4E800421  bctrl
	ctx.lr = 0x82814948;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82814948: 39600118  li r11, 0x118
	ctx.r[11].s64 = 280;
	// 8281494C: 13E018C7  vcmpequd (lvx128) v31, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814970(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82814970 size=8
    let mut pc: u32 = 0x82814970;
    'dispatch: loop {
        match pc {
            0x82814970 => {
    //   block [0x82814970..0x82814978)
	// 82814970: 806300D4  lwz r3, 0xd4(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(212 as u32) ) } as u64;
	// 82814974: 4BFFE14C  b 0x82812ac0
	sub_82812AC0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82814978 size=8
    let mut pc: u32 = 0x82814978;
    'dispatch: loop {
        match pc {
            0x82814978 => {
    //   block [0x82814978..0x82814980)
	// 82814978: C02300B8  lfs f1, 0xb8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(184 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8281497C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814980(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82814980 size=72
    let mut pc: u32 = 0x82814980;
    'dispatch: loop {
        match pc {
            0x82814980 => {
    //   block [0x82814980..0x828149C8)
	// 82814980: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814984: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82814988: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8281498C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814990: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814994: 48647F95  bl 0x82e5c928
	ctx.lr = 0x82814998;
	sub_82E5C928(ctx, base);
	// 82814998: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8281499C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828149A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828149A4: 394A924C  addi r10, r10, -0x6db4
	ctx.r[10].s64 = ctx.r[10].s64 + -28084;
	// 828149A8: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828149AC: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 828149B0: D01F0060  stfs f0, 0x60(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 828149B4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 828149B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828149BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828149C0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828149C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828149C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828149C8 size=460
    let mut pc: u32 = 0x828149C8;
    'dispatch: loop {
        match pc {
            0x828149C8 => {
    //   block [0x828149C8..0x82814B94)
	// 828149C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828149CC: 48993799  bl 0x831a8164
	ctx.lr = 0x828149D0;
	sub_831A8130(ctx, base);
	// 828149D0: DBC1FFC0  stfd f30, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[30].u64 ) };
	// 828149D4: DBE1FFC8  stfd f31, -0x38(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 828149D8: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828149DC: 3D408336  lis r10, -0x7cca
	ctx.r[10].s64 = -2093613056;
	// 828149E0: FFC00890  fmr f30, f1
	ctx.f[30].f64 = ctx.f[1].f64;
	// 828149E4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828149E8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828149EC: 3BAB9240  addi r29, r11, -0x6dc0
	ctx.r[29].s64 = ctx.r[11].s64 + -28096;
	// 828149F0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828149F4: 816AAE20  lwz r11, -0x51e0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20960 as u32) ) } as u64;
	// 828149F8: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 828149FC: 3F808336  lis r28, -0x7cca
	ctx.r[28].s64 = -2093613056;
	// 82814A00: 556907FF  clrlwi. r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82814A04: 40820014  bne 0x82814a18
	if !ctx.cr[0].eq {
	pc = 0x82814A18; continue 'dispatch;
	}
	// 82814A08: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 82814A0C: C01D0004  lfs f0, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814A10: D01CAE1C  stfs f0, -0x51e4(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(-20964 as u32), tmp.u32 ) };
	// 82814A14: 916AAE20  stw r11, -0x51e0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-20960 as u32), ctx.r[11].u32 ) };
	// 82814A18: 807F00C4  lwz r3, 0xc4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 82814A1C: C01E0030  lfs f0, 0x30(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814A20: C1BE0034  lfs f13, 0x34(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82814A24: C19E0038  lfs f12, 0x38(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(56 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82814A28: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814A2C: C17E003C  lfs f11, 0x3c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(60 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82814A30: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82814A34: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82814A38: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82814A3C: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82814A40: 419A0028  beq cr6, 0x82814a68
	if ctx.cr[6].eq {
	pc = 0x82814A68; continue 'dispatch;
	}
	// 82814A44: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82814A48: 4BC7D531  bl 0x82491f78
	ctx.lr = 0x82814A4C;
	sub_82491F78(ctx, base);
	// 82814A4C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82814A50: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82814A54: 83DF00C4  lwz r30, 0xc4(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(196 as u32) ) } as u64;
	// 82814A58: 486683B1  bl 0x82e7ce08
	ctx.lr = 0x82814A5C;
	sub_82E7CE08(ctx, base);
	// 82814A5C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82814A60: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82814A64: 4BC7D51D  bl 0x82491f80
	ctx.lr = 0x82814A68;
	sub_82491F80(ctx, base);
	// 82814A68: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 82814A6C: 39400170  li r10, 0x170
	ctx.r[10].s64 = 368;
	// 82814A70: 3D20832B  lis r9, -0x7cd5
	ctx.r[9].s64 = -2094333952;
	// 82814A74: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 82814A78: 3CE08200  lis r7, -0x7e00
	ctx.r[7].s64 = -2113929216;
	// 82814A7C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82814A80: 13DF50C7  vcmpequd (lvx128) v30, v31, v10
	tmp.u32 = ctx.r[31].u32 + ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814B98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82814B98 size=84
    let mut pc: u32 = 0x82814B98;
    'dispatch: loop {
        match pc {
            0x82814B98 => {
    //   block [0x82814B98..0x82814BEC)
	// 82814B98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814B9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82814BA0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82814BA4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814BA8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814BAC: 4893FA55  bl 0x83154600
	ctx.lr = 0x82814BB0;
	sub_83154600(ctx, base);
	// 82814BB0: 7C641B79  or. r4, r3, r3
	ctx.r[4].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82814BB4: 41820018  beq 0x82814bcc
	if ctx.cr[0].eq {
	pc = 0x82814BCC; continue 'dispatch;
	}
	// 82814BB8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82814BBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82814BC0: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 82814BC4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82814BC8: 4E800421  bctrl
	ctx.lr = 0x82814BCC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82814BCC: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82814BD0: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814BD4: D01F0060  stfs f0, 0x60(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 82814BD8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82814BDC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82814BE0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82814BE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82814BE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814BF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82814BF0 size=220
    let mut pc: u32 = 0x82814BF0;
    'dispatch: loop {
        match pc {
            0x82814BF0 => {
    //   block [0x82814BF0..0x82814CCC)
	// 82814BF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814BF4: 48993579  bl 0x831a816c
	ctx.lr = 0x82814BF8;
	sub_831A8130(ctx, base);
	// 82814BF8: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814BFC: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82814C00: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82814C04: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 82814C08: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 82814C0C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82814C10: 91210050  stw r9, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u32 ) };
	// 82814C14: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82814C18: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82814C1C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82814C20: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814CD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82814CD0 size=248
    let mut pc: u32 = 0x82814CD0;
    'dispatch: loop {
        match pc {
            0x82814CD0 => {
    //   block [0x82814CD0..0x82814DC8)
	// 82814CD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814CD4: 48993481  bl 0x831a8154
	ctx.lr = 0x82814CD8;
	sub_831A8130(ctx, base);
	// 82814CD8: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 82814CDC: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814CE0: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 82814CE4: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 82814CE8: 7C972378  mr r23, r4
	ctx.r[23].u64 = ctx.r[4].u64;
	// 82814CEC: 83580004  lwz r26, 4(r24)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 82814CF0: 81780008  lwz r11, 8(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 82814CF4: 7F1A5840  cmplw cr6, r26, r11
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82814CF8: 419A00C4  beq cr6, 0x82814dbc
	if ctx.cr[6].eq {
	pc = 0x82814DBC; continue 'dispatch;
	}
	// 82814CFC: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 82814D00: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82814D04: 3D208336  lis r9, -0x7cca
	ctx.r[9].s64 = -2093613056;
	// 82814D08: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82814D0C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82814D10: C3E808A4  lfs f31, 0x8a4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82814D14: 3B6A9288  addi r27, r10, -0x6d78
	ctx.r[27].s64 = ctx.r[10].s64 + -28024;
	// 82814D18: 3BE98614  addi r31, r9, -0x79ec
	ctx.r[31].s64 = ctx.r[9].s64 + -31212;
	// 82814D1C: 3BCB6910  addi r30, r11, 0x6910
	ctx.r[30].s64 = ctx.r[11].s64 + 26896;
	// 82814D20: 807A0018  lwz r3, 0x18(r26)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(24 as u32) ) } as u64;
	// 82814D24: 4BFC52AD  bl 0x827d9fd0
	ctx.lr = 0x82814D28;
	sub_827D9FD0(ctx, base);
	// 82814D28: 7C7C1B79  or. r28, r3, r3
	ctx.r[28].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 82814D2C: 41820080  beq 0x82814dac
	if ctx.cr[0].eq {
	pc = 0x82814DAC; continue 'dispatch;
	}
	// 82814D30: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 82814D34: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 82814D38: 93A10054  stw r29, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[29].u32 ) };
	// 82814D3C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82814D40: 38B900F0  addi r5, r25, 0xf0
	ctx.r[5].s64 = ctx.r[25].s64 + 240;
	// 82814D44: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82814D48: 4BFF7149  bl 0x8280be90
	ctx.lr = 0x82814D4C;
	sub_8280BE90(ctx, base);
	// 82814D4C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82814D50: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82814D54: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 82814D58: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82814D5C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82814D60: 4BAAF701  bl 0x822c4460
	ctx.lr = 0x82814D64;
	sub_822C4460(ctx, base);
	// 82814D64: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82814D68: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814D6C: 419A0008  beq cr6, 0x82814d74
	if ctx.cr[6].eq {
	pc = 0x82814D74; continue 'dispatch;
	}
	// 82814D70: 4BAABB21  bl 0x822c0890
	ctx.lr = 0x82814D74;
	sub_822C0890(ctx, base);
	// 82814D74: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82814D78: 3B810050  addi r28, r1, 0x50
	ctx.r[28].s64 = ctx.r[1].s64 + 80;
	// 82814D7C: 487F423D  bl 0x83008fb8
	ctx.lr = 0x82814D80;
	sub_83008FB8(ctx, base);
	// 82814D80: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82814D84: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82814D88: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82814D8C: 38A0012F  li r5, 0x12f
	ctx.r[5].s64 = 303;
	// 82814D90: 38770028  addi r3, r23, 0x28
	ctx.r[3].s64 = ctx.r[23].s64 + 40;
	// 82814D94: 7F87E378  mr r7, r28
	ctx.r[7].u64 = ctx.r[28].u64;
	// 82814D98: 48643CA9  bl 0x82e58a40
	ctx.lr = 0x82814D9C;
	sub_82E58A40(ctx, base);
	// 82814D9C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82814DA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814DA4: 419A0008  beq cr6, 0x82814dac
	if ctx.cr[6].eq {
	pc = 0x82814DAC; continue 'dispatch;
	}
	// 82814DA8: 4BAABAE9  bl 0x822c0890
	ctx.lr = 0x82814DAC;
	sub_822C0890(ctx, base);
	// 82814DAC: 81780008  lwz r11, 8(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 82814DB0: 3B5A0028  addi r26, r26, 0x28
	ctx.r[26].s64 = ctx.r[26].s64 + 40;
	// 82814DB4: 7F1A5840  cmplw cr6, r26, r11
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82814DB8: 409AFF68  bne cr6, 0x82814d20
	if !ctx.cr[6].eq {
	pc = 0x82814D20; continue 'dispatch;
	}
	// 82814DBC: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 82814DC0: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 82814DC4: 489933E0  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814DC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82814DC8 size=120
    let mut pc: u32 = 0x82814DC8;
    'dispatch: loop {
        match pc {
            0x82814DC8 => {
    //   block [0x82814DC8..0x82814E40)
	// 82814DC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814DCC: 4899339D  bl 0x831a8168
	ctx.lr = 0x82814DD0;
	sub_831A8130(ctx, base);
	// 82814DD0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814DD4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814DD8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82814DDC: 3BBFFFA8  addi r29, r31, -0x58
	ctx.r[29].s64 = ctx.r[31].s64 + -88;
	// 82814DE0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82814DE4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82814DE8: 4BFFD699  bl 0x82812480
	ctx.lr = 0x82814DEC;
	sub_82812480(ctx, base);
	// 82814DEC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82814DF0: 40820008  bne 0x82814df8
	if !ctx.cr[0].eq {
	pc = 0x82814DF8; continue 'dispatch;
	}
	// 82814DF4: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82814DF8: 817F00FC  lwz r11, 0xfc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(252 as u32) ) } as u64;
	// 82814DFC: 38BF00F8  addi r5, r31, 0xf8
	ctx.r[5].s64 = ctx.r[31].s64 + 248;
	// 82814E00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82814E04: 419A0028  beq cr6, 0x82814e2c
	if ctx.cr[6].eq {
	pc = 0x82814E2C; continue 'dispatch;
	}
	// 82814E08: 81450008  lwz r10, 8(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 82814E0C: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 82814E10: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 82814E14: 7D6B4BD7  divw. r11, r11, r9
	ctx.r[11].s32 = ctx.r[11].s32 / ctx.r[9].s32;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82814E18: 41820014  beq 0x82814e2c
	if ctx.cr[0].eq {
	pc = 0x82814E2C; continue 'dispatch;
	}
	// 82814E1C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82814E20: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82814E24: 4BFFFEAD  bl 0x82814cd0
	ctx.lr = 0x82814E28;
	sub_82814CD0(ctx, base);
	// 82814E28: 63DE0002  ori r30, r30, 2
	ctx.r[30].u64 = ctx.r[30].u64 | 2;
	// 82814E2C: 7FCB0034  cntlzw r11, r30
	ctx.r[11].u64 = if ctx.r[30].u32 == 0 { 32 } else { ctx.r[30].u32.leading_zeros() as u64 };
	// 82814E30: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82814E34: 69630001  xori r3, r11, 1
	ctx.r[3].u64 = ctx.r[11].u64 ^ 1;
	// 82814E38: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82814E3C: 4899337C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814E40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82814E40 size=164
    let mut pc: u32 = 0x82814E40;
    'dispatch: loop {
        match pc {
            0x82814E40 => {
    //   block [0x82814E40..0x82814EE4)
	// 82814E40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814E44: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82814E48: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82814E4C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82814E50: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814E54: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814E58: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82814E5C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82814E60: 396B9310  addi r11, r11, -0x6cf0
	ctx.r[11].s64 = ctx.r[11].s64 + -27888;
	// 82814E64: 394A92D4  addi r10, r10, -0x6d2c
	ctx.r[10].s64 = ctx.r[10].s64 + -27948;
	// 82814E68: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82814E6C: 387F0168  addi r3, r31, 0x168
	ctx.r[3].s64 = ctx.r[31].s64 + 360;
	// 82814E70: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82814E74: 3BDF0058  addi r30, r31, 0x58
	ctx.r[30].s64 = ctx.r[31].s64 + 88;
	// 82814E78: 485DE5B1  bl 0x82df3428
	ctx.lr = 0x82814E7C;
	sub_82DF3428(ctx, base);
	// 82814E7C: 387F0150  addi r3, r31, 0x150
	ctx.r[3].s64 = ctx.r[31].s64 + 336;
	// 82814E80: 4BC55181  bl 0x8246a000
	ctx.lr = 0x82814E84;
	sub_8246A000(ctx, base);
	// 82814E84: 807F00D4  lwz r3, 0xd4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(212 as u32) ) } as u64;
	// 82814E88: 4BAAB3E1  bl 0x822c0268
	ctx.lr = 0x82814E8C;
	sub_822C0268(ctx, base);
	// 82814E8C: 807F00D0  lwz r3, 0xd0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 82814E90: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814E94: 419A0008  beq cr6, 0x82814e9c
	if ctx.cr[6].eq {
	pc = 0x82814E9C; continue 'dispatch;
	}
	// 82814E98: 4BAAB9F9  bl 0x822c0890
	ctx.lr = 0x82814E9C;
	sub_822C0890(ctx, base);
	// 82814E9C: 807F00C8  lwz r3, 0xc8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(200 as u32) ) } as u64;
	// 82814EA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814EA4: 419A0008  beq cr6, 0x82814eac
	if ctx.cr[6].eq {
	pc = 0x82814EAC; continue 'dispatch;
	}
	// 82814EA8: 4BAAB9E9  bl 0x822c0890
	ctx.lr = 0x82814EAC;
	sub_822C0890(ctx, base);
	// 82814EAC: 807F00C0  lwz r3, 0xc0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(192 as u32) ) } as u64;
	// 82814EB0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82814EB4: 419A0008  beq cr6, 0x82814ebc
	if ctx.cr[6].eq {
	pc = 0x82814EBC; continue 'dispatch;
	}
	// 82814EB8: 4BAAB9D9  bl 0x822c0890
	ctx.lr = 0x82814EBC;
	sub_822C0890(ctx, base);
	// 82814EBC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82814EC0: 486476C9  bl 0x82e5c588
	ctx.lr = 0x82814EC4;
	sub_82E5C588(ctx, base);
	// 82814EC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82814EC8: 4BFFD811  bl 0x828126d8
	ctx.lr = 0x82814ECC;
	sub_828126D8(ctx, base);
	// 82814ECC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82814ED0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82814ED4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82814ED8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82814EDC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82814EE0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814EE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82814EE8 size=8
    let mut pc: u32 = 0x82814EE8;
    'dispatch: loop {
        match pc {
            0x82814EE8 => {
    //   block [0x82814EE8..0x82814EF0)
	// 82814EE8: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 82814EEC: 48000004  b 0x82814ef0
	sub_82814EF0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814EF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82814EF0 size=76
    let mut pc: u32 = 0x82814EF0;
    'dispatch: loop {
        match pc {
            0x82814EF0 => {
    //   block [0x82814EF0..0x82814F3C)
	// 82814EF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814EF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82814EF8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82814EFC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82814F00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814F04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814F08: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82814F0C: 4BFFFF35  bl 0x82814e40
	ctx.lr = 0x82814F10;
	sub_82814E40(ctx, base);
	// 82814F10: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82814F14: 4182000C  beq 0x82814f20
	if ctx.cr[0].eq {
	pc = 0x82814F20; continue 'dispatch;
	}
	// 82814F18: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82814F1C: 485DD4BD  bl 0x82df23d8
	ctx.lr = 0x82814F20;
	sub_82DF23D8(ctx, base);
	// 82814F20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82814F24: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82814F28: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82814F2C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82814F30: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82814F34: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82814F38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82814F40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82814F40 size=340
    let mut pc: u32 = 0x82814F40;
    'dispatch: loop {
        match pc {
            0x82814F40 => {
    //   block [0x82814F40..0x82815094)
	// 82814F40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82814F44: 48993225  bl 0x831a8168
	ctx.lr = 0x82814F48;
	sub_831A8130(ctx, base);
	// 82814F48: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82814F4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82814F50: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82814F54: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82814F58: 4BFFD879  bl 0x828127d0
	ctx.lr = 0x82814F5C;
	sub_828127D0(ctx, base);
	// 82814F5C: 387F0058  addi r3, r31, 0x58
	ctx.r[3].s64 = ctx.r[31].s64 + 88;
	// 82814F60: 4BFFFA21  bl 0x82814980
	ctx.lr = 0x82814F64;
	sub_82814980(ctx, base);
	// 82814F64: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82814F68: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82814F6C: 396B9310  addi r11, r11, -0x6cf0
	ctx.r[11].s64 = ctx.r[11].s64 + -27888;
	// 82814F70: 394A92D4  addi r10, r10, -0x6d2c
	ctx.r[10].s64 = ctx.r[10].s64 + -27948;
	// 82814F74: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82814F78: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82814F7C: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82814F80: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82814F84: 93DF00BC  stw r30, 0xbc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(188 as u32), ctx.r[30].u32 ) };
	// 82814F88: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82814F8C: 93DF00C0  stw r30, 0xc0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(192 as u32), ctx.r[30].u32 ) };
	// 82814F90: 388B9288  addi r4, r11, -0x6d78
	ctx.r[4].s64 = ctx.r[11].s64 + -28024;
	// 82814F94: 93DF00C4  stw r30, 0xc4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[30].u32 ) };
	// 82814F98: 38A00045  li r5, 0x45
	ctx.r[5].s64 = 69;
	// 82814F9C: 93DF00C8  stw r30, 0xc8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(200 as u32), ctx.r[30].u32 ) };
	// 82814FA0: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 82814FA4: 93DF00CC  stw r30, 0xcc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(204 as u32), ctx.r[30].u32 ) };
	// 82814FA8: 93DF00D0  stw r30, 0xd0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(208 as u32), ctx.r[30].u32 ) };
	// 82814FAC: 4BAAB42D  bl 0x822c03d8
	ctx.lr = 0x82814FB0;
	sub_822C03D8(ctx, base);
	// 82814FB0: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82814FB4: 41820020  beq 0x82814fd4
	if ctx.cr[0].eq {
	pc = 0x82814FD4; continue 'dispatch;
	}
	// 82814FB8: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82814FBC: C03C0024  lfs f1, 0x24(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(36 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82814FC0: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 82814FC4: 38ABF150  addi r5, r11, -0xeb0
	ctx.r[5].s64 = ctx.r[11].s64 + -3760;
	// 82814FC8: 388AF140  addi r4, r10, -0xec0
	ctx.r[4].s64 = ctx.r[10].s64 + -3776;
	// 82814FCC: 4BFFD7CD  bl 0x82812798
	ctx.lr = 0x82814FD0;
	sub_82812798(ctx, base);
	// 82814FD0: 48000008  b 0x82814fd8
	pc = 0x82814FD8; continue 'dispatch;
	// 82814FD4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82814FD8: 907F00D4  stw r3, 0xd4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(212 as u32), ctx.r[3].u32 ) };
	// 82814FDC: C01D0000  lfs f0, 0(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814FE0: D01F00E0  stfs f0, 0xe0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 82814FE4: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 82814FE8: C01D0004  lfs f0, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814FEC: 391F00E0  addi r8, r31, 0xe0
	ctx.r[8].s64 = ctx.r[31].s64 + 224;
	// 82814FF0: D01F00E4  stfs f0, 0xe4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 82814FF4: 397D0020  addi r11, r29, 0x20
	ctx.r[11].s64 = ctx.r[29].s64 + 32;
	// 82814FF8: C01D0008  lfs f0, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82814FFC: 38C00020  li r6, 0x20
	ctx.r[6].s64 = 32;
	// 82815000: D01F00E8  stfs f0, 0xe8(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 82815004: 38E00030  li r7, 0x30
	ctx.r[7].s64 = 48;
	// 82815008: C01D000C  lfs f0, 0xc(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8281500C: 39480020  addi r10, r8, 0x20
	ctx.r[10].s64 = ctx.r[8].s64 + 32;
	// 82815010: D01F00EC  stfs f0, 0xec(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 82815014: 3CA08338  lis r5, -0x7cc8
	ctx.r[5].s64 = -2093481984;
	// 82815018: 13FD48C7  vcmpequd (lvx128) v31, v29, v9
	tmp.u32 = ctx.r[29].u32 + ctx.r[9].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8281501C: 3B856910  addi r28, r5, 0x6910
	ctx.r[28].s64 = ctx.r[5].s64 + 26896;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815098(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815098 size=712
    let mut pc: u32 = 0x82815098;
    'dispatch: loop {
        match pc {
            0x82815098 => {
    //   block [0x82815098..0x82815360)
	// 82815098: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281509C: 489930B1  bl 0x831a814c
	ctx.lr = 0x828150A0;
	sub_831A8130(ctx, base);
	// 828150A0: 9421FEB0  stwu r1, -0x150(r1)
	ea = ctx.r[1].u32.wrapping_add(-336 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828150A4: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 828150A8: 83CD0000  lwz r30, 0(r13)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 828150AC: 3BA00014  li r29, 0x14
	ctx.r[29].s64 = 20;
	// 828150B0: 93410050  stw r26, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[26].u32 ) };
	// 828150B4: 7C972378  mr r23, r4
	ctx.r[23].u64 = ctx.r[4].u64;
	// 828150B8: 38A00027  li r5, 0x27
	ctx.r[5].s64 = 39;
	// 828150BC: 38800060  li r4, 0x60
	ctx.r[4].s64 = 96;
	// 828150C0: 7C761B78  mr r22, r3
	ctx.r[22].u64 = ctx.r[3].u64;
	// 828150C4: 7C7DF02E  lwzx r3, r29, r30
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 828150C8: 4868B669  bl 0x82ea0730
	ctx.lr = 0x828150CC;
	sub_82EA0730(ctx, base);
	// 828150CC: 3D608206  lis r11, -0x7dfa
	ctx.r[11].s64 = -2113536000;
	// 828150D0: 3D408202  lis r10, -0x7dfe
	ctx.r[10].s64 = -2113798144;
	// 828150D4: 396BCD00  addi r11, r11, -0x3300
	ctx.r[11].s64 = ctx.r[11].s64 + -13056;
	// 828150D8: 394A5930  addi r10, r10, 0x5930
	ctx.r[10].s64 = ctx.r[10].s64 + 22832;
	// 828150DC: 39210080  addi r9, r1, 0x80
	ctx.r[9].s64 = ctx.r[1].s64 + 128;
	// 828150E0: 390100A0  addi r8, r1, 0xa0
	ctx.r[8].s64 = ctx.r[1].s64 + 160;
	// 828150E4: 38E00060  li r7, 0x60
	ctx.r[7].s64 = 96;
	// 828150E8: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828150EC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828150F0: 13C050C7  vcmpequd (lvx128) v30, v0, v10
	tmp.u32 = ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828150F4: B0E30004  sth r7, 4(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[7].u16 ) };
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815360(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815360 size=244
    let mut pc: u32 = 0x82815360;
    'dispatch: loop {
        match pc {
            0x82815360 => {
    //   block [0x82815360..0x82815454)
	// 82815360: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815364: 48992DFD  bl 0x831a8160
	ctx.lr = 0x82815368;
	sub_831A8130(ctx, base);
	// 82815368: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281536C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82815370: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82815374: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 82815378: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 8281537C: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82815380: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 82815384: 807D00CC  lwz r3, 0xcc(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(204 as u32) ) } as u64;
	// 82815388: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 8281538C: 13E0F0C7  vcmpequd (lvx128) v31, v0, v30
	tmp.u32 = ctx.r[30].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815390: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815458(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815458 size=392
    let mut pc: u32 = 0x82815458;
    'dispatch: loop {
        match pc {
            0x82815458 => {
    //   block [0x82815458..0x828155E0)
	// 82815458: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281545C: 48992D09  bl 0x831a8164
	ctx.lr = 0x82815460;
	sub_831A8130(ctx, base);
	// 82815460: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 82815464: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815468: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281546C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82815470: D3E100D4  stfs f31, 0xd4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 82815474: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82815478: 3B9FFFA8  addi r28, r31, -0x58
	ctx.r[28].s64 = ctx.r[31].s64 + -88;
	// 8281547C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82815480: 4BFFCFF9  bl 0x82812478
	ctx.lr = 0x82815484;
	sub_82812478(ctx, base);
	// 82815484: 817F006C  lwz r11, 0x6c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(108 as u32) ) } as u64;
	// 82815488: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8281548C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815490: 419A002C  beq cr6, 0x828154bc
	if ctx.cr[6].eq {
	pc = 0x828154BC; continue 'dispatch;
	}
	// 82815494: 807F0064  lwz r3, 0x64(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(100 as u32) ) } as u64;
	// 82815498: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281549C: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 828154A0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828154A4: 4E800421  bctrl
	ctx.lr = 0x828154A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828154A8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828154AC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 828154B0: 80BF0108  lwz r5, 0x108(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(264 as u32) ) } as u64;
	// 828154B4: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 828154B8: 4BFFF511  bl 0x828149c8
	ctx.lr = 0x828154BC;
	sub_828149C8(ctx, base);
	// 828154BC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 828154C0: 4BFFD021  bl 0x828124e0
	ctx.lr = 0x828154C4;
	sub_828124E0(ctx, base);
	// 828154C4: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 828154C8: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 828154CC: 409A005C  bne cr6, 0x82815528
	if !ctx.cr[6].eq {
	pc = 0x82815528; continue 'dispatch;
	}
	// 828154D0: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 828154D4: C01F0128  lfs f0, 0x128(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828154D8: 39400118  li r10, 0x118
	ctx.r[10].s64 = 280;
	// 828154DC: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 828154E0: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 828154E4: 811C0000  lwz r8, 0(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 828154E8: 38E10060  addi r7, r1, 0x60
	ctx.r[7].s64 = ctx.r[1].s64 + 96;
	// 828154EC: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 828154F0: 38BF0088  addi r5, r31, 0x88
	ctx.r[5].s64 = ctx.r[31].s64 + 136;
	// 828154F4: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828154F8: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 828154FC: 13FF50C7  vcmpequd (lvx128) v31, v31, v10
	tmp.u32 = ctx.r[31].u32 + ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815500: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82815504: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82815508: 8168000C  lwz r11, 0xc(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 8281550C: D0010058  stfs f0, 0x58(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82815510: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82815514: 13C048C7  vcmpequd (lvx128) v30, v0, v9
	tmp.u32 = ctx.r[9].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828155E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828155E0 size=20
    let mut pc: u32 = 0x828155E0;
    'dispatch: loop {
        match pc {
            0x828155E0 => {
    //   block [0x828155E0..0x828155F4)
	// 828155E0: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 828155E4: 90A30004  stw r5, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 828155E8: 90C30008  stw r6, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 828155EC: 90E3000C  stw r7, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 828155F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828155F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828155F8 size=8
    let mut pc: u32 = 0x828155F8;
    'dispatch: loop {
        match pc {
            0x828155F8 => {
    //   block [0x828155F8..0x82815600)
	// 828155F8: 90830154  stw r4, 0x154(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(340 as u32), ctx.r[4].u32 ) };
	// 828155FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815600(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82815600 size=12
    let mut pc: u32 = 0x82815600;
    'dispatch: loop {
        match pc {
            0x82815600 => {
    //   block [0x82815600..0x8281560C)
	// 82815600: 81630148  lwz r11, 0x148(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(328 as u32) ) } as u64;
	// 82815604: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815608: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8281560C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8281560C size=36
    let mut pc: u32 = 0x8281560C;
    'dispatch: loop {
        match pc {
            0x8281560C => {
    //   block [0x8281560C..0x82815630)
	// 8281560C: 81440000  lwz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815610: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82815614: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82815618: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8281561C: 81440008  lwz r10, 8(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82815620: 914B0008  stw r10, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82815624: 8144000C  lwz r10, 0xc(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82815628: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8281562C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82815630 size=16
    let mut pc: u32 = 0x82815630;
    'dispatch: loop {
        match pc {
            0x82815630 => {
    //   block [0x82815630..0x82815640)
	// 82815630: 39600160  li r11, 0x160
	ctx.r[11].s64 = 352;
	// 82815634: 13E458C7  vcmpequd (lvx128) v31, v4, v11
	tmp.u32 = ctx.r[4].u32 + ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815640 size=160
    let mut pc: u32 = 0x82815640;
    'dispatch: loop {
        match pc {
            0x82815640 => {
    //   block [0x82815640..0x828156E0)
	// 82815640: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815644: 48992B29  bl 0x831a816c
	ctx.lr = 0x82815648;
	sub_831A8130(ctx, base);
	// 82815648: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281564C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82815650: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82815654: 389E0058  addi r4, r30, 0x58
	ctx.r[4].s64 = ctx.r[30].s64 + 88;
	// 82815658: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8281565C: 4BCF9E6D  bl 0x8250f4c8
	ctx.lr = 0x82815660;
	sub_8250F4C8(ctx, base);
	// 82815660: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815664: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815668: 388BFFFC  addi r4, r11, -4
	ctx.r[4].s64 = ctx.r[11].s64 + -4;
	// 8281566C: 409A0008  bne cr6, 0x82815674
	if !ctx.cr[6].eq {
	pc = 0x82815674; continue 'dispatch;
	}
	// 82815670: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82815674: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815678: 4BCF52D9  bl 0x8250a950
	ctx.lr = 0x8281567C;
	sub_8250A950(ctx, base);
	// 8281567C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815680: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815684: 3BEBFF40  addi r31, r11, -0xc0
	ctx.r[31].s64 = ctx.r[11].s64 + -192;
	// 82815688: 409A0008  bne cr6, 0x82815690
	if !ctx.cr[6].eq {
	pc = 0x82815690; continue 'dispatch;
	}
	// 8281568C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82815690: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815694: 485DC5FD  bl 0x82df1c90
	ctx.lr = 0x82815698;
	sub_82DF1C90(ctx, base);
	// 82815698: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8281569C: 485DC5F5  bl 0x82df1c90
	ctx.lr = 0x828156A0;
	sub_82DF1C90(ctx, base);
	// 828156A0: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 828156A4: 419A0034  beq cr6, 0x828156d8
	if ctx.cr[6].eq {
	pc = 0x828156D8; continue 'dispatch;
	}
	// 828156A8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 828156AC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828156B0: 485DE359  bl 0x82df3a08
	ctx.lr = 0x828156B4;
	sub_82DF3A08(ctx, base);
	// 828156B4: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 828156B8: 38C00007  li r6, 7
	ctx.r[6].s64 = 7;
	// 828156BC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 828156C0: 389E01A0  addi r4, r30, 0x1a0
	ctx.r[4].s64 = ctx.r[30].s64 + 416;
	// 828156C4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828156C8: C02B08A8  lfs f1, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 828156CC: 4BFBF485  bl 0x827d4b50
	ctx.lr = 0x828156D0;
	sub_827D4B50(ctx, base);
	// 828156D0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828156D4: 485DDD55  bl 0x82df3428
	ctx.lr = 0x828156D8;
	sub_82DF3428(ctx, base);
	// 828156D8: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 828156DC: 48992AE0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828156E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828156E0 size=196
    let mut pc: u32 = 0x828156E0;
    'dispatch: loop {
        match pc {
            0x828156E0 => {
    //   block [0x828156E0..0x828157A4)
	// 828156E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828156E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828156E8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828156EC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828156F0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828156F4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 828156F8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 828156FC: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 82815700: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82815704: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82815708: 4BAAB231  bl 0x822c0938
	ctx.lr = 0x8281570C;
	sub_822C0938(ctx, base);
	// 8281570C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82815710: 41820028  beq 0x82815738
	if ctx.cr[0].eq {
	pc = 0x82815738; continue 'dispatch;
	}
	// 82815714: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82815718: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 8281571C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82815720: 392B9354  addi r9, r11, -0x6cac
	ctx.r[9].s64 = ctx.r[11].s64 + -27820;
	// 82815724: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82815728: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8281572C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82815730: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82815734: 48000008  b 0x8281573c
	pc = 0x8281573C; continue 'dispatch;
	// 82815738: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8281573C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82815740: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815744: 409A0044  bne cr6, 0x82815788
	if !ctx.cr[6].eq {
	pc = 0x82815788; continue 'dispatch;
	}
	// 82815748: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8281574C: 419A001C  beq cr6, 0x82815768
	if ctx.cr[6].eq {
	pc = 0x82815768; continue 'dispatch;
	}
	// 82815750: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815754: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82815758: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281575C: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815760: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82815764: 4E800421  bctrl
	ctx.lr = 0x82815768;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82815768: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 8281576C: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82815770: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82815774: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82815778: 816BF190  lwz r11, -0xe70(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3696 as u32) ) } as u64;
	// 8281577C: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82815780: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82815784: 4BAAA87D  bl 0x822c0000
	ctx.lr = 0x82815788;
	sub_822C0000(ctx, base);
	// 82815788: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8281578C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82815790: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82815794: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82815798: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8281579C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828157A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828157A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828157A8 size=196
    let mut pc: u32 = 0x828157A8;
    'dispatch: loop {
        match pc {
            0x828157A8 => {
    //   block [0x828157A8..0x8281586C)
	// 828157A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828157AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828157B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828157B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828157B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828157BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 828157C0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 828157C4: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 828157C8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 828157CC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828157D0: 4BAAB169  bl 0x822c0938
	ctx.lr = 0x828157D4;
	sub_822C0938(ctx, base);
	// 828157D4: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828157D8: 41820028  beq 0x82815800
	if ctx.cr[0].eq {
	pc = 0x82815800; continue 'dispatch;
	}
	// 828157DC: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828157E0: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 828157E4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 828157E8: 392B9368  addi r9, r11, -0x6c98
	ctx.r[9].s64 = ctx.r[11].s64 + -27800;
	// 828157EC: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 828157F0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 828157F4: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 828157F8: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 828157FC: 48000008  b 0x82815804
	pc = 0x82815804; continue 'dispatch;
	// 82815800: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82815804: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82815808: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8281580C: 409A0044  bne cr6, 0x82815850
	if !ctx.cr[6].eq {
	pc = 0x82815850; continue 'dispatch;
	}
	// 82815810: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82815814: 419A001C  beq cr6, 0x82815830
	if ctx.cr[6].eq {
	pc = 0x82815830; continue 'dispatch;
	}
	// 82815818: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281581C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82815820: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815824: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815828: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281582C: 4E800421  bctrl
	ctx.lr = 0x82815830;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82815830: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82815834: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82815838: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8281583C: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82815840: 816BF190  lwz r11, -0xe70(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3696 as u32) ) } as u64;
	// 82815844: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82815848: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8281584C: 4BAAA7B5  bl 0x822c0000
	ctx.lr = 0x82815850;
	sub_822C0000(ctx, base);
	// 82815850: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82815854: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82815858: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281585C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82815860: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82815864: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82815868: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82815870 size=236
    let mut pc: u32 = 0x82815870;
    'dispatch: loop {
        match pc {
            0x82815870 => {
    //   block [0x82815870..0x8281595C)
	// 82815870: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815874: 489928E1  bl 0x831a8154
	ctx.lr = 0x82815878;
	sub_831A8130(ctx, base);
	// 82815878: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281587C: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 82815880: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 82815884: 3BCBAE24  addi r30, r11, -0x51dc
	ctx.r[30].s64 = ctx.r[11].s64 + -20956;
	// 82815888: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281588C: 7C992378  mr r25, r4
	ctx.r[25].u64 = ctx.r[4].u64;
	// 82815890: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82815894: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 82815898: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 8281589C: 7FDCF378  mr r28, r30
	ctx.r[28].u64 = ctx.r[30].u64;
	// 828158A0: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 828158A4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828158A8: 485DE161  bl 0x82df3a08
	ctx.lr = 0x828158AC;
	sub_82DF3A08(ctx, base);
	// 828158AC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 828158B0: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 828158B4: 485DDA55  bl 0x82df3308
	ctx.lr = 0x828158B8;
	sub_82DF3308(ctx, base);
	// 828158B8: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 828158BC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828158C0: 485DDB69  bl 0x82df3428
	ctx.lr = 0x828158C4;
	sub_82DF3428(ctx, base);
	// 828158C4: 56EB063F  clrlwi. r11, r23, 0x18
	ctx.r[11].u64 = ctx.r[23].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828158C8: 40820028  bne 0x828158f0
	if !ctx.cr[0].eq {
	pc = 0x828158F0; continue 'dispatch;
	}
	// 828158CC: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 828158D0: 3B9C0008  addi r28, r28, 8
	ctx.r[28].s64 = ctx.r[28].s64 + 8;
	// 828158D4: 2B1D0002  cmplwi cr6, r29, 2
	ctx.cr[6].compare_u32(ctx.r[29].u32, 2 as u32, &mut ctx.xer);
	// 828158D8: 4198FFC8  blt cr6, 0x828158a0
	if ctx.cr[6].lt {
	pc = 0x828158A0; continue 'dispatch;
	}
	// 828158DC: 931F0000  stw r24, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 828158E0: 931F0004  stw r24, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 828158E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828158E8: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 828158EC: 489928B8  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 828158F0: 57AB1838  slwi r11, r29, 3
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 828158F4: 395E0004  addi r10, r30, 4
	ctx.r[10].s64 = ctx.r[30].s64 + 4;
	// 828158F8: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 828158FC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82815900: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815904: 7D6B502E  lwzx r11, r11, r10
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82815908: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281590C: 4E800421  bctrl
	ctx.lr = 0x82815910;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82815910: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815914: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82815918: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8281591C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815920: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82815924: 419A0024  beq cr6, 0x82815948
	if ctx.cr[6].eq {
	pc = 0x82815948; continue 'dispatch;
	}
	// 82815928: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8281592C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82815930: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815934: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82815938: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8281593C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82815940: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815944: 4082FFE8  bne 0x8281592c
	if !ctx.cr[0].eq {
	pc = 0x8281592C; continue 'dispatch;
	}
	// 82815948: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8281594C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815950: 419AFF94  beq cr6, 0x828158e4
	if ctx.cr[6].eq {
	pc = 0x828158E4; continue 'dispatch;
	}
	// 82815954: 4BAAAF3D  bl 0x822c0890
	ctx.lr = 0x82815958;
	sub_822C0890(ctx, base);
	// 82815958: 4BFFFF8C  b 0x828158e4
	pc = 0x828158E4; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815960(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82815960 size=184
    let mut pc: u32 = 0x82815960;
    'dispatch: loop {
        match pc {
            0x82815960 => {
    //   block [0x82815960..0x82815A18)
	// 82815960: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815964: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82815968: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8281596C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82815970: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815974: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82815978: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8281597C: 389F0058  addi r4, r31, 0x58
	ctx.r[4].s64 = ctx.r[31].s64 + 88;
	// 82815980: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815984: 4BCF9B45  bl 0x8250f4c8
	ctx.lr = 0x82815988;
	sub_8250F4C8(ctx, base);
	// 82815988: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281598C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815990: 388BFFFC  addi r4, r11, -4
	ctx.r[4].s64 = ctx.r[11].s64 + -4;
	// 82815994: 409A0008  bne cr6, 0x8281599c
	if !ctx.cr[6].eq {
	pc = 0x8281599C; continue 'dispatch;
	}
	// 82815998: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8281599C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 828159A0: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 828159A4: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 828159A8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 828159AC: 483314F5  bl 0x82b46ea0
	ctx.lr = 0x828159B0;
	sub_82B46EA0(ctx, base);
	// 828159B0: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 828159B4: 485DC2DD  bl 0x82df1c90
	ctx.lr = 0x828159B8;
	sub_82DF1C90(ctx, base);
	// 828159B8: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 828159BC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828159C0: 419A0030  beq cr6, 0x828159f0
	if ctx.cr[6].eq {
	pc = 0x828159F0; continue 'dispatch;
	}
	// 828159C4: 389F0190  addi r4, r31, 0x190
	ctx.r[4].s64 = ctx.r[31].s64 + 400;
	// 828159C8: 483311E1  bl 0x82b46ba8
	ctx.lr = 0x828159CC;
	sub_82B46BA8(ctx, base);
	// 828159CC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828159D0: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 828159D4: 48330EED  bl 0x82b468c0
	ctx.lr = 0x828159D8;
	sub_82B468C0(ctx, base);
	// 828159D8: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 828159DC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 828159E0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 828159E4: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 828159E8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828159EC: 4E800421  bctrl
	ctx.lr = 0x828159F0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828159F0: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 828159F4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828159F8: 419A0008  beq cr6, 0x82815a00
	if ctx.cr[6].eq {
	pc = 0x82815A00; continue 'dispatch;
	}
	// 828159FC: 4BAAAE95  bl 0x822c0890
	ctx.lr = 0x82815A00;
	sub_822C0890(ctx, base);
	// 82815A00: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82815A04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82815A08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82815A0C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82815A10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82815A14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82815A18 size=112
    let mut pc: u32 = 0x82815A18;
    'dispatch: loop {
        match pc {
            0x82815A18 => {
    //   block [0x82815A18..0x82815A88)
	// 82815A18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815A1C: 48992751  bl 0x831a816c
	ctx.lr = 0x82815A20;
	sub_831A8130(ctx, base);
	// 82815A20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815A24: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 82815A28: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82815A2C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82815A30: 388BA66C  addi r4, r11, -0x5994
	ctx.r[4].s64 = ctx.r[11].s64 + -22932;
	// 82815A34: 38A00073  li r5, 0x73
	ctx.r[5].s64 = 115;
	// 82815A38: 38600060  li r3, 0x60
	ctx.r[3].s64 = 96;
	// 82815A3C: 485DC9AD  bl 0x82df23e8
	ctx.lr = 0x82815A40;
	sub_82DF23E8(ctx, base);
	// 82815A40: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82815A44: 41820010  beq 0x82815a54
	if ctx.cr[0].eq {
	pc = 0x82815A54; continue 'dispatch;
	}
	// 82815A48: 4833D749  bl 0x82b53190
	ctx.lr = 0x82815A4C;
	sub_82B53190(ctx, base);
	// 82815A4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82815A50: 48000008  b 0x82815a58
	pc = 0x82815A58; continue 'dispatch;
	// 82815A54: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82815A58: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 82815A5C: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 82815A60: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82815A64: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82815A68: 4BFFFC79  bl 0x828156e0
	ctx.lr = 0x82815A6C;
	sub_828156E0(ctx, base);
	// 82815A6C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82815A70: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82815A74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82815A78: 4BAAA589  bl 0x822c0000
	ctx.lr = 0x82815A7C;
	sub_822C0000(ctx, base);
	// 82815A7C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82815A80: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82815A84: 48992738  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815A88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815A88 size=188
    let mut pc: u32 = 0x82815A88;
    'dispatch: loop {
        match pc {
            0x82815A88 => {
    //   block [0x82815A88..0x82815B44)
	// 82815A88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815A8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82815A90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82815A94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82815A98: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815A9C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82815AA0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82815AA4: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 82815AA8: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815AAC: 4BAF3F25  bl 0x823099d0
	ctx.lr = 0x82815AB0;
	sub_823099D0(ctx, base);
	// 82815AB0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815AB4: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82815AB8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82815ABC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815AC0: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82815AC4: 419A0024  beq cr6, 0x82815ae8
	if ctx.cr[6].eq {
	pc = 0x82815AE8; continue 'dispatch;
	}
	// 82815AC8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82815ACC: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82815AD0: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815AD4: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82815AD8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82815ADC: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82815AE0: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815AE4: 4082FFE8  bne 0x82815acc
	if !ctx.cr[0].eq {
	pc = 0x82815ACC; continue 'dispatch;
	}
	// 82815AE8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82815AEC: 80DF0150  lwz r6, 0x150(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(336 as u32) ) } as u64;
	// 82815AF0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82815AF4: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82815AF8: 388A9378  addi r4, r10, -0x6c88
	ctx.r[4].s64 = ctx.r[10].s64 + -27784;
	// 82815AFC: 38A000EC  li r5, 0xec
	ctx.r[5].s64 = 236;
	// 82815B00: 387E0028  addi r3, r30, 0x28
	ctx.r[3].s64 = ctx.r[30].s64 + 40;
	// 82815B04: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82815B08: 48642F39  bl 0x82e58a40
	ctx.lr = 0x82815B0C;
	sub_82E58A40(ctx, base);
	// 82815B0C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82815B10: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815B14: 419A0008  beq cr6, 0x82815b1c
	if ctx.cr[6].eq {
	pc = 0x82815B1C; continue 'dispatch;
	}
	// 82815B18: 4BAAAD79  bl 0x822c0890
	ctx.lr = 0x82815B1C;
	sub_822C0890(ctx, base);
	// 82815B1C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82815B20: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815B24: 419A0008  beq cr6, 0x82815b2c
	if ctx.cr[6].eq {
	pc = 0x82815B2C; continue 'dispatch;
	}
	// 82815B28: 4BAAAD69  bl 0x822c0890
	ctx.lr = 0x82815B2C;
	sub_822C0890(ctx, base);
	// 82815B2C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82815B30: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82815B34: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82815B38: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82815B3C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82815B40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815B48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815B48 size=204
    let mut pc: u32 = 0x82815B48;
    'dispatch: loop {
        match pc {
            0x82815B48 => {
    //   block [0x82815B48..0x82815C14)
	// 82815B48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815B4C: 48992621  bl 0x831a816c
	ctx.lr = 0x82815B50;
	sub_831A8130(ctx, base);
	// 82815B50: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815B54: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82815B58: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82815B5C: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 82815B60: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82815B64: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82815B68: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82815B6C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82815B70: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815C18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82815C18 size=108
    let mut pc: u32 = 0x82815C18;
    'dispatch: loop {
        match pc {
            0x82815C18 => {
    //   block [0x82815C18..0x82815C84)
	// 82815C18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815C1C: 48992551  bl 0x831a816c
	ctx.lr = 0x82815C20;
	sub_831A8130(ctx, base);
	// 82815C20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815C24: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82815C28: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82815C2C: 3BFE0050  addi r31, r30, 0x50
	ctx.r[31].s64 = ctx.r[30].s64 + 80;
	// 82815C30: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815C34: 485DDF75  bl 0x82df3ba8
	ctx.lr = 0x82815C38;
	sub_82DF3BA8(ctx, base);
	// 82815C38: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82815C3C: 40820018  bne 0x82815c54
	if !ctx.cr[0].eq {
	pc = 0x82815C54; continue 'dispatch;
	}
	// 82815C40: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815C44: 485DD56D  bl 0x82df31b0
	ctx.lr = 0x82815C48;
	sub_82DF31B0(ctx, base);
	// 82815C48: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82815C4C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82815C50: 4BFFF9F1  bl 0x82815640
	ctx.lr = 0x82815C54;
	sub_82815640(ctx, base);
	// 82815C54: 3BFE004C  addi r31, r30, 0x4c
	ctx.r[31].s64 = ctx.r[30].s64 + 76;
	// 82815C58: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815C5C: 485DDF4D  bl 0x82df3ba8
	ctx.lr = 0x82815C60;
	sub_82DF3BA8(ctx, base);
	// 82815C60: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82815C64: 40820018  bne 0x82815c7c
	if !ctx.cr[0].eq {
	pc = 0x82815C7C; continue 'dispatch;
	}
	// 82815C68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815C6C: 485DD545  bl 0x82df31b0
	ctx.lr = 0x82815C70;
	sub_82DF31B0(ctx, base);
	// 82815C70: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82815C74: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82815C78: 4BFFFCE9  bl 0x82815960
	ctx.lr = 0x82815C7C;
	sub_82815960(ctx, base);
	// 82815C7C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82815C80: 4899253C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815C88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82815C88 size=144
    let mut pc: u32 = 0x82815C88;
    'dispatch: loop {
        match pc {
            0x82815C88 => {
    //   block [0x82815C88..0x82815D18)
	// 82815C88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815C8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82815C90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82815C94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82815C98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815C9C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82815CA0: 3D408338  lis r10, -0x7cc8
	ctx.r[10].s64 = -2093481984;
	// 82815CA4: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82815CA8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82815CAC: 38CA6910  addi r6, r10, 0x6910
	ctx.r[6].s64 = ctx.r[10].s64 + 26896;
	// 82815CB0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82815CB4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82815CB8: 4BFF61D9  bl 0x8280be90
	ctx.lr = 0x82815CBC;
	sub_8280BE90(ctx, base);
	// 82815CBC: 817E0148  lwz r11, 0x148(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(328 as u32) ) } as u64;
	// 82815CC0: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815CC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815CC8: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82815CCC: 916A0020  stw r11, 0x20(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 82815CD0: 817E0148  lwz r11, 0x148(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(328 as u32) ) } as u64;
	// 82815CD4: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82815CD8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815CDC: 916A0060  stw r11, 0x60(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82815CE0: 817E0148  lwz r11, 0x148(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(328 as u32) ) } as u64;
	// 82815CE4: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815CE8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815CEC: 916A0018  stw r11, 0x18(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 82815CF0: 817E0148  lwz r11, 0x148(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(328 as u32) ) } as u64;
	// 82815CF4: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815CF8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82815CFC: 916A001C  stw r11, 0x1c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 82815D00: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82815D04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82815D08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82815D0C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82815D10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82815D14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815D18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815D18 size=256
    let mut pc: u32 = 0x82815D18;
    'dispatch: loop {
        match pc {
            0x82815D18 => {
    //   block [0x82815D18..0x82815E18)
	// 82815D18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815D1C: 48992441  bl 0x831a815c
	ctx.lr = 0x82815D20;
	sub_831A8130(ctx, base);
	// 82815D20: DBE1FFB8  stfd f31, -0x48(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[31].u64 ) };
	// 82815D24: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815D28: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82815D2C: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 82815D30: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 82815D34: 83DC0004  lwz r30, 4(r28)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82815D38: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 82815D3C: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82815D40: 419A00CC  beq cr6, 0x82815e0c
	if ctx.cr[6].eq {
	pc = 0x82815E0C; continue 'dispatch;
	}
	// 82815D44: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82815D48: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82815D4C: 3B6B9378  addi r27, r11, -0x6c88
	ctx.r[27].s64 = ctx.r[11].s64 + -27784;
	// 82815D50: C3EA08A4  lfs f31, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82815D54: 807E0018  lwz r3, 0x18(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 82815D58: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815D5C: 419A00A0  beq cr6, 0x82815dfc
	if ctx.cr[6].eq {
	pc = 0x82815DFC; continue 'dispatch;
	}
	// 82815D60: 4BFC4271  bl 0x827d9fd0
	ctx.lr = 0x82815D64;
	sub_827D9FD0(ctx, base);
	// 82815D64: 7C7F1B79  or. r31, r3, r3
	ctx.r[31].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82815D68: 41820094  beq 0x82815dfc
	if ctx.cr[0].eq {
	pc = 0x82815DFC; continue 'dispatch;
	}
	// 82815D6C: 38B90190  addi r5, r25, 0x190
	ctx.r[5].s64 = ctx.r[25].s64 + 400;
	// 82815D70: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 82815D74: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815D78: 4BFFFF11  bl 0x82815c88
	ctx.lr = 0x82815D7C;
	sub_82815C88(ctx, base);
	// 82815D7C: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82815D80: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82815D84: 83A1005C  lwz r29, 0x5c(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82815D88: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82815D8C: 93A10054  stw r29, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[29].u32 ) };
	// 82815D90: 419A0024  beq cr6, 0x82815db4
	if ctx.cr[6].eq {
	pc = 0x82815DB4; continue 'dispatch;
	}
	// 82815D94: 397D0004  addi r11, r29, 4
	ctx.r[11].s64 = ctx.r[29].s64 + 4;
	// 82815D98: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82815D9C: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815DA0: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82815DA4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82815DA8: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82815DAC: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815DB0: 4082FFE8  bne 0x82815d98
	if !ctx.cr[0].eq {
	pc = 0x82815D98; continue 'dispatch;
	}
	// 82815DB4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815DB8: 3BE10050  addi r31, r1, 0x50
	ctx.r[31].s64 = ctx.r[1].s64 + 80;
	// 82815DBC: 487F31FD  bl 0x83008fb8
	ctx.lr = 0x82815DC0;
	sub_83008FB8(ctx, base);
	// 82815DC0: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 82815DC4: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82815DC8: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82815DCC: 38A0015E  li r5, 0x15e
	ctx.r[5].s64 = 350;
	// 82815DD0: 387A0028  addi r3, r26, 0x28
	ctx.r[3].s64 = ctx.r[26].s64 + 40;
	// 82815DD4: 7FE7FB78  mr r7, r31
	ctx.r[7].u64 = ctx.r[31].u64;
	// 82815DD8: 48642C69  bl 0x82e58a40
	ctx.lr = 0x82815DDC;
	sub_82E58A40(ctx, base);
	// 82815DDC: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82815DE0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815DE4: 419A0008  beq cr6, 0x82815dec
	if ctx.cr[6].eq {
	pc = 0x82815DEC; continue 'dispatch;
	}
	// 82815DE8: 4BAAAAA9  bl 0x822c0890
	ctx.lr = 0x82815DEC;
	sub_822C0890(ctx, base);
	// 82815DEC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82815DF0: 419A000C  beq cr6, 0x82815dfc
	if ctx.cr[6].eq {
	pc = 0x82815DFC; continue 'dispatch;
	}
	// 82815DF4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82815DF8: 4BAAAA99  bl 0x822c0890
	ctx.lr = 0x82815DFC;
	sub_822C0890(ctx, base);
	// 82815DFC: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 82815E00: 3BDE0028  addi r30, r30, 0x28
	ctx.r[30].s64 = ctx.r[30].s64 + 40;
	// 82815E04: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82815E08: 409AFF4C  bne cr6, 0x82815d54
	if !ctx.cr[6].eq {
	pc = 0x82815D54; continue 'dispatch;
	}
	// 82815E0C: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 82815E10: CBE1FFB8  lfd f31, -0x48(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-72 as u32) ) };
	// 82815E14: 48992398  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815E18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815E18 size=260
    let mut pc: u32 = 0x82815E18;
    'dispatch: loop {
        match pc {
            0x82815E18 => {
    //   block [0x82815E18..0x82815F1C)
	// 82815E18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815E1C: 48992351  bl 0x831a816c
	ctx.lr = 0x82815E20;
	sub_831A8130(ctx, base);
	// 82815E20: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815E24: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82815E28: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 82815E2C: 396B6880  addi r11, r11, 0x6880
	ctx.r[11].s64 = ctx.r[11].s64 + 26752;
	// 82815E30: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 82815E34: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 82815E38: 38E10070  addi r7, r1, 0x70
	ctx.r[7].s64 = ctx.r[1].s64 + 112;
	// 82815E3C: 38C10080  addi r6, r1, 0x80
	ctx.r[6].s64 = ctx.r[1].s64 + 128;
	// 82815E40: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 82815E44: 13CA5C07  vcmpneb. (lvlx128) v30, v10, v11
	tmp.u32 = ctx.r[10].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815E48: 3BC100A0  addi r30, r1, 0xa0
	ctx.r[30].s64 = ctx.r[1].s64 + 160;
	// 82815E4C: 13E05C07  vcmpneb. (lvlx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815E50: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82815E54: 13A95C07  vcmpneb. (lvlx128) v29, v9, v11
	tmp.u32 = ctx.r[9].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815E58: 13885C07  vcmpneb. (lvlx128) v28, v8, v11
	tmp.u32 = ctx.r[8].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[60] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82815E5C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82815F20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82815F20 size=264
    let mut pc: u32 = 0x82815F20;
    'dispatch: loop {
        match pc {
            0x82815F20 => {
    //   block [0x82815F20..0x82816028)
	// 82815F20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82815F24: 48992249  bl 0x831a816c
	ctx.lr = 0x82815F28;
	sub_831A8130(ctx, base);
	// 82815F28: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82815F2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82815F30: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82815F34: 4BFFC54D  bl 0x82812480
	ctx.lr = 0x82815F38;
	sub_82812480(ctx, base);
	// 82815F38: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82815F3C: 40820008  bne 0x82815f44
	if !ctx.cr[0].eq {
	pc = 0x82815F44; continue 'dispatch;
	}
	// 82815F40: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 82815F44: 817F01E4  lwz r11, 0x1e4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(484 as u32) ) } as u64;
	// 82815F48: 3BDF01E0  addi r30, r31, 0x1e0
	ctx.r[30].s64 = ctx.r[31].s64 + 480;
	// 82815F4C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815F50: 419A00C4  beq cr6, 0x82816014
	if ctx.cr[6].eq {
	pc = 0x82816014; continue 'dispatch;
	}
	// 82815F54: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82815F58: 39200028  li r9, 0x28
	ctx.r[9].s64 = 40;
	// 82815F5C: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 82815F60: 7D6B4BD7  divw. r11, r11, r9
	ctx.r[11].s32 = ctx.r[11].s32 / ctx.r[9].s32;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82815F64: 418200B0  beq 0x82816014
	if ctx.cr[0].eq {
	pc = 0x82816014; continue 'dispatch;
	}
	// 82815F68: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82815F6C: 4BFFFAAD  bl 0x82815a18
	ctx.lr = 0x82815F70;
	sub_82815A18(ctx, base);
	// 82815F70: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82815F74: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82815F78: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82815F7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82815F80: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82815F84: 419A0024  beq cr6, 0x82815fa8
	if ctx.cr[6].eq {
	pc = 0x82815FA8; continue 'dispatch;
	}
	// 82815F88: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82815F8C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82815F90: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815F94: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82815F98: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82815F9C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82815FA0: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82815FA4: 4082FFE8  bne 0x82815f8c
	if !ctx.cr[0].eq {
	pc = 0x82815F8C; continue 'dispatch;
	}
	// 82815FA8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82815FAC: 80DF0150  lwz r6, 0x150(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(336 as u32) ) } as u64;
	// 82815FB0: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82815FB4: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82815FB8: 388A9378  addi r4, r10, -0x6c88
	ctx.r[4].s64 = ctx.r[10].s64 + -27784;
	// 82815FBC: 38A0010F  li r5, 0x10f
	ctx.r[5].s64 = 271;
	// 82815FC0: 387F0080  addi r3, r31, 0x80
	ctx.r[3].s64 = ctx.r[31].s64 + 128;
	// 82815FC4: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82815FC8: 48642A79  bl 0x82e58a40
	ctx.lr = 0x82815FCC;
	sub_82E58A40(ctx, base);
	// 82815FCC: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82815FD0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815FD4: 419A0008  beq cr6, 0x82815fdc
	if ctx.cr[6].eq {
	pc = 0x82815FDC; continue 'dispatch;
	}
	// 82815FD8: 4BAAA8B9  bl 0x822c0890
	ctx.lr = 0x82815FDC;
	sub_822C0890(ctx, base);
	// 82815FDC: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82815FE0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82815FE4: 419A0008  beq cr6, 0x82815fec
	if ctx.cr[6].eq {
	pc = 0x82815FEC; continue 'dispatch;
	}
	// 82815FE8: 4BAAA8A9  bl 0x822c0890
	ctx.lr = 0x82815FEC;
	sub_822C0890(ctx, base);
	// 82815FEC: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82815FF0: 389F0058  addi r4, r31, 0x58
	ctx.r[4].s64 = ctx.r[31].s64 + 88;
	// 82815FF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82815FF8: 4BFFFD21  bl 0x82815d18
	ctx.lr = 0x82815FFC;
	sub_82815D18(ctx, base);
	// 82815FFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816000: 4BFFC479  bl 0x82812478
	ctx.lr = 0x82816004;
	sub_82812478(ctx, base);
	// 82816004: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82816008: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281600C: 4BFFFC0D  bl 0x82815c18
	ctx.lr = 0x82816010;
	sub_82815C18(ctx, base);
	// 82816010: 63BD0002  ori r29, r29, 2
	ctx.r[29].u64 = ctx.r[29].u64 | 2;
	// 82816014: 7FAB0034  cntlzw r11, r29
	ctx.r[11].u64 = if ctx.r[29].u32 == 0 { 32 } else { ctx.r[29].u32.leading_zeros() as u64 };
	// 82816018: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8281601C: 69630001  xori r3, r11, 1
	ctx.r[3].u64 = ctx.r[11].u64 ^ 1;
	// 82816020: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82816024: 48992198  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816028(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816028 size=144
    let mut pc: u32 = 0x82816028;
    'dispatch: loop {
        match pc {
            0x82816028 => {
    //   block [0x82816028..0x828160B8)
	// 82816028: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281602C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816030: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82816034: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816038: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281603C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816040: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816044: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82816048: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 8281604C: 396B9400  addi r11, r11, -0x6c00
	ctx.r[11].s64 = ctx.r[11].s64 + -27648;
	// 82816050: 394A93D4  addi r10, r10, -0x6c2c
	ctx.r[10].s64 = ctx.r[10].s64 + -27692;
	// 82816054: 392993C0  addi r9, r9, -0x6c40
	ctx.r[9].s64 = ctx.r[9].s64 + -27712;
	// 82816058: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8281605C: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82816060: 387F01E0  addi r3, r31, 0x1e0
	ctx.r[3].s64 = ctx.r[31].s64 + 480;
	// 82816064: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 82816068: 3BDF0058  addi r30, r31, 0x58
	ctx.r[30].s64 = ctx.r[31].s64 + 88;
	// 8281606C: 4BC53F95  bl 0x8246a000
	ctx.lr = 0x82816070;
	sub_8246A000(ctx, base);
	// 82816070: 807F014C  lwz r3, 0x14c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(332 as u32) ) } as u64;
	// 82816074: 4BAAA1F5  bl 0x822c0268
	ctx.lr = 0x82816078;
	sub_822C0268(ctx, base);
	// 82816078: 807F0148  lwz r3, 0x148(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 8281607C: 4BAAA1ED  bl 0x822c0268
	ctx.lr = 0x82816080;
	sub_822C0268(ctx, base);
	// 82816080: 807F0144  lwz r3, 0x144(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 82816084: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816088: 419A0008  beq cr6, 0x82816090
	if ctx.cr[6].eq {
	pc = 0x82816090; continue 'dispatch;
	}
	// 8281608C: 4BAAA805  bl 0x822c0890
	ctx.lr = 0x82816090;
	sub_822C0890(ctx, base);
	// 82816090: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816094: 4BCFB105  bl 0x82511198
	ctx.lr = 0x82816098;
	sub_82511198(ctx, base);
	// 82816098: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281609C: 4BFFC63D  bl 0x828126d8
	ctx.lr = 0x828160A0;
	sub_828126D8(ctx, base);
	// 828160A0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828160A4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828160A8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828160AC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 828160B0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828160B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828160B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828160B8 size=8
    let mut pc: u32 = 0x828160B8;
    'dispatch: loop {
        match pc {
            0x828160B8 => {
    //   block [0x828160B8..0x828160C0)
	// 828160B8: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 828160BC: 48000044  b 0x82816100
	sub_82816100(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828160C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828160C0 size=8
    let mut pc: u32 = 0x828160C0;
    'dispatch: loop {
        match pc {
            0x828160C0 => {
    //   block [0x828160C0..0x828160C8)
	// 828160C0: 3863FF80  addi r3, r3, -0x80
	ctx.r[3].s64 = ctx.r[3].s64 + -128;
	// 828160C4: 4800003C  b 0x82816100
	sub_82816100(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828160C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828160C8 size=40
    let mut pc: u32 = 0x828160C8;
    'dispatch: loop {
        match pc {
            0x828160C8 => {
    //   block [0x828160C8..0x828160F0)
	// 828160C8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828160CC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828160D0: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 828160D4: 396B9460  addi r11, r11, -0x6ba0
	ctx.r[11].s64 = ctx.r[11].s64 + -27552;
	// 828160D8: 394A9434  addi r10, r10, -0x6bcc
	ctx.r[10].s64 = ctx.r[10].s64 + -27596;
	// 828160DC: 39299420  addi r9, r9, -0x6be0
	ctx.r[9].s64 = ctx.r[9].s64 + -27616;
	// 828160E0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828160E4: 91430058  stw r10, 0x58(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 828160E8: 91230080  stw r9, 0x80(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 828160EC: 4BFFFF3C  b 0x82816028
	sub_82816028(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828160F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828160F0 size=8
    let mut pc: u32 = 0x828160F0;
    'dispatch: loop {
        match pc {
            0x828160F0 => {
    //   block [0x828160F0..0x828160F8)
	// 828160F0: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 828160F4: 480001DC  b 0x828162d0
	sub_828162D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828160F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828160F8 size=8
    let mut pc: u32 = 0x828160F8;
    'dispatch: loop {
        match pc {
            0x828160F8 => {
    //   block [0x828160F8..0x82816100)
	// 828160F8: 3863FF80  addi r3, r3, -0x80
	ctx.r[3].s64 = ctx.r[3].s64 + -128;
	// 828160FC: 480001D4  b 0x828162d0
	sub_828162D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816100(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816100 size=76
    let mut pc: u32 = 0x82816100;
    'dispatch: loop {
        match pc {
            0x82816100 => {
    //   block [0x82816100..0x8281614C)
	// 82816100: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816104: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816108: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8281610C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816110: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816114: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816118: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8281611C: 4BFFFF0D  bl 0x82816028
	ctx.lr = 0x82816120;
	sub_82816028(ctx, base);
	// 82816120: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82816124: 4182000C  beq 0x82816130
	if ctx.cr[0].eq {
	pc = 0x82816130; continue 'dispatch;
	}
	// 82816128: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8281612C: 485DC2AD  bl 0x82df23d8
	ctx.lr = 0x82816130;
	sub_82DF23D8(ctx, base);
	// 82816130: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816134: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816138: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281613C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816140: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816144: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82816148: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816150(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816150 size=380
    let mut pc: u32 = 0x82816150;
    'dispatch: loop {
        match pc {
            0x82816150 => {
    //   block [0x82816150..0x828162CC)
	// 82816150: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816154: 48992009  bl 0x831a815c
	ctx.lr = 0x82816158;
	sub_831A8130(ctx, base);
	// 82816158: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281615C: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 82816160: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816164: 93410050  stw r26, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[26].u32 ) };
	// 82816168: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8281616C: 3B7FFFA8  addi r27, r31, -0x58
	ctx.r[27].s64 = ctx.r[31].s64 + -88;
	// 82816170: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82816174: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82816178: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 8281617C: 4BFFC2FD  bl 0x82812478
	ctx.lr = 0x82816180;
	sub_82812478(ctx, base);
	// 82816180: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82816184: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82816188: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8281618C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82816190: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816194: 4BFFC55D  bl 0x828126f0
	ctx.lr = 0x82816198;
	sub_828126F0(ctx, base);
	// 82816198: 387E0038  addi r3, r30, 0x38
	ctx.r[3].s64 = ctx.r[30].s64 + 56;
	// 8281619C: 3B3F0128  addi r25, r31, 0x128
	ctx.r[25].s64 = ctx.r[31].s64 + 296;
	// 828161A0: 485DD011  bl 0x82df31b0
	ctx.lr = 0x828161A4;
	sub_82DF31B0(ctx, base);
	// 828161A4: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828161A8: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 828161AC: 7F25CB78  mr r5, r25
	ctx.r[5].u64 = ctx.r[25].u64;
	// 828161B0: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 828161B4: 4BFFF6BD  bl 0x82815870
	ctx.lr = 0x828161B8;
	sub_82815870(ctx, base);
	// 828161B8: 83C10058  lwz r30, 0x58(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 828161BC: 8321005C  lwz r25, 0x5c(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 828161C0: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 828161C4: 419A00F0  beq cr6, 0x828162b4
	if ctx.cr[6].eq {
	pc = 0x828162B4; continue 'dispatch;
	}
	// 828161C8: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 828161CC: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 828161D0: 93210054  stw r25, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[25].u32 ) };
	// 828161D4: 419A0024  beq cr6, 0x828161f8
	if ctx.cr[6].eq {
	pc = 0x828161F8; continue 'dispatch;
	}
	// 828161D8: 39790004  addi r11, r25, 4
	ctx.r[11].s64 = ctx.r[25].s64 + 4;
	// 828161DC: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 828161E0: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 828161E4: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 828161E8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 828161EC: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 828161F0: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 828161F4: 4082FFE8  bne 0x828161dc
	if !ctx.cr[0].eq {
	pc = 0x828161DC; continue 'dispatch;
	}
	// 828161F8: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 828161FC: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82816200: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82816204: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82816208: 4BFFCB51  bl 0x82812d58
	ctx.lr = 0x8281620C;
	sub_82812D58(ctx, base);
	// 8281620C: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82816210: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816214: 419A0008  beq cr6, 0x8281621c
	if ctx.cr[6].eq {
	pc = 0x8281621C; continue 'dispatch;
	}
	// 82816218: 4BAAA679  bl 0x822c0890
	ctx.lr = 0x8281621C;
	sub_822C0890(ctx, base);
	// 8281621C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82816220: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816224: 816B003C  lwz r11, 0x3c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 82816228: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8281622C: 4E800421  bctrl
	ctx.lr = 0x82816230;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82816230: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816234: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82816238: 388B9378  addi r4, r11, -0x6c88
	ctx.r[4].s64 = ctx.r[11].s64 + -27784;
	// 8281623C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82816240: 38A0008E  li r5, 0x8e
	ctx.r[5].s64 = 142;
	// 82816244: 38600008  li r3, 8
	ctx.r[3].s64 = 8;
	// 82816248: 4BAAA191  bl 0x822c03d8
	ctx.lr = 0x8281624C;
	sub_822C03D8(ctx, base);
	// 8281624C: 7C7D1B79  or. r29, r3, r3
	ctx.r[29].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82816250: 4182003C  beq 0x8281628c
	if ctx.cr[0].eq {
	pc = 0x8281628C; continue 'dispatch;
	}
	// 82816254: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816258: 3B400001  li r26, 1
	ctx.r[26].s64 = 1;
	// 8281625C: 4BFE30FD  bl 0x827f9358
	ctx.lr = 0x82816260;
	sub_827F9358(ctx, base);
	// 82816260: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 82816264: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82816268: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 8281626C: 4BCF92AD  bl 0x8250f518
	ctx.lr = 0x82816270;
	sub_8250F518(ctx, base);
	// 82816270: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82816274: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82816278: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 8281627C: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 82816280: 4BC7BF71  bl 0x824921f0
	ctx.lr = 0x82816284;
	sub_824921F0(ctx, base);
	// 82816284: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82816288: 48000008  b 0x82816290
	pc = 0x82816290; continue 'dispatch;
	// 8281628C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82816290: 387F00E8  addi r3, r31, 0xe8
	ctx.r[3].s64 = ctx.r[31].s64 + 232;
	// 82816294: 4BACEB55  bl 0x822e4de8
	ctx.lr = 0x82816298;
	sub_822E4DE8(ctx, base);
	// 82816298: 574B07FF  clrlwi. r11, r26, 0x1f
	ctx.r[11].u64 = ctx.r[26].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281629C: 4182000C  beq 0x828162a8
	if ctx.cr[0].eq {
	pc = 0x828162A8; continue 'dispatch;
	}
	// 828162A0: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 828162A4: 485DB9ED  bl 0x82df1c90
	ctx.lr = 0x828162A8;
	sub_82DF1C90(ctx, base);
	// 828162A8: 387E0028  addi r3, r30, 0x28
	ctx.r[3].s64 = ctx.r[30].s64 + 40;
	// 828162AC: 487F2D0D  bl 0x83008fb8
	ctx.lr = 0x828162B0;
	sub_83008FB8(ctx, base);
	// 828162B0: 907F00F8  stw r3, 0xf8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(248 as u32), ctx.r[3].u32 ) };
	// 828162B4: 2B190000  cmplwi cr6, r25, 0
	ctx.cr[6].compare_u32(ctx.r[25].u32, 0 as u32, &mut ctx.xer);
	// 828162B8: 419A000C  beq cr6, 0x828162c4
	if ctx.cr[6].eq {
	pc = 0x828162C4; continue 'dispatch;
	}
	// 828162BC: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 828162C0: 4BAAA5D1  bl 0x822c0890
	ctx.lr = 0x828162C4;
	sub_822C0890(ctx, base);
	// 828162C4: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 828162C8: 48991EE4  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828162D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828162D0 size=112
    let mut pc: u32 = 0x828162D0;
    'dispatch: loop {
        match pc {
            0x828162D0 => {
    //   block [0x828162D0..0x82816340)
	// 828162D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828162D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828162D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828162DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828162E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828162E4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828162E8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828162EC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828162F0: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 828162F4: 396B9460  addi r11, r11, -0x6ba0
	ctx.r[11].s64 = ctx.r[11].s64 + -27552;
	// 828162F8: 394A9434  addi r10, r10, -0x6bcc
	ctx.r[10].s64 = ctx.r[10].s64 + -27596;
	// 828162FC: 39299420  addi r9, r9, -0x6be0
	ctx.r[9].s64 = ctx.r[9].s64 + -27616;
	// 82816300: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816304: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82816308: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8281630C: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 82816310: 4BFFFD19  bl 0x82816028
	ctx.lr = 0x82816314;
	sub_82816028(ctx, base);
	// 82816314: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82816318: 4182000C  beq 0x82816324
	if ctx.cr[0].eq {
	pc = 0x82816324; continue 'dispatch;
	}
	// 8281631C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816320: 485DC0B9  bl 0x82df23d8
	ctx.lr = 0x82816324;
	sub_82DF23D8(ctx, base);
	// 82816324: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816328: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8281632C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82816330: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816334: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816338: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8281633C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816340(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816340 size=384
    let mut pc: u32 = 0x82816340;
    'dispatch: loop {
        match pc {
            0x82816340 => {
    //   block [0x82816340..0x828164C0)
	// 82816340: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816344: 48991E21  bl 0x831a8164
	ctx.lr = 0x82816348;
	sub_831A8130(ctx, base);
	// 82816348: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281634C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816350: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82816354: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82816358: 4BFFC621  bl 0x82812978
	ctx.lr = 0x8281635C;
	sub_82812978(ctx, base);
	// 8281635C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816360: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82816364: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 82816368: 396B9400  addi r11, r11, -0x6c00
	ctx.r[11].s64 = ctx.r[11].s64 + -27648;
	// 8281636C: 394A93D4  addi r10, r10, -0x6c2c
	ctx.r[10].s64 = ctx.r[10].s64 + -27692;
	// 82816370: 392993C0  addi r9, r9, -0x6c40
	ctx.r[9].s64 = ctx.r[9].s64 + -27712;
	// 82816374: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816378: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8281637C: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82816380: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 82816384: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816388: 93BF0140  stw r29, 0x140(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(320 as u32), ctx.r[29].u32 ) };
	// 8281638C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82816390: 93BF0144  stw r29, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[29].u32 ) };
	// 82816394: 3B8B9378  addi r28, r11, -0x6c88
	ctx.r[28].s64 = ctx.r[11].s64 + -27784;
	// 82816398: 38A00060  li r5, 0x60
	ctx.r[5].s64 = 96;
	// 8281639C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 828163A0: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 828163A4: 4BAAA035  bl 0x822c03d8
	ctx.lr = 0x828163A8;
	sub_822C03D8(ctx, base);
	// 828163A8: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828163AC: 41820028  beq 0x828163d4
	if ctx.cr[0].eq {
	pc = 0x828163D4; continue 'dispatch;
	}
	// 828163B0: 3D208336  lis r9, -0x7cca
	ctx.r[9].s64 = -2093613056;
	// 828163B4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 828163B8: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 828163BC: 81298614  lwz r9, -0x79ec(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-31212 as u32) ) } as u64;
	// 828163C0: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 828163C4: 91630008  stw r11, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 828163C8: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 828163CC: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 828163D0: 48000008  b 0x828163d8
	pc = 0x828163D8; continue 'dispatch;
	// 828163D4: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 828163D8: 915F0148  stw r10, 0x148(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), ctx.r[10].u32 ) };
	// 828163DC: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 828163E0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828163E4: 38A0005D  li r5, 0x5d
	ctx.r[5].s64 = 93;
	// 828163E8: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 828163EC: 4BAA9FED  bl 0x822c03d8
	ctx.lr = 0x828163F0;
	sub_822C03D8(ctx, base);
	// 828163F0: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 828163F4: 41820020  beq 0x82816414
	if ctx.cr[0].eq {
	pc = 0x82816414; continue 'dispatch;
	}
	// 828163F8: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 828163FC: C03B0024  lfs f1, 0x24(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(36 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82816400: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 82816404: 38ABF1B0  addi r5, r11, -0xe50
	ctx.r[5].s64 = ctx.r[11].s64 + -3664;
	// 82816408: 388AF1A0  addi r4, r10, -0xe60
	ctx.r[4].s64 = ctx.r[10].s64 + -3680;
	// 8281640C: 4BFFC38D  bl 0x82812798
	ctx.lr = 0x82816410;
	sub_82812798(ctx, base);
	// 82816410: 48000008  b 0x82816418
	pc = 0x82816418; continue 'dispatch;
	// 82816414: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82816418: 39600060  li r11, 0x60
	ctx.r[11].s64 = 96;
	// 8281641C: 907F014C  stw r3, 0x14c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(332 as u32), ctx.r[3].u32 ) };
	// 82816420: 93BF0150  stw r29, 0x150(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(336 as u32), ctx.r[29].u32 ) };
	// 82816424: 39400160  li r10, 0x160
	ctx.r[10].s64 = 352;
	// 82816428: 93BF0154  stw r29, 0x154(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(340 as u32), ctx.r[29].u32 ) };
	// 8281642C: 3D208338  lis r9, -0x7cc8
	ctx.r[9].s64 = -2093481984;
	// 82816430: 38E00170  li r7, 0x170
	ctx.r[7].s64 = 368;
	// 82816434: 38C96910  addi r6, r9, 0x6910
	ctx.r[6].s64 = ctx.r[9].s64 + 26896;
	// 82816438: 13FE58C7  vcmpequd (lvx128) v31, v30, v11
	tmp.u32 = ctx.r[30].u32 + ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 8281643C: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828164C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828164C0 size=184
    let mut pc: u32 = 0x828164C0;
    'dispatch: loop {
        match pc {
            0x828164C0 => {
    //   block [0x828164C0..0x82816578)
	// 828164C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828164C4: 48991CA5  bl 0x831a8168
	ctx.lr = 0x828164C8;
	sub_831A8130(ctx, base);
	// 828164C8: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828164CC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828164D0: 80630140  lwz r3, 0x140(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(320 as u32) ) } as u64;
	// 828164D4: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 828164D8: 3BFE0010  addi r31, r30, 0x10
	ctx.r[31].s64 = ctx.r[30].s64 + 16;
	// 828164DC: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 828164E0: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 828164E4: 7CE83B78  mr r8, r7
	ctx.r[8].u64 = ctx.r[7].u64;
	// 828164E8: 13C0E8C7  vcmpequd (lvx128) v30, v0, v29
	tmp.u32 = ctx.r[29].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828164EC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 828164F0: 13E0F8C7  vcmpequd (lvx128) v31, v0, v31
	tmp.u32 = ctx.r[31].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828164F4: 38C10060  addi r6, r1, 0x60
	ctx.r[6].s64 = ctx.r[1].s64 + 96;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816578 size=92
    let mut pc: u32 = 0x82816578;
    'dispatch: loop {
        match pc {
            0x82816578 => {
    //   block [0x82816578..0x828165D4)
	// 82816578: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281657C: 48991BF1  bl 0x831a816c
	ctx.lr = 0x82816580;
	sub_831A8130(ctx, base);
	// 82816580: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816584: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816588: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8281658C: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 82816590: 4BFFFDB1  bl 0x82816340
	ctx.lr = 0x82816594;
	sub_82816340(ctx, base);
	// 82816594: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816598: 93DF01F0  stw r30, 0x1f0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(496 as u32), ctx.r[30].u32 ) };
	// 8281659C: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828165A0: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 828165A4: 39000200  li r8, 0x200
	ctx.r[8].s64 = 512;
	// 828165A8: 396B9460  addi r11, r11, -0x6ba0
	ctx.r[11].s64 = ctx.r[11].s64 + -27552;
	// 828165AC: 394A9434  addi r10, r10, -0x6bcc
	ctx.r[10].s64 = ctx.r[10].s64 + -27596;
	// 828165B0: 39299420  addi r9, r9, -0x6be0
	ctx.r[9].s64 = ctx.r[9].s64 + -27616;
	// 828165B4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828165B8: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 828165BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828165C0: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 828165C4: 13E0E8C7  vcmpequd (lvx128) v31, v0, v29
	tmp.u32 = ctx.r[29].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828165D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828165D8 size=128
    let mut pc: u32 = 0x828165D8;
    'dispatch: loop {
        match pc {
            0x828165D8 => {
    //   block [0x828165D8..0x82816658)
	// 828165D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828165DC: 48991B91  bl 0x831a816c
	ctx.lr = 0x828165E0;
	sub_831A8130(ctx, base);
	// 828165E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828165E4: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828165E8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 828165EC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 828165F0: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 828165F4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 828165F8: 388B9378  addi r4, r11, -0x6c88
	ctx.r[4].s64 = ctx.r[11].s64 + -27784;
	// 828165FC: 38A00055  li r5, 0x55
	ctx.r[5].s64 = 85;
	// 82816600: 386001F0  li r3, 0x1f0
	ctx.r[3].s64 = 496;
	// 82816604: 485DBDE5  bl 0x82df23e8
	ctx.lr = 0x82816608;
	sub_82DF23E8(ctx, base);
	// 82816608: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 8281660C: 41820018  beq 0x82816624
	if ctx.cr[0].eq {
	pc = 0x82816624; continue 'dispatch;
	}
	// 82816610: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82816614: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82816618: 4BFFFD29  bl 0x82816340
	ctx.lr = 0x8281661C;
	sub_82816340(ctx, base);
	// 8281661C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816620: 48000008  b 0x82816628
	pc = 0x82816628; continue 'dispatch;
	// 82816624: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82816628: 93FD0000  stw r31, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8281662C: 3BDD0004  addi r30, r29, 4
	ctx.r[30].s64 = ctx.r[29].s64 + 4;
	// 82816630: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82816634: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816638: 4BFFF171  bl 0x828157a8
	ctx.lr = 0x8281663C;
	sub_828157A8(ctx, base);
	// 8281663C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82816640: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82816644: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816648: 4BAA99B9  bl 0x822c0000
	ctx.lr = 0x8281664C;
	sub_822C0000(ctx, base);
	// 8281664C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82816650: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816654: 48991B68  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816658 size=592
    let mut pc: u32 = 0x82816658;
    'dispatch: loop {
        match pc {
            0x82816658 => {
    //   block [0x82816658..0x828168A8)
	// 82816658: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281665C: 48991B09  bl 0x831a8164
	ctx.lr = 0x82816660;
	sub_831A8130(ctx, base);
	// 82816660: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 82816664: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816668: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8281666C: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82816670: 3BDFFFA8  addi r30, r31, -0x58
	ctx.r[30].s64 = ctx.r[31].s64 + -88;
	// 82816674: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816678: 4BFFBE01  bl 0x82812478
	ctx.lr = 0x8281667C;
	sub_82812478(ctx, base);
	// 8281667C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82816680: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816684: C3FB0000  lfs f31, 0(r27)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82816688: D3E10050  stfs f31, 0x50(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 8281668C: 4BFFBE55  bl 0x828124e0
	ctx.lr = 0x82816690;
	sub_828124E0(ctx, base);
	// 82816690: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 82816694: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82816698: 409A0030  bne cr6, 0x828166c8
	if !ctx.cr[6].eq {
	pc = 0x828166C8; continue 'dispatch;
	}
	// 8281669C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 828166A0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828166A4: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 828166A8: 816B0018  lwz r11, 0x18(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 828166AC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 828166B0: 4E800421  bctrl
	ctx.lr = 0x828166B4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 828166B4: 38BF0128  addi r5, r31, 0x128
	ctx.r[5].s64 = ctx.r[31].s64 + 296;
	// 828166B8: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 828166BC: 807F00F4  lwz r3, 0xf4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(244 as u32) ) } as u64;
	// 828166C0: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 828166C4: 4BFFC3FD  bl 0x82812ac0
	ctx.lr = 0x828166C8;
	sub_82812AC0(ctx, base);
	// 828166C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828166CC: 4BFFBE75  bl 0x82812540
	ctx.lr = 0x828166D0;
	sub_82812540(ctx, base);
	// 828166D0: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 828166D4: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 828166D8: 409A0024  bne cr6, 0x828166fc
	if !ctx.cr[6].eq {
	pc = 0x828166FC; continue 'dispatch;
	}
	// 828166DC: C03D0020  lfs f1, 0x20(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 828166E0: 3B9F0128  addi r28, r31, 0x128
	ctx.r[28].s64 = ctx.r[31].s64 + 296;
	// 828166E4: 3BBF0118  addi r29, r31, 0x118
	ctx.r[29].s64 = ctx.r[31].s64 + 280;
	// 828166E8: 807F00F4  lwz r3, 0xf4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(244 as u32) ) } as u64;
	// 828166EC: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 828166F0: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 828166F4: 4BFFC565  bl 0x82812c58
	ctx.lr = 0x828166F8;
	sub_82812C58(ctx, base);
	// 828166F8: 48000050  b 0x82816748
	pc = 0x82816748; continue 'dispatch;
	// 828166FC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82816700: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82816704: 482CCE75  bl 0x82ae3578
	ctx.lr = 0x82816708;
	sub_82AE3578(ctx, base);
	// 82816708: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 8281670C: 39410054  addi r10, r1, 0x54
	ctx.r[10].s64 = ctx.r[1].s64 + 84;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828168A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x828168A8 size=276
    let mut pc: u32 = 0x828168A8;
    'dispatch: loop {
        match pc {
            0x828168A8 => {
    //   block [0x828168A8..0x828169BC)
	// 828168A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828168AC: 489918BD  bl 0x831a8168
	ctx.lr = 0x828168B0;
	sub_831A8130(ctx, base);
	// 828168B0: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828168B4: 39600010  li r11, 0x10
	ctx.r[11].s64 = 16;
	// 828168B8: D0030000  stfs f0, 0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 828168BC: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 828168C0: C0040004  lfs f0, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828168C4: 39400030  li r10, 0x30
	ctx.r[10].s64 = 48;
	// 828168C8: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 828168CC: 39040020  addi r8, r4, 0x20
	ctx.r[8].s64 = ctx.r[4].s64 + 32;
	// 828168D0: C0040008  lfs f0, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828168D4: 38E30020  addi r7, r3, 0x20
	ctx.r[7].s64 = ctx.r[3].s64 + 32;
	// 828168D8: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 828168DC: 3B800060  li r28, 0x60
	ctx.r[28].s64 = 96;
	// 828168E0: C004000C  lfs f0, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 828168E4: 38C40070  addi r6, r4, 0x70
	ctx.r[6].s64 = ctx.r[4].s64 + 112;
	// 828168E8: D003000C  stfs f0, 0xc(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 828168EC: 38A30070  addi r5, r3, 0x70
	ctx.r[5].s64 = ctx.r[3].s64 + 112;
	// 828168F0: 13E458C7  vcmpequd (lvx128) v31, v4, v11
	tmp.u32 = ctx.r[4].u32 + ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828168F4: 3BE400B0  addi r31, r4, 0xb0
	ctx.r[31].s64 = ctx.r[4].s64 + 176;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828169C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x828169C0 size=128
    let mut pc: u32 = 0x828169C0;
    'dispatch: loop {
        match pc {
            0x828169C0 => {
    //   block [0x828169C0..0x82816A40)
	// 828169C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828169C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 828169C8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 828169CC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 828169D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828169D4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828169D8: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 828169DC: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 828169E0: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 828169E4: 396B94D4  addi r11, r11, -0x6b2c
	ctx.r[11].s64 = ctx.r[11].s64 + -27436;
	// 828169E8: 394A94A8  addi r10, r10, -0x6b58
	ctx.r[10].s64 = ctx.r[10].s64 + -27480;
	// 828169EC: 807F0148  lwz r3, 0x148(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(328 as u32) ) } as u64;
	// 828169F0: 39299494  addi r9, r9, -0x6b6c
	ctx.r[9].s64 = ctx.r[9].s64 + -27500;
	// 828169F4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 828169F8: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 828169FC: 3BDF0058  addi r30, r31, 0x58
	ctx.r[30].s64 = ctx.r[31].s64 + 88;
	// 82816A00: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 82816A04: 4BAA9865  bl 0x822c0268
	ctx.lr = 0x82816A08;
	sub_822C0268(ctx, base);
	// 82816A08: 807F0144  lwz r3, 0x144(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(324 as u32) ) } as u64;
	// 82816A0C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816A10: 419A0008  beq cr6, 0x82816a18
	if ctx.cr[6].eq {
	pc = 0x82816A18; continue 'dispatch;
	}
	// 82816A14: 4BAA9E7D  bl 0x822c0890
	ctx.lr = 0x82816A18;
	sub_822C0890(ctx, base);
	// 82816A18: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816A1C: 4BCFA77D  bl 0x82511198
	ctx.lr = 0x82816A20;
	sub_82511198(ctx, base);
	// 82816A20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816A24: 4BFFBCB5  bl 0x828126d8
	ctx.lr = 0x82816A28;
	sub_828126D8(ctx, base);
	// 82816A28: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816A2C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82816A30: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816A34: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816A38: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82816A3C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816A40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82816A40 size=8
    let mut pc: u32 = 0x82816A40;
    'dispatch: loop {
        match pc {
            0x82816A40 => {
    //   block [0x82816A40..0x82816A48)
	// 82816A40: 3863FF80  addi r3, r3, -0x80
	ctx.r[3].s64 = ctx.r[3].s64 + -128;
	// 82816A44: 480002F4  b 0x82816d38
	sub_82816D38(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816A48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82816A48 size=8
    let mut pc: u32 = 0x82816A48;
    'dispatch: loop {
        match pc {
            0x82816A48 => {
    //   block [0x82816A48..0x82816A50)
	// 82816A48: 3863FFA8  addi r3, r3, -0x58
	ctx.r[3].s64 = ctx.r[3].s64 + -88;
	// 82816A4C: 480002EC  b 0x82816d38
	sub_82816D38(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816A50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816A50 size=192
    let mut pc: u32 = 0x82816A50;
    'dispatch: loop {
        match pc {
            0x82816A50 => {
    //   block [0x82816A50..0x82816B10)
	// 82816A50: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816A54: 48991715  bl 0x831a8168
	ctx.lr = 0x82816A58;
	sub_831A8130(ctx, base);
	// 82816A58: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816A5C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82816A60: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82816A64: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 82816A68: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 82816A6C: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82816A70: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82816A74: 13C0E0C7  vcmpequd (lvx128) v30, v0, v28
	tmp.u32 = ctx.r[28].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82816A78: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82816A7C: 13E0F0C7  vcmpequd (lvx128) v31, v0, v30
	tmp.u32 = ctx.r[30].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82816A80: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816B10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82816B10 size=28
    let mut pc: u32 = 0x82816B10;
    'dispatch: loop {
        match pc {
            0x82816B10 => {
    //   block [0x82816B10..0x82816B2C)
	// 82816B10: 3D608206  lis r11, -0x7dfa
	ctx.r[11].s64 = -2113536000;
	// 82816B14: 13E028C7  vcmpequd (lvx128) v31, v0, v5
	tmp.u32 = ctx.r[5].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 82816B18: 396BB850  addi r11, r11, -0x47b0
	ctx.r[11].s64 = ctx.r[11].s64 + -18352;
	// 82816B1C: 13C058C7  vcmpequd (lvx128) v30, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816B30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816B30 size=196
    let mut pc: u32 = 0x82816B30;
    'dispatch: loop {
        match pc {
            0x82816B30 => {
    //   block [0x82816B30..0x82816BF4)
	// 82816B30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816B34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816B38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82816B3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816B40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816B44: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82816B48: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82816B4C: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 82816B50: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82816B54: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816B58: 4BAA9DE1  bl 0x822c0938
	ctx.lr = 0x82816B5C;
	sub_822C0938(ctx, base);
	// 82816B5C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82816B60: 41820028  beq 0x82816b88
	if ctx.cr[0].eq {
	pc = 0x82816B88; continue 'dispatch;
	}
	// 82816B64: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816B68: 93E3000C  stw r31, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 82816B6C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82816B70: 392B9480  addi r9, r11, -0x6b80
	ctx.r[9].s64 = ctx.r[11].s64 + -27520;
	// 82816B74: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82816B78: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82816B7C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82816B80: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82816B84: 48000008  b 0x82816b8c
	pc = 0x82816B8C; continue 'dispatch;
	// 82816B88: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82816B8C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816B90: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82816B94: 409A0044  bne cr6, 0x82816bd8
	if !ctx.cr[6].eq {
	pc = 0x82816BD8; continue 'dispatch;
	}
	// 82816B98: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82816B9C: 419A001C  beq cr6, 0x82816bb8
	if ctx.cr[6].eq {
	pc = 0x82816BB8; continue 'dispatch;
	}
	// 82816BA0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82816BA4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82816BA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816BAC: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82816BB0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82816BB4: 4E800421  bctrl
	ctx.lr = 0x82816BB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82816BB8: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82816BBC: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82816BC0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82816BC4: 394A0828  addi r10, r10, 0x828
	ctx.r[10].s64 = ctx.r[10].s64 + 2088;
	// 82816BC8: 816BF2B0  lwz r11, -0xd50(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3408 as u32) ) } as u64;
	// 82816BCC: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 82816BD0: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82816BD4: 4BAA942D  bl 0x822c0000
	ctx.lr = 0x82816BD8;
	sub_822C0000(ctx, base);
	// 82816BD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82816BDC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816BE0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82816BE4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816BE8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816BEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82816BF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816BF8 size=316
    let mut pc: u32 = 0x82816BF8;
    'dispatch: loop {
        match pc {
            0x82816BF8 => {
    //   block [0x82816BF8..0x82816D34)
	// 82816BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816BFC: 4899156D  bl 0x831a8168
	ctx.lr = 0x82816C00;
	sub_831A8130(ctx, base);
	// 82816C00: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816C04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816C08: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82816C0C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82816C10: 4BFFBD69  bl 0x82812978
	ctx.lr = 0x82816C14;
	sub_82812978(ctx, base);
	// 82816C14: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816C18: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82816C1C: 3D208208  lis r9, -0x7df8
	ctx.r[9].s64 = -2113404928;
	// 82816C20: 396B94D4  addi r11, r11, -0x6b2c
	ctx.r[11].s64 = ctx.r[11].s64 + -27436;
	// 82816C24: 394A94A8  addi r10, r10, -0x6b58
	ctx.r[10].s64 = ctx.r[10].s64 + -27480;
	// 82816C28: 39299494  addi r9, r9, -0x6b6c
	ctx.r[9].s64 = ctx.r[9].s64 + -27500;
	// 82816C2C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816C30: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82816C34: 915F0058  stw r10, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 82816C38: 913F0080  stw r9, 0x80(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), ctx.r[9].u32 ) };
	// 82816C3C: 3D608208  lis r11, -0x7df8
	ctx.r[11].s64 = -2113404928;
	// 82816C40: 93BF0140  stw r29, 0x140(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(320 as u32), ctx.r[29].u32 ) };
	// 82816C44: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82816C48: 93BF0144  stw r29, 0x144(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(324 as u32), ctx.r[29].u32 ) };
	// 82816C4C: 388B94E8  addi r4, r11, -0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + -27416;
	// 82816C50: 38A0003B  li r5, 0x3b
	ctx.r[5].s64 = 59;
	// 82816C54: 38600030  li r3, 0x30
	ctx.r[3].s64 = 48;
	// 82816C58: 4BAA9781  bl 0x822c03d8
	ctx.lr = 0x82816C5C;
	sub_822C03D8(ctx, base);
	// 82816C5C: 28030000  cmplwi r3, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82816C60: 41820020  beq 0x82816c80
	if ctx.cr[0].eq {
	pc = 0x82816C80; continue 'dispatch;
	}
	// 82816C64: 3D60832B  lis r11, -0x7cd5
	ctx.r[11].s64 = -2094333952;
	// 82816C68: C03C0024  lfs f1, 0x24(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(36 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82816C6C: 3D40832B  lis r10, -0x7cd5
	ctx.r[10].s64 = -2094333952;
	// 82816C70: 38ABF2D0  addi r5, r11, -0xd30
	ctx.r[5].s64 = ctx.r[11].s64 + -3376;
	// 82816C74: 388AF2C0  addi r4, r10, -0xd40
	ctx.r[4].s64 = ctx.r[10].s64 + -3392;
	// 82816C78: 4BFFBB21  bl 0x82812798
	ctx.lr = 0x82816C7C;
	sub_82812798(ctx, base);
	// 82816C7C: 48000008  b 0x82816c84
	pc = 0x82816C84; continue 'dispatch;
	// 82816C80: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82816C84: 907F0148  stw r3, 0x148(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(328 as u32), ctx.r[3].u32 ) };
	// 82816C88: 389E0060  addi r4, r30, 0x60
	ctx.r[4].s64 = ctx.r[30].s64 + 96;
	// 82816C8C: 387F0150  addi r3, r31, 0x150
	ctx.r[3].s64 = ctx.r[31].s64 + 336;
	// 82816C90: 486667C1  bl 0x82e7d450
	ctx.lr = 0x82816C94;
	sub_82E7D450(ctx, base);
	// 82816C94: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82816C98: 387F0160  addi r3, r31, 0x160
	ctx.r[3].s64 = ctx.r[31].s64 + 352;
	// 82816C9C: 4BFFFC0D  bl 0x828168a8
	ctx.lr = 0x82816CA0;
	sub_828168A8(ctx, base);
	// 82816CA0: C1BE0000  lfs f13, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82816CA4: D1BF02D0  stfs f13, 0x2d0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(720 as u32), tmp.u32 ) };
	// 82816CA8: 39200010  li r9, 0x10
	ctx.r[9].s64 = 16;
	// 82816CAC: 391F02D0  addi r8, r31, 0x2d0
	ctx.r[8].s64 = ctx.r[31].s64 + 720;
	// 82816CB0: 397E0020  addi r11, r30, 0x20
	ctx.r[11].s64 = ctx.r[30].s64 + 32;
	// 82816CB4: 38C00020  li r6, 0x20
	ctx.r[6].s64 = 32;
	// 82816CB8: 38E00030  li r7, 0x30
	ctx.r[7].s64 = 48;
	// 82816CBC: 39480020  addi r10, r8, 0x20
	ctx.r[10].s64 = ctx.r[8].s64 + 32;
	// 82816CC0: 3CA08338  lis r5, -0x7cc8
	ctx.r[5].s64 = -2093481984;
	// 82816CC4: 38800330  li r4, 0x330
	ctx.r[4].s64 = 816;
	// 82816CC8: 38A56910  addi r5, r5, 0x6910
	ctx.r[5].s64 = ctx.r[5].s64 + 26896;
	// 82816CCC: 3F808200  lis r28, -0x7e00
	ctx.r[28].s64 = -2113929216;
	// 82816CD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816CD4: C01C08A4  lfs f0, 0x8a4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82816CD8: C1BE0004  lfs f13, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82816CDC: D1BF02D4  stfs f13, 0x2d4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(724 as u32), tmp.u32 ) };
	// 82816CE0: C1BE0008  lfs f13, 8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82816CE4: D1BF02D8  stfs f13, 0x2d8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(728 as u32), tmp.u32 ) };
	// 82816CE8: C1BE000C  lfs f13, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82816CEC: D1BF02DC  stfs f13, 0x2dc(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(732 as u32), tmp.u32 ) };
	// 82816CF0: 13FE48C7  vcmpequd (lvx128) v31, v30, v9
	tmp.u32 = ctx.r[30].u32 + ctx.r[9].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816D38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816D38 size=76
    let mut pc: u32 = 0x82816D38;
    'dispatch: loop {
        match pc {
            0x82816D38 => {
    //   block [0x82816D38..0x82816D84)
	// 82816D38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816D3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816D40: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82816D44: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816D48: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816D4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816D50: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82816D54: 4BFFFC6D  bl 0x828169c0
	ctx.lr = 0x82816D58;
	sub_828169C0(ctx, base);
	// 82816D58: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82816D5C: 4182000C  beq 0x82816d68
	if ctx.cr[0].eq {
	pc = 0x82816D68; continue 'dispatch;
	}
	// 82816D60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816D64: 485DB675  bl 0x82df23d8
	ctx.lr = 0x82816D68;
	sub_82DF23D8(ctx, base);
	// 82816D68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82816D6C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816D70: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82816D74: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816D78: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816D7C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82816D80: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816D88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82816D88 size=112
    let mut pc: u32 = 0x82816D88;
    'dispatch: loop {
        match pc {
            0x82816D88 => {
    //   block [0x82816D88..0x82816DF8)
	// 82816D88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816D8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816D90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82816D94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816D98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816D9C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82816DA0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816DA4: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82816DA8: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82816DAC: 4BFFFD85  bl 0x82816b30
	ctx.lr = 0x82816DB0;
	sub_82816B30(ctx, base);
	// 82816DB0: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82816DB4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82816DB8: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82816DBC: 4BAA9245  bl 0x822c0000
	ctx.lr = 0x82816DC0;
	sub_822C0000(ctx, base);
	// 82816DC0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82816DC4: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82816DC8: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82816DCC: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82816DD0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816DD4: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82816DD8: 419A0008  beq cr6, 0x82816de0
	if ctx.cr[6].eq {
	pc = 0x82816DE0; continue 'dispatch;
	}
	// 82816DDC: 4BAA9AB5  bl 0x822c0890
	ctx.lr = 0x82816DE0;
	sub_822C0890(ctx, base);
	// 82816DE0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82816DE4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82816DE8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82816DEC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82816DF0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82816DF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816DF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816DF8 size=244
    let mut pc: u32 = 0x82816DF8;
    'dispatch: loop {
        match pc {
            0x82816DF8 => {
    //   block [0x82816DF8..0x82816EEC)
	// 82816DF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816DFC: 48991371  bl 0x831a816c
	ctx.lr = 0x82816E00;
	sub_831A8130(ctx, base);
	// 82816E00: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816E04: 3D608338  lis r11, -0x7cc8
	ctx.r[11].s64 = -2093481984;
	// 82816E08: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82816E0C: 396B6910  addi r11, r11, 0x6910
	ctx.r[11].s64 = ctx.r[11].s64 + 26896;
	// 82816E10: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816E14: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82816E18: 387FFFA8  addi r3, r31, -0x58
	ctx.r[3].s64 = ctx.r[31].s64 + -88;
	// 82816E1C: 13E058C7  vcmpequd (lvx128) v31, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816EF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816EF0 size=212
    let mut pc: u32 = 0x82816EF0;
    'dispatch: loop {
        match pc {
            0x82816EF0 => {
    //   block [0x82816EF0..0x82816FC4)
	// 82816EF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816EF4: 48991279  bl 0x831a816c
	ctx.lr = 0x82816EF8;
	sub_831A8130(ctx, base);
	// 82816EF8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816EFC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816F00: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82816F04: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82816F08: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 82816F0C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82816F10: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82816F14: 4BAF2ABD  bl 0x823099d0
	ctx.lr = 0x82816F18;
	sub_823099D0(ctx, base);
	// 82816F18: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82816F1C: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 82816F20: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 82816F24: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82816F28: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82816F2C: 4BAAD535  bl 0x822c4460
	ctx.lr = 0x82816F30;
	sub_822C4460(ctx, base);
	// 82816F30: 80610064  lwz r3, 0x64(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 82816F34: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816F38: 419A0008  beq cr6, 0x82816f40
	if ctx.cr[6].eq {
	pc = 0x82816F40; continue 'dispatch;
	}
	// 82816F3C: 4BAA9955  bl 0x822c0890
	ctx.lr = 0x82816F40;
	sub_822C0890(ctx, base);
	// 82816F40: 83A10054  lwz r29, 0x54(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82816F44: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82816F48: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82816F4C: 93A1005C  stw r29, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[29].u32 ) };
	// 82816F50: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 82816F54: 419A0024  beq cr6, 0x82816f78
	if ctx.cr[6].eq {
	pc = 0x82816F78; continue 'dispatch;
	}
	// 82816F58: 397D0004  addi r11, r29, 4
	ctx.r[11].s64 = ctx.r[29].s64 + 4;
	// 82816F5C: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82816F60: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82816F64: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82816F68: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82816F6C: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82816F70: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 82816F74: 4082FFE8  bne 0x82816f5c
	if !ctx.cr[0].eq {
	pc = 0x82816F5C; continue 'dispatch;
	}
	// 82816F78: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82816F7C: 80DF0340  lwz r6, 0x340(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(832 as u32) ) } as u64;
	// 82816F80: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 82816F84: 38E10058  addi r7, r1, 0x58
	ctx.r[7].s64 = ctx.r[1].s64 + 88;
	// 82816F88: 388A94E8  addi r4, r10, -0x6b18
	ctx.r[4].s64 = ctx.r[10].s64 + -27416;
	// 82816F8C: 38A000A8  li r5, 0xa8
	ctx.r[5].s64 = 168;
	// 82816F90: 387E0028  addi r3, r30, 0x28
	ctx.r[3].s64 = ctx.r[30].s64 + 40;
	// 82816F94: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82816F98: 48641AA9  bl 0x82e58a40
	ctx.lr = 0x82816F9C;
	sub_82E58A40(ctx, base);
	// 82816F9C: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82816FA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82816FA4: 419A0008  beq cr6, 0x82816fac
	if ctx.cr[6].eq {
	pc = 0x82816FAC; continue 'dispatch;
	}
	// 82816FA8: 4BAA98E9  bl 0x822c0890
	ctx.lr = 0x82816FAC;
	sub_822C0890(ctx, base);
	// 82816FAC: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82816FB0: 419A000C  beq cr6, 0x82816fbc
	if ctx.cr[6].eq {
	pc = 0x82816FBC; continue 'dispatch;
	}
	// 82816FB4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82816FB8: 4BAA98D9  bl 0x822c0890
	ctx.lr = 0x82816FBC;
	sub_822C0890(ctx, base);
	// 82816FBC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82816FC0: 489911FC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82816FC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82816FC8 size=224
    let mut pc: u32 = 0x82816FC8;
    'dispatch: loop {
        match pc {
            0x82816FC8 => {
    //   block [0x82816FC8..0x828170A8)
	// 82816FC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82816FCC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82816FD0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82816FD4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82816FD8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82816FDC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82816FE0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82816FE4: 4BFFB49D  bl 0x82812480
	ctx.lr = 0x82816FE8;
	sub_82812480(ctx, base);
	// 82816FE8: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82816FEC: 40820008  bne 0x82816ff4
	if !ctx.cr[0].eq {
	pc = 0x82816FF4; continue 'dispatch;
	}
	// 82816FF0: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 82816FF4: 897F0348  lbz r11, 0x348(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(840 as u32) ) } as u64;
	// 82816FF8: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82816FFC: 409A0088  bne cr6, 0x82817084
	if !ctx.cr[6].eq {
	pc = 0x82817084; continue 'dispatch;
	}
	// 82817000: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 82817004: 4BFFEA15  bl 0x82815a18
	ctx.lr = 0x82817008;
	sub_82815A18(ctx, base);
	// 82817008: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8281700C: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 82817010: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82817014: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82817018: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8281701C: 419A0024  beq cr6, 0x82817040
	if ctx.cr[6].eq {
	pc = 0x82817040; continue 'dispatch;
	}
	// 82817020: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82817024: 7D2000A6  mfmsr r9
	ctx.r[9].u64 = ctx.msr;
	// 82817028: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8281702C: 7D405828  lwarx r10, 0, r11
	// lwarx
	let ea = ctx.r[11].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[10].u64 = ctx.reserved.u32 as u64;
	// 82817030: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82817034: 7D40592D  stwcx. r10, 0, r11
	// stwcx.
	let addr = ctx.r[11].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[10].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 82817038: 7D210164  mtmsrd r9, 1
	ctx.msr = (ctx.r[9].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 8281703C: 4082FFE8  bne 0x82817024
	if !ctx.cr[0].eq {
	pc = 0x82817024; continue 'dispatch;
	}
	// 82817040: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82817044: 80DF0340  lwz r6, 0x340(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(832 as u32) ) } as u64;
	// 82817048: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8281704C: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82817050: 388A94E8  addi r4, r10, -0x6b18
	ctx.r[4].s64 = ctx.r[10].s64 + -27416;
	// 82817054: 38A000D3  li r5, 0xd3
	ctx.r[5].s64 = 211;
	// 82817058: 387F0080  addi r3, r31, 0x80
	ctx.r[3].s64 = ctx.r[31].s64 + 128;
	// 8281705C: C02B08A4  lfs f1, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82817060: 486419E1  bl 0x82e58a40
	ctx.lr = 0x82817064;
	sub_82E58A40(ctx, base);
	// 82817064: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82817068: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8281706C: 419A0008  beq cr6, 0x82817074
	if ctx.cr[6].eq {
	pc = 0x82817074; continue 'dispatch;
	}
	// 82817070: 4BAA9821  bl 0x822c0890
	ctx.lr = 0x82817074;
	sub_822C0890(ctx, base);
	// 82817074: 8061005C  lwz r3, 0x5c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82817078: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8281707C: 419A0008  beq cr6, 0x82817084
	if ctx.cr[6].eq {
	pc = 0x82817084; continue 'dispatch;
	}
	// 82817080: 4BAA9811  bl 0x822c0890
	ctx.lr = 0x82817084;
	sub_822C0890(ctx, base);
	// 82817084: 7FCB0034  cntlzw r11, r30
	ctx.r[11].u64 = if ctx.r[30].u32 == 0 { 32 } else { ctx.r[30].u32.leading_zeros() as u64 };
	// 82817088: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 8281708C: 69630001  xori r3, r11, 1
	ctx.r[3].u64 = ctx.r[11].u64 ^ 1;
	// 82817090: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82817094: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82817098: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8281709C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 828170A0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 828170A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828170A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x828170A8 size=476
    let mut pc: u32 = 0x828170A8;
    'dispatch: loop {
        match pc {
            0x828170A8 => {
    //   block [0x828170A8..0x82817284)
	// 828170A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 828170AC: 489910BD  bl 0x831a8168
	ctx.lr = 0x828170B0;
	sub_831A8130(ctx, base);
	// 828170B0: DBE1FFD0  stfd f31, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 828170B4: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 828170B8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828170BC: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 828170C0: 4BFFB501  bl 0x828125c0
	ctx.lr = 0x828170C4;
	sub_828125C0(ctx, base);
	// 828170C4: 3BDFFFA8  addi r30, r31, -0x58
	ctx.r[30].s64 = ctx.r[31].s64 + -88;
	// 828170C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828170CC: 4BFFB3AD  bl 0x82812478
	ctx.lr = 0x828170D0;
	sub_82812478(ctx, base);
	// 828170D0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 828170D4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828170D8: C3FC0000  lfs f31, 0(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 828170DC: D3E10054  stfs f31, 0x54(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 828170E0: 4BFFB401  bl 0x828124e0
	ctx.lr = 0x828170E4;
	sub_828124E0(ctx, base);
	// 828170E4: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 828170E8: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 828170EC: 409A0034  bne cr6, 0x82817120
	if !ctx.cr[6].eq {
	pc = 0x82817120; continue 'dispatch;
	}
	// 828170F0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 828170F4: 38BF0288  addi r5, r31, 0x288
	ctx.r[5].s64 = ctx.r[31].s64 + 648;
	// 828170F8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828170FC: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82817100: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82817104: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82817108: 4E800421  bctrl
	ctx.lr = 0x8281710C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8281710C: 38BF0278  addi r5, r31, 0x278
	ctx.r[5].s64 = ctx.r[31].s64 + 632;
	// 82817110: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 82817114: 807F00F0  lwz r3, 0xf0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) } as u64;
	// 82817118: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 8281711C: 4BFFB9A5  bl 0x82812ac0
	ctx.lr = 0x82817120;
	sub_82812AC0(ctx, base);
	// 82817120: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82817124: 4BFFB41D  bl 0x82812540
	ctx.lr = 0x82817128;
	sub_82812540(ctx, base);
	// 82817128: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 8281712C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 82817130: 409A0018  bne cr6, 0x82817148
	if !ctx.cr[6].eq {
	pc = 0x82817148; continue 'dispatch;
	}
	// 82817134: 38DF0278  addi r6, r31, 0x278
	ctx.r[6].s64 = ctx.r[31].s64 + 632;
	// 82817138: C03D0020  lfs f1, 0x20(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8281713C: 38BF02D8  addi r5, r31, 0x2d8
	ctx.r[5].s64 = ctx.r[31].s64 + 728;
	// 82817140: 807F00F0  lwz r3, 0xf0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(240 as u32) ) } as u64;
	// 82817144: 4BFFBB15  bl 0x82812c58
	ctx.lr = 0x82817148;
	sub_82812C58(ctx, base);
	// 82817148: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 8281714C: C1BF02EC  lfs f13, 0x2ec(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(748 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82817150: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 82817154: 397F02D8  addi r11, r31, 0x2d8
	ctx.r[11].s64 = ctx.r[31].s64 + 728;
	// 82817158: 390000F8  li r8, 0xf8
	ctx.r[8].s64 = 248;
	// 8281715C: C00A9C28  lfs f0, -0x63d8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-25560 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82817160: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 82817164: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82817168: 13E04C07  vcmpneb. (lvlx128) v31, v0, v9
	tmp.u32 = ctx.r[9].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817288(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82817288 size=676
    let mut pc: u32 = 0x82817288;
    'dispatch: loop {
        match pc {
            0x82817288 => {
    //   block [0x82817288..0x8281752C)
	// 82817288: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281728C: 48990EA5  bl 0x831a8130
	ctx.lr = 0x82817290;
	sub_831A8130(ctx, base);
	// 82817290: 9421FDE0  stwu r1, -0x220(r1)
	ea = ctx.r[1].u32.wrapping_add(-544 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82817294: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82817298: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8281729C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 828172A0: 4BFFB451  bl 0x828126f0
	ctx.lr = 0x828172A4;
	sub_828126F0(ctx, base);
	// 828172A4: 3B610170  addi r27, r1, 0x170
	ctx.r[27].s64 = ctx.r[1].s64 + 368;
	// 828172A8: 397F01B8  addi r11, r31, 0x1b8
	ctx.r[11].s64 = ctx.r[31].s64 + 440;
	// 828172AC: 93610070  stw r27, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[27].u32 ) };
	// 828172B0: 3B210080  addi r25, r1, 0x80
	ctx.r[25].s64 = ctx.r[1].s64 + 128;
	// 828172B4: 391F01F8  addi r8, r31, 0x1f8
	ctx.r[8].s64 = ctx.r[31].s64 + 504;
	// 828172B8: 38A10140  addi r5, r1, 0x140
	ctx.r[5].s64 = ctx.r[1].s64 + 320;
	// 828172BC: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 828172C0: 38810150  addi r4, r1, 0x150
	ctx.r[4].s64 = ctx.r[1].s64 + 336;
	// 828172C4: 13C05C07  vcmpneb. (lvlx128) v30, v0, v11
	tmp.u32 = ctx.r[11].u32;
	// load shuffled into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828172C8: 38610160  addi r3, r1, 0x160
	ctx.r[3].s64 = ctx.r[1].s64 + 352;
	// 828172CC: 90A10064  stw r5, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[5].u32 ) };
	// 828172D0: 3B010090  addi r24, r1, 0x90
	ctx.r[24].s64 = ctx.r[1].s64 + 144;
	// 828172D4: 12404407  vcmpneb. (lvlx128) v18, v0, v8
	tmp.u32 = ctx.r[8].u32;
	// load shuffled into ctx.v[50] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828172D8: 3AE100A0  addi r23, r1, 0xa0
	ctx.r[23].s64 = ctx.r[1].s64 + 160;
	// 828172DC: 90810060  stw r4, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[4].u32 ) };
	// 828172E0: 3AC100B0  addi r22, r1, 0xb0
	ctx.r[22].s64 = ctx.r[1].s64 + 176;
	// 828172E4: 13264407  vcmpneb. (lvlx128) v25, v6, v8
	tmp.u32 = ctx.r[6].u32 + ctx.r[8].u32;
	// load shuffled into ctx.v[57] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828172E8: 3AA100C0  addi r21, r1, 0xc0
	ctx.r[21].s64 = ctx.r[1].s64 + 192;
	// 828172EC: 9061005C  stw r3, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[3].u32 ) };
	// 828172F0: 3A8100D0  addi r20, r1, 0xd0
	ctx.r[20].s64 = ctx.r[1].s64 + 208;
	// 828172F4: 13E65C07  vcmpneb. (lvlx128) v31, v6, v11
	tmp.u32 = ctx.r[6].u32 + ctx.r[11].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 828172F8: 3A6100E0  addi r19, r1, 0xe0
	ctx.r[19].s64 = ctx.r[1].s64 + 224;
	// 828172FC: 3A4100F0  addi r18, r1, 0xf0
	ctx.r[18].s64 = ctx.r[1].s64 + 240;
	// 82817300: 3A210100  addi r17, r1, 0x100
	ctx.r[17].s64 = ctx.r[1].s64 + 256;
	// 82817304: 3A010110  addi r16, r1, 0x110
	ctx.r[16].s64 = ctx.r[1].s64 + 272;
	// 82817308: 39E10120  addi r15, r1, 0x120
	ctx.r[15].s64 = ctx.r[1].s64 + 288;
	// 8281730C: 39C10130  addi r14, r1, 0x130
	ctx.r[14].s64 = ctx.r[1].s64 + 304;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817530(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82817530 size=96
    let mut pc: u32 = 0x82817530;
    'dispatch: loop {
        match pc {
            0x82817530 => {
    //   block [0x82817530..0x82817590)
	// 82817530: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82817534: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82817538: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8281753C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82817540: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82817544: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82817548: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 8281754C: 4BFD419D  bl 0x827eb6e8
	ctx.lr = 0x82817550;
	sub_827EB6E8(ctx, base);
	// 82817550: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82817554: 41820020  beq 0x82817574
	if ctx.cr[0].eq {
	pc = 0x82817574; continue 'dispatch;
	}
	// 82817558: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8281755C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82817560: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82817564: 4BFD42AD  bl 0x827eb810
	ctx.lr = 0x82817568;
	sub_827EB810(ctx, base);
	// 82817568: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8281756C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82817570: 40820008  bne 0x82817578
	if !ctx.cr[0].eq {
	pc = 0x82817578; continue 'dispatch;
	}
	// 82817574: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82817578: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8281757C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82817580: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82817584: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82817588: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8281758C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817590(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82817590 size=8
    let mut pc: u32 = 0x82817590;
    'dispatch: loop {
        match pc {
            0x82817590 => {
    //   block [0x82817590..0x82817598)
	// 82817590: 80630234  lwz r3, 0x234(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(564 as u32) ) } as u64;
	// 82817594: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817598(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82817598 size=8
    let mut pc: u32 = 0x82817598;
    'dispatch: loop {
        match pc {
            0x82817598 => {
    //   block [0x82817598..0x828175A0)
	// 82817598: 8063022C  lwz r3, 0x22c(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(556 as u32) ) } as u64;
	// 8281759C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175A0 size=12
    let mut pc: u32 = 0x828175A0;
    'dispatch: loop {
        match pc {
            0x828175A0 => {
    //   block [0x828175A0..0x828175AC)
	// 828175A0: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 828175A4: 386B9BC9  addi r3, r11, -0x6437
	ctx.r[3].s64 = ctx.r[11].s64 + -25655;
	// 828175A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175B0 size=12
    let mut pc: u32 = 0x828175B0;
    'dispatch: loop {
        match pc {
            0x828175B0 => {
    //   block [0x828175B0..0x828175BC)
	// 828175B0: 3D608336  lis r11, -0x7cca
	ctx.r[11].s64 = -2093613056;
	// 828175B4: 386BAE38  addi r3, r11, -0x51c8
	ctx.r[3].s64 = ctx.r[11].s64 + -20936;
	// 828175B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175C0 size=4
    let mut pc: u32 = 0x828175C0;
    'dispatch: loop {
        match pc {
            0x828175C0 => {
    //   block [0x828175C0..0x828175C4)
	// 828175C0: 4BCF8580  b 0x8250fb40
	sub_8250FB40(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175C8 size=8
    let mut pc: u32 = 0x828175C8;
    'dispatch: loop {
        match pc {
            0x828175C8 => {
    //   block [0x828175C8..0x828175D0)
	// 828175C8: 90830244  stw r4, 0x244(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(580 as u32), ctx.r[4].u32 ) };
	// 828175CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175D0 size=8
    let mut pc: u32 = 0x828175D0;
    'dispatch: loop {
        match pc {
            0x828175D0 => {
    //   block [0x828175D0..0x828175D8)
	// 828175D0: 90830240  stw r4, 0x240(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(576 as u32), ctx.r[4].u32 ) };
	// 828175D4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175D8 size=16
    let mut pc: u32 = 0x828175D8;
    'dispatch: loop {
        match pc {
            0x828175D8 => {
    //   block [0x828175D8..0x828175E8)
	// 828175D8: 8163023C  lwz r11, 0x23c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(572 as u32) ) } as u64;
	// 828175DC: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 828175E0: 9163023C  stw r11, 0x23c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(572 as u32), ctx.r[11].u32 ) };
	// 828175E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175E8 size=16
    let mut pc: u32 = 0x828175E8;
    'dispatch: loop {
        match pc {
            0x828175E8 => {
    //   block [0x828175E8..0x828175F8)
	// 828175E8: 8163023C  lwz r11, 0x23c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(572 as u32) ) } as u64;
	// 828175EC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 828175F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 828175F4: 4D990020  bgtlr cr6
	if ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_828175F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x828175F8 size=8
    let mut pc: u32 = 0x828175F8;
    'dispatch: loop {
        match pc {
            0x828175F8 => {
    //   block [0x828175F8..0x82817600)
	// 828175F8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 828175FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817600(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82817600 size=68
    let mut pc: u32 = 0x82817600;
    'dispatch: loop {
        match pc {
            0x82817600 => {
    //   block [0x82817600..0x82817644)
	// 82817600: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82817604: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82817608: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8281760C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82817610: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82817614: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82817618: 816B004C  lwz r11, 0x4c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 8281761C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82817620: 4E800421  bctrl
	ctx.lr = 0x82817624;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82817624: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82817628: 387F0018  addi r3, r31, 0x18
	ctx.r[3].s64 = ctx.r[31].s64 + 24;
	// 8281762C: 485DC24D  bl 0x82df3878
	ctx.lr = 0x82817630;
	sub_82DF3878(ctx, base);
	// 82817630: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82817634: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82817638: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8281763C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82817640: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82817648 size=64
    let mut pc: u32 = 0x82817648;
    'dispatch: loop {
        match pc {
            0x82817648 => {
    //   block [0x82817648..0x82817688)
	// 82817648: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281764C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82817650: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82817654: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82817658: 4BFD4B09  bl 0x827ec160
	ctx.lr = 0x8281765C;
	sub_827EC160(ctx, base);
	// 8281765C: 7C7F1B79  or. r31, r3, r3
	ctx.r[31].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82817660: 41820014  beq 0x82817674
	if ctx.cr[0].eq {
	pc = 0x82817674; continue 'dispatch;
	}
	// 82817664: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82817668: 4BFD7579  bl 0x827eebe0
	ctx.lr = 0x8281766C;
	sub_827EEBE0(ctx, base);
	// 8281766C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82817670: 4BFD6731  bl 0x827edda0
	ctx.lr = 0x82817674;
	sub_827EDDA0(ctx, base);
	// 82817674: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82817678: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8281767C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82817680: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82817684: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817688(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82817688 size=128
    let mut pc: u32 = 0x82817688;
    'dispatch: loop {
        match pc {
            0x82817688 => {
    //   block [0x82817688..0x82817708)
	// 82817688: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281768C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82817690: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82817694: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82817698: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8281769C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 828176A0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 828176A4: 4BFD39ED  bl 0x827eb090
	ctx.lr = 0x828176A8;
	sub_827EB090(ctx, base);
	// 828176A8: 807F020C  lwz r3, 0x20c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(524 as u32) ) } as u64;
	// 828176AC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828176B0: 419A000C  beq cr6, 0x828176bc
	if ctx.cr[6].eq {
	pc = 0x828176BC; continue 'dispatch;
	}
	// 828176B4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828176B8: 4BFDA701  bl 0x827f1db8
	ctx.lr = 0x828176BC;
	sub_827F1DB8(ctx, base);
	// 828176BC: 807F0214  lwz r3, 0x214(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(532 as u32) ) } as u64;
	// 828176C0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 828176C4: 419A000C  beq cr6, 0x828176d0
	if ctx.cr[6].eq {
	pc = 0x828176D0; continue 'dispatch;
	}
	// 828176C8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 828176CC: 4BFDA6ED  bl 0x827f1db8
	ctx.lr = 0x828176D0;
	sub_827F1DB8(ctx, base);
	// 828176D0: 83DF021C  lwz r30, 0x21c(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(540 as u32) ) } as u64;
	// 828176D4: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 828176D8: 419A0018  beq cr6, 0x828176f0
	if ctx.cr[6].eq {
	pc = 0x828176F0; continue 'dispatch;
	}
	// 828176DC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 828176E0: 481FBFA1  bl 0x82a13680
	ctx.lr = 0x828176E4;
	sub_82A13680(ctx, base);
	// 828176E4: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 828176E8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 828176EC: 4832F4BD  bl 0x82b46ba8
	ctx.lr = 0x828176F0;
	sub_82B46BA8(ctx, base);
	// 828176F0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 828176F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 828176F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 828176FC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82817700: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82817704: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817708(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82817708 size=12
    let mut pc: u32 = 0x82817708;
    'dispatch: loop {
        match pc {
            0x82817708 => {
    //   block [0x82817708..0x82817714)
	// 82817708: 8063021C  lwz r3, 0x21c(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(540 as u32) ) } as u64;
	// 8281770C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82817710: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817714(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82817714 size=8
    let mut pc: u32 = 0x82817714;
    'dispatch: loop {
        match pc {
            0x82817714 => {
    //   block [0x82817714..0x8281771C)
	// 82817714: 4832EFB4  b 0x82b466c8
	sub_82B466C8(ctx, base);
	return;
	// 82817718: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82817720 size=12
    let mut pc: u32 = 0x82817720;
    'dispatch: loop {
        match pc {
            0x82817720 => {
    //   block [0x82817720..0x8281772C)
	// 82817720: 8063021C  lwz r3, 0x21c(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(540 as u32) ) } as u64;
	// 82817724: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82817728: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8281772C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8281772C size=8
    let mut pc: u32 = 0x8281772C;
    'dispatch: loop {
        match pc {
            0x8281772C => {
    //   block [0x8281772C..0x82817734)
	// 8281772C: 4832F294  b 0x82b469c0
	sub_82B469C0(ctx, base);
	return;
	// 82817730: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82817738(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82817738 size=56
    let mut pc: u32 = 0x82817738;
    'dispatch: loop {
        match pc {
            0x82817738 => {
    //   block [0x82817738..0x82817770)
	// 82817738: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8281773C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82817740: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82817744: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82817748: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8281774C: 481FBF35  bl 0x82a13680
	ctx.lr = 0x82817750;
	sub_82A13680(ctx, base);
	// 82817750: 817F0018  lwz r11, 0x18(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82817754: 13E018C7  vcmpequd (lvx128) v31, v0, v3
	tmp.u32 = ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}



pub fn sub_831D84D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D84D0 size=88
    let mut pc: u32 = 0x831D84D0;
    'dispatch: loop {
        match pc {
            0x831D84D0 => {
    //   block [0x831D84D0..0x831D8528)
	// 831D84D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D84D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D84D8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D84DC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D84E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D84E4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D84E8: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831D84EC: 392BFF60  addi r9, r11, -0xa0
	ctx.r[9].s64 = ctx.r[11].s64 + -160;
	// 831D84F0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D84F4: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D84F8: 419A0018  beq cr6, 0x831d8510
	if ctx.cr[6].eq {
	pc = 0x831D8510; continue 'dispatch;
	}
	// 831D84FC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8500: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831D8504: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831D8508: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831D850C: 480041B5  bl 0x831dc6c0
	ctx.lr = 0x831D8510;
	sub_831DC6C0(ctx, base);
	// 831D8510: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8514: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831D8518: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D851C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D8520: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D8524: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8528(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8528 size=272
    let mut pc: u32 = 0x831D8528;
    'dispatch: loop {
        match pc {
            0x831D8528 => {
    //   block [0x831D8528..0x831D8638)
	// 831D8528: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D852C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D8530: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831D8534: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D8538: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D853C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831D8540: 547E06BE  clrlwi r30, r3, 0x1a
	ctx.r[30].u64 = ctx.r[3].u32 as u64 & 0x0000003Fu64;
	// 831D8544: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 831D8548: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831D854C: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 831D8550: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D8554: 992B0000  stb r9, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 831D8558: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D855C: 4200FFF8  bdnz 0x831d8554
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831D8554; continue 'dispatch;
	}
	// 831D8560: 4806A45D  bl 0x832429bc
	ctx.lr = 0x831D8564;
	// extern call 0x832429BC → crate::xboxkrnl::KeGetCurrentProcessType
	crate::xboxkrnl::KeGetCurrentProcessType(ctx, base);
	// 831D8564: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 831D8568: 409A00A8  bne cr6, 0x831d8610
	if !ctx.cr[6].eq {
	pc = 0x831D8610; continue 'dispatch;
	}
	// 831D856C: 57CB063E  clrlwi r11, r30, 0x18
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	// 831D8570: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D8574: 409A0008  bne cr6, 0x831d857c
	if !ctx.cr[6].eq {
	pc = 0x831D857C; continue 'dispatch;
	}
	// 831D8578: 3BC00010  li r30, 0x10
	ctx.r[30].s64 = 16;
	// 831D857C: 57C6063E  clrlwi r6, r30, 0x18
	ctx.r[6].u64 = ctx.r[30].u32 as u64 & 0x000000FFu64;
	// 831D8580: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8584: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 831D8588: 38E00002  li r7, 2
	ctx.r[7].s64 = 2;
	// 831D858C: 550A07FE  clrlwi r10, r8, 0x1f
	ctx.r[10].u64 = ctx.r[8].u32 as u64 & 0x00000001u64;
	// 831D8590: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D8594: 419A0024  beq cr6, 0x831d85b8
	if ctx.cr[6].eq {
	pc = 0x831D85B8; continue 'dispatch;
	}
	// 831D8598: 7D4BFA14  add r10, r11, r31
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831D859C: 98EA0002  stb r7, 2(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(2 as u32), ctx.r[7].u8 ) };
	// 831D85A0: 895F0000  lbz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D85A4: 893F0001  lbz r9, 1(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(1 as u32) ) } as u64;
	// 831D85A8: 38890001  addi r4, r9, 1
	ctx.r[4].s64 = ctx.r[9].s64 + 1;
	// 831D85AC: 38AA0001  addi r5, r10, 1
	ctx.r[5].s64 = ctx.r[10].s64 + 1;
	// 831D85B0: 989F0001  stb r4, 1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(1 as u32), ctx.r[4].u8 ) };
	// 831D85B4: 98BF0000  stb r5, 0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u8 ) };
	// 831D85B8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D85BC: 5508F87E  srwi r8, r8, 1
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shr(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831D85C0: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 831D85C4: 4198FFC8  blt cr6, 0x831d858c
	if ctx.cr[6].lt {
	pc = 0x831D858C; continue 'dispatch;
	}
	// 831D85C8: 54CB06F6  rlwinm r11, r6, 0, 0x1b, 0x1b
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 831D85CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D85D0: 419A0010  beq cr6, 0x831d85e0
	if ctx.cr[6].eq {
	pc = 0x831D85E0; continue 'dispatch;
	}
	// 831D85D4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D85D8: 997F0006  stb r11, 6(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(6 as u32), ctx.r[11].u8 ) };
	// 831D85DC: 48000044  b 0x831d8620
	pc = 0x831D8620; continue 'dispatch;
	// 831D85E0: 39600005  li r11, 5
	ctx.r[11].s64 = 5;
	// 831D85E4: 395F0002  addi r10, r31, 2
	ctx.r[10].s64 = ctx.r[31].s64 + 2;
	// 831D85E8: 7D2A58AE  lbzx r9, r10, r11
	ctx.r[9].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831D85EC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D85F0: 409A0010  bne cr6, 0x831d8600
	if !ctx.cr[6].eq {
	pc = 0x831D8600; continue 'dispatch;
	}
	// 831D85F4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D85F8: 4080FFF0  bge 0x831d85e8
	if !ctx.cr[0].lt {
	pc = 0x831D85E8; continue 'dispatch;
	}
	// 831D85FC: 48000024  b 0x831d8620
	pc = 0x831D8620; continue 'dispatch;
	// 831D8600: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831D8604: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831D8608: 994B0002  stb r10, 2(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(2 as u32), ctx.r[10].u8 ) };
	// 831D860C: 48000014  b 0x831d8620
	pc = 0x831D8620; continue 'dispatch;
	// 831D8610: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D8614: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831D8618: 997F0001  stb r11, 1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(1 as u32), ctx.r[11].u8 ) };
	// 831D861C: 995F0006  stb r10, 6(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(6 as u32), ctx.r[10].u8 ) };
	// 831D8620: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831D8624: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D8628: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D862C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831D8630: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D8634: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8638(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D8638 size=12
    let mut pc: u32 = 0x831D8638;
    'dispatch: loop {
        match pc {
            0x831D8638 => {
    //   block [0x831D8638..0x831D8644)
	// 831D8638: 81630130  lwz r11, 0x130(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D863C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8640: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8644(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D8644 size=208
    let mut pc: u32 = 0x831D8644;
    'dispatch: loop {
        match pc {
            0x831D8644 => {
    //   block [0x831D8644..0x831D8714)
	// 831D8644: 896D010C  lbz r11, 0x10c(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831D8648: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831D864C: 7D4B21AE  stbx r10, r11, r4
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32), ctx.r[10].u8) };
	// 831D8650: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D8654: 81230148  lwz r9, 0x148(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(328 as u32) ) } as u64;
	// 831D8658: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D865C: 409A0008  bne cr6, 0x831d8664
	if !ctx.cr[6].eq {
	pc = 0x831D8664; continue 'dispatch;
	}
	// 831D8660: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8664: 81230144  lwz r9, 0x144(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(324 as u32) ) } as u64;
	// 831D8668: 7968C1C6  sldi r8, r11, 0x38
	ctx.r[8].u64 = ctx.r[11].u64.wrapping_shl(56);
	ctx.r[8].u32 = ctx.r[8].u64 as u32;
	// 831D866C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D8670: 7D0A4674  sradi r10, r8, 8
	ctx.xer.ca = (ctx.r[8].s64 < 0) && ((ctx.r[8].u64 & ((1u64 << 8) - 1)) != 0);
	ctx.r[10].s64 = ctx.r[8].s64 >> 8;
	// 831D8674: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D8678: 409A0008  bne cr6, 0x831d8680
	if !ctx.cr[6].eq {
	pc = 0x831D8680; continue 'dispatch;
	}
	// 831D867C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8680: 796BC1C6  sldi r11, r11, 0x38
	ctx.r[11].u64 = ctx.r[11].u64.wrapping_shl(56);
	ctx.r[11].u32 = ctx.r[11].u64 as u32;
	// 831D8684: 81230140  lwz r9, 0x140(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(320 as u32) ) } as u64;
	// 831D8688: 7D685378  or r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 831D868C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D8690: 7D0A4674  sradi r10, r8, 8
	ctx.xer.ca = (ctx.r[8].s64 < 0) && ((ctx.r[8].u64 & ((1u64 << 8) - 1)) != 0);
	ctx.r[10].s64 = ctx.r[8].s64 >> 8;
	// 831D8694: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D8698: 409A0008  bne cr6, 0x831d86a0
	if !ctx.cr[6].eq {
	pc = 0x831D86A0; continue 'dispatch;
	}
	// 831D869C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D86A0: 796BC1C6  sldi r11, r11, 0x38
	ctx.r[11].u64 = ctx.r[11].u64.wrapping_shl(56);
	ctx.r[11].u32 = ctx.r[11].u64 as u32;
	// 831D86A4: 8123013C  lwz r9, 0x13c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(316 as u32) ) } as u64;
	// 831D86A8: 7D685378  or r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 831D86AC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D86B0: 7D0A4674  sradi r10, r8, 8
	ctx.xer.ca = (ctx.r[8].s64 < 0) && ((ctx.r[8].u64 & ((1u64 << 8) - 1)) != 0);
	ctx.r[10].s64 = ctx.r[8].s64 >> 8;
	// 831D86B4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D86B8: 409A0008  bne cr6, 0x831d86c0
	if !ctx.cr[6].eq {
	pc = 0x831D86C0; continue 'dispatch;
	}
	// 831D86BC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D86C0: 796BC1C6  sldi r11, r11, 0x38
	ctx.r[11].u64 = ctx.r[11].u64.wrapping_shl(56);
	ctx.r[11].u32 = ctx.r[11].u64 as u32;
	// 831D86C4: 81230138  lwz r9, 0x138(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(312 as u32) ) } as u64;
	// 831D86C8: 7D685378  or r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 831D86CC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D86D0: 7D0A4674  sradi r10, r8, 8
	ctx.xer.ca = (ctx.r[8].s64 < 0) && ((ctx.r[8].u64 & ((1u64 << 8) - 1)) != 0);
	ctx.r[10].s64 = ctx.r[8].s64 >> 8;
	// 831D86D4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831D86D8: 409A0008  bne cr6, 0x831d86e0
	if !ctx.cr[6].eq {
	pc = 0x831D86E0; continue 'dispatch;
	}
	// 831D86DC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D86E0: 796BC1C6  sldi r11, r11, 0x38
	ctx.r[11].u64 = ctx.r[11].u64.wrapping_shl(56);
	ctx.r[11].u32 = ctx.r[11].u64 as u32;
	// 831D86E4: 81230134  lwz r9, 0x134(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(308 as u32) ) } as u64;
	// 831D86E8: 7D685378  or r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 | ctx.r[10].u64;
	// 831D86EC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D86F0: 7D094674  sradi r9, r8, 8
	ctx.xer.ca = (ctx.r[8].s64 < 0) && ((ctx.r[8].u64 & ((1u64 << 8) - 1)) != 0);
	ctx.r[9].s64 = ctx.r[8].s64 >> 8;
	// 831D86F4: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831D86F8: 409A0008  bne cr6, 0x831d8700
	if !ctx.cr[6].eq {
	pc = 0x831D8700; continue 'dispatch;
	}
	// 831D86FC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8700: E9640000  ld r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	// 831D8704: 794AC1C6  sldi r10, r10, 0x38
	ctx.r[10].u64 = ctx.r[10].u64.wrapping_shl(56);
	ctx.r[10].u32 = ctx.r[10].u64 as u32;
	// 831D8708: 7D4A4B78  or r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 831D870C: 2F2B0000  cmpdi cr6, r11, 0
	ctx.cr[6].compare_i64(ctx.r[11].s64, 0, &mut ctx.xer);
	// 831D8710: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8714(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D8714 size=28
    let mut pc: u32 = 0x831D8714;
    'dispatch: loop {
        match pc {
            0x831D8714 => {
    //   block [0x831D8714..0x831D8730)
	// 831D8714: 7F2A5800  cmpd cr6, r10, r11
	ctx.cr[6].compare_i64(ctx.r[10].s64, ctx.r[11].s64, &mut ctx.xer);
	// 831D8718: 419A0018  beq cr6, 0x831d8730
	if ctx.cr[6].eq {
		sub_831D8730(ctx, base);
		return;
	}
	// 831D871C: 7FFFFB78  mr r31, r31
	ctx.r[31].u64 = ctx.r[31].u64;
	// 831D8720: E9640000  ld r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	// 831D8724: 2F2B0000  cmpdi cr6, r11, 0
	ctx.cr[6].compare_i64(ctx.r[11].s64, 0, &mut ctx.xer);
	// 831D8728: 409AFFEC  bne cr6, 0x831d8714
	if !ctx.cr[6].eq {
	pc = 0x831D8714; continue 'dispatch;
	}
	// 831D872C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8730(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D8730 size=12
    let mut pc: u32 = 0x831D8730;
    'dispatch: loop {
        match pc {
            0x831D8730 => {
    //   block [0x831D8730..0x831D873C)
	// 831D8730: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8734: F9640000  std r11, 0(r4)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 831D8738: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8740(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8740 size=108
    let mut pc: u32 = 0x831D8740;
    'dispatch: loop {
        match pc {
            0x831D8740 => {
    //   block [0x831D8740..0x831D87AC)
	// 831D8740: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8744: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D8748: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831D874C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D8750: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8754: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 831D8758: 3BCB0C64  addi r30, r11, 0xc64
	ctx.r[30].s64 = ctx.r[11].s64 + 3172;
	// 831D875C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8760: 4806A20D  bl 0x8324296c
	ctx.lr = 0x831D8764;
	// extern call 0x8324296C → crate::xboxkrnl::RtlEnterCriticalSection
	crate::xboxkrnl::RtlEnterCriticalSection(ctx, base);
	// 831D8764: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8768: 3BEBD548  addi r31, r11, -0x2ab8
	ctx.r[31].s64 = ctx.r[11].s64 + -10936;
	// 831D876C: 816BD548  lwz r11, -0x2ab8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10936 as u32) ) } as u64;
	// 831D8770: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D8774: 419A0018  beq cr6, 0x831d878c
	if ctx.cr[6].eq {
	pc = 0x831D878C; continue 'dispatch;
	}
	// 831D8778: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D877C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D8780: 4806A37D  bl 0x83242afc
	ctx.lr = 0x831D8784;
	// extern call 0x83242AFC → crate::xboxkrnl::ExRegisterTitleTerminateNotification
	crate::xboxkrnl::ExRegisterTitleTerminateNotification(ctx, base);
	// 831D8784: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8788: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D878C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8790: 4806A1CD  bl 0x8324295c
	ctx.lr = 0x831D8794;
	// extern call 0x8324295C → crate::xboxkrnl::RtlLeaveCriticalSection
	crate::xboxkrnl::RtlLeaveCriticalSection(ctx, base);
	// 831D8794: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831D8798: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D879C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D87A0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831D87A4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D87A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D87B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D87B0 size=8
    let mut pc: u32 = 0x831D87B0;
    'dispatch: loop {
        match pc {
            0x831D87B0 => {
    //   block [0x831D87B0..0x831D87B8)
	// 831D87B0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D87B4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D87B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D87B8 size=20
    let mut pc: u32 = 0x831D87B8;
    'dispatch: loop {
        match pc {
            0x831D87B8 => {
    //   block [0x831D87B8..0x831D87CC)
	// 831D87B8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D87BC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D87C0: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D87C4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D87C8: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D87CC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D87CC size=4
    let mut pc: u32 = 0x831D87CC;
    'dispatch: loop {
        match pc {
            0x831D87CC => {
    //   block [0x831D87CC..0x831D87D0)
	// 831D87CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D87D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D87D0 size=132
    let mut pc: u32 = 0x831D87D0;
    'dispatch: loop {
        match pc {
            0x831D87D0 => {
    //   block [0x831D87D0..0x831D8854)
	// 831D87D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D87D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D87D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831D87DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D87E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D87E4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D87E8: 83DF0008  lwz r30, 8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D87EC: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831D87F0: 419A0018  beq cr6, 0x831d8808
	if ctx.cr[6].eq {
	pc = 0x831D8808; continue 'dispatch;
	}
	// 831D87F4: 57C3003E  slwi r3, r30, 0
	ctx.r[3].u32 = ctx.r[30].u32.wrapping_shl(0);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831D87F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D87FC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8800: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D8804: 4E800421  bctrl
	ctx.lr = 0x831D8808;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D8808: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D880C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D8810: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8814: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8818: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D881C: 4E800421  bctrl
	ctx.lr = 0x831D8820;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D8820: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831D8824: 419A0018  beq cr6, 0x831d883c
	if ctx.cr[6].eq {
	pc = 0x831D883C; continue 'dispatch;
	}
	// 831D8828: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D882C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8830: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8834: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D8838: 4E800421  bctrl
	ctx.lr = 0x831D883C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D883C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831D8840: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D8844: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D8848: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831D884C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D8850: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8858(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8858 size=384
    let mut pc: u32 = 0x831D8858;
    'dispatch: loop {
        match pc {
            0x831D8858 => {
    //   block [0x831D8858..0x831D89D8)
	// 831D8858: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D885C: 4BFCF905  bl 0x831a8160
	ctx.lr = 0x831D8860;
	sub_831A8130(ctx, base);
	// 831D8860: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8864: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831D8868: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831D886C: 4806A8F1  bl 0x8324315c
	ctx.lr = 0x831D8870;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8870: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8874: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D8878: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D887C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D8880: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8884: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8888: 419A0010  beq cr6, 0x831d8898
	if ctx.cr[6].eq {
	pc = 0x831D8898; continue 'dispatch;
	}
	// 831D888C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8890: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D8894: 419A0018  beq cr6, 0x831d88ac
	if ctx.cr[6].eq {
	pc = 0x831D88AC; continue 'dispatch;
	}
	// 831D8898: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D889C: 4806A1E1  bl 0x83242a7c
	ctx.lr = 0x831D88A0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D88A0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D88A4: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831D88A8: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831D88AC: 57AA34B2  rlwinm r10, r29, 6, 0x12, 0x19
	ctx.r[10].u64 = ctx.r[29].u32 as u64 & 0x03FFFFFFu64;
	// 831D88B0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D88B4: 7D4AD214  add r10, r10, r26
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[26].u64;
	// 831D88B8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D88BC: 3B600008  li r27, 8
	ctx.r[27].s64 = 8;
	// 831D88C0: 3B8A00A8  addi r28, r10, 0xa8
	ctx.r[28].s64 = ctx.r[10].s64 + 168;
	// 831D88C4: 939A0128  stw r28, 0x128(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(296 as u32), ctx.r[28].u32 ) };
	// 831D88C8: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D88CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D88D0: 419A00A0  beq cr6, 0x831d8970
	if ctx.cr[6].eq {
	pc = 0x831D8970; continue 'dispatch;
	}
	// 831D88D4: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D88D8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D88DC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831D88E0: 419A0040  beq cr6, 0x831d8920
	if ctx.cr[6].eq {
	pc = 0x831D8920; continue 'dispatch;
	}
	// 831D88E4: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D88E8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D88EC: 409A0034  bne cr6, 0x831d8920
	if !ctx.cr[6].eq {
	pc = 0x831D8920; continue 'dispatch;
	}
	// 831D88F0: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D88F4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D88F8: 40820028  bne 0x831d8920
	if !ctx.cr[0].eq {
	pc = 0x831D8920; continue 'dispatch;
	}
	// 831D88FC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8900: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D8904: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8908: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D890C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8910: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D8914: 4806A159  bl 0x83242a6c
	ctx.lr = 0x831D8918;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D8918: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D891C: 4806A851  bl 0x8324316c
	ctx.lr = 0x831D8920;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D8920: 807C0004  lwz r3, 4(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8924: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8928: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831D892C: 4E800421  bctrl
	ctx.lr = 0x831D8930;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D8930: 4806A82D  bl 0x8324315c
	ctx.lr = 0x831D8934;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8934: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8938: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D893C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D8940: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8944: 419A0010  beq cr6, 0x831d8954
	if ctx.cr[6].eq {
	pc = 0x831D8954; continue 'dispatch;
	}
	// 831D8948: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D894C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D8950: 419A0018  beq cr6, 0x831d8968
	if ctx.cr[6].eq {
	pc = 0x831D8968; continue 'dispatch;
	}
	// 831D8954: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8958: 4806A125  bl 0x83242a7c
	ctx.lr = 0x831D895C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D895C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8960: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831D8964: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831D8968: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D896C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8970: 377BFFFF  addic. r27, r27, -1
	ctx.xer.ca = (ctx.r[27].u32 > (!(-1 as u32)));
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 831D8974: 3B9C0008  addi r28, r28, 8
	ctx.r[28].s64 = ctx.r[28].s64 + 8;
	// 831D8978: 4082FF4C  bne 0x831d88c4
	if !ctx.cr[0].eq {
	pc = 0x831D88C4; continue 'dispatch;
	}
	// 831D897C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8980: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D8984: 917A0128  stw r11, 0x128(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(296 as u32), ctx.r[11].u32 ) };
	// 831D8988: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D898C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8990: 419A0040  beq cr6, 0x831d89d0
	if ctx.cr[6].eq {
	pc = 0x831D89D0; continue 'dispatch;
	}
	// 831D8994: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8998: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831D899C: 409A0034  bne cr6, 0x831d89d0
	if !ctx.cr[6].eq {
	pc = 0x831D89D0; continue 'dispatch;
	}
	// 831D89A0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D89A4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D89A8: 40820028  bne 0x831d89d0
	if !ctx.cr[0].eq {
	pc = 0x831D89D0; continue 'dispatch;
	}
	// 831D89AC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D89B0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D89B4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D89B8: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D89BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D89C0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D89C4: 4806A0A9  bl 0x83242a6c
	ctx.lr = 0x831D89C8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D89C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D89CC: 4806A7A1  bl 0x8324316c
	ctx.lr = 0x831D89D0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D89D0: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831D89D4: 4BFCF7DC  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D89D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D89D8 size=316
    let mut pc: u32 = 0x831D89D8;
    'dispatch: loop {
        match pc {
            0x831D89D8 => {
    //   block [0x831D89D8..0x831D8B14)
	// 831D89D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D89DC: 4BFCF785  bl 0x831a8160
	ctx.lr = 0x831D89E0;
	sub_831A8130(ctx, base);
	// 831D89E0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D89E4: 816D0100  lwz r11, 0x100(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(256 as u32) ) } as u64;
	// 831D89E8: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 831D89EC: 8143012C  lwz r10, 0x12c(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(300 as u32) ) } as u64;
	// 831D89F0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D89F4: 419A005C  beq cr6, 0x831d8a50
	if ctx.cr[6].eq {
	pc = 0x831D8A50; continue 'dispatch;
	}
	// 831D89F8: 894D010C  lbz r10, 0x10c(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831D89FC: 394A0053  addi r10, r10, 0x53
	ctx.r[10].s64 = ctx.r[10].s64 + 83;
	// 831D8A00: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831D8A04: 7D09182E  lwzx r8, r9, r3
	ctx.r[8].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32)) } as u64;
	// 831D8A08: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831D8A0C: 419A0044  beq cr6, 0x831d8a50
	if ctx.cr[6].eq {
	pc = 0x831D8A50; continue 'dispatch;
	}
	// 831D8A10: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D8A14: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 831D8A18: 3BEAD530  addi r31, r10, -0x2ad0
	ctx.r[31].s64 = ctx.r[10].s64 + -10960;
	// 831D8A1C: 3B630090  addi r27, r3, 0x90
	ctx.r[27].s64 = ctx.r[3].s64 + 144;
	// 831D8A20: 3B8B0C44  addi r28, r11, 0xc44
	ctx.r[28].s64 = ctx.r[11].s64 + 3140;
	// 831D8A24: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8A28: 811F0004  lwz r8, 4(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8A2C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8A30: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 831D8A34: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8A38: 7F1A3840  cmplw cr6, r26, r7
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831D8A3C: 419A001C  beq cr6, 0x831d8a58
	if ctx.cr[6].eq {
	pc = 0x831D8A58; continue 'dispatch;
	}
	// 831D8A40: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831D8A44: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831D8A48: 2B0A0006  cmplwi cr6, r10, 6
	ctx.cr[6].compare_u32(ctx.r[10].u32, 6 as u32, &mut ctx.xer);
	// 831D8A4C: 4198FFE8  blt cr6, 0x831d8a34
	if ctx.cr[6].lt {
	pc = 0x831D8A34; continue 'dispatch;
	}
	// 831D8A50: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831D8A54: 4BFCF75C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831D8A58: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D8A5C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831D8A60: 419A003C  beq cr6, 0x831d8a9c
	if ctx.cr[6].eq {
	pc = 0x831D8A9C; continue 'dispatch;
	}
	// 831D8A64: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831D8A68: 409A0034  bne cr6, 0x831d8a9c
	if !ctx.cr[6].eq {
	pc = 0x831D8A9C; continue 'dispatch;
	}
	// 831D8A6C: 3568FFFF  addic. r11, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8A70: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8A74: 40820028  bne 0x831d8a9c
	if !ctx.cr[0].eq {
	pc = 0x831D8A9C; continue 'dispatch;
	}
	// 831D8A78: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8A7C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D8A80: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8A84: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D8A88: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8A8C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D8A90: 48069FDD  bl 0x83242a6c
	ctx.lr = 0x831D8A94;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D8A94: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8A98: 4806A6D5  bl 0x8324316c
	ctx.lr = 0x831D8A9C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D8A9C: 83DC0018  lwz r30, 0x18(r28)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 831D8AA0: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831D8AA4: 419A0028  beq cr6, 0x831d8acc
	if ctx.cr[6].eq {
	pc = 0x831D8ACC; continue 'dispatch;
	}
	// 831D8AA8: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831D8AAC: 387C0004  addi r3, r28, 4
	ctx.r[3].s64 = ctx.r[28].s64 + 4;
	// 831D8AB0: 48069EAD  bl 0x8324295c
	ctx.lr = 0x831D8AB4;
	// extern call 0x8324295C → crate::xboxkrnl::RtlLeaveCriticalSection
	crate::xboxkrnl::RtlLeaveCriticalSection(ctx, base);
	// 831D8AB4: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831D8AB8: 4082FFF4  bne 0x831d8aac
	if !ctx.cr[0].eq {
	pc = 0x831D8AAC; continue 'dispatch;
	}
	// 831D8ABC: 387C0004  addi r3, r28, 4
	ctx.r[3].s64 = ctx.r[28].s64 + 4;
	// 831D8AC0: 48069EAD  bl 0x8324296c
	ctx.lr = 0x831D8AC4;
	// extern call 0x8324296C → crate::xboxkrnl::RtlEnterCriticalSection
	crate::xboxkrnl::RtlEnterCriticalSection(ctx, base);
	// 831D8AC4: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D8AC8: 4082FFF4  bne 0x831d8abc
	if !ctx.cr[0].eq {
	pc = 0x831D8ABC; continue 'dispatch;
	}
	// 831D8ACC: 4806A691  bl 0x8324315c
	ctx.lr = 0x831D8AD0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8AD0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8AD4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D8AD8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D8ADC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8AE0: 419A0010  beq cr6, 0x831d8af0
	if ctx.cr[6].eq {
	pc = 0x831D8AF0; continue 'dispatch;
	}
	// 831D8AE4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8AE8: 7F1E4840  cmplw cr6, r30, r9
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831D8AEC: 419A001C  beq cr6, 0x831d8b08
	if ctx.cr[6].eq {
	pc = 0x831D8B08; continue 'dispatch;
	}
	// 831D8AF0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8AF4: 48069F89  bl 0x83242a7c
	ctx.lr = 0x831D8AF8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D8AF8: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 831D8AFC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8B00: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831D8B04: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831D8B08: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 831D8B0C: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831D8B10: 4BFFFF1C  b 0x831d8a2c
	pc = 0x831D8A2C; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8B18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8B18 size=68
    let mut pc: u32 = 0x831D8B18;
    'dispatch: loop {
        match pc {
            0x831D8B18 => {
    //   block [0x831D8B18..0x831D8B5C)
	// 831D8B18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8B1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D8B20: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8B24: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8B28: 394BD548  addi r10, r11, -0x2ab8
	ctx.r[10].s64 = ctx.r[11].s64 + -10936;
	// 831D8B2C: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831D8B30: 409A001C  bne cr6, 0x831d8b4c
	if !ctx.cr[6].eq {
	pc = 0x831D8B4C; continue 'dispatch;
	}
	// 831D8B34: 4BFFFC0D  bl 0x831d8740
	ctx.lr = 0x831D8B38;
	sub_831D8740(ctx, base);
	// 831D8B38: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8B3C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831D8B40: 386BD558  addi r3, r11, -0x2aa8
	ctx.r[3].s64 = ctx.r[11].s64 + -10920;
	// 831D8B44: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D8B48: 4806A135  bl 0x83242c7c
	ctx.lr = 0x831D8B4C;
	// extern call 0x83242C7C → crate::xboxkrnl::KeSetEvent
	crate::xboxkrnl::KeSetEvent(ctx, base);
	// 831D8B4C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831D8B50: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D8B54: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D8B58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8B60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8B60 size=148
    let mut pc: u32 = 0x831D8B60;
    'dispatch: loop {
        match pc {
            0x831D8B60 => {
    //   block [0x831D8B60..0x831D8BF4)
	// 831D8B60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8B64: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D8B68: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831D8B6C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D8B70: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8B74: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D8B78: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D8B7C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831D8B80: 394BFF78  addi r10, r11, -0x88
	ctx.r[10].s64 = ctx.r[11].s64 + -136;
	// 831D8B84: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8B88: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831D8B8C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D8B90: 419A001C  beq cr6, 0x831d8bac
	if ctx.cr[6].eq {
	pc = 0x831D8BAC; continue 'dispatch;
	}
	// 831D8B94: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8B98: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8B9C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D8BA0: 4E800421  bctrl
	ctx.lr = 0x831D8BA4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D8BA4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831D8BA8: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831D8BAC: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D8BB0: 57CA07FE  clrlwi r10, r30, 0x1f
	ctx.r[10].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831D8BB4: 392BFF64  addi r9, r11, -0x9c
	ctx.r[9].s64 = ctx.r[11].s64 + -156;
	// 831D8BB8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D8BBC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D8BC0: 419A0018  beq cr6, 0x831d8bd8
	if ctx.cr[6].eq {
	pc = 0x831D8BD8; continue 'dispatch;
	}
	// 831D8BC4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8BC8: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831D8BCC: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831D8BD0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831D8BD4: 48003AED  bl 0x831dc6c0
	ctx.lr = 0x831D8BD8;
	sub_831DC6C0(ctx, base);
	// 831D8BD8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8BDC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831D8BE0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D8BE4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D8BE8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831D8BEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D8BF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8BF8 size=188
    let mut pc: u32 = 0x831D8BF8;
    'dispatch: loop {
        match pc {
            0x831D8BF8 => {
    //   block [0x831D8BF8..0x831D8CB4)
	// 831D8BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8BFC: 4BFCF56D  bl 0x831a8168
	ctx.lr = 0x831D8C00;
	sub_831A8130(ctx, base);
	// 831D8C00: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8C04: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831D8C08: 4806A555  bl 0x8324315c
	ctx.lr = 0x831D8C0C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8C0C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8C10: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D8C14: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D8C18: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831D8C1C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8C20: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8C24: 419A0010  beq cr6, 0x831d8c34
	if ctx.cr[6].eq {
	pc = 0x831D8C34; continue 'dispatch;
	}
	// 831D8C28: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8C2C: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D8C30: 419A0018  beq cr6, 0x831d8c48
	if ctx.cr[6].eq {
	pc = 0x831D8C48; continue 'dispatch;
	}
	// 831D8C34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8C38: 48069E45  bl 0x83242a7c
	ctx.lr = 0x831D8C3C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D8C3C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8C40: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831D8C44: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831D8C48: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D8C4C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D8C50: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8C54: 817E0024  lwz r11, 0x24(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 831D8C58: 813E0028  lwz r9, 0x28(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) } as u64;
	// 831D8C5C: 917E0028  stw r11, 0x28(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 831D8C60: 913E0024  stw r9, 0x24(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 831D8C64: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8C68: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8C6C: 419A0040  beq cr6, 0x831d8cac
	if ctx.cr[6].eq {
	pc = 0x831D8CAC; continue 'dispatch;
	}
	// 831D8C70: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8C74: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831D8C78: 409A0034  bne cr6, 0x831d8cac
	if !ctx.cr[6].eq {
	pc = 0x831D8CAC; continue 'dispatch;
	}
	// 831D8C7C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8C80: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8C84: 40820028  bne 0x831d8cac
	if !ctx.cr[0].eq {
	pc = 0x831D8CAC; continue 'dispatch;
	}
	// 831D8C88: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8C8C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D8C90: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8C94: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D8C98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8C9C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D8CA0: 48069DCD  bl 0x83242a6c
	ctx.lr = 0x831D8CA4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D8CA4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8CA8: 4806A4C5  bl 0x8324316c
	ctx.lr = 0x831D8CAC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D8CAC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831D8CB0: 4BFCF508  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8CB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8CB8 size=232
    let mut pc: u32 = 0x831D8CB8;
    'dispatch: loop {
        match pc {
            0x831D8CB8 => {
    //   block [0x831D8CB8..0x831D8DA0)
	// 831D8CB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8CBC: 4BFCF4B1  bl 0x831a816c
	ctx.lr = 0x831D8CC0;
	sub_831A8130(ctx, base);
	// 831D8CC0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8CC4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D8CC8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831D8CCC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8CD0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D8CD4: 419A000C  beq cr6, 0x831d8ce0
	if ctx.cr[6].eq {
	pc = 0x831D8CE0; continue 'dispatch;
	}
	// 831D8CD8: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831D8CDC: 48000010  b 0x831d8cec
	pc = 0x831D8CEC; continue 'dispatch;
	// 831D8CE0: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D8CE4: 394BFEA8  addi r10, r11, -0x158
	ctx.r[10].s64 = ctx.r[11].s64 + -344;
	// 831D8CE8: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831D8CEC: 38810058  addi r4, r1, 0x58
	ctx.r[4].s64 = ctx.r[1].s64 + 88;
	// 831D8CF0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831D8CF4: 4800299D  bl 0x831db690
	ctx.lr = 0x831D8CF8;
	sub_831DB690(ctx, base);
	// 831D8CF8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D8CFC: 4198009C  blt cr6, 0x831d8d98
	if ctx.cr[6].lt {
	pc = 0x831D8D98; continue 'dispatch;
	}
	// 831D8D00: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 831D8D04: 895F0000  lbz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8D08: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8D0C: 2B0A0006  cmplwi cr6, r10, 6
	ctx.cr[6].compare_u32(ctx.r[10].u32, 6 as u32, &mut ctx.xer);
	// 831D8D10: F9690000  std r11, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 831D8D14: F9690008  std r11, 8(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 831D8D18: 91690010  stw r11, 0x10(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831D8D1C: 99610070  stb r11, 0x70(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u8 ) };
	// 831D8D20: 99610074  stb r11, 0x74(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u8 ) };
	// 831D8D24: 41990008  bgt cr6, 0x831d8d2c
	if ctx.cr[6].gt {
	pc = 0x831D8D2C; continue 'dispatch;
	}
	// 831D8D28: 39400006  li r10, 6
	ctx.r[10].s64 = 6;
	// 831D8D2C: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831D8D30: 99410075  stb r10, 0x75(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(117 as u32), ctx.r[10].u8 ) };
	// 831D8D34: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 831D8D38: 6169BB80  ori r9, r11, 0xbb80
	ctx.r[9].u64 = ctx.r[11].u64 | 48000;
	// 831D8D3C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 831D8D40: 91210078  stw r9, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[9].u32 ) };
	// 831D8D44: 480095BD  bl 0x831e2300
	ctx.lr = 0x831D8D48;
	sub_831E2300(ctx, base);
	// 831D8D48: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831D8D4C: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D8D50: 41980044  blt cr6, 0x831d8d94
	if ctx.cr[6].lt {
	pc = 0x831D8D94; continue 'dispatch;
	}
	// 831D8D54: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831D8D58: 887F0002  lbz r3, 2(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(2 as u32) ) } as u64;
	// 831D8D5C: 4BFFF7CD  bl 0x831d8528
	ctx.lr = 0x831D8D60;
	sub_831D8528(ctx, base);
	// 831D8D60: 89010061  lbz r8, 0x61(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(97 as u32) ) } as u64;
	// 831D8D64: 81210054  lwz r9, 0x54(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831D8D68: 895F0001  lbz r10, 1(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(1 as u32) ) } as u64;
	// 831D8D6C: 7CC849D6  mullw r6, r8, r9
	ctx.r[6].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 831D8D70: 80E10058  lwz r7, 0x58(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831D8D74: 54CB083C  slwi r11, r6, 1
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831D8D78: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D8D7C: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 831D8D80: 419A0010  beq cr6, 0x831d8d90
	if ctx.cr[6].eq {
	pc = 0x831D8D90; continue 'dispatch;
	}
	// 831D8D84: 1D4A002C  mulli r10, r10, 0x2c
	ctx.r[10].s64 = ctx.r[10].s64 * 44;
	// 831D8D88: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831D8D8C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831D8D90: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D8D94: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8D98: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 831D8D9C: 4BFCF420  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8DA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8DA0 size=436
    let mut pc: u32 = 0x831D8DA0;
    'dispatch: loop {
        match pc {
            0x831D8DA0 => {
    //   block [0x831D8DA0..0x831D8F54)
	// 831D8DA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8DA4: 4BFCF3BD  bl 0x831a8160
	ctx.lr = 0x831D8DA8;
	sub_831A8130(ctx, base);
	// 831D8DA8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8DAC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8DB0: 8B4D010C  lbz r26, 0x10c(r13)
	ctx.r[26].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831D8DB4: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D8DB8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831D8DBC: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D8DC0: 4806A39D  bl 0x8324315c
	ctx.lr = 0x831D8DC4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8DC4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8DC8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D8DCC: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D8DD0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8DD4: 419A0010  beq cr6, 0x831d8de4
	if ctx.cr[6].eq {
	pc = 0x831D8DE4; continue 'dispatch;
	}
	// 831D8DD8: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8DDC: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831D8DE0: 419A0020  beq cr6, 0x831d8e00
	if ctx.cr[6].eq {
	pc = 0x831D8E00; continue 'dispatch;
	}
	// 831D8DE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8DE8: 48069C95  bl 0x83242a7c
	ctx.lr = 0x831D8DEC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D8DEC: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831D8DF0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8DF4: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831D8DF8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831D8DFC: 48000008  b 0x831d8e04
	pc = 0x831D8E04; continue 'dispatch;
	// 831D8E00: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D8E04: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 831D8E08: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831D8E0C: 817C0024  lwz r11, 0x24(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(36 as u32) ) } as u64;
	// 831D8E10: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8E14: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D8E18: 419A00E4  beq cr6, 0x831d8efc
	if ctx.cr[6].eq {
	pc = 0x831D8EFC; continue 'dispatch;
	}
	// 831D8E1C: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8E20: 7FCB5051  subf. r30, r11, r10
	ctx.r[30].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D8E24: 418200D8  beq 0x831d8efc
	if ctx.cr[0].eq {
	pc = 0x831D8EFC; continue 'dispatch;
	}
	// 831D8E28: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831D8E2C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8E30: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D8E34: 419A0020  beq cr6, 0x831d8e54
	if ctx.cr[6].eq {
	pc = 0x831D8E54; continue 'dispatch;
	}
	// 831D8E38: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8E3C: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831D8E40: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8E44: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8E48: 91070000  stw r8, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831D8E4C: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8E50: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D8E54: 813C0028  lwz r9, 0x28(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(40 as u32) ) } as u64;
	// 831D8E58: 391A0024  addi r8, r26, 0x24
	ctx.r[8].s64 = ctx.r[26].s64 + 36;
	// 831D8E5C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D8E60: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831D8E64: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8E68: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831D8E6C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D8E70: 80C90004  lwz r6, 4(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8E74: 90CB0004  stw r6, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831D8E78: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8E7C: 80AB0004  lwz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8E80: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D8E84: 7FC7D92E  stwx r30, r7, r27
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32.wrapping_add(ctx.r[27].u32), ctx.r[30].u32) };
	// 831D8E88: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8E8C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8E90: 419A0040  beq cr6, 0x831d8ed0
	if ctx.cr[6].eq {
	pc = 0x831D8ED0; continue 'dispatch;
	}
	// 831D8E94: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8E98: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831D8E9C: 409A0034  bne cr6, 0x831d8ed0
	if !ctx.cr[6].eq {
	pc = 0x831D8ED0; continue 'dispatch;
	}
	// 831D8EA0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8EA4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8EA8: 40820028  bne 0x831d8ed0
	if !ctx.cr[0].eq {
	pc = 0x831D8ED0; continue 'dispatch;
	}
	// 831D8EAC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8EB0: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D8EB4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8EB8: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D8EBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8EC0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D8EC4: 48069BA9  bl 0x83242a6c
	ctx.lr = 0x831D8EC8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D8EC8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831D8ECC: 4806A2A1  bl 0x8324316c
	ctx.lr = 0x831D8ED0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D8ED0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8ED4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D8ED8: 814B0044  lwz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831D8EDC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D8EE0: 4E800421  bctrl
	ctx.lr = 0x831D8EE4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D8EE4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D8EE8: 4198FED8  blt cr6, 0x831d8dc0
	if ctx.cr[6].lt {
	pc = 0x831D8DC0; continue 'dispatch;
	}
	// 831D8EEC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D8EF0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831D8EF4: 480037F5  bl 0x831dc6e8
	ctx.lr = 0x831D8EF8;
	sub_831DC6E8(ctx, base);
	// 831D8EF8: 4BFFFEC8  b 0x831d8dc0
	pc = 0x831D8DC0; continue 'dispatch;
	// 831D8EFC: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D8F00: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831D8F04: 419A0038  beq cr6, 0x831d8f3c
	if ctx.cr[6].eq {
	pc = 0x831D8F3C; continue 'dispatch;
	}
	// 831D8F08: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831D8F0C: 409A0030  bne cr6, 0x831d8f3c
	if !ctx.cr[6].eq {
	pc = 0x831D8F3C; continue 'dispatch;
	}
	// 831D8F10: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8F14: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8F18: 40820024  bne 0x831d8f3c
	if !ctx.cr[0].eq {
	pc = 0x831D8F3C; continue 'dispatch;
	}
	// 831D8F1C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D8F20: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8F24: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D8F28: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8F2C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D8F30: 48069B3D  bl 0x83242a6c
	ctx.lr = 0x831D8F34;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D8F34: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831D8F38: 4806A235  bl 0x8324316c
	ctx.lr = 0x831D8F3C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D8F3C: 397A0024  addi r11, r26, 0x24
	ctx.r[11].s64 = ctx.r[26].s64 + 36;
	// 831D8F40: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D8F44: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831D8F48: 7D49D92E  stwx r10, r9, r27
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[27].u32), ctx.r[10].u32) };
	// 831D8F4C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831D8F50: 4BFCF260  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D8F58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D8F58 size=228
    let mut pc: u32 = 0x831D8F58;
    'dispatch: loop {
        match pc {
            0x831D8F58 => {
    //   block [0x831D8F58..0x831D903C)
	// 831D8F58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D8F5C: 4BFCF209  bl 0x831a8164
	ctx.lr = 0x831D8F60;
	sub_831A8130(ctx, base);
	// 831D8F60: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D8F64: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D8F68: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 831D8F6C: 4806A1F1  bl 0x8324315c
	ctx.lr = 0x831D8F70;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D8F70: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D8F74: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D8F78: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D8F7C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D8F80: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8F84: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D8F88: 419A0010  beq cr6, 0x831d8f98
	if ctx.cr[6].eq {
	pc = 0x831D8F98; continue 'dispatch;
	}
	// 831D8F8C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8F90: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D8F94: 419A0018  beq cr6, 0x831d8fac
	if ctx.cr[6].eq {
	pc = 0x831D8FAC; continue 'dispatch;
	}
	// 831D8F98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D8F9C: 48069AE1  bl 0x83242a7c
	ctx.lr = 0x831D8FA0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D8FA0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8FA4: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831D8FA8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831D8FAC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D8FB0: 3BDC0044  addi r30, r28, 0x44
	ctx.r[30].s64 = ctx.r[28].s64 + 68;
	// 831D8FB4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D8FB8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D8FBC: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D8FC0: 419A0024  beq cr6, 0x831d8fe4
	if ctx.cr[6].eq {
	pc = 0x831D8FE4; continue 'dispatch;
	}
	// 831D8FC4: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8FC8: 7C6A5851  subf. r3, r10, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	ctx.cr[0].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D8FCC: 41820018  beq 0x831d8fe4
	if ctx.cr[0].eq {
	pc = 0x831D8FE4; continue 'dispatch;
	}
	// 831D8FD0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D8FD4: 4800363D  bl 0x831dc610
	ctx.lr = 0x831D8FD8;
	sub_831DC610(ctx, base);
	// 831D8FD8: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D8FDC: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 831D8FE0: 4098FFD8  bge cr6, 0x831d8fb8
	if !ctx.cr[6].lt {
	pc = 0x831D8FB8; continue 'dispatch;
	}
	// 831D8FE4: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D8FE8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D8FEC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831D8FF0: 419A0040  beq cr6, 0x831d9030
	if ctx.cr[6].eq {
	pc = 0x831D9030; continue 'dispatch;
	}
	// 831D8FF4: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D8FF8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D8FFC: 409A0034  bne cr6, 0x831d9030
	if !ctx.cr[6].eq {
	pc = 0x831D9030; continue 'dispatch;
	}
	// 831D9000: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D9004: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D9008: 40820028  bne 0x831d9030
	if !ctx.cr[0].eq {
	pc = 0x831D9030; continue 'dispatch;
	}
	// 831D900C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D9010: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D9014: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D9018: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D901C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9020: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D9024: 48069A49  bl 0x83242a6c
	ctx.lr = 0x831D9028;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D9028: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D902C: 4806A141  bl 0x8324316c
	ctx.lr = 0x831D9030;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D9030: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D9034: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831D9038: 4BFCF17C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9040(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9040 size=232
    let mut pc: u32 = 0x831D9040;
    'dispatch: loop {
        match pc {
            0x831D9040 => {
    //   block [0x831D9040..0x831D9128)
	// 831D9040: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9044: 4BFCF125  bl 0x831a8168
	ctx.lr = 0x831D9048;
	sub_831A8130(ctx, base);
	// 831D9048: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D904C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D9050: 4806A10D  bl 0x8324315c
	ctx.lr = 0x831D9054;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D9054: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D9058: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D905C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D9060: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D9064: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9068: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D906C: 419A0010  beq cr6, 0x831d907c
	if ctx.cr[6].eq {
	pc = 0x831D907C; continue 'dispatch;
	}
	// 831D9070: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9074: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D9078: 419A0018  beq cr6, 0x831d9090
	if ctx.cr[6].eq {
	pc = 0x831D9090; continue 'dispatch;
	}
	// 831D907C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9080: 480699FD  bl 0x83242a7c
	ctx.lr = 0x831D9084;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D9084: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9088: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831D908C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831D9090: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D9094: 387C0050  addi r3, r28, 0x50
	ctx.r[3].s64 = ctx.r[28].s64 + 80;
	// 831D9098: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D909C: 4BFFFB5D  bl 0x831d8bf8
	ctx.lr = 0x831D90A0;
	sub_831D8BF8(ctx, base);
	// 831D90A0: 897C0080  lbz r11, 0x80(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D90A4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831D90A8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D90AC: 419A0028  beq cr6, 0x831d90d4
	if ctx.cr[6].eq {
	pc = 0x831D90D4; continue 'dispatch;
	}
	// 831D90B0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831D90B4: 817C007C  lwz r11, 0x7c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(124 as u32) ) } as u64;
	// 831D90B8: 7C6BEA14  add r3, r11, r29
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831D90BC: 4BFFFB3D  bl 0x831d8bf8
	ctx.lr = 0x831D90C0;
	sub_831D8BF8(ctx, base);
	// 831D90C0: 897C0080  lbz r11, 0x80(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D90C4: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831D90C8: 3BBD002C  addi r29, r29, 0x2c
	ctx.r[29].s64 = ctx.r[29].s64 + 44;
	// 831D90CC: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D90D0: 4198FFE4  blt cr6, 0x831d90b4
	if ctx.cr[6].lt {
	pc = 0x831D90B4; continue 'dispatch;
	}
	// 831D90D4: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D90D8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831D90DC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831D90E0: 419A0040  beq cr6, 0x831d9120
	if ctx.cr[6].eq {
	pc = 0x831D9120; continue 'dispatch;
	}
	// 831D90E4: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D90E8: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D90EC: 409A0034  bne cr6, 0x831d9120
	if !ctx.cr[6].eq {
	pc = 0x831D9120; continue 'dispatch;
	}
	// 831D90F0: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D90F4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D90F8: 40820028  bne 0x831d9120
	if !ctx.cr[0].eq {
	pc = 0x831D9120; continue 'dispatch;
	}
	// 831D90FC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831D9100: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D9104: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D9108: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D910C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9110: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D9114: 48069959  bl 0x83242a6c
	ctx.lr = 0x831D9118;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D9118: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D911C: 4806A051  bl 0x8324316c
	ctx.lr = 0x831D9120;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D9120: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831D9124: 4BFCF094  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9128(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9128 size=316
    let mut pc: u32 = 0x831D9128;
    'dispatch: loop {
        match pc {
            0x831D9128 => {
    //   block [0x831D9128..0x831D9264)
	// 831D9128: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D912C: 4BFCF035  bl 0x831a8160
	ctx.lr = 0x831D9130;
	sub_831A8130(ctx, base);
	// 831D9130: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9134: 549A063E  clrlwi r26, r4, 0x18
	ctx.r[26].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831D9138: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D913C: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831D9140: 419A0094  beq cr6, 0x831d91d4
	if ctx.cr[6].eq {
	pc = 0x831D91D4; continue 'dispatch;
	}
	// 831D9144: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9148: 4BFFF711  bl 0x831d8858
	ctx.lr = 0x831D914C;
	sub_831D8858(ctx, base);
	// 831D914C: 817F0040  lwz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831D9150: 3B7F008C  addi r27, r31, 0x8c
	ctx.r[27].s64 = ctx.r[31].s64 + 140;
	// 831D9154: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831D9158: 814B0044  lwz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831D915C: 806A0018  lwz r3, 0x18(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 831D9160: 4806A03D  bl 0x8324319c
	ctx.lr = 0x831D9164;
	// extern call 0x8324319C → crate::xboxkrnl::XAudioGetVoiceCategoryVolumeChangeMask
	crate::xboxkrnl::XAudioGetVoiceCategoryVolumeChangeMask(ctx, base);
	// 831D9164: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831D9168: 3B800001  li r28, 1
	ctx.r[28].s64 = 1;
	// 831D916C: 3BBF0084  addi r29, r31, 0x84
	ctx.r[29].s64 = ctx.r[31].s64 + 132;
	// 831D9170: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9174: 41980034  blt cr6, 0x831d91a8
	if ctx.cr[6].lt {
	pc = 0x831D91A8; continue 'dispatch;
	}
	// 831D9178: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D917C: 7D6AE038  and r10, r11, r28
	ctx.r[10].u64 = ctx.r[11].u64 & ctx.r[28].u64;
	// 831D9180: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D9184: 419A0010  beq cr6, 0x831d9194
	if ctx.cr[6].eq {
	pc = 0x831D9194; continue 'dispatch;
	}
	// 831D9188: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831D918C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D9190: 48069FFD  bl 0x8324318c
	ctx.lr = 0x831D9194;
	// extern call 0x8324318C → crate::xboxkrnl::XAudioGetVoiceCategoryVolume
	crate::xboxkrnl::XAudioGetVoiceCategoryVolume(ctx, base);
	// 831D9194: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831D9198: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 831D919C: 579C083E  rotlwi r28, r28, 1
	ctx.r[28].u64 = ((ctx.r[28].u32).rotate_left(1)) as u64;
	// 831D91A0: 2B1E0002  cmplwi cr6, r30, 2
	ctx.cr[6].compare_u32(ctx.r[30].u32, 2 as u32, &mut ctx.xer);
	// 831D91A4: 4198FFCC  blt cr6, 0x831d9170
	if ctx.cr[6].lt {
	pc = 0x831D9170; continue 'dispatch;
	}
	// 831D91A8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D91AC: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D91B0: 816B0130  lwz r11, 0x130(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D91B4: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 831D91B8: 4099001C  ble cr6, 0x831d91d4
	if !ctx.cr[6].gt {
	pc = 0x831D91D4; continue 'dispatch;
	}
	// 831D91BC: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D91C0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D91C4: 386AD568  addi r3, r10, -0x2a98
	ctx.r[3].s64 = ctx.r[10].s64 + -10904;
	// 831D91C8: 38ABFFFF  addi r5, r11, -1
	ctx.r[5].s64 = ctx.r[11].s64 + -1;
	// 831D91CC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D91D0: 48069FAD  bl 0x8324317c
	ctx.lr = 0x831D91D4;
	// extern call 0x8324317C → crate::xboxkrnl::KeReleaseSemaphore
	crate::xboxkrnl::KeReleaseSemaphore(ctx, base);
	// 831D91D4: 389F0050  addi r4, r31, 0x50
	ctx.r[4].s64 = ctx.r[31].s64 + 80;
	// 831D91D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D91DC: 4BFFFBC5  bl 0x831d8da0
	ctx.lr = 0x831D91E0;
	sub_831D8DA0(ctx, base);
	// 831D91E0: 389F0164  addi r4, r31, 0x164
	ctx.r[4].s64 = ctx.r[31].s64 + 356;
	// 831D91E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D91E8: 4BFFF451  bl 0x831d8638
	ctx.lr = 0x831D91EC;
	sub_831D8638(ctx, base);
	// 831D91EC: 897F0080  lbz r11, 0x80(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D91F0: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 831D91F4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831D91F8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D91FC: 419A0044  beq cr6, 0x831d9240
	if ctx.cr[6].eq {
	pc = 0x831D9240; continue 'dispatch;
	}
	// 831D9200: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831D9204: 817F007C  lwz r11, 0x7c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(124 as u32) ) } as u64;
	// 831D9208: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D920C: 7C9C5A14  add r4, r28, r11
	ctx.r[4].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831D9210: 4BFFFB91  bl 0x831d8da0
	ctx.lr = 0x831D9214;
	sub_831D8DA0(ctx, base);
	// 831D9214: 57AB1838  slwi r11, r29, 3
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831D9218: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D921C: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831D9220: 388B0164  addi r4, r11, 0x164
	ctx.r[4].s64 = ctx.r[11].s64 + 356;
	// 831D9224: 4BFFF415  bl 0x831d8638
	ctx.lr = 0x831D9228;
	sub_831D8638(ctx, base);
	// 831D9228: 897F0080  lbz r11, 0x80(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D922C: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831D9230: 6BBD0001  xori r29, r29, 1
	ctx.r[29].u64 = ctx.r[29].u64 ^ 1;
	// 831D9234: 3B9C002C  addi r28, r28, 0x2c
	ctx.r[28].s64 = ctx.r[28].s64 + 44;
	// 831D9238: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D923C: 4198FFC8  blt cr6, 0x831d9204
	if ctx.cr[6].lt {
	pc = 0x831D9204; continue 'dispatch;
	}
	// 831D9240: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831D9244: 419A0018  beq cr6, 0x831d925c
	if ctx.cr[6].eq {
	pc = 0x831D925C; continue 'dispatch;
	}
	// 831D9248: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831D924C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9250: 917F008C  stw r11, 0x8c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 831D9254: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9258: 4BFFF601  bl 0x831d8858
	ctx.lr = 0x831D925C;
	sub_831D8858(ctx, base);
	// 831D925C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831D9260: 4BFCEF50  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9268(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9268 size=132
    let mut pc: u32 = 0x831D9268;
    'dispatch: loop {
        match pc {
            0x831D9268 => {
    //   block [0x831D9268..0x831D92EC)
	// 831D9268: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D926C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D9270: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D9274: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9278: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D927C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9280: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9284: 48008705  bl 0x831e1988
	ctx.lr = 0x831D9288;
	sub_831E1988(ctx, base);
	// 831D9288: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D928C: 419A004C  beq cr6, 0x831d92d8
	if ctx.cr[6].eq {
	pc = 0x831D92D8; continue 'dispatch;
	}
	// 831D9290: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9294: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831D9298: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D929C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D92A0: 419A0020  beq cr6, 0x831d92c0
	if ctx.cr[6].eq {
	pc = 0x831D92C0; continue 'dispatch;
	}
	// 831D92A4: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D92A8: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831D92AC: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D92B0: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D92B4: 90E80000  stw r7, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 831D92B8: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D92BC: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D92C0: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D92C4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D92C8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D92CC: 480086BD  bl 0x831e1988
	ctx.lr = 0x831D92D0;
	sub_831E1988(ctx, base);
	// 831D92D0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D92D4: 409AFFBC  bne cr6, 0x831d9290
	if !ctx.cr[6].eq {
	pc = 0x831D9290; continue 'dispatch;
	}
	// 831D92D8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831D92DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D92E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D92E4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D92E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D92F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D92F0 size=1208
    let mut pc: u32 = 0x831D92F0;
    'dispatch: loop {
        match pc {
            0x831D92F0 => {
    //   block [0x831D92F0..0x831D97A8)
	// 831D92F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D92F4: 4BFCEE59  bl 0x831a814c
	ctx.lr = 0x831D92F8;
	sub_831A8130(ctx, base);
	// 831D92F8: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D92FC: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 831D9300: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D9304: 394BFF8C  addi r10, r11, -0x74
	ctx.r[10].s64 = ctx.r[11].s64 + -116;
	// 831D9308: 91570000  stw r10, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831D930C: 4B5F5ECD  bl 0x827cf1d8
	ctx.lr = 0x831D9310;
	sub_827CF1D8(ctx, base);
	// 831D9310: 81770040  lwz r11, 0x40(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(64 as u32) ) } as u64;
	// 831D9314: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D9318: 419A001C  beq cr6, 0x831d9334
	if ctx.cr[6].eq {
	pc = 0x831D9334; continue 'dispatch;
	}
	// 831D931C: 806B0044  lwz r3, 0x44(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831D9320: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9324: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9328: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831D932C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9330: 4E800421  bctrl
	ctx.lr = 0x831D9334;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9334: 81770130  lwz r11, 0x130(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D9338: 3AC00000  li r22, 0
	ctx.r[22].s64 = 0;
	// 831D933C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D9340: 419A0050  beq cr6, 0x831d9390
	if ctx.cr[6].eq {
	pc = 0x831D9390; continue 'dispatch;
	}
	// 831D9344: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D9348: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831D934C: 386BD58C  addi r3, r11, -0x2a74
	ctx.r[3].s64 = ctx.r[11].s64 + -10868;
	// 831D9350: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9354: 48069929  bl 0x83242c7c
	ctx.lr = 0x831D9358;
	// extern call 0x83242C7C → crate::xboxkrnl::KeSetEvent
	crate::xboxkrnl::KeSetEvent(ctx, base);
	// 831D9358: 3BF70134  addi r31, r23, 0x134
	ctx.r[31].s64 = ctx.r[23].s64 + 308;
	// 831D935C: 3BC00006  li r30, 6
	ctx.r[30].s64 = 6;
	// 831D9360: 3BA0FFFF  li r29, -1
	ctx.r[29].s64 = -1;
	// 831D9364: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9368: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D936C: 419A0018  beq cr6, 0x831d9384
	if ctx.cr[6].eq {
	pc = 0x831D9384; continue 'dispatch;
	}
	// 831D9370: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831D9374: 4B9F498D  bl 0x82bcdd00
	ctx.lr = 0x831D9378;
	sub_82BCDD00(ctx, base);
	// 831D9378: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D937C: 4B9F36A5  bl 0x82bcca20
	ctx.lr = 0x831D9380;
	sub_82BCCA20(ctx, base);
	// 831D9380: 92DF0000  stw r22, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[22].u32 ) };
	// 831D9384: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D9388: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831D938C: 4082FFD8  bne 0x831d9364
	if !ctx.cr[0].eq {
	pc = 0x831D9364; continue 'dispatch;
	}
	// 831D9390: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 831D9394: 3BCB0C64  addi r30, r11, 0xc64
	ctx.r[30].s64 = ctx.r[11].s64 + 3172;
	// 831D9398: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D939C: 480695D1  bl 0x8324296c
	ctx.lr = 0x831D93A0;
	// extern call 0x8324296C → crate::xboxkrnl::RtlEnterCriticalSection
	crate::xboxkrnl::RtlEnterCriticalSection(ctx, base);
	// 831D93A0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D93A4: 3BEBD548  addi r31, r11, -0x2ab8
	ctx.r[31].s64 = ctx.r[11].s64 + -10936;
	// 831D93A8: 816BD548  lwz r11, -0x2ab8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10936 as u32) ) } as u64;
	// 831D93AC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D93B0: 419A0018  beq cr6, 0x831d93c8
	if ctx.cr[6].eq {
	pc = 0x831D93C8; continue 'dispatch;
	}
	// 831D93B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D93B8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D93BC: 48069741  bl 0x83242afc
	ctx.lr = 0x831D93C0;
	// extern call 0x83242AFC → crate::xboxkrnl::ExRegisterTitleTerminateNotification
	crate::xboxkrnl::ExRegisterTitleTerminateNotification(ctx, base);
	// 831D93C0: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D93C4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D93C8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D93CC: 48069591  bl 0x8324295c
	ctx.lr = 0x831D93D0;
	// extern call 0x8324295C → crate::xboxkrnl::RtlLeaveCriticalSection
	crate::xboxkrnl::RtlLeaveCriticalSection(ctx, base);
	// 831D93D0: 48069D8D  bl 0x8324315c
	ctx.lr = 0x831D93D4;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D93D4: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D93D8: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D93DC: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831D93E0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D93E4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D93E8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D93EC: 419A0010  beq cr6, 0x831d93fc
	if ctx.cr[6].eq {
	pc = 0x831D93FC; continue 'dispatch;
	}
	// 831D93F0: 83BF0008  lwz r29, 8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D93F4: 7F1EE840  cmplw cr6, r30, r29
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D93F8: 419A0020  beq cr6, 0x831d9418
	if ctx.cr[6].eq {
	pc = 0x831D9418; continue 'dispatch;
	}
	// 831D93FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9400: 4806967D  bl 0x83242a7c
	ctx.lr = 0x831D9404;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D9404: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831D9408: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D940C: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831D9410: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831D9414: 48000008  b 0x831d941c
	pc = 0x831D941C; continue 'dispatch;
	// 831D9418: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D941C: 3BCB0001  addi r30, r11, 1
	ctx.r[30].s64 = ctx.r[11].s64 + 1;
	// 831D9420: 3AB70050  addi r21, r23, 0x50
	ctx.r[21].s64 = ctx.r[23].s64 + 80;
	// 831D9424: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 831D9428: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D942C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9430: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831D9434: 48008555  bl 0x831e1988
	ctx.lr = 0x831D9438;
	sub_831E1988(ctx, base);
	// 831D9438: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D943C: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831D9440: 419A00C0  beq cr6, 0x831d9500
	if ctx.cr[6].eq {
	pc = 0x831D9500; continue 'dispatch;
	}
	// 831D9444: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D9448: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D944C: 419A0038  beq cr6, 0x831d9484
	if ctx.cr[6].eq {
	pc = 0x831D9484; continue 'dispatch;
	}
	// 831D9450: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D9454: 409A0030  bne cr6, 0x831d9484
	if !ctx.cr[6].eq {
	pc = 0x831D9484; continue 'dispatch;
	}
	// 831D9458: 357EFFFF  addic. r11, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D945C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D9460: 40820024  bne 0x831d9484
	if !ctx.cr[0].eq {
	pc = 0x831D9484; continue 'dispatch;
	}
	// 831D9464: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D9468: 7ECAB378  mr r10, r22
	ctx.r[10].u64 = ctx.r[22].u64;
	// 831D946C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D9470: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9474: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D9478: 480695F5  bl 0x83242a6c
	ctx.lr = 0x831D947C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D947C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D9480: 48069CED  bl 0x8324316c
	ctx.lr = 0x831D9484;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D9484: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9488: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831D948C: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D9490: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9494: 4E800421  bctrl
	ctx.lr = 0x831D9498;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9498: 48069CC5  bl 0x8324315c
	ctx.lr = 0x831D949C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D949C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D94A0: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D94A4: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D94A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D94AC: 419A0010  beq cr6, 0x831d94bc
	if ctx.cr[6].eq {
	pc = 0x831D94BC; continue 'dispatch;
	}
	// 831D94B0: 83BF0008  lwz r29, 8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D94B4: 7F1EE840  cmplw cr6, r30, r29
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D94B8: 419A0020  beq cr6, 0x831d94d8
	if ctx.cr[6].eq {
	pc = 0x831D94D8; continue 'dispatch;
	}
	// 831D94BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D94C0: 480695BD  bl 0x83242a7c
	ctx.lr = 0x831D94C4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D94C4: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831D94C8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D94CC: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831D94D0: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831D94D4: 48000008  b 0x831d94dc
	pc = 0x831D94DC; continue 'dispatch;
	// 831D94D8: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D94DC: 3BCB0001  addi r30, r11, 1
	ctx.r[30].s64 = ctx.r[11].s64 + 1;
	// 831D94E0: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D94E4: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 831D94E8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D94EC: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831D94F0: 48008499  bl 0x831e1988
	ctx.lr = 0x831D94F4;
	sub_831E1988(ctx, base);
	// 831D94F4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D94F8: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831D94FC: 409AFF48  bne cr6, 0x831d9444
	if !ctx.cr[6].eq {
	pc = 0x831D9444; continue 'dispatch;
	}
	// 831D9500: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D9504: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D9508: 419A0038  beq cr6, 0x831d9540
	if ctx.cr[6].eq {
	pc = 0x831D9540; continue 'dispatch;
	}
	// 831D950C: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D9510: 409A0030  bne cr6, 0x831d9540
	if !ctx.cr[6].eq {
	pc = 0x831D9540; continue 'dispatch;
	}
	// 831D9514: 357EFFFF  addic. r11, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D9518: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D951C: 40820024  bne 0x831d9540
	if !ctx.cr[0].eq {
	pc = 0x831D9540; continue 'dispatch;
	}
	// 831D9520: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D9524: 7ECAB378  mr r10, r22
	ctx.r[10].u64 = ctx.r[22].u64;
	// 831D9528: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D952C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9530: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D9534: 48069539  bl 0x83242a6c
	ctx.lr = 0x831D9538;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D9538: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D953C: 48069C31  bl 0x8324316c
	ctx.lr = 0x831D9540;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D9540: 89770080  lbz r11, 0x80(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[23].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D9544: 7ED8B378  mr r24, r22
	ctx.r[24].u64 = ctx.r[22].u64;
	// 831D9548: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D954C: 419A0188  beq cr6, 0x831d96d4
	if ctx.cr[6].eq {
	pc = 0x831D96D4; continue 'dispatch;
	}
	// 831D9550: 7ED9B378  mr r25, r22
	ctx.r[25].u64 = ctx.r[22].u64;
	// 831D9554: 8177007C  lwz r11, 0x7c(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(124 as u32) ) } as u64;
	// 831D9558: 7F595A14  add r26, r25, r11
	ctx.r[26].u64 = ctx.r[25].u64 + ctx.r[11].u64;
	// 831D955C: 48069C01  bl 0x8324315c
	ctx.lr = 0x831D9560;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D9560: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9564: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D9568: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D956C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D9570: 419A0010  beq cr6, 0x831d9580
	if ctx.cr[6].eq {
	pc = 0x831D9580; continue 'dispatch;
	}
	// 831D9574: 83BF0008  lwz r29, 8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9578: 7F1EE840  cmplw cr6, r30, r29
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D957C: 419A0020  beq cr6, 0x831d959c
	if ctx.cr[6].eq {
	pc = 0x831D959C; continue 'dispatch;
	}
	// 831D9580: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9584: 480694F9  bl 0x83242a7c
	ctx.lr = 0x831D9588;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D9588: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831D958C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9590: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831D9594: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831D9598: 48000008  b 0x831d95a0
	pc = 0x831D95A0; continue 'dispatch;
	// 831D959C: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D95A0: 3BCB0001  addi r30, r11, 1
	ctx.r[30].s64 = ctx.r[11].s64 + 1;
	// 831D95A4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D95A8: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 831D95AC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D95B0: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831D95B4: 480083D5  bl 0x831e1988
	ctx.lr = 0x831D95B8;
	sub_831E1988(ctx, base);
	// 831D95B8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D95BC: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831D95C0: 419A00C0  beq cr6, 0x831d9680
	if ctx.cr[6].eq {
	pc = 0x831D9680; continue 'dispatch;
	}
	// 831D95C4: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D95C8: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D95CC: 419A0038  beq cr6, 0x831d9604
	if ctx.cr[6].eq {
	pc = 0x831D9604; continue 'dispatch;
	}
	// 831D95D0: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D95D4: 409A0030  bne cr6, 0x831d9604
	if !ctx.cr[6].eq {
	pc = 0x831D9604; continue 'dispatch;
	}
	// 831D95D8: 357EFFFF  addic. r11, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D95DC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D95E0: 40820024  bne 0x831d9604
	if !ctx.cr[0].eq {
	pc = 0x831D9604; continue 'dispatch;
	}
	// 831D95E4: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D95E8: 7ECAB378  mr r10, r22
	ctx.r[10].u64 = ctx.r[22].u64;
	// 831D95EC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D95F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D95F4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D95F8: 48069475  bl 0x83242a6c
	ctx.lr = 0x831D95FC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D95FC: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D9600: 48069B6D  bl 0x8324316c
	ctx.lr = 0x831D9604;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D9604: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9608: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831D960C: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D9610: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9614: 4E800421  bctrl
	ctx.lr = 0x831D9618;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9618: 48069B45  bl 0x8324315c
	ctx.lr = 0x831D961C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831D961C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9620: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831D9624: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831D9628: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D962C: 419A0010  beq cr6, 0x831d963c
	if ctx.cr[6].eq {
	pc = 0x831D963C; continue 'dispatch;
	}
	// 831D9630: 83BF0008  lwz r29, 8(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9634: 7F1EE840  cmplw cr6, r30, r29
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D9638: 419A0020  beq cr6, 0x831d9658
	if ctx.cr[6].eq {
	pc = 0x831D9658; continue 'dispatch;
	}
	// 831D963C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9640: 4806943D  bl 0x83242a7c
	ctx.lr = 0x831D9644;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831D9644: 7FDDF378  mr r29, r30
	ctx.r[29].u64 = ctx.r[30].u64;
	// 831D9648: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D964C: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831D9650: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831D9654: 48000008  b 0x831d965c
	pc = 0x831D965C; continue 'dispatch;
	// 831D9658: 8B7F000C  lbz r27, 0xc(r31)
	ctx.r[27].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D965C: 3BCB0001  addi r30, r11, 1
	ctx.r[30].s64 = ctx.r[11].s64 + 1;
	// 831D9660: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D9664: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 831D9668: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D966C: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831D9670: 48008319  bl 0x831e1988
	ctx.lr = 0x831D9674;
	sub_831E1988(ctx, base);
	// 831D9674: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831D9678: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831D967C: 409AFF48  bne cr6, 0x831d95c4
	if !ctx.cr[6].eq {
	pc = 0x831D95C4; continue 'dispatch;
	}
	// 831D9680: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831D9684: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D9688: 419A0038  beq cr6, 0x831d96c0
	if ctx.cr[6].eq {
	pc = 0x831D96C0; continue 'dispatch;
	}
	// 831D968C: 7F0BE840  cmplw cr6, r11, r29
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[29].u32, &mut ctx.xer);
	// 831D9690: 409A0030  bne cr6, 0x831d96c0
	if !ctx.cr[6].eq {
	pc = 0x831D96C0; continue 'dispatch;
	}
	// 831D9694: 357EFFFF  addic. r11, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831D9698: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831D969C: 40820024  bne 0x831d96c0
	if !ctx.cr[0].eq {
	pc = 0x831D96C0; continue 'dispatch;
	}
	// 831D96A0: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D96A4: 7ECAB378  mr r10, r22
	ctx.r[10].u64 = ctx.r[22].u64;
	// 831D96A8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831D96AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D96B0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831D96B4: 480693B9  bl 0x83242a6c
	ctx.lr = 0x831D96B8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831D96B8: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D96BC: 48069AB1  bl 0x8324316c
	ctx.lr = 0x831D96C0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831D96C0: 89770080  lbz r11, 0x80(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[23].u32.wrapping_add(128 as u32) ) } as u64;
	// 831D96C4: 3B180001  addi r24, r24, 1
	ctx.r[24].s64 = ctx.r[24].s64 + 1;
	// 831D96C8: 3B39002C  addi r25, r25, 0x2c
	ctx.r[25].s64 = ctx.r[25].s64 + 44;
	// 831D96CC: 7F185840  cmplw cr6, r24, r11
	ctx.cr[6].compare_u32(ctx.r[24].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831D96D0: 4198FE84  blt cr6, 0x831d9554
	if ctx.cr[6].lt {
	pc = 0x831D9554; continue 'dispatch;
	}
	// 831D96D4: 80770040  lwz r3, 0x40(r23)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(64 as u32) ) } as u64;
	// 831D96D8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D96DC: 419A0018  beq cr6, 0x831d96f4
	if ctx.cr[6].eq {
	pc = 0x831D96F4; continue 'dispatch;
	}
	// 831D96E0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D96E4: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D96E8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D96EC: 4E800421  bctrl
	ctx.lr = 0x831D96F0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D96F0: 92D70040  stw r22, 0x40(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(64 as u32), ctx.r[22].u32 ) };
	// 831D96F4: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D96F8: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 831D96FC: 916AD59C  stw r11, -0x2a64(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-10852 as u32), ctx.r[11].u32 ) };
	// 831D9700: 8077003C  lwz r3, 0x3c(r23)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(60 as u32) ) } as u64;
	// 831D9704: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9708: 419A000C  beq cr6, 0x831d9714
	if ctx.cr[6].eq {
	pc = 0x831D9714; continue 'dispatch;
	}
	// 831D970C: 48001945  bl 0x831db050
	ctx.lr = 0x831D9710;
	sub_831DB050(ctx, base);
	// 831D9710: 92D7003C  stw r22, 0x3c(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(60 as u32), ctx.r[22].u32 ) };
	// 831D9714: 3BF7000C  addi r31, r23, 0xc
	ctx.r[31].s64 = ctx.r[23].s64 + 12;
	// 831D9718: 3BA00006  li r29, 6
	ctx.r[29].s64 = 6;
	// 831D971C: 3BC00002  li r30, 2
	ctx.r[30].s64 = 2;
	// 831D9720: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9724: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9728: 419A000C  beq cr6, 0x831d9734
	if ctx.cr[6].eq {
	pc = 0x831D9734; continue 'dispatch;
	}
	// 831D972C: 48001925  bl 0x831db050
	ctx.lr = 0x831D9730;
	sub_831DB050(ctx, base);
	// 831D9730: 92DF0000  stw r22, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[22].u32 ) };
	// 831D9734: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831D9738: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831D973C: 4082FFE4  bne 0x831d9720
	if !ctx.cr[0].eq {
	pc = 0x831D9720; continue 'dispatch;
	}
	// 831D9740: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831D9744: 4082FFD8  bne 0x831d971c
	if !ctx.cr[0].eq {
	pc = 0x831D971C; continue 'dispatch;
	}
	// 831D9748: 38750018  addi r3, r21, 0x18
	ctx.r[3].s64 = ctx.r[21].s64 + 24;
	// 831D974C: 4BFFFB1D  bl 0x831d9268
	ctx.lr = 0x831D9750;
	sub_831D9268(ctx, base);
	// 831D9750: 3875000C  addi r3, r21, 0xc
	ctx.r[3].s64 = ctx.r[21].s64 + 12;
	// 831D9754: 4BFFFB15  bl 0x831d9268
	ctx.lr = 0x831D9758;
	sub_831D9268(ctx, base);
	// 831D9758: 7EA3AB78  mr r3, r21
	ctx.r[3].u64 = ctx.r[21].u64;
	// 831D975C: 4BFFFB0D  bl 0x831d9268
	ctx.lr = 0x831D9760;
	sub_831D9268(ctx, base);
	// 831D9760: 38770044  addi r3, r23, 0x44
	ctx.r[3].s64 = ctx.r[23].s64 + 68;
	// 831D9764: 4BFFFB05  bl 0x831d9268
	ctx.lr = 0x831D9768;
	sub_831D9268(ctx, base);
	// 831D9768: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D976C: 80770008  lwz r3, 8(r23)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9770: 394BFF78  addi r10, r11, -0x88
	ctx.r[10].s64 = ctx.r[11].s64 + -136;
	// 831D9774: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9778: 91570000  stw r10, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831D977C: 419A0018  beq cr6, 0x831d9794
	if ctx.cr[6].eq {
	pc = 0x831D9794; continue 'dispatch;
	}
	// 831D9780: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9784: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9788: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D978C: 4E800421  bctrl
	ctx.lr = 0x831D9790;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9790: 92D70008  stw r22, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[22].u32 ) };
	// 831D9794: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D9798: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831D979C: 91570000  stw r10, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831D97A0: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 831D97A4: 4BFCE9F8  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D97A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D97A8 size=200
    let mut pc: u32 = 0x831D97A8;
    'dispatch: loop {
        match pc {
            0x831D97A8 => {
    //   block [0x831D97A8..0x831D9870)
	// 831D97A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D97AC: 4BFCE9B9  bl 0x831a8164
	ctx.lr = 0x831D97B0;
	sub_831A8130(ctx, base);
	// 831D97B0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D97B4: 896D010C  lbz r11, 0x10c(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831D97B8: 3FE08343  lis r31, -0x7cbd
	ctx.r[31].s64 = -2092761088;
	// 831D97BC: 814D0100  lwz r10, 0x100(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(256 as u32) ) } as u64;
	// 831D97C0: 392B0053  addi r9, r11, 0x53
	ctx.r[9].s64 = ctx.r[11].s64 + 83;
	// 831D97C4: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831D97C8: 817FD59C  lwz r11, -0x2a64(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D97CC: 3D208343  lis r9, -0x7cbd
	ctx.r[9].s64 = -2092761088;
	// 831D97D0: 3B89D57C  addi r28, r9, -0x2a84
	ctx.r[28].s64 = ctx.r[9].s64 + -10884;
	// 831D97D4: 7D48592E  stwx r10, r8, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32), ctx.r[10].u32) };
	// 831D97D8: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D97DC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D97E0: 3B6AD568  addi r27, r10, -0x2a98
	ctx.r[27].s64 = ctx.r[10].s64 + -10904;
	// 831D97E4: 3BABD58C  addi r29, r11, -0x2a74
	ctx.r[29].s64 = ctx.r[11].s64 + -10868;
	// 831D97E8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831D97EC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831D97F0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D97F4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D97F8: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831D97FC: 480694A1  bl 0x83242c9c
	ctx.lr = 0x831D9800;
	// extern call 0x83242C9C → crate::xboxkrnl::KeWaitForSingleObject
	crate::xboxkrnl::KeWaitForSingleObject(ctx, base);
	// 831D9800: 807FD59C  lwz r3, -0x2a64(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D9804: 8163012C  lwz r11, 0x12c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(300 as u32) ) } as u64;
	// 831D9808: 7D6A0034  cntlzw r10, r11
	ctx.r[10].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 831D980C: 554BDFFE  rlwinm r11, r10, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 831D9810: 7D7E5B78  mr r30, r11
	ctx.r[30].u64 = ctx.r[11].u64;
	// 831D9814: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D9818: 419A0024  beq cr6, 0x831d983c
	if ctx.cr[6].eq {
	pc = 0x831D983C; continue 'dispatch;
	}
	// 831D981C: 81630130  lwz r11, 0x130(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D9820: 34ABFFFF  addic. r5, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[5].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 831D9824: 41820028  beq 0x831d984c
	if ctx.cr[0].eq {
	pc = 0x831D984C; continue 'dispatch;
	}
	// 831D9828: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831D982C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D9830: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9834: 48069949  bl 0x8324317c
	ctx.lr = 0x831D9838;
	// extern call 0x8324317C → crate::xboxkrnl::KeReleaseSemaphore
	crate::xboxkrnl::KeReleaseSemaphore(ctx, base);
	// 831D9838: 48000014  b 0x831d984c
	pc = 0x831D984C; continue 'dispatch;
	// 831D983C: 4BFFF805  bl 0x831d9040
	ctx.lr = 0x831D9840;
	sub_831D9040(ctx, base);
	// 831D9840: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9844: 807FD59C  lwz r3, -0x2a64(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D9848: 4BFFF8E1  bl 0x831d9128
	ctx.lr = 0x831D984C;
	sub_831D9128(ctx, base);
	// 831D984C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831D9850: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831D9854: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9858: 48069425  bl 0x83242c7c
	ctx.lr = 0x831D985C;
	// extern call 0x83242C7C → crate::xboxkrnl::KeSetEvent
	crate::xboxkrnl::KeSetEvent(ctx, base);
	// 831D985C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831D9860: 419AFF88  beq cr6, 0x831d97e8
	if ctx.cr[6].eq {
	pc = 0x831D97E8; continue 'dispatch;
	}
	// 831D9864: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831D9868: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831D986C: 4BFCE948  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9870 size=172
    let mut pc: u32 = 0x831D9870;
    'dispatch: loop {
        match pc {
            0x831D9870 => {
    //   block [0x831D9870..0x831D991C)
	// 831D9870: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9874: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D9878: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831D987C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D9880: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9884: 896D010C  lbz r11, 0x10c(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831D9888: 3FE08343  lis r31, -0x7cbd
	ctx.r[31].s64 = -2092761088;
	// 831D988C: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D9890: 812D0100  lwz r9, 0x100(r13)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(256 as u32) ) } as u64;
	// 831D9894: 390B0053  addi r8, r11, 0x53
	ctx.r[8].s64 = ctx.r[11].s64 + 83;
	// 831D9898: 3BCAD568  addi r30, r10, -0x2a98
	ctx.r[30].s64 = ctx.r[10].s64 + -10904;
	// 831D989C: 550A103A  slwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831D98A0: 817FD59C  lwz r11, -0x2a64(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D98A4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D98A8: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831D98AC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D98B0: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D98B4: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831D98B8: 7D2A592E  stwx r9, r10, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32), ctx.r[9].u32) };
	// 831D98BC: 480693E1  bl 0x83242c9c
	ctx.lr = 0x831D98C0;
	// extern call 0x83242C9C → crate::xboxkrnl::KeWaitForSingleObject
	crate::xboxkrnl::KeWaitForSingleObject(ctx, base);
	// 831D98C0: 807FD59C  lwz r3, -0x2a64(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D98C4: 8123012C  lwz r9, 0x12c(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(300 as u32) ) } as u64;
	// 831D98C8: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831D98CC: 419A0034  beq cr6, 0x831d9900
	if ctx.cr[6].eq {
	pc = 0x831D9900; continue 'dispatch;
	}
	// 831D98D0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D98D4: 4BFFF855  bl 0x831d9128
	ctx.lr = 0x831D98D8;
	sub_831D9128(ctx, base);
	// 831D98D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D98DC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831D98E0: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D98E4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D98E8: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831D98EC: 480693B1  bl 0x83242c9c
	ctx.lr = 0x831D98F0;
	// extern call 0x83242C9C → crate::xboxkrnl::KeWaitForSingleObject
	crate::xboxkrnl::KeWaitForSingleObject(ctx, base);
	// 831D98F0: 807FD59C  lwz r3, -0x2a64(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831D98F4: 8163012C  lwz r11, 0x12c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(300 as u32) ) } as u64;
	// 831D98F8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D98FC: 409AFFD4  bne cr6, 0x831d98d0
	if !ctx.cr[6].eq {
	pc = 0x831D98D0; continue 'dispatch;
	}
	// 831D9900: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831D9904: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831D9908: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D990C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D9910: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831D9914: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D9918: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9920(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9920 size=280
    let mut pc: u32 = 0x831D9920;
    'dispatch: loop {
        match pc {
            0x831D9920 => {
    //   block [0x831D9920..0x831D9A38)
	// 831D9920: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9924: 4BFCE845  bl 0x831a8168
	ctx.lr = 0x831D9928;
	sub_831A8130(ctx, base);
	// 831D9928: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D992C: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831D9930: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9934: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 831D9938: 4B5F58A1  bl 0x827cf1d8
	ctx.lr = 0x831D993C;
	sub_827CF1D8(ctx, base);
	// 831D993C: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 831D9940: 3BCB0C24  addi r30, r11, 0xc24
	ctx.r[30].s64 = ctx.r[11].s64 + 3108;
	// 831D9944: 387E0004  addi r3, r30, 4
	ctx.r[3].s64 = ctx.r[30].s64 + 4;
	// 831D9948: 48069025  bl 0x8324296c
	ctx.lr = 0x831D994C;
	// extern call 0x8324296C → crate::xboxkrnl::RtlEnterCriticalSection
	crate::xboxkrnl::RtlEnterCriticalSection(ctx, base);
	// 831D994C: 816D0100  lwz r11, 0x100(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(256 as u32) ) } as u64;
	// 831D9950: 815F0130  lwz r10, 0x130(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D9954: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831D9958: 917F012C  stw r11, 0x12c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), ctx.r[11].u32 ) };
	// 831D995C: 419A0078  beq cr6, 0x831d99d4
	if ctx.cr[6].eq {
	pc = 0x831D99D4; continue 'dispatch;
	}
	// 831D9960: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831D9964: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831D9968: 386BD58C  addi r3, r11, -0x2a74
	ctx.r[3].s64 = ctx.r[11].s64 + -10868;
	// 831D996C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9970: 4806930D  bl 0x83242c7c
	ctx.lr = 0x831D9974;
	// extern call 0x83242C7C → crate::xboxkrnl::KeSetEvent
	crate::xboxkrnl::KeSetEvent(ctx, base);
	// 831D9974: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D9978: 3D208343  lis r9, -0x7cbd
	ctx.r[9].s64 = -2092761088;
	// 831D997C: 93810060  stw r28, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[28].u32 ) };
	// 831D9980: 390AD57C  addi r8, r10, -0x2a84
	ctx.r[8].s64 = ctx.r[10].s64 + -10884;
	// 831D9984: 38E9D558  addi r7, r9, -0x2aa8
	ctx.r[7].s64 = ctx.r[9].s64 + -10920;
	// 831D9988: 38A0002C  li r5, 0x2c
	ctx.r[5].s64 = 44;
	// 831D998C: 91010050  stw r8, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u32 ) };
	// 831D9990: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9994: 90E10054  stw r7, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[7].u32 ) };
	// 831D9998: 38610064  addi r3, r1, 0x64
	ctx.r[3].s64 = ctx.r[1].s64 + 100;
	// 831D999C: 4BFCE845  bl 0x831a81e0
	ctx.lr = 0x831D99A0;
	sub_831A81E0(ctx, base);
	// 831D99A0: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 831D99A4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831D99A8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831D99AC: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 831D99B0: 38C00003  li r6, 3
	ctx.r[6].s64 = 3;
	// 831D99B4: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831D99B8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831D99BC: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831D99C0: 4806978D  bl 0x8324314c
	ctx.lr = 0x831D99C4;
	// extern call 0x8324314C → crate::xboxkrnl::KeWaitForMultipleObjects
	crate::xboxkrnl::KeWaitForMultipleObjects(ctx, base);
	// 831D99C4: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 831D99C8: 409A0020  bne cr6, 0x831d99e8
	if !ctx.cr[6].eq {
	pc = 0x831D99E8; continue 'dispatch;
	}
	// 831D99CC: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 831D99D0: 48000018  b 0x831d99e8
	pc = 0x831D99E8; continue 'dispatch;
	// 831D99D4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D99D8: 4BFFF669  bl 0x831d9040
	ctx.lr = 0x831D99DC;
	sub_831D9040(ctx, base);
	// 831D99DC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D99E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D99E4: 4BFFF745  bl 0x831d9128
	ctx.lr = 0x831D99E8;
	sub_831D9128(ctx, base);
	// 831D99E8: 57AB063E  clrlwi r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	// 831D99EC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D99F0: 409A002C  bne cr6, 0x831d9a1c
	if !ctx.cr[6].eq {
	pc = 0x831D9A1C; continue 'dispatch;
	}
	// 831D99F4: 807F0040  lwz r3, 0x40(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831D99F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D99FC: 814B0044  lwz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831D9A00: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9A04: 4E800421  bctrl
	ctx.lr = 0x831D9A08;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9A08: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9A0C: 41980010  blt cr6, 0x831d9a1c
	if ctx.cr[6].lt {
	pc = 0x831D9A1C; continue 'dispatch;
	}
	// 831D9A10: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9A14: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831D9A18: 48002CD1  bl 0x831dc6e8
	ctx.lr = 0x831D9A1C;
	sub_831DC6E8(ctx, base);
	// 831D9A1C: 939F012C  stw r28, 0x12c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(300 as u32), ctx.r[28].u32 ) };
	// 831D9A20: 48002D01  bl 0x831dc720
	ctx.lr = 0x831D9A24;
	sub_831DC720(ctx, base);
	// 831D9A24: 387E0004  addi r3, r30, 4
	ctx.r[3].s64 = ctx.r[30].s64 + 4;
	// 831D9A28: 48068F35  bl 0x8324295c
	ctx.lr = 0x831D9A2C;
	// extern call 0x8324295C → crate::xboxkrnl::RtlLeaveCriticalSection
	crate::xboxkrnl::RtlLeaveCriticalSection(ctx, base);
	// 831D9A2C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831D9A30: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831D9A34: 4BFCE784  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9A38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9A38 size=212
    let mut pc: u32 = 0x831D9A38;
    'dispatch: loop {
        match pc {
            0x831D9A38 => {
    //   block [0x831D9A38..0x831D9B0C)
	// 831D9A38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9A3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D9A40: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D9A44: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9A48: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9A4C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D9A50: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831D9A54: 392BFF78  addi r9, r11, -0x88
	ctx.r[9].s64 = ctx.r[11].s64 + -136;
	// 831D9A58: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831D9A5C: 909F0008  stw r4, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 831D9A60: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831D9A64: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D9A68: 419A0018  beq cr6, 0x831d9a80
	if ctx.cr[6].eq {
	pc = 0x831D9A80; continue 'dispatch;
	}
	// 831D9A6C: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9A70: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831D9A74: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9A78: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9A7C: 4E800421  bctrl
	ctx.lr = 0x831D9A80;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9A80: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831D9A84: 397F0050  addi r11, r31, 0x50
	ctx.r[11].s64 = ctx.r[31].s64 + 80;
	// 831D9A88: 392AFF8C  addi r9, r10, -0x74
	ctx.r[9].s64 = ctx.r[10].s64 + -116;
	// 831D9A8C: 395F0044  addi r10, r31, 0x44
	ctx.r[10].s64 = ctx.r[31].s64 + 68;
	// 831D9A90: 39000018  li r8, 0x18
	ctx.r[8].s64 = 24;
	// 831D9A94: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D9A98: 38E00010  li r7, 0x10
	ctx.r[7].s64 = 16;
	// 831D9A9C: 915F0044  stw r10, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[10].u32 ) };
	// 831D9AA0: 915F0048  stw r10, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[10].u32 ) };
	// 831D9AA4: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 831D9AA8: 911F004C  stw r8, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[8].u32 ) };
	// 831D9AAC: 394B0018  addi r10, r11, 0x18
	ctx.r[10].s64 = ctx.r[11].s64 + 24;
	// 831D9AB0: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831D9AB4: 3CC08343  lis r6, -0x7cbd
	ctx.r[6].s64 = -2092761088;
	// 831D9AB8: 917F0054  stw r11, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 831D9ABC: 3D603F80  lis r11, 0x3f80
	ctx.r[11].s64 = 1065353216;
	// 831D9AC0: 90FF0058  stw r7, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[7].u32 ) };
	// 831D9AC4: 38FF0084  addi r7, r31, 0x84
	ctx.r[7].s64 = ctx.r[31].s64 + 132;
	// 831D9AC8: 911F0064  stw r8, 0x64(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), ctx.r[8].u32 ) };
	// 831D9ACC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9AD0: 913F005C  stw r9, 0x5c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(92 as u32), ctx.r[9].u32 ) };
	// 831D9AD4: 913F0060  stw r9, 0x60(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(96 as u32), ctx.r[9].u32 ) };
	// 831D9AD8: 911F0070  stw r8, 0x70(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(112 as u32), ctx.r[8].u32 ) };
	// 831D9ADC: 915F0068  stw r10, 0x68(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(104 as u32), ctx.r[10].u32 ) };
	// 831D9AE0: 915F006C  stw r10, 0x6c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(108 as u32), ctx.r[10].u32 ) };
	// 831D9AE4: 913F0074  stw r9, 0x74(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), ctx.r[9].u32 ) };
	// 831D9AE8: 915F0078  stw r10, 0x78(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(120 as u32), ctx.r[10].u32 ) };
	// 831D9AEC: 917F0084  stw r11, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 831D9AF0: 917F0088  stw r11, 0x88(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(136 as u32), ctx.r[11].u32 ) };
	// 831D9AF4: 93E6D59C  stw r31, -0x2a64(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(-10852 as u32), ctx.r[31].u32 ) };
	// 831D9AF8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831D9AFC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D9B00: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D9B04: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D9B08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9B10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9B10 size=48
    let mut pc: u32 = 0x831D9B10;
    'dispatch: loop {
        match pc {
            0x831D9B10 => {
    //   block [0x831D9B10..0x831D9B40)
	// 831D9B10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9B14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831D9B18: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831D9B1C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9B20: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9B24: 4BFFF7CD  bl 0x831d92f0
	ctx.lr = 0x831D9B28;
	sub_831D92F0(ctx, base);
	// 831D9B28: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9B2C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831D9B30: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831D9B34: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831D9B38: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831D9B3C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9B40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9B40 size=928
    let mut pc: u32 = 0x831D9B40;
    'dispatch: loop {
        match pc {
            0x831D9B40 => {
    //   block [0x831D9B40..0x831D9EE0)
	// 831D9B40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9B44: 4BFCE615  bl 0x831a8158
	ctx.lr = 0x831D9B48;
	sub_831A8130(ctx, base);
	// 831D9B48: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9B4C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831D9B50: 7C982378  mr r24, r4
	ctx.r[24].u64 = ctx.r[4].u64;
	// 831D9B54: 4B5F5685  bl 0x827cf1d8
	ctx.lr = 0x831D9B58;
	sub_827CF1D8(ctx, base);
	// 831D9B58: 89780001  lbz r11, 1(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(1 as u32) ) } as u64;
	// 831D9B5C: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 831D9B60: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 831D9B64: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831D9B68: 997E0080  stb r11, 0x80(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[11].u8 ) };
	// 831D9B6C: 419A00D4  beq cr6, 0x831d9c40
	if ctx.cr[6].eq {
	pc = 0x831D9C40; continue 'dispatch;
	}
	// 831D9B70: 3D6005D1  lis r11, 0x5d1
	ctx.r[11].s64 = 97583104;
	// 831D9B74: 616A745D  ori r10, r11, 0x745d
	ctx.r[10].u64 = ctx.r[11].u64 | 29789;
	// 831D9B78: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D9B7C: 41990018  bgt cr6, 0x831d9b94
	if ctx.cr[6].gt {
	pc = 0x831D9B94; continue 'dispatch;
	}
	// 831D9B80: 1D7F002C  mulli r11, r31, 0x2c
	ctx.r[11].s64 = ctx.r[31].s64 * 44;
	// 831D9B84: 3940FFFB  li r10, -5
	ctx.r[10].s64 = -5;
	// 831D9B88: 388B0004  addi r4, r11, 4
	ctx.r[4].s64 = ctx.r[11].s64 + 4;
	// 831D9B8C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831D9B90: 40990008  ble cr6, 0x831d9b98
	if !ctx.cr[6].gt {
	pc = 0x831D9B98; continue 'dispatch;
	}
	// 831D9B94: 3880FFFF  li r4, -1
	ctx.r[4].s64 = -1;
	// 831D9B98: 807E0008  lwz r3, 8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9B9C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9BA0: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831D9BA4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9BA8: 4E800421  bctrl
	ctx.lr = 0x831D9BAC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9BAC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9BB0: 419A0070  beq cr6, 0x831d9c20
	if ctx.cr[6].eq {
	pc = 0x831D9C20; continue 'dispatch;
	}
	// 831D9BB4: 38830004  addi r4, r3, 4
	ctx.r[4].s64 = ctx.r[3].s64 + 4;
	// 831D9BB8: 93E30000  stw r31, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831D9BBC: 34FFFFFF  addic. r7, r31, -1
	ctx.xer.ca = (ctx.r[31].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[31].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831D9BC0: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 831D9BC4: 41800054  blt 0x831d9c18
	if ctx.cr[0].lt {
	pc = 0x831D9C18; continue 'dispatch;
	}
	// 831D9BC8: 396A0010  addi r11, r10, 0x10
	ctx.r[11].s64 = ctx.r[10].s64 + 16;
	// 831D9BCC: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 831D9BD0: 38C00018  li r6, 0x18
	ctx.r[6].s64 = 24;
	// 831D9BD4: 392BFFFC  addi r9, r11, -4
	ctx.r[9].s64 = ctx.r[11].s64 + -4;
	// 831D9BD8: 914BFFF4  stw r10, -0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), ctx.r[10].u32 ) };
	// 831D9BDC: 390B0008  addi r8, r11, 8
	ctx.r[8].s64 = ctx.r[11].s64 + 8;
	// 831D9BE0: 914A0000  stw r10, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831D9BE4: 90ABFFF8  stw r5, -8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), ctx.r[5].u32 ) };
	// 831D9BE8: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831D9BEC: 912BFFFC  stw r9, -4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), ctx.r[9].u32 ) };
	// 831D9BF0: 394A002C  addi r10, r10, 0x2c
	ctx.r[10].s64 = ctx.r[10].s64 + 44;
	// 831D9BF4: 90CB0004  stw r6, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831D9BF8: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831D9BFC: 90CB0010  stw r6, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831D9C00: 910B0008  stw r8, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831D9C04: 910B000C  stw r8, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831D9C08: 912B0014  stw r9, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[9].u32 ) };
	// 831D9C0C: 910B0018  stw r8, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[8].u32 ) };
	// 831D9C10: 396B002C  addi r11, r11, 0x2c
	ctx.r[11].s64 = ctx.r[11].s64 + 44;
	// 831D9C14: 4080FFC0  bge 0x831d9bd4
	if !ctx.cr[0].lt {
	pc = 0x831D9BD4; continue 'dispatch;
	}
	// 831D9C18: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831D9C1C: 48000008  b 0x831d9c24
	pc = 0x831D9C24; continue 'dispatch;
	// 831D9C20: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 831D9C24: 917E007C  stw r11, 0x7c(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(124 as u32), ctx.r[11].u32 ) };
	// 831D9C28: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D9C2C: 409A0014  bne cr6, 0x831d9c40
	if !ctx.cr[6].eq {
	pc = 0x831D9C40; continue 'dispatch;
	}
	// 831D9C30: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831D9C34: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831D9C38: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831D9C3C: 4BFCE56C  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
	// 831D9C40: 81780004  lwz r11, 4(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9C44: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831D9C48: 419A000C  beq cr6, 0x831d9c54
	if ctx.cr[6].eq {
	pc = 0x831D9C54; continue 'dispatch;
	}
	// 831D9C4C: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 831D9C50: 48000010  b 0x831d9c60
	pc = 0x831D9C60; continue 'dispatch;
	// 831D9C54: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831D9C58: 394BFEA8  addi r10, r11, -0x158
	ctx.r[10].s64 = ctx.r[11].s64 + -344;
	// 831D9C5C: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 831D9C60: 38BE003C  addi r5, r30, 0x3c
	ctx.r[5].s64 = ctx.r[30].s64 + 60;
	// 831D9C64: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9C68: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 831D9C6C: 48001A5D  bl 0x831db6c8
	ctx.lr = 0x831D9C70;
	sub_831DB6C8(ctx, base);
	// 831D9C70: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831D9C74: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831D9C78: 4198025C  blt cr6, 0x831d9ed4
	if ctx.cr[6].lt {
	pc = 0x831D9ED4; continue 'dispatch;
	}
	// 831D9C7C: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D9C80: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 831D9C84: 396AD58C  addi r11, r10, -0x2a74
	ctx.r[11].s64 = ctx.r[10].s64 + -10868;
	// 831D9C88: 7F69DB78  mr r9, r27
	ctx.r[9].u64 = ctx.r[27].u64;
	// 831D9C8C: 3CC08343  lis r6, -0x7cbd
	ctx.r[6].s64 = -2092761088;
	// 831D9C90: 992AD58C  stb r9, -0x2a74(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(-10868 as u32), ctx.r[9].u8 ) };
	// 831D9C94: 38EB0008  addi r7, r11, 8
	ctx.r[7].s64 = ctx.r[11].s64 + 8;
	// 831D9C98: 392B0008  addi r9, r11, 8
	ctx.r[9].s64 = ctx.r[11].s64 + 8;
	// 831D9C9C: 7F28CB78  mr r8, r25
	ctx.r[8].u64 = ctx.r[25].u64;
	// 831D9CA0: 90EB0008  stw r7, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 831D9CA4: 3946D57C  addi r10, r6, -0x2a84
	ctx.r[10].s64 = ctx.r[6].s64 + -10884;
	// 831D9CA8: 912B000C  stw r9, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 831D9CAC: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831D9CB0: 7F68DB78  mr r8, r27
	ctx.r[8].u64 = ctx.r[27].u64;
	// 831D9CB4: 7F27CB78  mr r7, r25
	ctx.r[7].u64 = ctx.r[25].u64;
	// 831D9CB8: 396A0008  addi r11, r10, 8
	ctx.r[11].s64 = ctx.r[10].s64 + 8;
	// 831D9CBC: 9906D57C  stb r8, -0x2a84(r6)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[6].u32.wrapping_add(-10884 as u32), ctx.r[8].u8 ) };
	// 831D9CC0: 392A0008  addi r9, r10, 8
	ctx.r[9].s64 = ctx.r[10].s64 + 8;
	// 831D9CC4: 90EA0004  stw r7, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831D9CC8: 3C808343  lis r4, -0x7cbd
	ctx.r[4].s64 = -2092761088;
	// 831D9CCC: 916A0008  stw r11, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831D9CD0: 38A00006  li r5, 6
	ctx.r[5].s64 = 6;
	// 831D9CD4: 912A000C  stw r9, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 831D9CD8: 3864D568  addi r3, r4, -0x2a98
	ctx.r[3].s64 = ctx.r[4].s64 + -10904;
	// 831D9CDC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9CE0: 480694DD  bl 0x832431bc
	ctx.lr = 0x831D9CE4;
	// extern call 0x832431BC → crate::xboxkrnl::KeInitializeSemaphore
	crate::xboxkrnl::KeInitializeSemaphore(ctx, base);
	// 831D9CE4: 3C608343  lis r3, -0x7cbd
	ctx.r[3].s64 = -2092761088;
	// 831D9CE8: 7F2ACB78  mr r10, r25
	ctx.r[10].u64 = ctx.r[25].u64;
	// 831D9CEC: 3963D558  addi r11, r3, -0x2aa8
	ctx.r[11].s64 = ctx.r[3].s64 + -10920;
	// 831D9CF0: 3CC08343  lis r6, -0x7cbd
	ctx.r[6].s64 = -2092761088;
	// 831D9CF4: 390B0008  addi r8, r11, 8
	ctx.r[8].s64 = ctx.r[11].s64 + 8;
	// 831D9CF8: 9943D558  stb r10, -0x2aa8(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(-10920 as u32), ctx.r[10].u8 ) };
	// 831D9CFC: 7F29CB78  mr r9, r25
	ctx.r[9].u64 = ctx.r[25].u64;
	// 831D9D00: 3866D548  addi r3, r6, -0x2ab8
	ctx.r[3].s64 = ctx.r[6].s64 + -10936;
	// 831D9D04: 3CE0831E  lis r7, -0x7ce2
	ctx.r[7].s64 = -2095185920;
	// 831D9D08: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831D9D0C: 910B0008  stw r8, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831D9D10: 394B0008  addi r10, r11, 8
	ctx.r[10].s64 = ctx.r[11].s64 + 8;
	// 831D9D14: 39278B18  addi r9, r7, -0x74e8
	ctx.r[9].s64 = ctx.r[7].s64 + -29928;
	// 831D9D18: 3D007D80  lis r8, 0x7d80
	ctx.r[8].s64 = 2105540608;
	// 831D9D1C: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831D9D20: 9126D548  stw r9, -0x2ab8(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(-10936 as u32), ctx.r[9].u32 ) };
	// 831D9D24: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831D9D28: 91030004  stw r8, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831D9D2C: 48068DD1  bl 0x83242afc
	ctx.lr = 0x831D9D30;
	// extern call 0x83242AFC → crate::xboxkrnl::ExRegisterTitleTerminateNotification
	crate::xboxkrnl::ExRegisterTitleTerminateNotification(ctx, base);
	// 831D9D30: 933E0130  stw r25, 0x130(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(304 as u32), ctx.r[25].u32 ) };
	// 831D9D34: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831D9D38: 88780002  lbz r3, 2(r24)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(2 as u32) ) } as u64;
	// 831D9D3C: 4BFFE7ED  bl 0x831d8528
	ctx.lr = 0x831D9D40;
	sub_831D8528(ctx, base);
	// 831D9D40: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831D9D44: 3BBE0134  addi r29, r30, 0x134
	ctx.r[29].s64 = ctx.r[30].s64 + 308;
	// 831D9D48: 3F808200  lis r28, -0x7e00
	ctx.r[28].s64 = -2113929216;
	// 831D9D4C: 39610062  addi r11, r1, 0x62
	ctx.r[11].s64 = ctx.r[1].s64 + 98;
	// 831D9D50: 93210054  stw r25, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[25].u32 ) };
	// 831D9D54: 7D7F58AE  lbzx r11, r31, r11
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831D9D58: 556A07BE  clrlwi r10, r11, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000003u64;
	// 831D9D5C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D9D60: 419A0080  beq cr6, 0x831d9de0
	if ctx.cr[6].eq {
	pc = 0x831D9DE0; continue 'dispatch;
	}
	// 831D9D64: 3D40831E  lis r10, -0x7ce2
	ctx.r[10].s64 = -2095185920;
	// 831D9D68: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831D9D6C: 38EA9870  addi r7, r10, -0x6790
	ctx.r[7].s64 = ctx.r[10].s64 + -26512;
	// 831D9D70: 409A000C  bne cr6, 0x831d9d7c
	if !ctx.cr[6].eq {
	pc = 0x831D9D7C; continue 'dispatch;
	}
	// 831D9D74: 3D60831E  lis r11, -0x7ce2
	ctx.r[11].s64 = -2095185920;
	// 831D9D78: 38EB97A8  addi r7, r11, -0x6858
	ctx.r[7].s64 = ctx.r[11].s64 + -26712;
	// 831D9D7C: 7F6BF830  slw r11, r27, r31
	if (ctx.r[31].u8 & 0x20) != 0 {
		ctx.r[11].u64 = 0;
	} else {
		ctx.r[11].u64 = ((ctx.r[27].u32) << ((ctx.r[31].u8 & 0x1F) as u32)) as u64;
	}
	// 831D9D80: 7F69DB78  mr r9, r27
	ctx.r[9].u64 = ctx.r[27].u64;
	// 831D9D84: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831D9D88: 5169C00E  rlwimi r9, r11, 0x18, 0, 7
	ctx.r[9].u64 = (((ctx.r[11].u32).rotate_left(24) as u64) & 0x00000000FF000000) | (ctx.r[9].u64 & 0xFFFFFFFF00FFFFFF);
	// 831D9D8C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831D9D90: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831D9D94: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831D9D98: 38610054  addi r3, r1, 0x54
	ctx.r[3].s64 = ctx.r[1].s64 + 84;
	// 831D9D9C: 480692C1  bl 0x8324305c
	ctx.lr = 0x831D9DA0;
	// extern call 0x8324305C → crate::xboxkrnl::ExCreateThread
	crate::xboxkrnl::ExCreateThread(ctx, base);
	// 831D9DA0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9DA4: 4198FE8C  blt cr6, 0x831d9c30
	if ctx.cr[6].lt {
	pc = 0x831D9C30; continue 'dispatch;
	}
	// 831D9DA8: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831D9DAC: 809C05D0  lwz r4, 0x5d0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1488 as u32) ) } as u64;
	// 831D9DB0: 80610054  lwz r3, 0x54(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831D9DB4: 48068B69  bl 0x8324291c
	ctx.lr = 0x831D9DB8;
	// extern call 0x8324291C → crate::xboxkrnl::ObReferenceObjectByHandle
	crate::xboxkrnl::ObReferenceObjectByHandle(ctx, base);
	// 831D9DB8: 3880000F  li r4, 0xf
	ctx.r[4].s64 = 15;
	// 831D9DBC: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831D9DC0: 48068B4D  bl 0x8324290c
	ctx.lr = 0x831D9DC4;
	// extern call 0x8324290C → crate::xboxkrnl::KeSetBasePriorityThread
	crate::xboxkrnl::KeSetBasePriorityThread(ctx, base);
	// 831D9DC4: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831D9DC8: 480693E5  bl 0x832431ac
	ctx.lr = 0x831D9DCC;
	// extern call 0x832431AC → crate::xboxkrnl::KeResumeThread
	crate::xboxkrnl::KeResumeThread(ctx, base);
	// 831D9DCC: 80610050  lwz r3, 0x50(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831D9DD0: 48068B2D  bl 0x832428fc
	ctx.lr = 0x831D9DD4;
	// extern call 0x832428FC → crate::xboxkrnl::ObDereferenceObject
	crate::xboxkrnl::ObDereferenceObject(ctx, base);
	// 831D9DD4: 817E0130  lwz r11, 0x130(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(304 as u32) ) } as u64;
	// 831D9DD8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831D9DDC: 917E0130  stw r11, 0x130(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(304 as u32), ctx.r[11].u32 ) };
	// 831D9DE0: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831D9DE4: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 831D9DE8: 2F1F0006  cmpwi cr6, r31, 6
	ctx.cr[6].compare_i32(ctx.r[31].s32, 6, &mut ctx.xer);
	// 831D9DEC: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831D9DF0: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 831D9DF4: 4198FF58  blt cr6, 0x831d9d4c
	if ctx.cr[6].lt {
	pc = 0x831D9D4C; continue 'dispatch;
	}
	// 831D9DF8: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 831D9DFC: 89780000  lbz r11, 0(r24)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9E00: 2B0B0006  cmplwi cr6, r11, 6
	ctx.cr[6].compare_u32(ctx.r[11].u32, 6 as u32, &mut ctx.xer);
	// 831D9E04: FB2A0000  std r25, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[25].u64 ) };
	// 831D9E08: FB2A0008  std r25, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[25].u64 ) };
	// 831D9E0C: 932A0010  stw r25, 0x10(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[25].u32 ) };
	// 831D9E10: 9B210070  stb r25, 0x70(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[25].u8 ) };
	// 831D9E14: 9B210074  stb r25, 0x74(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[25].u8 ) };
	// 831D9E18: 41990008  bgt cr6, 0x831d9e20
	if ctx.cr[6].gt {
	pc = 0x831D9E20; continue 'dispatch;
	}
	// 831D9E1C: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 831D9E20: 3D400000  lis r10, 0
	ctx.r[10].s64 = 0;
	// 831D9E24: 99610075  stb r11, 0x75(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(117 as u32), ctx.r[11].u8 ) };
	// 831D9E28: 7F3CCB78  mr r28, r25
	ctx.r[28].u64 = ctx.r[25].u64;
	// 831D9E2C: 6148BB80  ori r8, r10, 0xbb80
	ctx.r[8].u64 = ctx.r[10].u64 | 48000;
	// 831D9E30: 3BA00003  li r29, 3
	ctx.r[29].s64 = 3;
	// 831D9E34: 91010078  stw r8, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[8].u32 ) };
	// 831D9E38: 39610062  addi r11, r1, 0x62
	ctx.r[11].s64 = ctx.r[1].s64 + 98;
	// 831D9E3C: 7D5C58AE  lbzx r10, r28, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831D9E40: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831D9E44: 419A0038  beq cr6, 0x831d9e7c
	if ctx.cr[6].eq {
	pc = 0x831D9E7C; continue 'dispatch;
	}
	// 831D9E48: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 831D9E4C: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831D9E50: 4198002C  blt cr6, 0x831d9e7c
	if ctx.cr[6].lt {
	pc = 0x831D9E7C; continue 'dispatch;
	}
	// 831D9E54: 7D7DFA14  add r11, r29, r31
	ctx.r[11].u64 = ctx.r[29].u64 + ctx.r[31].u64;
	// 831D9E58: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9E5C: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 831D9E60: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831D9E64: 7CABF214  add r5, r11, r30
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831D9E68: 480084F1  bl 0x831e2358
	ctx.lr = 0x831D9E6C;
	sub_831E2358(ctx, base);
	// 831D9E6C: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 831D9E70: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831D9E74: 2B1F0002  cmplwi cr6, r31, 2
	ctx.cr[6].compare_u32(ctx.r[31].u32, 2 as u32, &mut ctx.xer);
	// 831D9E78: 4198FFD4  blt cr6, 0x831d9e4c
	if ctx.cr[6].lt {
	pc = 0x831D9E4C; continue 'dispatch;
	}
	// 831D9E7C: 3BBD0002  addi r29, r29, 2
	ctx.r[29].s64 = ctx.r[29].s64 + 2;
	// 831D9E80: 3B9C0001  addi r28, r28, 1
	ctx.r[28].s64 = ctx.r[28].s64 + 1;
	// 831D9E84: 2B1D000F  cmplwi cr6, r29, 0xf
	ctx.cr[6].compare_u32(ctx.r[29].u32, 15 as u32, &mut ctx.xer);
	// 831D9E88: 4198FFB0  blt cr6, 0x831d9e38
	if ctx.cr[6].lt {
	pc = 0x831D9E38; continue 'dispatch;
	}
	// 831D9E8C: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 831D9E90: 41980044  blt cr6, 0x831d9ed4
	if ctx.cr[6].lt {
	pc = 0x831D9ED4; continue 'dispatch;
	}
	// 831D9E94: 3BFE0040  addi r31, r30, 0x40
	ctx.r[31].s64 = ctx.r[30].s64 + 64;
	// 831D9E98: 80780008  lwz r3, 8(r24)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(8 as u32) ) } as u64;
	// 831D9E9C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831D9EA0: 48008B39  bl 0x831e29d8
	ctx.lr = 0x831D9EA4;
	sub_831E29D8(ctx, base);
	// 831D9EA4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9EA8: 41980030  blt cr6, 0x831d9ed8
	if ctx.cr[6].lt {
	pc = 0x831D9ED8; continue 'dispatch;
	}
	// 831D9EAC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9EB0: 3D40831E  lis r10, -0x7ce2
	ctx.r[10].s64 = -2095185920;
	// 831D9EB4: 388A24B8  addi r4, r10, 0x24b8
	ctx.r[4].s64 = ctx.r[10].s64 + 9400;
	// 831D9EB8: 806B0044  lwz r3, 0x44(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831D9EBC: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9EC0: 8109001C  lwz r8, 0x1c(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) } as u64;
	// 831D9EC4: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831D9EC8: 4E800421  bctrl
	ctx.lr = 0x831D9ECC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9ECC: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831D9ED0: 4BFCE2D8  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
	// 831D9ED4: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831D9ED8: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 831D9EDC: 4BFCE2CC  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9EE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831D9EE0 size=252
    let mut pc: u32 = 0x831D9EE0;
    'dispatch: loop {
        match pc {
            0x831D9EE0 => {
    //   block [0x831D9EE0..0x831D9FDC)
	// 831D9EE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9EE4: 4BFCE285  bl 0x831a8168
	ctx.lr = 0x831D9EE8;
	sub_831A8130(ctx, base);
	// 831D9EE8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831D9EEC: 9081009C  stw r4, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[4].u32 ) };
	// 831D9EF0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831D9EF4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831D9EF8: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831D9EFC: 4BFFEDBD  bl 0x831d8cb8
	ctx.lr = 0x831D9F00;
	sub_831D8CB8(ctx, base);
	// 831D9F00: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9F04: 41980010  blt cr6, 0x831d9f14
	if ctx.cr[6].lt {
	pc = 0x831D9F14; continue 'dispatch;
	}
	// 831D9F08: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831D9F0C: 388B0174  addi r4, r11, 0x174
	ctx.r[4].s64 = ctx.r[11].s64 + 372;
	// 831D9F10: 48000008  b 0x831d9f18
	pc = 0x831D9F18; continue 'dispatch;
	// 831D9F14: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831D9F18: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9F1C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831D9F20: 41980094  blt cr6, 0x831d9fb4
	if ctx.cr[6].lt {
	pc = 0x831D9FB4; continue 'dispatch;
	}
	// 831D9F24: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 831D9F28: 38A1009C  addi r5, r1, 0x9c
	ctx.r[5].s64 = ctx.r[1].s64 + 156;
	// 831D9F2C: 60630005  ori r3, r3, 5
	ctx.r[3].u64 = ctx.r[3].u64 | 5;
	// 831D9F30: 48009039  bl 0x831e2f68
	ctx.lr = 0x831D9F34;
	sub_831E2F68(ctx, base);
	// 831D9F34: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9F38: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831D9F3C: 41980078  blt cr6, 0x831d9fb4
	if ctx.cr[6].lt {
	pc = 0x831D9FB4; continue 'dispatch;
	}
	// 831D9F40: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831D9F44: 38800174  li r4, 0x174
	ctx.r[4].s64 = 372;
	// 831D9F48: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9F4C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831D9F50: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9F54: 4E800421  bctrl
	ctx.lr = 0x831D9F58;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9F58: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9F5C: 419A0018  beq cr6, 0x831d9f74
	if ctx.cr[6].eq {
	pc = 0x831D9F74; continue 'dispatch;
	}
	// 831D9F60: 8081009C  lwz r4, 0x9c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831D9F64: 4BFFFAD5  bl 0x831d9a38
	ctx.lr = 0x831D9F68;
	sub_831D9A38(ctx, base);
	// 831D9F68: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831D9F6C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831D9F70: 409A0010  bne cr6, 0x831d9f80
	if !ctx.cr[6].eq {
	pc = 0x831D9F80; continue 'dispatch;
	}
	// 831D9F74: 3FE08007  lis r31, -0x7ff9
	ctx.r[31].s64 = -2147024896;
	// 831D9F78: 63FF000E  ori r31, r31, 0xe
	ctx.r[31].u64 = ctx.r[31].u64 | 14;
	// 831D9F7C: 48000038  b 0x831d9fb4
	pc = 0x831D9FB4; continue 'dispatch;
	// 831D9F80: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831D9F84: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D9F88: 4BFFFBB9  bl 0x831d9b40
	ctx.lr = 0x831D9F8C;
	sub_831D9B40(ctx, base);
	// 831D9F8C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831D9F90: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831D9F94: 4198000C  blt cr6, 0x831d9fa0
	if ctx.cr[6].lt {
	pc = 0x831D9FA0; continue 'dispatch;
	}
	// 831D9F98: 93DC0000  stw r30, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 831D9F9C: 48000018  b 0x831d9fb4
	pc = 0x831D9FB4; continue 'dispatch;
	// 831D9FA0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9FA4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831D9FA8: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831D9FAC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9FB0: 4E800421  bctrl
	ctx.lr = 0x831D9FB4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9FB4: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831D9FB8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831D9FBC: 419A0014  beq cr6, 0x831d9fd0
	if ctx.cr[6].eq {
	pc = 0x831D9FD0; continue 'dispatch;
	}
	// 831D9FC0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831D9FC4: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831D9FC8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831D9FCC: 4E800421  bctrl
	ctx.lr = 0x831D9FD0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831D9FD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831D9FD4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831D9FD8: 4BFCE1E0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9FE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831D9FE0 size=24
    let mut pc: u32 = 0x831D9FE0;
    'dispatch: loop {
        match pc {
            0x831D9FE0 => {
    //   block [0x831D9FE0..0x831D9FF8)
	// 831D9FE0: 3D607FEA  lis r11, 0x7fea
	ctx.r[11].s64 = 2146041856;
	// 831D9FE4: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831D9FE8: 61691800  ori r9, r11, 0x1800
	ctx.r[9].u64 = ctx.r[11].u64 | 6144;
	// 831D9FEC: 7D604C2C  lwbrx r11, 0, r9
	ctx.r[11].u64 = (unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32) }).swap_bytes() as u64;
	// 831D9FF0: 916AD5A0  stw r11, -0x2a60(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-10848 as u32), ctx.r[11].u32 ) };
	// 831D9FF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831D9FF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831D9FF8 size=508
    let mut pc: u32 = 0x831D9FF8;
    'dispatch: loop {
        match pc {
            0x831D9FF8 => {
    //   block [0x831D9FF8..0x831DA1F4)
	// 831D9FF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831D9FFC: 4BFCE159  bl 0x831a8154
	ctx.lr = 0x831DA000;
	sub_831A8130(ctx, base);
	// 831DA000: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DA004: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DA008: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831DA00C: 7CB82B78  mr r24, r5
	ctx.r[24].u64 = ctx.r[5].u64;
	// 831DA010: 7CD73378  mr r23, r6
	ctx.r[23].u64 = ctx.r[6].u64;
	// 831DA014: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 831DA018: 48000239  bl 0x831da250
	ctx.lr = 0x831DA01C;
	sub_831DA250(ctx, base);
	// 831DA01C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DA020: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831DA024: 409A0038  bne cr6, 0x831da05c
	if !ctx.cr[6].eq {
	pc = 0x831DA05C; continue 'dispatch;
	}
	// 831DA028: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DA02C: 3CA0A782  lis r5, -0x587e
	ctx.r[5].s64 = -1484652544;
	// 831DA030: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DA034: 60A50007  ori r5, r5, 7
	ctx.r[5].u64 = ctx.r[5].u64 | 7;
	// 831DA038: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831DA03C: 48002675  bl 0x831dc6b0
	ctx.lr = 0x831DA040;
	sub_831DC6B0(ctx, base);
	// 831DA040: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831DA044: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831DA048: 409A0014  bne cr6, 0x831da05c
	if !ctx.cr[6].eq {
	pc = 0x831DA05C; continue 'dispatch;
	}
	// 831DA04C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DA050: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831DA054: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DA058: 4BFCE14C  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 831DA05C: 57EB083C  slwi r11, r31, 1
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA060: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831DA064: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DA068: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DA06C: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA070: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DA074: 394B008F  addi r10, r11, 0x8f
	ctx.r[10].s64 = ctx.r[11].s64 + 143;
	// 831DA078: 555E0030  rlwinm r30, r10, 0, 0, 0x18
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA07C: 7F9EE850  subf r28, r30, r29
	ctx.r[28].s64 = ctx.r[29].s64 - ctx.r[30].s64;
	// 831DA080: 4BFE9FB1  bl 0x831c4030
	ctx.lr = 0x831DA084;
	sub_831C4030(ctx, base);
	// 831DA084: 393A0010  addi r9, r26, 0x10
	ctx.r[9].s64 = ctx.r[26].s64 + 16;
	// 831DA088: 93FA0000  stw r31, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831DA08C: 7FBED214  add r29, r30, r26
	ctx.r[29].u64 = ctx.r[30].u64 + ctx.r[26].u64;
	// 831DA090: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DA094: 913A0008  stw r9, 8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831DA098: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831DA09C: 419A0014  beq cr6, 0x831da0b0
	if ctx.cr[6].eq {
	pc = 0x831DA0B0; continue 'dispatch;
	}
	// 831DA0A0: 7C0BE8AC  dcbf r11, r29
	// 831DA0A4: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 831DA0A8: 7F0BE040  cmplw cr6, r11, r28
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[28].u32, &mut ctx.xer);
	// 831DA0AC: 4198FFF4  blt cr6, 0x831da0a0
	if ctx.cr[6].lt {
	pc = 0x831DA0A0; continue 'dispatch;
	}
	// 831DA0B0: 670B0003  oris r11, r24, 3
	ctx.r[11].u64 = ctx.r[24].u64 | 196608;
	// 831DA0B4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831DA0B8: 917A0004  stw r11, 4(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DA0BC: 419A00F4  beq cr6, 0x831da1b0
	if ctx.cr[6].eq {
	pc = 0x831DA1B0; continue 'dispatch;
	}
	// 831DA0C0: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831DA0C4: 3BDB0008  addi r30, r27, 8
	ctx.r[30].s64 = ctx.r[27].s64 + 8;
	// 831DA0C8: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831DA0CC: 7FFBFB78  mr r27, r31
	ctx.r[27].u64 = ctx.r[31].u64;
	// 831DA0D0: 6179AC44  ori r25, r11, 0xac44
	ctx.r[25].u64 = ctx.r[11].u64 | 44100;
	// 831DA0D4: 817A0008  lwz r11, 8(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA0D8: 7FFC5A14  add r31, r28, r11
	ctx.r[31].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831DA0DC: 93BF0044  stw r29, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[29].u32 ) };
	// 831DA0E0: 817EFFF8  lwz r11, -8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DA0E4: 2B0B5DC0  cmplwi cr6, r11, 0x5dc0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 24000 as u32, &mut ctx.xer);
	// 831DA0E8: 4199000C  bgt cr6, 0x831da0f4
	if ctx.cr[6].gt {
	pc = 0x831DA0F4; continue 'dispatch;
	}
	// 831DA0EC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DA0F0: 48000024  b 0x831da114
	pc = 0x831DA114; continue 'dispatch;
	// 831DA0F4: 2B0B7D00  cmplwi cr6, r11, 0x7d00
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32000 as u32, &mut ctx.xer);
	// 831DA0F8: 4199000C  bgt cr6, 0x831da104
	if ctx.cr[6].gt {
	pc = 0x831DA104; continue 'dispatch;
	}
	// 831DA0FC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831DA100: 48000014  b 0x831da114
	pc = 0x831DA114; continue 'dispatch;
	// 831DA104: 7D6BC810  subfc r11, r11, r25
	ctx.xer.ca = ctx.r[25].u32 >= ctx.r[11].u32;
	ctx.r[11].s64 = ctx.r[25].s64 - ctx.r[11].s64;
	// 831DA108: 7D4B5910  subfe r10, r11, r11
	let x = (!ctx.r[11].u32);
	let y = ctx.r[11].u32;
	let s = x.wrapping_add(y);
	let res = s.wrapping_add(ctx.xer.ca as u32);
	tmp.u8 = (s < x) as u8 | (res < s) as u8;
	ctx.r[10].u32 = res;
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	ctx.xer.ca = (tmp.u8 != 0);
	// 831DA10C: 554B07FE  clrlwi r11, r10, 0x1f
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831DA110: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 831DA114: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA118: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DA11C: 516AD8C8  rlwimi r10, r11, 0x1b, 3, 4
	ctx.r[10].u64 = (((ctx.r[11].u32).rotate_left(27) as u64) & 0x0000000018000000) | (ctx.r[10].u64 & 0xFFFFFFFFE7FFFFFF);
	// 831DA120: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DA124: 897E0000  lbz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA128: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 831DA12C: 512AE884  rlwimi r10, r9, 0x1d, 2, 2
	ctx.r[10].u64 = (((ctx.r[9].u32).rotate_left(29) as u64) & 0x0000000020000000) | (ctx.r[10].u64 & 0xFFFFFFFFDFFFFFFF);
	// 831DA130: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831DA134: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DA138: 88FE0001  lbz r7, 1(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 831DA13C: 50E8A216  rlwimi r8, r7, 0x14, 8, 0xb
	ctx.r[8].u64 = (((ctx.r[7].u32).rotate_left(20) as u64) & 0x0000000000F00000) | (ctx.r[8].u64 & 0xFFFFFFFFFF0FFFFF);
	// 831DA140: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831DA144: 48068979  bl 0x83242abc
	ctx.lr = 0x831DA148;
	// extern call 0x83242ABC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 831DA148: 907F001C  stw r3, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[3].u32 ) };
	// 831DA14C: 88DE0000  lbz r6, 0(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA150: 80BEFFFC  lwz r5, -4(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831DA154: 7C8629D6  mullw r4, r6, r5
	ctx.r[4].s64 = (ctx.r[6].s32 as i64) * (ctx.r[5].s32 as i64);
	// 831DA158: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA15C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA160: 656A8000  oris r10, r11, 0x8000
	ctx.r[10].u64 = ctx.r[11].u64 | 2147483648;
	// 831DA164: 50837952  rlwimi r3, r4, 0xf, 5, 9
	ctx.r[3].u64 = (((ctx.r[4].u32).rotate_left(15) as u64) & 0x0000000007C00000) | (ctx.r[3].u64 & 0xFFFFFFFFF83FFFFF);
	// 831DA168: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DA16C: 907F0000  stw r3, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831DA170: 893E0000  lbz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA174: 811EFFFC  lwz r8, -4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831DA178: 7CE941D6  mullw r7, r9, r8
	ctx.r[7].s64 = (ctx.r[9].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831DA17C: 54EB083C  slwi r11, r7, 1
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA180: 7FABEA14  add r29, r11, r29
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831DA184: 93BF0048  stw r29, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[29].u32 ) };
	// 831DA188: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DA18C: 48068931  bl 0x83242abc
	ctx.lr = 0x831DA190;
	// extern call 0x83242ABC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 831DA190: 907F0020  stw r3, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 831DA194: 88DE0000  lbz r6, 0(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA198: 54CB403E  rotlwi r11, r6, 8
	ctx.r[11].u64 = ((ctx.r[6].u32).rotate_left(8)) as u64;
	// 831DA19C: 377BFFFF  addic. r27, r27, -1
	ctx.xer.ca = (ctx.r[27].u32 > (!(-1 as u32)));
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 831DA1A0: 7FABEA14  add r29, r11, r29
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831DA1A4: 3B9C0060  addi r28, r28, 0x60
	ctx.r[28].s64 = ctx.r[28].s64 + 96;
	// 831DA1A8: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 831DA1AC: 4082FF28  bne 0x831da0d4
	if !ctx.cr[0].eq {
	pc = 0x831DA0D4; continue 'dispatch;
	}
	// 831DA1B0: 570B07FE  clrlwi r11, r24, 0x1f
	ctx.r[11].u64 = ctx.r[24].u32 as u64 & 0x00000001u64;
	// 831DA1B4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DA1B8: 409A002C  bne cr6, 0x831da1e4
	if !ctx.cr[6].eq {
	pc = 0x831DA1E4; continue 'dispatch;
	}
	// 831DA1BC: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DA1C0: 480009F9  bl 0x831dabb8
	ctx.lr = 0x831DA1C4;
	sub_831DABB8(ctx, base);
	// 831DA1C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DA1C8: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831DA1CC: 40980018  bge cr6, 0x831da1e4
	if !ctx.cr[6].lt {
	pc = 0x831DA1E4; continue 'dispatch;
	}
	// 831DA1D0: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DA1D4: 48000025  bl 0x831da1f8
	ctx.lr = 0x831DA1D8;
	sub_831DA1F8(ctx, base);
	// 831DA1D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DA1DC: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DA1E0: 4BFCDFC4  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 831DA1E4: 93570000  stw r26, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 831DA1E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA1EC: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DA1F0: 4BFCDFB4  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA1F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DA1F8 size=88
    let mut pc: u32 = 0x831DA1F8;
    'dispatch: loop {
        match pc {
            0x831DA1F8 => {
    //   block [0x831DA1F8..0x831DA250)
	// 831DA1F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DA1FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DA200: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DA204: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DA208: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DA20C: 4800009D  bl 0x831da2a8
	ctx.lr = 0x831DA210;
	sub_831DA2A8(ctx, base);
	// 831DA210: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA214: 556A07BC  rlwinm r10, r11, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA218: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA21C: 409A001C  bne cr6, 0x831da238
	if !ctx.cr[6].eq {
	pc = 0x831DA238; continue 'dispatch;
	}
	// 831DA220: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DA224: 3CA0A782  lis r5, -0x587e
	ctx.r[5].s64 = -1484652544;
	// 831DA228: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DA22C: 60A50007  ori r5, r5, 7
	ctx.r[5].u64 = ctx.r[5].u64 | 7;
	// 831DA230: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DA234: 4800248D  bl 0x831dc6c0
	ctx.lr = 0x831DA238;
	sub_831DC6C0(ctx, base);
	// 831DA238: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA23C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DA240: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DA244: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DA248: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DA24C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA250(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA250 size=84
    let mut pc: u32 = 0x831DA250;
    'dispatch: loop {
        match pc {
            0x831DA250 => {
    //   block [0x831DA250..0x831DA2A4)
	// 831DA250: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 831DA254: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DA258: 554B083C  slwi r11, r10, 1
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA25C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA260: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DA264: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA268: 390B008F  addi r8, r11, 0x8f
	ctx.r[8].s64 = ctx.r[11].s64 + 143;
	// 831DA26C: 55070030  rlwinm r7, r8, 0, 0, 0x18
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA270: 419A002C  beq cr6, 0x831da29c
	if ctx.cr[6].eq {
	pc = 0x831DA29C; continue 'dispatch;
	}
	// 831DA274: 39640008  addi r11, r4, 8
	ctx.r[11].s64 = ctx.r[4].s64 + 8;
	// 831DA278: 810BFFFC  lwz r8, -4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831DA27C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831DA280: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA284: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 831DA288: 38A80080  addi r5, r8, 0x80
	ctx.r[5].s64 = ctx.r[8].s64 + 128;
	// 831DA28C: 7C8531D6  mullw r4, r5, r6
	ctx.r[4].s64 = (ctx.r[5].s32 as i64) * (ctx.r[6].s32 as i64);
	// 831DA290: 5488083C  slwi r8, r4, 1
	ctx.r[8].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DA294: 7D284A14  add r9, r8, r9
	ctx.r[9].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831DA298: 4082FFE0  bne 0x831da278
	if !ctx.cr[0].eq {
	pc = 0x831DA278; continue 'dispatch;
	}
	// 831DA29C: 7C693A14  add r3, r9, r7
	ctx.r[3].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 831DA2A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA2A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DA2A8 size=120
    let mut pc: u32 = 0x831DA2A8;
    'dispatch: loop {
        match pc {
            0x831DA2A8 => {
    //   block [0x831DA2A8..0x831DA320)
	// 831DA2A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DA2AC: 4BFCDEBD  bl 0x831a8168
	ctx.lr = 0x831DA2B0;
	sub_831A8130(ctx, base);
	// 831DA2B0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DA2B4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DA2B8: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831DA2BC: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 831DA2C0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA2C4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DA2C8: 40990040  ble cr6, 0x831da308
	if !ctx.cr[6].gt {
	pc = 0x831DA308; continue 'dispatch;
	}
	// 831DA2CC: 7F9FE378  mr r31, r28
	ctx.r[31].u64 = ctx.r[28].u64;
	// 831DA2D0: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA2D4: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DA2D8: 806B0040  lwz r3, 0x40(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA2DC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DA2E0: 419A0014  beq cr6, 0x831da2f4
	if ctx.cr[6].eq {
	pc = 0x831DA2F4; continue 'dispatch;
	}
	// 831DA2E4: 48068EE9  bl 0x832431cc
	ctx.lr = 0x831DA2E8;
	// extern call 0x832431CC → crate::xboxkrnl::XMAReleaseContext
	crate::xboxkrnl::XMAReleaseContext(ctx, base);
	// 831DA2E8: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA2EC: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DA2F0: 938B0040  stw r28, 0x40(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(64 as u32), ctx.r[28].u32 ) };
	// 831DA2F4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA2F8: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831DA2FC: 3BFF0060  addi r31, r31, 0x60
	ctx.r[31].s64 = ctx.r[31].s64 + 96;
	// 831DA300: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DA304: 4198FFCC  blt cr6, 0x831da2d0
	if ctx.cr[6].lt {
	pc = 0x831DA2D0; continue 'dispatch;
	}
	// 831DA308: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA30C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA310: 556A0398  rlwinm r10, r11, 0, 0xe, 0xc
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA314: 915E0004  stw r10, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DA318: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DA31C: 4BFCDE9C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA320(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA320 size=12
    let mut pc: u32 = 0x831DA320;
    'dispatch: loop {
        match pc {
            0x831DA320 => {
    //   block [0x831DA320..0x831DA32C)
	// 831DA320: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA324: 556377FE  rlwinm r3, r11, 0xe, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x0003FFFFu64;
	// 831DA328: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DA330 size=212
    let mut pc: u32 = 0x831DA330;
    'dispatch: loop {
        match pc {
            0x831DA330 => {
    //   block [0x831DA330..0x831DA404)
	// 831DA330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DA334: 4BFCDE35  bl 0x831a8168
	ctx.lr = 0x831DA338;
	sub_831A8130(ctx, base);
	// 831DA338: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DA33C: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA340: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA344: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831DA348: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA34C: 54DEAAFE  srwi r30, r6, 0xb
	ctx.r[30].u32 = ctx.r[6].u32.wrapping_shr(11);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 831DA350: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA354: 7FEB5214  add r31, r11, r10
	ctx.r[31].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA358: 7D4B502E  lwzx r10, r11, r10
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831DA35C: 555C67BE  rlwinm r28, r10, 0xc, 0x1e, 0x1f
	ctx.r[28].u64 = ctx.r[10].u32 as u64 & 0x000FFFFFu64;
	// 831DA360: 578907FE  clrlwi r9, r28, 0x1f
	ctx.r[9].u64 = ctx.r[28].u32 as u64 & 0x00000001u64;
	// 831DA364: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA368: 409A0028  bne cr6, 0x831da390
	if !ctx.cr[6].eq {
	pc = 0x831DA390; continue 'dispatch;
	}
	// 831DA36C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DA370: 4806874D  bl 0x83242abc
	ctx.lr = 0x831DA374;
	// extern call 0x83242ABC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 831DA374: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA378: 907F0014  stw r3, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 831DA37C: 517E0026  rlwimi r30, r11, 0, 0, 0x13
	ctx.r[30].u64 = (((ctx.r[11].u32).rotate_left(0) as u64) & 0x00000000FFFFF000) | (ctx.r[30].u64 & 0xFFFFFFFF00000FFF);
	// 831DA380: 67CA0010  oris r10, r30, 0x10
	ctx.r[10].u64 = ctx.r[30].u64 | 1048576;
	// 831DA384: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DA388: 93BF0054  stw r29, 0x54(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(84 as u32), ctx.r[29].u32 ) };
	// 831DA38C: 48000038  b 0x831da3c4
	pc = 0x831DA3C4; continue 'dispatch;
	// 831DA390: 578B07BC  rlwinm r11, r28, 0, 0x1e, 0x1e
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA394: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DA398: 409A005C  bne cr6, 0x831da3f4
	if !ctx.cr[6].eq {
	pc = 0x831DA3F4; continue 'dispatch;
	}
	// 831DA39C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DA3A0: 4806871D  bl 0x83242abc
	ctx.lr = 0x831DA3A4;
	// extern call 0x83242ABC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 831DA3A4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA3A8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA3AC: 517E0026  rlwimi r30, r11, 0, 0, 0x13
	ctx.r[30].u64 = (((ctx.r[11].u32).rotate_left(0) as u64) & 0x00000000FFFFF000) | (ctx.r[30].u64 & 0xFFFFFFFF00000FFF);
	// 831DA3B0: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 831DA3B4: 65490020  oris r9, r10, 0x20
	ctx.r[9].u64 = ctx.r[10].u64 | 2097152;
	// 831DA3B8: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 831DA3BC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DA3C0: 93BF0058  stw r29, 0x58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(88 as u32), ctx.r[29].u32 ) };
	// 831DA3C4: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831DA3C8: 409A0020  bne cr6, 0x831da3e8
	if !ctx.cr[6].eq {
	pc = 0x831DA3E8; continue 'dispatch;
	}
	// 831DA3CC: 807D0000  lwz r3, 0(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA3D0: 480007C9  bl 0x831dab98
	ctx.lr = 0x831DA3D4;
	sub_831DAB98(ctx, base);
	// 831DA3D4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DA3D8: 419A0010  beq cr6, 0x831da3e8
	if ctx.cr[6].eq {
	pc = 0x831DA3E8; continue 'dispatch;
	}
	// 831DA3DC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA3E0: 5163000A  rlwimi r3, r11, 0, 0, 5
	ctx.r[3].u64 = (((ctx.r[11].u32).rotate_left(0) as u64) & 0x00000000FC000000) | (ctx.r[3].u64 & 0xFFFFFFFF03FFFFFF);
	// 831DA3E4: 907F0008  stw r3, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 831DA3E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA3EC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DA3F0: 4BFCDDC8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831DA3F4: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DA3F8: 60630005  ori r3, r3, 5
	ctx.r[3].u64 = ctx.r[3].u64 | 5;
	// 831DA3FC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DA400: 4BFCDDB8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA408(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA408 size=48
    let mut pc: u32 = 0x831DA408;
    'dispatch: loop {
        match pc {
            0x831DA408 => {
    //   block [0x831DA408..0x831DA438)
	// 831DA408: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA40C: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA410: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA414: 7D045A14  add r8, r4, r11
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA418: 5527039C  rlwinm r7, r9, 0, 0xe, 0xe
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA41C: 550B2834  slwi r11, r8, 5
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA420: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831DA424: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA428: 419A0010  beq cr6, 0x831da438
	if ctx.cr[6].eq {
		sub_831DA438(ctx, base);
		return;
	}
	// 831DA42C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA430: 554A67BE  rlwinm r10, r10, 0xc, 0x1e, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000FFFFFu64;
	// 831DA434: 48000010  b 0x831da444
	sub_831DA438(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA438(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA438 size=44
    let mut pc: u32 = 0x831DA438;
    'dispatch: loop {
        match pc {
            0x831DA438 => {
    //   block [0x831DA438..0x831DA464)
	// 831DA438: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA43C: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA440: 552A67BE  rlwinm r10, r9, 0xc, 0x1e, 0x1f
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x000FFFFFu64;
	// 831DA444: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831DA448: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA44C: 419A0018  beq cr6, 0x831da464
	if ctx.cr[6].eq {
		sub_831DA464(ctx, base);
		return;
	}
	// 831DA450: 812B0054  lwz r9, 0x54(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DA454: 7F092840  cmplw cr6, r9, r5
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[5].u32, &mut ctx.xer);
	// 831DA458: 409A000C  bne cr6, 0x831da464
	if !ctx.cr[6].eq {
		sub_831DA464(ctx, base);
		return;
	}
	// 831DA45C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831DA460: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA464(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA464 size=28
    let mut pc: u32 = 0x831DA464;
    'dispatch: loop {
        match pc {
            0x831DA464 => {
    //   block [0x831DA464..0x831DA480)
	// 831DA464: 554A07BC  rlwinm r10, r10, 0, 0x1e, 0x1e
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA468: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA46C: 419A0014  beq cr6, 0x831da480
	if ctx.cr[6].eq {
		sub_831DA480(ctx, base);
		return;
	}
	// 831DA470: 816B0058  lwz r11, 0x58(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DA474: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831DA478: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 831DA47C: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA480 size=8
    let mut pc: u32 = 0x831DA480;
    'dispatch: loop {
        match pc {
            0x831DA480 => {
    //   block [0x831DA480..0x831DA488)
	// 831DA480: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA484: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA488(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA488 size=60
    let mut pc: u32 = 0x831DA488;
    'dispatch: loop {
        match pc {
            0x831DA488 => {
    //   block [0x831DA488..0x831DA4C4)
	// 831DA488: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA48C: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA490: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA494: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA498: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA49C: 419A0028  beq cr6, 0x831da4c4
	if ctx.cr[6].eq {
		sub_831DA4C4(ctx, base);
		return;
	}
	// 831DA4A0: 7D245A14  add r9, r4, r11
	ctx.r[9].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA4A4: 55282834  slwi r8, r9, 5
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(5);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DA4A8: 7CE8502E  lwzx r7, r8, r10
	ctx.r[7].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831DA4AC: 54E60296  rlwinm r6, r7, 0, 0xa, 0xb
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA4B0: 3CA6FFD0  addis r5, r6, -0x30
	ctx.r[5].s64 = ctx.r[6].s64 + -3145728;
	// 831DA4B4: 7CA40034  cntlzw r4, r5
	ctx.r[4].u64 = if ctx.r[5].u32 == 0 { 32 } else { ctx.r[5].u32.leading_zeros() as u64 };
	// 831DA4B8: 5483DFFE  rlwinm r3, r4, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[4].u32 as u64 & 0x0000001Fu64;
	// 831DA4BC: 68630001  xori r3, r3, 1
	ctx.r[3].u64 = ctx.r[3].u64 ^ 1;
	// 831DA4C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA4C4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA4C4 size=44
    let mut pc: u32 = 0x831DA4C4;
    'dispatch: loop {
        match pc {
            0x831DA4C4 => {
    //   block [0x831DA4C4..0x831DA4F0)
	// 831DA4C4: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA4C8: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA4CC: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA4D0: 812A0040  lwz r9, 0x40(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA4D4: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA4D8: 55070296  rlwinm r7, r8, 0, 0xa, 0xb
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA4DC: 3CC7FFD0  addis r6, r7, -0x30
	ctx.r[6].s64 = ctx.r[7].s64 + -3145728;
	// 831DA4E0: 7CC50034  cntlzw r5, r6
	ctx.r[5].u64 = if ctx.r[6].u32 == 0 { 32 } else { ctx.r[6].u32.leading_zeros() as u64 };
	// 831DA4E4: 54A4DFFE  rlwinm r4, r5, 0x1b, 0x1f, 0x1f
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x0000001Fu64;
	// 831DA4E8: 68830001  xori r3, r4, 1
	ctx.r[3].u64 = ctx.r[4].u64 ^ 1;
	// 831DA4EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA4F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA4F0 size=56
    let mut pc: u32 = 0x831DA4F0;
    'dispatch: loop {
        match pc {
            0x831DA4F0 => {
    //   block [0x831DA4F0..0x831DA528)
	// 831DA4F0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA4F4: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA4F8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA4FC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA500: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA504: 419A0024  beq cr6, 0x831da528
	if ctx.cr[6].eq {
		sub_831DA528(ctx, base);
		return;
	}
	// 831DA508: 7D245A14  add r9, r4, r11
	ctx.r[9].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA50C: 55282834  slwi r8, r9, 5
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(5);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DA510: 7CE8502E  lwzx r7, r8, r10
	ctx.r[7].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831DA514: 54EB67BE  rlwinm r11, r7, 0xc, 0x1e, 0x1f
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000FFFFFu64;
	// 831DA518: 396B0000  addi r11, r11, 0
	ctx.r[11].s64 = ctx.r[11].s64 + 0;
	// 831DA51C: 7D6A0034  cntlzw r10, r11
	ctx.r[10].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 831DA520: 5543DFFE  rlwinm r3, r10, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 831DA524: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA528(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA528 size=40
    let mut pc: u32 = 0x831DA528;
    'dispatch: loop {
        match pc {
            0x831DA528 => {
    //   block [0x831DA528..0x831DA550)
	// 831DA528: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA52C: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA530: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA534: 812A0040  lwz r9, 0x40(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA538: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA53C: 550B67BE  rlwinm r11, r8, 0xc, 0x1e, 0x1f
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x000FFFFFu64;
	// 831DA540: 396B0000  addi r11, r11, 0
	ctx.r[11].s64 = ctx.r[11].s64 + 0;
	// 831DA544: 7D6A0034  cntlzw r10, r11
	ctx.r[10].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 831DA548: 5543DFFE  rlwinm r3, r10, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 831DA54C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA550(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA550 size=92
    let mut pc: u32 = 0x831DA550;
    'dispatch: loop {
        match pc {
            0x831DA550 => {
    //   block [0x831DA550..0x831DA5AC)
	// 831DA550: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA554: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA558: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA55C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA560: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA564: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA568: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA56C: 7D2B5214  add r9, r11, r10
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA570: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 831DA574: 409A0008  bne cr6, 0x831da57c
	if !ctx.cr[6].eq {
	pc = 0x831DA57C; continue 'dispatch;
	}
	// 831DA578: 81690040  lwz r11, 0x40(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA57C: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA580: 54EA0000  rlwinm r10, r7, 0, 0, 0
	ctx.r[10].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA584: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA588: 419A0034  beq cr6, 0x831da5bc
	if ctx.cr[6].eq {
		sub_831DA5BC(ctx, base);
		return;
	}
	// 831DA58C: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA590: 816B0024  lwz r11, 0x24(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA594: 550A2EFE  srwi r10, r8, 0x1b
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shr(27);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DA598: 556B06FE  clrlwi r11, r11, 0x1b
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 831DA59C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DA5A0: 4198000C  blt cr6, 0x831da5ac
	if ctx.cr[6].lt {
		sub_831DA5AC(ctx, base);
		return;
	}
	// 831DA5A4: 7D6B5050  subf r11, r11, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831DA5A8: 4800001C  b 0x831da5c4
	sub_831DA5BC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA5AC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA5AC size=16
    let mut pc: u32 = 0x831DA5AC;
    'dispatch: loop {
        match pc {
            0x831DA5AC => {
    //   block [0x831DA5AC..0x831DA5BC)
	// 831DA5AC: 550856FE  rlwinm r8, r8, 0xa, 0x1b, 0x1f
	ctx.r[8].u64 = ctx.r[8].u32 as u64 & 0x003FFFFFu64;
	// 831DA5B0: 7D6B4050  subf r11, r11, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[11].s64;
	// 831DA5B4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA5B8: 4800000C  b 0x831da5c4
	sub_831DA5BC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA5BC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA5BC size=36
    let mut pc: u32 = 0x831DA5BC;
    'dispatch: loop {
        match pc {
            0x831DA5BC => {
    //   block [0x831DA5BC..0x831DA5E0)
	// 831DA5BC: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA5C0: 556B56FE  rlwinm r11, r11, 0xa, 0x1b, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x003FFFFFu64;
	// 831DA5C4: 556A402E  slwi r10, r11, 8
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(8);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DA5C8: A1290052  lhz r9, 0x52(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(82 as u32) ) } as u64;
	// 831DA5CC: 54EB1FFE  rlwinm r11, r7, 3, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA5D0: 7D095050  subf r8, r9, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831DA5D4: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 831DA5D8: 7D033C30  srw r3, r8, r7
	if (ctx.r[7].u8 & 0x20) != 0 {
		ctx.r[3].u64 = 0;
	} else {
		ctx.r[3].u64 = ((ctx.r[8].u32) >> ((ctx.r[7].u8 & 0x1F) as u32)) as u64;
	}
	// 831DA5DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA5E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA5E0 size=436
    let mut pc: u32 = 0x831DA5E0;
    'dispatch: loop {
        match pc {
            0x831DA5E0 => {
    //   block [0x831DA5E0..0x831DA794)
	// 831DA5E0: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 831DA5E4: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831DA5E8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA5EC: 7D445A14  add r10, r4, r11
	ctx.r[10].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA5F0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA5F4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DA5F8: 555F2834  slwi r31, r10, 5
	ctx.r[31].u32 = ctx.r[10].u32.wrapping_shl(5);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 831DA5FC: 7D7F5A14  add r11, r31, r11
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DA600: 812B0024  lwz r9, 0x24(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA604: 814B0044  lwz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831DA608: 552844EE  rlwinm r8, r9, 8, 0x13, 0x17
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x00FFFFFFu64;
	// 831DA60C: A12B0052  lhz r9, 0x52(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(82 as u32) ) } as u64;
	// 831DA610: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 831DA614: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA618: 7D0A4A14  add r8, r10, r9
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831DA61C: 91060000  stw r8, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831DA620: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA624: 54EA1FFE  rlwinm r10, r7, 3, 0x1f, 0x1f
	ctx.r[10].u64 = ctx.r[7].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA628: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 831DA62C: 7CAA3030  slw r10, r5, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[10].u64 = 0;
	} else {
		ctx.r[10].u64 = ((ctx.r[5].u32) << ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 831DA630: 419A0080  beq cr6, 0x831da6b0
	if ctx.cr[6].eq {
	pc = 0x831DA6B0; continue 'dispatch;
	}
	// 831DA634: 21090100  subfic r8, r9, 0x100
	ctx.xer.ca = ctx.r[9].u32 <= 256 as u32;
	ctx.r[8].s64 = (256 as i64) - ctx.r[9].s64;
	// 831DA638: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DA63C: 4098001C  bge cr6, 0x831da658
	if !ctx.cr[6].lt {
	pc = 0x831DA658; continue 'dispatch;
	}
	// 831DA640: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA644: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831DA648: 7D445378  mr r4, r10
	ctx.r[4].u64 = ctx.r[10].u64;
	// 831DA64C: 7D1F4214  add r8, r31, r8
	ctx.r[8].u64 = ctx.r[31].u64 + ctx.r[8].u64;
	// 831DA650: B1280052  sth r9, 0x52(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(82 as u32), ctx.r[9].u16 ) };
	// 831DA654: 48000058  b 0x831da6ac
	pc = 0x831DA6AC; continue 'dispatch;
	// 831DA658: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA65C: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 831DA660: 7D044378  mr r4, r8
	ctx.r[4].u64 = ctx.r[8].u64;
	// 831DA664: 7CDF4A14  add r6, r31, r9
	ctx.r[6].u64 = ctx.r[31].u64 + ctx.r[9].u64;
	// 831DA668: 7D485050  subf r10, r8, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831DA66C: B0E60052  sth r7, 0x52(r6)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[6].u32.wrapping_add(82 as u32), ctx.r[7].u16 ) };
	// 831DA670: 80AB0000  lwz r5, 0(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA674: 810B0024  lwz r8, 0x24(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA678: 550906FE  clrlwi r9, r8, 0x1b
	ctx.r[9].u64 = ctx.r[8].u32 as u64 & 0x0000001Fu64;
	// 831DA67C: 54A756FE  rlwinm r7, r5, 0xa, 0x1b, 0x1f
	ctx.r[7].u64 = ctx.r[5].u32 as u64 & 0x003FFFFFu64;
	// 831DA680: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DA684: 7F093840  cmplw cr6, r9, r7
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831DA688: 41980008  blt cr6, 0x831da690
	if ctx.cr[6].lt {
	pc = 0x831DA690; continue 'dispatch;
	}
	// 831DA68C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DA690: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA694: 512806FE  rlwimi r8, r9, 0, 0x1b, 0x1f
	ctx.r[8].u64 = (((ctx.r[9].u32).rotate_left(0) as u64) & 0x000000000000001F) | (ctx.r[8].u64 & 0xFFFFFFFFFFFFFFE0);
	// 831DA698: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA69C: 64E68000  oris r6, r7, 0x8000
	ctx.r[6].u64 = ctx.r[7].u64 | 2147483648;
	// 831DA6A0: 910B0024  stw r8, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[8].u32 ) };
	// 831DA6A4: 90CB0004  stw r6, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831DA6A8: 409A0008  bne cr6, 0x831da6b0
	if !ctx.cr[6].eq {
	pc = 0x831DA6B0; continue 'dispatch;
	}
	// 831DA6AC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DA6B0: 80AB0024  lwz r5, 0x24(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA6B4: 5548C23E  srwi r8, r10, 8
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shr(8);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DA6B8: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA6BC: 555E063E  clrlwi r30, r10, 0x18
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831DA6C0: 54AA06FE  clrlwi r10, r5, 0x1b
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x0000001Fu64;
	// 831DA6C4: 54C72EFE  srwi r7, r6, 0x1b
	ctx.r[7].u32 = ctx.r[6].u32.wrapping_shr(27);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DA6C8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DA6CC: 7F075040  cmplw cr6, r7, r10
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DA6D0: 4099000C  ble cr6, 0x831da6dc
	if !ctx.cr[6].gt {
	pc = 0x831DA6DC; continue 'dispatch;
	}
	// 831DA6D4: 7D2A3850  subf r9, r10, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 831DA6D8: 48000020  b 0x831da6f8
	pc = 0x831DA6F8; continue 'dispatch;
	// 831DA6DC: 41980014  blt cr6, 0x831da6f0
	if ctx.cr[6].lt {
	pc = 0x831DA6F0; continue 'dispatch;
	}
	// 831DA6E0: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA6E4: 54E70000  rlwinm r7, r7, 0, 0, 0
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA6E8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831DA6EC: 409A000C  bne cr6, 0x831da6f8
	if !ctx.cr[6].eq {
	pc = 0x831DA6F8; continue 'dispatch;
	}
	// 831DA6F0: 54C956FE  rlwinm r9, r6, 0xa, 0x1b, 0x1f
	ctx.r[9].u64 = ctx.r[6].u32 as u64 & 0x003FFFFFu64;
	// 831DA6F4: 7D2A4850  subf r9, r10, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 831DA6F8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DA6FC: 419A0044  beq cr6, 0x831da740
	if ctx.cr[6].eq {
	pc = 0x831DA740; continue 'dispatch;
	}
	// 831DA700: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DA704: 41980008  blt cr6, 0x831da70c
	if ctx.cr[6].lt {
	pc = 0x831DA70C; continue 'dispatch;
	}
	// 831DA708: 7D284B78  mr r8, r9
	ctx.r[8].u64 = ctx.r[9].u64;
	// 831DA70C: 5507402E  slwi r7, r8, 8
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DA710: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831DA714: 54C656FE  rlwinm r6, r6, 0xa, 0x1b, 0x1f
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x003FFFFFu64;
	// 831DA718: 7C872214  add r4, r7, r4
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[4].u64;
	// 831DA71C: 7D284850  subf r9, r8, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[8].s64;
	// 831DA720: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831DA724: 41980008  blt cr6, 0x831da72c
	if ctx.cr[6].lt {
	pc = 0x831DA72C; continue 'dispatch;
	}
	// 831DA728: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DA72C: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA730: 514506FE  rlwimi r5, r10, 0, 0x1b, 0x1f
	ctx.r[5].u64 = (((ctx.r[10].u32).rotate_left(0) as u64) & 0x000000000000001F) | (ctx.r[5].u64 & 0xFFFFFFFFFFFFFFE0);
	// 831DA734: 65078000  oris r7, r8, 0x8000
	ctx.r[7].u64 = ctx.r[8].u64 | 2147483648;
	// 831DA738: 90AB0024  stw r5, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[5].u32 ) };
	// 831DA73C: 90EB0004  stw r7, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831DA740: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831DA744: 419A001C  beq cr6, 0x831da760
	if ctx.cr[6].eq {
	pc = 0x831DA760; continue 'dispatch;
	}
	// 831DA748: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA74C: 419A0014  beq cr6, 0x831da760
	if ctx.cr[6].eq {
	pc = 0x831DA760; continue 'dispatch;
	}
	// 831DA750: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA754: 7C9E2214  add r4, r30, r4
	ctx.r[4].u64 = ctx.r[30].u64 + ctx.r[4].u64;
	// 831DA758: 7D1F5214  add r8, r31, r10
	ctx.r[8].u64 = ctx.r[31].u64 + ctx.r[10].u64;
	// 831DA75C: B3C80052  sth r30, 0x52(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(82 as u32), ctx.r[30].u16 ) };
	// 831DA760: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA764: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA768: 7D7F5214  add r11, r31, r10
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[10].u64;
	// 831DA76C: 55291FFE  rlwinm r9, r9, 3, 0x1f, 0x1f
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA770: 394B004C  addi r10, r11, 0x4c
	ctx.r[10].s64 = ctx.r[11].s64 + 76;
	// 831DA774: 39090001  addi r8, r9, 1
	ctx.r[8].s64 = ctx.r[9].s64 + 1;
	// 831DA778: 814B004C  lwz r10, 0x4c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DA77C: 7C834430  srw r3, r4, r8
	if (ctx.r[8].u8 & 0x20) != 0 {
		ctx.r[3].u64 = 0;
	} else {
		ctx.r[3].u64 = ((ctx.r[4].u32) >> ((ctx.r[8].u8 & 0x1F) as u32)) as u64;
	}
	// 831DA780: 7CEA1A14  add r7, r10, r3
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 831DA784: 90EB004C  stw r7, 0x4c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(76 as u32), ctx.r[7].u32 ) };
	// 831DA788: EBC1FFF0  ld r30, -0x10(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DA78C: EBE1FFF8  ld r31, -8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	// 831DA790: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA798(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA798 size=120
    let mut pc: u32 = 0x831DA798;
    'dispatch: loop {
        match pc {
            0x831DA798 => {
    //   block [0x831DA798..0x831DA810)
	// 831DA798: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA79C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA7A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA7A4: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA7A8: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA7AC: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA7B0: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA7B4: 810B0044  lwz r8, 0x44(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831DA7B8: 554944EE  rlwinm r9, r10, 8, 0x13, 0x17
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00FFFFFFu64;
	// 831DA7BC: A14B0052  lhz r10, 0x52(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(82 as u32) ) } as u64;
	// 831DA7C0: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 831DA7C4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA7C8: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DA7CC: 91250000  stw r9, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DA7D0: 80EB0024  lwz r7, 0x24(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA7D4: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA7D8: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA7DC: 54C92EFE  srwi r9, r6, 0x1b
	ctx.r[9].u32 = ctx.r[6].u32.wrapping_shr(27);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DA7E0: 54EB06FE  clrlwi r11, r7, 0x1b
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x0000001Fu64;
	// 831DA7E4: 54C656FE  rlwinm r6, r6, 0xa, 0x1b, 0x1f
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x003FFFFFu64;
	// 831DA7E8: 55070FFE  srwi r7, r8, 0x1f
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shr(31);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DA7EC: 419A0010  beq cr6, 0x831da7fc
	if ctx.cr[6].eq {
	pc = 0x831DA7FC; continue 'dispatch;
	}
	// 831DA7F0: 206A0100  subfic r3, r10, 0x100
	ctx.xer.ca = ctx.r[10].u32 <= 256 as u32;
	ctx.r[3].s64 = (256 as i64) - ctx.r[10].s64;
	// 831DA7F4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DA7F8: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 831DA7FC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DA800: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DA804: 4099000C  ble cr6, 0x831da810
	if !ctx.cr[6].gt {
		sub_831DA810(ctx, base);
		return;
	}
	// 831DA808: 7D4B4850  subf r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831DA80C: 48000018  b 0x831da824
	sub_831DA810(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA810(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA810 size=44
    let mut pc: u32 = 0x831DA810;
    'dispatch: loop {
        match pc {
            0x831DA810 => {
    //   block [0x831DA810..0x831DA83C)
	// 831DA810: 41980010  blt cr6, 0x831da820
	if ctx.cr[6].lt {
	pc = 0x831DA820; continue 'dispatch;
	}
	// 831DA814: 54E9063E  clrlwi r9, r7, 0x18
	ctx.r[9].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831DA818: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA81C: 409A0008  bne cr6, 0x831da824
	if !ctx.cr[6].eq {
	pc = 0x831DA824; continue 'dispatch;
	}
	// 831DA820: 7D4B3050  subf r10, r11, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 831DA824: 55091FFE  rlwinm r9, r8, 3, 0x1f, 0x1f
	ctx.r[9].u64 = ctx.r[8].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA828: 554B402E  slwi r11, r10, 8
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(8);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA82C: 39490001  addi r10, r9, 1
	ctx.r[10].s64 = ctx.r[9].s64 + 1;
	// 831DA830: 7D2B1A14  add r9, r11, r3
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831DA834: 7D235430  srw r3, r9, r10
	if (ctx.r[10].u8 & 0x20) != 0 {
		ctx.r[3].u64 = 0;
	} else {
		ctx.r[3].u64 = ((ctx.r[9].u32) >> ((ctx.r[10].u8 & 0x1F) as u32)) as u64;
	}
	// 831DA838: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA840(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA840 size=100
    let mut pc: u32 = 0x831DA840;
    'dispatch: loop {
        match pc {
            0x831DA840 => {
    //   block [0x831DA840..0x831DA8A4)
	// 831DA840: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA844: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA848: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831DA84C: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA850: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA854: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA858: 80EB0004  lwz r7, 4(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA85C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA860: 54E81FFE  rlwinm r8, r7, 3, 0x1f, 0x1f
	ctx.r[8].u64 = ctx.r[7].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA864: 554956FE  rlwinm r9, r10, 0xa, 0x1b, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x003FFFFFu64;
	// 831DA868: 20C80007  subfic r6, r8, 7
	ctx.xer.ca = ctx.r[8].u32 <= 7 as u32;
	ctx.r[6].s64 = (7 as i64) - ctx.r[8].s64;
	// 831DA86C: 7CA83430  srw r8, r5, r6
	if (ctx.r[6].u8 & 0x20) != 0 {
		ctx.r[8].u64 = 0;
	} else {
		ctx.r[8].u64 = ((ctx.r[5].u32) >> ((ctx.r[6].u8 & 0x1F) as u32)) as u64;
	}
	// 831DA870: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DA874: 40980030  bge cr6, 0x831da8a4
	if !ctx.cr[6].lt {
		sub_831DA8A4(ctx, base);
		return;
	}
	// 831DA878: 55462EFE  srwi r6, r10, 0x1b
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shr(27);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DA87C: 7D083050  subf r8, r8, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[8].s64;
	// 831DA880: 7D084A14  add r8, r8, r9
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 831DA884: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DA888: 41980028  blt cr6, 0x831da8b0
	if ctx.cr[6].lt {
		sub_831DA8A4(ctx, base);
		return;
	}
	// 831DA88C: 7D094050  subf r8, r9, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 831DA890: 64E98000  oris r9, r7, 0x8000
	ctx.r[9].u64 = ctx.r[7].u64 | 2147483648;
	// 831DA894: 510AD808  rlwimi r10, r8, 0x1b, 0, 4
	ctx.r[10].u64 = (((ctx.r[8].u32).rotate_left(27) as u64) & 0x00000000F8000000) | (ctx.r[10].u64 & 0xFFFFFFFF07FFFFFF);
	// 831DA898: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DA89C: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DA8A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA8A4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA8A4 size=32
    let mut pc: u32 = 0x831DA8A4;
    'dispatch: loop {
        match pc {
            0x831DA8A4 => {
    //   block [0x831DA8A4..0x831DA8C4)
	// 831DA8A4: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA8A8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA8AC: 552801BE  clrlwi r8, r9, 6
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x03FFFFFFu64;
	// 831DA8B0: 64E98000  oris r9, r7, 0x8000
	ctx.r[9].u64 = ctx.r[7].u64 | 2147483648;
	// 831DA8B4: 510AD808  rlwimi r10, r8, 0x1b, 0, 4
	ctx.r[10].u64 = (((ctx.r[8].u32).rotate_left(27) as u64) & 0x00000000F8000000) | (ctx.r[10].u64 & 0xFFFFFFFF07FFFFFF);
	// 831DA8B8: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DA8BC: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DA8C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA8C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DA8C8 size=176
    let mut pc: u32 = 0x831DA8C8;
    'dispatch: loop {
        match pc {
            0x831DA8C8 => {
    //   block [0x831DA8C8..0x831DA978)
	// 831DA8C8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA8CC: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA8D0: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831DA8D4: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA8D8: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 831DA8DC: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA8E0: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831DA8E4: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA8E8: 55291FFE  rlwinm r9, r9, 3, 0x1f, 0x1f
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0x1FFFFFFFu64;
	// 831DA8EC: 38E90001  addi r7, r9, 1
	ctx.r[7].s64 = ctx.r[9].s64 + 1;
	// 831DA8F0: 54E9402E  slwi r9, r7, 8
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(8);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DA8F4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DA8F8: 419A0018  beq cr6, 0x831da910
	if ctx.cr[6].eq {
	pc = 0x831DA910; continue 'dispatch;
	}
	// 831DA8FC: 80EB0048  lwz r7, 0x48(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 831DA900: 7C0A3FEC  dcbz r10, r7
	ea.u32 = ctx.r[10].u32.wrapping_add(ctx.r[7].u32);
	ea.u32 &= !31;
	unsafe { crate::rt::memset_ea(ea.u32, 0, 32) };
	// 831DA904: 394A0080  addi r10, r10, 0x80
	ctx.r[10].s64 = ctx.r[10].s64 + 128;
	// 831DA908: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DA90C: 4198FFF0  blt cr6, 0x831da8fc
	if ctx.cr[6].lt {
	pc = 0x831DA8FC; continue 'dispatch;
	}
	// 831DA910: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DA914: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831DA918: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DA91C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DA920: 5545007E  clrlwi r5, r10, 1
	ctx.r[5].u64 = ctx.r[10].u32 as u64 & 0x7FFFFFFFu64;
	// 831DA924: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA928: 54EA0166  rlwinm r10, r7, 0, 5, 0x13
	ctx.r[10].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA92C: 80CB0024  lwz r6, 0x24(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DA930: 80EB000C  lwz r7, 0xc(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DA934: 5124FD00  rlwimi r4, r9, 0x1f, 0x14, 0
	ctx.r[4].u64 = (((ctx.r[9].u32).rotate_left(31) as u64) & 0xFFFFFFFF80000FFF) | (ctx.r[4].u64 & 0x000000007FFFF000);
	// 831DA938: 554A0312  rlwinm r10, r10, 0, 0xc, 9
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA93C: 910B0014  stw r8, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[8].u32 ) };
	// 831DA940: 54C60034  rlwinm r6, r6, 0, 0, 0x1a
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA944: 910B0018  stw r8, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[8].u32 ) };
	// 831DA948: 54E901BE  clrlwi r9, r7, 6
	ctx.r[9].u64 = ctx.r[7].u32 as u64 & 0x03FFFFFFu64;
	// 831DA94C: 90AB0010  stw r5, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[5].u32 ) };
	// 831DA950: 910B0054  stw r8, 0x54(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(84 as u32), ctx.r[8].u32 ) };
	// 831DA954: 910B0058  stw r8, 0x58(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(88 as u32), ctx.r[8].u32 ) };
	// 831DA958: 910B004C  stw r8, 0x4c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(76 as u32), ctx.r[8].u32 ) };
	// 831DA95C: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DA960: 90CB0024  stw r6, 0x24(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), ctx.r[6].u32 ) };
	// 831DA964: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831DA968: B10B0052  sth r8, 0x52(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(82 as u32), ctx.r[8].u16 ) };
	// 831DA96C: 910B0008  stw r8, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831DA970: 912B000C  stw r9, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 831DA974: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA978 size=48
    let mut pc: u32 = 0x831DA978;
    'dispatch: loop {
        match pc {
            0x831DA978 => {
    //   block [0x831DA978..0x831DA9A8)
	// 831DA978: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA97C: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA980: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA984: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA988: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA98C: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA990: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA994: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA998: 419A0010  beq cr6, 0x831da9a8
	if ctx.cr[6].eq {
		sub_831DA9A8(ctx, base);
		return;
	}
	// 831DA99C: 812A0008  lwz r9, 8(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA9A0: 552336FE  rlwinm r3, r9, 6, 0x1b, 0x1f
	ctx.r[3].u64 = ctx.r[9].u32 as u64 & 0x03FFFFFFu64;
	// 831DA9A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA9A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA9A8 size=16
    let mut pc: u32 = 0x831DA9A8;
    'dispatch: loop {
        match pc {
            0x831DA9A8 => {
    //   block [0x831DA9A8..0x831DA9B8)
	// 831DA9A8: 812A0040  lwz r9, 0x40(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA9AC: 81090008  lwz r8, 8(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA9B0: 550336FE  rlwinm r3, r8, 6, 0x1b, 0x1f
	ctx.r[3].u64 = ctx.r[8].u32 as u64 & 0x03FFFFFFu64;
	// 831DA9B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA9B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA9B8 size=48
    let mut pc: u32 = 0x831DA9B8;
    'dispatch: loop {
        match pc {
            0x831DA9B8 => {
    //   block [0x831DA9B8..0x831DA9E8)
	// 831DA9B8: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DA9BC: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DA9C0: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA9C4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DA9C8: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DA9CC: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DA9D0: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA9D4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DA9D8: 419A0010  beq cr6, 0x831da9e8
	if ctx.cr[6].eq {
		sub_831DA9E8(ctx, base);
		return;
	}
	// 831DA9DC: 812A000C  lwz r9, 0xc(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DA9E0: 552336FE  rlwinm r3, r9, 6, 0x1b, 0x1f
	ctx.r[3].u64 = ctx.r[9].u32 as u64 & 0x03FFFFFFu64;
	// 831DA9E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA9E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA9E8 size=16
    let mut pc: u32 = 0x831DA9E8;
    'dispatch: loop {
        match pc {
            0x831DA9E8 => {
    //   block [0x831DA9E8..0x831DA9F8)
	// 831DA9E8: 812A0040  lwz r9, 0x40(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DA9EC: 8109000C  lwz r8, 0xc(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DA9F0: 550336FE  rlwinm r3, r8, 6, 0x1b, 0x1f
	ctx.r[3].u64 = ctx.r[8].u32 as u64 & 0x03FFFFFFu64;
	// 831DA9F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DA9F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DA9F8 size=116
    let mut pc: u32 = 0x831DA9F8;
    'dispatch: loop {
        match pc {
            0x831DA9F8 => {
    //   block [0x831DA9F8..0x831DAA6C)
	// 831DA9F8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DA9FC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAA00: 8925000A  lbz r9, 0xa(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[5].u32.wrapping_add(10 as u32) ) } as u64;
	// 831DAA04: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAA08: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAA0C: 5528603E  rotlwi r8, r9, 0xc
	ctx.r[8].u64 = ((ctx.r[9].u32).rotate_left(12)) as u64;
	// 831DAA10: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAA14: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DAA18: 80EB0000  lwz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAA1C: 80CB0004  lwz r6, 4(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAA20: 54E40516  rlwinm r4, r7, 0, 0x14, 0xb
	ctx.r[4].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAA24: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DAA28: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DAA2C: 7D082378  or r8, r8, r4
	ctx.r[8].u64 = ctx.r[8].u64 | ctx.r[4].u64;
	// 831DAA30: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831DAA34: 88E50008  lbz r7, 8(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAA38: 50E664A6  rlwimi r6, r7, 0xc, 0x12, 0x13
	ctx.r[6].u64 = (((ctx.r[7].u32).rotate_left(12) as u64) & 0x0000000000003000) | (ctx.r[6].u64 & 0xFFFFFFFFFFFFCFFF);
	// 831DAA3C: 7CC43378  mr r4, r6
	ctx.r[4].u64 = ctx.r[6].u64;
	// 831DAA40: 90CB0004  stw r6, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831DAA44: 89050009  lbz r8, 9(r5)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[5].u32.wrapping_add(9 as u32) ) } as u64;
	// 831DAA48: 51048B1C  rlwimi r4, r8, 0x11, 0xc, 0xe
	ctx.r[4].u64 = (((ctx.r[8].u32).rotate_left(17) as u64) & 0x00000000000E0000) | (ctx.r[4].u64 & 0xFFFFFFFFFFF1FFFF);
	// 831DAA4C: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831DAA50: 80E50000  lwz r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAA54: 50EA01BE  rlwimi r10, r7, 0, 6, 0x1f
	ctx.r[10].u64 = (((ctx.r[7].u32).rotate_left(0) as u64) & 0x0000000003FFFFFF) | (ctx.r[10].u64 & 0xFFFFFFFFFC000000);
	// 831DAA58: 914B000C  stw r10, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831DAA5C: 80C50004  lwz r6, 4(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAA60: 5126000A  rlwimi r6, r9, 0, 0, 5
	ctx.r[6].u64 = (((ctx.r[9].u32).rotate_left(0) as u64) & 0x00000000FC000000) | (ctx.r[6].u64 & 0xFFFFFFFF03FFFFFF);
	// 831DAA64: 90CB0010  stw r6, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[6].u32 ) };
	// 831DAA68: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAA70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAA70 size=44
    let mut pc: u32 = 0x831DAA70;
    'dispatch: loop {
        match pc {
            0x831DAA70 => {
    //   block [0x831DAA70..0x831DAA9C)
	// 831DAA70: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAA74: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAA78: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAA7C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DAA80: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAA84: 419A0018  beq cr6, 0x831daa9c
	if ctx.cr[6].eq {
		sub_831DAA9C(ctx, base);
		return;
	}
	// 831DAA88: 7D245A14  add r9, r4, r11
	ctx.r[9].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAA8C: 55282834  slwi r8, r9, 5
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(5);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DAA90: 7CE8502E  lwzx r7, r8, r10
	ctx.r[7].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831DAA94: 54E3A63E  rlwinm r3, r7, 0x14, 0x18, 0x1f
	ctx.r[3].u64 = ctx.r[7].u32 as u64 & 0x00000FFFu64;
	// 831DAA98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAA9C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAA9C size=28
    let mut pc: u32 = 0x831DAA9C;
    'dispatch: loop {
        match pc {
            0x831DAA9C => {
    //   block [0x831DAA9C..0x831DAAB8)
	// 831DAA9C: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAAA0: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAAA4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DAAA8: 812A0040  lwz r9, 0x40(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DAAAC: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAAB0: 5503A63E  rlwinm r3, r8, 0x14, 0x18, 0x1f
	ctx.r[3].u64 = ctx.r[8].u32 as u64 & 0x00000FFFu64;
	// 831DAAB4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAAB8 size=28
    let mut pc: u32 = 0x831DAAB8;
    'dispatch: loop {
        match pc {
            0x831DAAB8 => {
    //   block [0x831DAAB8..0x831DAAD4)
	// 831DAAB8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAABC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAAC0: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAAC4: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAAC8: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DAACC: 806A004C  lwz r3, 0x4c(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DAAD0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAAD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAAD8 size=84
    let mut pc: u32 = 0x831DAAD8;
    'dispatch: loop {
        match pc {
            0x831DAAD8 => {
    //   block [0x831DAAD8..0x831DAB2C)
	// 831DAAD8: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAADC: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAAE0: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAAE4: 7D045A14  add r8, r4, r11
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAAE8: 5527039C  rlwinm r7, r9, 0, 0xe, 0xe
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAAEC: 550B2834  slwi r11, r8, 5
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAAF0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831DAAF4: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DAAF8: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831DAAFC: 409A0008  bne cr6, 0x831dab04
	if !ctx.cr[6].eq {
	pc = 0x831DAB04; continue 'dispatch;
	}
	// 831DAB00: 816A0040  lwz r11, 0x40(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DAB04: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAB08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAB0C: 55280296  rlwinm r8, r9, 0, 0xa, 0xb
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAB10: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DAB14: 409A0018  bne cr6, 0x831dab2c
	if !ctx.cr[6].eq {
		sub_831DAB2C(ctx, base);
		return;
	}
	// 831DAB18: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DAB1C: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DAB20: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DAB24: 91650008  stw r11, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 831DAB28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAB2C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAB2C size=52
    let mut pc: u32 = 0x831DAB2C;
    'dispatch: loop {
        match pc {
            0x831DAB2C => {
    //   block [0x831DAB2C..0x831DAB60)
	// 831DAB2C: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DAB30: 55290FFE  srwi r9, r9, 0x1f
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(31);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DAB34: 39090015  addi r8, r9, 0x15
	ctx.r[8].s64 = ctx.r[9].s64 + 21;
	// 831DAB38: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DAB3C: 7CC7502E  lwzx r6, r7, r10
	ctx.r[6].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 831DAB40: 90C50000  stw r6, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831DAB44: 808B0008  lwz r4, 8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAB48: 548A01BE  clrlwi r10, r4, 6
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x03FFFFFFu64;
	// 831DAB4C: 91450004  stw r10, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DAB50: 892B0004  lbz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAB54: 5528077E  clrlwi r8, r9, 0x1d
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x00000007u64;
	// 831DAB58: 91050008  stw r8, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831DAB5C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAB60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAB60 size=52
    let mut pc: u32 = 0x831DAB60;
    'dispatch: loop {
        match pc {
            0x831DAB60 => {
    //   block [0x831DAB60..0x831DAB94)
	// 831DAB60: 548B083C  slwi r11, r4, 1
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAB64: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAB68: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAB6C: 7D645A14  add r11, r4, r11
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[11].u64;
	// 831DAB70: 556B2834  slwi r11, r11, 5
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DAB74: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DAB78: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAB7C: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAB80: 5145000A  rlwimi r5, r10, 0, 0, 5
	ctx.r[5].u64 = (((ctx.r[10].u32).rotate_left(0) as u64) & 0x00000000FC000000) | (ctx.r[5].u64 & 0xFFFFFFFF03FFFFFF);
	// 831DAB84: 50C9C14E  rlwimi r9, r6, 0x18, 5, 7
	ctx.r[9].u64 = (((ctx.r[6].u32).rotate_left(24) as u64) & 0x0000000007000000) | (ctx.r[9].u64 & 0xFFFFFFFFF8FFFFFF);
	// 831DAB88: 90AB0008  stw r5, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 831DAB8C: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DAB90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAB98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAB98 size=16
    let mut pc: u32 = 0x831DAB98;
    'dispatch: loop {
        match pc {
            0x831DAB98 => {
    //   block [0x831DAB98..0x831DABA8)
	// 831DAB98: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831DAB9C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DABA0: 2B0B7FFF  cmplwi cr6, r11, 0x7fff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32767 as u32, &mut ctx.xer);
	// 831DABA4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DABA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DABA8 size=12
    let mut pc: u32 = 0x831DABA8;
    'dispatch: loop {
        match pc {
            0x831DABA8 => {
    //   block [0x831DABA8..0x831DABB4)
	// 831DABA8: 556BAC7E  rlwinm r11, r11, 0x15, 0x11, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000007FFu64;
	// 831DABAC: 386B0020  addi r3, r11, 0x20
	ctx.r[3].s64 = ctx.r[11].s64 + 32;
	// 831DABB0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DABB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DABB8 size=200
    let mut pc: u32 = 0x831DABB8;
    'dispatch: loop {
        match pc {
            0x831DABB8 => {
    //   block [0x831DABB8..0x831DAC80)
	// 831DABB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DABBC: 4BFCD599  bl 0x831a8154
	ctx.lr = 0x831DABC0;
	sub_831A8130(ctx, base);
	// 831DABC0: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DABC4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DABC8: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 831DABCC: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 831DABD0: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DABD4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DABD8: 40990090  ble cr6, 0x831dac68
	if !ctx.cr[6].gt {
	pc = 0x831DAC68; continue 'dispatch;
	}
	// 831DABDC: 3D601FFA  lis r11, 0x1ffa
	ctx.r[11].s64 = 536477696;
	// 831DABE0: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831DABE4: 3B200001  li r25, 1
	ctx.r[25].s64 = 1;
	// 831DABE8: 617B86A0  ori r27, r11, 0x86a0
	ctx.r[27].u64 = ctx.r[11].u64 | 34464;
	// 831DABEC: 3F408343  lis r26, -0x7cbd
	ctx.r[26].s64 = -2092761088;
	// 831DABF0: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DABF4: 7FDC5A14  add r30, r28, r11
	ctx.r[30].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 831DABF8: 3BFE0040  addi r31, r30, 0x40
	ctx.r[31].s64 = ctx.r[30].s64 + 64;
	// 831DABFC: 817E0040  lwz r11, 0x40(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DAC00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DAC04: 409A0050  bne cr6, 0x831dac54
	if !ctx.cr[6].eq {
	pc = 0x831DAC54; continue 'dispatch;
	}
	// 831DAC08: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DAC0C: 480685D1  bl 0x832431dc
	ctx.lr = 0x831DAC10;
	// extern call 0x832431DC → crate::xboxkrnl::XMACreateContext
	crate::xboxkrnl::XMACreateContext(ctx, base);
	// 831DAC10: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 831DAC14: 2F170000  cmpwi cr6, r23, 0
	ctx.cr[6].compare_i32(ctx.r[23].s32, 0, &mut ctx.xer);
	// 831DAC18: 4198005C  blt cr6, 0x831dac74
	if ctx.cr[6].lt {
	pc = 0x831DAC74; continue 'dispatch;
	}
	// 831DAC1C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAC20: 48067E9D  bl 0x83242abc
	ctx.lr = 0x831DAC24;
	// extern call 0x83242ABC → crate::xboxkrnl::MmGetPhysicalAddress
	crate::xboxkrnl::MmGetPhysicalAddress(ctx, base);
	// 831DAC24: 817AD5A0  lwz r11, -0x2a60(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-10848 as u32) ) } as u64;
	// 831DAC28: 7D6B1850  subf r11, r11, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[11].s64;
	// 831DAC2C: 7D6A3670  srawi r10, r11, 6
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 6) - 1)) != 0);
	ctx.r[10].s64 = (ctx.r[11].s32 >> 6) as i64;
	// 831DAC30: 5549043E  clrlwi r9, r10, 0x10
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x0000FFFFu64;
	// 831DAC34: 5528DD7E  rlwinm r8, r9, 0x1b, 0x15, 0x1f
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0x0000001Fu64;
	// 831DAC38: B13E0050  sth r9, 0x50(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(80 as u32), ctx.r[9].u16 ) };
	// 831DAC3C: 552706FE  clrlwi r7, r9, 0x1b
	ctx.r[7].u64 = ctx.r[9].u32 as u64 & 0x0000001Fu64;
	// 831DAC40: 7CC8DA14  add r6, r8, r27
	ctx.r[6].u64 = ctx.r[8].u64 + ctx.r[27].u64;
	// 831DAC44: 7F253830  slw r5, r25, r7
	if (ctx.r[7].u8 & 0x20) != 0 {
		ctx.r[5].u64 = 0;
	} else {
		ctx.r[5].u64 = ((ctx.r[25].u32) << ((ctx.r[7].u8 & 0x1F) as u32)) as u64;
	}
	// 831DAC48: 54C4103A  slwi r4, r6, 2
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831DAC4C: 7CA0252C  stwbrx r5, 0, r4
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[4].u32, (ctx.r[5].u32.swap_bytes())) };
	// 831DAC50: 7C0006AC  eieio
	// 831DAC54: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAC58: 3B180001  addi r24, r24, 1
	ctx.r[24].s64 = ctx.r[24].s64 + 1;
	// 831DAC5C: 3B9C0060  addi r28, r28, 0x60
	ctx.r[28].s64 = ctx.r[28].s64 + 96;
	// 831DAC60: 7F185840  cmplw cr6, r24, r11
	ctx.cr[6].compare_u32(ctx.r[24].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DAC64: 4198FF8C  blt cr6, 0x831dabf0
	if ctx.cr[6].lt {
	pc = 0x831DABF0; continue 'dispatch;
	}
	// 831DAC68: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAC6C: 656A0004  oris r10, r11, 4
	ctx.r[10].u64 = ctx.r[11].u64 | 262144;
	// 831DAC70: 915D0004  stw r10, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DAC74: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 831DAC78: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DAC7C: 4BFCD528  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAC80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DAC80 size=36
    let mut pc: u32 = 0x831DAC80;
    'dispatch: loop {
        match pc {
            0x831DAC80 => {
    //   block [0x831DAC80..0x831DACA4)
	// 831DAC80: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 831DAC84: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAC88: 556A039E  rlwinm r10, r11, 0, 0xe, 0xf
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAC8C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DAC90: 419A0014  beq cr6, 0x831daca4
	if ctx.cr[6].eq {
		sub_831DACA4(ctx, base);
		return;
	}
	// 831DAC94: 656B0001  oris r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 65536;
	// 831DAC98: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAC9C: 91690004  stw r11, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DACA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DACA4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DACA4 size=112
    let mut pc: u32 = 0x831DACA4;
    'dispatch: loop {
        match pc {
            0x831DACA4 => {
    //   block [0x831DACA4..0x831DAD14)
	// 831DACA4: 81690000  lwz r11, 0(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DACA8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DACAC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DACB0: 40990050  ble cr6, 0x831dad00
	if !ctx.cr[6].gt {
	pc = 0x831DAD00; continue 'dispatch;
	}
	// 831DACB4: 3D001FFA  lis r8, 0x1ffa
	ctx.r[8].s64 = 536477696;
	// 831DACB8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DACBC: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831DACC0: 61078690  ori r7, r8, 0x8690
	ctx.r[7].u64 = ctx.r[8].u64 | 34448;
	// 831DACC4: 81090008  lwz r8, 8(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DACC8: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831DACCC: A0A80050  lhz r5, 0x50(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DACD0: 54A4D97E  srwi r4, r5, 5
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shr(5);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831DACD4: 54A306FE  clrlwi r3, r5, 0x1b
	ctx.r[3].u64 = ctx.r[5].u32 as u64 & 0x0000001Fu64;
	// 831DACD8: 7D043A14  add r8, r4, r7
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[7].u64;
	// 831DACDC: 7CC51830  slw r5, r6, r3
	if (ctx.r[3].u8 & 0x20) != 0 {
		ctx.r[5].u64 = 0;
	} else {
		ctx.r[5].u64 = ((ctx.r[6].u32) << ((ctx.r[3].u8 & 0x1F) as u32)) as u64;
	}
	// 831DACE0: 5504103A  slwi r4, r8, 2
	ctx.r[4].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831DACE4: 7CA0252C  stwbrx r5, 0, r4
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[4].u32, (ctx.r[5].u32.swap_bytes())) };
	// 831DACE8: 7C0006AC  eieio
	// 831DACEC: 80690000  lwz r3, 0(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DACF0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831DACF4: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 831DACF8: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831DACFC: 4198FFC8  blt cr6, 0x831dacc4
	if ctx.cr[6].lt {
	pc = 0x831DACC4; continue 'dispatch;
	}
	// 831DAD00: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAD04: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAD08: 656A0001  oris r10, r11, 1
	ctx.r[10].u64 = ctx.r[11].u64 | 65536;
	// 831DAD0C: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DAD10: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAD18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DAD18 size=200
    let mut pc: u32 = 0x831DAD18;
    'dispatch: loop {
        match pc {
            0x831DAD18 => {
    //   block [0x831DAD18..0x831DADE0)
	// 831DAD18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DAD1C: 4BFCD451  bl 0x831a816c
	ctx.lr = 0x831DAD20;
	sub_831A8130(ctx, base);
	// 831DAD20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DAD24: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DAD28: 7FCC42E6  mftb r30, 0x10c
	ctx.r[30].u64 = crate::rt::rdtsc_u64();
	// 831DAD2C: 480000B5  bl 0x831dade0
	ctx.lr = 0x831DAD30;
	sub_831DADE0(ctx, base);
	// 831DAD30: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DAD34: 409A0030  bne cr6, 0x831dad64
	if !ctx.cr[6].eq {
	pc = 0x831DAD64; continue 'dispatch;
	}
	// 831DAD38: 7D6C42E6  mftb r11, 0x10c
	ctx.r[11].u64 = crate::rt::rdtsc_u64();
	// 831DAD3C: 7FBE5850  subf r29, r30, r11
	ctx.r[29].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 831DAD40: 48067CDD  bl 0x83242a1c
	ctx.lr = 0x831DAD44;
	// extern call 0x83242A1C → crate::xboxkrnl::KeQueryPerformanceFrequency
	crate::xboxkrnl::KeQueryPerformanceFrequency(ctx, base);
	// 831DAD44: 786AE8C2  rldicl r10, r3, 0x3d, 3
	ctx.r[10].u64 = ctx.r[3].u64 & 0x0000000000000007u64;
	// 831DAD48: 7F3D5040  cmpld cr6, r29, r10
	ctx.cr[6].compare_u64(ctx.r[29].u64, ctx.r[10].u64, &mut ctx.xer);
	// 831DAD4C: 41990024  bgt cr6, 0x831dad70
	if ctx.cr[6].gt {
	pc = 0x831DAD70; continue 'dispatch;
	}
	// 831DAD50: 7FFFFB78  mr r31, r31
	ctx.r[31].u64 = ctx.r[31].u64;
	// 831DAD54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DAD58: 48000089  bl 0x831dade0
	ctx.lr = 0x831DAD5C;
	sub_831DADE0(ctx, base);
	// 831DAD5C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DAD60: 419AFFD8  beq cr6, 0x831dad38
	if ctx.cr[6].eq {
	pc = 0x831DAD38; continue 'dispatch;
	}
	// 831DAD64: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DAD68: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DAD6C: 4BFCD450  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831DAD70: 3D607FEA  lis r11, 0x7fea
	ctx.r[11].s64 = 2146041856;
	// 831DAD74: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831DAD78: 616A1804  ori r10, r11, 0x1804
	ctx.r[10].u64 = ctx.r[11].u64 | 6148;
	// 831DAD7C: 7FC0512E  stwx r30, 0, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32, ctx.r[30].u32) };
	// 831DAD80: 7C0006AC  eieio
	// 831DAD84: 3D207FEA  lis r9, 0x7fea
	ctx.r[9].s64 = 2146041856;
	// 831DAD88: 3D000300  lis r8, 0x300
	ctx.r[8].s64 = 50331648;
	// 831DAD8C: 61271804  ori r7, r9, 0x1804
	ctx.r[7].u64 = ctx.r[9].u64 | 6148;
	// 831DAD90: 7D00392E  stwx r8, 0, r7
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32, ctx.r[8].u32) };
	// 831DAD94: 7C0006AC  eieio
	// 831DAD98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DAD9C: 48000045  bl 0x831dade0
	ctx.lr = 0x831DADA0;
	sub_831DADE0(ctx, base);
	// 831DADA0: 80DF0000  lwz r6, 0(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DADA4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831DADA8: 40990020  ble cr6, 0x831dadc8
	if !ctx.cr[6].gt {
	pc = 0x831DADC8; continue 'dispatch;
	}
	// 831DADAC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831DADB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DADB4: 4BFFFB15  bl 0x831da8c8
	ctx.lr = 0x831DADB8;
	sub_831DA8C8(ctx, base);
	// 831DADB8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DADBC: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831DADC0: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DADC4: 4198FFE8  blt cr6, 0x831dadac
	if ctx.cr[6].lt {
	pc = 0x831DADAC; continue 'dispatch;
	}
	// 831DADC8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DADCC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831DADD0: 656A0008  oris r10, r11, 8
	ctx.r[10].u64 = ctx.r[11].u64 | 524288;
	// 831DADD4: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DADD8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DADDC: 4BFCD3E0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DADE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DADE0 size=336
    let mut pc: u32 = 0x831DADE0;
    'dispatch: loop {
        match pc {
            0x831DADE0 => {
    //   block [0x831DADE0..0x831DAF30)
	// 831DADE0: FBC1FFF0  std r30, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[30].u64 ) };
	// 831DADE4: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831DADE8: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 831DADEC: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DADF0: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DADF4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DADF8: 409A0118  bne cr6, 0x831daf10
	if !ctx.cr[6].eq {
	pc = 0x831DAF10; continue 'dispatch;
	}
	// 831DADFC: 3D607FEA  lis r11, 0x7fea
	ctx.r[11].s64 = 2146041856;
	// 831DAE00: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAE04: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DAE08: 61671818  ori r7, r11, 0x1818
	ctx.r[7].u64 = ctx.r[11].u64 | 6168;
	// 831DAE0C: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 831DAE10: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DAE14: 7CC03C2C  lwbrx r6, 0, r7
	ctx.r[6].u64 = (unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32) }).swap_bytes() as u64;
	// 831DAE18: 68C70200  xori r7, r6, 0x200
	ctx.r[7].u64 = ctx.r[6].u64 ^ 512;
	// 831DAE1C: 419A002C  beq cr6, 0x831dae48
	if ctx.cr[6].eq {
	pc = 0x831DAE48; continue 'dispatch;
	}
	// 831DAE20: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAE24: 396B0050  addi r11, r11, 0x50
	ctx.r[11].s64 = ctx.r[11].s64 + 80;
	// 831DAE28: A0CB0000  lhz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAE2C: 7F063840  cmplw cr6, r6, r7
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831DAE30: 419A00F0  beq cr6, 0x831daf20
	if ctx.cr[6].eq {
	pc = 0x831DAF20; continue 'dispatch;
	}
	// 831DAE34: 80C90000  lwz r6, 0(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAE38: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831DAE3C: 396B0060  addi r11, r11, 0x60
	ctx.r[11].s64 = ctx.r[11].s64 + 96;
	// 831DAE40: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831DAE44: 4198FFE4  blt cr6, 0x831dae28
	if ctx.cr[6].lt {
	pc = 0x831DAE28; continue 'dispatch;
	}
	// 831DAE48: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831DAE4C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DAE50: 419A00B4  beq cr6, 0x831daf04
	if ctx.cr[6].eq {
	pc = 0x831DAF04; continue 'dispatch;
	}
	// 831DAE54: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 831DAE58: 38600010  li r3, 0x10
	ctx.r[3].s64 = 16;
	// 831DAE5C: 38C00020  li r6, 0x20
	ctx.r[6].s64 = 32;
	// 831DAE60: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAE64: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831DAE68: 38EB0010  addi r7, r11, 0x10
	ctx.r[7].s64 = ctx.r[11].s64 + 16;
	// 831DAE6C: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DAE70: 13EA18C7  vcmpequd (lvx128) v31, v10, v3
	tmp.u32 = ctx.r[10].u32 + ctx.r[3].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DAE74: 13CA30C7  vcmpequd (lvx128) v30, v10, v6
	tmp.u32 = ctx.r[10].u32 + ctx.r[6].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DAE78: 13A050C7  vcmpequd (lvx128) v29, v0, v10
	tmp.u32 = ctx.r[10].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DAF30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DAF30 size=284
    let mut pc: u32 = 0x831DAF30;
    'dispatch: loop {
        match pc {
            0x831DAF30 => {
    //   block [0x831DAF30..0x831DB04C)
	// 831DAF30: 7C681B78  mr r8, r3
	ctx.r[8].u64 = ctx.r[3].u64;
	// 831DAF34: 80A80000  lwz r5, 0(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAF38: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831DAF3C: 419A0040  beq cr6, 0x831daf7c
	if ctx.cr[6].eq {
	pc = 0x831DAF7C; continue 'dispatch;
	}
	// 831DAF40: 80E80008  lwz r7, 8(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAF44: 54A6003E  slwi r6, r5, 0
	ctx.r[6].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DAF48: 81470000  lwz r10, 0(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DAF4C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DAF50: 81270044  lwz r9, 0x44(r7)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(68 as u32) ) } as u64;
	// 831DAF54: 554A94EE  rlwinm r10, r10, 0x12, 0x13, 0x17
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x00003FFFu64;
	// 831DAF58: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DAF5C: 419A0014  beq cr6, 0x831daf70
	if ctx.cr[6].eq {
	pc = 0x831DAF70; continue 'dispatch;
	}
	// 831DAF60: 7C0B48AC  dcbf r11, r9
	// 831DAF64: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 831DAF68: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DAF6C: 4198FFF4  blt cr6, 0x831daf60
	if ctx.cr[6].lt {
	pc = 0x831DAF60; continue 'dispatch;
	}
	// 831DAF70: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831DAF74: 38E70060  addi r7, r7, 0x60
	ctx.r[7].s64 = ctx.r[7].s64 + 96;
	// 831DAF78: 4082FFD0  bne 0x831daf48
	if !ctx.cr[0].eq {
	pc = 0x831DAF48; continue 'dispatch;
	}
	// 831DAF7C: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DAF80: 556A039C  rlwinm r10, r11, 0, 0xe, 0xe
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DAF84: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DAF88: 419A0054  beq cr6, 0x831dafdc
	if ctx.cr[6].eq {
	pc = 0x831DAFDC; continue 'dispatch;
	}
	// 831DAF8C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DAF90: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831DAF94: 419A0048  beq cr6, 0x831dafdc
	if ctx.cr[6].eq {
	pc = 0x831DAFDC; continue 'dispatch;
	}
	// 831DAF98: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DAF9C: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 831DAFA0: 38E00020  li r7, 0x20
	ctx.r[7].s64 = 32;
	// 831DAFA4: 81680008  lwz r11, 8(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DAFA8: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DAFAC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DAFB0: 394A0060  addi r10, r10, 0x60
	ctx.r[10].s64 = ctx.r[10].s64 + 96;
	// 831DAFB4: 80AB0040  lwz r5, 0x40(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DAFB8: 13EB30C7  vcmpequd (lvx128) v31, v11, v6
	tmp.u32 = ctx.r[11].u32 + ctx.r[6].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DAFBC: 13CB38C7  vcmpequd (lvx128) v30, v11, v7
	tmp.u32 = ctx.r[11].u32 + ctx.r[7].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[62] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DAFC0: 13A058C7  vcmpequd (lvx128) v29, v0, v11
	tmp.u32 = ctx.r[11].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB050(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB050 size=32
    let mut pc: u32 = 0x831DB050;
    'dispatch: loop {
        match pc {
            0x831DB050 => {
    //   block [0x831DB050..0x831DB070)
	// 831DB050: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DB054: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 831DB058: 409A0008  bne cr6, 0x831db060
	if !ctx.cr[6].eq {
	pc = 0x831DB060; continue 'dispatch;
	}
	// 831DB05C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB060: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB064: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB068: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB06C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB070(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB070 size=32
    let mut pc: u32 = 0x831DB070;
    'dispatch: loop {
        match pc {
            0x831DB070 => {
    //   block [0x831DB070..0x831DB090)
	// 831DB070: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DB074: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 831DB078: 409A0008  bne cr6, 0x831db080
	if !ctx.cr[6].eq {
	pc = 0x831DB080; continue 'dispatch;
	}
	// 831DB07C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB080: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB084: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB088: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB08C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB090(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB090 size=32
    let mut pc: u32 = 0x831DB090;
    'dispatch: loop {
        match pc {
            0x831DB090 => {
    //   block [0x831DB090..0x831DB0B0)
	// 831DB090: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DB094: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 831DB098: 409A0008  bne cr6, 0x831db0a0
	if !ctx.cr[6].eq {
	pc = 0x831DB0A0; continue 'dispatch;
	}
	// 831DB09C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB0A0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB0A4: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DB0A8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB0AC: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB0B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB0B0 size=84
    let mut pc: u32 = 0x831DB0B0;
    'dispatch: loop {
        match pc {
            0x831DB0B0 => {
    //   block [0x831DB0B0..0x831DB104)
	// 831DB0B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB0B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DB0B8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB0BC: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB0C0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DB0C4: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DB0C8: 40820028  bne 0x831db0f0
	if !ctx.cr[0].eq {
	pc = 0x831DB0F0; continue 'dispatch;
	}
	// 831DB0CC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB0D0: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB0D4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB0D8: 4E800421  bctrl
	ctx.lr = 0x831DB0DC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB0DC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB0E0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DB0E4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB0E8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB0EC: 4E800020  blr
	return;
	// 831DB0F0: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831DB0F4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DB0F8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB0FC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB100: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB108 size=24
    let mut pc: u32 = 0x831DB108;
    'dispatch: loop {
        match pc {
            0x831DB108 => {
    //   block [0x831DB108..0x831DB120)
	// 831DB108: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DB10C: 39630008  addi r11, r3, 8
	ctx.r[11].s64 = ctx.r[3].s64 + 8;
	// 831DB110: 409A0008  bne cr6, 0x831db118
	if !ctx.cr[6].eq {
	pc = 0x831DB118; continue 'dispatch;
	}
	// 831DB114: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB118: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DB11C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB120 size=40
    let mut pc: u32 = 0x831DB120;
    'dispatch: loop {
        match pc {
            0x831DB120 => {
    //   block [0x831DB120..0x831DB148)
	// 831DB120: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831DB124: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831DB128: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB12C: 2B0A007F  cmplwi cr6, r10, 0x7f
	ctx.cr[6].compare_u32(ctx.r[10].u32, 127 as u32, &mut ctx.xer);
	// 831DB130: 41990018  bgt cr6, 0x831db148
	if ctx.cr[6].gt {
		sub_831DB148(ctx, base);
		return;
	}
	// 831DB134: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB138: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB13C: 40980040  bge cr6, 0x831db17c
	if !ctx.cr[6].lt {
		sub_831DB148(ctx, base);
		return;
	}
	// 831DB140: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB144: 48000018  b 0x831db15c
	sub_831DB148(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB148(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB148 size=76
    let mut pc: u32 = 0x831DB148;
    'dispatch: loop {
        match pc {
            0x831DB148 => {
    //   block [0x831DB148..0x831DB194)
	// 831DB148: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB14C: 394AFF80  addi r10, r10, -0x80
	ctx.r[10].s64 = ctx.r[10].s64 + -128;
	// 831DB150: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB154: 40980028  bge cr6, 0x831db17c
	if !ctx.cr[6].lt {
	pc = 0x831DB17C; continue 'dispatch;
	}
	// 831DB158: 812B0014  lwz r9, 0x14(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB15C: 554B1838  slwi r11, r10, 3
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DB160: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831DB164: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB168: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB16C: 419A0010  beq cr6, 0x831db17c
	if ctx.cr[6].eq {
	pc = 0x831DB17C; continue 'dispatch;
	}
	// 831DB170: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB174: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB178: 409A0008  bne cr6, 0x831db180
	if !ctx.cr[6].eq {
	pc = 0x831DB180; continue 'dispatch;
	}
	// 831DB17C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB180: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB184: 409A0010  bne cr6, 0x831db194
	if !ctx.cr[6].eq {
		sub_831DB194(ctx, base);
		return;
	}
	// 831DB188: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831DB18C: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831DB190: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB194(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB194 size=16
    let mut pc: u32 = 0x831DB194;
    'dispatch: loop {
        match pc {
            0x831DB194 => {
    //   block [0x831DB194..0x831DB1A4)
	// 831DB194: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB198: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831DB19C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831DB1A0: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB1A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB1A8 size=44
    let mut pc: u32 = 0x831DB1A8;
    'dispatch: loop {
        match pc {
            0x831DB1A8 => {
    //   block [0x831DB1A8..0x831DB1D4)
	// 831DB1A8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831DB1AC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831DB1B0: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831DB1B4: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB1B8: 2B0A007F  cmplwi cr6, r10, 0x7f
	ctx.cr[6].compare_u32(ctx.r[10].u32, 127 as u32, &mut ctx.xer);
	// 831DB1BC: 41990018  bgt cr6, 0x831db1d4
	if ctx.cr[6].gt {
		sub_831DB1D4(ctx, base);
		return;
	}
	// 831DB1C0: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB1C4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB1C8: 40980040  bge cr6, 0x831db208
	if !ctx.cr[6].lt {
		sub_831DB1D4(ctx, base);
		return;
	}
	// 831DB1CC: 812B000C  lwz r9, 0xc(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB1D0: 48000018  b 0x831db1e8
	sub_831DB1D4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB1D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB1D4 size=76
    let mut pc: u32 = 0x831DB1D4;
    'dispatch: loop {
        match pc {
            0x831DB1D4 => {
    //   block [0x831DB1D4..0x831DB220)
	// 831DB1D4: 812B0010  lwz r9, 0x10(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB1D8: 394AFF80  addi r10, r10, -0x80
	ctx.r[10].s64 = ctx.r[10].s64 + -128;
	// 831DB1DC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB1E0: 40980028  bge cr6, 0x831db208
	if !ctx.cr[6].lt {
	pc = 0x831DB208; continue 'dispatch;
	}
	// 831DB1E4: 812B0014  lwz r9, 0x14(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB1E8: 554B1838  slwi r11, r10, 3
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DB1EC: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831DB1F0: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB1F4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB1F8: 419A0010  beq cr6, 0x831db208
	if ctx.cr[6].eq {
	pc = 0x831DB208; continue 'dispatch;
	}
	// 831DB1FC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB200: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB204: 409A0008  bne cr6, 0x831db20c
	if !ctx.cr[6].eq {
	pc = 0x831DB20C; continue 'dispatch;
	}
	// 831DB208: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB20C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB210: 409A0010  bne cr6, 0x831db220
	if !ctx.cr[6].eq {
		sub_831DB220(ctx, base);
		return;
	}
	// 831DB214: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831DB218: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831DB21C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB220(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB220 size=16
    let mut pc: u32 = 0x831DB220;
    'dispatch: loop {
        match pc {
            0x831DB220 => {
    //   block [0x831DB220..0x831DB230)
	// 831DB220: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB224: 7CC53378  mr r5, r6
	ctx.r[5].u64 = ctx.r[6].u64;
	// 831DB228: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831DB22C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB230(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB230 size=512
    let mut pc: u32 = 0x831DB230;
    'dispatch: loop {
        match pc {
            0x831DB230 => {
    //   block [0x831DB230..0x831DB430)
	// 831DB230: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB234: 4BFCCF29  bl 0x831a815c
	ctx.lr = 0x831DB238;
	sub_831A8130(ctx, base);
	// 831DB238: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB23C: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831DB240: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 831DB244: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DB248: 7F3ACB78  mr r26, r25
	ctx.r[26].u64 = ctx.r[25].u64;
	// 831DB24C: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 831DB250: 895B0000  lbz r10, 0(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB254: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB258: 419A00A4  beq cr6, 0x831db2fc
	if ctx.cr[6].eq {
	pc = 0x831DB2FC; continue 'dispatch;
	}
	// 831DB25C: 7F28CB78  mr r8, r25
	ctx.r[8].u64 = ctx.r[25].u64;
	// 831DB260: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB264: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DB268: 409A0008  bne cr6, 0x831db270
	if !ctx.cr[6].eq {
	pc = 0x831DB270; continue 'dispatch;
	}
	// 831DB26C: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB270: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB274: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB278: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DB27C: 7D2A3A14  add r9, r10, r7
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 831DB280: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB284: 40980078  bge cr6, 0x831db2fc
	if !ctx.cr[6].lt {
	pc = 0x831DB2FC; continue 'dispatch;
	}
	// 831DB288: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB28C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB290: 409A0010  bne cr6, 0x831db2a0
	if !ctx.cr[6].eq {
	pc = 0x831DB2A0; continue 'dispatch;
	}
	// 831DB294: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB298: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB29C: 419A0024  beq cr6, 0x831db2c0
	if ctx.cr[6].eq {
	pc = 0x831DB2C0; continue 'dispatch;
	}
	// 831DB2A0: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB2A4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DB2A8: 813F0014  lwz r9, 0x14(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB2AC: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DB2B0: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831DB2B4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB2B8: 4198FFD0  blt cr6, 0x831db288
	if ctx.cr[6].lt {
	pc = 0x831DB288; continue 'dispatch;
	}
	// 831DB2BC: 48000040  b 0x831db2fc
	pc = 0x831DB2FC; continue 'dispatch;
	// 831DB2C0: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB2C4: 7D275850  subf r9, r7, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 831DB2C8: 3B5A0001  addi r26, r26, 1
	ctx.r[26].s64 = ctx.r[26].s64 + 1;
	// 831DB2CC: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831DB2D0: 7D291E70  srawi r9, r9, 3
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 3) as i64;
	// 831DB2D4: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 831DB2D8: 38E90080  addi r7, r9, 0x80
	ctx.r[7].s64 = ctx.r[9].s64 + 128;
	// 831DB2DC: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB2E0: 98EA0000  stb r7, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[7].u8 ) };
	// 831DB2E4: 90CB0000  stw r6, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831DB2E8: 808A0008  lwz r4, 8(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB2EC: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831DB2F0: 887B0000  lbz r3, 0(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB2F4: 7F1A1840  cmplw cr6, r26, r3
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831DB2F8: 4198FF68  blt cr6, 0x831db260
	if ctx.cr[6].lt {
	pc = 0x831DB260; continue 'dispatch;
	}
	// 831DB2FC: 897B0000  lbz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB300: 7FDA5851  subf. r30, r26, r11
	ctx.r[30].s64 = ctx.r[11].s64 - ctx.r[26].s64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831DB304: 40820010  bne 0x831db314
	if !ctx.cr[0].eq {
	pc = 0x831DB314; continue 'dispatch;
	}
	// 831DB308: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB30C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DB310: 4BFCCE9C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
	// 831DB314: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB318: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831DB31C: 2B0B0080  cmplwi cr6, r11, 0x80
	ctx.cr[6].compare_u32(ctx.r[11].u32, 128 as u32, &mut ctx.xer);
	// 831DB320: 40990014  ble cr6, 0x831db334
	if !ctx.cr[6].gt {
	pc = 0x831DB334; continue 'dispatch;
	}
	// 831DB324: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DB328: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831DB32C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DB330: 4BFCCE7C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
	// 831DB334: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831DB338: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DB33C: 3B8AD5A4  addi r28, r10, -0x2a5c
	ctx.r[28].s64 = ctx.r[10].s64 + -10844;
	// 831DB340: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 831DB344: 55641838  slwi r4, r11, 3
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831DB348: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831DB34C: 48001365  bl 0x831dc6b0
	ctx.lr = 0x831DB350;
	sub_831DC6B0(ctx, base);
	// 831DB350: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DB354: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831DB358: 409A0018  bne cr6, 0x831db370
	if !ctx.cr[6].eq {
	pc = 0x831DB370; continue 'dispatch;
	}
	// 831DB35C: 3F208007  lis r25, -0x7ff9
	ctx.r[25].s64 = -2147024896;
	// 831DB360: 6339000E  ori r25, r25, 0xe
	ctx.r[25].u64 = ctx.r[25].u64 | 14;
	// 831DB364: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831DB368: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DB36C: 4BFCCE40  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
	// 831DB370: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB374: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB378: 419A0034  beq cr6, 0x831db3ac
	if ctx.cr[6].eq {
	pc = 0x831DB3AC; continue 'dispatch;
	}
	// 831DB37C: 55651838  slwi r5, r11, 3
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831DB380: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB384: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DB388: 4BFCD189  bl 0x831a8510
	ctx.lr = 0x831DB38C;
	sub_831A8510(ctx, base);
	// 831DB38C: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB390: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831DB394: 419A0018  beq cr6, 0x831db3ac
	if ctx.cr[6].eq {
	pc = 0x831DB3AC; continue 'dispatch;
	}
	// 831DB398: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DB39C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831DB3A0: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 831DB3A4: 4800131D  bl 0x831dc6c0
	ctx.lr = 0x831DB3A8;
	sub_831DC6C0(ctx, base);
	// 831DB3A8: 933F0014  stw r25, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[25].u32 ) };
	// 831DB3AC: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB3B0: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 831DB3B4: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831DB3B8: 93BF0014  stw r29, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u32 ) };
	// 831DB3BC: 7D4AF214  add r10, r10, r30
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[30].u64;
	// 831DB3C0: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831DB3C4: 419A0060  beq cr6, 0x831db424
	if ctx.cr[6].eq {
	pc = 0x831DB424; continue 'dispatch;
	}
	// 831DB3C8: 574A083C  slwi r10, r26, 1
	ctx.r[10].u32 = ctx.r[26].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DB3CC: 7D5A5214  add r10, r26, r10
	ctx.r[10].u64 = ctx.r[26].u64 + ctx.r[10].u64;
	// 831DB3D0: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DB3D4: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB3D8: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB3DC: 7D3E5050  subf r9, r30, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 831DB3E0: 815B0004  lwz r10, 4(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB3E4: 7CC95A14  add r6, r9, r11
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831DB3E8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831DB3EC: 54C91838  slwi r9, r6, 3
	ctx.r[9].u32 = ctx.r[6].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DB3F0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DB3F4: 7D29EA14  add r9, r9, r29
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[29].u64;
	// 831DB3F8: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 831DB3FC: 7CA74850  subf r5, r7, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 831DB400: 808A0004  lwz r4, 4(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB404: 7F0BF040  cmplw cr6, r11, r30
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[30].u32, &mut ctx.xer);
	// 831DB408: 7CA71E70  srawi r7, r5, 3
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[5].s32 >> 3) as i64;
	// 831DB40C: 38670080  addi r3, r7, 0x80
	ctx.r[3].s64 = ctx.r[7].s64 + 128;
	// 831DB410: 986A0000  stb r3, 0(r10)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[3].u8 ) };
	// 831DB414: 90890000  stw r4, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831DB418: 80CA0008  lwz r6, 8(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB41C: 90C90004  stw r6, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831DB420: 4198FFB4  blt cr6, 0x831db3d4
	if ctx.cr[6].lt {
	pc = 0x831DB3D4; continue 'dispatch;
	}
	// 831DB424: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 831DB428: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DB42C: 4BFCCD80  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB430(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB430 size=120
    let mut pc: u32 = 0x831DB430;
    'dispatch: loop {
        match pc {
            0x831DB430 => {
    //   block [0x831DB430..0x831DB4A8)
	// 831DB430: 89640000  lbz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB434: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831DB438: 7D094378  mr r9, r8
	ctx.r[9].u64 = ctx.r[8].u64;
	// 831DB43C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB440: 419A0060  beq cr6, 0x831db4a0
	if ctx.cr[6].eq {
	pc = 0x831DB4A0; continue 'dispatch;
	}
	// 831DB444: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB448: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DB44C: 7D6958AE  lbzx r11, r9, r11
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831DB450: 396BFF80  addi r11, r11, -0x80
	ctx.r[11].s64 = ctx.r[11].s64 + -128;
	// 831DB454: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DB458: 40980038  bge cr6, 0x831db490
	if !ctx.cr[6].lt {
	pc = 0x831DB490; continue 'dispatch;
	}
	// 831DB45C: 81430014  lwz r10, 0x14(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB460: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DB464: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DB468: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB46C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB470: 419A0020  beq cr6, 0x831db490
	if ctx.cr[6].eq {
	pc = 0x831DB490; continue 'dispatch;
	}
	// 831DB474: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB478: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB47C: 419A0014  beq cr6, 0x831db490
	if ctx.cr[6].eq {
	pc = 0x831DB490; continue 'dispatch;
	}
	// 831DB480: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB484: 419A000C  beq cr6, 0x831db490
	if ctx.cr[6].eq {
	pc = 0x831DB490; continue 'dispatch;
	}
	// 831DB488: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831DB48C: 910B0004  stw r8, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831DB490: 89640000  lbz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB494: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DB498: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DB49C: 4198FFA8  blt cr6, 0x831db444
	if ctx.cr[6].lt {
	pc = 0x831DB444; continue 'dispatch;
	}
	// 831DB4A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB4A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB4A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB4A8 size=16
    let mut pc: u32 = 0x831DB4A8;
    'dispatch: loop {
        match pc {
            0x831DB4A8 => {
    //   block [0x831DB4A8..0x831DB4B8)
	// 831DB4A8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831DB4AC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB4B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB4B4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB4B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB4B8 size=12
    let mut pc: u32 = 0x831DB4B8;
    'dispatch: loop {
        match pc {
            0x831DB4B8 => {
    //   block [0x831DB4B8..0x831DB4C4)
	// 831DB4B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB4BC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB4C0: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB4C4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB4C4 size=64
    let mut pc: u32 = 0x831DB4C4;
    'dispatch: loop {
        match pc {
            0x831DB4C4 => {
    //   block [0x831DB4C4..0x831DB504)
	// 831DB4C4: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB4C8: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DB4CC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB4D0: 419A002C  beq cr6, 0x831db4fc
	if ctx.cr[6].eq {
	pc = 0x831DB4FC; continue 'dispatch;
	}
	// 831DB4D4: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB4D8: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 831DB4DC: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB4E0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DB4E4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DB4E8: 40990008  ble cr6, 0x831db4f0
	if !ctx.cr[6].gt {
	pc = 0x831DB4F0; continue 'dispatch;
	}
	// 831DB4EC: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831DB4F0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DB4F4: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 831DB4F8: 4082FFE4  bne 0x831db4dc
	if !ctx.cr[0].eq {
	pc = 0x831DB4DC; continue 'dispatch;
	}
	// 831DB4FC: 55231838  slwi r3, r9, 3
	ctx.r[3].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 831DB500: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB508(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB508 size=276
    let mut pc: u32 = 0x831DB508;
    'dispatch: loop {
        match pc {
            0x831DB508 => {
    //   block [0x831DB508..0x831DB61C)
	// 831DB508: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB50C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DB510: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831DB514: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DB518: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB51C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DB520: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DB524: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831DB528: 392BFFA0  addi r9, r11, -0x60
	ctx.r[9].s64 = ctx.r[11].s64 + -96;
	// 831DB52C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831DB530: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DB534: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DB538: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DB53C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB540: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB544: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DB548: 419A0028  beq cr6, 0x831db570
	if ctx.cr[6].eq {
	pc = 0x831DB570; continue 'dispatch;
	}
	// 831DB54C: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB550: 89680000  lbz r11, 0(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB554: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DB558: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DB55C: 40990008  ble cr6, 0x831db564
	if !ctx.cr[6].gt {
	pc = 0x831DB564; continue 'dispatch;
	}
	// 831DB560: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831DB564: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DB568: 3908000C  addi r8, r8, 0xc
	ctx.r[8].s64 = ctx.r[8].s64 + 12;
	// 831DB56C: 4082FFE4  bne 0x831db550
	if !ctx.cr[0].eq {
	pc = 0x831DB550; continue 'dispatch;
	}
	// 831DB570: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DB574: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB578: 419A0020  beq cr6, 0x831db598
	if ctx.cr[6].eq {
	pc = 0x831DB598; continue 'dispatch;
	}
	// 831DB57C: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB580: 55441838  slwi r4, r10, 3
	ctx.r[4].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831DB584: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 831DB588: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB58C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB590: 4E800421  bctrl
	ctx.lr = 0x831DB594;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB594: 907F000C  stw r3, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 831DB598: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB59C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DB5A0: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB5A4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB5A8: 419A0058  beq cr6, 0x831db600
	if ctx.cr[6].eq {
	pc = 0x831DB600; continue 'dispatch;
	}
	// 831DB5AC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB5B0: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB5B4: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DB5B8: 811F000C  lwz r8, 0xc(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB5BC: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DB5C0: 88EA0000  lbz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB5C4: 80CA0004  lwz r6, 4(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB5C8: 54EA183E  rotlwi r10, r7, 3
	ctx.r[10].u64 = ((ctx.r[7].u32).rotate_left(3)) as u64;
	// 831DB5CC: 7CC8512E  stwx r6, r8, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32), ctx.r[6].u32) };
	// 831DB5D0: 80FF000C  lwz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB5D4: 7C875214  add r4, r7, r10
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[10].u64;
	// 831DB5D8: 80BE0000  lwz r5, 0(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB5DC: 81050004  lwz r8, 4(r5)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB5E0: 7C685A14  add r3, r8, r11
	ctx.r[3].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831DB5E4: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB5E8: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 831DB5EC: 91440004  stw r10, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DB5F0: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB5F4: 890A0000  lbz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB5F8: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DB5FC: 4198FFB4  blt cr6, 0x831db5b0
	if ctx.cr[6].lt {
	pc = 0x831DB5B0; continue 'dispatch;
	}
	// 831DB600: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB604: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DB608: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB60C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB610: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831DB614: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DB618: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB620(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB620 size=108
    let mut pc: u32 = 0x831DB620;
    'dispatch: loop {
        match pc {
            0x831DB620 => {
    //   block [0x831DB620..0x831DB68C)
	// 831DB620: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB624: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DB628: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DB62C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB630: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DB634: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DB638: 394BFFA0  addi r10, r11, -0x60
	ctx.r[10].s64 = ctx.r[11].s64 + -96;
	// 831DB63C: 809F0014  lwz r4, 0x14(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB640: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DB644: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831DB648: 419A0020  beq cr6, 0x831db668
	if ctx.cr[6].eq {
	pc = 0x831DB668; continue 'dispatch;
	}
	// 831DB64C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DB650: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DB654: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DB658: 60A50004  ori r5, r5, 4
	ctx.r[5].u64 = ctx.r[5].u64 | 4;
	// 831DB65C: 48001065  bl 0x831dc6c0
	ctx.lr = 0x831DB660;
	sub_831DC6C0(ctx, base);
	// 831DB660: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DB664: 915F0014  stw r10, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831DB668: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DB66C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB670: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831DB674: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DB678: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DB67C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB680: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB684: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DB688: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB690(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB690 size=56
    let mut pc: u32 = 0x831DB690;
    'dispatch: loop {
        match pc {
            0x831DB690 => {
    //   block [0x831DB690..0x831DB6C8)
	// 831DB690: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB694: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DB698: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DB69C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB6A0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831DB6A4: 4BFFFE05  bl 0x831db4a8
	ctx.lr = 0x831DB6A8;
	sub_831DB4A8(ctx, base);
	// 831DB6A8: 39630018  addi r11, r3, 0x18
	ctx.r[11].s64 = ctx.r[3].s64 + 24;
	// 831DB6AC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB6B0: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DB6B4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DB6B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB6BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB6C0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DB6C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB6C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB6C8 size=116
    let mut pc: u32 = 0x831DB6C8;
    'dispatch: loop {
        match pc {
            0x831DB6C8 => {
    //   block [0x831DB6C8..0x831DB73C)
	// 831DB6C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB6CC: 4BFCCAA1  bl 0x831a816c
	ctx.lr = 0x831DB6D0;
	sub_831A8130(ctx, base);
	// 831DB6D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB6D4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831DB6D8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DB6DC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831DB6E0: 38800018  li r4, 0x18
	ctx.r[4].s64 = 24;
	// 831DB6E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB6E8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB6EC: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DB6F0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB6F4: 4E800421  bctrl
	ctx.lr = 0x831DB6F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB6F8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DB6FC: 419A0030  beq cr6, 0x831db72c
	if ctx.cr[6].eq {
	pc = 0x831DB72C; continue 'dispatch;
	}
	// 831DB700: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831DB704: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831DB708: 4BFFFE01  bl 0x831db508
	ctx.lr = 0x831DB70C;
	sub_831DB508(ctx, base);
	// 831DB70C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831DB710: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB714: 419A0018  beq cr6, 0x831db72c
	if ctx.cr[6].eq {
	pc = 0x831DB72C; continue 'dispatch;
	}
	// 831DB718: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DB71C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DB720: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DB724: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DB728: 4BFCCA94  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831DB72C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DB730: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831DB734: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DB738: 4BFCCA84  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB740(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB740 size=72
    let mut pc: u32 = 0x831DB740;
    'dispatch: loop {
        match pc {
            0x831DB740 => {
    //   block [0x831DB740..0x831DB788)
	// 831DB740: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB744: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831DB748: 409A0040  bne cr6, 0x831db788
	if !ctx.cr[6].eq {
		sub_831DB788(ctx, base);
		return;
	}
	// 831DB74C: 89030004  lbz r8, 4(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB750: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DB754: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DB758: 419A0028  beq cr6, 0x831db780
	if ctx.cr[6].eq {
	pc = 0x831DB780; continue 'dispatch;
	}
	// 831DB75C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB760: 55691838  slwi r9, r11, 3
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DB764: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DB768: 7D291A14  add r9, r9, r3
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[3].u64;
	// 831DB76C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831DB770: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DB774: 8929000C  lbz r9, 0xc(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB778: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DB77C: 4198FFE4  blt cr6, 0x831db760
	if ctx.cr[6].lt {
	pc = 0x831DB760; continue 'dispatch;
	}
	// 831DB780: 99440001  stb r10, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[10].u8 ) };
	// 831DB784: 4800000C  b 0x831db790
	sub_831DB788(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB788 size=32
    let mut pc: u32 = 0x831DB788;
    'dispatch: loop {
        match pc {
            0x831DB788 => {
    //   block [0x831DB788..0x831DB7A8)
	// 831DB788: 89630004  lbz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB78C: 99640001  stb r11, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[11].u8 ) };
	// 831DB790: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831DB794: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DB798: 6169BB80  ori r9, r11, 0xbb80
	ctx.r[9].u64 = ctx.r[11].u64 | 48000;
	// 831DB79C: 99440000  stb r10, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 831DB7A0: 91240004  stw r9, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DB7A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB7A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB7A8 size=100
    let mut pc: u32 = 0x831DB7A8;
    'dispatch: loop {
        match pc {
            0x831DB7A8 => {
    //   block [0x831DB7A8..0x831DB80C)
	// 831DB7A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB7AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DB7B0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DB7B4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB7B8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DB7BC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831DB7C0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB7C4: 814B003C  lwz r10, 0x3c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831DB7C8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB7CC: 4E800421  bctrl
	ctx.lr = 0x831DB7D0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB7D0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DB7D4: 41980024  blt cr6, 0x831db7f8
	if ctx.cr[6].lt {
	pc = 0x831DB7F8; continue 'dispatch;
	}
	// 831DB7D8: 817F004C  lwz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DB7DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DB7E0: 419A0018  beq cr6, 0x831db7f8
	if ctx.cr[6].eq {
	pc = 0x831DB7F8; continue 'dispatch;
	}
	// 831DB7E4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB7E8: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831DB7EC: 812A0020  lwz r9, 0x20(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 831DB7F0: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831DB7F4: 4E800421  bctrl
	ctx.lr = 0x831DB7F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB7F8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DB7FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DB800: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DB804: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DB808: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB810(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB810 size=232
    let mut pc: u32 = 0x831DB810;
    'dispatch: loop {
        match pc {
            0x831DB810 => {
    //   block [0x831DB810..0x831DB8F8)
	// 831DB810: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB814: 4BFCC951  bl 0x831a8164
	ctx.lr = 0x831DB818;
	sub_831A8130(ctx, base);
	// 831DB818: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB81C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DB820: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831DB824: 48067939  bl 0x8324315c
	ctx.lr = 0x831DB828;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DB828: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DB82C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DB830: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DB834: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DB838: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB83C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DB840: 419A0010  beq cr6, 0x831db850
	if ctx.cr[6].eq {
	pc = 0x831DB850; continue 'dispatch;
	}
	// 831DB844: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB848: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DB84C: 419A0018  beq cr6, 0x831db864
	if ctx.cr[6].eq {
	pc = 0x831DB864; continue 'dispatch;
	}
	// 831DB850: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB854: 48067229  bl 0x83242a7c
	ctx.lr = 0x831DB858;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DB858: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB85C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DB860: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DB864: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DB868: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DB86C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DB870: 807C004C  lwz r3, 0x4c(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DB874: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB878: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831DB87C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB880: 4E800421  bctrl
	ctx.lr = 0x831DB884;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB884: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DB888: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831DB88C: 41980014  blt cr6, 0x831db8a0
	if ctx.cr[6].lt {
	pc = 0x831DB8A0; continue 'dispatch;
	}
	// 831DB890: 895C003D  lbz r10, 0x3d(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DB894: 89210050  lbz r9, 0x50(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DB898: 7D484B78  or r8, r10, r9
	ctx.r[8].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 831DB89C: 991B0000  stb r8, 0(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 831DB8A0: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DB8A4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DB8A8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DB8AC: 419A0040  beq cr6, 0x831db8ec
	if ctx.cr[6].eq {
	pc = 0x831DB8EC; continue 'dispatch;
	}
	// 831DB8B0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DB8B4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DB8B8: 409A0034  bne cr6, 0x831db8ec
	if !ctx.cr[6].eq {
	pc = 0x831DB8EC; continue 'dispatch;
	}
	// 831DB8BC: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DB8C0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DB8C4: 40820028  bne 0x831db8ec
	if !ctx.cr[0].eq {
	pc = 0x831DB8EC; continue 'dispatch;
	}
	// 831DB8C8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DB8CC: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB8D0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DB8D4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DB8D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB8DC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DB8E0: 4806718D  bl 0x83242a6c
	ctx.lr = 0x831DB8E4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DB8E4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DB8E8: 48067885  bl 0x8324316c
	ctx.lr = 0x831DB8EC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DB8EC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DB8F0: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DB8F4: 4BFCC8C0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB8F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DB8F8 size=28
    let mut pc: u32 = 0x831DB8F8;
    'dispatch: loop {
        match pc {
            0x831DB8F8 => {
    //   block [0x831DB8F8..0x831DB914)
	// 831DB8F8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DB8FC: 894D010C  lbz r10, 0x10c(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[13].u32.wrapping_add(268 as u32) ) } as u64;
	// 831DB900: 554A183E  rotlwi r10, r10, 3
	ctx.r[10].u64 = ((ctx.r[10].u32).rotate_left(3)) as u64;
	// 831DB904: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DB908: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DB90C: 8069000C  lwz r3, 0xc(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DB910: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DB918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DB918 size=240
    let mut pc: u32 = 0x831DB918;
    'dispatch: loop {
        match pc {
            0x831DB918 => {
    //   block [0x831DB918..0x831DBA08)
	// 831DB918: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DB91C: 4BFCC851  bl 0x831a816c
	ctx.lr = 0x831DB920;
	sub_831A8130(ctx, base);
	// 831DB920: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DB924: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DB928: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DB92C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831DB930: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831DB934: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DB938: 895F0090  lbz r10, 0x90(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(144 as u32) ) } as u64;
	// 831DB93C: 7D285030  slw r8, r9, r10
	if (ctx.r[10].u8 & 0x20) != 0 {
		ctx.r[8].u64 = 0;
	} else {
		ctx.r[8].u64 = ((ctx.r[9].u32) << ((ctx.r[10].u8 & 0x1F) as u32)) as u64;
	}
	// 831DB940: 80EB008C  lwz r7, 0x8c(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(140 as u32) ) } as u64;
	// 831DB944: 7D063838  and r6, r8, r7
	ctx.r[6].u64 = ctx.r[8].u64 & ctx.r[7].u64;
	// 831DB948: 2F060000  cmpwi cr6, r6, 0
	ctx.cr[6].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 831DB94C: 419A001C  beq cr6, 0x831db968
	if ctx.cr[6].eq {
	pc = 0x831DB968; continue 'dispatch;
	}
	// 831DB950: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB954: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831DB958: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB95C: 4E800421  bctrl
	ctx.lr = 0x831DB960;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB960: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DB964: 4198009C  blt cr6, 0x831dba00
	if ctx.cr[6].lt {
	pc = 0x831DBA00; continue 'dispatch;
	}
	// 831DB968: 3BBF004C  addi r29, r31, 0x4c
	ctx.r[29].s64 = ctx.r[31].s64 + 76;
	// 831DB96C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831DB970: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831DB974: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB978: 48008589  bl 0x831e3f00
	ctx.lr = 0x831DB97C;
	sub_831E3F00(ctx, base);
	// 831DB97C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DB980: 41980080  blt cr6, 0x831dba00
	if ctx.cr[6].lt {
	pc = 0x831DBA00; continue 'dispatch;
	}
	// 831DB984: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831DB988: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB98C: 48007C0D  bl 0x831e3598
	ctx.lr = 0x831DB990;
	sub_831E3598(ctx, base);
	// 831DB990: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DB994: 4198006C  blt cr6, 0x831dba00
	if ctx.cr[6].lt {
	pc = 0x831DBA00; continue 'dispatch;
	}
	// 831DB998: 807D0000  lwz r3, 0(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB99C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DB9A0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DB9A4: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831DB9A8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DB9AC: 4E800421  bctrl
	ctx.lr = 0x831DB9B0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DB9B0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DB9B4: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831DB9B8: 41980044  blt cr6, 0x831db9fc
	if ctx.cr[6].lt {
	pc = 0x831DB9FC; continue 'dispatch;
	}
	// 831DB9BC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831DB9C0: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831DB9C4: 48000D25  bl 0x831dc6e8
	ctx.lr = 0x831DB9C8;
	sub_831DC6E8(ctx, base);
	// 831DB9C8: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DB9CC: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831DB9D0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB9D4: 409A0028  bne cr6, 0x831db9fc
	if !ctx.cr[6].eq {
	pc = 0x831DB9FC; continue 'dispatch;
	}
	// 831DB9D8: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DB9DC: 556A077A  rlwinm r10, r11, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831DB9E0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DB9E4: 409A0018  bne cr6, 0x831db9fc
	if !ctx.cr[6].eq {
	pc = 0x831DB9FC; continue 'dispatch;
	}
	// 831DB9E8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DB9EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DB9F0: 48008859  bl 0x831e4248
	ctx.lr = 0x831DB9F4;
	sub_831E4248(ctx, base);
	// 831DB9F4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DB9F8: 4BFCC7C4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831DB9FC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DBA00: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DBA04: 4BFCC7B8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBA08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DBA08 size=36
    let mut pc: u32 = 0x831DBA08;
    'dispatch: loop {
        match pc {
            0x831DBA08 => {
    //   block [0x831DBA08..0x831DBA2C)
	// 831DBA08: 89630090  lbz r11, 0x90(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(144 as u32) ) } as u64;
	// 831DBA0C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831DBA10: 4098001C  bge cr6, 0x831dba2c
	if !ctx.cr[6].lt {
		sub_831DBA2C(ctx, base);
		return;
	}
	// 831DBA14: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831DBA18: 392B0021  addi r9, r11, 0x21
	ctx.r[9].s64 = ctx.r[11].s64 + 33;
	// 831DBA1C: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DBA20: 816AD59C  lwz r11, -0x2a64(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBA24: 7C085C2E  lfsx f0, r8, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DBA28: 4800000C  b 0x831dba34
	sub_831DBA2C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBA2C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DBA2C size=40
    let mut pc: u32 = 0x831DBA2C;
    'dispatch: loop {
        match pc {
            0x831DBA2C => {
    //   block [0x831DBA2C..0x831DBA54)
	// 831DBA2C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831DBA30: C00B08A8  lfs f0, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DBA34: 8163004C  lwz r11, 0x4c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DBA38: C1A3008C  lfs f13, 0x8c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(140 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DBA3C: EC2D0032  fmuls f1, f13, f0
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DBA40: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831DBA44: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBA48: 812A0058  lwz r9, 0x58(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DBA4C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831DBA50: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBA58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DBA58 size=200
    let mut pc: u32 = 0x831DBA58;
    'dispatch: loop {
        match pc {
            0x831DBA58 => {
    //   block [0x831DBA58..0x831DBB20)
	// 831DBA58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DBA5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DBA60: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DBA64: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831DBA68: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DBA6C: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 831DBA70: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DBA74: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DBA78: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831DBA7C: 4200FFF8  bdnz 0x831dba74
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831DBA74; continue 'dispatch;
	}
	// 831DBA80: 4BFFFCC1  bl 0x831db740
	ctx.lr = 0x831DBA84;
	sub_831DB740(ctx, base);
	// 831DBA84: 81230044  lwz r9, 0x44(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(68 as u32) ) } as u64;
	// 831DBA88: 3D408343  lis r10, -0x7cbd
	ctx.r[10].s64 = -2092761088;
	// 831DBA8C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DBA90: 91240008  stw r9, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831DBA94: 812AD59C  lwz r9, -0x2a64(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBA98: 3949000C  addi r10, r9, 0xc
	ctx.r[10].s64 = ctx.r[9].s64 + 12;
	// 831DBA9C: 810A0000  lwz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBAA0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DBAA4: 409A006C  bne cr6, 0x831dbb10
	if !ctx.cr[6].eq {
	pc = 0x831DBB10; continue 'dispatch;
	}
	// 831DBAA8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DBAAC: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831DBAB0: 2B0B0006  cmplwi cr6, r11, 6
	ctx.cr[6].compare_u32(ctx.r[11].u32, 6 as u32, &mut ctx.xer);
	// 831DBAB4: 4198FFE8  blt cr6, 0x831dba9c
	if ctx.cr[6].lt {
	pc = 0x831DBA9C; continue 'dispatch;
	}
	// 831DBAB8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DBABC: 9164000C  stw r11, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 831DBAC0: 8163004C  lwz r11, 0x4c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DBAC4: 91640010  stw r11, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DBAC8: 81430058  lwz r10, 0x58(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DBACC: 91440014  stw r10, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831DBAD0: 89630039  lbz r11, 0x39(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(57 as u32) ) } as u64;
	// 831DBAD4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DBAD8: 409A0008  bne cr6, 0x831dbae0
	if !ctx.cr[6].eq {
	pc = 0x831DBAE0; continue 'dispatch;
	}
	// 831DBADC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831DBAE0: 99640018  stb r11, 0x18(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), ctx.r[11].u8 ) };
	// 831DBAE4: 8963003A  lbz r11, 0x3a(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(58 as u32) ) } as u64;
	// 831DBAE8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DBAEC: 409A0008  bne cr6, 0x831dbaf4
	if !ctx.cr[6].eq {
	pc = 0x831DBAF4; continue 'dispatch;
	}
	// 831DBAF0: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 831DBAF4: 99640019  stb r11, 0x19(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(25 as u32), ctx.r[11].u8 ) };
	// 831DBAF8: 81430048  lwz r10, 0x48(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(72 as u32) ) } as u64;
	// 831DBAFC: 9144001C  stw r10, 0x1c(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), ctx.r[10].u32 ) };
	// 831DBB00: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DBB04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DBB08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DBB0C: 4E800020  blr
	return;
	// 831DBB10: 556B1838  slwi r11, r11, 3
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DBB14: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831DBB18: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DBB1C: 4BFFFFA0  b 0x831dbabc
	pc = 0x831DBABC; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBB20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DBB20 size=220
    let mut pc: u32 = 0x831DBB20;
    'dispatch: loop {
        match pc {
            0x831DBB20 => {
    //   block [0x831DBB20..0x831DBBFC)
	// 831DBB20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DBB24: 4BFCC649  bl 0x831a816c
	ctx.lr = 0x831DBB28;
	sub_831A8130(ctx, base);
	// 831DBB28: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DBB2C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DBB30: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831DBB34: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831DBB38: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DBB3C: 816BD59C  lwz r11, -0x2a64(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBB40: 83CB003C  lwz r30, 0x3c(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831DBB44: 4BFFFF15  bl 0x831dba58
	ctx.lr = 0x831DBB48;
	sub_831DBA58(ctx, base);
	// 831DBB48: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DBB4C: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 831DBB50: 48007559  bl 0x831e30a8
	ctx.lr = 0x831DBB54;
	sub_831E30A8(ctx, base);
	// 831DBB54: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DBB58: 41980098  blt cr6, 0x831dbbf0
	if ctx.cr[6].lt {
	pc = 0x831DBBF0; continue 'dispatch;
	}
	// 831DBB5C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DBB60: 39610080  addi r11, r1, 0x80
	ctx.r[11].s64 = ctx.r[1].s64 + 128;
	// 831DBB64: 3920000A  li r9, 0xa
	ctx.r[9].s64 = 10;
	// 831DBB68: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831DBB6C: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 831DBB70: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DBB74: 4200FFF8  bdnz 0x831dbb6c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831DBB6C; continue 'dispatch;
	}
	// 831DBB78: 817F0058  lwz r11, 0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DBB7C: 38610088  addi r3, r1, 0x88
	ctx.r[3].s64 = ctx.r[1].s64 + 136;
	// 831DBB80: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831DBB84: 99410080  stb r10, 0x80(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[10].u8 ) };
	// 831DBB88: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DBB8C: 91610084  stw r11, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 831DBB90: 4BFCC981  bl 0x831a8510
	ctx.lr = 0x831DBB94;
	sub_831A8510(ctx, base);
	// 831DBB94: 895F003B  lbz r10, 0x3b(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(59 as u32) ) } as u64;
	// 831DBB98: C01F003C  lfs f0, 0x3c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DBB9C: 893F0040  lbz r9, 0x40(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DBBA0: D00100C0  stfs f0, 0xc0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 831DBBA4: 811F0050  lwz r8, 0x50(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DBBA8: 38A10054  addi r5, r1, 0x54
	ctx.r[5].s64 = ctx.r[1].s64 + 84;
	// 831DBBAC: 80FF0054  lwz r7, 0x54(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DBBB0: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 831DBBB4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DBBB8: 994100C4  stb r10, 0xc4(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[10].u8 ) };
	// 831DBBBC: 992100C5  stb r9, 0xc5(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(197 as u32), ctx.r[9].u8 ) };
	// 831DBBC0: 910100C8  stw r8, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[8].u32 ) };
	// 831DBBC4: 90E100CC  stw r7, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[7].u32 ) };
	// 831DBBC8: 4BFFF4A9  bl 0x831db070
	ctx.lr = 0x831DBBCC;
	sub_831DB070(ctx, base);
	// 831DBBCC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DBBD0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DBBD4: 41980020  blt cr6, 0x831dbbf4
	if ctx.cr[6].lt {
	pc = 0x831DBBF4; continue 'dispatch;
	}
	// 831DBBD8: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DBBDC: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DBBE0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DBBE4: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DBBE8: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 831DBBEC: 4BFCC5D0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831DBBF0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DBBF4: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 831DBBF8: 4BFCC5C4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBC00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DBC00 size=340
    let mut pc: u32 = 0x831DBC00;
    'dispatch: loop {
        match pc {
            0x831DBC00 => {
    //   block [0x831DBC00..0x831DBD54)
	// 831DBC00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DBC04: 4BFCC561  bl 0x831a8164
	ctx.lr = 0x831DBC08;
	sub_831A8130(ctx, base);
	// 831DBC08: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DBC0C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DBC10: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831DBC14: 394BFFC8  addi r10, r11, -0x38
	ctx.r[10].s64 = ctx.r[11].s64 + -56;
	// 831DBC18: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831DBC1C: 915B0000  stw r10, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DBC20: 812A003C  lwz r9, 0x3c(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(60 as u32) ) } as u64;
	// 831DBC24: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831DBC28: 4E800421  bctrl
	ctx.lr = 0x831DBC2C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DBC2C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DBC30: 41980020  blt cr6, 0x831dbc50
	if ctx.cr[6].lt {
	pc = 0x831DBC50; continue 'dispatch;
	}
	// 831DBC34: 807B004C  lwz r3, 0x4c(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DBC38: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DBC3C: 419A0014  beq cr6, 0x831dbc50
	if ctx.cr[6].eq {
	pc = 0x831DBC50; continue 'dispatch;
	}
	// 831DBC40: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBC44: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 831DBC48: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DBC4C: 4E800421  bctrl
	ctx.lr = 0x831DBC50;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DBC50: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DBC54: 838BD59C  lwz r28, -0x2a64(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBC58: 48067505  bl 0x8324315c
	ctx.lr = 0x831DBC5C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DBC5C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DBC60: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DBC64: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DBC68: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DBC6C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBC70: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBC74: 419A0010  beq cr6, 0x831dbc84
	if ctx.cr[6].eq {
	pc = 0x831DBC84; continue 'dispatch;
	}
	// 831DBC78: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DBC7C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DBC80: 419A001C  beq cr6, 0x831dbc9c
	if ctx.cr[6].eq {
	pc = 0x831DBC9C; continue 'dispatch;
	}
	// 831DBC84: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBC88: 48066DF5  bl 0x83242a7c
	ctx.lr = 0x831DBC8C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DBC8C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831DBC90: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBC94: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DBC98: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831DBC9C: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831DBCA0: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DBCA4: 817C0058  lwz r11, 0x58(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DBCA8: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 831DBCAC: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBCB0: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DBCB4: 419A0028  beq cr6, 0x831dbcdc
	if ctx.cr[6].eq {
	pc = 0x831DBCDC; continue 'dispatch;
	}
	// 831DBCB8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBCBC: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DBCC0: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBCC4: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBCC8: 91280000  stw r9, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DBCCC: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBCD0: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DBCD4: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DBCD8: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBCDC: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831DBCE0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831DBCE4: 419A003C  beq cr6, 0x831dbd20
	if ctx.cr[6].eq {
	pc = 0x831DBD20; continue 'dispatch;
	}
	// 831DBCE8: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DBCEC: 409A0034  bne cr6, 0x831dbd20
	if !ctx.cr[6].eq {
	pc = 0x831DBD20; continue 'dispatch;
	}
	// 831DBCF0: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBCF4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBCF8: 40820028  bne 0x831dbd20
	if !ctx.cr[0].eq {
	pc = 0x831DBD20; continue 'dispatch;
	}
	// 831DBCFC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DBD00: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DBD04: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DBD08: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DBD0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBD10: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DBD14: 48066D59  bl 0x83242a6c
	ctx.lr = 0x831DBD18;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DBD18: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DBD1C: 48067451  bl 0x8324316c
	ctx.lr = 0x831DBD20;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DBD20: 807B004C  lwz r3, 0x4c(r27)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DBD24: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DBD28: 419A001C  beq cr6, 0x831dbd44
	if ctx.cr[6].eq {
	pc = 0x831DBD44; continue 'dispatch;
	}
	// 831DBD2C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBD30: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBD34: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DBD38: 4E800421  bctrl
	ctx.lr = 0x831DBD3C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DBD3C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831DBD40: 913B004C  stw r9, 0x4c(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(76 as u32), ctx.r[9].u32 ) };
	// 831DBD44: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 831DBD48: 480076E9  bl 0x831e3430
	ctx.lr = 0x831DBD4C;
	sub_831E3430(ctx, base);
	// 831DBD4C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DBD50: 4BFCC464  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBD58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DBD58 size=16
    let mut pc: u32 = 0x831DBD58;
    'dispatch: loop {
        match pc {
            0x831DBD58 => {
    //   block [0x831DBD58..0x831DBD68)
	// 831DBD58: 81630030  lwz r11, 0x30(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(48 as u32) ) } as u64;
	// 831DBD5C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DBD60: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DBD64: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBD68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DBD68 size=16
    let mut pc: u32 = 0x831DBD68;
    'dispatch: loop {
        match pc {
            0x831DBD68 => {
    //   block [0x831DBD68..0x831DBD78)
	// 831DBD68: 8963000C  lbz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DBD6C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DBD70: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831DBD74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBD78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DBD78 size=28
    let mut pc: u32 = 0x831DBD78;
    'dispatch: loop {
        match pc {
            0x831DBD78 => {
    //   block [0x831DBD78..0x831DBD94)
	// 831DBD78: 39630034  addi r11, r3, 0x34
	ctx.r[11].s64 = ctx.r[3].s64 + 52;
	// 831DBD7C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DBD80: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBD84: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DBD88: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBD8C: 91240004  stw r9, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DBD90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBD98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DBD98 size=220
    let mut pc: u32 = 0x831DBD98;
    'dispatch: loop {
        match pc {
            0x831DBD98 => {
    //   block [0x831DBD98..0x831DBE74)
	// 831DBD98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DBD9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DBDA0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831DBDA4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DBDA8: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DBDAC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DBDB0: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831DBDB4: 387E0054  addi r3, r30, 0x54
	ctx.r[3].s64 = ctx.r[30].s64 + 84;
	// 831DBDB8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831DBDBC: 4BFCC755  bl 0x831a8510
	ctx.lr = 0x831DBDC0;
	sub_831A8510(ctx, base);
	// 831DBDC0: 897F0038  lbz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 831DBDC4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DBDC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBDCC: 997E0090  stb r11, 0x90(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(144 as u32), ctx.r[11].u8 ) };
	// 831DBDD0: 4BFFFC89  bl 0x831dba58
	ctx.lr = 0x831DBDD4;
	sub_831DBA58(ctx, base);
	// 831DBDD4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DBDD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DBDDC: 48007385  bl 0x831e3160
	ctx.lr = 0x831DBDE0;
	sub_831E3160(ctx, base);
	// 831DBDE0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DBDE4: 41980078  blt cr6, 0x831dbe5c
	if ctx.cr[6].lt {
	pc = 0x831DBE5C; continue 'dispatch;
	}
	// 831DBDE8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DBDEC: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 831DBDF0: 3920000A  li r9, 0xa
	ctx.r[9].s64 = 10;
	// 831DBDF4: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831DBDF8: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 831DBDFC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DBE00: 4200FFF8  bdnz 0x831dbdf8
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831DBDF8; continue 'dispatch;
	}
	// 831DBE04: 817F0058  lwz r11, 0x58(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DBE08: 38610078  addi r3, r1, 0x78
	ctx.r[3].s64 = ctx.r[1].s64 + 120;
	// 831DBE0C: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831DBE10: 99410070  stb r10, 0x70(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u8 ) };
	// 831DBE14: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DBE18: 91610074  stw r11, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[11].u32 ) };
	// 831DBE1C: 4BFCC6F5  bl 0x831a8510
	ctx.lr = 0x831DBE20;
	sub_831A8510(ctx, base);
	// 831DBE20: 895F003B  lbz r10, 0x3b(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(59 as u32) ) } as u64;
	// 831DBE24: C01F003C  lfs f0, 0x3c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DBE28: 893F0040  lbz r9, 0x40(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831DBE2C: D00100B0  stfs f0, 0xb0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 831DBE30: 811F0050  lwz r8, 0x50(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DBE34: 38C000FF  li r6, 0xff
	ctx.r[6].s64 = 255;
	// 831DBE38: 80FF0054  lwz r7, 0x54(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DBE3C: 38A10070  addi r5, r1, 0x70
	ctx.r[5].s64 = ctx.r[1].s64 + 112;
	// 831DBE40: 389E004C  addi r4, r30, 0x4c
	ctx.r[4].s64 = ctx.r[30].s64 + 76;
	// 831DBE44: 994100B4  stb r10, 0xb4(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[10].u8 ) };
	// 831DBE48: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DBE4C: 992100B5  stb r9, 0xb5(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(181 as u32), ctx.r[9].u8 ) };
	// 831DBE50: 910100B8  stw r8, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[8].u32 ) };
	// 831DBE54: 90E100BC  stw r7, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[7].u32 ) };
	// 831DBE58: 48007DA1  bl 0x831e3bf8
	ctx.lr = 0x831DBE5C;
	sub_831E3BF8(ctx, base);
	// 831DBE5C: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 831DBE60: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DBE64: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DBE68: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831DBE6C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DBE70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DBE78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DBE78 size=652
    let mut pc: u32 = 0x831DBE78;
    'dispatch: loop {
        match pc {
            0x831DBE78 => {
    //   block [0x831DBE78..0x831DC104)
	// 831DBE78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DBE7C: 4BFCC2E9  bl 0x831a8164
	ctx.lr = 0x831DBE80;
	sub_831A8130(ctx, base);
	// 831DBE80: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DBE84: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831DBE88: 480672D5  bl 0x8324315c
	ctx.lr = 0x831DBE8C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DBE8C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DBE90: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DBE94: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DBE98: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DBE9C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBEA0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBEA4: 419A0010  beq cr6, 0x831dbeb4
	if ctx.cr[6].eq {
	pc = 0x831DBEB4; continue 'dispatch;
	}
	// 831DBEA8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DBEAC: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DBEB0: 419A0020  beq cr6, 0x831dbed0
	if ctx.cr[6].eq {
	pc = 0x831DBED0; continue 'dispatch;
	}
	// 831DBEB4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBEB8: 48066BC5  bl 0x83242a7c
	ctx.lr = 0x831DBEBC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DBEBC: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 831DBEC0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBEC4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DBEC8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DBECC: 48000008  b 0x831dbed4
	pc = 0x831DBED4; continue 'dispatch;
	// 831DBED0: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DBED4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DBED8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBEDC: 893B003D  lbz r9, 0x3d(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DBEE0: 55280672  rlwinm r8, r9, 0, 0x19, 0x19
	ctx.r[8].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DBEE4: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831DBEE8: 409A0054  bne cr6, 0x831dbf3c
	if !ctx.cr[6].eq {
	pc = 0x831DBF3C; continue 'dispatch;
	}
	// 831DBEEC: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 831DBEF0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBEF4: 419A0038  beq cr6, 0x831dbf2c
	if ctx.cr[6].eq {
	pc = 0x831DBF2C; continue 'dispatch;
	}
	// 831DBEF8: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DBEFC: 409A0030  bne cr6, 0x831dbf2c
	if !ctx.cr[6].eq {
	pc = 0x831DBF2C; continue 'dispatch;
	}
	// 831DBF00: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBF04: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBF08: 40820024  bne 0x831dbf2c
	if !ctx.cr[0].eq {
	pc = 0x831DBF2C; continue 'dispatch;
	}
	// 831DBF0C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DBF10: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DBF14: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DBF18: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBF1C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DBF20: 48066B4D  bl 0x83242a6c
	ctx.lr = 0x831DBF24;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DBF24: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DBF28: 48067245  bl 0x8324316c
	ctx.lr = 0x831DBF2C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DBF2C: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831DBF30: 60634004  ori r3, r3, 0x4004
	ctx.r[3].u64 = ctx.r[3].u64 | 16388;
	// 831DBF34: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DBF38: 4BFCC27C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831DBF3C: 3FC08343  lis r30, -0x7cbd
	ctx.r[30].s64 = -2092761088;
	// 831DBF40: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831DBF44: 807ED59C  lwz r3, -0x2a64(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBF48: 4BFFCA91  bl 0x831d89d8
	ctx.lr = 0x831DBF4C;
	sub_831D89D8(ctx, base);
	// 831DBF4C: 839ED59C  lwz r28, -0x2a64(r30)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DBF50: 4806720D  bl 0x8324315c
	ctx.lr = 0x831DBF54;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DBF54: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBF58: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DBF5C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DBF60: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBF64: 419A0010  beq cr6, 0x831dbf74
	if ctx.cr[6].eq {
	pc = 0x831DBF74; continue 'dispatch;
	}
	// 831DBF68: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DBF6C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DBF70: 419A001C  beq cr6, 0x831dbf8c
	if ctx.cr[6].eq {
	pc = 0x831DBF8C; continue 'dispatch;
	}
	// 831DBF74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DBF78: 48066B05  bl 0x83242a7c
	ctx.lr = 0x831DBF7C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DBF7C: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831DBF80: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBF84: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DBF88: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831DBF8C: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831DBF90: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DBF94: 817C004C  lwz r11, 0x4c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DBF98: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 831DBF9C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBFA0: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831DBFA4: 419A0028  beq cr6, 0x831dbfcc
	if ctx.cr[6].eq {
	pc = 0x831DBFCC; continue 'dispatch;
	}
	// 831DBFA8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBFAC: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DBFB0: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DBFB4: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBFB8: 91280000  stw r9, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DBFBC: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBFC0: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DBFC4: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DBFC8: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DBFCC: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831DBFD0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831DBFD4: 419A003C  beq cr6, 0x831dc010
	if ctx.cr[6].eq {
	pc = 0x831DC010; continue 'dispatch;
	}
	// 831DBFD8: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DBFDC: 409A0034  bne cr6, 0x831dc010
	if !ctx.cr[6].eq {
	pc = 0x831DC010; continue 'dispatch;
	}
	// 831DBFE0: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DBFE4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DBFE8: 40820028  bne 0x831dc010
	if !ctx.cr[0].eq {
	pc = 0x831DC010; continue 'dispatch;
	}
	// 831DBFEC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DBFF0: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DBFF4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DBFF8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DBFFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC000: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC004: 48066A69  bl 0x83242a6c
	ctx.lr = 0x831DC008;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC008: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC00C: 48067161  bl 0x8324316c
	ctx.lr = 0x831DC010;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC010: 4806714D  bl 0x8324315c
	ctx.lr = 0x831DC014;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC014: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC018: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC01C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DC020: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC024: 419A0010  beq cr6, 0x831dc034
	if ctx.cr[6].eq {
	pc = 0x831DC034; continue 'dispatch;
	}
	// 831DC028: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC02C: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC030: 419A0018  beq cr6, 0x831dc048
	if ctx.cr[6].eq {
	pc = 0x831DC048; continue 'dispatch;
	}
	// 831DC034: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC038: 48066A45  bl 0x83242a7c
	ctx.lr = 0x831DC03C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC03C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC040: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DC044: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DC048: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC04C: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC050: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC054: 897B003D  lbz r11, 0x3d(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DC058: 5569063E  clrlwi r9, r11, 0x18
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831DC05C: 552906B0  rlwinm r9, r9, 0, 0x1a, 0x18
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DC060: 993B003D  stb r9, 0x3d(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(61 as u32), ctx.r[9].u8 ) };
	// 831DC064: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC068: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC06C: 419A0044  beq cr6, 0x831dc0b0
	if ctx.cr[6].eq {
	pc = 0x831DC0B0; continue 'dispatch;
	}
	// 831DC070: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC074: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC078: 409A0038  bne cr6, 0x831dc0b0
	if !ctx.cr[6].eq {
	pc = 0x831DC0B0; continue 'dispatch;
	}
	// 831DC07C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC080: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC084: 4082002C  bne 0x831dc0b0
	if !ctx.cr[0].eq {
	pc = 0x831DC0B0; continue 'dispatch;
	}
	// 831DC088: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC08C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC090: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC094: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC098: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC09C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC0A0: 480669CD  bl 0x83242a6c
	ctx.lr = 0x831DC0A4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC0A4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC0A8: 480670C5  bl 0x8324316c
	ctx.lr = 0x831DC0AC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC0AC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC0B0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC0B4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC0B8: 419A0040  beq cr6, 0x831dc0f8
	if ctx.cr[6].eq {
	pc = 0x831DC0F8; continue 'dispatch;
	}
	// 831DC0BC: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC0C0: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC0C4: 409A0034  bne cr6, 0x831dc0f8
	if !ctx.cr[6].eq {
	pc = 0x831DC0F8; continue 'dispatch;
	}
	// 831DC0C8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC0CC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC0D0: 40820028  bne 0x831dc0f8
	if !ctx.cr[0].eq {
	pc = 0x831DC0F8; continue 'dispatch;
	}
	// 831DC0D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC0D8: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC0DC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC0E0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC0E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC0E8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC0EC: 48066981  bl 0x83242a6c
	ctx.lr = 0x831DC0F0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC0F0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC0F4: 48067079  bl 0x8324316c
	ctx.lr = 0x831DC0F8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC0F8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC0FC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DC100: 4BFCC0B4  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DC108 size=248
    let mut pc: u32 = 0x831DC108;
    'dispatch: loop {
        match pc {
            0x831DC108 => {
    //   block [0x831DC108..0x831DC200)
	// 831DC108: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC10C: 4BFCC059  bl 0x831a8164
	ctx.lr = 0x831DC110;
	sub_831A8130(ctx, base);
	// 831DC110: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC114: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC118: 48006F01  bl 0x831e3018
	ctx.lr = 0x831DC11C;
	sub_831E3018(ctx, base);
	// 831DC11C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831DC120: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831DC124: 3D208343  lis r9, -0x7cbd
	ctx.r[9].s64 = -2092761088;
	// 831DC128: 390AFFC8  addi r8, r10, -0x38
	ctx.r[8].s64 = ctx.r[10].s64 + -56;
	// 831DC12C: C00B08A8  lfs f0, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DC130: 911D0000  stw r8, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831DC134: D01D008C  stfs f0, 0x8c(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 831DC138: 8169D59C  lwz r11, -0x2a64(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DC13C: 3BCB0050  addi r30, r11, 0x50
	ctx.r[30].s64 = ctx.r[11].s64 + 80;
	// 831DC140: 4806701D  bl 0x8324315c
	ctx.lr = 0x831DC144;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC144: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC148: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831DC14C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DC150: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 831DC154: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC158: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC15C: 419A0010  beq cr6, 0x831dc16c
	if ctx.cr[6].eq {
	pc = 0x831DC16C; continue 'dispatch;
	}
	// 831DC160: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC164: 7F1C5040  cmplw cr6, r28, r10
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC168: 419A0018  beq cr6, 0x831dc180
	if ctx.cr[6].eq {
	pc = 0x831DC180; continue 'dispatch;
	}
	// 831DC16C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC170: 4806690D  bl 0x83242a7c
	ctx.lr = 0x831DC174;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC174: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC178: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 831DC17C: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831DC180: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC184: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC188: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC18C: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC190: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 831DC194: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 831DC198: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC19C: 912B0004  stw r9, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DC1A0: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC1A4: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC1A8: 91680000  stw r11, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DC1AC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC1B0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC1B4: 419A0040  beq cr6, 0x831dc1f4
	if ctx.cr[6].eq {
	pc = 0x831DC1F4; continue 'dispatch;
	}
	// 831DC1B8: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC1BC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC1C0: 409A0034  bne cr6, 0x831dc1f4
	if !ctx.cr[6].eq {
	pc = 0x831DC1F4; continue 'dispatch;
	}
	// 831DC1C4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC1C8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC1CC: 40820028  bne 0x831dc1f4
	if !ctx.cr[0].eq {
	pc = 0x831DC1F4; continue 'dispatch;
	}
	// 831DC1D0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC1D4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC1D8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC1DC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC1E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC1E4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC1E8: 48066885  bl 0x83242a6c
	ctx.lr = 0x831DC1EC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC1EC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC1F0: 48066F7D  bl 0x8324316c
	ctx.lr = 0x831DC1F4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC1F4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DC1F8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DC1FC: 4BFCBFB8  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC200(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC200 size=48
    let mut pc: u32 = 0x831DC200;
    'dispatch: loop {
        match pc {
            0x831DC200 => {
    //   block [0x831DC200..0x831DC230)
	// 831DC200: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC204: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DC208: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DC20C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC210: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DC214: 4BFFF9ED  bl 0x831dbc00
	ctx.lr = 0x831DC218;
	sub_831DBC00(ctx, base);
	// 831DC218: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC21C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DC220: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DC224: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DC228: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DC22C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC230(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC230 size=556
    let mut pc: u32 = 0x831DC230;
    'dispatch: loop {
        match pc {
            0x831DC230 => {
    //   block [0x831DC230..0x831DC45C)
	// 831DC230: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC234: 4BFCBF2D  bl 0x831a8160
	ctx.lr = 0x831DC238;
	sub_831A8130(ctx, base);
	// 831DC238: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC23C: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831DC240: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 831DC244: 48066F19  bl 0x8324315c
	ctx.lr = 0x831DC248;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC248: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC24C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC250: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DC254: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DC258: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC25C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC260: 419A0010  beq cr6, 0x831dc270
	if ctx.cr[6].eq {
	pc = 0x831DC270; continue 'dispatch;
	}
	// 831DC264: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC268: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC26C: 419A0018  beq cr6, 0x831dc284
	if ctx.cr[6].eq {
	pc = 0x831DC284; continue 'dispatch;
	}
	// 831DC270: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC274: 48066809  bl 0x83242a7c
	ctx.lr = 0x831DC278;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC278: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC27C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DC280: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DC284: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC288: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC28C: 895B003D  lbz r10, 0x3d(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DC290: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831DC294: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831DC298: 419A0010  beq cr6, 0x831dc2a8
	if ctx.cr[6].eq {
	pc = 0x831DC2A8; continue 'dispatch;
	}
	// 831DC29C: 3F408000  lis r26, -0x8000
	ctx.r[26].s64 = -2147483648;
	// 831DC2A0: 635AFFFF  ori r26, r26, 0xffff
	ctx.r[26].u64 = ctx.r[26].u64 | 65535;
	// 831DC2A4: 48000164  b 0x831dc408
	pc = 0x831DC408; continue 'dispatch;
	// 831DC2A8: 554A0672  rlwinm r10, r10, 0, 0x19, 0x19
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831DC2AC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DC2B0: 409A0158  bne cr6, 0x831dc408
	if !ctx.cr[6].eq {
	pc = 0x831DC408; continue 'dispatch;
	}
	// 831DC2B4: 48066EA9  bl 0x8324315c
	ctx.lr = 0x831DC2B8;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC2B8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC2BC: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC2C0: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DC2C4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC2C8: 419A0010  beq cr6, 0x831dc2d8
	if ctx.cr[6].eq {
	pc = 0x831DC2D8; continue 'dispatch;
	}
	// 831DC2CC: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC2D0: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC2D4: 419A0018  beq cr6, 0x831dc2ec
	if ctx.cr[6].eq {
	pc = 0x831DC2EC; continue 'dispatch;
	}
	// 831DC2D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC2DC: 480667A1  bl 0x83242a7c
	ctx.lr = 0x831DC2E0;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC2E0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC2E4: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DC2E8: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DC2EC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC2F0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC2F4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC2F8: 897B003D  lbz r11, 0x3d(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DC2FC: 61690040  ori r9, r11, 0x40
	ctx.r[9].u64 = ctx.r[11].u64 | 64;
	// 831DC300: 993B003D  stb r9, 0x3d(r27)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[27].u32.wrapping_add(61 as u32), ctx.r[9].u8 ) };
	// 831DC304: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC308: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC30C: 419A0040  beq cr6, 0x831dc34c
	if ctx.cr[6].eq {
	pc = 0x831DC34C; continue 'dispatch;
	}
	// 831DC310: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC314: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC318: 409A0034  bne cr6, 0x831dc34c
	if !ctx.cr[6].eq {
	pc = 0x831DC34C; continue 'dispatch;
	}
	// 831DC31C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC320: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC324: 40820028  bne 0x831dc34c
	if !ctx.cr[0].eq {
	pc = 0x831DC34C; continue 'dispatch;
	}
	// 831DC328: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC32C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC330: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC334: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC338: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC33C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC340: 4806672D  bl 0x83242a6c
	ctx.lr = 0x831DC344;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC344: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC348: 48066E25  bl 0x8324316c
	ctx.lr = 0x831DC34C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC34C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC350: 83CBD59C  lwz r30, -0x2a64(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831DC354: 48066E09  bl 0x8324315c
	ctx.lr = 0x831DC358;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC358: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC35C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DC360: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831DC364: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC368: 419A0010  beq cr6, 0x831dc378
	if ctx.cr[6].eq {
	pc = 0x831DC378; continue 'dispatch;
	}
	// 831DC36C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC370: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC374: 419A0018  beq cr6, 0x831dc38c
	if ctx.cr[6].eq {
	pc = 0x831DC38C; continue 'dispatch;
	}
	// 831DC378: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC37C: 48066701  bl 0x83242a7c
	ctx.lr = 0x831DC380;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC380: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC384: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831DC388: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831DC38C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC390: 395E0044  addi r10, r30, 0x44
	ctx.r[10].s64 = ctx.r[30].s64 + 68;
	// 831DC394: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC398: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 831DC39C: 817E004C  lwz r11, 0x4c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DC3A0: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 831DC3A4: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831DC3A8: 815E0048  lwz r10, 0x48(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) } as u64;
	// 831DC3AC: 914B0004  stw r10, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831DC3B0: 917E0048  stw r11, 0x48(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 831DC3B4: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC3B8: 91680000  stw r11, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DC3BC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC3C0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC3C4: 419A0044  beq cr6, 0x831dc408
	if ctx.cr[6].eq {
	pc = 0x831DC408; continue 'dispatch;
	}
	// 831DC3C8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC3CC: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC3D0: 409A0038  bne cr6, 0x831dc408
	if !ctx.cr[6].eq {
	pc = 0x831DC408; continue 'dispatch;
	}
	// 831DC3D4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC3D8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC3DC: 4082002C  bne 0x831dc408
	if !ctx.cr[0].eq {
	pc = 0x831DC408; continue 'dispatch;
	}
	// 831DC3E0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC3E4: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC3E8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC3EC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC3F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC3F4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC3F8: 48066675  bl 0x83242a6c
	ctx.lr = 0x831DC3FC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC3FC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC400: 48066D6D  bl 0x8324316c
	ctx.lr = 0x831DC404;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC404: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC408: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC40C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC410: 419A0040  beq cr6, 0x831dc450
	if ctx.cr[6].eq {
	pc = 0x831DC450; continue 'dispatch;
	}
	// 831DC414: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC418: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC41C: 409A0034  bne cr6, 0x831dc450
	if !ctx.cr[6].eq {
	pc = 0x831DC450; continue 'dispatch;
	}
	// 831DC420: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC424: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC428: 40820028  bne 0x831dc450
	if !ctx.cr[0].eq {
	pc = 0x831DC450; continue 'dispatch;
	}
	// 831DC42C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DC430: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC434: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DC438: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC43C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC440: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC444: 48066629  bl 0x83242a6c
	ctx.lr = 0x831DC448;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC448: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC44C: 48066D21  bl 0x8324316c
	ctx.lr = 0x831DC450;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC450: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DC454: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DC458: 4BFCBD58  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC460(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC460 size=172
    let mut pc: u32 = 0x831DC460;
    'dispatch: loop {
        match pc {
            0x831DC460 => {
    //   block [0x831DC460..0x831DC50C)
	// 831DC460: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC464: 4BFCBD09  bl 0x831a816c
	ctx.lr = 0x831DC468;
	sub_831A8130(ctx, base);
	// 831DC468: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC46C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DC470: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831DC474: 4BFFFA05  bl 0x831dbe78
	ctx.lr = 0x831DC478;
	sub_831DBE78(ctx, base);
	// 831DC478: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 831DC47C: 616A4004  ori r10, r11, 0x4004
	ctx.r[10].u64 = ctx.r[11].u64 | 16388;
	// 831DC480: 7F035000  cmpw cr6, r3, r10
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831DC484: 409A0080  bne cr6, 0x831dc504
	if !ctx.cr[6].eq {
	pc = 0x831DC504; continue 'dispatch;
	}
	// 831DC488: 807E004C  lwz r3, 0x4c(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DC48C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DC490: 419A0068  beq cr6, 0x831dc4f8
	if ctx.cr[6].eq {
	pc = 0x831DC4F8; continue 'dispatch;
	}
	// 831DC494: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC498: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DC49C: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831DC4A0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC4A4: 4E800421  bctrl
	ctx.lr = 0x831DC4A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC4A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC4AC: 41980058  blt cr6, 0x831dc504
	if ctx.cr[6].lt {
	pc = 0x831DC504; continue 'dispatch;
	}
	// 831DC4B0: 57EB07FE  clrlwi r11, r31, 0x1f
	ctx.r[11].u64 = ctx.r[31].u32 as u64 & 0x00000001u64;
	// 831DC4B4: 57FD063E  clrlwi r29, r31, 0x18
	ctx.r[29].u64 = ctx.r[31].u32 as u64 & 0x000000FFu64;
	// 831DC4B8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DC4BC: 409A003C  bne cr6, 0x831dc4f8
	if !ctx.cr[6].eq {
	pc = 0x831DC4F8; continue 'dispatch;
	}
	// 831DC4C0: 807E004C  lwz r3, 0x4c(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DC4C4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DC4C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC4CC: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831DC4D0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC4D4: 4E800421  bctrl
	ctx.lr = 0x831DC4D8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC4D8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC4DC: 41980028  blt cr6, 0x831dc504
	if ctx.cr[6].lt {
	pc = 0x831DC504; continue 'dispatch;
	}
	// 831DC4E0: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DC4E4: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831DC4E8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DC4EC: 409A000C  bne cr6, 0x831dc4f8
	if !ctx.cr[6].eq {
	pc = 0x831DC4F8; continue 'dispatch;
	}
	// 831DC4F0: 57AB063E  clrlwi r11, r29, 0x18
	ctx.r[11].u64 = ctx.r[29].u32 as u64 & 0x000000FFu64;
	// 831DC4F4: 617F0001  ori r31, r11, 1
	ctx.r[31].u64 = ctx.r[11].u64 | 1;
	// 831DC4F8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DC4FC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC500: 48007D49  bl 0x831e4248
	ctx.lr = 0x831DC504;
	sub_831E4248(ctx, base);
	// 831DC504: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DC508: 4BFCBCB4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC510(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC510 size=256
    let mut pc: u32 = 0x831DC510;
    'dispatch: loop {
        match pc {
            0x831DC510 => {
    //   block [0x831DC510..0x831DC610)
	// 831DC510: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC514: 4BFCBC55  bl 0x831a8168
	ctx.lr = 0x831DC518;
	sub_831A8130(ctx, base);
	// 831DC518: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC51C: 9081009C  stw r4, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[4].u32 ) };
	// 831DC520: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DC524: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC528: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831DC52C: 4BFFF5F5  bl 0x831dbb20
	ctx.lr = 0x831DC530;
	sub_831DBB20(ctx, base);
	// 831DC530: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC534: 41980010  blt cr6, 0x831dc544
	if ctx.cr[6].lt {
	pc = 0x831DC544; continue 'dispatch;
	}
	// 831DC538: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DC53C: 388B0094  addi r4, r11, 0x94
	ctx.r[4].s64 = ctx.r[11].s64 + 148;
	// 831DC540: 48000008  b 0x831dc548
	pc = 0x831DC548; continue 'dispatch;
	// 831DC544: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DC548: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DC54C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC550: 41980098  blt cr6, 0x831dc5e8
	if ctx.cr[6].lt {
	pc = 0x831DC5E8; continue 'dispatch;
	}
	// 831DC554: 3C606182  lis r3, 0x6182
	ctx.r[3].s64 = 1635909632;
	// 831DC558: 38A1009C  addi r5, r1, 0x9c
	ctx.r[5].s64 = ctx.r[1].s64 + 156;
	// 831DC55C: 60630006  ori r3, r3, 6
	ctx.r[3].u64 = ctx.r[3].u64 | 6;
	// 831DC560: 48006A09  bl 0x831e2f68
	ctx.lr = 0x831DC564;
	sub_831E2F68(ctx, base);
	// 831DC564: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DC568: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831DC56C: 4198007C  blt cr6, 0x831dc5e8
	if ctx.cr[6].lt {
	pc = 0x831DC5E8; continue 'dispatch;
	}
	// 831DC570: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DC574: 38800094  li r4, 0x94
	ctx.r[4].s64 = 148;
	// 831DC578: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC57C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DC580: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC584: 4E800421  bctrl
	ctx.lr = 0x831DC588;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC588: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DC58C: 419A001C  beq cr6, 0x831dc5a8
	if ctx.cr[6].eq {
	pc = 0x831DC5A8; continue 'dispatch;
	}
	// 831DC590: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831DC594: 8081009C  lwz r4, 0x9c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DC598: 4BFFFB71  bl 0x831dc108
	ctx.lr = 0x831DC59C;
	sub_831DC108(ctx, base);
	// 831DC59C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DC5A0: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831DC5A4: 409A0010  bne cr6, 0x831dc5b4
	if !ctx.cr[6].eq {
	pc = 0x831DC5B4; continue 'dispatch;
	}
	// 831DC5A8: 3FE08007  lis r31, -0x7ff9
	ctx.r[31].s64 = -2147024896;
	// 831DC5AC: 63FF000E  ori r31, r31, 0xe
	ctx.r[31].u64 = ctx.r[31].u64 | 14;
	// 831DC5B0: 48000038  b 0x831dc5e8
	pc = 0x831DC5E8; continue 'dispatch;
	// 831DC5B4: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831DC5B8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC5BC: 4BFFF7DD  bl 0x831dbd98
	ctx.lr = 0x831DC5C0;
	sub_831DBD98(ctx, base);
	// 831DC5C0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DC5C4: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831DC5C8: 4198000C  blt cr6, 0x831dc5d4
	if ctx.cr[6].lt {
	pc = 0x831DC5D4; continue 'dispatch;
	}
	// 831DC5CC: 93DC0000  stw r30, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 831DC5D0: 48000018  b 0x831dc5e8
	pc = 0x831DC5E8; continue 'dispatch;
	// 831DC5D4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC5D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC5DC: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC5E0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC5E4: 4E800421  bctrl
	ctx.lr = 0x831DC5E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC5E8: 8061009C  lwz r3, 0x9c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DC5EC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831DC5F0: 419A0014  beq cr6, 0x831dc604
	if ctx.cr[6].eq {
	pc = 0x831DC604; continue 'dispatch;
	}
	// 831DC5F4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC5F8: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC5FC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC600: 4E800421  bctrl
	ctx.lr = 0x831DC604;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC604: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC608: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831DC60C: 4BFCBBAC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC610 size=160
    let mut pc: u32 = 0x831DC610;
    'dispatch: loop {
        match pc {
            0x831DC610 => {
    //   block [0x831DC610..0x831DC6B0)
	// 831DC610: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC614: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DC618: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DC61C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC620: 548B07FE  clrlwi r11, r4, 0x1f
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831DC624: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DC628: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DC62C: 419A001C  beq cr6, 0x831dc648
	if ctx.cr[6].eq {
	pc = 0x831DC648; continue 'dispatch;
	}
	// 831DC630: 4BFFFC01  bl 0x831dc230
	ctx.lr = 0x831DC634;
	sub_831DC230(ctx, base);
	// 831DC634: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DC638: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DC63C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DC640: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DC644: 4E800020  blr
	return;
	// 831DC648: 4BFFF831  bl 0x831dbe78
	ctx.lr = 0x831DC64C;
	sub_831DBE78(ctx, base);
	// 831DC64C: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 831DC650: 616A4004  ori r10, r11, 0x4004
	ctx.r[10].u64 = ctx.r[11].u64 | 16388;
	// 831DC654: 7F035000  cmpw cr6, r3, r10
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[10].s32, &mut ctx.xer);
	// 831DC658: 419A000C  beq cr6, 0x831dc664
	if ctx.cr[6].eq {
	pc = 0x831DC664; continue 'dispatch;
	}
	// 831DC65C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC660: 4198003C  blt cr6, 0x831dc69c
	if ctx.cr[6].lt {
	pc = 0x831DC69C; continue 'dispatch;
	}
	// 831DC664: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC668: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC66C: 814B005C  lwz r10, 0x5c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(92 as u32) ) } as u64;
	// 831DC670: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831DC674: 4E800421  bctrl
	ctx.lr = 0x831DC678;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC678: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 831DC67C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DC680: 81090030  lwz r8, 0x30(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(48 as u32) ) } as u64;
	// 831DC684: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831DC688: 4E800421  bctrl
	ctx.lr = 0x831DC68C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831DC68C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DC690: 4198000C  blt cr6, 0x831dc69c
	if ctx.cr[6].lt {
	pc = 0x831DC69C; continue 'dispatch;
	}
	// 831DC694: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC698: 48007989  bl 0x831e4020
	ctx.lr = 0x831DC69C;
	sub_831E4020(ctx, base);
	// 831DC69C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DC6A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DC6A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DC6A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DC6AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC6B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC6B0 size=12
    let mut pc: u32 = 0x831DC6B0;
    'dispatch: loop {
        match pc {
            0x831DC6B0 => {
    //   block [0x831DC6B0..0x831DC6BC)
	// 831DC6B0: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831DC6B4: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831DC6B8: 4BFE78A0  b 0x831c3f58
	sub_831C3F58(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC6C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC6C0 size=12
    let mut pc: u32 = 0x831DC6C0;
    'dispatch: loop {
        match pc {
            0x831DC6C0 => {
    //   block [0x831DC6C0..0x831DC6CC)
	// 831DC6C0: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831DC6C4: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831DC6C8: 4BFE7928  b 0x831c3ff0
	sub_831C3FF0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC6D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC6D0 size=16
    let mut pc: u32 = 0x831DC6D0;
    'dispatch: loop {
        match pc {
            0x831DC6D0 => {
    //   block [0x831DC6D0..0x831DC6E0)
	// 831DC6D0: 8963003D  lbz r11, 0x3d(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(61 as u32) ) } as u64;
	// 831DC6D4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC6D8: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831DC6DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC6E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC6E0 size=8
    let mut pc: u32 = 0x831DC6E0;
    'dispatch: loop {
        match pc {
            0x831DC6E0 => {
    //   block [0x831DC6E0..0x831DC6E8)
	// 831DC6E0: 80630020  lwz r3, 0x20(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 831DC6E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC6E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC6E8 size=52
    let mut pc: u32 = 0x831DC6E8;
    'dispatch: loop {
        match pc {
            0x831DC6E8 => {
    //   block [0x831DC6E8..0x831DC71C)
	// 831DC6E8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC6EC: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DC6F0: 396BD5A8  addi r11, r11, -0x2a58
	ctx.r[11].s64 = ctx.r[11].s64 + -10840;
	// 831DC6F4: 7CCA5A14  add r6, r10, r11
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DC6F8: 7CE000A6  mfmsr r7
	ctx.r[7].u64 = ctx.msr;
	// 831DC6FC: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831DC700: 7D203028  lwarx r9, 0, r6
	// lwarx
	let ea = ctx.r[6].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[9].u64 = ctx.reserved.u32 as u64;
	// 831DC704: 7D044A14  add r8, r4, r9
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[9].u64;
	// 831DC708: 7D00312D  stwcx. r8, 0, r6
	// stwcx.
	let addr = ctx.r[6].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[8].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 831DC70C: 7CE10164  mtmsrd r7, 1
	ctx.msr = (ctx.r[7].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831DC710: 4082FFE8  bne 0x831dc6f8
	if !ctx.cr[0].eq {
	pc = 0x831DC6F8; continue 'dispatch;
	}
	// 831DC714: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC718: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC720(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DC720 size=192
    let mut pc: u32 = 0x831DC720;
    'dispatch: loop {
        match pc {
            0x831DC720 => {
    //   block [0x831DC720..0x831DC7E0)
	// 831DC720: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC724: 4BFCBA3D  bl 0x831a8160
	ctx.lr = 0x831DC728;
	sub_831A8130(ctx, base);
	// 831DC728: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC72C: 7D4C42E6  mftb r10, 0x10c
	ctx.r[10].u64 = crate::rt::rdtsc_u64();
	// 831DC730: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC734: 3B810050  addi r28, r1, 0x50
	ctx.r[28].s64 = ctx.r[1].s64 + 80;
	// 831DC738: 3BEBD5A8  addi r31, r11, -0x2a58
	ctx.r[31].s64 = ctx.r[11].s64 + -10840;
	// 831DC73C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831DC740: 7D5A0676  sradi r26, r10, 0x20
	ctx.xer.ca = (ctx.r[10].s64 < 0) && ((ctx.r[10].u64 & ((1u64 << 32) - 1)) != 0);
	ctx.r[26].s64 = ctx.r[10].s64 >> 32;
	// 831DC744: 7D5B5378  mr r27, r10
	ctx.r[27].u64 = ctx.r[10].u64;
	// 831DC748: 816BD5A8  lwz r11, -0x2a58(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10840 as u32) ) } as u64;
	// 831DC74C: FBDC0000  std r30, 0(r28)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 831DC750: 3C605841  lis r3, 0x5841
	ctx.r[3].s64 = 1480654848;
	// 831DC754: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC758: 38A00028  li r5, 0x28
	ctx.r[5].s64 = 40;
	// 831DC75C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC760: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DC764: 811F000C  lwz r8, 0xc(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC768: 60637564  ori r3, r3, 0x7564
	ctx.r[3].u64 = ctx.r[3].u64 | 30052;
	// 831DC76C: 80FF0010  lwz r7, 0x10(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DC770: 80DF0014  lwz r6, 0x14(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831DC774: 83BF0018  lwz r29, 0x18(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DC778: FBDC0008  std r30, 8(r28)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 831DC77C: FBDC0010  std r30, 0x10(r28)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[28].u32.wrapping_add(16 as u32), ctx.r[30].u64 ) };
	// 831DC780: FBDC0018  std r30, 0x18(r28)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[28].u32.wrapping_add(24 as u32), ctx.r[30].u64 ) };
	// 831DC784: FBDC0020  std r30, 0x20(r28)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[28].u32.wrapping_add(32 as u32), ctx.r[30].u64 ) };
	// 831DC788: 93410054  stw r26, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[26].u32 ) };
	// 831DC78C: 93610058  stw r27, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[27].u32 ) };
	// 831DC790: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 831DC794: 91410060  stw r10, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 831DC798: 91210064  stw r9, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[9].u32 ) };
	// 831DC79C: 91010068  stw r8, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[8].u32 ) };
	// 831DC7A0: 90E1006C  stw r7, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[7].u32 ) };
	// 831DC7A4: 90C10070  stw r6, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[6].u32 ) };
	// 831DC7A8: 93A10074  stw r29, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[29].u32 ) };
	// 831DC7AC: 4BFE7EC5  bl 0x831c4670
	ctx.lr = 0x831DC7B0;
	sub_831C4670(ctx, base);
	// 831DC7B0: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 831DC7B4: 7D2BF82E  lwzx r9, r11, r31
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 831DC7B8: 391F001C  addi r8, r31, 0x1c
	ctx.r[8].s64 = ctx.r[31].s64 + 28;
	// 831DC7BC: 7D4BFA14  add r10, r11, r31
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831DC7C0: 7FCBF92E  stwx r30, r11, r31
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32), ctx.r[30].u32) };
	// 831DC7C4: 7D2B412E  stwx r9, r11, r8
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), ctx.r[9].u32) };
	// 831DC7C8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831DC7CC: 2F0B001C  cmpwi cr6, r11, 0x1c
	ctx.cr[6].compare_i32(ctx.r[11].s32, 28, &mut ctx.xer);
	// 831DC7D0: 4198FFE4  blt cr6, 0x831dc7b4
	if ctx.cr[6].lt {
	pc = 0x831DC7B4; continue 'dispatch;
	}
	// 831DC7D4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC7D8: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 831DC7DC: 4BFCB9D4  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC7E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC7E0 size=24
    let mut pc: u32 = 0x831DC7E0;
    'dispatch: loop {
        match pc {
            0x831DC7E0 => {
    //   block [0x831DC7E0..0x831DC7F8)
	// 831DC7E0: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 831DC7E4: 39400EA6  li r10, 0xea6
	ctx.r[10].s64 = 3750;
	// 831DC7E8: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831DC7EC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC7F0: B1440002  sth r10, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[10].u16 ) };
	// 831DC7F4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC7F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DC7F8 size=16
    let mut pc: u32 = 0x831DC7F8;
    'dispatch: loop {
        match pc {
            0x831DC7F8 => {
    //   block [0x831DC7F8..0x831DC808)
	// 831DC7F8: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC7FC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DC800: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DC804: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DC808(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DC808 size=528
    let mut pc: u32 = 0x831DC808;
    'dispatch: loop {
        match pc {
            0x831DC808 => {
    //   block [0x831DC808..0x831DCA18)
	// 831DC808: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DC80C: 4BFCB955  bl 0x831a8160
	ctx.lr = 0x831DC810;
	sub_831A8130(ctx, base);
	// 831DC810: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 831DC814: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DC818: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831DC81C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DC820: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 831DC824: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 831DC828: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 831DC82C: 419A0118  beq cr6, 0x831dc944
	if ctx.cr[6].eq {
	pc = 0x831DC944; continue 'dispatch;
	}
	// 831DC830: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 831DC834: 419A0018  beq cr6, 0x831dc84c
	if ctx.cr[6].eq {
	pc = 0x831DC84C; continue 'dispatch;
	}
	// 831DC838: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DC83C: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831DC840: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DC844: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831DC848: 4BFCB968  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831DC84C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831DC850: 4BFE7D81  bl 0x831c45d0
	ctx.lr = 0x831DC854;
	sub_831C45D0(ctx, base);
	// 831DC854: 48066909  bl 0x8324315c
	ctx.lr = 0x831DC858;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC858: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC85C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC860: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DC864: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DC868: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC86C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC870: 419A0010  beq cr6, 0x831dc880
	if ctx.cr[6].eq {
	pc = 0x831DC880; continue 'dispatch;
	}
	// 831DC874: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC878: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC87C: 419A0018  beq cr6, 0x831dc894
	if ctx.cr[6].eq {
	pc = 0x831DC894; continue 'dispatch;
	}
	// 831DC880: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC884: 480661F9  bl 0x83242a7c
	ctx.lr = 0x831DC888;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC888: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC88C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DC890: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DC894: 3D1C0005  addis r8, r28, 5
	ctx.r[8].s64 = ctx.r[28].s64 + 327680;
	// 831DC898: C8010050  lfd f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 831DC89C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DC8A0: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 831DC8A4: 3908BAA0  addi r8, r8, -0x4560
	ctx.r[8].s64 = ctx.r[8].s64 + -17760;
	// 831DC8A8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC8AC: 3D3C0005  addis r9, r28, 5
	ctx.r[9].s64 = ctx.r[28].s64 + 327680;
	// 831DC8B0: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831DC8B4: 3929BAA8  addi r9, r9, -0x4558
	ctx.r[9].s64 = ctx.r[9].s64 + -17752;
	// 831DC8B8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DC8BC: C9680000  lfd f11, 0(r8)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	// 831DC8C0: C8070048  lfd f0, 0x48(r7)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[7].u32.wrapping_add(72 as u32) ) };
	// 831DC8C4: C9890000  lfd f12, 0(r9)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	// 831DC8C8: FD20669C  fcfid f9, f12
	ctx.f[9].f64 = (ctx.f[12].s64 as f64);
	// 831DC8CC: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831DC8D0: FCE90032  fmul f7, f9, f0
	ctx.f[7].f64 = ctx.f[9].f64 * ctx.f[0].f64;
	// 831DC8D4: FD0A6824  fdiv f8, f10, f13
	ctx.f[8].f64 = ctx.f[10].f64 / ctx.f[13].f64;
	// 831DC8D8: FCC83824  fdiv f6, f8, f7
	ctx.f[6].f64 = ctx.f[8].f64 / ctx.f[7].f64;
	// 831DC8DC: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831DC8E0: D0BB0000  stfs f5, 0(r27)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DC8E4: FB480000  std r26, 0(r8)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[26].u64 ) };
	// 831DC8E8: FB490000  std r26, 0(r9)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[26].u64 ) };
	// 831DC8EC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC8F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC8F4: 419A0114  beq cr6, 0x831dca08
	if ctx.cr[6].eq {
	pc = 0x831DCA08; continue 'dispatch;
	}
	// 831DC8F8: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC8FC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DC900: 409A0108  bne cr6, 0x831dca08
	if !ctx.cr[6].eq {
	pc = 0x831DCA08; continue 'dispatch;
	}
	// 831DC904: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC908: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC90C: 408200FC  bne 0x831dca08
	if !ctx.cr[0].eq {
	pc = 0x831DCA08; continue 'dispatch;
	}
	// 831DC910: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 831DC914: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC918: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 831DC91C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC920: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC924: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC928: 48066145  bl 0x83242a6c
	ctx.lr = 0x831DC92C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC92C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DC930: 4806683D  bl 0x8324316c
	ctx.lr = 0x831DC934;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC934: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DC938: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DC93C: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831DC940: 4BFCB870  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831DC944: 48066819  bl 0x8324315c
	ctx.lr = 0x831DC948;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DC948: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DC94C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DC950: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DC954: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DC958: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC95C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC960: 419A0010  beq cr6, 0x831dc970
	if ctx.cr[6].eq {
	pc = 0x831DC970; continue 'dispatch;
	}
	// 831DC964: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DC968: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC96C: 419A0024  beq cr6, 0x831dc990
	if ctx.cr[6].eq {
	pc = 0x831DC990; continue 'dispatch;
	}
	// 831DC970: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC974: 48066109  bl 0x83242a7c
	ctx.lr = 0x831DC978;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DC978: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 831DC97C: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 831DC980: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC984: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC988: 98FF000C  stb r7, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u8 ) };
	// 831DC98C: 48000008  b 0x831dc994
	pc = 0x831DC994; continue 'dispatch;
	// 831DC990: 88FF000C  lbz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DC994: 356B0001  addic. r11, r11, 1
	ctx.xer.ca = (ctx.r[11].u32 > (!(1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC998: 3D208202  lis r9, -0x7dfe
	ctx.r[9].s64 = -2113798144;
	// 831DC99C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC9A0: 7DA86B78  mr r8, r13
	ctx.r[8].u64 = ctx.r[13].u64;
	// 831DC9A4: 80DC0010  lwz r6, 0x10(r28)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DC9A8: C0096218  lfs f0, 0x6218(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(25112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DC9AC: 81260004  lwz r9, 4(r6)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DC9B0: 7CA9E214  add r5, r9, r28
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[28].u64;
	// 831DC9B4: C1A5006C  lfs f13, 0x6c(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(108 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DC9B8: EFED0032  fmuls f31, f13, f0
	ctx.f[31].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DC9BC: 4182003C  beq 0x831dc9f8
	if ctx.cr[0].eq {
	pc = 0x831DC9F8; continue 'dispatch;
	}
	// 831DC9C0: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DC9C4: 409A0034  bne cr6, 0x831dc9f8
	if !ctx.cr[6].eq {
	pc = 0x831DC9F8; continue 'dispatch;
	}
	// 831DC9C8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DC9CC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DC9D0: 40820028  bne 0x831dc9f8
	if !ctx.cr[0].eq {
	pc = 0x831DC9F8; continue 'dispatch;
	}
	// 831DC9D4: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 831DC9D8: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 831DC9DC: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DC9E0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC9E4: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DC9E8: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 831DC9EC: 48066081  bl 0x83242a6c
	ctx.lr = 0x831DC9F0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DC9F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DC9F4: 48066779  bl 0x8324316c
	ctx.lr = 0x831DC9F8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DC9F8: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 831DC9FC: C00B9528  lfs f0, -0x6ad8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27352 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCA00: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DCA04: D01B0000  stfs f0, 0(r27)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCA08: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DCA0C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 831DCA10: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831DCA14: 4BFCB79C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DCA18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DCA18 size=948
    let mut pc: u32 = 0x831DCA18;
    'dispatch: loop {
        match pc {
            0x831DCA18 => {
    //   block [0x831DCA18..0x831DCDCC)
	// 831DCA18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DCA1C: 4BFCB745  bl 0x831a8160
	ctx.lr = 0x831DCA20;
	sub_831A8130(ctx, base);
	// 831DCA20: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 831DCA24: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DCA28: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831DCA2C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DCA30: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 831DCA34: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831DCA38: 4198017C  blt cr6, 0x831dcbb4
	if ctx.cr[6].lt {
	pc = 0x831DCBB4; continue 'dispatch;
	}
	// 831DCA3C: 419A00CC  beq cr6, 0x831dcb08
	if ctx.cr[6].eq {
	pc = 0x831DCB08; continue 'dispatch;
	}
	// 831DCA40: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831DCA44: 4198001C  blt cr6, 0x831dca60
	if ctx.cr[6].lt {
	pc = 0x831DCA60; continue 'dispatch;
	}
	// 831DCA48: 3F408007  lis r26, -0x7ff9
	ctx.r[26].s64 = -2147024896;
	// 831DCA4C: 635A0057  ori r26, r26, 0x57
	ctx.r[26].u64 = ctx.r[26].u64 | 87;
	// 831DCA50: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DCA54: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 831DCA58: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831DCA5C: 4BFCB754  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831DCA60: C3E60000  lfs f31, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DCA64: 480666F9  bl 0x8324315c
	ctx.lr = 0x831DCA68;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCA68: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DCA6C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DCA70: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DCA74: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DCA78: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCA7C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCA80: 419A0010  beq cr6, 0x831dca90
	if ctx.cr[6].eq {
	pc = 0x831DCA90; continue 'dispatch;
	}
	// 831DCA84: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCA88: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCA8C: 419A0018  beq cr6, 0x831dcaa4
	if ctx.cr[6].eq {
	pc = 0x831DCAA4; continue 'dispatch;
	}
	// 831DCA90: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCA94: 48065FE9  bl 0x83242a7c
	ctx.lr = 0x831DCA98;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCA98: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCA9C: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DCAA0: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DCAA4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCAA8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCAAC: 480666B1  bl 0x8324315c
	ctx.lr = 0x831DCAB0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCAB0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCAB4: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DCAB8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DCABC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCAC0: 419A0010  beq cr6, 0x831dcad0
	if ctx.cr[6].eq {
	pc = 0x831DCAD0; continue 'dispatch;
	}
	// 831DCAC4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCAC8: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCACC: 419A0018  beq cr6, 0x831dcae4
	if ctx.cr[6].eq {
	pc = 0x831DCAE4; continue 'dispatch;
	}
	// 831DCAD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCAD4: 48065FA9  bl 0x83242a7c
	ctx.lr = 0x831DCAD8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCAD8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCADC: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DCAE0: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DCAE4: 3D208202  lis r9, -0x7dfe
	ctx.r[9].s64 = -2113798144;
	// 831DCAE8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCAEC: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 831DCAF0: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCAF4: 991C00CC  stb r8, 0xcc(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(204 as u32), ctx.r[8].u8 ) };
	// 831DCAF8: C0096218  lfs f0, 0x6218(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(25112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCAFC: EC1F0032  fmuls f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DCB00: D01C00C8  stfs f0, 0xc8(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 831DCB04: 48000220  b 0x831dcd24
	pc = 0x831DCD24; continue 'dispatch;
	// 831DCB08: 83660000  lwz r27, 0(r6)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DCB0C: 48066651  bl 0x8324315c
	ctx.lr = 0x831DCB10;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCB10: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DCB14: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DCB18: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DCB1C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DCB20: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCB24: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCB28: 419A0010  beq cr6, 0x831dcb38
	if ctx.cr[6].eq {
	pc = 0x831DCB38; continue 'dispatch;
	}
	// 831DCB2C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCB30: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCB34: 419A0018  beq cr6, 0x831dcb4c
	if ctx.cr[6].eq {
	pc = 0x831DCB4C; continue 'dispatch;
	}
	// 831DCB38: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCB3C: 48065F41  bl 0x83242a7c
	ctx.lr = 0x831DCB40;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCB40: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCB44: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DCB48: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DCB4C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCB50: 3BDC0010  addi r30, r28, 0x10
	ctx.r[30].s64 = ctx.r[28].s64 + 16;
	// 831DCB54: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCB58: 48066605  bl 0x8324315c
	ctx.lr = 0x831DCB5C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCB5C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCB60: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DCB64: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831DCB68: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCB6C: 419A0010  beq cr6, 0x831dcb7c
	if ctx.cr[6].eq {
	pc = 0x831DCB7C; continue 'dispatch;
	}
	// 831DCB70: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCB74: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCB78: 419A0018  beq cr6, 0x831dcb90
	if ctx.cr[6].eq {
	pc = 0x831DCB90; continue 'dispatch;
	}
	// 831DCB7C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCB80: 48065EFD  bl 0x83242a7c
	ctx.lr = 0x831DCB84;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCB84: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCB88: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831DCB8C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831DCB90: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCB94: 387E0088  addi r3, r30, 0x88
	ctx.r[3].s64 = ctx.r[30].s64 + 136;
	// 831DCB98: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCB9C: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 831DCBA0: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831DCBA4: 4BFCB96D  bl 0x831a8510
	ctx.lr = 0x831DCBA8;
	sub_831A8510(ctx, base);
	// 831DCBA8: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831DCBAC: 997E00BE  stb r11, 0xbe(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(190 as u32), ctx.r[11].u8 ) };
	// 831DCBB0: 48000174  b 0x831dcd24
	pc = 0x831DCD24; continue 'dispatch;
	// 831DCBB4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831DCBB8: 83E60000  lwz r31, 0(r6)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DCBBC: 48007BED  bl 0x831e47a8
	ctx.lr = 0x831DCBC0;
	sub_831E47A8(ctx, base);
	// 831DCBC0: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DCBC4: 3D608202  lis r11, -0x7dfe
	ctx.r[11].s64 = -2113798144;
	// 831DCBC8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831DCBCC: 91210050  stw r9, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u32 ) };
	// 831DCBD0: 891F0004  lbz r8, 4(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCBD4: C00B6218  lfs f0, 0x6218(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(25112 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCBD8: 91010054  stw r8, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[8].u32 ) };
	// 831DCBDC: C1AA0050  lfs f13, 0x50(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(80 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DCBE0: 88FF0006  lbz r7, 6(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(6 as u32) ) } as u64;
	// 831DCBE4: 90E10058  stw r7, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[7].u32 ) };
	// 831DCBE8: 88DF0007  lbz r6, 7(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(7 as u32) ) } as u64;
	// 831DCBEC: 90C1005C  stw r6, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[6].u32 ) };
	// 831DCBF0: 88BF0008  lbz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCBF4: 90A10060  stw r5, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[5].u32 ) };
	// 831DCBF8: 889F0009  lbz r4, 9(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(9 as u32) ) } as u64;
	// 831DCBFC: 90810064  stw r4, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[4].u32 ) };
	// 831DCC00: 887F000A  lbz r3, 0xa(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(10 as u32) ) } as u64;
	// 831DCC04: 90610068  stw r3, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[3].u32 ) };
	// 831DCC08: 897F000B  lbz r11, 0xb(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(11 as u32) ) } as u64;
	// 831DCC0C: 9161006C  stw r11, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[11].u32 ) };
	// 831DCC10: 895F000C  lbz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DCC14: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831DCC18: 893F000D  lbz r9, 0xd(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 831DCC1C: 91210074  stw r9, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[9].u32 ) };
	// 831DCC20: 891F000E  lbz r8, 0xe(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 831DCC24: 91010078  stw r8, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[8].u32 ) };
	// 831DCC28: 88FF000F  lbz r7, 0xf(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(15 as u32) ) } as u64;
	// 831DCC2C: 90E1007C  stw r7, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[7].u32 ) };
	// 831DCC30: 88DF0005  lbz r6, 5(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(5 as u32) ) } as u64;
	// 831DCC34: 90C10080  stw r6, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[6].u32 ) };
	// 831DCC38: C19F0010  lfs f12, 0x10(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DCC3C: D1810084  stfs f12, 0x84(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 831DCC40: C17F0014  lfs f11, 0x14(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DCC44: D1610088  stfs f11, 0x88(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 831DCC48: C15F0018  lfs f10, 0x18(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DCC4C: D141008C  stfs f10, 0x8c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 831DCC50: C13F001C  lfs f9, 0x1c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DCC54: D1210090  stfs f9, 0x90(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 831DCC58: C11F0020  lfs f8, 0x20(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DCC5C: D1010094  stfs f8, 0x94(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 831DCC60: C0FF0024  lfs f7, 0x24(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DCC64: D0E10098  stfs f7, 0x98(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 831DCC68: C0DF0028  lfs f6, 0x28(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DCC6C: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DCC70: D0A1009C  stfs f5, 0x9c(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 831DCC74: C09F002C  lfs f4, 0x2c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DCC78: EC640372  fmuls f3, f4, f13
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DCC7C: D06100A0  stfs f3, 0xa0(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 831DCC80: 480664DD  bl 0x8324315c
	ctx.lr = 0x831DCC84;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCC84: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DCC88: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831DCC8C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DCC90: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DCC94: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCC98: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCC9C: 419A0010  beq cr6, 0x831dccac
	if ctx.cr[6].eq {
	pc = 0x831DCCAC; continue 'dispatch;
	}
	// 831DCCA0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCCA4: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCCA8: 419A0018  beq cr6, 0x831dccc0
	if ctx.cr[6].eq {
	pc = 0x831DCCC0; continue 'dispatch;
	}
	// 831DCCAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCCB0: 48065DCD  bl 0x83242a7c
	ctx.lr = 0x831DCCB4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCCB4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCCB8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DCCBC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831DCCC0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCCC4: 3BBC0010  addi r29, r28, 0x10
	ctx.r[29].s64 = ctx.r[28].s64 + 16;
	// 831DCCC8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCCCC: 48066491  bl 0x8324315c
	ctx.lr = 0x831DCCD0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DCCD0: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCCD4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DCCD8: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831DCCDC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCCE0: 419A0010  beq cr6, 0x831dccf0
	if ctx.cr[6].eq {
	pc = 0x831DCCF0; continue 'dispatch;
	}
	// 831DCCE4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCCE8: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DCCEC: 419A0018  beq cr6, 0x831dcd04
	if ctx.cr[6].eq {
	pc = 0x831DCD04; continue 'dispatch;
	}
	// 831DCCF0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCCF4: 48065D89  bl 0x83242a7c
	ctx.lr = 0x831DCCF8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DCCF8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCCFC: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831DCD00: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831DCD04: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DCD08: 387D0034  addi r3, r29, 0x34
	ctx.r[3].s64 = ctx.r[29].s64 + 52;
	// 831DCD0C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DCD10: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCD14: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 831DCD18: 4BFCB7F9  bl 0x831a8510
	ctx.lr = 0x831DCD1C;
	sub_831A8510(ctx, base);
	// 831DCD1C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 831DCD20: 997D00BD  stb r11, 0xbd(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(189 as u32), ctx.r[11].u8 ) };
	// 831DCD24: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCD28: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DCD2C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCD30: 419A0044  beq cr6, 0x831dcd74
	if ctx.cr[6].eq {
	pc = 0x831DCD74; continue 'dispatch;
	}
	// 831DCD34: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCD38: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DCD3C: 409A0038  bne cr6, 0x831dcd74
	if !ctx.cr[6].eq {
	pc = 0x831DCD74; continue 'dispatch;
	}
	// 831DCD40: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCD44: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCD48: 4082002C  bne 0x831dcd74
	if !ctx.cr[0].eq {
	pc = 0x831DCD74; continue 'dispatch;
	}
	// 831DCD4C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DCD50: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DCD54: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DCD58: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DCD5C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCD60: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DCD64: 48065D09  bl 0x83242a6c
	ctx.lr = 0x831DCD68;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DCD68: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DCD6C: 48066401  bl 0x8324316c
	ctx.lr = 0x831DCD70;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DCD70: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DCD74: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831DCD78: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCD7C: 419A0040  beq cr6, 0x831dcdbc
	if ctx.cr[6].eq {
	pc = 0x831DCDBC; continue 'dispatch;
	}
	// 831DCD80: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCD84: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DCD88: 409A0034  bne cr6, 0x831dcdbc
	if !ctx.cr[6].eq {
	pc = 0x831DCDBC; continue 'dispatch;
	}
	// 831DCD8C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DCD90: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DCD94: 40820028  bne 0x831dcdbc
	if !ctx.cr[0].eq {
	pc = 0x831DCDBC; continue 'dispatch;
	}
	// 831DCD98: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DCD9C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DCDA0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DCDA4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DCDA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DCDAC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DCDB0: 48065CBD  bl 0x83242a6c
	ctx.lr = 0x831DCDB4;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DCDB4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DCDB8: 480663B5  bl 0x8324316c
	ctx.lr = 0x831DCDBC;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DCDBC: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831DCDC0: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 831DCDC4: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 831DCDC8: 4BFCB3E8  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DCDD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DCDD0 size=1612
    let mut pc: u32 = 0x831DCDD0;
    'dispatch: loop {
        match pc {
            0x831DCDD0 => {
    //   block [0x831DCDD0..0x831DD41C)
	// 831DCDD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DCDD4: 4BFCB365  bl 0x831a8138
	ctx.lr = 0x831DCDD8;
	sub_831A8130(ctx, base);
	// 831DCDD8: DBC1FF68  stfd f30, -0x98(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), ctx.f[30].u64 ) };
	// 831DCDDC: DBE1FF70  stfd f31, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.f[31].u64 ) };
	// 831DCDE0: 8103000C  lwz r8, 0xc(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DCDE4: C0030014  lfs f0, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCDE8: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCDEC: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCDF0: 3AA30014  addi r21, r3, 0x14
	ctx.r[21].s64 = ctx.r[3].s64 + 20;
	// 831DCDF4: 7F284850  subf r25, r8, r9
	ctx.r[25].s64 = ctx.r[9].s64 - ctx.r[8].s64;
	// 831DCDF8: 2B190004  cmplwi cr6, r25, 4
	ctx.cr[6].compare_u32(ctx.r[25].u32, 4 as u32, &mut ctx.xer);
	// 831DCDFC: 41990014  bgt cr6, 0x831dce10
	if ctx.cr[6].gt {
	pc = 0x831DCE10; continue 'dispatch;
	}
	// 831DCE00: 7D694050  subf r11, r9, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 831DCE04: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831DCE08: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831DCE0C: 40990008  ble cr6, 0x831dce14
	if !ctx.cr[6].gt {
	pc = 0x831DCE14; continue 'dispatch;
	}
	// 831DCE10: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 831DCE14: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 831DCE18: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DCE1C: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DCE20: 3AE30004  addi r23, r3, 4
	ctx.r[23].s64 = ctx.r[3].s64 + 4;
	// 831DCE24: 3AC30018  addi r22, r3, 0x18
	ctx.r[22].s64 = ctx.r[3].s64 + 24;
	// 831DCE28: C00B9A8C  lfs f0, -0x6574(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-25972 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCE2C: EC0C0032  fmuls f0, f12, f0
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DCE30: FDA0065E  fctidz f13, f0
	ctx.f[13].s64 = if ctx.f[0].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[0].f64.trunc() as i64 };
	// 831DCE34: D9A1FF60  stfd f13, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[13].u64 ) };
	// 831DCE38: 80E1FF64  lwz r7, -0x9c(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-156 as u32) ) } as u64;
	// 831DCE3C: 54E7F87E  srwi r7, r7, 1
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shr(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DCE40: 2B070100  cmplwi cr6, r7, 0x100
	ctx.cr[6].compare_u32(ctx.r[7].u32, 256 as u32, &mut ctx.xer);
	// 831DCE44: 409803E8  bge cr6, 0x831dd22c
	if !ctx.cr[6].lt {
	pc = 0x831DD22C; continue 'dispatch;
	}
	// 831DCE48: 3CC08200  lis r6, -0x7e00
	ctx.r[6].s64 = -2113929216;
	// 831DCE4C: 3FE08212  lis r31, -0x7dee
	ctx.r[31].s64 = -2112749568;
	// 831DCE50: 39630020  addi r11, r3, 0x20
	ctx.r[11].s64 = ctx.r[3].s64 + 32;
	// 831DCE54: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 831DCE58: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 831DCE5C: C16608A8  lfs f11, 0x8a8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(2216 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DCE60: C01FDFA8  lfs f0, -0x2058(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-8280 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DCE64: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DCE68: 41980124  blt cr6, 0x831dcf8c
	if ctx.cr[6].lt {
	pc = 0x831DCF8C; continue 'dispatch;
	}
	// 831DCE6C: 38CA0002  addi r6, r10, 2
	ctx.r[6].s64 = ctx.r[10].s64 + 2;
	// 831DCE70: 7FA95050  subf r29, r9, r10
	ctx.r[29].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831DCE74: 7D285050  subf r9, r8, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831DCE78: 54FB003A  rlwinm r27, r7, 0, 0, 0x1d
	ctx.r[27].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DCE7C: 54C8103A  slwi r8, r6, 2
	ctx.r[8].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DCE80: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 831DCE84: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 831DCE88: 3BFD0002  addi r31, r29, 2
	ctx.r[31].s64 = ctx.r[29].s64 + 2;
	// 831DCE8C: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831DCE90: 3BC40008  addi r30, r4, 8
	ctx.r[30].s64 = ctx.r[4].s64 + 8;
	// 831DCE94: 3925000C  addi r9, r5, 0xc
	ctx.r[9].s64 = ctx.r[5].s64 + 12;
	// 831DCE98: 7F452050  subf r26, r5, r4
	ctx.r[26].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831DCE9C: 54FCF0BE  srwi r28, r7, 2
	ctx.r[28].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831DCEA0: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 831DCEA4: ED4C0028  fsubs f10, f12, f0
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DCEA8: 7F1DCA14  add r24, r29, r25
	ctx.r[24].u64 = ctx.r[29].u64 + ctx.r[25].u64;
	// 831DCEAC: ED2D002A  fadds f9, f13, f0
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DCEB0: 3A86FFFF  addi r20, r6, -1
	ctx.r[20].s64 = ctx.r[6].s64 + -1;
	// 831DCEB4: 57B2143A  rlwinm r18, r29, 2, 0x10, 0x1d
	ctx.r[18].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEB8: C11EFFF8  lfs f8, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DCEBC: 5718143A  rlwinm r24, r24, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[24].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEC0: C0FEFFFC  lfs f7, -4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DCEC4: 5694143A  rlwinm r20, r20, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEC8: C0DE0000  lfs f6, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DCECC: 3A7FFFFF  addi r19, r31, -1
	ctx.r[19].s64 = ctx.r[31].s64 + -1;
	// 831DCED0: 7CBA4C2E  lfsx f5, r26, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DCED4: 3A260001  addi r17, r6, 1
	ctx.r[17].s64 = ctx.r[6].s64 + 1;
	// 831DCED8: 7C925C2E  lfsx f4, r18, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[18].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DCEDC: 5673143A  rlwinm r19, r19, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEE0: 7C785C2E  lfsx f3, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DCEE4: 54D0143A  rlwinm r16, r6, 2, 0x10, 0x1d
	ctx.r[16].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEE8: D108FFF8  stfs f8, -8(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DCEEC: 57F2143A  rlwinm r18, r31, 2, 0x10, 0x1d
	ctx.r[18].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCEF0: EC4A0028  fsubs f2, f10, f0
	ctx.f[2].f64 = (((ctx.f[10].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DCEF4: 7D145C2E  lfsx f8, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DCEF8: ED4802B2  fmuls f10, f8, f10
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 831DCEFC: 5638143A  rlwinm r24, r17, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[17].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCF00: ED020028  fsubs f8, f2, f0
	ctx.f[8].f64 = (((ctx.f[2].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DCF04: 3A9F0001  addi r20, r31, 1
	ctx.r[20].s64 = ctx.r[31].s64 + 1;
	// 831DCF08: EC29002A  fadds f1, f9, f0
	ctx.f[1].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DCF0C: 379CFFFF  addic. r28, r28, -1
	ctx.xer.ca = (ctx.r[28].u32 > (!(-1 as u32)));
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831DCF10: EC840372  fmuls f4, f4, f13
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DCF14: 7DB35C2E  lfsx f13, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DCF18: D0E8FFFC  stfs f7, -4(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DCF1C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DCF20: 7CF05C2E  lfsx f7, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DCF24: EC4700B2  fmuls f2, f7, f2
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831DCF28: 7FD25C2E  lfsx f30, r18, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[18].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DCF2C: EFE1002A  fadds f31, f1, f0
	ctx.f[31].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DCF30: D0C80000  stfs f6, 0(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCF34: EC83233A  fmadds f4, f3, f12, f4
	ctx.f[4].f64 = (((ctx.f[3].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DCF38: 7CF85C2E  lfsx f7, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DCF3C: ECC70232  fmuls f6, f7, f8
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 831DCF40: 5698143A  rlwinm r24, r20, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCF44: EC5E107A  fmadds f2, f30, f1, f2
	ctx.f[2].f64 = (((ctx.f[30].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DCF48: EC6D527A  fmadds f3, f13, f9, f10
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DCF4C: D089FFF8  stfs f4, -8(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DCF50: D069FFFC  stfs f3, -4(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DCF54: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 831DCF58: D0490000  stfs f2, 0(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCF5C: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DCF60: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 831DCF64: ED880028  fsubs f12, f8, f0
	ctx.f[12].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DCF68: 7C385C2E  lfsx f1, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DCF6C: EDA137FA  fmadds f13, f1, f31, f6
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DCF70: D1A90004  stfs f13, 4(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DCF74: EDBF002A  fadds f13, f31, f0
	ctx.f[13].f64 = ((ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DCF78: D0A80004  stfs f5, 4(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DCF7C: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 831DCF80: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 831DCF84: 4082FF20  bne 0x831dcea4
	if !ctx.cr[0].eq {
	pc = 0x831DCEA4; continue 'dispatch;
	}
	// 831DCF88: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCF8C: 7F1B3840  cmplw cr6, r27, r7
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831DCF90: 41990088  bgt cr6, 0x831dd018
	if ctx.cr[6].gt {
	pc = 0x831DD018; continue 'dispatch;
	}
	// 831DCF94: 5766103A  slwi r6, r27, 2
	ctx.r[6].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DCF98: 83830008  lwz r28, 8(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DCF9C: 7D3B3850  subf r9, r27, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[27].s64;
	// 831DCFA0: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DCFA4: 7FA62214  add r29, r6, r4
	ctx.r[29].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 831DCFA8: C1970000  lfs f12, 0(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DCFAC: 555F103A  slwi r31, r10, 2
	ctx.r[31].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 831DCFB0: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DCFB4: 7FC62A14  add r30, r6, r5
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 831DCFB8: 7D1C5050  subf r8, r28, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[28].s64;
	// 831DCFBC: 38DDFFFC  addi r6, r29, -4
	ctx.r[6].s64 = ctx.r[29].s64 + -4;
	// 831DCFC0: 7FFF5A14  add r31, r31, r11
	ctx.r[31].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DCFC4: 7FBBE050  subf r29, r27, r28
	ctx.r[29].s64 = ctx.r[28].s64 - ctx.r[27].s64;
	// 831DCFC8: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DCFCC: 551C143A  rlwinm r28, r8, 2, 0x10, 0x1d
	ctx.r[28].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCFD0: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DCFD4: 7F7D4214  add r27, r29, r8
	ctx.r[27].u64 = ctx.r[29].u64 + ctx.r[8].u64;
	// 831DCFD8: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DCFDC: 577B143A  rlwinm r27, r27, 2, 0x10, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 831DCFE0: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831DCFE4: 7D3C5C2E  lfsx f9, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DCFE8: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DCFEC: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DCFF0: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DCFF4: 7CFB5C2E  lfsx f7, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DCFF8: D15F0000  stfs f10, 0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DCFFC: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DD000: ECC7433A  fmadds f6, f7, f12, f8
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DD004: D0DE0000  stfs f6, 0(r30)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD008: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD00C: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 831DD010: 4082FFBC  bne 0x831dcfcc
	if !ctx.cr[0].eq {
	pc = 0x831DCFCC; continue 'dispatch;
	}
	// 831DD014: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD018: 83430010  lwz r26, 0x10(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DD01C: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DD020: 7F1A4840  cmplw cr6, r26, r9
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DD024: 419A000C  beq cr6, 0x831dd030
	if ctx.cr[6].eq {
	pc = 0x831DD030; continue 'dispatch;
	}
	// 831DD028: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 831DD02C: 4800000C  b 0x831dd038
	pc = 0x831DD038; continue 'dispatch;
	// 831DD030: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 831DD034: C18808A4  lfs f12, 0x8a4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD038: 21070100  subfic r8, r7, 0x100
	ctx.xer.ca = ctx.r[7].u32 <= 256 as u32;
	ctx.r[8].s64 = (256 as i64) - ctx.r[7].s64;
	// 831DD03C: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD040: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DD044: 9123000C  stw r9, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 831DD048: 93430008  stw r26, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[26].u32 ) };
	// 831DD04C: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 831DD050: 2F080004  cmpwi cr6, r8, 4
	ctx.cr[6].compare_i32(ctx.r[8].s32, 4, &mut ctx.xer);
	// 831DD054: 41980144  blt cr6, 0x831dd198
	if ctx.cr[6].lt {
	pc = 0x831DD198; continue 'dispatch;
	}
	// 831DD058: 212700FC  subfic r9, r7, 0xfc
	ctx.xer.ca = ctx.r[7].u32 <= 252 as u32;
	ctx.r[9].s64 = (252 as i64) - ctx.r[7].s64;
	// 831DD05C: 8283000C  lwz r20, 0xc(r3)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DD060: 39070003  addi r8, r7, 3
	ctx.r[8].s64 = ctx.r[7].s64 + 3;
	// 831DD064: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DD068: 38CA0002  addi r6, r10, 2
	ctx.r[6].s64 = ctx.r[10].s64 + 2;
	// 831DD06C: 3BA90001  addi r29, r9, 1
	ctx.r[29].s64 = ctx.r[9].s64 + 1;
	// 831DD070: 3BE70002  addi r31, r7, 2
	ctx.r[31].s64 = ctx.r[7].s64 + 2;
	// 831DD074: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DD078: 7D345050  subf r9, r20, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[20].s64;
	// 831DD07C: 54D9103A  slwi r25, r6, 2
	ctx.r[25].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[25].u64 = ctx.r[25].u32 as u64;
	// 831DD080: 57BB103A  slwi r27, r29, 2
	ctx.r[27].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831DD084: 7F9A5050  subf r28, r26, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[26].s64;
	// 831DD088: 57F8103A  slwi r24, r31, 2
	ctx.r[24].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 831DD08C: 7FC82214  add r30, r8, r4
	ctx.r[30].u64 = ctx.r[8].u64 + ctx.r[4].u64;
	// 831DD090: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 831DD094: 7D195A14  add r8, r25, r11
	ctx.r[8].u64 = ctx.r[25].u64 + ctx.r[11].u64;
	// 831DD098: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 831DD09C: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 831DD0A0: 7D382A14  add r9, r24, r5
	ctx.r[9].u64 = ctx.r[24].u64 + ctx.r[5].u64;
	// 831DD0A4: 7F252050  subf r25, r5, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831DD0A8: 7F54D050  subf r26, r20, r26
	ctx.r[26].s64 = ctx.r[26].s64 - ctx.r[20].s64;
	// 831DD0AC: 7F7B3A14  add r27, r27, r7
	ctx.r[27].u64 = ctx.r[27].u64 + ctx.r[7].u64;
	// 831DD0B0: 7CFAE214  add r7, r26, r28
	ctx.r[7].u64 = ctx.r[26].u64 + ctx.r[28].u64;
	// 831DD0B4: C15EFFF4  lfs f10, -0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD0B8: 3B1FFFFF  addi r24, r31, -1
	ctx.r[24].s64 = ctx.r[31].s64 + -1;
	// 831DD0BC: C13EFFF8  lfs f9, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD0C0: 3A86FFFF  addi r20, r6, -1
	ctx.r[20].s64 = ctx.r[6].s64 + -1;
	// 831DD0C4: ED6D002A  fadds f11, f13, f0
	ctx.f[11].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DD0C8: 54E7143A  rlwinm r7, r7, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0CC: ED0C0028  fsubs f8, f12, f0
	ctx.f[8].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD0D0: 5793143A  rlwinm r19, r28, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0D4: 7CE9CC2E  lfsx f7, r9, r25
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[25].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD0D8: 5694143A  rlwinm r20, r20, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0DC: C0DE0000  lfs f6, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD0E0: 5718143A  rlwinm r24, r24, 2, 0x10, 0x1d
	ctx.r[24].u64 = ctx.r[24].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0E4: 3A5F0001  addi r18, r31, 1
	ctx.r[18].s64 = ctx.r[31].s64 + 1;
	// 831DD0E8: 7C875C2E  lfsx f4, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DD0EC: 54C7143A  rlwinm r7, r6, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0F0: 7CB35C2E  lfsx f5, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DD0F4: 57F3143A  rlwinm r19, r31, 2, 0x10, 0x1d
	ctx.r[19].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD0F8: D148FFF8  stfs f10, -8(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DD0FC: EDA50372  fmuls f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DD100: 7C545C2E  lfsx f2, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DD104: 5654143A  rlwinm r20, r18, 2, 0x10, 0x1d
	ctx.r[20].u64 = ctx.r[18].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD108: 7C385C2E  lfsx f1, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DD10C: EC6B002A  fadds f3, f11, f0
	ctx.f[3].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DD110: D128FFFC  stfs f9, -4(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DD114: ED480028  fsubs f10, f8, f0
	ctx.f[10].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD118: 7FE75C2E  lfsx f31, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DD11C: ED23002A  fadds f9, f3, f0
	ctx.f[9].f64 = ((ctx.f[3].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DD120: 7CB35C2E  lfsx f5, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DD124: EC2102F2  fmuls f1, f1, f11
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DD128: D0E80000  stfs f7, 0(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD12C: ECE500F2  fmuls f7, f5, f3
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[3].f64) as f32) as f64);
	// 831DD130: 7D745C2E  lfsx f11, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD134: EFCA0028  fsubs f30, f10, f0
	ctx.f[30].f64 = (((ctx.f[10].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD138: ECAB0272  fmuls f5, f11, f9
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[9].f64) as f32) as f64);
	// 831DD13C: 38E60001  addi r7, r6, 1
	ctx.r[7].s64 = ctx.r[6].s64 + 1;
	// 831DD140: 54E7143A  rlwinm r7, r7, 2, 0x10, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD144: EC620A3A  fmadds f3, f2, f8, f1
	ctx.f[3].f64 = (((ctx.f[2].f64 * ctx.f[8].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DD148: EC846B3A  fmadds f4, f4, f12, f13
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 831DD14C: D089FFFC  stfs f4, -4(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DD150: EC5F3ABA  fmadds f2, f31, f10, f7
	ctx.f[2].f64 = (((ctx.f[31].f64 * ctx.f[10].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DD154: D0690000  stfs f3, 0(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD158: D0490004  stfs f2, 4(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD15C: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831DD160: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DD164: ED9E0028  fsubs f12, f30, f0
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD168: 7C275C2E  lfsx f1, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DD16C: EDA12FBA  fmadds f13, f1, f30, f5
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[30].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DD170: D1A90008  stfs f13, 8(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD174: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 831DD178: D0C80004  stfs f6, 4(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD17C: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DD180: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 831DD184: EDA9002A  fadds f13, f9, f0
	ctx.f[13].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DD188: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 831DD18C: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 831DD190: 4082FF20  bne 0x831dd0b0
	if !ctx.cr[0].eq {
	pc = 0x831DD0B0; continue 'dispatch;
	}
	// 831DD194: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD198: 2B1B0100  cmplwi cr6, r27, 0x100
	ctx.cr[6].compare_u32(ctx.r[27].u32, 256 as u32, &mut ctx.xer);
	// 831DD19C: 40980084  bge cr6, 0x831dd220
	if !ctx.cr[6].lt {
	pc = 0x831DD220; continue 'dispatch;
	}
	// 831DD1A0: 5767103A  slwi r7, r27, 2
	ctx.r[7].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DD1A4: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DD1A8: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DD1AC: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DD1B0: 7C672A14  add r3, r7, r5
	ctx.r[3].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 831DD1B4: C1970000  lfs f12, 0(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD1B8: 213B0100  subfic r9, r27, 0x100
	ctx.xer.ca = ctx.r[27].u32 <= 256 as u32;
	ctx.r[9].s64 = (256 as i64) - ctx.r[27].s64;
	// 831DD1BC: 7CE72214  add r7, r7, r4
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[4].u64;
	// 831DD1C0: 7D1F5050  subf r8, r31, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DD1C4: 38830004  addi r4, r3, 4
	ctx.r[4].s64 = ctx.r[3].s64 + 4;
	// 831DD1C8: 7CC65A14  add r6, r6, r11
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 831DD1CC: 7C7EF850  subf r3, r30, r31
	ctx.r[3].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 831DD1D0: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DD1D4: 551F143A  rlwinm r31, r8, 2, 0x10, 0x1d
	ctx.r[31].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD1D8: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD1DC: 7FC34214  add r30, r3, r8
	ctx.r[30].u64 = ctx.r[3].u64 + ctx.r[8].u64;
	// 831DD1E0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DD1E4: 57DE143A  rlwinm r30, r30, 2, 0x10, 0x1d
	ctx.r[30].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD1E8: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831DD1EC: 7D5F5C2E  lfsx f10, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD1F0: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831DD1F4: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DD1F8: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DD1FC: 7D1E5C2E  lfsx f8, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD200: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD204: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DD208: ECE84B3A  fmadds f7, f8, f12, f9
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD20C: D0E40000  stfs f7, 0(r4)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD210: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD214: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DD218: 4082FFBC  bne 0x831dd1d4
	if !ctx.cr[0].eq {
	pc = 0x831DD1D4; continue 'dispatch;
	}
	// 831DD21C: D1970000  stfs f12, 0(r23)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD220: 554B04BE  clrlwi r11, r10, 0x12
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x00003FFFu64;
	// 831DD224: 91760000  stw r11, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DD228: 480001D8  b 0x831dd400
	pc = 0x831DD400; continue 'dispatch;
	// 831DD22C: 3BEA0100  addi r31, r10, 0x100
	ctx.r[31].s64 = ctx.r[10].s64 + 256;
	// 831DD230: 2B1F4000  cmplwi cr6, r31, 0x4000
	ctx.cr[6].compare_u32(ctx.r[31].u32, 16384 as u32, &mut ctx.xer);
	// 831DD234: 4098014C  bge cr6, 0x831dd380
	if !ctx.cr[6].lt {
	pc = 0x831DD380; continue 'dispatch;
	}
	// 831DD238: 7CE85050  subf r7, r8, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	// 831DD23C: 39670100  addi r11, r7, 0x100
	ctx.r[11].s64 = ctx.r[7].s64 + 256;
	// 831DD240: 2B0B4000  cmplwi cr6, r11, 0x4000
	ctx.cr[6].compare_u32(ctx.r[11].u32, 16384 as u32, &mut ctx.xer);
	// 831DD244: 4098013C  bge cr6, 0x831dd380
	if !ctx.cr[6].lt {
	pc = 0x831DD380; continue 'dispatch;
	}
	// 831DD248: 7D695050  subf r11, r9, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 831DD24C: 3BCB0100  addi r30, r11, 0x100
	ctx.r[30].s64 = ctx.r[11].s64 + 256;
	// 831DD250: 2B1E4000  cmplwi cr6, r30, 0x4000
	ctx.cr[6].compare_u32(ctx.r[30].u32, 16384 as u32, &mut ctx.xer);
	// 831DD254: 4098012C  bge cr6, 0x831dd380
	if !ctx.cr[6].lt {
	pc = 0x831DD380; continue 'dispatch;
	}
	// 831DD258: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831DD25C: 41980124  blt cr6, 0x831dd380
	if ctx.cr[6].lt {
	pc = 0x831DD380; continue 'dispatch;
	}
	// 831DD260: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DD264: 4198011C  blt cr6, 0x831dd380
	if ctx.cr[6].lt {
	pc = 0x831DD380; continue 'dispatch;
	}
	// 831DD268: 396A0008  addi r11, r10, 8
	ctx.r[11].s64 = ctx.r[10].s64 + 8;
	// 831DD26C: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831DD270: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DD274: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 831DD278: 409A0080  bne cr6, 0x831dd2f8
	if !ctx.cr[6].eq {
	pc = 0x831DD2F8; continue 'dispatch;
	}
	// 831DD27C: 550A103A  slwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DD280: 39250004  addi r9, r5, 4
	ctx.r[9].s64 = ctx.r[5].s64 + 4;
	// 831DD284: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831DD288: 38E00041  li r7, 0x41
	ctx.r[7].s64 = 65;
	// 831DD28C: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 831DD290: 13E02407  vcmpneb. (lvlx128) v31, v0, v4
	tmp.u32 = ctx.r[4].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DD294: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 831DD298: 13C82447  vcmpneh. (lvrx128) v30, v8, v4
	tmp.u32 = ctx.r[8].u32 + ctx.r[4].u32;
	// load reversed into ctx.v[62] using VectorMaskR (or zero if (tmp.u32 & 0xF) == 0)
	// 831DD29C: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 831DD2A0: 13A05407  vcmpneb. (lvlx128) v29, v0, v10
	tmp.u32 = ctx.r[10].u32;
	// load shuffled into ctx.v[61] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DD420(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DD420 size=272
    let mut pc: u32 = 0x831DD420;
    'dispatch: loop {
        match pc {
            0x831DD420 => {
    //   block [0x831DD420..0x831DD530)
	// 831DD420: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 831DD424: C1230014  lfs f9, 0x14(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD428: C1830010  lfs f12, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD42C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 831DD430: D1250000  stfs f9, 0(r5)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD434: 2F060004  cmpwi cr6, r6, 4
	ctx.cr[6].compare_i32(ctx.r[6].s32, 4, &mut ctx.xer);
	// 831DD438: 39650004  addi r11, r5, 4
	ctx.r[11].s64 = ctx.r[5].s64 + 4;
	// 831DD43C: C10A08A8  lfs f8, 0x8a8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2216 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD440: 4198009C  blt cr6, 0x831dd4dc
	if ctx.cr[6].lt {
	pc = 0x831DD4DC; continue 'dispatch;
	}
	// 831DD444: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD448: 54C9003A  rlwinm r9, r6, 0, 0, 0x1d
	ctx.r[9].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 831DD44C: ED680028  fsubs f11, f8, f0
	ctx.f[11].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD450: C1430018  lfs f10, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD454: 54CAF0BE  srwi r10, r6, 2
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DD458: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DD45C: EDAA02F2  fmuls f13, f10, f11
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DD460: C0E40000  lfs f7, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD464: ED200272  fmuls f9, f0, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 831DD468: ECC70372  fmuls f6, f7, f13
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DD46C: C0A40004  lfs f5, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DD470: EC8502B2  fmuls f4, f5, f10
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[10].f64) as f32) as f64);
	// 831DD474: C0640008  lfs f3, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DD478: C024000C  lfs f1, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DD47C: EC4302B2  fmuls f2, f3, f10
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[10].f64) as f32) as f64);
	// 831DD480: ECE102B2  fmuls f7, f1, f10
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[10].f64) as f32) as f64);
	// 831DD484: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831DD488: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 831DD48C: ECAD4B3A  fmadds f5, f13, f12, f9
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD490: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD494: ED80333A  fmadds f12, f0, f12, f6
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD498: EC600172  fmuls f3, f0, f5
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DD49C: EC200332  fmuls f1, f0, f12
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD4A0: ED2D1B3A  fmadds f9, f13, f12, f3
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DD4A4: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD4A8: ED840AFA  fmadds f12, f4, f11, f1
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DD4AC: ECC00272  fmuls f6, f0, f9
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 831DD4B0: ECA00332  fmuls f5, f0, f12
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD4B4: EC8D333A  fmadds f4, f13, f12, f6
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD4B8: D08B0008  stfs f4, 8(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD4BC: ED822AFA  fmadds f12, f2, f11, f5
	ctx.f[12].f64 = (((ctx.f[2].f64 * ctx.f[11].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DD4C0: EC600132  fmuls f3, f0, f4
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64) as f32) as f64);
	// 831DD4C4: EC400332  fmuls f2, f0, f12
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD4C8: ED2D1B3A  fmadds f9, f13, f12, f3
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DD4CC: D12B000C  stfs f9, 0xc(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DD4D0: ED8712FA  fmadds f12, f7, f11, f2
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DD4D4: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 831DD4D8: 4082FF88  bne 0x831dd460
	if !ctx.cr[0].eq {
	pc = 0x831DD460; continue 'dispatch;
	}
	// 831DD4DC: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831DD4E0: 41990044  bgt cr6, 0x831dd524
	if ctx.cr[6].gt {
	pc = 0x831DD524; continue 'dispatch;
	}
	// 831DD4E4: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD4E8: 7D493050  subf r10, r9, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[9].s64;
	// 831DD4EC: EDA80028  fsubs f13, f8, f0
	ctx.f[13].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DD4F0: C1630018  lfs f11, 0x18(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD4F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831DD4F8: EDAD02F2  fmuls f13, f13, f11
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DD4FC: ED600272  fmuls f11, f0, f9
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 831DD500: C1040000  lfs f8, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD504: ED400332  fmuls f10, f0, f12
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD508: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831DD50C: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DD510: ED2D5B3A  fmadds f9, f13, f12, f11
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DD514: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD518: ED8D523A  fmadds f12, f13, f8, f10
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DD51C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831DD520: 4082FFDC  bne 0x831dd4fc
	if !ctx.cr[0].eq {
	pc = 0x831DD4FC; continue 'dispatch;
	}
	// 831DD524: D1230014  stfs f9, 0x14(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DD528: D1830010  stfs f12, 0x10(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DD52C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DD530(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DD530 size=200
    let mut pc: u32 = 0x831DD530;
    'dispatch: loop {
        match pc {
            0x831DD530 => {
    //   block [0x831DD530..0x831DD5F8)
	// 831DD530: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DD534: 4BFCAC31  bl 0x831a8164
	ctx.lr = 0x831DD538;
	sub_831A8130(ctx, base);
	// 831DD538: 80E30024  lwz r7, 0x24(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DD53C: 3943002C  addi r10, r3, 0x2c
	ctx.r[10].s64 = ctx.r[3].s64 + 44;
	// 831DD540: 83C30000  lwz r30, 0(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DD544: C1630008  lfs f11, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD548: 83E3000C  lwz r31, 0xc(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DD54C: 54E9103A  slwi r9, r7, 2
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DD550: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DD554: C1430020  lfs f10, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD558: 7D7E3850  subf r11, r30, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[30].s64;
	// 831DD55C: C0030010  lfs f0, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD560: 7D095214  add r8, r9, r10
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DD564: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DD568: 7FFFF050  subf r31, r31, r30
	ctx.r[31].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 831DD56C: C183001C  lfs f12, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD570: D1650000  stfs f11, 0(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD574: 7FDDF050  subf r30, r29, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[29].s64;
	// 831DD578: D1460000  stfs f10, 0(r6)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD57C: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 831DD580: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DD584: 557D157A  rlwinm r29, r11, 2, 0x15, 0x1d
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD588: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD58C: 7F9F5A14  add r28, r31, r11
	ctx.r[28].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DD590: 7F7E5A14  add r27, r30, r11
	ctx.r[27].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 831DD594: 579C157A  rlwinm r28, r28, 2, 0x15, 0x1d
	ctx.r[28].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD598: 577B157A  rlwinm r27, r27, 2, 0x15, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD59C: 7D5D542E  lfsx f10, r29, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD5A0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 831DD5A4: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DD5A8: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DD5AC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DD5B0: 7D1C542E  lfsx f8, r28, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD5B4: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DD5B8: 7CFB542E  lfsx f7, r27, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD5BC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DD5C0: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD5C4: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD5C8: D0C60000  stfs f6, 0(r6)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD5CC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831DD5D0: ECA8483A  fmadds f5, f8, f0, f9
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD5D4: D0A50000  stfs f5, 0(r5)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD5D8: 4082FFAC  bne 0x831dd584
	if !ctx.cr[0].eq {
	pc = 0x831DD584; continue 'dispatch;
	}
	// 831DD5DC: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 831DD5E0: FC002890  fmr f0, f5
	ctx.f[0].f64 = ctx.f[5].f64;
	// 831DD5E4: FDA03090  fmr f13, f6
	ctx.f[13].f64 = ctx.f[6].f64;
	// 831DD5E8: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD5EC: D1A30020  stfs f13, 0x20(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831DD5F0: 91630024  stw r11, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 831DD5F4: 4BFCABC0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DD5F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DD5F8 size=680
    let mut pc: u32 = 0x831DD5F8;
    'dispatch: loop {
        match pc {
            0x831DD5F8 => {
    //   block [0x831DD5F8..0x831DD8A0)
	// 831DD5F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DD5FC: 4BFCAB51  bl 0x831a814c
	ctx.lr = 0x831DD600;
	sub_831A8130(ctx, base);
	// 831DD600: 3981FFA0  addi r12, r1, -0x60
	ctx.r[12].s64 = ctx.r[1].s64 + -96;
	// 831DD604: 4BFCB471  bl 0x831a8a74
	ctx.lr = 0x831DD608;
	sub_831A8A40(ctx, base);
	// 831DD608: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DD60C: 39630018  addi r11, r3, 0x18
	ctx.r[11].s64 = ctx.r[3].s64 + 24;
	// 831DD610: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DD614: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD618: 392A0002  addi r9, r10, 2
	ctx.r[9].s64 = ctx.r[10].s64 + 2;
	// 831DD61C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DD620: 7D465050  subf r10, r6, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[6].s64;
	// 831DD624: C183000C  lfs f12, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD628: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DD62C: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 831DD630: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 831DD634: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831DD638: 38EAFFFE  addi r7, r10, -2
	ctx.r[7].s64 = ctx.r[10].s64 + -2;
	// 831DD63C: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD640: 38AAFFFF  addi r5, r10, -1
	ctx.r[5].s64 = ctx.r[10].s64 + -1;
	// 831DD644: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD648: 54E715FA  rlwinm r7, r7, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD64C: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD650: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD654: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD658: 555F15FA  rlwinm r31, r10, 2, 0x17, 0x1d
	ctx.r[31].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD65C: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD660: 3BCA0001  addi r30, r10, 1
	ctx.r[30].s64 = ctx.r[10].s64 + 1;
	// 831DD664: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD668: 3BAA0002  addi r29, r10, 2
	ctx.r[29].s64 = ctx.r[10].s64 + 2;
	// 831DD66C: C0A40018  lfs f5, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DD670: 7C875C2E  lfsx f4, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DD674: 57C715FA  rlwinm r7, r30, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD678: EC60593A  fmadds f3, f0, f4, f11
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DD67C: D069FFF8  stfs f3, -8(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DD680: 7C455C2E  lfsx f2, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DD684: EC2050BA  fmadds f1, f0, f2, f10
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DD688: D029FFFC  stfs f1, -4(r9)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DD68C: 38AA0003  addi r5, r10, 3
	ctx.r[5].s64 = ctx.r[10].s64 + 3;
	// 831DD690: 7D7F5C2E  lfsx f11, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD694: 57BF15FA  rlwinm r31, r29, 2, 0x17, 0x1d
	ctx.r[31].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD698: ED404AFA  fmadds f10, f0, f11, f9
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[11].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD69C: D1490000  stfs f10, 0(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD6A0: 7D275C2E  lfsx f9, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD6A4: 54A515FA  rlwinm r5, r5, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD6A8: ED00427A  fmadds f8, f0, f9, f8
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DD6AC: 38EA0004  addi r7, r10, 4
	ctx.r[7].s64 = ctx.r[10].s64 + 4;
	// 831DD6B0: D1090004  stfs f8, 4(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD6B4: 3BCA0005  addi r30, r10, 5
	ctx.r[30].s64 = ctx.r[10].s64 + 5;
	// 831DD6B8: 7FFF5C2E  lfsx f31, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DD6BC: 54E715FA  rlwinm r7, r7, 2, 0x17, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD6C0: ECE03FFA  fmadds f7, f0, f31, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DD6C4: D0E90008  stfs f7, 8(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD6C8: 7FC55C2E  lfsx f30, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DD6CC: 57C515FA  rlwinm r5, r30, 2, 0x17, 0x1d
	ctx.r[5].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD6D0: ECC037BA  fmadds f6, f0, f30, f6
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[30].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD6D4: D0C9000C  stfs f6, 0xc(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DD6D8: 7FA75C2E  lfsx f29, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DD6DC: ECA02F7A  fmadds f5, f0, f29, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[29].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DD6E0: C384001C  lfs f28, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DD6E4: 38E4001C  addi r7, r4, 0x1c
	ctx.r[7].s64 = ctx.r[4].s64 + 28;
	// 831DD6E8: D0A90010  stfs f5, 0x10(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DD6EC: EC8D20FA  fmadds f4, f13, f3, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DD6F0: 7F655C2E  lfsx f27, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831DD6F4: EF80E6FA  fmadds f28, f0, f27, f28
	ctx.f[28].f64 = (((ctx.f[0].f64 * ctx.f[27].f64 + ctx.f[28].f64) as f32) as f64);
	// 831DD6F8: EC6D107A  fmadds f3, f13, f1, f2
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DD6FC: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD700: EC4D5ABA  fmadds f2, f13, f10, f11
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DD704: D3890014  stfs f28, 0x14(r9)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DD708: EC2D4A3A  fmadds f1, f13, f8, f9
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD70C: D0840004  stfs f4, 4(r4)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD710: ED6DF9FA  fmadds f11, f13, f7, f31
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DD714: D0640008  stfs f3, 8(r4)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD718: ED4DF1BA  fmadds f10, f13, f6, f30
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[6].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DD71C: D044000C  stfs f2, 0xc(r4)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DD720: D0240010  stfs f1, 0x10(r4)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DD724: ED2DE97A  fmadds f9, f13, f5, f29
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DD728: D1640014  stfs f11, 0x14(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DD72C: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DD730: D1440018  stfs f10, 0x18(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DD734: ED8DDF3A  fmadds f12, f13, f28, f27
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[28].f64 + ctx.f[27].f64) as f32) as f64);
	// 831DD738: D1270000  stfs f9, 0(r7)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD73C: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 831DD740: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831DD744: 39290020  addi r9, r9, 0x20
	ctx.r[9].s64 = ctx.r[9].s64 + 32;
	// 831DD748: 4082FEF0  bne 0x831dd638
	if !ctx.cr[0].eq {
	pc = 0x831DD638; continue 'dispatch;
	}
	// 831DD74C: 7CE600D0  neg r7, r6
	ctx.r[7].s64 = -ctx.r[6].s64;
	// 831DD750: 21260002  subfic r9, r6, 2
	ctx.xer.ca = ctx.r[6].u32 <= 2 as u32;
	ctx.r[9].s64 = (2 as i64) - ctx.r[6].s64;
	// 831DD754: 394B0008  addi r10, r11, 8
	ctx.r[10].s64 = ctx.r[11].s64 + 8;
	// 831DD758: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 831DD75C: 54E615FA  rlwinm r6, r7, 2, 0x17, 0x1d
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD760: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD764: 38A9FFFF  addi r5, r9, -1
	ctx.r[5].s64 = ctx.r[9].s64 + -1;
	// 831DD768: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD76C: 553B15FA  rlwinm r27, r9, 2, 0x17, 0x1d
	ctx.r[27].u64 = ctx.r[9].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD770: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD774: 54BA15FA  rlwinm r26, r5, 2, 0x17, 0x1d
	ctx.r[26].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD778: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD77C: 38A90001  addi r5, r9, 1
	ctx.r[5].s64 = ctx.r[9].s64 + 1;
	// 831DD780: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD784: 7CC65C2E  lfsx f6, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD788: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 831DD78C: ECA059BA  fmadds f5, f0, f6, f11
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DD790: D0AAFFF8  stfs f5, -8(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DD794: 54B915FA  rlwinm r25, r5, 2, 0x17, 0x1d
	ctx.r[25].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD798: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD79C: 54D815FA  rlwinm r24, r6, 2, 0x17, 0x1d
	ctx.r[24].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD7A0: C0840014  lfs f4, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DD7A4: 38C90004  addi r6, r9, 4
	ctx.r[6].s64 = ctx.r[9].s64 + 4;
	// 831DD7A8: C0640018  lfs f3, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DD7AC: 38A90003  addi r5, r9, 3
	ctx.r[5].s64 = ctx.r[9].s64 + 3;
	// 831DD7B0: 54D615FA  rlwinm r22, r6, 2, 0x17, 0x1d
	ctx.r[22].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD7B4: 38C40008  addi r6, r4, 8
	ctx.r[6].s64 = ctx.r[4].s64 + 8;
	// 831DD7B8: 54B715FA  rlwinm r23, r5, 2, 0x17, 0x1d
	ctx.r[23].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD7BC: 38A90005  addi r5, r9, 5
	ctx.r[5].s64 = ctx.r[9].s64 + 5;
	// 831DD7C0: 3B84001C  addi r28, r4, 0x1c
	ctx.r[28].s64 = ctx.r[4].s64 + 28;
	// 831DD7C4: EC4D317A  fmadds f2, f13, f5, f6
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD7C8: D0440004  stfs f2, 4(r4)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD7CC: 54B515FA  rlwinm r21, r5, 2, 0x17, 0x1d
	ctx.r[21].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD7D0: 38A4000C  addi r5, r4, 0xc
	ctx.r[5].s64 = ctx.r[4].s64 + 12;
	// 831DD7D4: 3BE40010  addi r31, r4, 0x10
	ctx.r[31].s64 = ctx.r[4].s64 + 16;
	// 831DD7D8: C03C0000  lfs f1, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DD7DC: 3BC40014  addi r30, r4, 0x14
	ctx.r[30].s64 = ctx.r[4].s64 + 20;
	// 831DD7E0: 3BA40018  addi r29, r4, 0x18
	ctx.r[29].s64 = ctx.r[4].s64 + 24;
	// 831DD7E4: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DD7E8: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 831DD7EC: 38E70008  addi r7, r7, 8
	ctx.r[7].s64 = ctx.r[7].s64 + 8;
	// 831DD7F0: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 831DD7F4: 7D9A5C2E  lfsx f12, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD7F8: ED60533A  fmadds f11, f0, f12, f10
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DD7FC: D16AFFFC  stfs f11, -4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DD800: 7CDB5C2E  lfsx f6, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD804: ECA049BA  fmadds f5, f0, f6, f9
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[6].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD808: D0AA0000  stfs f5, 0(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD80C: ED4D62FA  fmadds f10, f13, f11, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 831DD810: D1460000  stfs f10, 0(r6)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD814: ED6D317A  fmadds f11, f13, f5, f6
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD818: D1650000  stfs f11, 0(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD81C: 7C595C2E  lfsx f2, r25, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DD820: ED8040BA  fmadds f12, f0, f2, f8
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DD824: D18A0004  stfs f12, 4(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DD828: ED0D133A  fmadds f8, f13, f12, f2
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DD82C: D11F0000  stfs f8, 0(r31)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD830: 7D585C2E  lfsx f10, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD834: ED203ABA  fmadds f9, f0, f10, f7
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DD838: D12A0008  stfs f9, 8(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD83C: 7CD75C2E  lfsx f6, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD840: ECA021BA  fmadds f5, f0, f6, f4
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DD844: D0AA000C  stfs f5, 0xc(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DD848: ECED527A  fmadds f7, f13, f9, f10
	ctx.f[7].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DD84C: 7C965C2E  lfsx f4, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DD850: EC60193A  fmadds f3, f0, f4, f3
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DD854: D06A0010  stfs f3, 0x10(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DD858: EC4D317A  fmadds f2, f13, f5, f6
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DD85C: 7D955C2E  lfsx f12, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD860: ED600B3A  fmadds f11, f0, f12, f1
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DD864: D16A0014  stfs f11, 0x14(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DD868: ED4D20FA  fmadds f10, f13, f3, f4
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DD86C: D0FE0000  stfs f7, 0(r30)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD870: ED8D62FA  fmadds f12, f13, f11, f12
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64);
	// 831DD874: D05D0000  stfs f2, 0(r29)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD878: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 831DD87C: D15C0000  stfs f10, 0(r28)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD880: 4082FEDC  bne 0x831dd75c
	if !ctx.cr[0].eq {
	pc = 0x831DD75C; continue 'dispatch;
	}
	// 831DD884: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831DD888: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DD88C: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD890: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DD894: 3981FFA0  addi r12, r1, -0x60
	ctx.r[12].s64 = ctx.r[1].s64 + -96;
	// 831DD898: 4BFCB229  bl 0x831a8ac0
	ctx.lr = 0x831DD89C;
	sub_831A8A8C(ctx, base);
	// 831DD89C: 4BFCA900  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DD8A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DD8A0 size=200
    let mut pc: u32 = 0x831DD8A0;
    'dispatch: loop {
        match pc {
            0x831DD8A0 => {
    //   block [0x831DD8A0..0x831DD968)
	// 831DD8A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DD8A4: 4BFCA8C1  bl 0x831a8164
	ctx.lr = 0x831DD8A8;
	sub_831A8130(ctx, base);
	// 831DD8A8: 80E30024  lwz r7, 0x24(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 831DD8AC: 3943002C  addi r10, r3, 0x2c
	ctx.r[10].s64 = ctx.r[3].s64 + 44;
	// 831DD8B0: 83C30000  lwz r30, 0(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DD8B4: C1630008  lfs f11, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD8B8: 83E3000C  lwz r31, 0xc(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DD8BC: 54E9103A  slwi r9, r7, 2
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DD8C0: 83A30018  lwz r29, 0x18(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DD8C4: C1430020  lfs f10, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD8C8: 7D7E3850  subf r11, r30, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[30].s64;
	// 831DD8CC: C0030010  lfs f0, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD8D0: 7D095214  add r8, r9, r10
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DD8D4: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DD8D8: 7FFFF050  subf r31, r31, r30
	ctx.r[31].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 831DD8DC: C183001C  lfs f12, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD8E0: D1650000  stfs f11, 0(r5)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD8E4: 7FDDF050  subf r30, r29, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[29].s64;
	// 831DD8E8: D1460000  stfs f10, 0(r6)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD8EC: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 831DD8F0: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DD8F4: 557D14FA  rlwinm r29, r11, 2, 0x13, 0x1d
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD8F8: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD8FC: 7F9F5A14  add r28, r31, r11
	ctx.r[28].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DD900: 7F7E5A14  add r27, r30, r11
	ctx.r[27].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 831DD904: 579C14FA  rlwinm r28, r28, 2, 0x13, 0x1d
	ctx.r[28].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD908: 577B14FA  rlwinm r27, r27, 2, 0x13, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD90C: 7D5D542E  lfsx f10, r29, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD910: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 831DD914: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DD918: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DD91C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DD920: 7D1C542E  lfsx f8, r28, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD924: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DD928: 7CFB542E  lfsx f7, r27, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD92C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DD930: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD934: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DD938: D0C60000  stfs f6, 0(r6)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD93C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831DD940: ECA8483A  fmadds f5, f8, f0, f9
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DD944: D0A50000  stfs f5, 0(r5)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DD948: 4082FFAC  bne 0x831dd8f4
	if !ctx.cr[0].eq {
	pc = 0x831DD8F4; continue 'dispatch;
	}
	// 831DD94C: 54EB057E  clrlwi r11, r7, 0x15
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000007FFu64;
	// 831DD950: FC002890  fmr f0, f5
	ctx.f[0].f64 = ctx.f[5].f64;
	// 831DD954: FDA03090  fmr f13, f6
	ctx.f[13].f64 = ctx.f[6].f64;
	// 831DD958: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DD95C: D1A30020  stfs f13, 0x20(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 831DD960: 91630024  stw r11, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 831DD964: 4BFCA850  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DD968(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DD968 size=372
    let mut pc: u32 = 0x831DD968;
    'dispatch: loop {
        match pc {
            0x831DD968 => {
    //   block [0x831DD968..0x831DDADC)
	// 831DD968: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DD96C: 4BFCA801  bl 0x831a816c
	ctx.lr = 0x831DD970;
	sub_831A8130(ctx, base);
	// 831DD970: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 831DD974: 4BFCB101  bl 0x831a8a74
	ctx.lr = 0x831DD978;
	sub_831A8A40(ctx, base);
	// 831DD978: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DD97C: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 831DD980: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DD984: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DD988: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 831DD98C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DD990: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831DD994: C183000C  lfs f12, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DD998: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DD99C: 394B0002  addi r10, r11, 2
	ctx.r[10].s64 = ctx.r[11].s64 + 2;
	// 831DD9A0: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 831DD9A4: 7D664A14  add r11, r6, r9
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[9].u64;
	// 831DD9A8: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DD9AC: 38CAFFFE  addi r6, r10, -2
	ctx.r[6].s64 = ctx.r[10].s64 + -2;
	// 831DD9B0: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DD9B4: 38AAFFFF  addi r5, r10, -1
	ctx.r[5].s64 = ctx.r[10].s64 + -1;
	// 831DD9B8: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DD9BC: 54C615BA  rlwinm r6, r6, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD9C0: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DD9C4: 54A515BA  rlwinm r5, r5, 2, 0x16, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD9C8: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DD9CC: 555F15BA  rlwinm r31, r10, 2, 0x16, 0x1d
	ctx.r[31].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD9D0: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DD9D4: 3BCA0001  addi r30, r10, 1
	ctx.r[30].s64 = ctx.r[10].s64 + 1;
	// 831DD9D8: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DD9DC: 3BAA0002  addi r29, r10, 2
	ctx.r[29].s64 = ctx.r[10].s64 + 2;
	// 831DD9E0: C0A40018  lfs f5, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DD9E4: 7C864C2E  lfsx f4, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DD9E8: 57C615BA  rlwinm r6, r30, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DD9EC: EC60593A  fmadds f3, f0, f4, f11
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DD9F0: D06BFFF8  stfs f3, -8(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DD9F4: 7C454C2E  lfsx f2, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DD9F8: EC2050BA  fmadds f1, f0, f2, f10
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DD9FC: D02BFFFC  stfs f1, -4(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DDA00: 38AA0003  addi r5, r10, 3
	ctx.r[5].s64 = ctx.r[10].s64 + 3;
	// 831DDA04: 7D5F4C2E  lfsx f10, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDA08: 57BF15BA  rlwinm r31, r29, 2, 0x16, 0x1d
	ctx.r[31].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDA0C: ED204ABA  fmadds f9, f0, f10, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DDA10: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDA14: 7FE64C2E  lfsx f31, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DDA18: 54A515BA  rlwinm r5, r5, 2, 0x16, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDA1C: ED0047FA  fmadds f8, f0, f31, f8
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DDA20: 38CA0004  addi r6, r10, 4
	ctx.r[6].s64 = ctx.r[10].s64 + 4;
	// 831DDA24: D10B0004  stfs f8, 4(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDA28: 3BCA0005  addi r30, r10, 5
	ctx.r[30].s64 = ctx.r[10].s64 + 5;
	// 831DDA2C: 7FDF4C2E  lfsx f30, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DDA30: ECE03FBA  fmadds f7, f0, f30, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[30].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DDA34: 54C615BA  rlwinm r6, r6, 2, 0x16, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDA38: D0EB0008  stfs f7, 8(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDA3C: 7FA54C2E  lfsx f29, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DDA40: 57C515BA  rlwinm r5, r30, 2, 0x16, 0x1d
	ctx.r[5].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDA44: ECC0377A  fmadds f6, f0, f29, f6
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[29].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DDA48: D0CB000C  stfs f6, 0xc(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDA4C: 7F864C2E  lfsx f28, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DDA50: ECA02F3A  fmadds f5, f0, f28, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[28].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DDA54: C164001C  lfs f11, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDA58: EC8D20FA  fmadds f4, f13, f3, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DDA5C: D0AB0010  stfs f5, 0x10(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDA60: EC4D107A  fmadds f2, f13, f1, f2
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DDA64: 7C654C2E  lfsx f3, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DDA68: EF6058FA  fmadds f27, f0, f3, f11
	ctx.f[27].f64 = (((ctx.f[0].f64 * ctx.f[3].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DDA6C: ED6D1EFA  fmadds f11, f13, f27, f3
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[27].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DDA70: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDA74: EC2D527A  fmadds f1, f13, f9, f10
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDA78: D0840004  stfs f4, 4(r4)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDA7C: ED8DFA3A  fmadds f12, f13, f8, f31
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DDA80: D1840010  stfs f12, 0x10(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDA84: ED4DF1FA  fmadds f10, f13, f7, f30
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DDA88: D0440008  stfs f2, 8(r4)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDA8C: ED2DE9BA  fmadds f9, f13, f6, f29
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[6].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DDA90: D024000C  stfs f1, 0xc(r4)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDA94: ED0DE17A  fmadds f8, f13, f5, f28
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[28].f64) as f32) as f64);
	// 831DDA98: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDA9C: D1240018  stfs f9, 0x18(r4)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DDAA0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DDAA4: D104001C  stfs f8, 0x1c(r4)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831DDAA8: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 831DDAAC: D36B0014  stfs f27, 0x14(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDAB0: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831DDAB4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831DDAB8: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 831DDABC: 4082FEF0  bne 0x831dd9ac
	if !ctx.cr[0].eq {
	pc = 0x831DD9AC; continue 'dispatch;
	}
	// 831DDAC0: 54EB063E  clrlwi r11, r7, 0x18
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831DDAC4: D163000C  stfs f11, 0xc(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDAC8: D1640000  stfs f11, 0(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDACC: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DDAD0: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 831DDAD4: 4BFCAFED  bl 0x831a8ac0
	ctx.lr = 0x831DDAD8;
	sub_831A8A8C(ctx, base);
	// 831DDAD8: 4BFCA6E4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DDAE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DDAE0 size=372
    let mut pc: u32 = 0x831DDAE0;
    'dispatch: loop {
        match pc {
            0x831DDAE0 => {
    //   block [0x831DDAE0..0x831DDC54)
	// 831DDAE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DDAE4: 4BFCA689  bl 0x831a816c
	ctx.lr = 0x831DDAE8;
	sub_831A8130(ctx, base);
	// 831DDAE8: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 831DDAEC: 4BFCAF89  bl 0x831a8a74
	ctx.lr = 0x831DDAF0;
	sub_831A8A40(ctx, base);
	// 831DDAF0: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DDAF4: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 831DDAF8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DDAFC: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDB00: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 831DDB04: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DDB08: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831DDB0C: C183000C  lfs f12, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DDB10: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DDB14: 394B0002  addi r10, r11, 2
	ctx.r[10].s64 = ctx.r[11].s64 + 2;
	// 831DDB18: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 831DDB1C: 7D664A14  add r11, r6, r9
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[9].u64;
	// 831DDB20: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DDB24: 38CAFFFE  addi r6, r10, -2
	ctx.r[6].s64 = ctx.r[10].s64 + -2;
	// 831DDB28: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDB2C: 38AAFFFF  addi r5, r10, -1
	ctx.r[5].s64 = ctx.r[10].s64 + -1;
	// 831DDB30: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDB34: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB38: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DDB3C: 54A5157A  rlwinm r5, r5, 2, 0x15, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB40: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DDB44: 555F157A  rlwinm r31, r10, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB48: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DDB4C: 3BCA0001  addi r30, r10, 1
	ctx.r[30].s64 = ctx.r[10].s64 + 1;
	// 831DDB50: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DDB54: 3BAA0002  addi r29, r10, 2
	ctx.r[29].s64 = ctx.r[10].s64 + 2;
	// 831DDB58: C0A40018  lfs f5, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DDB5C: 7C864C2E  lfsx f4, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DDB60: 57C6157A  rlwinm r6, r30, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB64: EC60593A  fmadds f3, f0, f4, f11
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DDB68: D06BFFF8  stfs f3, -8(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DDB6C: 7C454C2E  lfsx f2, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DDB70: EC2050BA  fmadds f1, f0, f2, f10
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDB74: D02BFFFC  stfs f1, -4(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DDB78: 38AA0003  addi r5, r10, 3
	ctx.r[5].s64 = ctx.r[10].s64 + 3;
	// 831DDB7C: 7D5F4C2E  lfsx f10, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDB80: 57BF157A  rlwinm r31, r29, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB84: ED204ABA  fmadds f9, f0, f10, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DDB88: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDB8C: 7FE64C2E  lfsx f31, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DDB90: 54A5157A  rlwinm r5, r5, 2, 0x15, 0x1d
	ctx.r[5].u64 = ctx.r[5].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDB94: ED0047FA  fmadds f8, f0, f31, f8
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DDB98: 38CA0004  addi r6, r10, 4
	ctx.r[6].s64 = ctx.r[10].s64 + 4;
	// 831DDB9C: D10B0004  stfs f8, 4(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDBA0: 3BCA0005  addi r30, r10, 5
	ctx.r[30].s64 = ctx.r[10].s64 + 5;
	// 831DDBA4: 7FDF4C2E  lfsx f30, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DDBA8: ECE03FBA  fmadds f7, f0, f30, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[30].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DDBAC: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDBB0: D0EB0008  stfs f7, 8(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDBB4: 7FA54C2E  lfsx f29, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DDBB8: 57C5157A  rlwinm r5, r30, 2, 0x15, 0x1d
	ctx.r[5].u64 = ctx.r[30].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDBBC: ECC0377A  fmadds f6, f0, f29, f6
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[29].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DDBC0: D0CB000C  stfs f6, 0xc(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDBC4: 7F864C2E  lfsx f28, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DDBC8: ECA02F3A  fmadds f5, f0, f28, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[28].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DDBCC: C164001C  lfs f11, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDBD0: EC8D20FA  fmadds f4, f13, f3, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DDBD4: D0AB0010  stfs f5, 0x10(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDBD8: EC4D107A  fmadds f2, f13, f1, f2
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DDBDC: 7C654C2E  lfsx f3, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DDBE0: EF6058FA  fmadds f27, f0, f3, f11
	ctx.f[27].f64 = (((ctx.f[0].f64 * ctx.f[3].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DDBE4: ED6D1EFA  fmadds f11, f13, f27, f3
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[27].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DDBE8: D1840000  stfs f12, 0(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDBEC: EC2D527A  fmadds f1, f13, f9, f10
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDBF0: D0840004  stfs f4, 4(r4)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDBF4: ED8DFA3A  fmadds f12, f13, f8, f31
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DDBF8: D1840010  stfs f12, 0x10(r4)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDBFC: ED4DF1FA  fmadds f10, f13, f7, f30
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DDC00: D0440008  stfs f2, 8(r4)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDC04: ED2DE9BA  fmadds f9, f13, f6, f29
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[6].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DDC08: D024000C  stfs f1, 0xc(r4)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDC0C: ED0DE17A  fmadds f8, f13, f5, f28
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[28].f64) as f32) as f64);
	// 831DDC10: D1440014  stfs f10, 0x14(r4)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDC14: D1240018  stfs f9, 0x18(r4)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DDC18: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DDC1C: D104001C  stfs f8, 0x1c(r4)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831DDC20: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 831DDC24: D36B0014  stfs f27, 0x14(r11)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDC28: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831DDC2C: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831DDC30: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 831DDC34: 4082FEF0  bne 0x831ddb24
	if !ctx.cr[0].eq {
	pc = 0x831DDB24; continue 'dispatch;
	}
	// 831DDC38: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 831DDC3C: D163000C  stfs f11, 0xc(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDC40: D1640000  stfs f11, 0(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDC44: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DDC48: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 831DDC4C: 4BFCAE75  bl 0x831a8ac0
	ctx.lr = 0x831DDC50;
	sub_831A8A8C(ctx, base);
	// 831DDC50: 4BFCA56C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DDC58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DDC58 size=376
    let mut pc: u32 = 0x831DDC58;
    'dispatch: loop {
        match pc {
            0x831DDC58 => {
    //   block [0x831DDC58..0x831DDDD0)
	// 831DDC58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DDC5C: 4BFCA50D  bl 0x831a8168
	ctx.lr = 0x831DDC60;
	sub_831A8130(ctx, base);
	// 831DDC60: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 831DDC64: 4BFCAE11  bl 0x831a8a74
	ctx.lr = 0x831DDC68;
	sub_831A8A40(ctx, base);
	// 831DDC68: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DDC6C: 39230018  addi r9, r3, 0x18
	ctx.r[9].s64 = ctx.r[3].s64 + 24;
	// 831DDC70: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DDC74: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDC78: 39470002  addi r10, r7, 2
	ctx.r[10].s64 = ctx.r[7].s64 + 2;
	// 831DDC7C: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DDC80: 7D6B3850  subf r11, r11, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831DDC84: C183000C  lfs f12, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DDC88: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831DDC8C: 39000020  li r8, 0x20
	ctx.r[8].s64 = 32;
	// 831DDC90: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 831DDC94: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 831DDC98: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DDC9C: 38CBFFFE  addi r6, r11, -2
	ctx.r[6].s64 = ctx.r[11].s64 + -2;
	// 831DDCA0: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDCA4: 3BEBFFFF  addi r31, r11, -1
	ctx.r[31].s64 = ctx.r[11].s64 + -1;
	// 831DDCA8: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDCAC: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDCB0: C1240008  lfs f9, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DDCB4: 57FF157A  rlwinm r31, r31, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDCB8: C104000C  lfs f8, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DDCBC: 557E157A  rlwinm r30, r11, 2, 0x15, 0x1d
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDCC0: C0E40010  lfs f7, 0x10(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DDCC4: 3BAB0001  addi r29, r11, 1
	ctx.r[29].s64 = ctx.r[11].s64 + 1;
	// 831DDCC8: C0C40014  lfs f6, 0x14(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DDCCC: 3B8B0002  addi r28, r11, 2
	ctx.r[28].s64 = ctx.r[11].s64 + 2;
	// 831DDCD0: C0A40018  lfs f5, 0x18(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DDCD4: 7C864C2E  lfsx f4, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DDCD8: 57A6157A  rlwinm r6, r29, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDCDC: EC60593A  fmadds f3, f0, f4, f11
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DDCE0: D06AFFF8  stfs f3, -8(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DDCE4: 7C5F4C2E  lfsx f2, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DDCE8: EC2050BA  fmadds f1, f0, f2, f10
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDCEC: D02AFFFC  stfs f1, -4(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DDCF0: 3BEB0003  addi r31, r11, 3
	ctx.r[31].s64 = ctx.r[11].s64 + 3;
	// 831DDCF4: 7D5E4C2E  lfsx f10, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDCF8: 579E157A  rlwinm r30, r28, 2, 0x15, 0x1d
	ctx.r[30].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDCFC: ED204ABA  fmadds f9, f0, f10, f9
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DDD00: D12A0000  stfs f9, 0(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDD04: 7FE64C2E  lfsx f31, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DDD08: 57FF157A  rlwinm r31, r31, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDD0C: ED0047FA  fmadds f8, f0, f31, f8
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DDD10: 38CB0004  addi r6, r11, 4
	ctx.r[6].s64 = ctx.r[11].s64 + 4;
	// 831DDD14: D10A0004  stfs f8, 4(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDD18: 3BAB0005  addi r29, r11, 5
	ctx.r[29].s64 = ctx.r[11].s64 + 5;
	// 831DDD1C: 7FDE4C2E  lfsx f30, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DDD20: ECE03FBA  fmadds f7, f0, f30, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[30].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DDD24: 54C6157A  rlwinm r6, r6, 2, 0x15, 0x1d
	ctx.r[6].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDD28: D0EA0008  stfs f7, 8(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDD2C: 7FBF4C2E  lfsx f29, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DDD30: 57BF157A  rlwinm r31, r29, 2, 0x15, 0x1d
	ctx.r[31].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDD34: ECC0377A  fmadds f6, f0, f29, f6
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[29].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DDD38: D0CA000C  stfs f6, 0xc(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDD3C: 7F864C2E  lfsx f28, r6, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DDD40: ECA02F3A  fmadds f5, f0, f28, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[28].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DDD44: C164001C  lfs f11, 0x1c(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(28 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDD48: EC8D20FA  fmadds f4, f13, f3, f4
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DDD4C: D0AA0010  stfs f5, 0x10(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDD50: EC4D107A  fmadds f2, f13, f1, f2
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DDD54: 7C7F4C2E  lfsx f3, r31, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DDD58: EF6058FA  fmadds f27, f0, f3, f11
	ctx.f[27].f64 = (((ctx.f[0].f64 * ctx.f[3].f64 + ctx.f[11].f64) as f32) as f64);
	// 831DDD5C: ED6D1EFA  fmadds f11, f13, f27, f3
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[27].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DDD60: D1850000  stfs f12, 0(r5)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDD64: EC2D527A  fmadds f1, f13, f9, f10
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDD68: D0850004  stfs f4, 4(r5)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDD6C: ED8DFA3A  fmadds f12, f13, f8, f31
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[8].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DDD70: D1850010  stfs f12, 0x10(r5)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DDD74: ED4DF1FA  fmadds f10, f13, f7, f30
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[7].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DDD78: D0450008  stfs f2, 8(r5)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDD7C: ED2DE9BA  fmadds f9, f13, f6, f29
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[6].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DDD80: D025000C  stfs f1, 0xc(r5)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDD84: ED0DE17A  fmadds f8, f13, f5, f28
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[5].f64 + ctx.f[28].f64) as f32) as f64);
	// 831DDD88: D1450014  stfs f10, 0x14(r5)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDD8C: D1250018  stfs f9, 0x18(r5)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DDD90: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831DDD94: D105001C  stfs f8, 0x1c(r5)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831DDD98: 38840020  addi r4, r4, 0x20
	ctx.r[4].s64 = ctx.r[4].s64 + 32;
	// 831DDD9C: D36A0014  stfs f27, 0x14(r10)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDDA0: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831DDDA4: 38A50020  addi r5, r5, 0x20
	ctx.r[5].s64 = ctx.r[5].s64 + 32;
	// 831DDDA8: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 831DDDAC: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 831DDDB0: 4082FEEC  bne 0x831ddc9c
	if !ctx.cr[0].eq {
	pc = 0x831DDC9C; continue 'dispatch;
	}
	// 831DDDB4: 54EB05FE  clrlwi r11, r7, 0x17
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000001FFu64;
	// 831DDDB8: D163000C  stfs f11, 0xc(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DDDBC: D1640000  stfs f11, 0(r4)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDDC0: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DDDC4: 3981FFD8  addi r12, r1, -0x28
	ctx.r[12].s64 = ctx.r[1].s64 + -40;
	// 831DDDC8: 4BFCACF9  bl 0x831a8ac0
	ctx.lr = 0x831DDDCC;
	sub_831A8A8C(ctx, base);
	// 831DDDCC: 4BFCA3EC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DDDD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DDDD0 size=164
    let mut pc: u32 = 0x831DDDD0;
    'dispatch: loop {
        match pc {
            0x831DDDD0 => {
    //   block [0x831DDDD0..0x831DDE74)
	// 831DDDD0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DDDD4: 4BFCA399  bl 0x831a816c
	ctx.lr = 0x831DDDD8;
	sub_831A8130(ctx, base);
	// 831DDDD8: 80E30018  lwz r7, 0x18(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DDDDC: 3BE30020  addi r31, r3, 0x20
	ctx.r[31].s64 = ctx.r[3].s64 + 32;
	// 831DDDE0: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DDDE4: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDDE8: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DDDEC: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DDDF0: C1A30014  lfs f13, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DDDF4: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 831DDDF8: 7D4A3850  subf r10, r10, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[10].s64;
	// 831DDDFC: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DDE00: C1630010  lfs f11, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDE04: 39600100  li r11, 0x100
	ctx.r[11].s64 = 256;
	// 831DDE08: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE0C: 7D08FA14  add r8, r8, r31
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 831DDE10: D1A60000  stfs f13, 0(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE14: 38E70100  addi r7, r7, 0x100
	ctx.r[7].s64 = ctx.r[7].s64 + 256;
	// 831DDE18: 555E153A  rlwinm r30, r10, 2, 0x14, 0x1d
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDE1C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DDE20: 553D153A  rlwinm r29, r9, 2, 0x14, 0x1d
	ctx.r[29].u64 = ctx.r[9].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDE24: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 831DDE28: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DDE2C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DDE30: 7D5EFC2E  lfsx f10, r30, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DDE34: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DDE38: 7D3DFC2E  lfsx f9, r29, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DDE3C: EC0A0332  fmuls f0, f10, f12
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DDE40: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE44: EDA902F2  fmuls f13, f9, f11
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DDE48: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE4C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831DDE50: D1A60000  stfs f13, 0(r6)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE54: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DDE58: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831DDE5C: 4082FFBC  bne 0x831dde18
	if !ctx.cr[0].eq {
	pc = 0x831DDE18; continue 'dispatch;
	}
	// 831DDE60: 54EB05BE  clrlwi r11, r7, 0x16
	ctx.r[11].u64 = ctx.r[7].u32 as u64 & 0x000003FFu64;
	// 831DDE64: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DDE68: D1A30014  stfs f13, 0x14(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DDE6C: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831DDE70: 4BFCA34C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DDE78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831DDE78 size=1256
    let mut pc: u32 = 0x831DDE78;
    'dispatch: loop {
        match pc {
            0x831DDE78 => {
    //   block [0x831DDE78..0x831DE360)
	// 831DDE78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DDE7C: 4BFCA2C9  bl 0x831a8144
	ctx.lr = 0x831DDE80;
	sub_831A8130(ctx, base);
	// 831DDE80: DBC1FF80  stfd f30, -0x80(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.f[30].u64 ) };
	// 831DDE84: DBE1FF88  stfd f31, -0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.f[31].u64 ) };
	// 831DDE88: 3D60820D  lis r11, -0x7df3
	ctx.r[11].s64 = -2113077248;
	// 831DDE8C: C0030014  lfs f0, 0x14(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDE90: D0050000  stfs f0, 0(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDE94: 81430018  lwz r10, 0x18(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DDE98: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DDE9C: C00B9A8C  lfs f0, -0x6574(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-25972 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDEA0: EDAC0032  fmuls f13, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DDEA4: FD606E5E  fctidz f11, f13
	ctx.f[11].s64 = if ctx.f[13].f64 > (i64::MAX as f64) { i64::MAX } else { ctx.f[13].f64.trunc() as i64 };
	// 831DDEA8: D961FF70  stfd f11, -0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.f[11].u64 ) };
	// 831DDEAC: 8121FF74  lwz r9, -0x8c(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-140 as u32) ) } as u64;
	// 831DDEB0: 5527F87E  srwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shr(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DDEB4: 2B070100  cmplwi cr6, r7, 0x100
	ctx.cr[6].compare_u32(ctx.r[7].u32, 256 as u32, &mut ctx.xer);
	// 831DDEB8: 409803F4  bge cr6, 0x831de2ac
	if !ctx.cr[6].lt {
	pc = 0x831DE2AC; continue 'dispatch;
	}
	// 831DDEBC: 3D208200  lis r9, -0x7e00
	ctx.r[9].s64 = -2113929216;
	// 831DDEC0: 3D008212  lis r8, -0x7dee
	ctx.r[8].s64 = -2112749568;
	// 831DDEC4: 39630020  addi r11, r3, 0x20
	ctx.r[11].s64 = ctx.r[3].s64 + 32;
	// 831DDEC8: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 831DDECC: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 831DDED0: C16908A8  lfs f11, 0x8a8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(2216 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DDED4: C008DFA8  lfs f0, -0x2058(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-8280 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DDED8: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DDEDC: 41980130  blt cr6, 0x831de00c
	if ctx.cr[6].lt {
	pc = 0x831DE00C; continue 'dispatch;
	}
	// 831DDEE0: 8323000C  lwz r25, 0xc(r3)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DDEE4: 390A0002  addi r8, r10, 2
	ctx.r[8].s64 = ctx.r[10].s64 + 2;
	// 831DDEE8: 83830008  lwz r28, 8(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DDEEC: 54FB003A  rlwinm r27, r7, 0, 0, 0x1d
	ctx.r[27].u64 = ctx.r[7].u32 as u64 & 0xFFFFFFFFu64;
	// 831DDEF0: 7D395050  subf r9, r25, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[25].s64;
	// 831DDEF4: 7FBC5050  subf r29, r28, r10
	ctx.r[29].s64 = ctx.r[10].s64 - ctx.r[28].s64;
	// 831DDEF8: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DDEFC: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 831DDF00: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 831DDF04: 7F39E050  subf r25, r25, r28
	ctx.r[25].s64 = ctx.r[28].s64 - ctx.r[25].s64;
	// 831DDF08: 3BFD0002  addi r31, r29, 2
	ctx.r[31].s64 = ctx.r[29].s64 + 2;
	// 831DDF0C: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831DDF10: 3BC40008  addi r30, r4, 8
	ctx.r[30].s64 = ctx.r[4].s64 + 8;
	// 831DDF14: 3925000C  addi r9, r5, 0xc
	ctx.r[9].s64 = ctx.r[5].s64 + 12;
	// 831DDF18: 7F452050  subf r26, r5, r4
	ctx.r[26].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831DDF1C: 54FCF0BE  srwi r28, r7, 2
	ctx.r[28].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 831DDF20: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 831DDF24: ED4C0028  fsubs f10, f12, f0
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DDF28: 7F1DCA14  add r24, r29, r25
	ctx.r[24].u64 = ctx.r[29].u64 + ctx.r[25].u64;
	// 831DDF2C: ED2D002A  fadds f9, f13, f0
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DDF30: 3AE6FFFF  addi r23, r6, -1
	ctx.r[23].s64 = ctx.r[6].s64 + -1;
	// 831DDF34: 57B515BA  rlwinm r21, r29, 2, 0x16, 0x1d
	ctx.r[21].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF38: C11EFFF8  lfs f8, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DDF3C: 571815BA  rlwinm r24, r24, 2, 0x16, 0x1d
	ctx.r[24].u64 = ctx.r[24].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF40: C0FEFFFC  lfs f7, -4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DDF44: 56F715BA  rlwinm r23, r23, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF48: C0DE0000  lfs f6, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DDF4C: 3ADFFFFF  addi r22, r31, -1
	ctx.r[22].s64 = ctx.r[31].s64 + -1;
	// 831DDF50: 7CBA4C2E  lfsx f5, r26, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DDF54: 3A860001  addi r20, r6, 1
	ctx.r[20].s64 = ctx.r[6].s64 + 1;
	// 831DDF58: 7C955C2E  lfsx f4, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DDF5C: 56D615BA  rlwinm r22, r22, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[22].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF60: 7C785C2E  lfsx f3, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DDF64: 54D315BA  rlwinm r19, r6, 2, 0x16, 0x1d
	ctx.r[19].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF68: D108FFF8  stfs f8, -8(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DDF6C: 57F515BA  rlwinm r21, r31, 2, 0x16, 0x1d
	ctx.r[21].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF70: EC4A0028  fsubs f2, f10, f0
	ctx.f[2].f64 = (((ctx.f[10].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DDF74: 7D175C2E  lfsx f8, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DDF78: ED4802B2  fmuls f10, f8, f10
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 831DDF7C: 569815BA  rlwinm r24, r20, 2, 0x16, 0x1d
	ctx.r[24].u64 = ctx.r[20].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDF80: ED020028  fsubs f8, f2, f0
	ctx.f[8].f64 = (((ctx.f[2].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DDF84: 3AFF0001  addi r23, r31, 1
	ctx.r[23].s64 = ctx.r[31].s64 + 1;
	// 831DDF88: EC29002A  fadds f1, f9, f0
	ctx.f[1].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DDF8C: 379CFFFF  addic. r28, r28, -1
	ctx.xer.ca = (ctx.r[28].u32 > (!(-1 as u32)));
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 831DDF90: EC840372  fmuls f4, f4, f13
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DDF94: 7DB65C2E  lfsx f13, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DDF98: D0E8FFFC  stfs f7, -4(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DDF9C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DDFA0: 7CF35C2E  lfsx f7, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DDFA4: EC4700B2  fmuls f2, f7, f2
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 831DDFA8: 7FD55C2E  lfsx f30, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DDFAC: EFE1002A  fadds f31, f1, f0
	ctx.f[31].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DDFB0: D0C80000  stfs f6, 0(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDFB4: EC83233A  fmadds f4, f3, f12, f4
	ctx.f[4].f64 = (((ctx.f[3].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DDFB8: 7CF85C2E  lfsx f7, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DDFBC: ECC70232  fmuls f6, f7, f8
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 831DDFC0: 56F815BA  rlwinm r24, r23, 2, 0x16, 0x1d
	ctx.r[24].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 831DDFC4: EC5E107A  fmadds f2, f30, f1, f2
	ctx.f[2].f64 = (((ctx.f[30].f64 * ctx.f[1].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DDFC8: EC6D527A  fmadds f3, f13, f9, f10
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DDFCC: D089FFF8  stfs f4, -8(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DDFD0: D069FFFC  stfs f3, -4(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DDFD4: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 831DDFD8: D0490000  stfs f2, 0(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DDFDC: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DDFE0: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 831DDFE4: ED880028  fsubs f12, f8, f0
	ctx.f[12].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DDFE8: 7C385C2E  lfsx f1, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DDFEC: EDA137FA  fmadds f13, f1, f31, f6
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DDFF0: D1A90004  stfs f13, 4(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDFF4: EDBF002A  fadds f13, f31, f0
	ctx.f[13].f64 = ((ctx.f[31].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DDFF8: D0A80004  stfs f5, 4(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DDFFC: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 831DE000: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 831DE004: 4082FF20  bne 0x831ddf24
	if !ctx.cr[0].eq {
	pc = 0x831DDF24; continue 'dispatch;
	}
	// 831DE008: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE00C: 7F1B3840  cmplw cr6, r27, r7
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831DE010: 41990088  bgt cr6, 0x831de098
	if ctx.cr[6].gt {
	pc = 0x831DE098; continue 'dispatch;
	}
	// 831DE014: 5766103A  slwi r6, r27, 2
	ctx.r[6].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DE018: 83830008  lwz r28, 8(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DE01C: 7D3B3850  subf r9, r27, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[27].s64;
	// 831DE020: 8363000C  lwz r27, 0xc(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DE024: 7FA62214  add r29, r6, r4
	ctx.r[29].u64 = ctx.r[6].u64 + ctx.r[4].u64;
	// 831DE028: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DE02C: 555F103A  slwi r31, r10, 2
	ctx.r[31].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 831DE030: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DE034: 7FC62A14  add r30, r6, r5
	ctx.r[30].u64 = ctx.r[6].u64 + ctx.r[5].u64;
	// 831DE038: 7D1C5050  subf r8, r28, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[28].s64;
	// 831DE03C: 38DDFFFC  addi r6, r29, -4
	ctx.r[6].s64 = ctx.r[29].s64 + -4;
	// 831DE040: 7FFF5A14  add r31, r31, r11
	ctx.r[31].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DE044: 7FBBE050  subf r29, r27, r28
	ctx.r[29].s64 = ctx.r[28].s64 - ctx.r[27].s64;
	// 831DE048: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DE04C: 551C15BA  rlwinm r28, r8, 2, 0x16, 0x1d
	ctx.r[28].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE050: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DE054: 7F7D4214  add r27, r29, r8
	ctx.r[27].u64 = ctx.r[29].u64 + ctx.r[8].u64;
	// 831DE058: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DE05C: 577B15BA  rlwinm r27, r27, 2, 0x16, 0x1d
	ctx.r[27].u64 = ctx.r[27].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE060: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831DE064: 7D3C5C2E  lfsx f9, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DE068: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DE06C: ED090372  fmuls f8, f9, f13
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DE070: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE074: 7CFB5C2E  lfsx f7, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DE078: D15F0000  stfs f10, 0(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE07C: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DE080: ECC7433A  fmadds f6, f7, f12, f8
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DE084: D0DE0000  stfs f6, 0(r30)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE088: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE08C: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 831DE090: 4082FFBC  bne 0x831de04c
	if !ctx.cr[0].eq {
	pc = 0x831DE04C; continue 'dispatch;
	}
	// 831DE094: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE098: 83430010  lwz r26, 0x10(r3)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DE09C: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DE0A0: 7F1A4840  cmplw cr6, r26, r9
	ctx.cr[6].compare_u32(ctx.r[26].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831DE0A4: 419A000C  beq cr6, 0x831de0b0
	if ctx.cr[6].eq {
	pc = 0x831DE0B0; continue 'dispatch;
	}
	// 831DE0A8: FD805890  fmr f12, f11
	ctx.f[12].f64 = ctx.f[11].f64;
	// 831DE0AC: 4800000C  b 0x831de0b8
	pc = 0x831DE0B8; continue 'dispatch;
	// 831DE0B0: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 831DE0B4: C18808A4  lfs f12, 0x8a4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DE0B8: 21070100  subfic r8, r7, 0x100
	ctx.xer.ca = ctx.r[7].u32 <= 256 as u32;
	ctx.r[8].s64 = (256 as i64) - ctx.r[7].s64;
	// 831DE0BC: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE0C0: EDAB6028  fsubs f13, f11, f12
	ctx.f[13].f64 = (((ctx.f[11].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DE0C4: 93430008  stw r26, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[26].u32 ) };
	// 831DE0C8: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 831DE0CC: 9123000C  stw r9, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 831DE0D0: 2F080004  cmpwi cr6, r8, 4
	ctx.cr[6].compare_i32(ctx.r[8].s32, 4, &mut ctx.xer);
	// 831DE0D4: 41980144  blt cr6, 0x831de218
	if ctx.cr[6].lt {
	pc = 0x831DE218; continue 'dispatch;
	}
	// 831DE0D8: 212700FC  subfic r9, r7, 0xfc
	ctx.xer.ca = ctx.r[7].u32 <= 252 as u32;
	ctx.r[9].s64 = (252 as i64) - ctx.r[7].s64;
	// 831DE0DC: 82E3000C  lwz r23, 0xc(r3)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DE0E0: 39070003  addi r8, r7, 3
	ctx.r[8].s64 = ctx.r[7].s64 + 3;
	// 831DE0E4: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DE0E8: 38CA0002  addi r6, r10, 2
	ctx.r[6].s64 = ctx.r[10].s64 + 2;
	// 831DE0EC: 3BA90001  addi r29, r9, 1
	ctx.r[29].s64 = ctx.r[9].s64 + 1;
	// 831DE0F0: 3BE70002  addi r31, r7, 2
	ctx.r[31].s64 = ctx.r[7].s64 + 2;
	// 831DE0F4: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 831DE0F8: 7D375050  subf r9, r23, r10
	ctx.r[9].s64 = ctx.r[10].s64 - ctx.r[23].s64;
	// 831DE0FC: 54D9103A  slwi r25, r6, 2
	ctx.r[25].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[25].u64 = ctx.r[25].u32 as u64;
	// 831DE100: 57BB103A  slwi r27, r29, 2
	ctx.r[27].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 831DE104: 7F9A5050  subf r28, r26, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[26].s64;
	// 831DE108: 57F8103A  slwi r24, r31, 2
	ctx.r[24].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 831DE10C: 7FC82214  add r30, r8, r4
	ctx.r[30].u64 = ctx.r[8].u64 + ctx.r[4].u64;
	// 831DE110: 38C90002  addi r6, r9, 2
	ctx.r[6].s64 = ctx.r[9].s64 + 2;
	// 831DE114: 7D195A14  add r8, r25, r11
	ctx.r[8].u64 = ctx.r[25].u64 + ctx.r[11].u64;
	// 831DE118: 7D5B5214  add r10, r27, r10
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[10].u64;
	// 831DE11C: 3BFC0002  addi r31, r28, 2
	ctx.r[31].s64 = ctx.r[28].s64 + 2;
	// 831DE120: 7D382A14  add r9, r24, r5
	ctx.r[9].u64 = ctx.r[24].u64 + ctx.r[5].u64;
	// 831DE124: 7F252050  subf r25, r5, r4
	ctx.r[25].s64 = ctx.r[4].s64 - ctx.r[5].s64;
	// 831DE128: 7F57D050  subf r26, r23, r26
	ctx.r[26].s64 = ctx.r[26].s64 - ctx.r[23].s64;
	// 831DE12C: 7F7B3A14  add r27, r27, r7
	ctx.r[27].u64 = ctx.r[27].u64 + ctx.r[7].u64;
	// 831DE130: 7CFAE214  add r7, r26, r28
	ctx.r[7].u64 = ctx.r[26].u64 + ctx.r[28].u64;
	// 831DE134: C15EFFF4  lfs f10, -0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DE138: 3B1FFFFF  addi r24, r31, -1
	ctx.r[24].s64 = ctx.r[31].s64 + -1;
	// 831DE13C: C13EFFF8  lfs f9, -8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DE140: 3AE6FFFF  addi r23, r6, -1
	ctx.r[23].s64 = ctx.r[6].s64 + -1;
	// 831DE144: ED6D002A  fadds f11, f13, f0
	ctx.f[11].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE148: 54E715BA  rlwinm r7, r7, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE14C: ED0C0028  fsubs f8, f12, f0
	ctx.f[8].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE150: 579615BA  rlwinm r22, r28, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[28].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE154: 7CF94C2E  lfsx f7, r25, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DE158: 56F715BA  rlwinm r23, r23, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[23].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE15C: C0DE0000  lfs f6, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DE160: 571815BA  rlwinm r24, r24, 2, 0x16, 0x1d
	ctx.r[24].u64 = ctx.r[24].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE164: 3ABF0001  addi r21, r31, 1
	ctx.r[21].s64 = ctx.r[31].s64 + 1;
	// 831DE168: 7C875C2E  lfsx f4, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DE16C: 54C715BA  rlwinm r7, r6, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE170: 7CB65C2E  lfsx f5, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DE174: 57F615BA  rlwinm r22, r31, 2, 0x16, 0x1d
	ctx.r[22].u64 = ctx.r[31].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE178: D148FFF8  stfs f10, -8(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 831DE17C: EDA50372  fmuls f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DE180: 7C575C2E  lfsx f2, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DE184: 56B715BA  rlwinm r23, r21, 2, 0x16, 0x1d
	ctx.r[23].u64 = ctx.r[21].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE188: 7C385C2E  lfsx f1, r24, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DE18C: EC6B002A  fadds f3, f11, f0
	ctx.f[3].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE190: D128FFFC  stfs f9, -4(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DE194: ED480028  fsubs f10, f8, f0
	ctx.f[10].f64 = (((ctx.f[8].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE198: 7FE75C2E  lfsx f31, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE19C: ED23002A  fadds f9, f3, f0
	ctx.f[9].f64 = ((ctx.f[3].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE1A0: 7CB65C2E  lfsx f5, r22, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DE1A4: EC2102F2  fmuls f1, f1, f11
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE1A8: D0E80000  stfs f7, 0(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE1AC: ECE500F2  fmuls f7, f5, f3
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[3].f64) as f32) as f64);
	// 831DE1B0: 7D775C2E  lfsx f11, r23, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DE1B4: EFCA0028  fsubs f30, f10, f0
	ctx.f[30].f64 = (((ctx.f[10].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE1B8: ECAB0272  fmuls f5, f11, f9
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[9].f64) as f32) as f64);
	// 831DE1BC: 38E60001  addi r7, r6, 1
	ctx.r[7].s64 = ctx.r[6].s64 + 1;
	// 831DE1C0: 54E715BA  rlwinm r7, r7, 2, 0x16, 0x1d
	ctx.r[7].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE1C4: EC620A3A  fmadds f3, f2, f8, f1
	ctx.f[3].f64 = (((ctx.f[2].f64 * ctx.f[8].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DE1C8: EC846B3A  fmadds f4, f4, f12, f13
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 831DE1CC: D089FFFC  stfs f4, -4(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831DE1D0: EC5F3ABA  fmadds f2, f31, f10, f7
	ctx.f[2].f64 = (((ctx.f[31].f64 * ctx.f[10].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DE1D4: D0690000  stfs f3, 0(r9)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE1D8: D0490004  stfs f2, 4(r9)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE1DC: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831DE1E0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DE1E4: ED9E0028  fsubs f12, f30, f0
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE1E8: 7C275C2E  lfsx f1, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DE1EC: EDA12FBA  fmadds f13, f1, f30, f5
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[30].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DE1F0: D1A90008  stfs f13, 8(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DE1F4: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 831DE1F8: D0C80004  stfs f6, 4(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE1FC: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831DE200: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 831DE204: EDA9002A  fadds f13, f9, f0
	ctx.f[13].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE208: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 831DE20C: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 831DE210: 4082FF20  bne 0x831de130
	if !ctx.cr[0].eq {
	pc = 0x831DE130; continue 'dispatch;
	}
	// 831DE214: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE218: 2B1B0100  cmplwi cr6, r27, 0x100
	ctx.cr[6].compare_u32(ctx.r[27].u32, 256 as u32, &mut ctx.xer);
	// 831DE21C: 40980084  bge cr6, 0x831de2a0
	if !ctx.cr[6].lt {
	pc = 0x831DE2A0; continue 'dispatch;
	}
	// 831DE220: 5767103A  slwi r7, r27, 2
	ctx.r[7].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DE224: 83C30008  lwz r30, 8(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DE228: 83A3000C  lwz r29, 0xc(r3)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DE22C: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 831DE230: 7FE72A14  add r31, r7, r5
	ctx.r[31].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 831DE234: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DE238: 213B0100  subfic r9, r27, 0x100
	ctx.xer.ca = ctx.r[27].u32 <= 256 as u32;
	ctx.r[9].s64 = (256 as i64) - ctx.r[27].s64;
	// 831DE23C: 7CE72214  add r7, r7, r4
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[4].u64;
	// 831DE240: 7D1E5050  subf r8, r30, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 831DE244: 389F0004  addi r4, r31, 4
	ctx.r[4].s64 = ctx.r[31].s64 + 4;
	// 831DE248: 7CC65A14  add r6, r6, r11
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 831DE24C: 7FFDF050  subf r31, r29, r30
	ctx.r[31].s64 = ctx.r[30].s64 - ctx.r[29].s64;
	// 831DE250: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 831DE254: 551E15BA  rlwinm r30, r8, 2, 0x16, 0x1d
	ctx.r[30].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE258: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DE25C: 7FBF4214  add r29, r31, r8
	ctx.r[29].u64 = ctx.r[31].u64 + ctx.r[8].u64;
	// 831DE260: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DE264: 57BD15BA  rlwinm r29, r29, 2, 0x16, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE268: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 831DE26C: 7D5E5C2E  lfsx f10, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DE270: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831DE274: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DE278: EDAD002A  fadds f13, f13, f0
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DE27C: 7D1D5C2E  lfsx f8, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DE280: D1660000  stfs f11, 0(r6)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE284: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 831DE288: ECE84B3A  fmadds f7, f8, f12, f9
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DE28C: D0E40000  stfs f7, 0(r4)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE290: ED8C0028  fsubs f12, f12, f0
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 831DE294: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DE298: 4082FFBC  bne 0x831de254
	if !ctx.cr[0].eq {
	pc = 0x831DE254; continue 'dispatch;
	}
	// 831DE29C: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE2A0: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831DE2A4: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831DE2A8: 4800009C  b 0x831de344
	pc = 0x831DE344; continue 'dispatch;
	// 831DE2AC: 7D6A5050  subf r11, r10, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[10].s64;
	// 831DE2B0: 83E30008  lwz r31, 8(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DE2B4: 83C3000C  lwz r30, 0xc(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DE2B8: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 831DE2BC: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 831DE2C0: FC006090  fmr f0, f12
	ctx.f[0].f64 = ctx.f[12].f64;
	// 831DE2C4: 7D7F5050  subf r11, r31, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE2C8: 7FFEF850  subf r31, r30, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[30].s64;
	// 831DE2CC: 3FC08212  lis r30, -0x7dee
	ctx.r[30].s64 = -2112749568;
	// 831DE2D0: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831DE2D4: C1A808A8  lfs f13, 0x8a8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DE2D8: 38C30020  addi r6, r3, 0x20
	ctx.r[6].s64 = ctx.r[3].s64 + 32;
	// 831DE2DC: EDAD6028  fsubs f13, f13, f12
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DE2E0: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DE2E4: 7D093214  add r8, r9, r6
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 831DE2E8: C19EDFA8  lfs f12, -0x2058(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-8280 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DE2EC: 7CE72A14  add r7, r7, r5
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[5].u64;
	// 831DE2F0: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 831DE2F4: 394A0100  addi r10, r10, 0x100
	ctx.r[10].s64 = ctx.r[10].s64 + 256;
	// 831DE2F8: 557E15BA  rlwinm r30, r11, 2, 0x16, 0x1d
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE2FC: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DE300: 7FBF5A14  add r29, r31, r11
	ctx.r[29].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 831DE304: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831DE308: 57BD15BA  rlwinm r29, r29, 2, 0x16, 0x1d
	ctx.r[29].u64 = ctx.r[29].u32 as u64 & 0x3FFFFFFFu64;
	// 831DE30C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DE310: 7D5E342E  lfsx f10, r30, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DE314: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 831DE318: ED2A0372  fmuls f9, f10, f13
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[13].f64) as f32) as f64);
	// 831DE31C: EDAD602A  fadds f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 831DE320: 7D1D342E  lfsx f8, r29, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DE324: D1680000  stfs f11, 0(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE328: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 831DE32C: ECE8483A  fmadds f7, f8, f0, f9
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DE330: D0E70000  stfs f7, 0(r7)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DE334: EC006028  fsubs f0, f0, f12
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 831DE338: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 831DE33C: 4082FFBC  bne 0x831de2f8
	if !ctx.cr[0].eq {
	pc = 0x831DE2F8; continue 'dispatch;
	}
	// 831DE340: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DE344: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831DE348: C0050400  lfs f0, 0x400(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(1024 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DE34C: D0030014  stfs f0, 0x14(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DE350: 91630018  stw r11, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831DE354: CBC1FF80  lfd f30, -0x80(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-128 as u32) ) };
	// 831DE358: CBE1FF88  lfd f31, -0x78(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-120 as u32) ) };
	// 831DE35C: 4BFC9E38  b 0x831a8194
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DE360(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DE360 size=88
    let mut pc: u32 = 0x831DE360;
    'dispatch: loop {
        match pc {
            0x831DE360 => {
    //   block [0x831DE360..0x831DE3B8)
	// 831DE360: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DE364: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DE368: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DE36C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DE370: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DE374: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DE378: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831DE37C: 392BFF64  addi r9, r11, -0x9c
	ctx.r[9].s64 = ctx.r[11].s64 + -156;
	// 831DE380: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831DE384: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DE388: 419A0018  beq cr6, 0x831de3a0
	if ctx.cr[6].eq {
	pc = 0x831DE3A0; continue 'dispatch;
	}
	// 831DE38C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DE390: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DE394: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DE398: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DE39C: 4BFFE325  bl 0x831dc6c0
	ctx.lr = 0x831DE3A0;
	sub_831DC6C0(ctx, base);
	// 831DE3A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DE3A4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DE3A8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DE3AC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DE3B0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DE3B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DE3B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DE3B8 size=20
    let mut pc: u32 = 0x831DE3B8;
    'dispatch: loop {
        match pc {
            0x831DE3B8 => {
    //   block [0x831DE3B8..0x831DE3CC)
	// 831DE3B8: 3D600004  lis r11, 4
	ctx.r[11].s64 = 262144;
	// 831DE3BC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DE3C0: 616BBAB0  ori r11, r11, 0xbab0
	ctx.r[11].u64 = ctx.r[11].u64 | 47792;
	// 831DE3C4: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831DE3C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DE3D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DE3D0 size=6008
    let mut pc: u32 = 0x831DE3D0;
    'dispatch: loop {
        match pc {
            0x831DE3D0 => {
    //   block [0x831DE3D0..0x831DFB48)
	// 831DE3D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DE3D4: 4BFC9D5D  bl 0x831a8130
	ctx.lr = 0x831DE3D8;
	sub_831A8130(ctx, base);
	// 831DE3D8: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 831DE3DC: 4BFCA665  bl 0x831a8a40
	ctx.lr = 0x831DE3E0;
	sub_831A8A40(ctx, base);
	// 831DE3E0: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 831DE3E4: E981E000  ld r12, -0x2000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8192 as u32) ) };
	// 831DE3E8: E981D000  ld r12, -0x3000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-12288 as u32) ) };
	// 831DE3EC: E981C000  ld r12, -0x4000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16384 as u32) ) };
	// 831DE3F0: 9421B9D0  stwu r1, -0x4630(r1)
	ea = ctx.r[1].u32.wrapping_add(-17968 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DE3F4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DE3F8: 93C14644  stw r30, 0x4644(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(17988 as u32), ctx.r[30].u32 ) };
	// 831DE3FC: 817E0064  lwz r11, 0x64(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(100 as u32) ) } as u64;
	// 831DE400: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 831DE404: 419A0024  beq cr6, 0x831de428
	if ctx.cr[6].eq {
	pc = 0x831DE428; continue 'dispatch;
	}
	// 831DE408: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 831DE40C: 419A0014  beq cr6, 0x831de420
	if ctx.cr[6].eq {
	pc = 0x831DE420; continue 'dispatch;
	}
	// 831DE410: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DE414: 83A40004  lwz r29, 4(r4)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DE418: 916100A0  stw r11, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 831DE41C: 48000018  b 0x831de434
	pc = 0x831DE434; continue 'dispatch;
	// 831DE420: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DE424: 48000008  b 0x831de42c
	pc = 0x831DE42C; continue 'dispatch;
	// 831DE428: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DE42C: 916100A0  stw r11, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u32 ) };
	// 831DE430: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 831DE434: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DE438: 81250004  lwz r9, 4(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DE43C: 8105000C  lwz r8, 0xc(r5)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DE440: 80E50010  lwz r7, 0x10(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DE444: 93A10098  stw r29, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[29].u32 ) };
	// 831DE448: 9141014C  stw r10, 0x14c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), ctx.r[10].u32 ) };
	// 831DE44C: 91210144  stw r9, 0x144(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), ctx.r[9].u32 ) };
	// 831DE450: 9101013C  stw r8, 0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), ctx.r[8].u32 ) };
	// 831DE454: 90E10134  stw r7, 0x134(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), ctx.r[7].u32 ) };
	// 831DE458: 7C005A2C  dcbt 0, r11
	// 831DE45C: 7C00EA2C  dcbt 0, r29
	// 831DE460: 38C00080  li r6, 0x80
	ctx.r[6].s64 = 128;
	// 831DE464: 7C065A2C  dcbt r6, r11
	// 831DE468: 38A00080  li r5, 0x80
	ctx.r[5].s64 = 128;
	// 831DE46C: 7C05EA2C  dcbt r5, r29
	// 831DE470: 38A11E40  addi r5, r1, 0x1e40
	ctx.r[5].s64 = ctx.r[1].s64 + 7744;
	// 831DE474: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 831DE478: 387E0068  addi r3, r30, 0x68
	ctx.r[3].s64 = ctx.r[30].s64 + 104;
	// 831DE47C: 4BFFE955  bl 0x831dcdd0
	ctx.lr = 0x831DE480;
	sub_831DCDD0(ctx, base);
	// 831DE480: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE484: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 831DE488: 38A126C0  addi r5, r1, 0x26c0
	ctx.r[5].s64 = ctx.r[1].s64 + 9920;
	// 831DE48C: 38811E40  addi r4, r1, 0x1e40
	ctx.r[4].s64 = ctx.r[1].s64 + 7744;
	// 831DE490: 386300A8  addi r3, r3, 0xa8
	ctx.r[3].s64 = ctx.r[3].s64 + 168;
	// 831DE494: 4BFFEF8D  bl 0x831dd420
	ctx.lr = 0x831DE498;
	sub_831DD420(ctx, base);
	// 831DE498: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE49C: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 831DE4A0: 38C11A30  addi r6, r1, 0x1a30
	ctx.r[6].s64 = ctx.r[1].s64 + 6704;
	// 831DE4A4: 38A101E0  addi r5, r1, 0x1e0
	ctx.r[5].s64 = ctx.r[1].s64 + 480;
	// 831DE4A8: 388126C0  addi r4, r1, 0x26c0
	ctx.r[4].s64 = ctx.r[1].s64 + 9920;
	// 831DE4AC: 386300F0  addi r3, r3, 0xf0
	ctx.r[3].s64 = ctx.r[3].s64 + 240;
	// 831DE4B0: 4BFFF081  bl 0x831dd530
	ctx.lr = 0x831DE4B4;
	sub_831DD530(ctx, base);
	// 831DE4B4: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE4B8: 388101E0  addi r4, r1, 0x1e0
	ctx.r[4].s64 = ctx.r[1].s64 + 480;
	// 831DE4BC: 3863091C  addi r3, r3, 0x91c
	ctx.r[3].s64 = ctx.r[3].s64 + 2332;
	// 831DE4C0: 4BFFF139  bl 0x831dd5f8
	ctx.lr = 0x831DE4C4;
	sub_831DD5F8(ctx, base);
	// 831DE4C4: 388140FF  addi r4, r1, 0x40ff
	ctx.r[4].s64 = ctx.r[1].s64 + 16639;
	// 831DE4C8: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE4CC: 549F0030  rlwinm r31, r4, 0, 0, 0x18
	ctx.r[31].u64 = ctx.r[4].u32 as u64 & 0xFFFFFFFFu64;
	// 831DE4D0: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 831DE4D4: 38C12F40  addi r6, r1, 0x2f40
	ctx.r[6].s64 = ctx.r[1].s64 + 12096;
	// 831DE4D8: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831DE4DC: 388101E0  addi r4, r1, 0x1e0
	ctx.r[4].s64 = ctx.r[1].s64 + 480;
	// 831DE4E0: 38630B34  addi r3, r3, 0xb34
	ctx.r[3].s64 = ctx.r[3].s64 + 2868;
	// 831DE4E4: 4BFFF3BD  bl 0x831dd8a0
	ctx.lr = 0x831DE4E8;
	sub_831DD8A0(ctx, base);
	// 831DE4E8: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE4EC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DE4F0: 38632B60  addi r3, r3, 0x2b60
	ctx.r[3].s64 = ctx.r[3].s64 + 11104;
	// 831DE4F4: 4BFFF475  bl 0x831dd968
	ctx.lr = 0x831DE4F8;
	sub_831DD968(ctx, base);
	// 831DE4F8: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE4FC: 38A11220  addi r5, r1, 0x1220
	ctx.r[5].s64 = ctx.r[1].s64 + 4640;
	// 831DE500: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DE504: 38632F78  addi r3, r3, 0x2f78
	ctx.r[3].s64 = ctx.r[3].s64 + 12152;
	// 831DE508: 4BFFF751  bl 0x831ddc58
	ctx.lr = 0x831DE50C;
	sub_831DDC58(ctx, base);
	// 831DE50C: 386137DF  addi r3, r1, 0x37df
	ctx.r[3].s64 = ctx.r[1].s64 + 14303;
	// 831DE510: 39413C6F  addi r10, r1, 0x3c6f
	ctx.r[10].s64 = ctx.r[1].s64 + 15471;
	// 831DE514: 546B0030  rlwinm r11, r3, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0xFFFFFFFFu64;
	// 831DE518: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE51C: 55450030  rlwinm r5, r10, 0, 0, 0x18
	ctx.r[5].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831DE520: 38CB0008  addi r6, r11, 8
	ctx.r[6].s64 = ctx.r[11].s64 + 8;
	// 831DE524: 38811220  addi r4, r1, 0x1220
	ctx.r[4].s64 = ctx.r[1].s64 + 4640;
	// 831DE528: 90A100E8  stw r5, 0xe8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[5].u32 ) };
	// 831DE52C: 38633790  addi r3, r3, 0x3790
	ctx.r[3].s64 = ctx.r[3].s64 + 14224;
	// 831DE530: 90C100DC  stw r6, 0xdc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), ctx.r[6].u32 ) };
	// 831DE534: 4BFFF89D  bl 0x831dddd0
	ctx.lr = 0x831DE538;
	sub_831DDDD0(ctx, base);
	// 831DE538: 3C7E0001  addis r3, r30, 1
	ctx.r[3].s64 = ctx.r[30].s64 + 65536;
	// 831DE53C: 38A11E40  addi r5, r1, 0x1e40
	ctx.r[5].s64 = ctx.r[1].s64 + 7744;
	// 831DE540: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831DE544: 38630088  addi r3, r3, 0x88
	ctx.r[3].s64 = ctx.r[3].s64 + 136;
	// 831DE548: 4BFFE889  bl 0x831dcdd0
	ctx.lr = 0x831DE54C;
	sub_831DCDD0(ctx, base);
	// 831DE54C: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE550: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 831DE554: 38A126C0  addi r5, r1, 0x26c0
	ctx.r[5].s64 = ctx.r[1].s64 + 9920;
	// 831DE558: 38811E40  addi r4, r1, 0x1e40
	ctx.r[4].s64 = ctx.r[1].s64 + 7744;
	// 831DE55C: 386300C8  addi r3, r3, 0xc8
	ctx.r[3].s64 = ctx.r[3].s64 + 200;
	// 831DE560: 4BFFEEC1  bl 0x831dd420
	ctx.lr = 0x831DE564;
	sub_831DD420(ctx, base);
	// 831DE564: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 831DE568: 38C11220  addi r6, r1, 0x1220
	ctx.r[6].s64 = ctx.r[1].s64 + 4640;
	// 831DE56C: 38A10A00  addi r5, r1, 0xa00
	ctx.r[5].s64 = ctx.r[1].s64 + 2560;
	// 831DE570: 388126C0  addi r4, r1, 0x26c0
	ctx.r[4].s64 = ctx.r[1].s64 + 9920;
	// 831DE574: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE578: 386347B8  addi r3, r3, 0x47b8
	ctx.r[3].s64 = ctx.r[3].s64 + 18360;
	// 831DE57C: 4BFFEFB5  bl 0x831dd530
	ctx.lr = 0x831DE580;
	sub_831DD530(ctx, base);
	// 831DE580: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE584: 38810A00  addi r4, r1, 0xa00
	ctx.r[4].s64 = ctx.r[1].s64 + 2560;
	// 831DE588: 38634FE4  addi r3, r3, 0x4fe4
	ctx.r[3].s64 = ctx.r[3].s64 + 20452;
	// 831DE58C: 4BFFF06D  bl 0x831dd5f8
	ctx.lr = 0x831DE590;
	sub_831DD5F8(ctx, base);
	// 831DE590: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE594: 38E00100  li r7, 0x100
	ctx.r[7].s64 = 256;
	// 831DE598: 38C13350  addi r6, r1, 0x3350
	ctx.r[6].s64 = ctx.r[1].s64 + 13136;
	// 831DE59C: 38A105F0  addi r5, r1, 0x5f0
	ctx.r[5].s64 = ctx.r[1].s64 + 1520;
	// 831DE5A0: 38810A00  addi r4, r1, 0xa00
	ctx.r[4].s64 = ctx.r[1].s64 + 2560;
	// 831DE5A4: 386351FC  addi r3, r3, 0x51fc
	ctx.r[3].s64 = ctx.r[3].s64 + 20988;
	// 831DE5A8: 4BFFF2F9  bl 0x831dd8a0
	ctx.lr = 0x831DE5AC;
	sub_831DD8A0(ctx, base);
	// 831DE5AC: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE5B0: 388105F0  addi r4, r1, 0x5f0
	ctx.r[4].s64 = ctx.r[1].s64 + 1520;
	// 831DE5B4: 38637228  addi r3, r3, 0x7228
	ctx.r[3].s64 = ctx.r[3].s64 + 29224;
	// 831DE5B8: 4BFFF3B1  bl 0x831dd968
	ctx.lr = 0x831DE5BC;
	sub_831DD968(ctx, base);
	// 831DE5BC: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE5C0: 38A10E10  addi r5, r1, 0xe10
	ctx.r[5].s64 = ctx.r[1].s64 + 3600;
	// 831DE5C4: 388105F0  addi r4, r1, 0x5f0
	ctx.r[4].s64 = ctx.r[1].s64 + 1520;
	// 831DE5C8: 38637640  addi r3, r3, 0x7640
	ctx.r[3].s64 = ctx.r[3].s64 + 30272;
	// 831DE5CC: 4BFFF68D  bl 0x831ddc58
	ctx.lr = 0x831DE5D0;
	sub_831DDC58(ctx, base);
	// 831DE5D0: 39211EBF  addi r9, r1, 0x1ebf
	ctx.r[9].s64 = ctx.r[1].s64 + 7871;
	// 831DE5D4: 3901273F  addi r8, r1, 0x273f
	ctx.r[8].s64 = ctx.r[1].s64 + 10047;
	// 831DE5D8: 552B0030  rlwinm r11, r9, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831DE5DC: 3C7E0002  addis r3, r30, 2
	ctx.r[3].s64 = ctx.r[30].s64 + 131072;
	// 831DE5E0: 55050030  rlwinm r5, r8, 0, 0, 0x18
	ctx.r[5].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831DE5E4: 38CB0008  addi r6, r11, 8
	ctx.r[6].s64 = ctx.r[11].s64 + 8;
	// 831DE5E8: 38810E10  addi r4, r1, 0xe10
	ctx.r[4].s64 = ctx.r[1].s64 + 3600;
	// 831DE5EC: 90A100E0  stw r5, 0xe0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[5].u32 ) };
	// 831DE5F0: 38637E58  addi r3, r3, 0x7e58
	ctx.r[3].s64 = ctx.r[3].s64 + 32344;
	// 831DE5F4: 90C100E4  stw r6, 0xe4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), ctx.r[6].u32 ) };
	// 831DE5F8: 90A100D8  stw r5, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[5].u32 ) };
	// 831DE5FC: 4BFFF7D5  bl 0x831dddd0
	ctx.lr = 0x831DE600;
	sub_831DDDD0(ctx, base);
	// 831DE600: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831DE604: 3CC00002  lis r6, 2
	ctx.r[6].s64 = 131072;
	// 831DE608: C01E0060  lfs f0, 0x60(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DE60C: 3CA00002  lis r5, 2
	ctx.r[5].s64 = 131072;
	// 831DE610: 3C800002  lis r4, 2
	ctx.r[4].s64 = 131072;
	// 831DE614: 60E347B0  ori r3, r7, 0x47b0
	ctx.r[3].u64 = ctx.r[7].u64 | 18352;
	// 831DE618: 60CB00EC  ori r11, r6, 0xec
	ctx.r[11].u64 = ctx.r[6].u64 | 236;
	// 831DE61C: 60AA47B4  ori r10, r5, 0x47b4
	ctx.r[10].u64 = ctx.r[5].u64 | 18356;
	// 831DE620: 608900E8  ori r9, r4, 0xe8
	ctx.r[9].u64 = ctx.r[4].u64 | 232;
	// 831DE624: 39010A00  addi r8, r1, 0xa00
	ctx.r[8].s64 = ctx.r[1].s64 + 2560;
	// 831DE628: 7DBE1C2E  lfsx f13, r30, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DE62C: 38E11A30  addi r7, r1, 0x1a30
	ctx.r[7].s64 = ctx.r[1].s64 + 6704;
	// 831DE630: 7D9E5C2E  lfsx f12, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DE634: 38C105F0  addi r6, r1, 0x5f0
	ctx.r[6].s64 = ctx.r[1].s64 + 1520;
	// 831DE638: 7D7E542E  lfsx f11, r30, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DE63C: 38A101E0  addi r5, r1, 0x1e0
	ctx.r[5].s64 = ctx.r[1].s64 + 480;
	// 831DE640: 7D5E4C2E  lfsx f10, r30, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DE644: 38811220  addi r4, r1, 0x1220
	ctx.r[4].s64 = ctx.r[1].s64 + 4640;
	// 831DE648: 38610A04  addi r3, r1, 0xa04
	ctx.r[3].s64 = ctx.r[1].s64 + 2564;
	// 831DE64C: 39611A34  addi r11, r1, 0x1a34
	ctx.r[11].s64 = ctx.r[1].s64 + 6708;
	// 831DE650: 394105F4  addi r10, r1, 0x5f4
	ctx.r[10].s64 = ctx.r[1].s64 + 1524;
	// 831DE654: 392101E4  addi r9, r1, 0x1e4
	ctx.r[9].s64 = ctx.r[1].s64 + 484;
	// 831DE658: 7D1F4050  subf r8, r31, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 831DE65C: 7CFF3850  subf r7, r31, r7
	ctx.r[7].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 831DE660: 7CDF3050  subf r6, r31, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 831DE664: 91010090  stw r8, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[8].u32 ) };
	// 831DE668: 3BC11224  addi r30, r1, 0x1224
	ctx.r[30].s64 = ctx.r[1].s64 + 4644;
	// 831DE66C: 90E10068  stw r7, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[7].u32 ) };
	// 831DE670: 3BA10A08  addi r29, r1, 0xa08
	ctx.r[29].s64 = ctx.r[1].s64 + 2568;
	// 831DE674: 90C10088  stw r6, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[6].u32 ) };
	// 831DE678: 3B9F0004  addi r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 4;
	// 831DE67C: 7CBF2850  subf r5, r31, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 831DE680: 7C9F2050  subf r4, r31, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 831DE684: 9381009C  stw r28, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[28].u32 ) };
	// 831DE688: 7C7F1850  subf r3, r31, r3
	ctx.r[3].s64 = ctx.r[3].s64 - ctx.r[31].s64;
	// 831DE68C: 90A10074  stw r5, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[5].u32 ) };
	// 831DE690: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE694: 908100B4  stw r4, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[4].u32 ) };
	// 831DE698: 7D5F5050  subf r10, r31, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE69C: 906100A4  stw r3, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[3].u32 ) };
	// 831DE6A0: 7D3F4850  subf r9, r31, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[31].s64;
	// 831DE6A4: 916100C0  stw r11, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[11].u32 ) };
	// 831DE6A8: 7D1FF050  subf r8, r31, r30
	ctx.r[8].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 831DE6AC: 91410078  stw r10, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[10].u32 ) };
	// 831DE6B0: 7CFFE850  subf r7, r31, r29
	ctx.r[7].s64 = ctx.r[29].s64 - ctx.r[31].s64;
	// 831DE6B4: 912100D0  stw r9, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[9].u32 ) };
	// 831DE6B8: 38C11A38  addi r6, r1, 0x1a38
	ctx.r[6].s64 = ctx.r[1].s64 + 6712;
	// 831DE6BC: 90E100BC  stw r7, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[7].u32 ) };
	// 831DE6C0: 38E11A40  addi r7, r1, 0x1a40
	ctx.r[7].s64 = ctx.r[1].s64 + 6720;
	// 831DE6C4: 392105FC  addi r9, r1, 0x5fc
	ctx.r[9].s64 = ctx.r[1].s64 + 1532;
	// 831DE6C8: 910100C8  stw r8, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[8].u32 ) };
	// 831DE6CC: 90E10050  stw r7, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u32 ) };
	// 831DE6D0: 3BC10600  addi r30, r1, 0x600
	ctx.r[30].s64 = ctx.r[1].s64 + 1536;
	// 831DE6D4: 83A10050  lwz r29, 0x50(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DE6D8: 7D3F4850  subf r9, r31, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[31].s64;
	// 831DE6DC: 93C10054  stw r30, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[30].u32 ) };
	// 831DE6E0: 38E101F0  addi r7, r1, 0x1f0
	ctx.r[7].s64 = ctx.r[1].s64 + 496;
	// 831DE6E4: 3B81122C  addi r28, r1, 0x122c
	ctx.r[28].s64 = ctx.r[1].s64 + 4652;
	// 831DE6E8: 912100A8  stw r9, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[9].u32 ) };
	// 831DE6EC: 3BC10A10  addi r30, r1, 0xa10
	ctx.r[30].s64 = ctx.r[1].s64 + 2576;
	// 831DE6F0: 90E10050  stw r7, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[7].u32 ) };
	// 831DE6F4: 390101EC  addi r8, r1, 0x1ec
	ctx.r[8].s64 = ctx.r[1].s64 + 492;
	// 831DE6F8: 83610054  lwz r27, 0x54(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DE6FC: 7D3FE050  subf r9, r31, r28
	ctx.r[9].s64 = ctx.r[28].s64 - ctx.r[31].s64;
	// 831DE700: 93C10050  stw r30, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 831DE704: 7D1F4050  subf r8, r31, r8
	ctx.r[8].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 831DE708: 57DE003E  slwi r30, r30, 0
	ctx.r[30].u32 = ctx.r[30].u32.wrapping_shl(0);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 831DE70C: 9121008C  stw r9, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[9].u32 ) };
	// 831DE710: 38A105F8  addi r5, r1, 0x5f8
	ctx.r[5].s64 = ctx.r[1].s64 + 1528;
	// 831DE714: 910100B0  stw r8, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[8].u32 ) };
	// 831DE718: 7D3FD850  subf r9, r31, r27
	ctx.r[9].s64 = ctx.r[27].s64 - ctx.r[31].s64;
	// 831DE71C: 388101E8  addi r4, r1, 0x1e8
	ctx.r[4].s64 = ctx.r[1].s64 + 488;
	// 831DE720: 9121005C  stw r9, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[9].u32 ) };
	// 831DE724: 38611228  addi r3, r1, 0x1228
	ctx.r[3].s64 = ctx.r[1].s64 + 4648;
	// 831DE728: 7D1FF050  subf r8, r31, r30
	ctx.r[8].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 831DE72C: 39610A0C  addi r11, r1, 0xa0c
	ctx.r[11].s64 = ctx.r[1].s64 + 2572;
	// 831DE730: 39411A3C  addi r10, r1, 0x1a3c
	ctx.r[10].s64 = ctx.r[1].s64 + 6716;
	// 831DE734: 91010084  stw r8, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[8].u32 ) };
	// 831DE738: 7CDF3050  subf r6, r31, r6
	ctx.r[6].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 831DE73C: 7CBF2850  subf r5, r31, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 831DE740: 7C9F2050  subf r4, r31, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 831DE744: 90C100CC  stw r6, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[6].u32 ) };
	// 831DE748: 7C7F1850  subf r3, r31, r3
	ctx.r[3].s64 = ctx.r[3].s64 - ctx.r[31].s64;
	// 831DE74C: 90A10080  stw r5, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[5].u32 ) };
	// 831DE750: 7FDFE850  subf r30, r31, r29
	ctx.r[30].s64 = ctx.r[29].s64 - ctx.r[31].s64;
	// 831DE754: 908100AC  stw r4, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[4].u32 ) };
	// 831DE758: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE75C: 906100C4  stw r3, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[3].u32 ) };
	// 831DE760: 7D5F5050  subf r10, r31, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE764: 93C10094  stw r30, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[30].u32 ) };
	// 831DE768: 39210E20  addi r9, r1, 0xe20
	ctx.r[9].s64 = ctx.r[1].s64 + 3616;
	// 831DE76C: 916100B8  stw r11, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u32 ) };
	// 831DE770: 54E7003E  slwi r7, r7, 0
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(0);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 831DE774: 914100D4  stw r10, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[10].u32 ) };
	// 831DE778: 39011640  addi r8, r1, 0x1640
	ctx.r[8].s64 = ctx.r[1].s64 + 5696;
	// 831DE77C: 91210050  stw r9, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u32 ) };
	// 831DE780: 38C11230  addi r6, r1, 0x1230
	ctx.r[6].s64 = ctx.r[1].s64 + 4656;
	// 831DE784: 38A10A14  addi r5, r1, 0xa14
	ctx.r[5].s64 = ctx.r[1].s64 + 2580;
	// 831DE788: 9101006C  stw r8, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[8].u32 ) };
	// 831DE78C: 38811A44  addi r4, r1, 0x1a44
	ctx.r[4].s64 = ctx.r[1].s64 + 6724;
	// 831DE790: 38610604  addi r3, r1, 0x604
	ctx.r[3].s64 = ctx.r[1].s64 + 1540;
	// 831DE794: 396101F4  addi r11, r1, 0x1f4
	ctx.r[11].s64 = ctx.r[1].s64 + 500;
	// 831DE798: 39411234  addi r10, r1, 0x1234
	ctx.r[10].s64 = ctx.r[1].s64 + 4660;
	// 831DE79C: 3BC11644  addi r30, r1, 0x1644
	ctx.r[30].s64 = ctx.r[1].s64 + 5700;
	// 831DE7A0: 7D3F3850  subf r9, r31, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 831DE7A4: 7D1F3050  subf r8, r31, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 831DE7A8: 93C10054  stw r30, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[30].u32 ) };
	// 831DE7AC: 7CFF2850  subf r7, r31, r5
	ctx.r[7].s64 = ctx.r[5].s64 - ctx.r[31].s64;
	// 831DE7B0: 7CDF2050  subf r6, r31, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[31].s64;
	// 831DE7B4: 7CBF1850  subf r5, r31, r3
	ctx.r[5].s64 = ctx.r[3].s64 - ctx.r[31].s64;
	// 831DE7B8: 3B410A18  addi r26, r1, 0xa18
	ctx.r[26].s64 = ctx.r[1].s64 + 2584;
	// 831DE7BC: 3B211A48  addi r25, r1, 0x1a48
	ctx.r[25].s64 = ctx.r[1].s64 + 6728;
	// 831DE7C0: 3B010608  addi r24, r1, 0x608
	ctx.r[24].s64 = ctx.r[1].s64 + 1544;
	// 831DE7C4: 3AE101F8  addi r23, r1, 0x1f8
	ctx.r[23].s64 = ctx.r[1].s64 + 504;
	// 831DE7C8: 3AC11238  addi r22, r1, 0x1238
	ctx.r[22].s64 = ctx.r[1].s64 + 4664;
	// 831DE7CC: 3AA11630  addi r21, r1, 0x1630
	ctx.r[21].s64 = ctx.r[1].s64 + 5680;
	// 831DE7D0: 3A810E10  addi r20, r1, 0xe10
	ctx.r[20].s64 = ctx.r[1].s64 + 3600;
	// 831DE7D4: 3A611634  addi r19, r1, 0x1634
	ctx.r[19].s64 = ctx.r[1].s64 + 5684;
	// 831DE7D8: 3A410E14  addi r18, r1, 0xe14
	ctx.r[18].s64 = ctx.r[1].s64 + 3604;
	// 831DE7DC: 3A211638  addi r17, r1, 0x1638
	ctx.r[17].s64 = ctx.r[1].s64 + 5688;
	// 831DE7E0: 3A010E18  addi r16, r1, 0xe18
	ctx.r[16].s64 = ctx.r[1].s64 + 3608;
	// 831DE7E4: 39E1163C  addi r15, r1, 0x163c
	ctx.r[15].s64 = ctx.r[1].s64 + 5692;
	// 831DE7E8: 39C10E1C  addi r14, r1, 0xe1c
	ctx.r[14].s64 = ctx.r[1].s64 + 3612;
	// 831DE7EC: 3BA10E24  addi r29, r1, 0xe24
	ctx.r[29].s64 = ctx.r[1].s64 + 3620;
	// 831DE7F0: 3B811648  addi r28, r1, 0x1648
	ctx.r[28].s64 = ctx.r[1].s64 + 5704;
	// 831DE7F4: 3B610E28  addi r27, r1, 0xe28
	ctx.r[27].s64 = ctx.r[1].s64 + 3624;
	// 831DE7F8: 7C9F5850  subf r4, r31, r11
	ctx.r[4].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE7FC: 7C7F5050  subf r3, r31, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE800: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DE804: 7FDFD050  subf r30, r31, r26
	ctx.r[30].s64 = ctx.r[26].s64 - ctx.r[31].s64;
	// 831DE808: 7F5FB050  subf r26, r31, r22
	ctx.r[26].s64 = ctx.r[22].s64 - ctx.r[31].s64;
	// 831DE80C: 93A10064  stw r29, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[29].u32 ) };
	// 831DE810: 7D5F5850  subf r10, r31, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE814: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DE818: 7EDF9050  subf r22, r31, r18
	ctx.r[22].s64 = ctx.r[18].s64 - ctx.r[31].s64;
	// 831DE81C: 93610060  stw r27, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[27].u32 ) };
	// 831DE820: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE824: 82410064  lwz r18, 0x64(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 831DE828: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831DE82C: 7FBFC850  subf r29, r31, r25
	ctx.r[29].s64 = ctx.r[25].s64 - ctx.r[31].s64;
	// 831DE830: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 831DE834: 7F3FA850  subf r25, r31, r21
	ctx.r[25].s64 = ctx.r[21].s64 - ctx.r[31].s64;
	// 831DE838: 81610060  lwz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831DE83C: 7F7FB850  subf r27, r31, r23
	ctx.r[27].s64 = ctx.r[23].s64 - ctx.r[31].s64;
	// 831DE840: 93810070  stw r28, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[28].u32 ) };
	// 831DE844: 7F9FC050  subf r28, r31, r24
	ctx.r[28].s64 = ctx.r[24].s64 - ctx.r[31].s64;
	// 831DE848: 81410070  lwz r10, 0x70(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 831DE84C: 7D5F5050  subf r10, r31, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE850: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831DE854: 7E5F9050  subf r18, r31, r18
	ctx.r[18].s64 = ctx.r[18].s64 - ctx.r[31].s64;
	// 831DE858: 8141006C  lwz r10, 0x6c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831DE85C: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 831DE860: 7EBF8850  subf r21, r31, r17
	ctx.r[21].s64 = ctx.r[17].s64 - ctx.r[31].s64;
	// 831DE864: 92410064  stw r18, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[18].u32 ) };
	// 831DE868: 7F1FA050  subf r24, r31, r20
	ctx.r[24].s64 = ctx.r[20].s64 - ctx.r[31].s64;
	// 831DE86C: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 831DE870: 7EFF9850  subf r23, r31, r19
	ctx.r[23].s64 = ctx.r[19].s64 - ctx.r[31].s64;
	// 831DE874: 8161009C  lwz r11, 0x9c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DE878: 7E3F5050  subf r17, r31, r10
	ctx.r[17].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 831DE87C: 7E9F8050  subf r20, r31, r16
	ctx.r[20].s64 = ctx.r[16].s64 - ctx.r[31].s64;
	// 831DE880: 7E7F7850  subf r19, r31, r15
	ctx.r[19].s64 = ctx.r[15].s64 - ctx.r[31].s64;
	// 831DE884: 7E5F7050  subf r18, r31, r14
	ctx.r[18].s64 = ctx.r[14].s64 - ctx.r[31].s64;
	// 831DE888: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DE88C: 83E10088  lwz r31, 0x88(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 831DE890: 3A0105F0  addi r16, r1, 0x5f0
	ctx.r[16].s64 = ctx.r[1].s64 + 1520;
	// 831DE894: 81E10078  lwz r15, 0x78(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 831DE898: C12BFFFC  lfs f9, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DE89C: C10B0004  lfs f8, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DE8A0: 81C10080  lwz r14, 0x80(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 831DE8A4: C0EB0008  lfs f7, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DE8A8: ECC90332  fmuls f6, f9, f12
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DE8AC: EC880332  fmuls f4, f8, f12
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DE8B0: FA2100F0  std r17, 0xf0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[17].u64 ) };
	// 831DE8B4: 7C7F5C2E  lfsx f3, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DE8B8: EC470332  fmuls f2, f7, f12
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DE8BC: 7C2F5C2E  lfsx f1, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DE8C0: ED2302F2  fmuls f9, f3, f11
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE8C4: 7D0A842E  lfsx f8, r10, r16
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[16].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DE8C8: 83E10090  lwz r31, 0x90(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 831DE8CC: 82010068  lwz r16, 0x68(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 831DE8D0: ECE102F2  fmuls f7, f1, f11
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE8D4: 81E10074  lwz r15, 0x74(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 831DE8D8: EC2802F2  fmuls f1, f8, f11
	ctx.f[1].f64 = (((ctx.f[8].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE8DC: 822100A4  lwz r17, 0xa4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) } as u64;
	// 831DE8E0: 7C6E5C2E  lfsx f3, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DE8E4: FA610108  std r19, 0x108(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), ctx.r[19].u64 ) };
	// 831DE8E8: ED0302F2  fmuls f8, f3, f11
	ctx.f[8].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE8EC: FA4100F8  std r18, 0xf8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), ctx.r[18].u64 ) };
	// 831DE8F0: 3A4101E0  addi r18, r1, 0x1e0
	ctx.r[18].s64 = ctx.r[1].s64 + 480;
	// 831DE8F4: 826100D0  lwz r19, 0xd0(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) } as u64;
	// 831DE8F8: 7FF05C2E  lfsx f31, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE8FC: 7C7F5C2E  lfsx f3, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DE900: 83E100AC  lwz r31, 0xac(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) } as u64;
	// 831DE904: C0AB000C  lfs f5, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DE908: 820100B8  lwz r16, 0xb8(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 831DE90C: 7FCF5C2E  lfsx f30, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE910: 39C10A00  addi r14, r1, 0xa00
	ctx.r[14].s64 = ctx.r[1].s64 + 2560;
	// 831DE914: 7FB15C2E  lfsx f29, r17, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE918: ECA50332  fmuls f5, f5, f12
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DE91C: ED3E4ABA  fmadds f9, f30, f10, f9
	ctx.f[9].f64 = (((ctx.f[30].f64 * ctx.f[10].f64 + ctx.f[9].f64) as f32) as f64);
	// 831DE920: 7FCA942E  lfsx f30, r10, r18
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[18].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE924: EC9D237A  fmadds f4, f29, f13, f4
	ctx.f[4].f64 = (((ctx.f[29].f64 * ctx.f[13].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DE928: 7FB35C2E  lfsx f29, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE92C: FAA10128  std r21, 0x128(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), ctx.r[21].u64 ) };
	// 831DE930: EC63FB7A  fmadds f3, f3, f13, f31
	ctx.f[3].f64 = (((ctx.f[3].f64 * ctx.f[13].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DE934: 82A100BC  lwz r21, 0xbc(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 831DE938: EC3E0ABA  fmadds f1, f30, f10, f1
	ctx.f[1].f64 = (((ctx.f[30].f64 * ctx.f[10].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DE93C: ECFD3ABA  fmadds f7, f29, f10, f7
	ctx.f[7].f64 = (((ctx.f[29].f64 * ctx.f[10].f64 + ctx.f[7].f64) as f32) as f64);
	// 831DE940: 7FDF5C2E  lfsx f30, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE944: 7FB05C2E  lfsx f29, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE948: FA810118  std r20, 0x118(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[20].u64 ) };
	// 831DE94C: 7FEA742E  lfsx f31, r10, r14
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[14].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE950: 83E100B4  lwz r31, 0xb4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 831DE954: 820100C0  lwz r16, 0xc0(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 831DE958: 3A811A30  addi r20, r1, 0x1a30
	ctx.r[20].s64 = ctx.r[1].s64 + 6704;
	// 831DE95C: ECDF337A  fmadds f6, f31, f13, f6
	ctx.f[6].f64 = (((ctx.f[31].f64 * ctx.f[13].f64 + ctx.f[6].f64) as f32) as f64);
	// 831DE960: 7FF55C2E  lfsx f31, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE964: EC5F137A  fmadds f2, f31, f13, f2
	ctx.f[2].f64 = (((ctx.f[31].f64 * ctx.f[13].f64 + ctx.f[2].f64) as f32) as f64);
	// 831DE968: 39C11220  addi r14, r1, 0x1220
	ctx.r[14].s64 = ctx.r[1].s64 + 4640;
	// 831DE96C: ECBD2B7A  fmadds f5, f29, f13, f5
	ctx.f[5].f64 = (((ctx.f[29].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DE970: 81E100C8  lwz r15, 0xc8(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 831DE974: 7FBF5C2E  lfsx f29, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE978: 82A100CC  lwz r21, 0xcc(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 831DE97C: 7FEAA42E  lfsx f31, r10, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE980: 828100C4  lwz r20, 0xc4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) } as u64;
	// 831DE984: 7F905C2E  lfsx f28, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DE988: 826100D4  lwz r19, 0xd4(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) } as u64;
	// 831DE98C: 83E100A8  lwz r31, 0xa8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) } as u64;
	// 831DE990: ED1E42BA  fmadds f8, f30, f10, f8
	ctx.f[8].f64 = (((ctx.f[30].f64 * ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64);
	// 831DE994: 820100B0  lwz r16, 0xb0(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 831DE998: C3CB0000  lfs f30, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE99C: 7F6A742E  lfsx f27, r10, r14
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[14].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831DE9A0: EC6C1FBA  fmadds f3, f12, f30, f3
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[30].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DE9A4: 7F4F5C2E  lfsx f26, r15, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831DE9A8: ED29E82A  fadds f9, f9, f29
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[29].f64) as f32) as f64;
	// 831DE9AC: ECC6F82A  fadds f6, f6, f31
	ctx.f[6].f64 = ((ctx.f[6].f64 + ctx.f[31].f64) as f32) as f64;
	// 831DE9B0: 7F355C2E  lfsx f25, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831DE9B4: EC84E02A  fadds f4, f4, f28
	ctx.f[4].f64 = ((ctx.f[4].f64 + ctx.f[28].f64) as f32) as f64;
	// 831DE9B8: 7FD45C2E  lfsx f30, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE9BC: 7FB35C2E  lfsx f29, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE9C0: 39E11630  addi r15, r1, 0x1630
	ctx.r[15].s64 = ctx.r[1].s64 + 5680;
	// 831DE9C4: 7FFF5C2E  lfsx f31, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DE9C8: EC21D82A  fadds f1, f1, f27
	ctx.f[1].f64 = ((ctx.f[1].f64 + ctx.f[27].f64) as f32) as f64;
	// 831DE9CC: 7F905C2E  lfsx f28, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DE9D0: 8201005C  lwz r16, 0x5c(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831DE9D4: ED08F02A  fadds f8, f8, f30
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[30].f64) as f32) as f64;
	// 831DE9D8: C3CB0010  lfs f30, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DE9DC: EFFF02F2  fmuls f31, f31, f11
	ctx.f[31].f64 = (((ctx.f[31].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DE9E0: EFDE0332  fmuls f30, f30, f12
	ctx.f[30].f64 = (((ctx.f[30].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DE9E4: 7F655C2E  lfsx f27, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831DE9E8: ECA5E82A  fadds f5, f5, f29
	ctx.f[5].f64 = ((ctx.f[5].f64 + ctx.f[29].f64) as f32) as f64;
	// 831DE9EC: C3AB0014  lfs f29, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DE9F0: ECE7D02A  fadds f7, f7, f26
	ctx.f[7].f64 = ((ctx.f[7].f64 + ctx.f[26].f64) as f32) as f64;
	// 831DE9F4: C34B0018  lfs f26, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831DE9F8: 7F105C2E  lfsx f24, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 831DE9FC: 82010084  lwz r16, 0x84(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 831DEA00: EFBD0332  fmuls f29, f29, f12
	ctx.f[29].f64 = (((ctx.f[29].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DEA04: 81C1008C  lwz r14, 0x8c(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 831DEA08: EF7B02F2  fmuls f27, f27, f11
	ctx.f[27].f64 = (((ctx.f[27].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DEA0C: 82A10094  lwz r21, 0x94(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) } as u64;
	// 831DEA10: EC42C82A  fadds f2, f2, f25
	ctx.f[2].f64 = ((ctx.f[2].f64 + ctx.f[25].f64) as f32) as f64;
	// 831DEA14: 7F3C5C2E  lfsx f25, r28, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831DEA18: EF5A0332  fmuls f26, f26, f12
	ctx.f[26].f64 = (((ctx.f[26].f64 * ctx.f[12].f64) as f32) as f64);
	// 831DEA1C: 7EC75C2E  lfsx f22, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 831DEA20: 7E705C2E  lfsx f19, r16, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 831DEA24: EF3902F2  fmuls f25, f25, f11
	ctx.f[25].f64 = (((ctx.f[25].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DEA28: EFFCFABA  fmadds f31, f28, f10, f31
	ctx.f[31].f64 = (((ctx.f[28].f64 * ctx.f[10].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DEA2C: 7EA45C2E  lfsx f21, r4, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 831DEA30: EFD3F37A  fmadds f30, f19, f13, f30
	ctx.f[30].f64 = (((ctx.f[19].f64 * ctx.f[13].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DEA34: 7E9E5C2E  lfsx f20, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 831DEA38: EF1802F2  fmuls f24, f24, f11
	ctx.f[24].f64 = (((ctx.f[24].f64 * ctx.f[11].f64) as f32) as f64);
	// 831DEA3C: 7EE95C2E  lfsx f23, r9, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 831DEA40: 82810050  lwz r20, 0x50(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DEA44: 7F9B5C2E  lfsx f28, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DEA48: ECC60032  fmuls f6, f6, f0
	ctx.f[6].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEA4C: 7CCA7D2E  stfsx f6, r10, r15
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[15].u32), tmp.u32) };
	// 831DEA50: EFB6EB7A  fmadds f29, f22, f13, f29
	ctx.f[29].f64 = (((ctx.f[22].f64 * ctx.f[13].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DEA54: 7ECE5C2E  lfsx f22, r14, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 831DEA58: EF75DABA  fmadds f27, f21, f10, f27
	ctx.f[27].f64 = (((ctx.f[21].f64 * ctx.f[10].f64 + ctx.f[27].f64) as f32) as f64);
	// 831DEA5C: 7EB55C2E  lfsx f21, r21, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 831DEA60: 82A10070  lwz r21, 0x70(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 831DEA64: 3BE10E10  addi r31, r1, 0xe10
	ctx.r[31].s64 = ctx.r[1].s64 + 3600;
	// 831DEA68: EF54D37A  fmadds f26, f20, f13, f26
	ctx.f[26].f64 = (((ctx.f[20].f64 * ctx.f[13].f64 + ctx.f[26].f64) as f32) as f64);
	// 831DEA6C: 92810060  stw r20, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[20].u32 ) };
	// 831DEA70: EF9CCABA  fmadds f28, f28, f10, f25
	ctx.f[28].f64 = (((ctx.f[28].f64 * ctx.f[10].f64 + ctx.f[25].f64) as f32) as f64);
	// 831DEA74: EA810118  ld r20, 0x118(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) };
	// 831DEA78: EFFFB02A  fadds f31, f31, f22
	ctx.f[31].f64 = ((ctx.f[31].f64 + ctx.f[22].f64) as f32) as f64;
	// 831DEA7C: EA610108  ld r19, 0x108(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) };
	// 831DEA80: ECDEA82A  fadds f6, f30, f21
	ctx.f[6].f64 = ((ctx.f[30].f64 + ctx.f[21].f64) as f32) as f64;
	// 831DEA84: EA4100F8  ld r18, 0xf8(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) };
	// 831DEA88: EF17C2BA  fmadds f24, f23, f10, f24
	ctx.f[24].f64 = (((ctx.f[23].f64 * ctx.f[10].f64 + ctx.f[24].f64) as f32) as f64);
	// 831DEA8C: 92A1006C  stw r21, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[21].u32 ) };
	// 831DEA90: EAA10128  ld r21, 0x128(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(296 as u32) ) };
	// 831DEA94: EC210032  fmuls f1, f1, f0
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEA98: 7EE65C2E  lfsx f23, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 831DEA9C: EC630032  fmuls f3, f3, f0
	ctx.f[3].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAA0: 7C2AFD2E  stfsx f1, r10, r31
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32), tmp.u32) };
	// 831DEAA4: EC290032  fmuls f1, f9, f0
	ctx.f[1].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAA8: 7F235C2E  lfsx f25, r3, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831DEAAC: ED240032  fmuls f9, f4, f0
	ctx.f[9].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAB0: 7E7D5C2E  lfsx f19, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 831DEAB4: EFDDB82A  fadds f30, f29, f23
	ctx.f[30].f64 = ((ctx.f[29].f64 + ctx.f[23].f64) as f32) as f64;
	// 831DEAB8: 7E885C2E  lfsx f20, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 831DEABC: EC820032  fmuls f4, f2, f0
	ctx.f[4].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAC0: 7E5A5C2E  lfsx f18, r26, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 831DEAC4: EFBBC82A  fadds f29, f27, f25
	ctx.f[29].f64 = ((ctx.f[27].f64 + ctx.f[25].f64) as f32) as f64;
	// 831DEAC8: 7C795D2E  stfsx f3, r25, r11
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[25].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEACC: EF7A982A  fadds f27, f26, f19
	ctx.f[27].f64 = ((ctx.f[26].f64 + ctx.f[19].f64) as f32) as f64;
	// 831DEAD0: 7C385D2E  stfsx f1, r24, r11
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[24].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEAD4: ECE70032  fmuls f7, f7, f0
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAD8: 7D375D2E  stfsx f9, r23, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[23].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEADC: EC680032  fmuls f3, f8, f0
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAE0: EC450032  fmuls f2, f5, f0
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAE4: 82010054  lwz r16, 0x54(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DEAE8: EC3F0032  fmuls f1, f31, f0
	ctx.f[1].f64 = (((ctx.f[31].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEAEC: 81C10064  lwz r14, 0x64(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 831DEAF0: 7CF65D2E  stfsx f7, r22, r11
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[22].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEAF4: EF58A02A  fadds f26, f24, f20
	ctx.f[26].f64 = ((ctx.f[24].f64 + ctx.f[20].f64) as f32) as f64;
	// 831DEAF8: 7C955D2E  stfsx f4, r21, r11
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[21].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEAFC: EF9C902A  fadds f28, f28, f18
	ctx.f[28].f64 = ((ctx.f[28].f64 + ctx.f[18].f64) as f32) as f64;
	// 831DEB00: 7C745D2E  stfsx f3, r20, r11
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB04: 394A0020  addi r10, r10, 0x20
	ctx.r[10].s64 = ctx.r[10].s64 + 32;
	// 831DEB08: 7C535D2E  stfsx f2, r19, r11
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB0C: ED260032  fmuls f9, f6, f0
	ctx.f[9].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB10: 7C325D2E  stfsx f1, r18, r11
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[18].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB14: 83E10060  lwz r31, 0x60(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831DEB18: ED1A0032  fmuls f8, f26, f0
	ctx.f[8].f64 = (((ctx.f[26].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB1C: ECBB0032  fmuls f5, f27, f0
	ctx.f[5].f64 = (((ctx.f[27].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB20: EA2100F0  ld r17, 0xf0(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	// 831DEB24: ECFE0032  fmuls f7, f30, f0
	ctx.f[7].f64 = (((ctx.f[30].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB28: 7CF05D2E  stfsx f7, r16, r11
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB2C: ECDD0032  fmuls f6, f29, f0
	ctx.f[6].f64 = (((ctx.f[29].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB30: 7CCE5D2E  stfsx f6, r14, r11
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB34: EC9C0032  fmuls f4, f28, f0
	ctx.f[4].f64 = (((ctx.f[28].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DEB38: 2F0A0400  cmpwi cr6, r10, 0x400
	ctx.cr[6].compare_i32(ctx.r[10].s32, 1024, &mut ctx.xer);
	// 831DEB3C: 7D1F5D2E  stfsx f8, r31, r11
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB40: 83E1006C  lwz r31, 0x6c(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831DEB44: 7D315D2E  stfsx f9, r17, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB48: 7CBF5D2E  stfsx f5, r31, r11
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB4C: 83E10058  lwz r31, 0x58(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DEB50: 7C9F5D2E  stfsx f4, r31, r11
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DEB54: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831DEB58: 4198FD34  blt cr6, 0x831de88c
	if ctx.cr[6].lt {
	pc = 0x831DE88C; continue 'dispatch;
	}
	// 831DEB5C: 81614644  lwz r11, 0x4644(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(17988 as u32) ) } as u64;
	// 831DEB60: 3D400002  lis r10, 2
	ctx.r[10].s64 = 131072;
	// 831DEB64: 3D200002  lis r9, 2
	ctx.r[9].s64 = 131072;
	// 831DEB68: 3CCB0003  addis r6, r11, 3
	ctx.r[6].s64 = ctx.r[11].s64 + 196608;
	// 831DEB6C: 6145969C  ori r5, r10, 0x969c
	ctx.r[5].u64 = ctx.r[10].u64 | 38556;
	// 831DEB70: 38C69690  addi r6, r6, -0x6970
	ctx.r[6].s64 = ctx.r[6].s64 + -26992;
	// 831DEB74: 3D000002  lis r8, 2
	ctx.r[8].s64 = 131072;
	// 831DEB78: 90A10058  stw r5, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[5].u32 ) };
	// 831DEB7C: 3CE00002  lis r7, 2
	ctx.r[7].s64 = 131072;
	// 831DEB80: 90C1006C  stw r6, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[6].u32 ) };
	// 831DEB84: 61249EB0  ori r4, r9, 0x9eb0
	ctx.r[4].u64 = ctx.r[9].u64 | 40624;
	// 831DEB88: 61039ED0  ori r3, r8, 0x9ed0
	ctx.r[3].u64 = ctx.r[8].u64 | 40656;
	// 831DEB8C: 60E99EE4  ori r9, r7, 0x9ee4
	ctx.r[9].u64 = ctx.r[7].u64 | 40676;
	// 831DEB90: 90810094  stw r4, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[4].u32 ) };
	// 831DEB94: 9061008C  stw r3, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[3].u32 ) };
	// 831DEB98: 7D7F5B78  mr r31, r11
	ctx.r[31].u64 = ctx.r[11].u64;
	// 831DEB9C: 91210084  stw r9, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[9].u32 ) };
	// 831DEBA0: 3D4B0003  addis r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 196608;
	// 831DEBA4: 3D0B0003  addis r8, r11, 3
	ctx.r[8].s64 = ctx.r[11].s64 + 196608;
	// 831DEBA8: 394A8E78  addi r10, r10, -0x7188
	ctx.r[10].s64 = ctx.r[10].s64 + -29064;
	// 831DEBAC: 3CBF0003  addis r5, r31, 3
	ctx.r[5].s64 = ctx.r[31].s64 + 196608;
	// 831DEBB0: 39089EA8  addi r8, r8, -0x6158
	ctx.r[8].s64 = ctx.r[8].s64 + -24920;
	// 831DEBB4: 9141009C  stw r10, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[10].u32 ) };
	// 831DEBB8: 3C9F0003  addis r4, r31, 3
	ctx.r[4].s64 = ctx.r[31].s64 + 196608;
	// 831DEBBC: 38EA0010  addi r7, r10, 0x10
	ctx.r[7].s64 = ctx.r[10].s64 + 16;
	// 831DEBC0: 91010148  stw r8, 0x148(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), ctx.r[8].u32 ) };
	// 831DEBC4: 38A58E84  addi r5, r5, -0x717c
	ctx.r[5].s64 = ctx.r[5].s64 + -29052;
	// 831DEBC8: 3D5F0003  addis r10, r31, 3
	ctx.r[10].s64 = ctx.r[31].s64 + 196608;
	// 831DEBCC: 90E1005C  stw r7, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[7].u32 ) };
	// 831DEBD0: 38849F04  addi r4, r4, -0x60fc
	ctx.r[4].s64 = ctx.r[4].s64 + -24828;
	// 831DEBD4: 90A100CC  stw r5, 0xcc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), ctx.r[5].u32 ) };
	// 831DEBD8: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831DEBDC: 3D1F0003  addis r8, r31, 3
	ctx.r[8].s64 = ctx.r[31].s64 + 196608;
	// 831DEBE0: 908100BC  stw r4, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[4].u32 ) };
	// 831DEBE4: 394ADF40  addi r10, r10, -0x20c0
	ctx.r[10].s64 = ctx.r[10].s64 + -8384;
	// 831DEBE8: 90C10074  stw r6, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[6].u32 ) };
	// 831DEBEC: 3CBF0003  addis r5, r31, 3
	ctx.r[5].s64 = ctx.r[31].s64 + 196608;
	// 831DEBF0: 3908EF6C  addi r8, r8, -0x1094
	ctx.r[8].s64 = ctx.r[8].s64 + -4244;
	// 831DEBF4: 914100A4  stw r10, 0xa4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), ctx.r[10].u32 ) };
	// 831DEBF8: 3C7F0003  addis r3, r31, 3
	ctx.r[3].s64 = ctx.r[31].s64 + 196608;
	// 831DEBFC: 8141006C  lwz r10, 0x6c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831DEC00: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831DEC04: 91010154  stw r8, 0x154(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), ctx.r[8].u32 ) };
	// 831DEC08: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 831DEC0C: 81010058  lwz r8, 0x58(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DEC10: 3CFF0003  addis r7, r31, 3
	ctx.r[7].s64 = ctx.r[31].s64 + 196608;
	// 831DEC14: 3CDF0003  addis r6, r31, 3
	ctx.r[6].s64 = ctx.r[31].s64 + 196608;
	// 831DEC18: 3C9F0003  addis r4, r31, 3
	ctx.r[4].s64 = ctx.r[31].s64 + 196608;
	// 831DEC1C: 38A5EFC0  addi r5, r5, -0x1040
	ctx.r[5].s64 = ctx.r[5].s64 + -4160;
	// 831DEC20: 3863DF24  addi r3, r3, -0x20dc
	ctx.r[3].s64 = ctx.r[3].s64 + -8412;
	// 831DEC24: 396B9F10  addi r11, r11, -0x60f0
	ctx.r[11].s64 = ctx.r[11].s64 + -24816;
	// 831DEC28: 90A10160  stw r5, 0x160(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), ctx.r[5].u32 ) };
	// 831DEC2C: 3929E758  addi r9, r9, -0x18a8
	ctx.r[9].s64 = ctx.r[9].s64 + -6312;
	// 831DEC30: 906100D0  stw r3, 0xd0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[3].u32 ) };
	// 831DEC34: 38E7EF8C  addi r7, r7, -0x1074
	ctx.r[7].s64 = ctx.r[7].s64 + -4212;
	// 831DEC38: 916100B0  stw r11, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[11].u32 ) };
	// 831DEC3C: 38C6EFA0  addi r6, r6, -0x1060
	ctx.r[6].s64 = ctx.r[6].s64 + -4192;
	// 831DEC40: 91210130  stw r9, 0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[9].u32 ) };
	// 831DEC44: 38842FE0  addi r4, r4, 0x2fe0
	ctx.r[4].s64 = ctx.r[4].s64 + 12256;
	// 831DEC48: 90E10158  stw r7, 0x158(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), ctx.r[7].u32 ) };
	// 831DEC4C: 38AA0010  addi r5, r10, 0x10
	ctx.r[5].s64 = ctx.r[10].s64 + 16;
	// 831DEC50: 90C10100  stw r6, 0x100(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), ctx.r[6].u32 ) };
	// 831DEC54: 7D5F4214  add r10, r31, r8
	ctx.r[10].u64 = ctx.r[31].u64 + ctx.r[8].u64;
	// 831DEC58: 90810110  stw r4, 0x110(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[4].u32 ) };
	// 831DEC5C: 80C10094  lwz r6, 0x94(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) } as u64;
	// 831DEC60: 3C7F0003  addis r3, r31, 3
	ctx.r[3].s64 = ctx.r[31].s64 + 196608;
	// 831DEC64: 8081008C  lwz r4, 0x8c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 831DEC68: 3D7F0003  addis r11, r31, 3
	ctx.r[11].s64 = ctx.r[31].s64 + 196608;
	// 831DEC6C: 81010084  lwz r8, 0x84(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 831DEC70: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 831DEC74: 3CFF0003  addis r7, r31, 3
	ctx.r[7].s64 = ctx.r[31].s64 + 196608;
	// 831DEC78: 90A10058  stw r5, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[5].u32 ) };
	// 831DEC7C: 3863EFCC  addi r3, r3, -0x1034
	ctx.r[3].s64 = ctx.r[3].s64 + -4148;
	// 831DEC80: 914100C8  stw r10, 0xc8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[10].u32 ) };
	// 831DEC84: 396B2FFC  addi r11, r11, 0x2ffc
	ctx.r[11].s64 = ctx.r[11].s64 + 12284;
	// 831DEC88: 39295018  addi r9, r9, 0x5018
	ctx.r[9].s64 = ctx.r[9].s64 + 20504;
	// 831DEC8C: 38E77030  addi r7, r7, 0x7030
	ctx.r[7].s64 = ctx.r[7].s64 + 28720;
	// 831DEC90: 7CDF3214  add r6, r31, r6
	ctx.r[6].u64 = ctx.r[31].u64 + ctx.r[6].u64;
	// 831DEC94: 7C9F2214  add r4, r31, r4
	ctx.r[4].u64 = ctx.r[31].u64 + ctx.r[4].u64;
	// 831DEC98: 7D1F4214  add r8, r31, r8
	ctx.r[8].u64 = ctx.r[31].u64 + ctx.r[8].u64;
	// 831DEC9C: 3CBF0004  addis r5, r31, 4
	ctx.r[5].s64 = ctx.r[31].s64 + 262144;
	// 831DECA0: 3F9F0004  addis r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 262144;
	// 831DECA4: 90C100C0  stw r6, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[6].u32 ) };
	// 831DECA8: 908100B4  stw r4, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[4].u32 ) };
	// 831DECAC: 3D5F0004  addis r10, r31, 4
	ctx.r[10].s64 = ctx.r[31].s64 + 262144;
	// 831DECB0: 3B9C40E8  addi r28, r28, 0x40e8
	ctx.r[28].s64 = ctx.r[28].s64 + 16616;
	// 831DECB4: 91210120  stw r9, 0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[9].u32 ) };
	// 831DECB8: 3CDF0004  addis r6, r31, 4
	ctx.r[6].s64 = ctx.r[31].s64 + 262144;
	// 831DECBC: 906100A8  stw r3, 0xa8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[3].u32 ) };
	// 831DECC0: 3C9F0004  addis r4, r31, 4
	ctx.r[4].s64 = ctx.r[31].s64 + 262144;
	// 831DECC4: 93810188  stw r28, 0x188(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), ctx.r[28].u32 ) };
	// 831DECC8: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 831DECCC: 90E10170  stw r7, 0x170(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), ctx.r[7].u32 ) };
	// 831DECD0: 38A59048  addi r5, r5, -0x6fb8
	ctx.r[5].s64 = ctx.r[5].s64 + -28600;
	// 831DECD4: 830100D8  lwz r24, 0xd8(r1)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) } as u64;
	// 831DECD8: 3929E74C  addi r9, r9, -0x18b4
	ctx.r[9].s64 = ctx.r[9].s64 + -6324;
	// 831DECDC: 910100B8  stw r8, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[8].u32 ) };
	// 831DECE0: 394AA05C  addi r10, r10, -0x5fa4
	ctx.r[10].s64 = ctx.r[10].s64 + -24484;
	// 831DECE4: 90A100EC  stw r5, 0xec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), ctx.r[5].u32 ) };
	// 831DECE8: 38C6E078  addi r6, r6, -0x1f88
	ctx.r[6].s64 = ctx.r[6].s64 + -8072;
	// 831DECEC: 912101A0  stw r9, 0x1a0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(416 as u32), ctx.r[9].u32 ) };
	// 831DECF0: 3884E09C  addi r4, r4, -0x1f64
	ctx.r[4].s64 = ctx.r[4].s64 + -8036;
	// 831DECF4: 91410178  stw r10, 0x178(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), ctx.r[10].u32 ) };
	// 831DECF8: 3FDF0004  addis r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 262144;
	// 831DECFC: 90C10084  stw r6, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[6].u32 ) };
	// 831DED00: 3F7F0004  addis r27, r31, 4
	ctx.r[27].s64 = ctx.r[31].s64 + 262144;
	// 831DED04: 90810094  stw r4, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[4].u32 ) };
	// 831DED08: 3F5F0005  addis r26, r31, 5
	ctx.r[26].s64 = ctx.r[31].s64 + 327680;
	// 831DED0C: 91610168  stw r11, 0x168(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), ctx.r[11].u32 ) };
	// 831DED10: 3F3F0004  addis r25, r31, 4
	ctx.r[25].s64 = ctx.r[31].s64 + 262144;
	// 831DED14: 816100E8  lwz r11, 0xe8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) } as u64;
	// 831DED18: 3EFF0004  addis r23, r31, 4
	ctx.r[23].s64 = ctx.r[31].s64 + 262144;
	// 831DED1C: 810100DC  lwz r8, 0xdc(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) } as u64;
	// 831DED20: 3F9F0003  addis r28, r31, 3
	ctx.r[28].s64 = ctx.r[31].s64 + 196608;
	// 831DED24: 83A100E4  lwz r29, 0xe4(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) } as u64;
	// 831DED28: 3BDE20D0  addi r30, r30, 0x20d0
	ctx.r[30].s64 = ctx.r[30].s64 + 8400;
	// 831DED2C: 3B7B50FC  addi r27, r27, 0x50fc
	ctx.r[27].s64 = ctx.r[27].s64 + 20732;
	// 831DED30: 3B5A9118  addi r26, r26, -0x6ee8
	ctx.r[26].s64 = ctx.r[26].s64 + -28392;
	// 831DED34: 93C10138  stw r30, 0x138(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), ctx.r[30].u32 ) };
	// 831DED38: 3B395108  addi r25, r25, 0x5108
	ctx.r[25].s64 = ctx.r[25].s64 + 20744;
	// 831DED3C: 93610140  stw r27, 0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[27].u32 ) };
	// 831DED40: 3AF7A068  addi r23, r23, -0x5f98
	ctx.r[23].s64 = ctx.r[23].s64 + -24472;
	// 831DED44: 934100D8  stw r26, 0xd8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[26].u32 ) };
	// 831DED48: 3B9CDF1C  addi r28, r28, -0x20e4
	ctx.r[28].s64 = ctx.r[28].s64 + -8420;
	// 831DED4C: 932100D4  stw r25, 0xd4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), ctx.r[25].u32 ) };
	// 831DED50: 38E90010  addi r7, r9, 0x10
	ctx.r[7].s64 = ctx.r[9].s64 + 16;
	// 831DED54: 92E100C4  stw r23, 0xc4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), ctx.r[23].u32 ) };
	// 831DED58: 3C7F0004  addis r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 262144;
	// 831DED5C: 93810198  stw r28, 0x198(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), ctx.r[28].u32 ) };
	// 831DED60: 3D5F0003  addis r10, r31, 3
	ctx.r[10].s64 = ctx.r[31].s64 + 196608;
	// 831DED64: 3CDF0003  addis r6, r31, 3
	ctx.r[6].s64 = ctx.r[31].s64 + 196608;
	// 831DED68: 3CBF0003  addis r5, r31, 3
	ctx.r[5].s64 = ctx.r[31].s64 + 196608;
	// 831DED6C: 3D3F0003  addis r9, r31, 3
	ctx.r[9].s64 = ctx.r[31].s64 + 196608;
	// 831DED70: 3C9F0004  addis r4, r31, 4
	ctx.r[4].s64 = ctx.r[31].s64 + 262144;
	// 831DED74: 3EDF0003  addis r22, r31, 3
	ctx.r[22].s64 = ctx.r[31].s64 + 196608;
	// 831DED78: 386300B8  addi r3, r3, 0xb8
	ctx.r[3].s64 = ctx.r[3].s64 + 184;
	// 831DED7C: 394ADF34  addi r10, r10, -0x20cc
	ctx.r[10].s64 = ctx.r[10].s64 + -8396;
	// 831DED80: 38C62FF0  addi r6, r6, 0x2ff0
	ctx.r[6].s64 = ctx.r[6].s64 + 12272;
	// 831DED84: 9061008C  stw r3, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[3].u32 ) };
	// 831DED88: 38A57024  addi r5, r5, 0x7024
	ctx.r[5].s64 = ctx.r[5].s64 + 28708;
	// 831DED8C: 806100E0  lwz r3, 0xe0(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) } as u64;
	// 831DED90: 39295008  addi r9, r9, 0x5008
	ctx.r[9].s64 = ctx.r[9].s64 + 20488;
	// 831DED94: 91410150  stw r10, 0x150(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), ctx.r[10].u32 ) };
	// 831DED98: 3884903C  addi r4, r4, -0x6fc4
	ctx.r[4].s64 = ctx.r[4].s64 + -28612;
	// 831DED9C: 90C101A4  stw r6, 0x1a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(420 as u32), ctx.r[6].u32 ) };
	// 831DEDA0: 3FDF0003  addis r30, r31, 3
	ctx.r[30].s64 = ctx.r[31].s64 + 196608;
	// 831DEDA4: 91210164  stw r9, 0x164(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), ctx.r[9].u32 ) };
	// 831DEDA8: 3AD6EF64  addi r22, r22, -0x109c
	ctx.r[22].s64 = ctx.r[22].s64 + -4252;
	// 831DEDAC: 90A1018C  stw r5, 0x18c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), ctx.r[5].u32 ) };
	// 831DEDB0: 3F7F0003  addis r27, r31, 3
	ctx.r[27].s64 = ctx.r[31].s64 + 196608;
	// 831DEDB4: 9081016C  stw r4, 0x16c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), ctx.r[4].u32 ) };
	// 831DEDB8: 3F5F0004  addis r26, r31, 4
	ctx.r[26].s64 = ctx.r[31].s64 + 262144;
	// 831DEDBC: 92C101A8  stw r22, 0x1a8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(424 as u32), ctx.r[22].u32 ) };
	// 831DEDC0: 3F9F0004  addis r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 262144;
	// 831DEDC4: 3F3F0004  addis r25, r31, 4
	ctx.r[25].s64 = ctx.r[31].s64 + 262144;
	// 831DEDC8: 3EFF0004  addis r23, r31, 4
	ctx.r[23].s64 = ctx.r[31].s64 + 262144;
	// 831DEDCC: 3BDE9EFC  addi r30, r30, -0x6104
	ctx.r[30].s64 = ctx.r[30].s64 + -24836;
	// 831DEDD0: 3B7BEFB8  addi r27, r27, -0x1048
	ctx.r[27].s64 = ctx.r[27].s64 + -4168;
	// 831DEDD4: 3B5AA054  addi r26, r26, -0x5fac
	ctx.r[26].s64 = ctx.r[26].s64 + -24492;
	// 831DEDD8: 3B9C00A8  addi r28, r28, 0xa8
	ctx.r[28].s64 = ctx.r[28].s64 + 168;
	// 831DEDDC: 3B39E074  addi r25, r25, -0x1f8c
	ctx.r[25].s64 = ctx.r[25].s64 + -8076;
	// 831DEDE0: 3AF7E090  addi r23, r23, -0x1f70
	ctx.r[23].s64 = ctx.r[23].s64 + -8048;
	// 831DEDE4: 93810078  stw r28, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[28].u32 ) };
	// 831DEDE8: 3F9F0004  addis r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 262144;
	// 831DEDEC: 9321019C  stw r25, 0x19c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), ctx.r[25].u32 ) };
	// 831DEDF0: 3F3F0003  addis r25, r31, 3
	ctx.r[25].s64 = ctx.r[31].s64 + 196608;
	// 831DEDF4: 3B9C20C4  addi r28, r28, 0x20c4
	ctx.r[28].s64 = ctx.r[28].s64 + 8388;
	// 831DEDF8: 92E10080  stw r23, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[23].u32 ) };
	// 831DEDFC: 3B392FD8  addi r25, r25, 0x2fd8
	ctx.r[25].s64 = ctx.r[25].s64 + 12248;
	// 831DEE00: 8241009C  lwz r18, 0x9c(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DEE04: 93810060  stw r28, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[28].u32 ) };
	// 831DEE08: 3F9F0004  addis r28, r31, 4
	ctx.r[28].s64 = ctx.r[31].s64 + 262144;
	// 831DEE0C: 9321015C  stw r25, 0x15c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), ctx.r[25].u32 ) };
	// 831DEE10: 3F3F0005  addis r25, r31, 5
	ctx.r[25].s64 = ctx.r[31].s64 + 327680;
	// 831DEE14: 3B9C50F4  addi r28, r28, 0x50f4
	ctx.r[28].s64 = ctx.r[28].s64 + 20724;
	// 831DEE18: 3B399114  addi r25, r25, -0x6eec
	ctx.r[25].s64 = ctx.r[25].s64 + -28396;
	// 831DEE1C: 93810108  stw r28, 0x108(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), ctx.r[28].u32 ) };
	// 831DEE20: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831DEE24: 93210118  stw r25, 0x118(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[25].u32 ) };
	// 831DEE28: 3EFF0004  addis r23, r31, 4
	ctx.r[23].s64 = ctx.r[31].s64 + 262144;
	// 831DEE2C: 93810068  stw r28, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[28].u32 ) };
	// 831DEE30: 7F834050  subf r28, r3, r8
	ctx.r[28].s64 = ctx.r[8].s64 - ctx.r[3].s64;
	// 831DEE34: 7F23C050  subf r25, r3, r24
	ctx.r[25].s64 = ctx.r[24].s64 - ctx.r[3].s64;
	// 831DEE38: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 831DEE3C: 93810054  stw r28, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[28].u32 ) };
	// 831DEE40: 7C63E850  subf r3, r3, r29
	ctx.r[3].s64 = ctx.r[29].s64 - ctx.r[3].s64;
	// 831DEE44: 93210088  stw r25, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[25].u32 ) };
	// 831DEE48: 3AF740DC  addi r23, r23, 0x40dc
	ctx.r[23].s64 = ctx.r[23].s64 + 16604;
	// 831DEE4C: 91610064  stw r11, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[11].u32 ) };
	// 831DEE50: 906100AC  stw r3, 0xac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), ctx.r[3].u32 ) };
	// 831DEE54: 3C608201  lis r3, -0x7dff
	ctx.r[3].s64 = -2113863680;
	// 831DEE58: 92E10070  stw r23, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[23].u32 ) };
	// 831DEE5C: 3EE08201  lis r23, -0x7dff
	ctx.r[23].s64 = -2113863680;
	// 831DEE60: 3A800100  li r20, 0x100
	ctx.r[20].s64 = 256;
	// 831DEE64: 3FBF0003  addis r29, r31, 3
	ctx.r[29].s64 = ctx.r[31].s64 + 196608;
	// 831DEE68: 3F9F0003  addis r28, r31, 3
	ctx.r[28].s64 = ctx.r[31].s64 + 196608;
	// 831DEE6C: 92810090  stw r20, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[20].u32 ) };
	// 831DEE70: 3EDF0003  addis r22, r31, 3
	ctx.r[22].s64 = ctx.r[31].s64 + 196608;
	// 831DEE74: C0030A98  lfs f0, 0xa98(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(2712 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DEE78: 3EBF0003  addis r21, r31, 3
	ctx.r[21].s64 = ctx.r[31].s64 + 196608;
	// 831DEE7C: C1B79524  lfs f13, -0x6adc(r23)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DEE80: 80610058  lwz r3, 0x58(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831DEE84: 390A0010  addi r8, r10, 0x10
	ctx.r[8].s64 = ctx.r[10].s64 + 16;
	// 831DEE88: 3B290014  addi r25, r9, 0x14
	ctx.r[25].s64 = ctx.r[9].s64 + 20;
	// 831DEE8C: 82E1005C  lwz r23, 0x5c(r1)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 831DEE90: D0010190  stfs f0, 0x190(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), tmp.u32 ) };
	// 831DEE94: 3BBD9EC0  addi r29, r29, -0x6140
	ctx.r[29].s64 = ctx.r[29].s64 + -24896;
	// 831DEE98: D1A10058  stfs f13, 0x58(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 831DEE9C: 3B9CEF7C  addi r28, r28, -0x1084
	ctx.r[28].s64 = ctx.r[28].s64 + -4228;
	// 831DEEA0: 3AD69EE0  addi r22, r22, -0x6120
	ctx.r[22].s64 = ctx.r[22].s64 + -24864;
	// 831DEEA4: 3AB5EF9C  addi r21, r21, -0x1064
	ctx.r[21].s64 = ctx.r[21].s64 + -4196;
	// 831DEEA8: 397E0018  addi r11, r30, 0x18
	ctx.r[11].s64 = ctx.r[30].s64 + 24;
	// 831DEEAC: 395B0018  addi r10, r27, 0x18
	ctx.r[10].s64 = ctx.r[27].s64 + 24;
	// 831DEEB0: 38C60010  addi r6, r6, 0x10
	ctx.r[6].s64 = ctx.r[6].s64 + 16;
	// 831DEEB4: 38A50010  addi r5, r5, 0x10
	ctx.r[5].s64 = ctx.r[5].s64 + 16;
	// 831DEEB8: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 831DEEBC: 393A0018  addi r9, r26, 0x18
	ctx.r[9].s64 = ctx.r[26].s64 + 24;
	// 831DEEC0: 48000008  b 0x831deec8
	pc = 0x831DEEC8; continue 'dispatch;
	// 831DEEC4: 82810090  lwz r20, 0x90(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 831DEEC8: 82610074  lwz r19, 0x74(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 831DEECC: 567306FE  clrlwi r19, r19, 0x1b
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x0000001Fu64;
	// 831DEED0: 2F130000  cmpwi cr6, r19, 0
	ctx.cr[6].compare_i32(ctx.r[19].s32, 0, &mut ctx.xer);
	// 831DEED4: 409A0014  bne cr6, 0x831deee8
	if !ctx.cr[6].eq {
	pc = 0x831DEEE8; continue 'dispatch;
	}
	// 831DEED8: 826100A0  lwz r19, 0xa0(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 831DEEDC: 7C149A2C  dcbt r20, r19
	// 831DEEE0: 82610098  lwz r19, 0x98(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) } as u64;
	// 831DEEE4: 7C149A2C  dcbt r20, r19
	// 831DEEE8: C0120008  lfs f0, 8(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DEEEC: 82770000  lwz r19, 0(r23)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DEEF0: 82520000  lwz r18, 0(r18)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DEEF4: 3A211630  addi r17, r1, 0x1630
	ctx.r[17].s64 = ctx.r[1].s64 + 5680;
	// 831DEEF8: 7E749B78  mr r20, r19
	ctx.r[20].u64 = ctx.r[19].u64;
	// 831DEEFC: FBE10180  std r31, 0x180(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[31].u64 ) };
	// 831DEF00: 7E729850  subf r19, r18, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[18].s64;
	// 831DEF04: FB4101C0  std r26, 0x1c0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), ctx.r[26].u64 ) };
	// 831DEF08: 39F40002  addi r15, r20, 2
	ctx.r[15].s64 = ctx.r[20].s64 + 2;
	// 831DEF0C: 81C100D8  lwz r14, 0xd8(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) } as u64;
	// 831DEF10: 567405FE  clrlwi r20, r19, 0x17
	ctx.r[20].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 831DEF14: 82610094  lwz r19, 0x94(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) } as u64;
	// 831DEF18: 83E1008C  lwz r31, 0x8c(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 831DEF1C: 3A010E10  addi r16, r1, 0xe10
	ctx.r[16].s64 = ctx.r[1].s64 + 3600;
	// 831DEF20: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DEF24: 83410084  lwz r26, 0x84(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) } as u64;
	// 831DEF28: FB2101B8  std r25, 0x1b8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), ctx.r[25].u64 ) };
	// 831DEF2C: 55EF103A  slwi r15, r15, 2
	ctx.r[15].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[15].u64 = ctx.r[15].u32 as u64;
	// 831DEF30: F92101C8  std r9, 0x1c8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), ctx.r[9].u64 ) };
	// 831DEF34: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DEF38: 82410064  lwz r18, 0x64(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 831DEF3C: C10E0000  lfs f8, 0(r14)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DEF40: 832100A8  lwz r25, 0xa8(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) } as u64;
	// 831DEF44: C0F30000  lfs f7, 0(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DEF48: 812100D4  lwz r9, 0xd4(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) } as u64;
	// 831DEF4C: C0DF0000  lfs f6, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DEF50: C09A0000  lfs f4, 0(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DEF54: F88101D0  std r4, 0x1d0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(464 as u32), ctx.r[4].u64 ) };
	// 831DEF58: 7C74BC2E  lfsx f3, r20, r23
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[23].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DEF5C: 81C100C4  lwz r14, 0xc4(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) } as u64;
	// 831DEF60: 7DB8942E  lfsx f13, r24, r18
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[18].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DEF64: 826100CC  lwz r19, 0xcc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) } as u64;
	// 831DEF68: 83E100C8  lwz r31, 0xc8(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 831DEF6C: C1790000  lfs f11, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DEF70: 834100B4  lwz r26, 0xb4(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 831DEF74: C0290000  lfs f1, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DEF78: 808100B8  lwz r4, 0xb8(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 831DEF7C: EC4068FA  fmadds f2, f0, f3, f13
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[3].f64 + ctx.f[13].f64) as f32) as f64);
	// 831DEF80: F8A101B0  std r5, 0x1b0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), ctx.r[5].u64 ) };
	// 831DEF84: C00E0000  lfs f0, 0(r14)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DEF88: 824100B0  lwz r18, 0xb0(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 831DEF8C: C3F30000  lfs f31, 0(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DEF90: 828100C0  lwz r20, 0xc0(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 831DEF94: C1BF0000  lfs f13, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DEF98: 832100BC  lwz r25, 0xbc(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 831DEF9C: C3BA0000  lfs f29, 0(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DEFA0: 812100D0  lwz r9, 0xd0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) } as u64;
	// 831DEFA4: C3840000  lfs f28, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 831DEFA8: 80A100A4  lwz r5, 0xa4(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) } as u64;
	// 831DEFAC: C1920000  lfs f12, 0(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DEFB0: 81C10130  lwz r14, 0x130(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 831DEFB4: 82610154  lwz r19, 0x154(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(340 as u32) ) } as u64;
	// 831DEFB8: C3D40000  lfs f30, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DEFBC: 83E10158  lwz r31, 0x158(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(344 as u32) ) } as u64;
	// 831DEFC0: C3790000  lfs f27, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 831DEFC4: 83410160  lwz r26, 0x160(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(352 as u32) ) } as u64;
	// 831DEFC8: C1490000  lfs f10, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DEFCC: 80810110  lwz r4, 0x110(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(272 as u32) ) } as u64;
	// 831DEFD0: C3450000  lfs f26, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 831DEFD4: 824100AC  lwz r18, 0xac(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) } as u64;
	// 831DEFD8: C32E0000  lfs f25, 0(r14)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 831DEFDC: 82810100  lwz r20, 0x100(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(256 as u32) ) } as u64;
	// 831DEFE0: C3130000  lfs f24, 0(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) };
	ctx.f[24].f64 = (tmp.f32 as f64);
	// 831DEFE4: 83210168  lwz r25, 0x168(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(360 as u32) ) } as u64;
	// 831DEFE8: 7E52C214  add r18, r18, r24
	ctx.r[18].u64 = ctx.r[18].u64 + ctx.r[24].u64;
	// 831DEFEC: 81210120  lwz r9, 0x120(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(288 as u32) ) } as u64;
	// 831DEFF0: C2FF0000  lfs f23, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 831DEFF4: 80A10170  lwz r5, 0x170(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(368 as u32) ) } as u64;
	// 831DEFF8: C2BA0000  lfs f21, 0(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) };
	ctx.f[21].f64 = (tmp.f32 as f64);
	// 831DEFFC: C1240000  lfs f9, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DF000: ECA2402A  fadds f5, f2, f8
	ctx.f[5].f64 = ((ctx.f[2].f64 + ctx.f[8].f64) as f32) as f64;
	// 831DF004: 81C100EC  lwz r14, 0xec(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(236 as u32) ) } as u64;
	// 831DF008: C2D40000  lfs f22, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 831DF00C: 82610178  lwz r19, 0x178(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(376 as u32) ) } as u64;
	// 831DF010: C2990000  lfs f20, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[20].f64 = (tmp.f32 as f64);
	// 831DF014: 83E10138  lwz r31, 0x138(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) } as u64;
	// 831DF018: C2690000  lfs f19, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[19].f64 = (tmp.f32 as f64);
	// 831DF01C: C0450000  lfs f2, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF020: 3B412F40  addi r26, r1, 0x2f40
	ctx.r[26].s64 = ctx.r[1].s64 + 12096;
	// 831DF024: 38813350  addi r4, r1, 0x3350
	ctx.r[4].s64 = ctx.r[1].s64 + 13136;
	// 831DF028: 92410050  stw r18, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[18].u32 ) };
	// 831DF02C: C24E0000  lfs f18, 0(r14)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) };
	ctx.f[18].f64 = (tmp.f32 as f64);
	// 831DF030: 8241009C  lwz r18, 0x9c(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) } as u64;
	// 831DF034: 82810188  lwz r20, 0x188(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(392 as u32) ) } as u64;
	// 831DF038: C21F0000  lfs f16, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831DF03C: 81C10140  lwz r14, 0x140(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(320 as u32) ) } as u64;
	// 831DF040: D0E10194  stfs f7, 0x194(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), tmp.u32 ) };
	// 831DF044: D20100F0  stfs f16, 0xf0(r1)
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), tmp.u32 ) };
	// 831DF048: ECE5202A  fadds f7, f5, f4
	ctx.f[7].f64 = ((ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64;
	// 831DF04C: C2330000  lfs f17, 0(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 831DF050: EC882028  fsubs f4, f8, f4
	ctx.f[4].f64 = (((ctx.f[8].f64 - ctx.f[4].f64) as f32) as f64);
	// 831DF054: C2120004  lfs f16, 4(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(4 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831DF058: 82610068  lwz r19, 0x68(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 831DF05C: C1F40000  lfs f15, 0(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 831DF060: 81210054  lwz r9, 0x54(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DF064: C1CE0000  lfs f14, 0(r14)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[14].u32.wrapping_add(0 as u32) ) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 831DF068: 80A10050  lwz r5, 0x50(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DF06C: 7CEFBD2E  stfsx f7, r15, r23
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[15].u32.wrapping_add(ctx.r[23].u32), tmp.u32) };
	// 831DF070: 82970000  lwz r20, 0(r23)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF074: 39F40001  addi r15, r20, 1
	ctx.r[15].s64 = ctx.r[20].s64 + 1;
	// 831DF078: 82810088  lwz r20, 0x88(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 831DF07C: 7D14D42E  lfsx f8, r20, r26
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[26].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DF080: 55EF05FE  clrlwi r15, r15, 0x17
	ctx.r[15].u64 = ctx.r[15].u32 as u64 & 0x000001FFu64;
	// 831DF084: D101005C  stfs f8, 0x5c(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 831DF088: EC7019FA  fmadds f3, f16, f7, f3
	ctx.f[3].f64 = (((ctx.f[16].f64 * ctx.f[7].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DF08C: 7D14242E  lfsx f8, r20, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DF090: 8281006C  lwz r20, 0x6c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 831DF094: 91F70000  stw r15, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[15].u32 ) };
	// 831DF098: D072000C  stfs f3, 0xc(r18)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF09C: 7CF38C2E  lfsx f7, r19, r17
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[17].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DF0A0: 81E30000  lwz r15, 0(r3)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF0A4: 7C73842E  lfsx f3, r19, r16
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[16].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF0A8: EC27082A  fadds f1, f7, f1
	ctx.f[1].f64 = ((ctx.f[7].f64 + ctx.f[1].f64) as f32) as f64;
	// 831DF0AC: D2210174  stfs f17, 0x174(r1)
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(372 as u32), tmp.u32 ) };
	// 831DF0B0: ECE3002A  fadds f7, f3, f0
	ctx.f[7].f64 = ((ctx.f[3].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DF0B4: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF0B8: C2140008  lfs f16, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831DF0BC: C2340004  lfs f17, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 831DF0C0: D1E100F8  stfs f15, 0xf8(r1)
	tmp.f32 = (ctx.f[15].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), tmp.u32 ) };
	// 831DF0C4: D0C1007C  stfs f6, 0x7c(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 831DF0C8: C0C10058  lfs f6, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DF0CC: C061005C  lfs f3, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF0D0: EC03682A  fadds f0, f3, f13
	ctx.f[0].f64 = ((ctx.f[3].f64 + ctx.f[13].f64) as f32) as f64;
	// 831DF0D4: 7E737850  subf r19, r19, r15
	ctx.r[19].s64 = ctx.r[15].s64 - ctx.r[19].s64;
	// 831DF0D8: EC21602A  fadds f1, f1, f12
	ctx.f[1].f64 = ((ctx.f[1].f64 + ctx.f[12].f64) as f32) as f64;
	// 831DF0DC: 7DF17B78  mr r17, r15
	ctx.r[17].u64 = ctx.r[15].u64;
	// 831DF0E0: D001005C  stfs f0, 0x5c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 831DF0E4: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 831DF0E8: C0A10190  lfs f5, 0x190(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(400 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF0EC: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF0F0: 7C09C42E  lfsx f0, r9, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DF0F4: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF0F8: C1A50000  lfs f13, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DF0FC: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF100: D1C10128  stfs f14, 0x128(r1)
	tmp.f32 = (ctx.f[14].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 831DF104: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF108: EF9C0172  fmuls f28, f28, f5
	ctx.f[28].f64 = (((ctx.f[28].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DF10C: 7DF31C2E  lfsx f15, r19, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 831DF110: EFF0FBFA  fmadds f31, f16, f15, f31
	ctx.f[31].f64 = (((ctx.f[16].f64 * ctx.f[15].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DF114: 7FF11D2E  stfsx f31, r17, r3
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 831DF118: 82630000  lwz r19, 0(r3)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF11C: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF120: EFFF7C7A  fmadds f31, f31, f17, f15
	ctx.f[31].f64 = (((ctx.f[31].f64 * ctx.f[17].f64 + ctx.f[15].f64) as f32) as f64);
	// 831DF124: EE27582A  fadds f17, f7, f11
	ctx.f[17].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 831DF128: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 831DF12C: ECE101B2  fmuls f7, f1, f6
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[6].f64) as f32) as f64);
	// 831DF130: 92630000  stw r19, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF134: D3F4000C  stfs f31, 0xc(r20)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF138: 82810148  lwz r20, 0x148(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(328 as u32) ) } as u64;
	// 831DF13C: 3A74000C  addi r19, r20, 0xc
	ctx.r[19].s64 = ctx.r[20].s64 + 12;
	// 831DF140: C3F40004  lfs f31, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF144: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF148: C2140010  lfs f16, 0x10(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(16 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831DF14C: 563107FE  clrlwi r17, r17, 0x1f
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 831DF150: ECD101B2  fmuls f6, f17, f6
	ctx.f[6].f64 = (((ctx.f[17].f64 * ctx.f[6].f64) as f32) as f64);
	// 831DF154: C221005C  lfs f17, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 831DF158: 3A310004  addi r17, r17, 4
	ctx.r[17].s64 = ctx.r[17].s64 + 4;
	// 831DF15C: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF160: 7C31A42E  lfsx f1, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF164: D2140014  stfs f16, 0x14(r20)
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF168: D2340010  stfs f17, 0x10(r20)
	tmp.f32 = (ctx.f[17].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF16C: EC218FFA  fmadds f1, f1, f31, f17
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[31].f64 + ctx.f[17].f64) as f32) as f64);
	// 831DF170: D0340008  stfs f1, 8(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF174: 829D0000  lwz r20, 0(r29)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF178: C03D0008  lfs f1, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF17C: 569407FE  clrlwi r20, r20, 0x1f
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000001u64;
	// 831DF180: C3FD000C  lfs f31, 0xc(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF184: 3A340006  addi r17, r20, 6
	ctx.r[17].s64 = ctx.r[20].s64 + 6;
	// 831DF188: C23D0004  lfs f17, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[17].f64 = (tmp.f32 as f64);
	// 831DF18C: 3A9D0014  addi r20, r29, 0x14
	ctx.r[20].s64 = ctx.r[29].s64 + 20;
	// 831DF190: C21D0018  lfs f16, 0x18(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(24 as u32) ) };
	ctx.f[16].f64 = (tmp.f32 as f64);
	// 831DF194: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF198: 3A960010  addi r20, r22, 0x10
	ctx.r[20].s64 = ctx.r[22].s64 + 16;
	// 831DF19C: C1F80000  lfs f15, 0(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) };
	ctx.f[15].f64 = (tmp.f32 as f64);
	// 831DF1A0: EF28C82A  fadds f25, f8, f25
	ctx.f[25].f64 = ((ctx.f[8].f64 + ctx.f[25].f64) as f32) as f64;
	// 831DF1A4: 7DD1EC2E  lfsx f14, r17, r29
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[29].u32)) };
	ctx.f[14].f64 = (tmp.f32 as f64);
	// 831DF1A8: EC21F3BA  fmadds f1, f1, f14, f30
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[14].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DF1AC: EFFF03B2  fmuls f31, f31, f14
	ctx.f[31].f64 = (((ctx.f[31].f64 * ctx.f[14].f64) as f32) as f64);
	// 831DF1B0: D03D0018  stfs f1, 0x18(r29)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF1B4: D21D001C  stfs f16, 0x1c(r29)
	tmp.f32 = (ctx.f[16].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831DF1B8: EC21FC7A  fmadds f1, f1, f17, f31
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[17].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DF1BC: D03D0010  stfs f1, 0x10(r29)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF1C0: C036000C  lfs f1, 0xc(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(12 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF1C4: 82360000  lwz r17, 0(r22)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF1C8: C3F60014  lfs f31, 0x14(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(20 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF1CC: 563307FE  clrlwi r19, r17, 0x1f
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 831DF1D0: 3A730005  addi r19, r19, 5
	ctx.r[19].s64 = ctx.r[19].s64 + 5;
	// 831DF1D4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF1D8: 7FD3B42E  lfsx f30, r19, r22
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[22].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF1DC: EC3EE87A  fmadds f1, f30, f1, f29
	ctx.f[1].f64 = (((ctx.f[30].f64 * ctx.f[1].f64 + ctx.f[29].f64) as f32) as f64);
	// 831DF1E0: D0360014  stfs f1, 0x14(r22)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF1E4: D3F60018  stfs f31, 0x18(r22)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF1E8: C3F60008  lfs f31, 8(r22)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(8 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF1EC: EC3F0072  fmuls f1, f31, f1
	ctx.f[1].f64 = (((ctx.f[31].f64 * ctx.f[1].f64) as f32) as f64);
	// 831DF1F0: D0360004  stfs f1, 4(r22)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF1F4: 823E000C  lwz r17, 0xc(r30)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DF1F8: C03E0004  lfs f1, 4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF1FC: 826B0000  lwz r19, 0(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF200: C3FE0010  lfs f31, 0x10(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF204: 7E709B78  mr r16, r19
	ctx.r[16].u64 = ctx.r[19].u64;
	// 831DF208: 81FE0000  lwz r15, 0(r30)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF20C: 7E0F8050  subf r16, r15, r16
	ctx.r[16].s64 = ctx.r[16].s64 - ctx.r[15].s64;
	// 831DF210: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 831DF214: 5614053E  clrlwi r20, r16, 0x14
	ctx.r[20].u64 = ctx.r[16].u32 as u64 & 0x00000FFFu64;
	// 831DF218: 5673053E  clrlwi r19, r19, 0x14
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF21C: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF220: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF224: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DF228: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF22C: 7FD45C2E  lfsx f30, r20, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF230: EC3E0072  fmuls f1, f30, f1
	ctx.f[1].f64 = (((ctx.f[30].f64 * ctx.f[1].f64) as f32) as f64);
	// 831DF234: 7FD35C2E  lfsx f30, r19, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF238: EFFE07F2  fmuls f31, f30, f31
	ctx.f[31].f64 = (((ctx.f[30].f64 * ctx.f[31].f64) as f32) as f64);
	// 831DF23C: D03E0008  stfs f1, 8(r30)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF240: D3FE0014  stfs f31, 0x14(r30)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF244: 828B0000  lwz r20, 0(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF248: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF24C: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DF250: 7F945D2E  stfsx f28, r20, r11
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 831DF254: 828B0000  lwz r20, 0(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF258: 3A740001  addi r19, r20, 1
	ctx.r[19].s64 = ctx.r[20].s64 + 1;
	// 831DF25C: 82810198  lwz r20, 0x198(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(408 as u32) ) } as u64;
	// 831DF260: 5673053E  clrlwi r19, r19, 0x14
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF264: 926B0000  stw r19, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF268: C0340004  lfs f1, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF26C: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF270: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 831DF274: 3A730004  addi r19, r19, 4
	ctx.r[19].s64 = ctx.r[19].s64 + 4;
	// 831DF278: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF27C: 7FF3A42E  lfsx f31, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF280: EC3F0072  fmuls f1, f31, f1
	ctx.f[1].f64 = (((ctx.f[31].f64 * ctx.f[1].f64) as f32) as f64);
	// 831DF284: D0340008  stfs f1, 8(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF288: 3A94000C  addi r20, r20, 0xc
	ctx.r[20].s64 = ctx.r[20].s64 + 12;
	// 831DF28C: C0340004  lfs f1, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF290: D0340008  stfs f1, 8(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF294: D3740004  stfs f27, 4(r20)
	tmp.f32 = (ctx.f[27].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF298: 82810150  lwz r20, 0x150(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(336 as u32) ) } as u64;
	// 831DF29C: 82680000  lwz r19, 0(r8)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF2A0: 7E719B78  mr r17, r19
	ctx.r[17].u64 = ctx.r[19].u64;
	// 831DF2A4: 82140000  lwz r16, 0(r20)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF2A8: C0340008  lfs f1, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF2AC: C3F40004  lfs f31, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF2B0: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 831DF2B4: 563105FE  clrlwi r17, r17, 0x17
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x000001FFu64;
	// 831DF2B8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF2BC: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF2C0: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF2C4: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF2C8: 7FD1442E  lfsx f30, r17, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF2CC: EC8127BA  fmadds f4, f1, f30, f4
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[30].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DF2D0: EC24782A  fadds f1, f4, f15
	ctx.f[1].f64 = ((ctx.f[4].f64 + ctx.f[15].f64) as f32) as f64;
	// 831DF2D4: 7C33452E  stfsx f1, r19, r8
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 831DF2D8: 82680000  lwz r19, 0(r8)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF2DC: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF2E0: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 831DF2E4: EC81F7FA  fmadds f4, f1, f31, f30
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 831DF2E8: EC360172  fmuls f1, f22, f5
	ctx.f[1].f64 = (((ctx.f[22].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DF2EC: 92680000  stw r19, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF2F0: D094000C  stfs f4, 0xc(r20)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF2F4: 828101A0  lwz r20, 0x1a0(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(416 as u32) ) } as u64;
	// 831DF2F8: 82670000  lwz r19, 0(r7)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF2FC: 7E719B78  mr r17, r19
	ctx.r[17].u64 = ctx.r[19].u64;
	// 831DF300: C0940008  lfs f4, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF304: 82140000  lwz r16, 0(r20)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF308: C0B40004  lfs f5, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF30C: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 831DF310: 563105FE  clrlwi r17, r17, 0x17
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x000001FFu64;
	// 831DF314: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF318: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF31C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF320: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF324: 7FF13C2E  lfsx f31, r17, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF328: EC84D7FA  fmadds f4, f4, f31, f26
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[31].f64 + ctx.f[26].f64) as f32) as f64);
	// 831DF32C: 7C933D2E  stfsx f4, r19, r7
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 831DF330: 82670000  lwz r19, 0(r7)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF334: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF338: ECA4F97A  fmadds f5, f4, f5, f31
	ctx.f[5].f64 = (((ctx.f[4].f64 * ctx.f[5].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DF33C: 567305FE  clrlwi r19, r19, 0x17
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000001FFu64;
	// 831DF340: 92670000  stw r19, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF344: D0B4000C  stfs f5, 0xc(r20)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF348: 828101A8  lwz r20, 0x1a8(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(424 as u32) ) } as u64;
	// 831DF34C: 3A74000C  addi r19, r20, 0xc
	ctx.r[19].s64 = ctx.r[20].s64 + 12;
	// 831DF350: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF354: 563107FE  clrlwi r17, r17, 0x1f
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 831DF358: 3A310004  addi r17, r17, 4
	ctx.r[17].s64 = ctx.r[17].s64 + 4;
	// 831DF35C: C0B40010  lfs f5, 0x10(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(16 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF360: C0940004  lfs f4, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF364: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF368: 7FF1A42E  lfsx f31, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF36C: EC9FC93A  fmadds f4, f31, f4, f25
	ctx.f[4].f64 = (((ctx.f[31].f64 * ctx.f[4].f64 + ctx.f[25].f64) as f32) as f64);
	// 831DF370: D0B40014  stfs f5, 0x14(r20)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF374: D3340010  stfs f25, 0x10(r20)
	tmp.f32 = (ctx.f[25].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF378: D0940008  stfs f4, 8(r20)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF37C: 829C0000  lwz r20, 0(r28)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF380: C09C0004  lfs f4, 4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF384: 569407FE  clrlwi r20, r20, 0x1f
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000001u64;
	// 831DF388: C3FC000C  lfs f31, 0xc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF38C: 3A340006  addi r17, r20, 6
	ctx.r[17].s64 = ctx.r[20].s64 + 6;
	// 831DF390: C3DC0018  lfs f30, 0x18(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF394: 3A9C0014  addi r20, r28, 0x14
	ctx.r[20].s64 = ctx.r[28].s64 + 20;
	// 831DF398: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF39C: C0BC0008  lfs f5, 8(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF3A0: 3A950010  addi r20, r21, 0x10
	ctx.r[20].s64 = ctx.r[21].s64 + 16;
	// 831DF3A4: 7FB1E42E  lfsx f29, r17, r28
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[28].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DF3A8: ECA5C77A  fmadds f5, f5, f29, f24
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[29].f64 + ctx.f[24].f64) as f32) as f64);
	// 831DF3AC: EC850132  fmuls f4, f5, f4
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[4].f64) as f32) as f64);
	// 831DF3B0: D0BC0018  stfs f5, 0x18(r28)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF3B4: D3DC001C  stfs f30, 0x1c(r28)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831DF3B8: ECBD27FA  fmadds f5, f29, f31, f4
	ctx.f[5].f64 = (((ctx.f[29].f64 * ctx.f[31].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DF3BC: D0BC0010  stfs f5, 0x10(r28)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF3C0: C095000C  lfs f4, 0xc(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF3C4: 82350000  lwz r17, 0(r21)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF3C8: C0B50014  lfs f5, 0x14(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(20 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF3CC: 563307FE  clrlwi r19, r17, 0x1f
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 831DF3D0: 3A730005  addi r19, r19, 5
	ctx.r[19].s64 = ctx.r[19].s64 + 5;
	// 831DF3D4: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF3D8: 7FF3AC2E  lfsx f31, r19, r21
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[21].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831DF3DC: EC9FB93A  fmadds f4, f31, f4, f23
	ctx.f[4].f64 = (((ctx.f[31].f64 * ctx.f[4].f64 + ctx.f[23].f64) as f32) as f64);
	// 831DF3E0: D0950014  stfs f4, 0x14(r21)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF3E4: D0B50018  stfs f5, 0x18(r21)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF3E8: C0B50008  lfs f5, 8(r21)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF3EC: EC840172  fmuls f4, f4, f5
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DF3F0: D0950004  stfs f4, 4(r21)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF3F4: 826A0000  lwz r19, 0(r10)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF3F8: 823B000C  lwz r17, 0xc(r27)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DF3FC: C09B0004  lfs f4, 4(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF400: 821B0000  lwz r16, 0(r27)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF404: C0BB0010  lfs f5, 0x10(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(16 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF408: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 831DF40C: 822A0000  lwz r17, 0(r10)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF410: EB2101B8  ld r25, 0x1b8(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(440 as u32) ) };
	// 831DF414: EFE0A02A  fadds f31, f0, f20
	ctx.f[31].f64 = ((ctx.f[0].f64 + ctx.f[20].f64) as f32) as f64;
	// 831DF418: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 831DF41C: E8A101B0  ld r5, 0x1b0(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(432 as u32) ) };
	// 831DF420: 5673053E  clrlwi r19, r19, 0x14
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF424: E88101D0  ld r4, 0x1d0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(464 as u32) ) };
	// 831DF428: 5634053E  clrlwi r20, r17, 0x14
	ctx.r[20].u64 = ctx.r[17].u32 as u64 & 0x00000FFFu64;
	// 831DF42C: E92101C8  ld r9, 0x1c8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(456 as u32) ) };
	// 831DF430: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF434: EC63902A  fadds f3, f3, f18
	ctx.f[3].f64 = ((ctx.f[3].f64 + ctx.f[18].f64) as f32) as f64;
	// 831DF438: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF43C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF440: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DF444: 7FD3542E  lfsx f30, r19, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF448: 7FB4542E  lfsx f29, r20, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[20].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 831DF44C: ECA507B2  fmuls f5, f5, f30
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[30].f64) as f32) as f64);
	// 831DF450: EC9D0132  fmuls f4, f29, f4
	ctx.f[4].f64 = (((ctx.f[29].f64 * ctx.f[4].f64) as f32) as f64);
	// 831DF454: D09B0008  stfs f4, 8(r27)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF458: D0BB0014  stfs f5, 0x14(r27)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF45C: 828A0000  lwz r20, 0(r10)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF460: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF464: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DF468: 7C34552E  stfsx f1, r20, r10
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 831DF46C: 828A0000  lwz r20, 0(r10)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF470: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 831DF474: 5693053E  clrlwi r19, r20, 0x14
	ctx.r[19].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 831DF478: 8281015C  lwz r20, 0x15c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(348 as u32) ) } as u64;
	// 831DF47C: 926A0000  stw r19, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF480: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF484: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 831DF488: 3A730004  addi r19, r19, 4
	ctx.r[19].s64 = ctx.r[19].s64 + 4;
	// 831DF48C: C0340004  lfs f1, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF490: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF494: 7CB3A42E  lfsx f5, r19, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF498: EC850072  fmuls f4, f5, f1
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[1].f64) as f32) as f64);
	// 831DF49C: D0940008  stfs f4, 8(r20)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF4A0: 3A94000C  addi r20, r20, 0xc
	ctx.r[20].s64 = ctx.r[20].s64 + 12;
	// 831DF4A4: C0340004  lfs f1, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF4A8: D0340008  stfs f1, 8(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF4AC: D2B40004  stfs f21, 4(r20)
	tmp.f32 = (ctx.f[21].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF4B0: 828101A4  lwz r20, 0x1a4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(420 as u32) ) } as u64;
	// 831DF4B4: C0940008  lfs f4, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF4B8: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF4BC: 82660000  lwz r19, 0(r6)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF4C0: C0B40004  lfs f5, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF4C4: 7E719850  subf r19, r17, r19
	ctx.r[19].s64 = ctx.r[19].s64 - ctx.r[17].s64;
	// 831DF4C8: 5671057E  clrlwi r17, r19, 0x15
	ctx.r[17].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 831DF4CC: 82660000  lwz r19, 0(r6)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF4D0: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF4D4: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF4D8: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF4DC: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF4E0: 7C31342E  lfsx f1, r17, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF4E4: EC81693A  fmadds f4, f1, f4, f13
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[4].f64 + ctx.f[13].f64) as f32) as f64);
	// 831DF4E8: EC84482A  fadds f4, f4, f9
	ctx.f[4].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 831DF4EC: EC84502A  fadds f4, f4, f10
	ctx.f[4].f64 = ((ctx.f[4].f64 + ctx.f[10].f64) as f32) as f64;
	// 831DF4F0: 7C93352E  stfsx f4, r19, r6
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 831DF4F4: 82660000  lwz r19, 0(r6)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF4F8: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF4FC: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 831DF500: EC24097A  fmadds f1, f4, f5, f1
	ctx.f[1].f64 = (((ctx.f[4].f64 * ctx.f[5].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF504: 92660000  stw r19, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF508: D034000C  stfs f1, 0xc(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF50C: 82810164  lwz r20, 0x164(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(356 as u32) ) } as u64;
	// 831DF510: 82790000  lwz r19, 0(r25)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF514: 7E719B78  mr r17, r19
	ctx.r[17].u64 = ctx.r[19].u64;
	// 831DF518: 82140000  lwz r16, 0(r20)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF51C: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 831DF520: 3A130002  addi r16, r19, 2
	ctx.r[16].s64 = ctx.r[19].s64 + 2;
	// 831DF524: C0B4000C  lfs f5, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF528: 5633057E  clrlwi r19, r17, 0x15
	ctx.r[19].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 831DF52C: C0940008  lfs f4, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF530: C0340004  lfs f1, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF534: 5611103A  slwi r17, r16, 2
	ctx.r[17].u32 = ctx.r[16].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF538: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF53C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF540: EB4101C0  ld r26, 0x1c0(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(448 as u32) ) };
	// 831DF544: 82010074  lwz r16, 0x74(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 831DF548: 7FD3CC2E  lfsx f30, r19, r25
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[25].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831DF54C: EC9EF93A  fmadds f4, f30, f4, f31
	ctx.f[4].f64 = (((ctx.f[30].f64 * ctx.f[4].f64 + ctx.f[31].f64) as f32) as f64);
	// 831DF550: 7C91CD2E  stfsx f4, r17, r25
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[25].u32), tmp.u32) };
	// 831DF554: ECBE0172  fmuls f5, f30, f5
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DF558: EC212FFA  fmadds f1, f1, f31, f5
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[31].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DF55C: 82790000  lwz r19, 0(r25)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF560: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF564: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 831DF568: 92790000  stw r19, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF56C: D0340010  stfs f1, 0x10(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF570: 8281018C  lwz r20, 0x18c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(396 as u32) ) } as u64;
	// 831DF574: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF578: C0940008  lfs f4, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF57C: 81E50000  lwz r15, 0(r5)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF580: C0B40004  lfs f5, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF584: 7E317850  subf r17, r17, r15
	ctx.r[17].s64 = ctx.r[15].s64 - ctx.r[17].s64;
	// 831DF588: 5631057E  clrlwi r17, r17, 0x15
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x000007FFu64;
	// 831DF58C: 7DF37B78  mr r19, r15
	ctx.r[19].u64 = ctx.r[15].u64;
	// 831DF590: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF594: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF598: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF59C: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF5A0: 7C312C2E  lfsx f1, r17, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF5A4: EC81993A  fmadds f4, f1, f4, f19
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[4].f64 + ctx.f[19].f64) as f32) as f64);
	// 831DF5A8: 7C932D2E  stfsx f4, r19, r5
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 831DF5AC: 82650000  lwz r19, 0(r5)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF5B0: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF5B4: EC24097A  fmadds f1, f4, f5, f1
	ctx.f[1].f64 = (((ctx.f[4].f64 * ctx.f[5].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF5B8: 5673057E  clrlwi r19, r19, 0x15
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000007FFu64;
	// 831DF5BC: 92650000  stw r19, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF5C0: D034000C  stfs f1, 0xc(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF5C4: 8281016C  lwz r20, 0x16c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(364 as u32) ) } as u64;
	// 831DF5C8: C0B40008  lfs f5, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF5CC: C0940004  lfs f4, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF5D0: 81E40000  lwz r15, 0(r4)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF5D4: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF5D8: 7E317850  subf r17, r17, r15
	ctx.r[17].s64 = ctx.r[15].s64 - ctx.r[17].s64;
	// 831DF5DC: 563105BE  clrlwi r17, r17, 0x16
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x000003FFu64;
	// 831DF5E0: 7DF37B78  mr r19, r15
	ctx.r[19].u64 = ctx.r[15].u64;
	// 831DF5E4: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF5E8: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF5EC: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF5F0: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF5F4: 7C31242E  lfsx f1, r17, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF5F8: ECA1017A  fmadds f5, f1, f5, f0
	ctx.f[5].f64 = (((ctx.f[1].f64 * ctx.f[5].f64 + ctx.f[0].f64) as f32) as f64);
	// 831DF5FC: EC45102A  fadds f2, f5, f2
	ctx.f[2].f64 = ((ctx.f[5].f64 + ctx.f[2].f64) as f32) as f64;
	// 831DF600: 7C53252E  stfsx f2, r19, r4
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 831DF604: EC22093A  fmadds f1, f2, f4, f1
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[4].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF608: 82640000  lwz r19, 0(r4)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF60C: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF610: 567305BE  clrlwi r19, r19, 0x16
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x000003FFu64;
	// 831DF614: 92640000  stw r19, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF618: D034000C  stfs f1, 0xc(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF61C: 827A000C  lwz r19, 0xc(r26)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DF620: C0BA0010  lfs f5, 0x10(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF624: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF628: C09A0004  lfs f4, 4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF62C: 7E91A378  mr r17, r20
	ctx.r[17].u64 = ctx.r[20].u64;
	// 831DF630: 7E93A050  subf r20, r19, r20
	ctx.r[20].s64 = ctx.r[20].s64 - ctx.r[19].s64;
	// 831DF634: 827A0000  lwz r19, 0(r26)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF638: 5694053E  clrlwi r20, r20, 0x14
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x00000FFFu64;
	// 831DF63C: 7E738850  subf r19, r19, r17
	ctx.r[19].s64 = ctx.r[17].s64 - ctx.r[19].s64;
	// 831DF640: 3A340002  addi r17, r20, 2
	ctx.r[17].s64 = ctx.r[20].s64 + 2;
	// 831DF644: 5674053E  clrlwi r20, r19, 0x14
	ctx.r[20].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF648: 5633103A  slwi r19, r17, 2
	ctx.r[19].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF64C: 3A340002  addi r17, r20, 2
	ctx.r[17].s64 = ctx.r[20].s64 + 2;
	// 831DF650: 561406FE  clrlwi r20, r16, 0x1b
	ctx.r[20].u64 = ctx.r[16].u32 as u64 & 0x0000001Fu64;
	// 831DF654: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF658: 2F140000  cmpwi cr6, r20, 0
	ctx.cr[6].compare_i32(ctx.r[20].s32, 0, &mut ctx.xer);
	// 831DF65C: 7C534C2E  lfsx f2, r19, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[19].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF660: EC220172  fmuls f1, f2, f5
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[5].f64) as f32) as f64);
	// 831DF664: 7CB14C2E  lfsx f5, r17, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF668: EC850132  fmuls f4, f5, f4
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[4].f64) as f32) as f64);
	// 831DF66C: D09A0008  stfs f4, 8(r26)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF670: D03A0014  stfs f1, 0x14(r26)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF674: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF678: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF67C: 5694103A  slwi r20, r20, 2
	ctx.r[20].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 831DF680: 7C744D2E  stfsx f3, r20, r9
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 831DF684: EBE10180  ld r31, 0x180(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(384 as u32) ) };
	// 831DF688: C0410174  lfs f2, 0x174(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(372 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF68C: 82890000  lwz r20, 0(r9)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF690: 3A740001  addi r19, r20, 1
	ctx.r[19].s64 = ctx.r[20].s64 + 1;
	// 831DF694: 8281019C  lwz r20, 0x19c(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(412 as u32) ) } as u64;
	// 831DF698: 5671053E  clrlwi r17, r19, 0x14
	ctx.r[17].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF69C: 3A740010  addi r19, r20, 0x10
	ctx.r[19].s64 = ctx.r[20].s64 + 16;
	// 831DF6A0: 92290000  stw r17, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[17].u32 ) };
	// 831DF6A4: 82340000  lwz r17, 0(r20)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF6A8: C0740008  lfs f3, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF6AC: EC2300B2  fmuls f1, f3, f2
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[2].f64) as f32) as f64);
	// 831DF6B0: 563107FE  clrlwi r17, r17, 0x1f
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000001u64;
	// 831DF6B4: C0B4000C  lfs f5, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF6B8: C0940014  lfs f4, 0x14(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(20 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF6BC: 3A310005  addi r17, r17, 5
	ctx.r[17].s64 = ctx.r[17].s64 + 5;
	// 831DF6C0: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF6C4: 7C71A42E  lfsx f3, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF6C8: D0940018  stfs f4, 0x18(r20)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF6CC: EC23097A  fmadds f1, f3, f5, f1
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[5].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF6D0: D0540014  stfs f2, 0x14(r20)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF6D4: D0340004  stfs f1, 4(r20)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF6D8: 409A0010  bne cr6, 0x831df6e8
	if !ctx.cr[6].eq {
	pc = 0x831DF6E8; continue 'dispatch;
	}
	// 831DF6DC: 82810090  lwz r20, 0x90(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 831DF6E0: 3A940080  addi r20, r20, 0x80
	ctx.r[20].s64 = ctx.r[20].s64 + 128;
	// 831DF6E4: 92810090  stw r20, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[20].u32 ) };
	// 831DF6E8: 82010080  lwz r16, 0x80(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 831DF6EC: C081007C  lfs f4, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF6F0: 82610078  lwz r19, 0x78(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 831DF6F4: ED495028  fsubs f10, f9, f10
	ctx.f[10].f64 = (((ctx.f[9].f64 - ctx.f[10].f64) as f32) as f64);
	// 831DF6F8: 7E118378  mr r17, r16
	ctx.r[17].u64 = ctx.r[16].u64;
	// 831DF6FC: 81E10060  lwz r15, 0x60(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831DF700: 7E0E8378  mr r14, r16
	ctx.r[14].u64 = ctx.r[16].u64;
	// 831DF704: F9610180  std r11, 0x180(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), ctx.r[11].u64 ) };
	// 831DF708: 3A910010  addi r20, r17, 0x10
	ctx.r[20].s64 = ctx.r[17].s64 + 16;
	// 831DF70C: C1210194  lfs f9, 0x194(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(404 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831DF710: 3A930014  addi r20, r19, 0x14
	ctx.r[20].s64 = ctx.r[19].s64 + 20;
	// 831DF714: C0700004  lfs f3, 4(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF718: 3A6F0010  addi r19, r15, 0x10
	ctx.r[19].s64 = ctx.r[15].s64 + 16;
	// 831DF71C: 81E10070  lwz r15, 0x70(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 831DF720: 3A100010  addi r16, r16, 0x10
	ctx.r[16].s64 = ctx.r[16].s64 + 16;
	// 831DF724: 81710010  lwz r11, 0x10(r17)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DF728: C0510008  lfs f2, 8(r17)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(8 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF72C: 82310000  lwz r17, 0(r17)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF730: ECAD482A  fadds f5, f13, f9
	ctx.f[5].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 831DF734: 7D715850  subf r11, r17, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[17].s64;
	// 831DF738: 91E1007C  stw r15, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[15].u32 ) };
	// 831DF73C: 81F00000  lwz r15, 0(r16)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF740: 39EF0002  addi r15, r15, 2
	ctx.r[15].s64 = ctx.r[15].s64 + 2;
	// 831DF744: 8221007C  lwz r17, 0x7c(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 831DF748: 91E1007C  stw r15, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[15].u32 ) };
	// 831DF74C: 556F057E  clrlwi r15, r11, 0x15
	ctx.r[15].u64 = ctx.r[11].u32 as u64 & 0x000007FFu64;
	// 831DF750: 3A310010  addi r17, r17, 0x10
	ctx.r[17].s64 = ctx.r[17].s64 + 16;
	// 831DF754: 39EF0002  addi r15, r15, 2
	ctx.r[15].s64 = ctx.r[15].s64 + 2;
	// 831DF758: 55EF103A  slwi r15, r15, 2
	ctx.r[15].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[15].u64 = ctx.r[15].u32 as u64;
	// 831DF75C: 7C2F842E  lfsx f1, r15, r16
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[16].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF760: ED4150BA  fmadds f10, f1, f2, f10
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DF764: 8161007C  lwz r11, 0x7c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 831DF768: ED2A002A  fadds f9, f10, f0
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 831DF76C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DF770: 7D2B852E  stfsx f9, r11, r16
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[16].u32), tmp.u32) };
	// 831DF774: 81F00000  lwz r15, 0(r16)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF778: 39EF0001  addi r15, r15, 1
	ctx.r[15].s64 = ctx.r[15].s64 + 1;
	// 831DF77C: 55EF057E  clrlwi r15, r15, 0x15
	ctx.r[15].u64 = ctx.r[15].u32 as u64 & 0x000007FFu64;
	// 831DF780: EC6908FA  fmadds f3, f9, f3, f1
	ctx.f[3].f64 = (((ctx.f[9].f64 * ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF784: 91F00000  stw r15, 0(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(0 as u32), ctx.r[15].u32 ) };
	// 831DF788: D06E000C  stfs f3, 0xc(r14)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF78C: 82010078  lwz r16, 0x78(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 831DF790: C010000C  lfs f0, 0xc(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DF794: C0500008  lfs f2, 8(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(8 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF798: 81D00000  lwz r14, 0(r16)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF79C: 81740000  lwz r11, 0(r20)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF7A0: 7D6F5B78  mr r15, r11
	ctx.r[15].u64 = ctx.r[11].u64;
	// 831DF7A4: 7DCE5850  subf r14, r14, r11
	ctx.r[14].s64 = ctx.r[11].s64 - ctx.r[14].s64;
	// 831DF7A8: C0300004  lfs f1, 4(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF7AC: 396F0002  addi r11, r15, 2
	ctx.r[11].s64 = ctx.r[15].s64 + 2;
	// 831DF7B0: 55CF057E  clrlwi r15, r14, 0x15
	ctx.r[15].u64 = ctx.r[14].u32 as u64 & 0x000007FFu64;
	// 831DF7B4: 556E103A  slwi r14, r11, 2
	ctx.r[14].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 831DF7B8: 39EF0002  addi r15, r15, 2
	ctx.r[15].s64 = ctx.r[15].s64 + 2;
	// 831DF7BC: 55EF103A  slwi r15, r15, 2
	ctx.r[15].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[15].u64 = ctx.r[15].u32 as u64;
	// 831DF7C0: 7D4FA42E  lfsx f10, r15, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DF7C4: EC6A0032  fmuls f3, f10, f0
	ctx.f[3].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DF7C8: ED2A28BA  fmadds f9, f10, f2, f5
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[2].f64 + ctx.f[5].f64) as f32) as f64);
	// 831DF7CC: 7D2EA52E  stfsx f9, r14, r20
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 831DF7D0: 81F40000  lwz r15, 0(r20)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF7D4: 39EF0001  addi r15, r15, 1
	ctx.r[15].s64 = ctx.r[15].s64 + 1;
	// 831DF7D8: 55EF057E  clrlwi r15, r15, 0x15
	ctx.r[15].u64 = ctx.r[15].u32 as u64 & 0x000007FFu64;
	// 831DF7DC: EC45187A  fmadds f2, f5, f1, f3
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[1].f64 + ctx.f[3].f64) as f32) as f64);
	// 831DF7E0: 91F40000  stw r15, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[15].u32 ) };
	// 831DF7E4: D0500010  stfs f2, 0x10(r16)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 831DF7E8: 82810060  lwz r20, 0x60(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 831DF7EC: C0340008  lfs f1, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF7F0: 81F30000  lwz r15, 0(r19)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF7F4: 81D40000  lwz r14, 0(r20)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF7F8: C0140004  lfs f0, 4(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DF7FC: 7DF07B78  mr r16, r15
	ctx.r[16].u64 = ctx.r[15].u64;
	// 831DF800: 7DEE7850  subf r15, r14, r15
	ctx.r[15].s64 = ctx.r[15].s64 - ctx.r[14].s64;
	// 831DF804: 39D00002  addi r14, r16, 2
	ctx.r[14].s64 = ctx.r[16].s64 + 2;
	// 831DF808: 55F0057E  clrlwi r16, r15, 0x15
	ctx.r[16].u64 = ctx.r[15].u32 as u64 & 0x000007FFu64;
	// 831DF80C: 55CF103A  slwi r15, r14, 2
	ctx.r[15].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[15].u64 = ctx.r[15].u32 as u64;
	// 831DF810: 3A100002  addi r16, r16, 2
	ctx.r[16].s64 = ctx.r[16].s64 + 2;
	// 831DF814: 5610103A  slwi r16, r16, 2
	ctx.r[16].u32 = ctx.r[16].u32.wrapping_shl(2);
	ctx.r[16].u64 = ctx.r[16].u32 as u64;
	// 831DF818: 7D509C2E  lfsx f10, r16, r19
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[19].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831DF81C: ED2122BA  fmadds f9, f1, f10, f4
	ctx.f[9].f64 = (((ctx.f[1].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 831DF820: 7D2F9D2E  stfsx f9, r15, r19
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[15].u32.wrapping_add(ctx.r[19].u32), tmp.u32) };
	// 831DF824: 82130000  lwz r16, 0(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF828: 3A100001  addi r16, r16, 1
	ctx.r[16].s64 = ctx.r[16].s64 + 1;
	// 831DF82C: 560F057E  clrlwi r15, r16, 0x15
	ctx.r[15].u64 = ctx.r[16].u32 as u64 & 0x000007FFu64;
	// 831DF830: ECA9503A  fmadds f5, f9, f0, f10
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64);
	// 831DF834: 81C10068  lwz r14, 0x68(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 831DF838: C08100F0  lfs f4, 0xf0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831DF83C: 91F30000  stw r15, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[15].u32 ) };
	// 831DF840: D0B4000C  stfs f5, 0xc(r20)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF844: 3A8E0004  addi r20, r14, 4
	ctx.r[20].s64 = ctx.r[14].s64 + 4;
	// 831DF848: 82610064  lwz r19, 0x64(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 831DF84C: 82010070  lwz r16, 0x70(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 831DF850: D0D80000  stfs f6, 0(r24)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DF854: 92810068  stw r20, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[20].u32 ) };
	// 831DF858: C06100F8  lfs f3, 0xf8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831DF85C: 82810054  lwz r20, 0x54(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 831DF860: EC48182A  fadds f2, f8, f3
	ctx.f[2].f64 = ((ctx.f[8].f64 + ctx.f[3].f64) as f32) as f64;
	// 831DF864: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831DF868: 7CF89D2E  stfsx f7, r24, r19
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[24].u32.wrapping_add(ctx.r[19].u32), tmp.u32) };
	// 831DF86C: 81C10074  lwz r14, 0x74(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 831DF870: C0300008  lfs f1, 8(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(8 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DF874: 81E10088  lwz r15, 0x88(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 831DF878: 39CE0001  addi r14, r14, 1
	ctx.r[14].s64 = ctx.r[14].s64 + 1;
	// 831DF87C: 7D94C52E  stfsx f12, r20, r24
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[24].u32), tmp.u32) };
	// 831DF880: 39EF0004  addi r15, r15, 4
	ctx.r[15].s64 = ctx.r[15].s64 + 4;
	// 831DF884: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831DF888: 91C10074  stw r14, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[14].u32 ) };
	// 831DF88C: 91E10088  stw r15, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[15].u32 ) };
	// 831DF890: 3B180004  addi r24, r24, 4
	ctx.r[24].s64 = ctx.r[24].s64 + 4;
	// 831DF894: 82710000  lwz r19, 0(r17)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF898: C0100004  lfs f0, 4(r16)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DF89C: 82900000  lwz r20, 0(r16)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF8A0: 39D30002  addi r14, r19, 2
	ctx.r[14].s64 = ctx.r[19].s64 + 2;
	// 831DF8A4: 7E949850  subf r20, r20, r19
	ctx.r[20].s64 = ctx.r[19].s64 - ctx.r[20].s64;
	// 831DF8A8: 81E10068  lwz r15, 0x68(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 831DF8AC: 55CE103A  slwi r14, r14, 2
	ctx.r[14].u32 = ctx.r[14].u32.wrapping_shl(2);
	ctx.r[14].u64 = ctx.r[14].u32 as u64;
	// 831DF8B0: 82610108  lwz r19, 0x108(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) } as u64;
	// 831DF8B4: 569405BE  clrlwi r20, r20, 0x16
	ctx.r[20].u64 = ctx.r[20].u32 as u64 & 0x000003FFu64;
	// 831DF8B8: 2F0F0400  cmpwi cr6, r15, 0x400
	ctx.cr[6].compare_i32(ctx.r[15].s32, 1024, &mut ctx.xer);
	// 831DF8BC: 3A940002  addi r20, r20, 2
	ctx.r[20].s64 = ctx.r[20].s64 + 2;
	// 831DF8C0: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831DF8C4: 3A930018  addi r20, r19, 0x18
	ctx.r[20].s64 = ctx.r[19].s64 + 24;
	// 831DF8C8: 7D8B8C2E  lfsx f12, r11, r17
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[17].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DF8CC: ED6C687A  fmadds f11, f12, f1, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64);
	// 831DF8D0: ED4B202A  fadds f10, f11, f4
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64;
	// 831DF8D4: 7D4E8D2E  stfsx f10, r14, r17
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[17].u32), tmp.u32) };
	// 831DF8D8: ED2A603A  fmadds f9, f10, f0, f12
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64);
	// 831DF8DC: 81F10000  lwz r15, 0(r17)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF8E0: 39EF0001  addi r15, r15, 1
	ctx.r[15].s64 = ctx.r[15].s64 + 1;
	// 831DF8E4: 55EF05BE  clrlwi r15, r15, 0x16
	ctx.r[15].u64 = ctx.r[15].u32 as u64 & 0x000003FFu64;
	// 831DF8E8: 91F10000  stw r15, 0(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(0 as u32), ctx.r[15].u32 ) };
	// 831DF8EC: D130000C  stfs f9, 0xc(r16)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 831DF8F0: 82130000  lwz r16, 0(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF8F4: C1130010  lfs f8, 0x10(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831DF8F8: 82330018  lwz r17, 0x18(r19)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DF8FC: C0F30004  lfs f7, 4(r19)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831DF900: 7E308850  subf r17, r16, r17
	ctx.r[17].s64 = ctx.r[17].s64 - ctx.r[16].s64;
	// 831DF904: 82130018  lwz r16, 0x18(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DF908: 5631053E  clrlwi r17, r17, 0x14
	ctx.r[17].u64 = ctx.r[17].u32 as u64 & 0x00000FFFu64;
	// 831DF90C: 81F3000C  lwz r15, 0xc(r19)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DF910: 7E0F8050  subf r16, r15, r16
	ctx.r[16].s64 = ctx.r[16].s64 - ctx.r[15].s64;
	// 831DF914: 3A310002  addi r17, r17, 2
	ctx.r[17].s64 = ctx.r[17].s64 + 2;
	// 831DF918: 5610053E  clrlwi r16, r16, 0x14
	ctx.r[16].u64 = ctx.r[16].u32 as u64 & 0x00000FFFu64;
	// 831DF91C: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF920: 3A100002  addi r16, r16, 2
	ctx.r[16].s64 = ctx.r[16].s64 + 2;
	// 831DF924: 5610103A  slwi r16, r16, 2
	ctx.r[16].u32 = ctx.r[16].u32.wrapping_shl(2);
	ctx.r[16].u64 = ctx.r[16].u32 as u64;
	// 831DF928: 7CD1A42E  lfsx f6, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831DF92C: 7CB0A42E  lfsx f5, r16, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831DF930: EC850232  fmuls f4, f5, f8
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[8].f64) as f32) as f64);
	// 831DF934: EC6601F2  fmuls f3, f6, f7
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[7].f64) as f32) as f64);
	// 831DF938: D0730008  stfs f3, 8(r19)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831DF93C: D0930014  stfs f4, 0x14(r19)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF940: 82730018  lwz r19, 0x18(r19)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(24 as u32) ) } as u64;
	// 831DF944: 3A730002  addi r19, r19, 2
	ctx.r[19].s64 = ctx.r[19].s64 + 2;
	// 831DF948: 5673103A  slwi r19, r19, 2
	ctx.r[19].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[19].u64 = ctx.r[19].u32 as u64;
	// 831DF94C: 7C53A52E  stfsx f2, r19, r20
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[19].u32.wrapping_add(ctx.r[20].u32), tmp.u32) };
	// 831DF950: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF954: 3A730001  addi r19, r19, 1
	ctx.r[19].s64 = ctx.r[19].s64 + 1;
	// 831DF958: 5673053E  clrlwi r19, r19, 0x14
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000FFFu64;
	// 831DF95C: 92740000  stw r19, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 831DF960: 82810118  lwz r20, 0x118(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 831DF964: 82740000  lwz r19, 0(r20)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DF968: C0540008  lfs f2, 8(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(8 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831DF96C: 567307FE  clrlwi r19, r19, 0x1f
	ctx.r[19].u64 = ctx.r[19].u32 as u64 & 0x00000001u64;
	// 831DF970: C0010128  lfs f0, 0x128(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(296 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831DF974: 3A330005  addi r17, r19, 5
	ctx.r[17].s64 = ctx.r[19].s64 + 5;
	// 831DF978: EC220032  fmuls f1, f2, f0
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[0].f64) as f32) as f64);
	// 831DF97C: C1B4000C  lfs f13, 0xc(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831DF980: 5631103A  slwi r17, r17, 2
	ctx.r[17].u32 = ctx.r[17].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 831DF984: C1940014  lfs f12, 0x14(r20)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831DF988: E9610180  ld r11, 0x180(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(384 as u32) ) };
	// 831DF98C: 3A740010  addi r19, r20, 0x10
	ctx.r[19].s64 = ctx.r[20].s64 + 16;
	// 831DF990: 7D71A42E  lfsx f11, r17, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831DF994: D1940018  stfs f12, 0x18(r20)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 831DF998: D0140014  stfs f0, 0x14(r20)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 831DF99C: ED4B0B7A  fmadds f10, f11, f13, f1
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 831DF9A0: D1540004  stfs f10, 4(r20)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831DF9A4: 4198F520  blt cr6, 0x831deec4
	if ctx.cr[6].lt {
	pc = 0x831DEEC4; continue 'dispatch;
	}
	// 831DF9A8: 836100E8  lwz r27, 0xe8(r1)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) } as u64;
	// 831DF9AC: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DF9B0: 838100DC  lwz r28, 0xdc(r1)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) } as u64;
	// 831DF9B4: 38639130  addi r3, r3, -0x6ed0
	ctx.r[3].s64 = ctx.r[3].s64 + -28368;
	// 831DF9B8: 834100E4  lwz r26, 0xe4(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) } as u64;
	// 831DF9BC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831DF9C0: 4BFFE121  bl 0x831ddae0
	ctx.lr = 0x831DF9C4;
	sub_831DDAE0(ctx, base);
	// 831DF9C4: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DF9C8: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831DF9CC: 38639948  addi r3, r3, -0x66b8
	ctx.r[3].s64 = ctx.r[3].s64 + -26296;
	// 831DF9D0: 4BFFE111  bl 0x831ddae0
	ctx.lr = 0x831DF9D4;
	sub_831DDAE0(ctx, base);
	// 831DF9D4: 83C100E0  lwz r30, 0xe0(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) } as u64;
	// 831DF9D8: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DF9DC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831DF9E0: 3863A160  addi r3, r3, -0x5ea0
	ctx.r[3].s64 = ctx.r[3].s64 + -24224;
	// 831DF9E4: 4BFFE0FD  bl 0x831ddae0
	ctx.lr = 0x831DF9E8;
	sub_831DDAE0(ctx, base);
	// 831DF9E8: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DF9EC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831DF9F0: 3863A978  addi r3, r3, -0x5688
	ctx.r[3].s64 = ctx.r[3].s64 + -22152;
	// 831DF9F4: 4BFFE0ED  bl 0x831ddae0
	ctx.lr = 0x831DF9F8;
	sub_831DDAE0(ctx, base);
	// 831DF9F8: 3BBCFFF8  addi r29, r28, -8
	ctx.r[29].s64 = ctx.r[28].s64 + -8;
	// 831DF9FC: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DFA00: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831DFA04: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831DFA08: 3863B190  addi r3, r3, -0x4e70
	ctx.r[3].s64 = ctx.r[3].s64 + -20080;
	// 831DFA0C: 4BFFE46D  bl 0x831dde78
	ctx.lr = 0x831DFA10;
	sub_831DDE78(ctx, base);
	// 831DFA10: 3B9AFFF8  addi r28, r26, -8
	ctx.r[28].s64 = ctx.r[26].s64 + -8;
	// 831DFA14: 3C7F0005  addis r3, r31, 5
	ctx.r[3].s64 = ctx.r[31].s64 + 327680;
	// 831DFA18: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 831DFA1C: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 831DFA20: 3863B5B0  addi r3, r3, -0x4a50
	ctx.r[3].s64 = ctx.r[3].s64 + -19024;
	// 831DFA24: 4BFFE455  bl 0x831dde78
	ctx.lr = 0x831DFA28;
	sub_831DDE78(ctx, base);
	// 831DFA28: 38E0005C  li r7, 0x5c
	ctx.r[7].s64 = 92;
	// 831DFA2C: 3CC08335  lis r6, -0x7ccb
	ctx.r[6].s64 = -2093678592;
	// 831DFA30: 812100A0  lwz r9, 0xa0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 831DFA34: 81010098  lwz r8, 0x98(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) } as u64;
	// 831DFA38: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 831DFA3C: 38A60C80  addi r5, r6, 0xc80
	ctx.r[5].s64 = ctx.r[6].s64 + 3200;
	// 831DFA40: 80C10144  lwz r6, 0x144(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(324 as u32) ) } as u64;
	// 831DFA44: 7C69D850  subf r3, r9, r27
	ctx.r[3].s64 = ctx.r[27].s64 - ctx.r[9].s64;
	// 831DFA48: 13FF3C07  vcmpneb. (lvlx128) v31, v31, v7
	tmp.u32 = ctx.r[31].u32 + ctx.r[7].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831DFA4C: 7F09E850  subf r24, r9, r29
	ctx.r[24].s64 = ctx.r[29].s64 - ctx.r[9].s64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFB48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831DFB48 size=316
    let mut pc: u32 = 0x831DFB48;
    'dispatch: loop {
        match pc {
            0x831DFB48 => {
    //   block [0x831DFB48..0x831DFC84)
	// 831DFB48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DFB4C: 4BFC8615  bl 0x831a8160
	ctx.lr = 0x831DFB50;
	sub_831A8130(ctx, base);
	// 831DFB50: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DFB54: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831DFB58: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831DFB5C: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 831DFB60: 480635FD  bl 0x8324315c
	ctx.lr = 0x831DFB64;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831DFB64: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DFB68: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831DFB6C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831DFB70: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831DFB74: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFB78: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DFB7C: 419A0010  beq cr6, 0x831dfb8c
	if ctx.cr[6].eq {
	pc = 0x831DFB8C; continue 'dispatch;
	}
	// 831DFB80: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DFB84: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831DFB88: 419A0018  beq cr6, 0x831dfba0
	if ctx.cr[6].eq {
	pc = 0x831DFBA0; continue 'dispatch;
	}
	// 831DFB8C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DFB90: 48062EED  bl 0x83242a7c
	ctx.lr = 0x831DFB94;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831DFB94: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFB98: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831DFB9C: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831DFBA0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831DFBA4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DFBA8: 897E00BC  lbz r11, 0xbc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(188 as u32) ) } as u64;
	// 831DFBAC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DFBB0: 419A0018  beq cr6, 0x831dfbc8
	if ctx.cr[6].eq {
	pc = 0x831DFBC8; continue 'dispatch;
	}
	// 831DFBB4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DFBB8: C03E00B8  lfs f1, 0xb8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(184 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831DFBBC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFBC0: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831DFBC4: 48005075  bl 0x831e4c38
	ctx.lr = 0x831DFBC8;
	sub_831E4C38(ctx, base);
	// 831DFBC8: 897E00BD  lbz r11, 0xbd(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(189 as u32) ) } as u64;
	// 831DFBCC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DFBD0: 419A001C  beq cr6, 0x831dfbec
	if ctx.cr[6].eq {
	pc = 0x831DFBEC; continue 'dispatch;
	}
	// 831DFBD4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DFBD8: 389E0034  addi r4, r30, 0x34
	ctx.r[4].s64 = ctx.r[30].s64 + 52;
	// 831DFBDC: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFBE0: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831DFBE4: 4800506D  bl 0x831e4c50
	ctx.lr = 0x831DFBE8;
	sub_831E4C50(ctx, base);
	// 831DFBE8: 48000020  b 0x831dfc08
	pc = 0x831DFC08; continue 'dispatch;
	// 831DFBEC: 897E00BE  lbz r11, 0xbe(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(190 as u32) ) } as u64;
	// 831DFBF0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831DFBF4: 419A0014  beq cr6, 0x831dfc08
	if ctx.cr[6].eq {
	pc = 0x831DFC08; continue 'dispatch;
	}
	// 831DFBF8: 38BE0088  addi r5, r30, 0x88
	ctx.r[5].s64 = ctx.r[30].s64 + 136;
	// 831DFBFC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DFC00: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DFC04: 48006C55  bl 0x831e6858
	ctx.lr = 0x831DFC08;
	sub_831E6858(ctx, base);
	// 831DFC08: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DFC0C: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 831DFC10: 995E00BE  stb r10, 0xbe(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(190 as u32), ctx.r[10].u8 ) };
	// 831DFC14: 995E00BC  stb r10, 0xbc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(188 as u32), ctx.r[10].u8 ) };
	// 831DFC18: 995E00BD  stb r10, 0xbd(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(189 as u32), ctx.r[10].u8 ) };
	// 831DFC1C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFC20: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DFC24: 419A003C  beq cr6, 0x831dfc60
	if ctx.cr[6].eq {
	pc = 0x831DFC60; continue 'dispatch;
	}
	// 831DFC28: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831DFC2C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831DFC30: 409A0030  bne cr6, 0x831dfc60
	if !ctx.cr[6].eq {
	pc = 0x831DFC60; continue 'dispatch;
	}
	// 831DFC34: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831DFC38: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831DFC3C: 40820024  bne 0x831dfc60
	if !ctx.cr[0].eq {
	pc = 0x831DFC60; continue 'dispatch;
	}
	// 831DFC40: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831DFC44: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831DFC48: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DFC4C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DFC50: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831DFC54: 48062E19  bl 0x83242a6c
	ctx.lr = 0x831DFC58;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831DFC58: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831DFC5C: 48063511  bl 0x8324316c
	ctx.lr = 0x831DFC60;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831DFC60: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831DFC64: 38C00100  li r6, 0x100
	ctx.r[6].s64 = 256;
	// 831DFC68: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 831DFC6C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 831DFC70: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFC74: 7C6BF214  add r3, r11, r30
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831DFC78: 4BFFE759  bl 0x831de3d0
	ctx.lr = 0x831DFC7C;
	sub_831DE3D0(ctx, base);
	// 831DFC7C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831DFC80: 4BFC8530  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFC88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DFC88 size=116
    let mut pc: u32 = 0x831DFC88;
    'dispatch: loop {
        match pc {
            0x831DFC88 => {
    //   block [0x831DFC88..0x831DFCFC)
	// 831DFC88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DFC8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DFC90: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DFC94: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DFC98: 8143FF40  lwz r10, -0xc0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-192 as u32) ) } as u64;
	// 831DFC9C: 3BE3FF40  addi r31, r3, -0xc0
	ctx.r[31].s64 = ctx.r[3].s64 + -192;
	// 831DFCA0: 548507FE  clrlwi r5, r4, 0x1f
	ctx.r[5].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831DFCA4: 397F0034  addi r11, r31, 0x34
	ctx.r[11].s64 = ctx.r[31].s64 + 52;
	// 831DFCA8: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831DFCAC: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831DFCB0: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFCB4: 38E90044  addi r7, r9, 0x44
	ctx.r[7].s64 = ctx.r[9].s64 + 68;
	// 831DFCB8: 38C8FF60  addi r6, r8, -0xa0
	ctx.r[6].s64 = ctx.r[8].s64 + -160;
	// 831DFCBC: 7C8A5A14  add r4, r10, r11
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DFCC0: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831DFCC4: 90E4FFCC  stw r7, -0x34(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(-52 as u32), ctx.r[7].u32 ) };
	// 831DFCC8: 90C30000  stw r6, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831DFCCC: 419A0018  beq cr6, 0x831dfce4
	if ctx.cr[6].eq {
	pc = 0x831DFCE4; continue 'dispatch;
	}
	// 831DFCD0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DFCD4: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DFCD8: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DFCDC: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DFCE0: 4BFFC9E1  bl 0x831dc6c0
	ctx.lr = 0x831DFCE4;
	sub_831DC6C0(ctx, base);
	// 831DFCE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DFCE8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DFCEC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DFCF0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DFCF4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DFCF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFD00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DFD00 size=8
    let mut pc: u32 = 0x831DFD00;
    'dispatch: loop {
        match pc {
            0x831DFD00 => {
    //   block [0x831DFD00..0x831DFD08)
	// 831DFD00: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831DFD04: 480002A4  b 0x831dffa8
	sub_831DFFA8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFD08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DFD08 size=8
    let mut pc: u32 = 0x831DFD08;
    'dispatch: loop {
        match pc {
            0x831DFD08 => {
    //   block [0x831DFD08..0x831DFD10)
	// 831DFD08: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831DFD0C: 480005CC  b 0x831e02d8
	sub_831E02D8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFD10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DFD10 size=8
    let mut pc: u32 = 0x831DFD10;
    'dispatch: loop {
        match pc {
            0x831DFD10 => {
    //   block [0x831DFD10..0x831DFD18)
	// 831DFD10: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831DFD14: 4800093C  b 0x831e0650
	sub_831E0650(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFD18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DFD18 size=360
    let mut pc: u32 = 0x831DFD18;
    'dispatch: loop {
        match pc {
            0x831DFD18 => {
    //   block [0x831DFD18..0x831DFE80)
	// 831DFD18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DFD1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DFD20: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831DFD24: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DFD28: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DFD2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DFD30: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831DFD34: 38810078  addi r4, r1, 0x78
	ctx.r[4].s64 = ctx.r[1].s64 + 120;
	// 831DFD38: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831DFD3C: 4800234D  bl 0x831e2088
	ctx.lr = 0x831DFD40;
	sub_831E2088(ctx, base);
	// 831DFD40: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DFD44: 41980124  blt cr6, 0x831dfe68
	if ctx.cr[6].lt {
	pc = 0x831DFE68; continue 'dispatch;
	}
	// 831DFD48: 38810068  addi r4, r1, 0x68
	ctx.r[4].s64 = ctx.r[1].s64 + 104;
	// 831DFD4C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DFD50: 48002339  bl 0x831e2088
	ctx.lr = 0x831DFD54;
	sub_831E2088(ctx, base);
	// 831DFD54: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DFD58: 41980110  blt cr6, 0x831dfe68
	if ctx.cr[6].lt {
	pc = 0x831DFE68; continue 'dispatch;
	}
	// 831DFD5C: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831DFD60: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831DFD64: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 831DFD68: 6168BB80  ori r8, r11, 0xbb80
	ctx.r[8].u64 = ctx.r[11].u64 | 48000;
	// 831DFD6C: 99410068  stb r10, 0x68(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[10].u8 ) };
	// 831DFD70: 99210069  stb r9, 0x69(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(105 as u32), ctx.r[9].u8 ) };
	// 831DFD74: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831DFD78: 9101006C  stw r8, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[8].u32 ) };
	// 831DFD7C: 38810068  addi r4, r1, 0x68
	ctx.r[4].s64 = ctx.r[1].s64 + 104;
	// 831DFD80: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DFD84: 48002565  bl 0x831e22e8
	ctx.lr = 0x831DFD88;
	sub_831E22E8(ctx, base);
	// 831DFD88: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831DFD8C: 419800DC  blt cr6, 0x831dfe68
	if ctx.cr[6].lt {
	pc = 0x831DFE68; continue 'dispatch;
	}
	// 831DFD90: 89610079  lbz r11, 0x79(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(121 as u32) ) } as u64;
	// 831DFD94: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831DFD98: 419800CC  blt cr6, 0x831dfe64
	if ctx.cr[6].lt {
	pc = 0x831DFE64; continue 'dispatch;
	}
	// 831DFD9C: 419A0020  beq cr6, 0x831dfdbc
	if ctx.cr[6].eq {
	pc = 0x831DFDBC; continue 'dispatch;
	}
	// 831DFDA0: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831DFDA4: 41980010  blt cr6, 0x831dfdb4
	if ctx.cr[6].lt {
	pc = 0x831DFDB4; continue 'dispatch;
	}
	// 831DFDA8: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831DFDAC: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831DFDB0: 480000B8  b 0x831dfe68
	pc = 0x831DFE68; continue 'dispatch;
	// 831DFDB4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DFDB8: 48000008  b 0x831dfdc0
	pc = 0x831DFDC0; continue 'dispatch;
	// 831DFDBC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831DFDC0: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DFDC4: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 831DFDC8: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFDCC: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 831DFDD0: 386B0010  addi r3, r11, 0x10
	ctx.r[3].s64 = ctx.r[11].s64 + 16;
	// 831DFDD4: 4B8E8815  bl 0x82ac85e8
	ctx.lr = 0x831DFDD8;
	sub_82AC85E8(ctx, base);
	// 831DFDD8: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 831DFDDC: 81410080  lwz r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 831DFDE0: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 831DFDE4: 392B0400  addi r9, r11, 0x400
	ctx.r[9].s64 = ctx.r[11].s64 + 1024;
	// 831DFDE8: 390A0400  addi r8, r10, 0x400
	ctx.r[8].s64 = ctx.r[10].s64 + 1024;
	// 831DFDEC: 38EB0800  addi r7, r11, 0x800
	ctx.r[7].s64 = ctx.r[11].s64 + 2048;
	// 831DFDF0: 91210094  stw r9, 0x94(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), ctx.r[9].u32 ) };
	// 831DFDF4: 38CB1000  addi r6, r11, 0x1000
	ctx.r[6].s64 = ctx.r[11].s64 + 4096;
	// 831DFDF8: 91610090  stw r11, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 831DFDFC: 38AB1400  addi r5, r11, 0x1400
	ctx.r[5].s64 = ctx.r[11].s64 + 5120;
	// 831DFE00: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831DFE04: 91010054  stw r8, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[8].u32 ) };
	// 831DFE08: 90E10098  stw r7, 0x98(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[7].u32 ) };
	// 831DFE0C: 90C1009C  stw r6, 0x9c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), ctx.r[6].u32 ) };
	// 831DFE10: 90A100A0  stw r5, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[5].u32 ) };
	// 831DFE14: 4B9ED2A5  bl 0x82bcd0b8
	ctx.lr = 0x831DFE18;
	sub_82BCD0B8(ctx, base);
	// 831DFE18: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 831DFE1C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831DFE20: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DFE24: 4BFFFD25  bl 0x831dfb48
	ctx.lr = 0x831DFE28;
	sub_831DFB48(ctx, base);
	// 831DFE28: 38610058  addi r3, r1, 0x58
	ctx.r[3].s64 = ctx.r[1].s64 + 88;
	// 831DFE2C: 4B9ED28D  bl 0x82bcd0b8
	ctx.lr = 0x831DFE30;
	sub_82BCD0B8(ctx, base);
	// 831DFE30: 3D7F0005  addis r11, r31, 5
	ctx.r[11].s64 = ctx.r[31].s64 + 327680;
	// 831DFE34: 3C9F0005  addis r4, r31, 5
	ctx.r[4].s64 = ctx.r[31].s64 + 327680;
	// 831DFE38: E8E10060  ld r7, 0x60(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 831DFE3C: 396BBAA8  addi r11, r11, -0x4558
	ctx.r[11].s64 = ctx.r[11].s64 + -17752;
	// 831DFE40: E9410058  ld r10, 0x58(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 831DFE44: 3884BAA0  addi r4, r4, -0x4560
	ctx.r[4].s64 = ctx.r[4].s64 + -17760;
	// 831DFE48: E92B0000  ld r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	// 831DFE4C: E9040000  ld r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	// 831DFE50: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831DFE54: F92B0000  std r9, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u64 ) };
	// 831DFE58: 7D674050  subf r11, r7, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[7].s64;
	// 831DFE5C: 7CCB5214  add r6, r11, r10
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831DFE60: F8C40000  std r6, 0(r4)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[6].u64 ) };
	// 831DFE64: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831DFE68: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 831DFE6C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DFE70: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DFE74: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831DFE78: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DFE7C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFE80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DFE80 size=116
    let mut pc: u32 = 0x831DFE80;
    'dispatch: loop {
        match pc {
            0x831DFE80 => {
    //   block [0x831DFE80..0x831DFEF4)
	// 831DFE80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DFE84: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831DFE88: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831DFE8C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DFE90: 8143FFCC  lwz r10, -0x34(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-52 as u32) ) } as u64;
	// 831DFE94: 3BE3FFCC  addi r31, r3, -0x34
	ctx.r[31].s64 = ctx.r[3].s64 + -52;
	// 831DFE98: 548507FE  clrlwi r5, r4, 0x1f
	ctx.r[5].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 831DFE9C: 397F0034  addi r11, r31, 0x34
	ctx.r[11].s64 = ctx.r[31].s64 + 52;
	// 831DFEA0: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831DFEA4: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831DFEA8: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFEAC: 38E90044  addi r7, r9, 0x44
	ctx.r[7].s64 = ctx.r[9].s64 + 68;
	// 831DFEB0: 38C8FF60  addi r6, r8, -0xa0
	ctx.r[6].s64 = ctx.r[8].s64 + -160;
	// 831DFEB4: 7C8A5A14  add r4, r10, r11
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DFEB8: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 831DFEBC: 90E4FFCC  stw r7, -0x34(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(-52 as u32), ctx.r[7].u32 ) };
	// 831DFEC0: 90C30000  stw r6, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831DFEC4: 419A0018  beq cr6, 0x831dfedc
	if ctx.cr[6].eq {
	pc = 0x831DFEDC; continue 'dispatch;
	}
	// 831DFEC8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831DFECC: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831DFED0: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831DFED4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831DFED8: 4BFFC7E9  bl 0x831dc6c0
	ctx.lr = 0x831DFEDC;
	sub_831DC6C0(ctx, base);
	// 831DFEDC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DFEE0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831DFEE4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831DFEE8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831DFEEC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831DFEF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFEF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831DFEF8 size=176
    let mut pc: u32 = 0x831DFEF8;
    'dispatch: loop {
        match pc {
            0x831DFEF8 => {
    //   block [0x831DFEF8..0x831DFFA8)
	// 831DFEF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831DFEFC: 4BFC8271  bl 0x831a816c
	ctx.lr = 0x831DFF00;
	sub_831A8130(ctx, base);
	// 831DFF00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831DFF04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831DFF08: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DFF0C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831DFF10: 392B0028  addi r9, r11, 0x28
	ctx.r[9].s64 = ctx.r[11].s64 + 40;
	// 831DFF14: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831DFF18: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831DFF1C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831DFF20: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831DFF24: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831DFF28: 80A40004  lwz r5, 4(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFF2C: 38670064  addi r3, r7, 0x64
	ctx.r[3].s64 = ctx.r[7].s64 + 100;
	// 831DFF30: 38880080  addi r4, r8, 0x80
	ctx.r[4].s64 = ctx.r[8].s64 + 128;
	// 831DFF34: 90BF000C  stw r5, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 831DFF38: 3966005C  addi r11, r6, 0x5c
	ctx.r[11].s64 = ctx.r[6].s64 + 92;
	// 831DFF3C: 907F0004  stw r3, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 831DFF40: 909F0000  stw r4, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 831DFF44: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 831DFF48: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831DFF4C: 397F0004  addi r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 4;
	// 831DFF50: 387E00C0  addi r3, r30, 0xc0
	ctx.r[3].s64 = ctx.r[30].s64 + 192;
	// 831DFF54: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831DFF58: 48005A91  bl 0x831e59e8
	ctx.lr = 0x831DFF5C;
	sub_831E59E8(ctx, base);
	// 831DFF5C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831DFF60: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831DFF64: 48006A4D  bl 0x831e69b0
	ctx.lr = 0x831DFF68;
	sub_831E69B0(ctx, base);
	// 831DFF68: 811F0010  lwz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DFF6C: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831DFF70: 387E0034  addi r3, r30, 0x34
	ctx.r[3].s64 = ctx.r[30].s64 + 52;
	// 831DFF74: 392A0058  addi r9, r10, 0x58
	ctx.r[9].s64 = ctx.r[10].s64 + 88;
	// 831DFF78: 80E80004  lwz r7, 4(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFF7C: 7D27F12E  stwx r9, r7, r30
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32.wrapping_add(ctx.r[30].u32), ctx.r[9].u32) };
	// 831DFF80: 48004829  bl 0x831e47a8
	ctx.lr = 0x831DFF84;
	sub_831E47A8(ctx, base);
	// 831DFF84: 3CA00004  lis r5, 4
	ctx.r[5].s64 = 262144;
	// 831DFF88: 3CC00004  lis r6, 4
	ctx.r[6].s64 = 262144;
	// 831DFF8C: 60A3BAA8  ori r3, r5, 0xbaa8
	ctx.r[3].u64 = ctx.r[5].u64 | 47784;
	// 831DFF90: 60C4BAA0  ori r4, r6, 0xbaa0
	ctx.r[4].u64 = ctx.r[6].u64 | 47776;
	// 831DFF94: 7FBF192A  stdx r29, r31, r3
	unsafe { crate::rt::store_u64(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[3].u32), ctx.r[29].u64) };
	// 831DFF98: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831DFF9C: 7FBF212A  stdx r29, r31, r4
	unsafe { crate::rt::store_u64(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[4].u32), ctx.r[29].u64) };
	// 831DFFA0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831DFFA4: 4BFC8218  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831DFFA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831DFFA8 size=88
    let mut pc: u32 = 0x831DFFA8;
    'dispatch: loop {
        match pc {
            0x831DFFA8 => {
    //   block [0x831DFFA8..0x831E0000)
	// 831DFFA8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831DFFAC: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831DFFB0: 392B0080  addi r9, r11, 0x80
	ctx.r[9].s64 = ctx.r[11].s64 + 128;
	// 831DFFB4: 390A0064  addi r8, r10, 0x64
	ctx.r[8].s64 = ctx.r[10].s64 + 100;
	// 831DFFB8: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831DFFBC: 39630010  addi r11, r3, 0x10
	ctx.r[11].s64 = ctx.r[3].s64 + 16;
	// 831DFFC0: 91030004  stw r8, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 831DFFC4: 3CA0821A  lis r5, -0x7de6
	ctx.r[5].s64 = -2112225280;
	// 831DFFC8: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 831DFFCC: 396B0034  addi r11, r11, 0x34
	ctx.r[11].s64 = ctx.r[11].s64 + 52;
	// 831DFFD0: 39430004  addi r10, r3, 4
	ctx.r[10].s64 = ctx.r[3].s64 + 4;
	// 831DFFD4: 3905FF60  addi r8, r5, -0xa0
	ctx.r[8].s64 = ctx.r[5].s64 + -160;
	// 831DFFD8: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831DFFDC: 3C80821A  lis r4, -0x7de6
	ctx.r[4].s64 = -2112225280;
	// 831DFFE0: 39260044  addi r9, r6, 0x44
	ctx.r[9].s64 = ctx.r[6].s64 + 68;
	// 831DFFE4: 38C4FF64  addi r6, r4, -0x9c
	ctx.r[6].s64 = ctx.r[4].s64 + -156;
	// 831DFFE8: 81470004  lwz r10, 4(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 831DFFEC: 7CAA5A14  add r5, r10, r11
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831DFFF0: 9125FFCC  stw r9, -0x34(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(-52 as u32), ctx.r[9].u32 ) };
	// 831DFFF4: 910300D0  stw r8, 0xd0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(208 as u32), ctx.r[8].u32 ) };
	// 831DFFF8: 90C30004  stw r6, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831DFFFC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0000(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E0000 size=184
    let mut pc: u32 = 0x831E0000;
    'dispatch: loop {
        match pc {
            0x831E0000 => {
    //   block [0x831E0000..0x831E00B8)
	// 831E0000: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0004: 4BFC8165  bl 0x831a8168
	ctx.lr = 0x831E0008;
	sub_831A8130(ctx, base);
	// 831E0008: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E000C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E0010: 3C800004  lis r4, 4
	ctx.r[4].s64 = 262144;
	// 831E0014: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E0018: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831E001C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0020: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0024: 6084BAB0  ori r4, r4, 0xbab0
	ctx.r[4].u64 = ctx.r[4].u64 | 47792;
	// 831E0028: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E002C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0030: 4E800421  bctrl
	ctx.lr = 0x831E0034;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0034: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E0038: 419A001C  beq cr6, 0x831e0054
	if ctx.cr[6].eq {
	pc = 0x831E0054; continue 'dispatch;
	}
	// 831E003C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E0040: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E0044: 4BFFFEB5  bl 0x831dfef8
	ctx.lr = 0x831E0048;
	sub_831DFEF8(ctx, base);
	// 831E0048: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E004C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E0050: 409A0014  bne cr6, 0x831e0064
	if !ctx.cr[6].eq {
	pc = 0x831E0064; continue 'dispatch;
	}
	// 831E0054: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E0058: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E005C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0060: 4BFC8158  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E0064: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0068: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 831E006C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E0070: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0074: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E0078: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E007C: 4E800421  bctrl
	ctx.lr = 0x831E0080;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0080: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E0084: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 831E0088: 41980010  blt cr6, 0x831e0098
	if ctx.cr[6].lt {
	pc = 0x831E0098; continue 'dispatch;
	}
	// 831E008C: 93FC0000  stw r31, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831E0090: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0094: 4BFC8124  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831E0098: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E009C: 387F0004  addi r3, r31, 4
	ctx.r[3].s64 = ctx.r[31].s64 + 4;
	// 831E00A0: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E00A4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E00A8: 4E800421  bctrl
	ctx.lr = 0x831E00AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E00AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E00B0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E00B4: 4BFC8104  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E00B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E00B8 size=32
    let mut pc: u32 = 0x831E00B8;
    'dispatch: loop {
        match pc {
            0x831E00B8 => {
    //   block [0x831E00B8..0x831E00D8)
	// 831E00B8: 3D408345  lis r10, -0x7cbb
	ctx.r[10].s64 = -2092630016;
	// 831E00BC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E00C0: 916AD004  stw r11, -0x2ffc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-12284 as u32), ctx.r[11].u32 ) };
	// 831E00C4: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E00C8: 80840008  lwz r4, 8(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E00CC: 8109001C  lwz r8, 0x1c(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E00D0: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E00D4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E00D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E00D8 size=104
    let mut pc: u32 = 0x831E00D8;
    'dispatch: loop {
        match pc {
            0x831E00D8 => {
    //   block [0x831E00D8..0x831E0140)
	// 831E00D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E00DC: 4BFC8091  bl 0x831a816c
	ctx.lr = 0x831E00E0;
	sub_831A8130(ctx, base);
	// 831E00E0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E00E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E00E8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E00EC: 3BFE0018  addi r31, r30, 0x18
	ctx.r[31].s64 = ctx.r[30].s64 + 24;
	// 831E00F0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E00F4: 817E0018  lwz r11, 0x18(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E00F8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E00FC: 419A001C  beq cr6, 0x831e0118
	if ctx.cr[6].eq {
	pc = 0x831E0118; continue 'dispatch;
	}
	// 831E0100: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831E0104: 480630F9  bl 0x832431fc
	ctx.lr = 0x831E0108;
	// extern call 0x832431FC → crate::xboxkrnl::XAudioUnregisterRenderDriverClient
	crate::xboxkrnl::XAudioUnregisterRenderDriverClient(ctx, base);
	// 831E0108: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E010C: 4198002C  blt cr6, 0x831e0138
	if ctx.cr[6].lt {
	pc = 0x831E0138; continue 'dispatch;
	}
	// 831E0110: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0114: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E0118: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E011C: 419A001C  beq cr6, 0x831e0138
	if ctx.cr[6].eq {
	pc = 0x831E0138; continue 'dispatch;
	}
	// 831E0120: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0124: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E0128: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 831E012C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E0130: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 831E0134: 480630B9  bl 0x832431ec
	ctx.lr = 0x831E0138;
	// extern call 0x832431EC → crate::xboxkrnl::XAudioRegisterRenderDriverClient
	crate::xboxkrnl::XAudioRegisterRenderDriverClient(ctx, base);
	// 831E0138: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E013C: 4BFC8080  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0140(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E0140 size=192
    let mut pc: u32 = 0x831E0140;
    'dispatch: loop {
        match pc {
            0x831E0140 => {
    //   block [0x831E0140..0x831E0200)
	// 831E0140: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0144: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E0148: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E014C: 3D408330  lis r10, -0x7cd0
	ctx.r[10].s64 = -2094006272;
	// 831E0150: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E0154: 394AFF20  addi r10, r10, -0xe0
	ctx.r[10].s64 = ctx.r[10].s64 + -224;
	// 831E0158: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E015C: 2B091800  cmplwi cr6, r9, 0x1800
	ctx.cr[6].compare_u32(ctx.r[9].u32, 6144 as u32, &mut ctx.xer);
	// 831E0160: 419A0090  beq cr6, 0x831e01f0
	if ctx.cr[6].eq {
	pc = 0x831E01F0; continue 'dispatch;
	}
	// 831E0164: 39201800  li r9, 0x1800
	ctx.r[9].s64 = 6144;
	// 831E0168: 7CC000A6  mfmsr r6
	ctx.r[6].u64 = ctx.msr;
	// 831E016C: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831E0170: 7D005028  lwarx r8, 0, r10
	// lwarx
	let ea = ctx.r[10].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[8].u64 = ctx.reserved.u32 as u64;
	// 831E0174: 7CE94214  add r7, r9, r8
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 831E0178: 7CE0512D  stwcx. r7, 0, r10
	// stwcx.
	let addr = ctx.r[10].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[7].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 831E017C: 7CC10164  mtmsrd r6, 1
	ctx.msr = (ctx.r[6].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831E0180: 4082FFE8  bne 0x831e0168
	if !ctx.cr[0].eq {
	pc = 0x831E0168; continue 'dispatch;
	}
	// 831E0184: 7D034378  mr r3, r8
	ctx.r[3].u64 = ctx.r[8].u64;
	// 831E0188: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E018C: 419A0058  beq cr6, 0x831e01e4
	if ctx.cr[6].eq {
	pc = 0x831E01E4; continue 'dispatch;
	}
	// 831E0190: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0194: 7D2A1850  subf r9, r10, r3
	ctx.r[9].s64 = ctx.r[3].s64 - ctx.r[10].s64;
	// 831E0198: 2B091800  cmplwi cr6, r9, 0x1800
	ctx.cr[6].compare_u32(ctx.r[9].u32, 6144 as u32, &mut ctx.xer);
	// 831E019C: 409A0010  bne cr6, 0x831e01ac
	if !ctx.cr[6].eq {
	pc = 0x831E01AC; continue 'dispatch;
	}
	// 831E01A0: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E01A4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E01A8: 48000008  b 0x831e01b0
	pc = 0x831E01B0; continue 'dispatch;
	// 831E01AC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E01B0: 914B0014  stw r10, 0x14(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831E01B4: 554A003E  slwi r10, r10, 0
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E01B8: 906B0010  stw r3, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[3].u32 ) };
	// 831E01BC: 2B0A000E  cmplwi cr6, r10, 0xe
	ctx.cr[6].compare_u32(ctx.r[10].u32, 14 as u32, &mut ctx.xer);
	// 831E01C0: 41990030  bgt cr6, 0x831e01f0
	if ctx.cr[6].gt {
	pc = 0x831E01F0; continue 'dispatch;
	}
	// 831E01C4: 38A01800  li r5, 0x1800
	ctx.r[5].s64 = 6144;
	// 831E01C8: 80840008  lwz r4, 8(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E01CC: 4BFC8345  bl 0x831a8510
	ctx.lr = 0x831E01D0;
	sub_831A8510(ctx, base);
	// 831E01D0: 7C2004AC  lwsync
	// 831E01D4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E01D8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E01DC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E01E0: 4E800020  blr
	return;
	// 831E01E4: 3D408345  lis r10, -0x7cbb
	ctx.r[10].s64 = -2092630016;
	// 831E01E8: 814AD004  lwz r10, -0x2ffc(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12284 as u32) ) } as u64;
	// 831E01EC: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E01F0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E01F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E01F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E01FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0200(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E0200 size=160
    let mut pc: u32 = 0x831E0200;
    'dispatch: loop {
        match pc {
            0x831E0200 => {
    //   block [0x831E0200..0x831E02A0)
	// 831E0200: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0204: 4BFC7F69  bl 0x831a816c
	ctx.lr = 0x831E0208;
	sub_831A8130(ctx, base);
	// 831E0208: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E020C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E0210: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E0214: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E0218: 3CC08345  lis r6, -0x7cbb
	ctx.r[6].s64 = -2092630016;
	// 831E021C: 38AA00BC  addi r5, r10, 0xbc
	ctx.r[5].s64 = ctx.r[10].s64 + 188;
	// 831E0220: 388700A0  addi r4, r7, 0xa0
	ctx.r[4].s64 = ctx.r[7].s64 + 160;
	// 831E0224: 39601800  li r11, 0x1800
	ctx.r[11].s64 = 6144;
	// 831E0228: 90BF0000  stw r5, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E022C: 3C608330  lis r3, -0x7cd0
	ctx.r[3].s64 = -2094006272;
	// 831E0230: 909F0004  stw r4, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E0234: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E0238: 9166D004  stw r11, -0x2ffc(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(-12284 as u32), ctx.r[11].u32 ) };
	// 831E023C: 3BDF0004  addi r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 4;
	// 831E0240: 3943FF20  addi r10, r3, -0xe0
	ctx.r[10].s64 = ctx.r[3].s64 + -224;
	// 831E0244: 7D0000A6  mfmsr r8
	ctx.r[8].u64 = ctx.msr;
	// 831E0248: 7DA10164  mtmsrd r13, 1
	ctx.msr = (ctx.r[13].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831E024C: 7D205028  lwarx r9, 0, r10
	// lwarx
	let ea = ctx.r[10].u32;
	ctx.reserved.u32 = unsafe { crate::rt::load_u32(base as *const u8, ea) };
	ctx.r[9].u64 = ctx.reserved.u32 as u64;
	// 831E0250: 7F09E800  cmpw cr6, r9, r29
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[29].s32, &mut ctx.xer);
	// 831E0254: 409A0014  bne cr6, 0x831e0268
	if !ctx.cr[6].eq {
	pc = 0x831E0268; continue 'dispatch;
	}
	// 831E0258: 7D60512D  stwcx. r11, 0, r10
	// stwcx.
	let addr = ctx.r[10].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[11].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 831E025C: 7D010164  mtmsrd r8, 1
	ctx.msr = (ctx.r[8].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831E0260: 4082FFE4  bne 0x831e0244
	if !ctx.cr[0].eq {
	pc = 0x831E0244; continue 'dispatch;
	}
	// 831E0264: 4800000C  b 0x831e0270
	pc = 0x831E0270; continue 'dispatch;
	// 831E0268: 7D20512D  stwcx. r9, 0, r10
	// stwcx.
	let addr = ctx.r[10].u32;
	ctx.cr[0].lt = false;
	ctx.cr[0].gt = false;
	let ok = unsafe { crate::rt::stwcx32(base as *mut u8, addr, ctx.reserved.u32, ctx.r[9].u32) };
	ctx.cr[0].eq = ok;
	ctx.cr[0].so = ctx.xer.so;
	// 831E026C: 7D010164  mtmsrd r8, 1
	ctx.msr = (ctx.r[8].u32 & 0x8020) | (ctx.msr & !0x8020);
	// 831E0270: 807F0018  lwz r3, 0x18(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E0274: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E0278: 419A0014  beq cr6, 0x831e028c
	if ctx.cr[6].eq {
	pc = 0x831E028C; continue 'dispatch;
	}
	// 831E027C: 48062F81  bl 0x832431fc
	ctx.lr = 0x831E0280;
	// extern call 0x832431FC → crate::xboxkrnl::XAudioUnregisterRenderDriverClient
	crate::xboxkrnl::XAudioUnregisterRenderDriverClient(ctx, base);
	// 831E0280: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E0284: 41980008  blt cr6, 0x831e028c
	if ctx.cr[6].lt {
	pc = 0x831E028C; continue 'dispatch;
	}
	// 831E0288: 93BF0018  stw r29, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[29].u32 ) };
	// 831E028C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E0290: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831E0294: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E0298: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E029C: 4BFC7F20  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E02A0 size=8
    let mut pc: u32 = 0x831E02A0;
    'dispatch: loop {
        match pc {
            0x831E02A0 => {
    //   block [0x831E02A0..0x831E02A8)
	// 831E02A0: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E02A4: 480000BC  b 0x831e0360
	sub_831E0360(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E02A8 size=24
    let mut pc: u32 = 0x831E02A8;
    'dispatch: loop {
        match pc {
            0x831E02A8 => {
    //   block [0x831E02A8..0x831E02C0)
	// 831E02A8: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E02AC: 394B0004  addi r10, r11, 4
	ctx.r[10].s64 = ctx.r[11].s64 + 4;
	// 831E02B0: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E02B4: 38690001  addi r3, r9, 1
	ctx.r[3].s64 = ctx.r[9].s64 + 1;
	// 831E02B8: 906B0008  stw r3, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 831E02BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E02C0 size=24
    let mut pc: u32 = 0x831E02C0;
    'dispatch: loop {
        match pc {
            0x831E02C0 => {
    //   block [0x831E02C0..0x831E02D8)
	// 831E02C0: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 831E02C4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E02C8: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E02CC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E02D0: B1440002  sth r10, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[10].u16 ) };
	// 831E02D4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E02D8 size=16
    let mut pc: u32 = 0x831E02D8;
    'dispatch: loop {
        match pc {
            0x831E02D8 => {
    //   block [0x831E02D8..0x831E02E8)
	// 831E02D8: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E02DC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E02E0: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E02E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E02E8 size=8
    let mut pc: u32 = 0x831E02E8;
    'dispatch: loop {
        match pc {
            0x831E02E8 => {
    //   block [0x831E02E8..0x831E02F0)
	// 831E02E8: 90640000  stw r3, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 831E02EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E02F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E02F0 size=96
    let mut pc: u32 = 0x831E02F0;
    'dispatch: loop {
        match pc {
            0x831E02F0 => {
    //   block [0x831E02F0..0x831E0350)
	// 831E02F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E02F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E02F8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E02FC: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0300: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E0304: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831E0308: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E030C: 48001D7D  bl 0x831e2088
	ctx.lr = 0x831E0310;
	sub_831E2088(ctx, base);
	// 831E0310: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E0314: 41980028  blt cr6, 0x831e033c
	if ctx.cr[6].lt {
	pc = 0x831E033C; continue 'dispatch;
	}
	// 831E0318: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E031C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E0320: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0324: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E0328: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E032C: 4E800421  bctrl
	ctx.lr = 0x831E0330;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0330: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E0334: 807F0018  lwz r3, 0x18(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E0338: 48062ED5  bl 0x8324320c
	ctx.lr = 0x831E033C;
	// extern call 0x8324320C → crate::xboxkrnl::XAudioSubmitRenderDriverFrame
	crate::xboxkrnl::XAudioSubmitRenderDriverFrame(ctx, base);
	// 831E033C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E0340: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0344: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E0348: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E034C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0350(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0350 size=16
    let mut pc: u32 = 0x831E0350;
    'dispatch: loop {
        match pc {
            0x831E0350 => {
    //   block [0x831E0350..0x831E0360)
	// 831E0350: 3960001C  li r11, 0x1c
	ctx.r[11].s64 = 28;
	// 831E0354: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0358: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E035C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0360(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E0360 size=48
    let mut pc: u32 = 0x831E0360;
    'dispatch: loop {
        match pc {
            0x831E0360 => {
    //   block [0x831E0360..0x831E0390)
	// 831E0360: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0364: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E0368: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E036C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0370: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E0374: 4BFFFE8D  bl 0x831e0200
	ctx.lr = 0x831E0378;
	sub_831E0200(ctx, base);
	// 831E0378: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E037C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E0380: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0384: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E0388: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E038C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0390(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0390 size=72
    let mut pc: u32 = 0x831E0390;
    'dispatch: loop {
        match pc {
            0x831E0390 => {
    //   block [0x831E0390..0x831E03D8)
	// 831E0390: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E0394: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E0398: 392B0028  addi r9, r11, 0x28
	ctx.r[9].s64 = ctx.r[11].s64 + 40;
	// 831E039C: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E03A0: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E03A4: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E03A8: 91230004  stw r9, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E03AC: 80C40004  lwz r6, 4(r4)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E03B0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E03B4: 38A800BC  addi r5, r8, 0xbc
	ctx.r[5].s64 = ctx.r[8].s64 + 188;
	// 831E03B8: 90C3000C  stw r6, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 831E03BC: 388700A0  addi r4, r7, 0xa0
	ctx.r[4].s64 = ctx.r[7].s64 + 160;
	// 831E03C0: 90A30000  stw r5, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E03C4: 39630004  addi r11, r3, 4
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	// 831E03C8: 91430010  stw r10, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 831E03CC: 90830004  stw r4, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E03D0: 91430014  stw r10, 0x14(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[10].u32 ) };
	// 831E03D4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E03D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E03D8 size=224
    let mut pc: u32 = 0x831E03D8;
    'dispatch: loop {
        match pc {
            0x831E03D8 => {
    //   block [0x831E03D8..0x831E04B8)
	// 831E03D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E03DC: 4BFC7D89  bl 0x831a8164
	ctx.lr = 0x831E03E0;
	sub_831A8130(ctx, base);
	// 831E03E0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E03E4: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E03E8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E03EC: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 831E03F0: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 831E03F4: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 831E03F8: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E03FC: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0400: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0404: 4E800421  bctrl
	ctx.lr = 0x831E0408;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0408: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E040C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E0410: 419A0078  beq cr6, 0x831e0488
	if ctx.cr[6].eq {
	pc = 0x831E0488; continue 'dispatch;
	}
	// 831E0414: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E0418: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E041C: 392B0028  addi r9, r11, 0x28
	ctx.r[9].s64 = ctx.r[11].s64 + 40;
	// 831E0420: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E0424: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0428: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E042C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0430: 80DD0004  lwz r6, 4(r29)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0434: 38A800BC  addi r5, r8, 0xbc
	ctx.r[5].s64 = ctx.r[8].s64 + 188;
	// 831E0438: 90DF000C  stw r6, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 831E043C: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E0440: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 831E0444: 388700A0  addi r4, r7, 0xa0
	ctx.r[4].s64 = ctx.r[7].s64 + 160;
	// 831E0448: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 831E044C: 54AB003E  slwi r11, r5, 0
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E0450: 90BF0000  stw r5, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E0454: 3BDF0004  addi r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 4;
	// 831E0458: 909F0004  stw r4, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E045C: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 831E0460: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E0464: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E0468: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E046C: 4E800421  bctrl
	ctx.lr = 0x831E0470;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0470: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E0474: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831E0478: 41980020  blt cr6, 0x831e0498
	if ctx.cr[6].lt {
	pc = 0x831E0498; continue 'dispatch;
	}
	// 831E047C: 93FB0000  stw r31, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831E0480: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0484: 4BFC7D30  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E0488: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E048C: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E0490: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0494: 4BFC7D20  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E0498: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E049C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E04A0: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E04A4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E04A8: 4E800421  bctrl
	ctx.lr = 0x831E04AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E04AC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E04B0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E04B4: 4BFC7D00  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E04B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E04B8 size=256
    let mut pc: u32 = 0x831E04B8;
    'dispatch: loop {
        match pc {
            0x831E04B8 => {
    //   block [0x831E04B8..0x831E05B8)
	// 831E04B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E04BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E04C0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E04C4: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E04C8: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E04CC: 7CDF3378  mr r31, r6
	ctx.r[31].u64 = ctx.r[6].u64;
	// 831E04D0: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E04D4: 409A0040  bne cr6, 0x831e0514
	if !ctx.cr[6].eq {
	pc = 0x831E0514; continue 'dispatch;
	}
	// 831E04D8: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E04DC: 2B0A0003  cmplwi cr6, r10, 3
	ctx.cr[6].compare_u32(ctx.r[10].u32, 3 as u32, &mut ctx.xer);
	// 831E04E0: 409A0034  bne cr6, 0x831e0514
	if !ctx.cr[6].eq {
	pc = 0x831E0514; continue 'dispatch;
	}
	// 831E04E4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E04E8: 38DF0004  addi r6, r31, 4
	ctx.r[6].s64 = ctx.r[31].s64 + 4;
	// 831E04EC: 80BF0004  lwz r5, 4(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E04F0: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E04F4: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E04F8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E04FC: 4E800421  bctrl
	ctx.lr = 0x831E0500;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0500: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E0504: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0508: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E050C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E0510: 4E800020  blr
	return;
	// 831E0514: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E0518: 409A0048  bne cr6, 0x831e0560
	if !ctx.cr[6].eq {
	pc = 0x831E0560; continue 'dispatch;
	}
	// 831E051C: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E0520: 2B0A0002  cmplwi cr6, r10, 2
	ctx.cr[6].compare_u32(ctx.r[10].u32, 2 as u32, &mut ctx.xer);
	// 831E0524: 409A003C  bne cr6, 0x831e0560
	if !ctx.cr[6].eq {
	pc = 0x831E0560; continue 'dispatch;
	}
	// 831E0528: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E052C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E0530: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E0534: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0538: 4E800421  bctrl
	ctx.lr = 0x831E053C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E053C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E0540: 41980064  blt cr6, 0x831e05a4
	if ctx.cr[6].lt {
	pc = 0x831E05A4; continue 'dispatch;
	}
	// 831E0544: 89410050  lbz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E0548: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E054C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E0550: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0554: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E0558: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E055C: 4E800020  blr
	return;
	// 831E0560: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E0564: 409A0038  bne cr6, 0x831e059c
	if !ctx.cr[6].eq {
	pc = 0x831E059C; continue 'dispatch;
	}
	// 831E0568: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E056C: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E0570: 409A002C  bne cr6, 0x831e059c
	if !ctx.cr[6].eq {
	pc = 0x831E059C; continue 'dispatch;
	}
	// 831E0574: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0578: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E057C: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831E0580: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0584: 4E800421  bctrl
	ctx.lr = 0x831E0588;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0588: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E058C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0590: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E0594: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E0598: 4E800020  blr
	return;
	// 831E059C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E05A0: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E05A4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E05A8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E05AC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E05B0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E05B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E05B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E05B8 size=44
    let mut pc: u32 = 0x831E05B8;
    'dispatch: loop {
        match pc {
            0x831E05B8 => {
    //   block [0x831E05B8..0x831E05E4)
	// 831E05B8: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E05BC: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E05C0: 409A0024  bne cr6, 0x831e05e4
	if !ctx.cr[6].eq {
		sub_831E05E4(ctx, base);
		return;
	}
	// 831E05C4: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E05C8: 2B0A0003  cmplwi cr6, r10, 3
	ctx.cr[6].compare_u32(ctx.r[10].u32, 3 as u32, &mut ctx.xer);
	// 831E05CC: 409A0018  bne cr6, 0x831e05e4
	if !ctx.cr[6].eq {
		sub_831E05E4(ctx, base);
		return;
	}
	// 831E05D0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E05D4: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E05D8: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E05DC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E05E0: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E05E4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E05E4 size=44
    let mut pc: u32 = 0x831E05E4;
    'dispatch: loop {
        match pc {
            0x831E05E4 => {
    //   block [0x831E05E4..0x831E0610)
	// 831E05E4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E05E8: 409A0028  bne cr6, 0x831e0610
	if !ctx.cr[6].eq {
		sub_831E0610(ctx, base);
		return;
	}
	// 831E05EC: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E05F0: 2B0A0002  cmplwi cr6, r10, 2
	ctx.cr[6].compare_u32(ctx.r[10].u32, 2 as u32, &mut ctx.xer);
	// 831E05F4: 409A001C  bne cr6, 0x831e0610
	if !ctx.cr[6].eq {
		sub_831E0610(ctx, base);
		return;
	}
	// 831E05F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E05FC: 81460000  lwz r10, 0(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0600: 5544063E  clrlwi r4, r10, 0x18
	ctx.r[4].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831E0604: 812B0020  lwz r9, 0x20(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E0608: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E060C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0610 size=40
    let mut pc: u32 = 0x831E0610;
    'dispatch: loop {
        match pc {
            0x831E0610 => {
    //   block [0x831E0610..0x831E0638)
	// 831E0610: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E0614: 409A0024  bne cr6, 0x831e0638
	if !ctx.cr[6].eq {
		sub_831E0638(ctx, base);
		return;
	}
	// 831E0618: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E061C: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E0620: 409A0018  bne cr6, 0x831e0638
	if !ctx.cr[6].eq {
		sub_831E0638(ctx, base);
		return;
	}
	// 831E0624: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0628: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E062C: 814B0030  lwz r10, 0x30(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 831E0630: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0634: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0638(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0638 size=12
    let mut pc: u32 = 0x831E0638;
    'dispatch: loop {
        match pc {
            0x831E0638 => {
    //   block [0x831E0638..0x831E0644)
	// 831E0638: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E063C: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E0640: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0648(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0648 size=8
    let mut pc: u32 = 0x831E0648;
    'dispatch: loop {
        match pc {
            0x831E0648 => {
    //   block [0x831E0648..0x831E0650)
	// 831E0648: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 831E064C: 48000934  b 0x831e0f80
	sub_831E0F80(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0650(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E0650 size=72
    let mut pc: u32 = 0x831E0650;
    'dispatch: loop {
        match pc {
            0x831E0650 => {
    //   block [0x831E0650..0x831E0698)
	// 831E0650: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0654: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E0658: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E065C: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0660: 39630004  addi r11, r3, 4
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	// 831E0664: 346AFFFF  addic. r3, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[3].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E0668: 906B0004  stw r3, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 831E066C: 4082001C  bne 0x831e0688
	if !ctx.cr[0].eq {
	pc = 0x831E0688; continue 'dispatch;
	}
	// 831E0670: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0674: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831E0678: 812A000C  lwz r9, 0xc(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E067C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E0680: 4E800421  bctrl
	ctx.lr = 0x831E0684;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0684: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0688: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E068C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E0690: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E0694: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0698(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0698 size=24
    let mut pc: u32 = 0x831E0698;
    'dispatch: loop {
        match pc {
            0x831E0698 => {
    //   block [0x831E0698..0x831E06B0)
	// 831E0698: 39600006  li r11, 6
	ctx.r[11].s64 = 6;
	// 831E069C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E06A0: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E06A4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E06A8: B1440002  sth r10, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[10].u16 ) };
	// 831E06AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E06B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E06B0 size=16
    let mut pc: u32 = 0x831E06B0;
    'dispatch: loop {
        match pc {
            0x831E06B0 => {
    //   block [0x831E06B0..0x831E06C0)
	// 831E06B0: 8963001A  lbz r11, 0x1a(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(26 as u32) ) } as u64;
	// 831E06B4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E06B8: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E06BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E06C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E06C0 size=12
    let mut pc: u32 = 0x831E06C0;
    'dispatch: loop {
        match pc {
            0x831E06C0 => {
    //   block [0x831E06C0..0x831E06CC)
	// 831E06C0: 9883001A  stb r4, 0x1a(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(26 as u32), ctx.r[4].u8 ) };
	// 831E06C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E06C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E06D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E06D0 size=20
    let mut pc: u32 = 0x831E06D0;
    'dispatch: loop {
        match pc {
            0x831E06D0 => {
    //   block [0x831E06D0..0x831E06E4)
	// 831E06D0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E06D4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E06D8: 814B0038  lwz r10, 0x38(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E06DC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E06E0: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E06E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E06E8 size=12
    let mut pc: u32 = 0x831E06E8;
    'dispatch: loop {
        match pc {
            0x831E06E8 => {
    //   block [0x831E06E8..0x831E06F4)
	// 831E06E8: 3963FFFC  addi r11, r3, -4
	ctx.r[11].s64 = ctx.r[3].s64 + -4;
	// 831E06EC: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E06F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E06F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E06F8 size=200
    let mut pc: u32 = 0x831E06F8;
    'dispatch: loop {
        match pc {
            0x831E06F8 => {
    //   block [0x831E06F8..0x831E07C0)
	// 831E06F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E06FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E0700: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E0704: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E0708: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E070C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E0710: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E0714: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0718: 895E0008  lbz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E071C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E0720: 419A001C  beq cr6, 0x831e073c
	if ctx.cr[6].eq {
	pc = 0x831E073C; continue 'dispatch;
	}
	// 831E0724: 896B0000  lbz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0728: 5549063E  clrlwi r9, r10, 0x18
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831E072C: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 831E0730: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E0734: 41990008  bgt cr6, 0x831e073c
	if ctx.cr[6].gt {
	pc = 0x831E073C; continue 'dispatch;
	}
	// 831E0738: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831E073C: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831E0740: 995F0018  stb r10, 0x18(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[10].u8 ) };
	// 831E0744: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E0748: 419A0028  beq cr6, 0x831e0770
	if ctx.cr[6].eq {
	pc = 0x831E0770; continue 'dispatch;
	}
	// 831E074C: 81250000  lwz r9, 0(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0750: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E0754: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 831E0758: 7D0B5214  add r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E075C: 5504103A  slwi r4, r8, 2
	ctx.r[4].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831E0760: 80E90014  lwz r7, 0x14(r9)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0764: 7CE903A6  mtctr r7
	ctx.ctr.u64 = ctx.r[7].u64;
	// 831E0768: 4E800421  bctrl
	ctx.lr = 0x831E076C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E076C: 907F0014  stw r3, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 831E0770: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0774: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0778: 809E000C  lwz r4, 0xc(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E077C: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 831E0780: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E0784: 4E800421  bctrl
	ctx.lr = 0x831E0788;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E0788: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E078C: 4198001C  blt cr6, 0x831e07a8
	if ctx.cr[6].lt {
	pc = 0x831E07A8; continue 'dispatch;
	}
	// 831E0790: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0794: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0798: 889E0009  lbz r4, 9(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(9 as u32) ) } as u64;
	// 831E079C: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E07A0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E07A4: 4E800421  bctrl
	ctx.lr = 0x831E07A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E07A8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E07AC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E07B0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E07B4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E07B8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E07BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E07C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E07C0 size=344
    let mut pc: u32 = 0x831E07C0;
    'dispatch: loop {
        match pc {
            0x831E07C0 => {
    //   block [0x831E07C0..0x831E0918)
	// 831E07C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E07C4: 4BFC7999  bl 0x831a815c
	ctx.lr = 0x831E07C8;
	sub_831A8130(ctx, base);
	// 831E07C8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E07CC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E07D0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E07D4: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 831E07D8: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 831E07DC: 48062981  bl 0x8324315c
	ctx.lr = 0x831E07E0;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E07E0: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E07E4: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E07E8: 3BABD530  addi r29, r11, -0x2ad0
	ctx.r[29].s64 = ctx.r[11].s64 + -10960;
	// 831E07EC: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 831E07F0: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E07F4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E07F8: 419A0010  beq cr6, 0x831e0808
	if ctx.cr[6].eq {
	pc = 0x831E0808; continue 'dispatch;
	}
	// 831E07FC: 815D0008  lwz r10, 8(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0800: 7F1C5040  cmplw cr6, r28, r10
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0804: 419A0018  beq cr6, 0x831e081c
	if ctx.cr[6].eq {
	pc = 0x831E081C; continue 'dispatch;
	}
	// 831E0808: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E080C: 48062271  bl 0x83242a7c
	ctx.lr = 0x831E0810;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E0810: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0814: 939D0008  stw r28, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 831E0818: 9B5D000C  stb r26, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[26].u8 ) };
	// 831E081C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0820: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E0824: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0828: 897F0010  lbz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E082C: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 831E0830: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E0834: 554A1838  slwi r10, r10, 3
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E0838: 419A0084  beq cr6, 0x831e08bc
	if ctx.cr[6].eq {
	pc = 0x831E08BC; continue 'dispatch;
	}
	// 831E083C: 395E0008  addi r10, r30, 8
	ctx.r[10].s64 = ctx.r[30].s64 + 8;
	// 831E0840: 997E0000  stb r11, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E0844: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831E0848: 915E0004  stw r10, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E084C: 891F0010  lbz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0850: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831E0854: 419A006C  beq cr6, 0x831e08c0
	if ctx.cr[6].eq {
	pc = 0x831E08C0; continue 'dispatch;
	}
	// 831E0858: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E085C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0860: 811F0014  lwz r8, 0x14(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0864: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831E0868: 80FE0004  lwz r7, 4(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E086C: 7CCB40AE  lbzx r6, r11, r8
	ctx.r[6].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 831E0870: 7CCA39AE  stbx r6, r10, r7
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[7].u32), ctx.r[6].u8) };
	// 831E0874: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0878: 7CAA4214  add r5, r10, r8
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E087C: 811F0014  lwz r8, 0x14(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0880: 7C8B4214  add r4, r11, r8
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 831E0884: 88640001  lbz r3, 1(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E0888: 98650001  stb r3, 1(r5)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[5].u32.wrapping_add(1 as u32), ctx.r[3].u8 ) };
	// 831E088C: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0890: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0894: 7CEB3A14  add r7, r11, r7
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 831E0898: 7CCA4214  add r6, r10, r8
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E089C: C0070008  lfs f0, 8(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E08A0: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 831E08A4: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 831E08A8: D0060004  stfs f0, 4(r6)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E08AC: 88BF0010  lbz r5, 0x10(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E08B0: 7F092840  cmplw cr6, r9, r5
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[5].u32, &mut ctx.xer);
	// 831E08B4: 4198FFAC  blt cr6, 0x831e0860
	if ctx.cr[6].lt {
	pc = 0x831E0860; continue 'dispatch;
	}
	// 831E08B8: 48000008  b 0x831e08c0
	pc = 0x831E08C0; continue 'dispatch;
	// 831E08BC: 91590000  stw r10, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E08C0: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E08C4: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E08C8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E08CC: 419A0040  beq cr6, 0x831e090c
	if ctx.cr[6].eq {
	pc = 0x831E090C; continue 'dispatch;
	}
	// 831E08D0: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E08D4: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E08D8: 409A0034  bne cr6, 0x831e090c
	if !ctx.cr[6].eq {
	pc = 0x831E090C; continue 'dispatch;
	}
	// 831E08DC: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E08E0: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E08E4: 40820028  bne 0x831e090c
	if !ctx.cr[0].eq {
	pc = 0x831E090C; continue 'dispatch;
	}
	// 831E08E8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E08EC: 8BFD000C  lbz r31, 0xc(r29)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E08F0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E08F4: 915D0008  stw r10, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E08F8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E08FC: 997D000C  stb r11, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0900: 4806216D  bl 0x83242a6c
	ctx.lr = 0x831E0904;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0904: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0908: 48062865  bl 0x8324316c
	ctx.lr = 0x831E090C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E090C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0910: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E0914: 4BFC7898  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E0918 size=612
    let mut pc: u32 = 0x831E0918;
    'dispatch: loop {
        match pc {
            0x831E0918 => {
    //   block [0x831E0918..0x831E0B7C)
	// 831E0918: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E091C: 4BFC7849  bl 0x831a8164
	ctx.lr = 0x831E0920;
	sub_831A8130(ctx, base);
	// 831E0920: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0924: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E0928: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E092C: 48062831  bl 0x8324315c
	ctx.lr = 0x831E0930;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E0930: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E0934: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E0938: 3BABD530  addi r29, r11, -0x2ad0
	ctx.r[29].s64 = ctx.r[11].s64 + -10960;
	// 831E093C: 7DBC6B78  mr r28, r13
	ctx.r[28].u64 = ctx.r[13].u64;
	// 831E0940: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0944: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0948: 419A0010  beq cr6, 0x831e0958
	if ctx.cr[6].eq {
	pc = 0x831E0958; continue 'dispatch;
	}
	// 831E094C: 813D0008  lwz r9, 8(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0950: 7F1C4840  cmplw cr6, r28, r9
	ctx.cr[6].compare_u32(ctx.r[28].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0954: 419A0024  beq cr6, 0x831e0978
	if ctx.cr[6].eq {
	pc = 0x831E0978; continue 'dispatch;
	}
	// 831E0958: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E095C: 48062121  bl 0x83242a7c
	ctx.lr = 0x831E0960;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E0960: 7F89E378  mr r9, r28
	ctx.r[9].u64 = ctx.r[28].u64;
	// 831E0964: 7F68DB78  mr r8, r27
	ctx.r[8].u64 = ctx.r[27].u64;
	// 831E0968: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E096C: 913D0008  stw r9, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 831E0970: 991D000C  stb r8, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[8].u8 ) };
	// 831E0974: 48000008  b 0x831e097c
	pc = 0x831E097C; continue 'dispatch;
	// 831E0978: 891D000C  lbz r8, 0xc(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E097C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0980: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E0984: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0988: 419A018C  beq cr6, 0x831e0b14
	if ctx.cr[6].eq {
	pc = 0x831E0B14; continue 'dispatch;
	}
	// 831E098C: 895E0000  lbz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0990: 88FF0018  lbz r7, 0x18(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E0994: 7D465378  mr r6, r10
	ctx.r[6].u64 = ctx.r[10].u64;
	// 831E0998: 7F063840  cmplw cr6, r6, r7
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[7].u32, &mut ctx.xer);
	// 831E099C: 409900A8  ble cr6, 0x831e0a44
	if !ctx.cr[6].gt {
	pc = 0x831E0A44; continue 'dispatch;
	}
	// 831E09A0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E09A4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E09A8: 419A0048  beq cr6, 0x831e09f0
	if ctx.cr[6].eq {
	pc = 0x831E09F0; continue 'dispatch;
	}
	// 831E09AC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E09B0: 409A0040  bne cr6, 0x831e09f0
	if !ctx.cr[6].eq {
	pc = 0x831E09F0; continue 'dispatch;
	}
	// 831E09B4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E09B8: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E09BC: 40820034  bne 0x831e09f0
	if !ctx.cr[0].eq {
	pc = 0x831E09F0; continue 'dispatch;
	}
	// 831E09C0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E09C4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E09C8: 997D000C  stb r11, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E09CC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E09D0: 915D0008  stw r10, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E09D4: 7D1F4378  mr r31, r8
	ctx.r[31].u64 = ctx.r[8].u64;
	// 831E09D8: 48062095  bl 0x83242a6c
	ctx.lr = 0x831E09DC;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E09DC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E09E0: 4806278D  bl 0x8324316c
	ctx.lr = 0x831E09E4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E09E4: 891D000C  lbz r8, 0xc(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E09E8: 813D0008  lwz r9, 8(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E09EC: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E09F0: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E09F4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E09F8: 419A003C  beq cr6, 0x831e0a34
	if ctx.cr[6].eq {
	pc = 0x831E0A34; continue 'dispatch;
	}
	// 831E09FC: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0A00: 409A0034  bne cr6, 0x831e0a34
	if !ctx.cr[6].eq {
	pc = 0x831E0A34; continue 'dispatch;
	}
	// 831E0A04: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0A08: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0A0C: 40820028  bne 0x831e0a34
	if !ctx.cr[0].eq {
	pc = 0x831E0A34; continue 'dispatch;
	}
	// 831E0A10: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0A14: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0A18: 997D000C  stb r11, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0A1C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E0A20: 915D0008  stw r10, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0A24: 7D1F4378  mr r31, r8
	ctx.r[31].u64 = ctx.r[8].u64;
	// 831E0A28: 48062045  bl 0x83242a6c
	ctx.lr = 0x831E0A2C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0A2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0A30: 4806273D  bl 0x8324316c
	ctx.lr = 0x831E0A34;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0A34: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E0A38: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E0A3C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0A40: 4BFC7774  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E0A44: 554B063E  clrlwi r11, r10, 0x18
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 831E0A48: 995F0010  stb r10, 0x10(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u8 ) };
	// 831E0A4C: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831E0A50: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E0A54: 419A007C  beq cr6, 0x831e0ad0
	if ctx.cr[6].eq {
	pc = 0x831E0AD0; continue 'dispatch;
	}
	// 831E0A58: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0A5C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0A60: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0A64: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831E0A68: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0A6C: 7CC858AE  lbzx r6, r8, r11
	ctx.r[6].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831E0A70: 7CCA39AE  stbx r6, r10, r7
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[7].u32), ctx.r[6].u8) };
	// 831E0A74: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0A78: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0A7C: 7CA85A14  add r5, r8, r11
	ctx.r[5].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831E0A80: 7C8A3A14  add r4, r10, r7
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 831E0A84: 88650001  lbz r3, 1(r5)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[5].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E0A88: 98640001  stb r3, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[3].u8 ) };
	// 831E0A8C: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0A90: 811E0004  lwz r8, 4(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0A94: 7D085A14  add r8, r8, r11
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 831E0A98: 7CEA3A14  add r7, r10, r7
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 831E0A9C: C0080004  lfs f0, 4(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E0AA0: D0070004  stfs f0, 4(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E0AA4: 80FE0004  lwz r7, 4(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0AA8: 811F0014  lwz r8, 0x14(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0AAC: 7CC75A14  add r6, r7, r11
	ctx.r[6].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 831E0AB0: 7CAA4214  add r5, r10, r8
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E0AB4: C1A60004  lfs f13, 4(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E0AB8: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 831E0ABC: D1A50008  stfs f13, 8(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E0AC0: 889F0010  lbz r4, 0x10(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0AC4: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 831E0AC8: 7F092040  cmplw cr6, r9, r4
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[4].u32, &mut ctx.xer);
	// 831E0ACC: 4198FF94  blt cr6, 0x831e0a60
	if ctx.cr[6].lt {
	pc = 0x831E0A60; continue 'dispatch;
	}
	// 831E0AD0: 897F0010  lbz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0AD4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831E0AD8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E0ADC: 419A0030  beq cr6, 0x831e0b0c
	if ctx.cr[6].eq {
	pc = 0x831E0B0C; continue 'dispatch;
	}
	// 831E0AE0: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0AE4: 891F0010  lbz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0AE8: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831E0AEC: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0AF0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0AF4: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0AF8: 40990008  ble cr6, 0x831e0b00
	if !ctx.cr[6].gt {
	pc = 0x831E0B00; continue 'dispatch;
	}
	// 831E0AFC: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831E0B00: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 831E0B04: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 831E0B08: 4082FFE4  bne 0x831e0aec
	if !ctx.cr[0].eq {
	pc = 0x831E0AEC; continue 'dispatch;
	}
	// 831E0B0C: 993F0019  stb r9, 0x19(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(25 as u32), ctx.r[9].u8 ) };
	// 831E0B10: 48000014  b 0x831e0b24
	pc = 0x831E0B24; continue 'dispatch;
	// 831E0B14: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0B18: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0B1C: 997F0010  stb r11, 0x10(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u8 ) };
	// 831E0B20: 995F0019  stb r10, 0x19(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(25 as u32), ctx.r[10].u8 ) };
	// 831E0B24: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0B28: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E0B2C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831E0B30: 419A0040  beq cr6, 0x831e0b70
	if ctx.cr[6].eq {
	pc = 0x831E0B70; continue 'dispatch;
	}
	// 831E0B34: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0B38: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E0B3C: 409A0034  bne cr6, 0x831e0b70
	if !ctx.cr[6].eq {
	pc = 0x831E0B70; continue 'dispatch;
	}
	// 831E0B40: 3569FFFF  addic. r11, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0B44: 917D0004  stw r11, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0B48: 40820028  bne 0x831e0b70
	if !ctx.cr[0].eq {
	pc = 0x831E0B70; continue 'dispatch;
	}
	// 831E0B4C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0B50: 8BFD000C  lbz r31, 0xc(r29)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0B54: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0B58: 915D0008  stw r10, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0B5C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E0B60: 997D000C  stb r11, 0xc(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0B64: 48061F09  bl 0x83242a6c
	ctx.lr = 0x831E0B68;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0B68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0B6C: 48062601  bl 0x8324316c
	ctx.lr = 0x831E0B70;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0B70: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0B74: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0B78: 4BFC763C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0B80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E0B80 size=304
    let mut pc: u32 = 0x831E0B80;
    'dispatch: loop {
        match pc {
            0x831E0B80 => {
    //   block [0x831E0B80..0x831E0CB0)
	// 831E0B80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0B84: 4BFC75E1  bl 0x831a8164
	ctx.lr = 0x831E0B88;
	sub_831A8130(ctx, base);
	// 831E0B88: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0B8C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E0B90: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E0B94: 480625C9  bl 0x8324315c
	ctx.lr = 0x831E0B98;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E0B98: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E0B9C: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E0BA0: 3BCBD530  addi r30, r11, -0x2ad0
	ctx.r[30].s64 = ctx.r[11].s64 + -10960;
	// 831E0BA4: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E0BA8: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0BAC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0BB0: 419A0010  beq cr6, 0x831e0bc0
	if ctx.cr[6].eq {
	pc = 0x831E0BC0; continue 'dispatch;
	}
	// 831E0BB4: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0BB8: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0BBC: 419A001C  beq cr6, 0x831e0bd8
	if ctx.cr[6].eq {
	pc = 0x831E0BD8; continue 'dispatch;
	}
	// 831E0BC0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0BC4: 48061EB9  bl 0x83242a7c
	ctx.lr = 0x831E0BC8;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E0BC8: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 831E0BCC: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0BD0: 9B7E000C  stb r27, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831E0BD4: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0BD8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0BDC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 831E0BE0: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0BE4: 893F0000  lbz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0BE8: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E0BEC: 419A0074  beq cr6, 0x831e0c60
	if ctx.cr[6].eq {
	pc = 0x831E0C60; continue 'dispatch;
	}
	// 831E0BF0: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831E0BF4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 831E0BF8: C00B08A8  lfs f0, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E0BFC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0C00: 895C0010  lbz r10, 0x10(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0C04: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831E0C08: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0C0C: 7F085040  cmplw cr6, r8, r10
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0C10: 40980030  bge cr6, 0x831e0c40
	if !ctx.cr[6].lt {
	pc = 0x831E0C40; continue 'dispatch;
	}
	// 831E0C14: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0C18: 811C0014  lwz r8, 0x14(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0C1C: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 831E0C20: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0C24: 5547083E  rotlwi r7, r10, 1
	ctx.r[7].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831E0C28: 7D4A3A14  add r10, r10, r7
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 831E0C2C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E0C30: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E0C34: C1A80008  lfs f13, 8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E0C38: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E0C3C: 48000008  b 0x831e0c44
	pc = 0x831E0C44; continue 'dispatch;
	// 831E0C40: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E0C44: 897F0000  lbz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0C48: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 831E0C4C: 39290008  addi r9, r9, 8
	ctx.r[9].s64 = ctx.r[9].s64 + 8;
	// 831E0C50: 7F065840  cmplw cr6, r6, r11
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E0C54: 4198FFA8  blt cr6, 0x831e0bfc
	if ctx.cr[6].lt {
	pc = 0x831E0BFC; continue 'dispatch;
	}
	// 831E0C58: 815E0008  lwz r10, 8(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0C5C: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0C60: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 831E0C64: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0C68: 419A003C  beq cr6, 0x831e0ca4
	if ctx.cr[6].eq {
	pc = 0x831E0CA4; continue 'dispatch;
	}
	// 831E0C6C: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0C70: 409A0034  bne cr6, 0x831e0ca4
	if !ctx.cr[6].eq {
	pc = 0x831E0CA4; continue 'dispatch;
	}
	// 831E0C74: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0C78: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0C7C: 40820028  bne 0x831e0ca4
	if !ctx.cr[0].eq {
	pc = 0x831E0CA4; continue 'dispatch;
	}
	// 831E0C80: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0C84: 8BFE000C  lbz r31, 0xc(r30)
	ctx.r[31].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0C88: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0C8C: 997E000C  stb r11, 0xc(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0C90: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0C94: 915E0008  stw r10, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0C98: 48061DD5  bl 0x83242a6c
	ctx.lr = 0x831E0C9C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0C9C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0CA0: 480624CD  bl 0x8324316c
	ctx.lr = 0x831E0CA4;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0CA4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0CA8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E0CAC: 4BFC7508  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0CB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E0CB0 size=476
    let mut pc: u32 = 0x831E0CB0;
    'dispatch: loop {
        match pc {
            0x831E0CB0 => {
    //   block [0x831E0CB0..0x831E0E8C)
	// 831E0CB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0CB4: 4BFC74AD  bl 0x831a8160
	ctx.lr = 0x831E0CB8;
	sub_831A8130(ctx, base);
	// 831E0CB8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0CBC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E0CC0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E0CC4: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 831E0CC8: 48062495  bl 0x8324315c
	ctx.lr = 0x831E0CCC;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E0CCC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E0CD0: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E0CD4: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E0CD8: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E0CDC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0CE0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0CE4: 419A0010  beq cr6, 0x831e0cf4
	if ctx.cr[6].eq {
	pc = 0x831E0CF4; continue 'dispatch;
	}
	// 831E0CE8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0CEC: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0CF0: 419A001C  beq cr6, 0x831e0d0c
	if ctx.cr[6].eq {
	pc = 0x831E0D0C; continue 'dispatch;
	}
	// 831E0CF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0CF8: 48061D85  bl 0x83242a7c
	ctx.lr = 0x831E0CFC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E0CFC: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 831E0D00: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0D04: 9B7F000C  stb r27, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[27].u8 ) };
	// 831E0D08: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0D0C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0D10: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0D14: 893E0000  lbz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0D18: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E0D1C: 419A0078  beq cr6, 0x831e0d94
	if ctx.cr[6].eq {
	pc = 0x831E0D94; continue 'dispatch;
	}
	// 831E0D20: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831E0D24: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0D28: 550A1838  slwi r10, r8, 3
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831E0D2C: 893C0010  lbz r9, 0x10(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E0D30: 7CEA58AE  lbzx r7, r10, r11
	ctx.r[7].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 831E0D34: 7F074840  cmplw cr6, r7, r9
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0D38: 409800AC  bge cr6, 0x831e0de4
	if !ctx.cr[6].lt {
	pc = 0x831E0DE4; continue 'dispatch;
	}
	// 831E0D3C: 556B003E  slwi r11, r11, 0
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E0D40: 813C0014  lwz r9, 0x14(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E0D44: 5747063E  clrlwi r7, r26, 0x18
	ctx.r[7].u64 = ctx.r[26].u32 as u64 & 0x000000FFu64;
	// 831E0D48: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E0D4C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 831E0D50: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0D54: C00B0004  lfs f0, 4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E0D58: 554B083E  rotlwi r11, r10, 1
	ctx.r[11].u64 = ((ctx.r[10].u32).rotate_left(1)) as u64;
	// 831E0D5C: 7CCA5A14  add r6, r10, r11
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E0D60: 54CB103A  slwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E0D64: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E0D68: D00B0008  stfs f0, 8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831E0D6C: 419A0008  beq cr6, 0x831e0d74
	if ctx.cr[6].eq {
	pc = 0x831E0D74; continue 'dispatch;
	}
	// 831E0D70: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831E0D74: 39680001  addi r11, r8, 1
	ctx.r[11].s64 = ctx.r[8].s64 + 1;
	// 831E0D78: 895E0000  lbz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E0D7C: 556B063E  clrlwi r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E0D80: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 831E0D84: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0D88: 4198FF9C  blt cr6, 0x831e0d24
	if ctx.cr[6].lt {
	pc = 0x831E0D24; continue 'dispatch;
	}
	// 831E0D8C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0D90: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0D94: 7DA96B78  mr r9, r13
	ctx.r[9].u64 = ctx.r[13].u64;
	// 831E0D98: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0D9C: 419A003C  beq cr6, 0x831e0dd8
	if ctx.cr[6].eq {
	pc = 0x831E0DD8; continue 'dispatch;
	}
	// 831E0DA0: 7F095040  cmplw cr6, r9, r10
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0DA4: 409A0034  bne cr6, 0x831e0dd8
	if !ctx.cr[6].eq {
	pc = 0x831E0DD8; continue 'dispatch;
	}
	// 831E0DA8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0DAC: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0DB0: 40820028  bne 0x831e0dd8
	if !ctx.cr[0].eq {
	pc = 0x831E0DD8; continue 'dispatch;
	}
	// 831E0DB4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0DB8: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0DBC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0DC0: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0DC4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0DC8: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0DCC: 48061CA1  bl 0x83242a6c
	ctx.lr = 0x831E0DD0;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0DD0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0DD4: 48062399  bl 0x8324316c
	ctx.lr = 0x831E0DD8;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0DD8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0DDC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E0DE0: 4BFC73D0  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 831E0DE4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0DE8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E0DEC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0DF0: 419A0044  beq cr6, 0x831e0e34
	if ctx.cr[6].eq {
	pc = 0x831E0E34; continue 'dispatch;
	}
	// 831E0DF4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0DF8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0DFC: 409A0038  bne cr6, 0x831e0e34
	if !ctx.cr[6].eq {
	pc = 0x831E0E34; continue 'dispatch;
	}
	// 831E0E00: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0E04: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0E08: 4082002C  bne 0x831e0e34
	if !ctx.cr[0].eq {
	pc = 0x831E0E34; continue 'dispatch;
	}
	// 831E0E0C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0E10: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0E14: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0E18: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0E1C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0E20: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0E24: 48061C49  bl 0x83242a6c
	ctx.lr = 0x831E0E28;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0E28: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0E2C: 48062341  bl 0x8324316c
	ctx.lr = 0x831E0E30;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0E30: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E0E34: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E0E38: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0E3C: 419A0040  beq cr6, 0x831e0e7c
	if ctx.cr[6].eq {
	pc = 0x831E0E7C; continue 'dispatch;
	}
	// 831E0E40: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E0E44: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E0E48: 409A0034  bne cr6, 0x831e0e7c
	if !ctx.cr[6].eq {
	pc = 0x831E0E7C; continue 'dispatch;
	}
	// 831E0E4C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E0E50: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E0E54: 40820028  bne 0x831e0e7c
	if !ctx.cr[0].eq {
	pc = 0x831E0E7C; continue 'dispatch;
	}
	// 831E0E58: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E0E5C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E0E60: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0E64: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E0E68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E0E6C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E0E70: 48061BFD  bl 0x83242a6c
	ctx.lr = 0x831E0E74;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E0E74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E0E78: 480622F5  bl 0x8324316c
	ctx.lr = 0x831E0E7C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E0E7C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E0E80: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E0E84: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E0E88: 4BFC7328  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0E90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E0E90 size=236
    let mut pc: u32 = 0x831E0E90;
    'dispatch: loop {
        match pc {
            0x831E0E90 => {
    //   block [0x831E0E90..0x831E0F7C)
	// 831E0E90: FBE1FFF8  std r31, -8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[31].u64 ) };
	// 831E0E94: 54EAD9FE  rlwinm r10, r7, 0x1b, 7, 0x1f
	ctx.r[10].u64 = ctx.r[7].u32 as u64 & 0x0000001Fu64;
	// 831E0E98: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E0E9C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E0EA0: 419A0018  beq cr6, 0x831e0eb8
	if ctx.cr[6].eq {
	pc = 0x831E0EB8; continue 'dispatch;
	}
	// 831E0EA4: 55693830  slwi r9, r11, 7
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 831E0EA8: 7C091A2C  dcbt r9, r3
	// 831E0EAC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E0EB0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E0EB4: 4198FFF0  blt cr6, 0x831e0ea4
	if ctx.cr[6].lt {
	pc = 0x831E0EA4; continue 'dispatch;
	}
	// 831E0EB8: 13E030C7  vcmpequd (lvx128) v31, v0, v6
	tmp.u32 = ctx.r[6].u32;
	tmp.u32 &= !0xFu32;
	// load 16B at tmp.u32 into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
	// 831E0EBC: 54EBF0BE  srwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0F80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E0F80 size=44
    let mut pc: u32 = 0x831E0F80;
    'dispatch: loop {
        match pc {
            0x831E0F80 => {
    //   block [0x831E0F80..0x831E0FAC)
	// 831E0F80: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E0F84: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E0F88: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E0F8C: 390B0108  addi r8, r11, 0x108
	ctx.r[8].s64 = ctx.r[11].s64 + 264;
	// 831E0F90: 38EA00E8  addi r7, r10, 0xe8
	ctx.r[7].s64 = ctx.r[10].s64 + 232;
	// 831E0F94: 38C9FF64  addi r6, r9, -0x9c
	ctx.r[6].s64 = ctx.r[9].s64 + -156;
	// 831E0F98: 91030000  stw r8, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 831E0F9C: 90E30004  stw r7, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 831E0FA0: 39630004  addi r11, r3, 4
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	// 831E0FA4: 90C30004  stw r6, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 831E0FA8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E0FB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E0FB0 size=896
    let mut pc: u32 = 0x831E0FB0;
    'dispatch: loop {
        match pc {
            0x831E0FB0 => {
    //   block [0x831E0FB0..0x831E1330)
	// 831E0FB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E0FB4: 4BFC71AD  bl 0x831a8160
	ctx.lr = 0x831E0FB8;
	sub_831A8130(ctx, base);
	// 831E0FB8: DBC1FFB8  stfd f30, -0x48(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-72 as u32), ctx.f[30].u64 ) };
	// 831E0FBC: DBE1FFC0  stfd f31, -0x40(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 831E0FC0: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E0FC4: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E0FC8: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831E0FCC: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 831E0FD0: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 831E0FD4: 387DFFF8  addi r3, r29, -8
	ctx.r[3].s64 = ctx.r[29].s64 + -8;
	// 831E0FD8: 409A0008  bne cr6, 0x831e0fe0
	if !ctx.cr[6].eq {
	pc = 0x831E0FE0; continue 'dispatch;
	}
	// 831E0FDC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E0FE0: 38810070  addi r4, r1, 0x70
	ctx.r[4].s64 = ctx.r[1].s64 + 112;
	// 831E0FE4: 4800107D  bl 0x831e2060
	ctx.lr = 0x831E0FE8;
	sub_831E2060(ctx, base);
	// 831E0FE8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E0FEC: 41980334  blt cr6, 0x831e1320
	if ctx.cr[6].lt {
	pc = 0x831E1320; continue 'dispatch;
	}
	// 831E0FF0: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831E0FF4: 3BFCFFF8  addi r31, r28, -8
	ctx.r[31].s64 = ctx.r[28].s64 + -8;
	// 831E0FF8: 409A0008  bne cr6, 0x831e1000
	if !ctx.cr[6].eq {
	pc = 0x831E1000; continue 'dispatch;
	}
	// 831E0FFC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E1000: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831E1004: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1008: 48001059  bl 0x831e2060
	ctx.lr = 0x831E100C;
	sub_831E2060(ctx, base);
	// 831E100C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E1010: 41980310  blt cr6, 0x831e1320
	if ctx.cr[6].lt {
	pc = 0x831E1320; continue 'dispatch;
	}
	// 831E1014: 897B001A  lbz r11, 0x1a(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(26 as u32) ) } as u64;
	// 831E1018: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E101C: 409A001C  bne cr6, 0x831e1038
	if !ctx.cr[6].eq {
	pc = 0x831E1038; continue 'dispatch;
	}
	// 831E1020: 897B0019  lbz r11, 0x19(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(25 as u32) ) } as u64;
	// 831E1024: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 831E1028: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831E102C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1030: 99610061  stb r11, 0x61(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(97 as u32), ctx.r[11].u8 ) };
	// 831E1034: 4800118D  bl 0x831e21c0
	ctx.lr = 0x831E1038;
	sub_831E21C0(ctx, base);
	// 831E1038: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E103C: 419802E4  blt cr6, 0x831e1320
	if ctx.cr[6].lt {
	pc = 0x831E1320; continue 'dispatch;
	}
	// 831E1040: 4806211D  bl 0x8324315c
	ctx.lr = 0x831E1044;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1044: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1048: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E104C: 3B4BD530  addi r26, r11, -0x2ad0
	ctx.r[26].s64 = ctx.r[11].s64 + -10960;
	// 831E1050: 7DBF6B78  mr r31, r13
	ctx.r[31].u64 = ctx.r[13].u64;
	// 831E1054: 817A0004  lwz r11, 4(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1058: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E105C: 419A0010  beq cr6, 0x831e106c
	if ctx.cr[6].eq {
	pc = 0x831E106C; continue 'dispatch;
	}
	// 831E1060: 815A0008  lwz r10, 8(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1064: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E1068: 419A0018  beq cr6, 0x831e1080
	if ctx.cr[6].eq {
	pc = 0x831E1080; continue 'dispatch;
	}
	// 831E106C: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 831E1070: 48061A0D  bl 0x83242a7c
	ctx.lr = 0x831E1074;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1074: 817A0004  lwz r11, 4(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1078: 93FA0008  stw r31, 8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(8 as u32), ctx.r[31].u32 ) };
	// 831E107C: 9BDA000C  stb r30, 0xc(r26)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[30].u8 ) };
	// 831E1080: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 831E1084: 915A0004  stw r10, 4(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E1088: 897B0010  lbz r11, 0x10(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[27].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E108C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E1090: 419A0148  beq cr6, 0x831e11d8
	if ctx.cr[6].eq {
	pc = 0x831E11D8; continue 'dispatch;
	}
	// 831E1094: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 831E1098: 3D208203  lis r9, -0x7dfd
	ctx.r[9].s64 = -2113732608;
	// 831E109C: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E10A0: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 831E10A4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E10A8: C3CAE830  lfs f30, -0x17d0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-6096 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 831E10AC: 3BAB2990  addi r29, r11, 0x2990
	ctx.r[29].s64 = ctx.r[11].s64 + 10640;
	// 831E10B0: C3E912AC  lfs f31, 0x12ac(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4780 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 831E10B4: 817B0014  lwz r11, 0x14(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E10B8: 81010068  lwz r8, 0x68(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 831E10BC: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831E10C0: 88C10061  lbz r6, 0x61(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(97 as u32) ) } as u64;
	// 831E10C4: 80E10078  lwz r7, 0x78(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 831E10C8: 3BEB0004  addi r31, r11, 4
	ctx.r[31].s64 = ctx.r[11].s64 + 4;
	// 831E10CC: 88AB0001  lbz r5, 1(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E10D0: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831E10D4: 896B0000  lbz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E10D8: 54AA503E  rotlwi r10, r5, 0xa
	ctx.r[10].u64 = ((ctx.r[5].u32).rotate_left(10)) as u64;
	// 831E10DC: 5569503E  rotlwi r9, r11, 0xa
	ctx.r[9].u64 = ((ctx.r[11].u32).rotate_left(10)) as u64;
	// 831E10E0: 7C6A4214  add r3, r10, r8
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 831E10E4: 7D493A14  add r10, r9, r7
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 831E10E8: 7F053040  cmplw cr6, r5, r6
	ctx.cr[6].compare_u32(ctx.r[5].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831E10EC: 409800D4  bge cr6, 0x831e11c0
	if !ctx.cr[6].lt {
	pc = 0x831E11C0; continue 'dispatch;
	}
	// 831E10F0: 89010071  lbz r8, 0x71(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(113 as u32) ) } as u64;
	// 831E10F4: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E10F8: 409800B0  bge cr6, 0x831e11a8
	if !ctx.cr[6].lt {
	pc = 0x831E11A8; continue 'dispatch;
	}
	// 831E10FC: C01F0000  lfs f0, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E1100: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 831E1104: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 831E1108: 13E0FC07  vcmpneb. (lvlx128) v31, v0, v31
	tmp.u32 = ctx.r[31].u32;
	// load shuffled into ctx.v[63] using VectorMaskL[(tmp.u32 & 0xF)]
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1330 size=72
    let mut pc: u32 = 0x831E1330;
    'dispatch: loop {
        match pc {
            0x831E1330 => {
    //   block [0x831E1330..0x831E1378)
	// 831E1330: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1334: 89630008  lbz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1338: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E133C: 419A001C  beq cr6, 0x831e1358
	if ctx.cr[6].eq {
	pc = 0x831E1358; continue 'dispatch;
	}
	// 831E1340: 894A0000  lbz r10, 0(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1344: 5569063E  clrlwi r9, r11, 0x18
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E1348: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 831E134C: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1350: 41990008  bgt cr6, 0x831e1358
	if ctx.cr[6].gt {
	pc = 0x831E1358; continue 'dispatch;
	}
	// 831E1354: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 831E1358: 556A063E  clrlwi r10, r11, 0x18
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 831E135C: 556B0DFC  rlwinm r11, r11, 1, 0x17, 0x1e
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x7FFFFFFFu64;
	// 831E1360: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1364: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831E1368: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E136C: 394B001C  addi r10, r11, 0x1c
	ctx.r[10].s64 = ctx.r[11].s64 + 28;
	// 831E1370: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E1374: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1378(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1378 size=212
    let mut pc: u32 = 0x831E1378;
    'dispatch: loop {
        match pc {
            0x831E1378 => {
    //   block [0x831E1378..0x831E144C)
	// 831E1378: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E137C: 4BFC6DE9  bl 0x831a8164
	ctx.lr = 0x831E1380;
	sub_831A8130(ctx, base);
	// 831E1380: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1384: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 831E1388: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E138C: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 831E1390: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 831E1394: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E1398: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E139C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E13A0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E13A4: 4E800421  bctrl
	ctx.lr = 0x831E13A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E13A8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E13AC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E13B0: 419A006C  beq cr6, 0x831e141c
	if ctx.cr[6].eq {
	pc = 0x831E141C; continue 'dispatch;
	}
	// 831E13B4: 3D00821A  lis r8, -0x7de6
	ctx.r[8].s64 = -2112225280;
	// 831E13B8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E13BC: 38C80108  addi r6, r8, 0x108
	ctx.r[6].s64 = ctx.r[8].s64 + 264;
	// 831E13C0: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E13C4: 392B0028  addi r9, r11, 0x28
	ctx.r[9].s64 = ctx.r[11].s64 + 40;
	// 831E13C8: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E13CC: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E13D0: 54CB003E  slwi r11, r6, 0
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E13D4: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E13D8: 388700E8  addi r4, r7, 0xe8
	ctx.r[4].s64 = ctx.r[7].s64 + 232;
	// 831E13DC: 80BC0004  lwz r5, 4(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E13E0: 90BF000C  stw r5, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 831E13E4: 3BDF0004  addi r30, r31, 4
	ctx.r[30].s64 = ctx.r[31].s64 + 4;
	// 831E13E8: 909F0004  stw r4, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 831E13EC: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 831E13F0: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E13F4: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 831E13F8: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E13FC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1400: 4E800421  bctrl
	ctx.lr = 0x831E1404;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1404: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E1408: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 831E140C: 41980020  blt cr6, 0x831e142c
	if ctx.cr[6].lt {
	pc = 0x831E142C; continue 'dispatch;
	}
	// 831E1410: 93FB0000  stw r31, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 831E1414: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1418: 4BFC6D9C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E141C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E1420: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E1424: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1428: 4BFC6D8C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E142C: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1430: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1434: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1438: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E143C: 4E800421  bctrl
	ctx.lr = 0x831E1440;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1440: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E1444: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1448: 4BFC6D6C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1450(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1450 size=48
    let mut pc: u32 = 0x831E1450;
    'dispatch: loop {
        match pc {
            0x831E1450 => {
    //   block [0x831E1450..0x831E1480)
	// 831E1450: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 831E1454: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 831E1458: 7CA72B78  mr r7, r5
	ctx.r[7].u64 = ctx.r[5].u64;
	// 831E145C: 388B0008  addi r4, r11, 8
	ctx.r[4].s64 = ctx.r[11].s64 + 8;
	// 831E1460: 386A000C  addi r3, r10, 0xc
	ctx.r[3].s64 = ctx.r[10].s64 + 12;
	// 831E1464: 812B0048  lwz r9, 0x48(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E1468: 912A00AC  stw r9, 0xac(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(172 as u32), ctx.r[9].u32 ) };
	// 831E146C: 810B004C  lwz r8, 0x4c(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 831E1470: 910A00B0  stw r8, 0xb0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(176 as u32), ctx.r[8].u32 ) };
	// 831E1474: 88CB0045  lbz r6, 0x45(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(69 as u32) ) } as u64;
	// 831E1478: 88AB0044  lbz r5, 0x44(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E147C: 48005664  b 0x831e6ae0
	sub_831E6AE0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1480 size=64
    let mut pc: u32 = 0x831E1480;
    'dispatch: loop {
        match pc {
            0x831E1480 => {
    //   block [0x831E1480..0x831E14C0)
	// 831E1480: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E1484: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E1488: 409A005C  bne cr6, 0x831e14e4
	if !ctx.cr[6].eq {
		sub_831E14E4(ctx, base);
		return;
	}
	// 831E148C: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E1490: 2B0A0003  cmplwi cr6, r10, 3
	ctx.cr[6].compare_u32(ctx.r[10].u32, 3 as u32, &mut ctx.xer);
	// 831E1494: 409A0050  bne cr6, 0x831e14e4
	if !ctx.cr[6].eq {
		sub_831E14E4(ctx, base);
		return;
	}
	// 831E1498: 81660004  lwz r11, 4(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E149C: 2B0B0038  cmplwi cr6, r11, 0x38
	ctx.cr[6].compare_u32(ctx.r[11].u32, 56 as u32, &mut ctx.xer);
	// 831E14A0: 409A0020  bne cr6, 0x831e14c0
	if !ctx.cr[6].eq {
		sub_831E14C0(ctx, base);
		return;
	}
	// 831E14A4: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E14A8: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E14AC: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E14B0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E14B4: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E14B8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E14BC: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E14C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E14C0 size=36
    let mut pc: u32 = 0x831E14C0;
    'dispatch: loop {
        match pc {
            0x831E14C0 => {
    //   block [0x831E14C0..0x831E14E4)
	// 831E14C0: 2B0B003C  cmplwi cr6, r11, 0x3c
	ctx.cr[6].compare_u32(ctx.r[11].u32, 60 as u32, &mut ctx.xer);
	// 831E14C4: 409A00A4  bne cr6, 0x831e1568
	if !ctx.cr[6].eq {
		sub_831E1568(ctx, base);
		return;
	}
	// 831E14C8: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E14CC: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E14D0: 38A40038  addi r5, r4, 0x38
	ctx.r[5].s64 = ctx.r[4].s64 + 56;
	// 831E14D4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E14D8: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E14DC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E14E0: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E14E4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E14E4 size=44
    let mut pc: u32 = 0x831E14E4;
    'dispatch: loop {
        match pc {
            0x831E14E4 => {
    //   block [0x831E14E4..0x831E1510)
	// 831E14E4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E14E8: 409A0028  bne cr6, 0x831e1510
	if !ctx.cr[6].eq {
		sub_831E1510(ctx, base);
		return;
	}
	// 831E14EC: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E14F0: 2B0A0001  cmplwi cr6, r10, 1
	ctx.cr[6].compare_u32(ctx.r[10].u32, 1 as u32, &mut ctx.xer);
	// 831E14F4: 409A001C  bne cr6, 0x831e1510
	if !ctx.cr[6].eq {
		sub_831E1510(ctx, base);
		return;
	}
	// 831E14F8: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E14FC: 7CC43378  mr r4, r6
	ctx.r[4].u64 = ctx.r[6].u64;
	// 831E1500: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1504: 814B003C  lwz r10, 0x3c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(60 as u32) ) } as u64;
	// 831E1508: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E150C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1510(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1510 size=44
    let mut pc: u32 = 0x831E1510;
    'dispatch: loop {
        match pc {
            0x831E1510 => {
    //   block [0x831E1510..0x831E153C)
	// 831E1510: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E1514: 409A0028  bne cr6, 0x831e153c
	if !ctx.cr[6].eq {
		sub_831E153C(ctx, base);
		return;
	}
	// 831E1518: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E151C: 2B0A0001  cmplwi cr6, r10, 1
	ctx.cr[6].compare_u32(ctx.r[10].u32, 1 as u32, &mut ctx.xer);
	// 831E1520: 409A001C  bne cr6, 0x831e153c
	if !ctx.cr[6].eq {
		sub_831E153C(ctx, base);
		return;
	}
	// 831E1524: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E1528: 7CC43378  mr r4, r6
	ctx.r[4].u64 = ctx.r[6].u64;
	// 831E152C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1530: 814B0044  lwz r10, 0x44(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E1534: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1538: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E153C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E153C size=44
    let mut pc: u32 = 0x831E153C;
    'dispatch: loop {
        match pc {
            0x831E153C => {
    //   block [0x831E153C..0x831E1568)
	// 831E153C: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E1540: 409A0028  bne cr6, 0x831e1568
	if !ctx.cr[6].eq {
		sub_831E1568(ctx, base);
		return;
	}
	// 831E1544: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E1548: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E154C: 409A001C  bne cr6, 0x831e1568
	if !ctx.cr[6].eq {
		sub_831E1568(ctx, base);
		return;
	}
	// 831E1550: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E1554: 7CC43378  mr r4, r6
	ctx.r[4].u64 = ctx.r[6].u64;
	// 831E1558: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E155C: 814B004C  lwz r10, 0x4c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(76 as u32) ) } as u64;
	// 831E1560: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1564: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1568(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1568 size=12
    let mut pc: u32 = 0x831E1568;
    'dispatch: loop {
        match pc {
            0x831E1568 => {
    //   block [0x831E1568..0x831E1574)
	// 831E1568: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E156C: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E1570: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1578(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1578 size=64
    let mut pc: u32 = 0x831E1578;
    'dispatch: loop {
        match pc {
            0x831E1578 => {
    //   block [0x831E1578..0x831E15B8)
	// 831E1578: 548B063E  clrlwi r11, r4, 0x18
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x000000FFu64;
	// 831E157C: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 831E1580: 409A005C  bne cr6, 0x831e15dc
	if !ctx.cr[6].eq {
		sub_831E15DC(ctx, base);
		return;
	}
	// 831E1584: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E1588: 2B0A0003  cmplwi cr6, r10, 3
	ctx.cr[6].compare_u32(ctx.r[10].u32, 3 as u32, &mut ctx.xer);
	// 831E158C: 409A0050  bne cr6, 0x831e15dc
	if !ctx.cr[6].eq {
		sub_831E15DC(ctx, base);
		return;
	}
	// 831E1590: 81660004  lwz r11, 4(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1594: 2B0B0038  cmplwi cr6, r11, 0x38
	ctx.cr[6].compare_u32(ctx.r[11].u32, 56 as u32, &mut ctx.xer);
	// 831E1598: 409A0020  bne cr6, 0x831e15b8
	if !ctx.cr[6].eq {
		sub_831E15B8(ctx, base);
		return;
	}
	// 831E159C: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E15A0: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E15A4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E15A8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E15AC: 814B0038  lwz r10, 0x38(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E15B0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E15B4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E15B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E15B8 size=36
    let mut pc: u32 = 0x831E15B8;
    'dispatch: loop {
        match pc {
            0x831E15B8 => {
    //   block [0x831E15B8..0x831E15DC)
	// 831E15B8: 2B0B003C  cmplwi cr6, r11, 0x3c
	ctx.cr[6].compare_u32(ctx.r[11].u32, 60 as u32, &mut ctx.xer);
	// 831E15BC: 409A00A4  bne cr6, 0x831e1660
	if !ctx.cr[6].eq {
		sub_831E1660(ctx, base);
		return;
	}
	// 831E15C0: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E15C4: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E15C8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E15CC: 88A40038  lbz r5, 0x38(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E15D0: 814B0038  lwz r10, 0x38(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E15D4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E15D8: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E15DC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E15DC size=44
    let mut pc: u32 = 0x831E15DC;
    'dispatch: loop {
        match pc {
            0x831E15DC => {
    //   block [0x831E15DC..0x831E1608)
	// 831E15DC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E15E0: 409A0028  bne cr6, 0x831e1608
	if !ctx.cr[6].eq {
		sub_831E1608(ctx, base);
		return;
	}
	// 831E15E4: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E15E8: 2B0A0001  cmplwi cr6, r10, 1
	ctx.cr[6].compare_u32(ctx.r[10].u32, 1 as u32, &mut ctx.xer);
	// 831E15EC: 409A001C  bne cr6, 0x831e1608
	if !ctx.cr[6].eq {
		sub_831E1608(ctx, base);
		return;
	}
	// 831E15F0: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E15F4: C0260000  lfs f1, 0(r6)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E15F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E15FC: 814B0040  lwz r10, 0x40(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(64 as u32) ) } as u64;
	// 831E1600: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1604: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1608(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E1608 size=44
    let mut pc: u32 = 0x831E1608;
    'dispatch: loop {
        match pc {
            0x831E1608 => {
    //   block [0x831E1608..0x831E1634)
	// 831E1608: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E160C: 409A0028  bne cr6, 0x831e1634
	if !ctx.cr[6].eq {
		sub_831E1634(ctx, base);
		return;
	}
	// 831E1610: 54AA063E  clrlwi r10, r5, 0x18
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E1614: 2B0A0001  cmplwi cr6, r10, 1
	ctx.cr[6].compare_u32(ctx.r[10].u32, 1 as u32, &mut ctx.xer);
	// 831E1618: 409A001C  bne cr6, 0x831e1634
	if !ctx.cr[6].eq {
		sub_831E1634(ctx, base);
		return;
	}
	// 831E161C: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E1620: C0260000  lfs f1, 0(r6)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E1624: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1628: 814B0048  lwz r10, 0x48(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(72 as u32) ) } as u64;
	// 831E162C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1630: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1634(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E1634 size=44
    let mut pc: u32 = 0x831E1634;
    'dispatch: loop {
        match pc {
            0x831E1634 => {
    //   block [0x831E1634..0x831E1660)
	// 831E1634: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E1638: 409A0028  bne cr6, 0x831e1660
	if !ctx.cr[6].eq {
		sub_831E1660(ctx, base);
		return;
	}
	// 831E163C: 54AB063E  clrlwi r11, r5, 0x18
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E1640: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E1644: 409A001C  bne cr6, 0x831e1660
	if !ctx.cr[6].eq {
		sub_831E1660(ctx, base);
		return;
	}
	// 831E1648: 3863000C  addi r3, r3, 0xc
	ctx.r[3].s64 = ctx.r[3].s64 + 12;
	// 831E164C: C0260000  lfs f1, 0(r6)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E1650: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1654: 814B0050  lwz r10, 0x50(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E1658: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E165C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1660(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1660 size=12
    let mut pc: u32 = 0x831E1660;
    'dispatch: loop {
        match pc {
            0x831E1660 => {
    //   block [0x831E1660..0x831E166C)
	// 831E1660: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E1664: 60630057  ori r3, r3, 0x57
	ctx.r[3].u64 = ctx.r[3].u64 | 87;
	// 831E1668: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1670(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1670 size=16
    let mut pc: u32 = 0x831E1670;
    'dispatch: loop {
        match pc {
            0x831E1670 => {
    //   block [0x831E1670..0x831E1680)
	// 831E1670: 89630008  lbz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1674: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E1678: 41990008  bgt cr6, 0x831e1680
	if ctx.cr[6].gt {
		sub_831E1680(ctx, base);
		return;
	}
	// 831E167C: 48009574  b 0x831eabf0
	sub_831EABF0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1680(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1680 size=12
    let mut pc: u32 = 0x831E1680;
    'dispatch: loop {
        match pc {
            0x831E1680 => {
    //   block [0x831E1680..0x831E168C)
	// 831E1680: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831E1684: 409A0008  bne cr6, 0x831e168c
	if !ctx.cr[6].eq {
		sub_831E168C(ctx, base);
		return;
	}
	// 831E1688: 480070D8  b 0x831e8760
	sub_831E8760(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E168C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E168C size=12
    let mut pc: u32 = 0x831E168C;
    'dispatch: loop {
        match pc {
            0x831E168C => {
    //   block [0x831E168C..0x831E1698)
	// 831E168C: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E1690: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E1694: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1698(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1698 size=16
    let mut pc: u32 = 0x831E1698;
    'dispatch: loop {
        match pc {
            0x831E1698 => {
    //   block [0x831E1698..0x831E16A8)
	// 831E1698: 89630008  lbz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E169C: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E16A0: 41990008  bgt cr6, 0x831e16a8
	if ctx.cr[6].gt {
		sub_831E16A8(ctx, base);
		return;
	}
	// 831E16A4: 48009D94  b 0x831eb438
	sub_831EB438(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E16A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E16A8 size=12
    let mut pc: u32 = 0x831E16A8;
    'dispatch: loop {
        match pc {
            0x831E16A8 => {
    //   block [0x831E16A8..0x831E16B4)
	// 831E16A8: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 831E16AC: 409A0008  bne cr6, 0x831e16b4
	if !ctx.cr[6].eq {
		sub_831E16B4(ctx, base);
		return;
	}
	// 831E16B0: 48008C38  b 0x831ea2e8
	sub_831EA2E8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E16B4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E16B4 size=12
    let mut pc: u32 = 0x831E16B4;
    'dispatch: loop {
        match pc {
            0x831E16B4 => {
    //   block [0x831E16B4..0x831E16C0)
	// 831E16B4: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E16B8: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E16BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E16C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E16C0 size=104
    let mut pc: u32 = 0x831E16C0;
    'dispatch: loop {
        match pc {
            0x831E16C0 => {
    //   block [0x831E16C0..0x831E1728)
	// 831E16C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E16C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E16C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E16CC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E16D0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E16D4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E16D8: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E16DC: 392B0028  addi r9, r11, 0x28
	ctx.r[9].s64 = ctx.r[11].s64 + 40;
	// 831E16E0: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 831E16E4: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E16E8: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E16EC: 81040004  lwz r8, 4(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E16F0: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E16F4: 48005395  bl 0x831e6a88
	ctx.lr = 0x831E16F8;
	sub_831E6A88(ctx, base);
	// 831E16F8: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E16FC: 3CC0821A  lis r6, -0x7de6
	ctx.r[6].s64 = -2112225280;
	// 831E1700: 38A701A8  addi r5, r7, 0x1a8
	ctx.r[5].s64 = ctx.r[7].s64 + 424;
	// 831E1704: 38860148  addi r4, r6, 0x148
	ctx.r[4].s64 = ctx.r[6].s64 + 328;
	// 831E1708: 90BF0000  stw r5, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E170C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1710: 909F000C  stw r4, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 831E1714: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E1718: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E171C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E1720: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1724: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1728(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1728 size=8
    let mut pc: u32 = 0x831E1728;
    'dispatch: loop {
        match pc {
            0x831E1728 => {
    //   block [0x831E1728..0x831E1730)
	// 831E1728: 3863FFF4  addi r3, r3, -0xc
	ctx.r[3].s64 = ctx.r[3].s64 + -12;
	// 831E172C: 4800082C  b 0x831e1f58
	sub_831E1F58(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1730(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1730 size=16
    let mut pc: u32 = 0x831E1730;
    'dispatch: loop {
        match pc {
            0x831E1730 => {
    //   block [0x831E1730..0x831E1740)
	// 831E1730: 8963009C  lbz r11, 0x9c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E1734: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1738: 99640000  stb r11, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E173C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1740(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1740 size=4
    let mut pc: u32 = 0x831E1740;
    'dispatch: loop {
        match pc {
            0x831E1740 => {
    //   block [0x831E1740..0x831E1744)
	// 831E1740: 48005408  b 0x831e6b48
	sub_831E6B48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1748(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1748 size=80
    let mut pc: u32 = 0x831E1748;
    'dispatch: loop {
        match pc {
            0x831E1748 => {
    //   block [0x831E1748..0x831E1798)
	// 831E1748: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E174C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E1750: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E1754: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1758: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E175C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E1760: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E1764: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E1768: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E176C: 4E800421  bctrl
	ctx.lr = 0x831E1770;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1770: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E1774: 41980010  blt cr6, 0x831e1784
	if ctx.cr[6].lt {
	pc = 0x831E1784; continue 'dispatch;
	}
	// 831E1778: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E177C: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E1780: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E1784: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E1788: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E178C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E1790: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1794: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1798(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1798 size=76
    let mut pc: u32 = 0x831E1798;
    'dispatch: loop {
        match pc {
            0x831E1798 => {
    //   block [0x831E1798..0x831E17E4)
	// 831E1798: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E179C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E17A0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E17A4: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E17A8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E17AC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E17B0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E17B4: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E17B8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E17BC: 4E800421  bctrl
	ctx.lr = 0x831E17C0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E17C0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E17C4: 4198000C  blt cr6, 0x831e17d0
	if ctx.cr[6].lt {
	pc = 0x831E17D0; continue 'dispatch;
	}
	// 831E17C8: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E17CC: 93EB0010  stw r31, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[31].u32 ) };
	// 831E17D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E17D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E17D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E17DC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E17E0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E17E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E17E8 size=80
    let mut pc: u32 = 0x831E17E8;
    'dispatch: loop {
        match pc {
            0x831E17E8 => {
    //   block [0x831E17E8..0x831E1838)
	// 831E17E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E17EC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E17F0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E17F4: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E17F8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E17FC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E1800: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E1804: 814B0058  lwz r10, 0x58(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(88 as u32) ) } as u64;
	// 831E1808: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E180C: 4E800421  bctrl
	ctx.lr = 0x831E1810;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1810: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E1814: 41980010  blt cr6, 0x831e1824
	if ctx.cr[6].lt {
	pc = 0x831E1824; continue 'dispatch;
	}
	// 831E1818: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E181C: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E1820: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E1824: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E1828: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E182C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E1830: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1834: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1838 size=96
    let mut pc: u32 = 0x831E1838;
    'dispatch: loop {
        match pc {
            0x831E1838 => {
    //   block [0x831E1838..0x831E1898)
	// 831E1838: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E183C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E1840: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E1844: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E1848: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E184C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E1850: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 831E1854: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831E1858: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E185C: 419A0010  beq cr6, 0x831e186c
	if ctx.cr[6].eq {
	pc = 0x831E186C; continue 'dispatch;
	}
	// 831E1860: 389F0024  addi r4, r31, 0x24
	ctx.r[4].s64 = ctx.r[31].s64 + 36;
	// 831E1864: 38A00038  li r5, 0x38
	ctx.r[5].s64 = 56;
	// 831E1868: 4BFC6CA9  bl 0x831a8510
	ctx.lr = 0x831E186C;
	sub_831A8510(ctx, base);
	// 831E186C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E1870: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1874: 419A000C  beq cr6, 0x831e1880
	if ctx.cr[6].eq {
	pc = 0x831E1880; continue 'dispatch;
	}
	// 831E1878: 897F009D  lbz r11, 0x9d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(157 as u32) ) } as u64;
	// 831E187C: 997E0000  stb r11, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 831E1880: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E1884: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E1888: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E188C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E1890: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1894: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1898(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E1898 size=16
    let mut pc: u32 = 0x831E1898;
    'dispatch: loop {
        match pc {
            0x831E1898 => {
    //   block [0x831E1898..0x831E18A8)
	// 831E1898: C0030060  lfs f0, 0x60(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E189C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E18A0: D0040000  stfs f0, 0(r4)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E18A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E18A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E18A8 size=12
    let mut pc: u32 = 0x831E18A8;
    'dispatch: loop {
        match pc {
            0x831E18A8 => {
    //   block [0x831E18A8..0x831E18B4)
	// 831E18A8: D0230060  stfs f1, 0x60(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 831E18AC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E18B0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E18B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E18B8 size=72
    let mut pc: u32 = 0x831E18B8;
    'dispatch: loop {
        match pc {
            0x831E18B8 => {
    //   block [0x831E18B8..0x831E1900)
	// 831E18B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E18BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E18C0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E18C4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E18C8: C0230064  lfs f1, 0x64(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(100 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831E18CC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E18D0: 4BFCCA01  bl 0x831ae2d0
	ctx.lr = 0x831E18D4;
	sub_831AE2D0(ctx, base);
	// 831E18D4: FDA00818  frsp f13, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E18D8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E18DC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E18E0: C00B01D0  lfs f0, 0x1d0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(464 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E18E4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831E18E8: D19F0000  stfs f12, 0(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E18EC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E18F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E18F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E18F8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E18FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1900(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831E1900 size=68
    let mut pc: u32 = 0x831E1900;
    'dispatch: loop {
        match pc {
            0x831E1900 => {
    //   block [0x831E1900..0x831E1944)
	// 831E1900: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1904: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E1908: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E190C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1910: 3D608205  lis r11, -0x7dfb
	ctx.r[11].s64 = -2113601536;
	// 831E1914: FC400890  fmr f2, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[1].f64;
	// 831E1918: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E191C: C82BAA10  lfd f1, -0x55f0(r11)
	ctx.f[1].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[11].u32.wrapping_add(-22000 as u32) ) };
	// 831E1920: 4BFC9B89  bl 0x831ab4a8
	ctx.lr = 0x831E1924;
	sub_831AB4A8(ctx, base);
	// 831E1924: FC000818  frsp f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (ctx.f[1].f64 as f32) as f64;
	// 831E1928: D01F0064  stfs f0, 0x64(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 831E192C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1930: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E1934: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E1938: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E193C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1940: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1948(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E1948 size=16
    let mut pc: u32 = 0x831E1948;
    'dispatch: loop {
        match pc {
            0x831E1948 => {
    //   block [0x831E1948..0x831E1958)
	// 831E1948: C0030064  lfs f0, 0x64(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(100 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831E194C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1950: D0040000  stfs f0, 0(r4)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831E1954: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1958(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831E1958 size=12
    let mut pc: u32 = 0x831E1958;
    'dispatch: loop {
        match pc {
            0x831E1958 => {
    //   block [0x831E1958..0x831E1964)
	// 831E1958: D0230064  stfs f1, 0x64(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 831E195C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1960: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1968(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1968 size=28
    let mut pc: u32 = 0x831E1968;
    'dispatch: loop {
        match pc {
            0x831E1968 => {
    //   block [0x831E1968..0x831E1984)
	// 831E1968: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E196C: 39400004  li r10, 4
	ctx.r[10].s64 = 4;
	// 831E1970: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1974: 99440000  stb r10, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 831E1978: A16B1090  lhz r11, 0x1090(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(4240 as u32) ) } as u64;
	// 831E197C: B1640002  sth r11, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[11].u16 ) };
	// 831E1980: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1988(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E1988 size=20
    let mut pc: u32 = 0x831E1988;
    'dispatch: loop {
        match pc {
            0x831E1988 => {
    //   block [0x831E1988..0x831E199C)
	// 831E1988: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E198C: 419A0010  beq cr6, 0x831e199c
	if ctx.cr[6].eq {
		sub_831E199C(ctx, base);
		return;
	}
	// 831E1990: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1994: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 831E1998: 48000008  b 0x831e19a0
	sub_831E199C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E199C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E199C size=20
    let mut pc: u32 = 0x831E199C;
    'dispatch: loop {
        match pc {
            0x831E199C => {
    //   block [0x831E199C..0x831E19B0)
	// 831E199C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E19A0: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 831E19A4: 419A000C  beq cr6, 0x831e19b0
	if ctx.cr[6].eq {
		sub_831E19B0(ctx, base);
		return;
	}
	// 831E19A8: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E19AC: 48000008  b 0x831e19b4
	sub_831E19B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E19B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E19B0 size=24
    let mut pc: u32 = 0x831E19B0;
    'dispatch: loop {
        match pc {
            0x831E19B0 => {
    //   block [0x831E19B0..0x831E19C8)
	// 831E19B0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E19B4: 7F035840  cmplw cr6, r3, r11
	ctx.cr[6].compare_u32(ctx.r[3].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E19B8: 419A0010  beq cr6, 0x831e19c8
	if ctx.cr[6].eq {
		sub_831E19C8(ctx, base);
		return;
	}
	// 831E19BC: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E19C0: 7C6A5850  subf r3, r10, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 831E19C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E19C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E19C8 size=8
    let mut pc: u32 = 0x831E19C8;
    'dispatch: loop {
        match pc {
            0x831E19C8 => {
    //   block [0x831E19C8..0x831E19D0)
	// 831E19C8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E19CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E19D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E19D0 size=84
    let mut pc: u32 = 0x831E19D0;
    'dispatch: loop {
        match pc {
            0x831E19D0 => {
    //   block [0x831E19D0..0x831E1A24)
	// 831E19D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E19D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E19D8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E19DC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E19E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E19E4: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E19E8: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E19EC: 392B01A8  addi r9, r11, 0x1a8
	ctx.r[9].s64 = ctx.r[11].s64 + 424;
	// 831E19F0: 390A0148  addi r8, r10, 0x148
	ctx.r[8].s64 = ctx.r[10].s64 + 328;
	// 831E19F4: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E19F8: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 831E19FC: 911F000C  stw r8, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831E1A00: 480050C9  bl 0x831e6ac8
	ctx.lr = 0x831E1A04;
	sub_831E6AC8(ctx, base);
	// 831E1A04: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E1A08: 38C7FF64  addi r6, r7, -0x9c
	ctx.r[6].s64 = ctx.r[7].s64 + -156;
	// 831E1A0C: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 831E1A10: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E1A14: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E1A18: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E1A1C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1A20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1A28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1A28 size=316
    let mut pc: u32 = 0x831E1A28;
    'dispatch: loop {
        match pc {
            0x831E1A28 => {
    //   block [0x831E1A28..0x831E1B64)
	// 831E1A28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1A2C: 4BFC6739  bl 0x831a8164
	ctx.lr = 0x831E1A30;
	sub_831A8130(ctx, base);
	// 831E1A30: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1A34: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E1A38: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E1A3C: 48061721  bl 0x8324315c
	ctx.lr = 0x831E1A40;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1A40: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1A44: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E1A48: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E1A4C: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E1A50: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1A54: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E1A58: 419A0010  beq cr6, 0x831e1a68
	if ctx.cr[6].eq {
	pc = 0x831E1A68; continue 'dispatch;
	}
	// 831E1A5C: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1A60: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1A64: 419A0020  beq cr6, 0x831e1a84
	if ctx.cr[6].eq {
	pc = 0x831E1A84; continue 'dispatch;
	}
	// 831E1A68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1A6C: 48061011  bl 0x83242a7c
	ctx.lr = 0x831E1A70;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1A70: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831E1A74: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1A78: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E1A7C: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E1A80: 48000008  b 0x831e1a88
	pc = 0x831E1A88; continue 'dispatch;
	// 831E1A84: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1A88: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E1A8C: 397C0004  addi r11, r28, 4
	ctx.r[11].s64 = ctx.r[28].s64 + 4;
	// 831E1A90: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E1A94: 813C0004  lwz r9, 4(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1A98: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E1A9C: 419A0014  beq cr6, 0x831e1ab0
	if ctx.cr[6].eq {
	pc = 0x831E1AB0; continue 'dispatch;
	}
	// 831E1AA0: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1AA4: 7D6B4850  subf r11, r11, r9
	ctx.r[11].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831E1AA8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E1AAC: 409A0054  bne cr6, 0x831e1b00
	if !ctx.cr[6].eq {
	pc = 0x831E1B00; continue 'dispatch;
	}
	// 831E1AB0: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E1AB4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E1AB8: 419A0038  beq cr6, 0x831e1af0
	if ctx.cr[6].eq {
	pc = 0x831E1AF0; continue 'dispatch;
	}
	// 831E1ABC: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1AC0: 409A0030  bne cr6, 0x831e1af0
	if !ctx.cr[6].eq {
	pc = 0x831E1AF0; continue 'dispatch;
	}
	// 831E1AC4: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1AC8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1ACC: 40820024  bne 0x831e1af0
	if !ctx.cr[0].eq {
	pc = 0x831E1AF0; continue 'dispatch;
	}
	// 831E1AD0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1AD4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1AD8: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1ADC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1AE0: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1AE4: 48060F89  bl 0x83242a6c
	ctx.lr = 0x831E1AE8;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1AE8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E1AEC: 48061681  bl 0x8324316c
	ctx.lr = 0x831E1AF0;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1AF0: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E1AF4: 60634005  ori r3, r3, 0x4005
	ctx.r[3].u64 = ctx.r[3].u64 | 16389;
	// 831E1AF8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1AFC: 4BFC66B8  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 831E1B00: 2B1B0000  cmplwi cr6, r27, 0
	ctx.cr[6].compare_u32(ctx.r[27].u32, 0 as u32, &mut ctx.xer);
	// 831E1B04: 419A0014  beq cr6, 0x831e1b18
	if ctx.cr[6].eq {
	pc = 0x831E1B18; continue 'dispatch;
	}
	// 831E1B08: 917B0000  stw r11, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E1B0C: 8BBF000C  lbz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1B10: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1B14: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1B18: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E1B1C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E1B20: 419A0038  beq cr6, 0x831e1b58
	if ctx.cr[6].eq {
	pc = 0x831E1B58; continue 'dispatch;
	}
	// 831E1B24: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1B28: 409A0030  bne cr6, 0x831e1b58
	if !ctx.cr[6].eq {
	pc = 0x831E1B58; continue 'dispatch;
	}
	// 831E1B2C: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1B30: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1B34: 40820024  bne 0x831e1b58
	if !ctx.cr[0].eq {
	pc = 0x831E1B58; continue 'dispatch;
	}
	// 831E1B38: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1B3C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1B40: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1B44: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1B48: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1B4C: 48060F21  bl 0x83242a6c
	ctx.lr = 0x831E1B50;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1B50: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E1B54: 48061619  bl 0x8324316c
	ctx.lr = 0x831E1B58;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1B58: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1B5C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1B60: 4BFC6654  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1B68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1B68 size=204
    let mut pc: u32 = 0x831E1B68;
    'dispatch: loop {
        match pc {
            0x831E1B68 => {
    //   block [0x831E1B68..0x831E1C34)
	// 831E1B68: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1B6C: 4BFC65F5  bl 0x831a8160
	ctx.lr = 0x831E1B70;
	sub_831A8130(ctx, base);
	// 831E1B70: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1B74: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E1B78: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 831E1B7C: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 831E1B80: 480615DD  bl 0x8324315c
	ctx.lr = 0x831E1B84;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1B84: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1B88: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 831E1B8C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E1B90: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E1B94: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1B98: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1B9C: 419A0010  beq cr6, 0x831e1bac
	if ctx.cr[6].eq {
	pc = 0x831E1BAC; continue 'dispatch;
	}
	// 831E1BA0: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1BA4: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E1BA8: 419A0018  beq cr6, 0x831e1bc0
	if ctx.cr[6].eq {
	pc = 0x831E1BC0; continue 'dispatch;
	}
	// 831E1BAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1BB0: 48060ECD  bl 0x83242a7c
	ctx.lr = 0x831E1BB4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1BB4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1BB8: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E1BBC: 9B5F000C  stb r26, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u8 ) };
	// 831E1BC0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E1BC4: 578A063E  clrlwi r10, r28, 0x18
	ctx.r[10].u64 = ctx.r[28].u32 as u64 & 0x000000FFu64;
	// 831E1BC8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1BCC: 5769063E  clrlwi r9, r27, 0x18
	ctx.r[9].u64 = ctx.r[27].u32 as u64 & 0x000000FFu64;
	// 831E1BD0: 891E009C  lbz r8, 0x9c(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E1BD4: 7D075078  andc r7, r8, r10
	ctx.r[7].u64 = ctx.r[8].u64 & !ctx.r[10].u64;
	// 831E1BD8: 7CE64B78  or r6, r7, r9
	ctx.r[6].u64 = ctx.r[7].u64 | ctx.r[9].u64;
	// 831E1BDC: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E1BE0: 98DE009C  stb r6, 0x9c(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(156 as u32), ctx.r[6].u8 ) };
	// 831E1BE4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1BE8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1BEC: 419A0040  beq cr6, 0x831e1c2c
	if ctx.cr[6].eq {
	pc = 0x831E1C2C; continue 'dispatch;
	}
	// 831E1BF0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1BF4: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E1BF8: 409A0034  bne cr6, 0x831e1c2c
	if !ctx.cr[6].eq {
	pc = 0x831E1C2C; continue 'dispatch;
	}
	// 831E1BFC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1C00: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1C04: 40820028  bne 0x831e1c2c
	if !ctx.cr[0].eq {
	pc = 0x831E1C2C; continue 'dispatch;
	}
	// 831E1C08: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1C0C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1C10: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1C14: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1C18: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1C1C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1C20: 48060E4D  bl 0x83242a6c
	ctx.lr = 0x831E1C24;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1C24: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1C28: 48061545  bl 0x8324316c
	ctx.lr = 0x831E1C2C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1C2C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E1C30: 4BFC6580  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1C38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1C38 size=244
    let mut pc: u32 = 0x831E1C38;
    'dispatch: loop {
        match pc {
            0x831E1C38 => {
    //   block [0x831E1C38..0x831E1D2C)
	// 831E1C38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1C3C: 4BFC652D  bl 0x831a8168
	ctx.lr = 0x831E1C40;
	sub_831A8130(ctx, base);
	// 831E1C40: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1C44: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E1C48: 48061515  bl 0x8324315c
	ctx.lr = 0x831E1C4C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1C4C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1C50: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E1C54: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E1C58: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E1C5C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1C60: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1C64: 419A0010  beq cr6, 0x831e1c74
	if ctx.cr[6].eq {
	pc = 0x831E1C74; continue 'dispatch;
	}
	// 831E1C68: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1C6C: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E1C70: 419A0018  beq cr6, 0x831e1c88
	if ctx.cr[6].eq {
	pc = 0x831E1C88; continue 'dispatch;
	}
	// 831E1C74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1C78: 48060E05  bl 0x83242a7c
	ctx.lr = 0x831E1C7C;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1C7C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1C80: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E1C84: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E1C88: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E1C8C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1C90: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E1C94: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831E1C98: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E1C9C: 409A0010  bne cr6, 0x831e1cac
	if !ctx.cr[6].eq {
	pc = 0x831E1CAC; continue 'dispatch;
	}
	// 831E1CA0: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831E1CA4: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 831E1CA8: 48000018  b 0x831e1cc0
	pc = 0x831E1CC0; continue 'dispatch;
	// 831E1CAC: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E1CB0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E1CB4: 419A0024  beq cr6, 0x831e1cd8
	if ctx.cr[6].eq {
	pc = 0x831E1CD8; continue 'dispatch;
	}
	// 831E1CB8: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831E1CBC: 38800006  li r4, 6
	ctx.r[4].s64 = 6;
	// 831E1CC0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1CC4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1CC8: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E1CCC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1CD0: 4E800421  bctrl
	ctx.lr = 0x831E1CD4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1CD4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1CD8: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E1CDC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1CE0: 419A0040  beq cr6, 0x831e1d20
	if ctx.cr[6].eq {
	pc = 0x831E1D20; continue 'dispatch;
	}
	// 831E1CE4: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1CE8: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E1CEC: 409A0034  bne cr6, 0x831e1d20
	if !ctx.cr[6].eq {
	pc = 0x831E1D20; continue 'dispatch;
	}
	// 831E1CF0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1CF4: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1CF8: 40820028  bne 0x831e1d20
	if !ctx.cr[0].eq {
	pc = 0x831E1D20; continue 'dispatch;
	}
	// 831E1CFC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1D00: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1D04: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1D08: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1D0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1D10: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1D14: 48060D59  bl 0x83242a6c
	ctx.lr = 0x831E1D18;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1D18: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1D1C: 48061451  bl 0x8324316c
	ctx.lr = 0x831E1D20;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1D20: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1D24: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1D28: 4BFC6490  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1D30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1D30 size=308
    let mut pc: u32 = 0x831E1D30;
    'dispatch: loop {
        match pc {
            0x831E1D30 => {
    //   block [0x831E1D30..0x831E1E64)
	// 831E1D30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1D34: 4BFC6431  bl 0x831a8164
	ctx.lr = 0x831E1D38;
	sub_831A8130(ctx, base);
	// 831E1D38: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1D3C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E1D40: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 831E1D44: 48061419  bl 0x8324315c
	ctx.lr = 0x831E1D48;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1D48: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1D4C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E1D50: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E1D54: 7DBD6B78  mr r29, r13
	ctx.r[29].u64 = ctx.r[13].u64;
	// 831E1D58: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1D5C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1D60: 419A0010  beq cr6, 0x831e1d70
	if ctx.cr[6].eq {
	pc = 0x831E1D70; continue 'dispatch;
	}
	// 831E1D64: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1D68: 7F1D5040  cmplw cr6, r29, r10
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E1D6C: 419A0018  beq cr6, 0x831e1d84
	if ctx.cr[6].eq {
	pc = 0x831E1D84; continue 'dispatch;
	}
	// 831E1D70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1D74: 48060D09  bl 0x83242a7c
	ctx.lr = 0x831E1D78;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1D78: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1D7C: 93BF0008  stw r29, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 831E1D80: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E1D84: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831E1D88: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1D8C: 895E009C  lbz r10, 0x9c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(156 as u32) ) } as u64;
	// 831E1D90: 554907FE  clrlwi r9, r10, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831E1D94: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E1D98: 419A0078  beq cr6, 0x831e1e10
	if ctx.cr[6].eq {
	pc = 0x831E1E10; continue 'dispatch;
	}
	// 831E1D9C: 576907FE  clrlwi r9, r27, 0x1f
	ctx.r[9].u64 = ctx.r[27].u32 as u64 & 0x00000001u64;
	// 831E1DA0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E1DA4: 409A004C  bne cr6, 0x831e1df0
	if !ctx.cr[6].eq {
	pc = 0x831E1DF0; continue 'dispatch;
	}
	// 831E1DA8: 554906FC  rlwinm r9, r10, 0, 0x1b, 0x1e
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E1DAC: 552907B6  rlwinm r9, r9, 0, 0x1e, 0x1b
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 831E1DB0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E1DB4: 409A003C  bne cr6, 0x831e1df0
	if !ctx.cr[6].eq {
	pc = 0x831E1DF0; continue 'dispatch;
	}
	// 831E1DB8: 554A077A  rlwinm r10, r10, 0, 0x1d, 0x1d
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 831E1DBC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E1DC0: 409A0050  bne cr6, 0x831e1e10
	if !ctx.cr[6].eq {
	pc = 0x831E1E10; continue 'dispatch;
	}
	// 831E1DC4: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1DC8: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 831E1DCC: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 831E1DD0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1DD4: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E1DD8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1DDC: 4E800421  bctrl
	ctx.lr = 0x831E1DE0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1DE0: 3D20821A  lis r9, -0x7de6
	ctx.r[9].s64 = -2112225280;
	// 831E1DE4: A1691090  lhz r11, 0x1090(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(4240 as u32) ) } as u64;
	// 831E1DE8: B17E009E  sth r11, 0x9e(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(158 as u32), ctx.r[11].u16 ) };
	// 831E1DEC: 48000020  b 0x831e1e0c
	pc = 0x831E1E0C; continue 'dispatch;
	// 831E1DF0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1DF4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E1DF8: 38800057  li r4, 0x57
	ctx.r[4].s64 = 87;
	// 831E1DFC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1E00: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E1E04: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1E08: 4E800421  bctrl
	ctx.lr = 0x831E1E0C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1E0C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1E10: 7DAA6B78  mr r10, r13
	ctx.r[10].u64 = ctx.r[13].u64;
	// 831E1E14: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1E18: 419A0040  beq cr6, 0x831e1e58
	if ctx.cr[6].eq {
	pc = 0x831E1E58; continue 'dispatch;
	}
	// 831E1E1C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1E20: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E1E24: 409A0034  bne cr6, 0x831e1e58
	if !ctx.cr[6].eq {
	pc = 0x831E1E58; continue 'dispatch;
	}
	// 831E1E28: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1E2C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1E30: 40820028  bne 0x831e1e58
	if !ctx.cr[0].eq {
	pc = 0x831E1E58; continue 'dispatch;
	}
	// 831E1E34: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1E38: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1E3C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1E40: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1E44: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1E48: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1E4C: 48060C21  bl 0x83242a6c
	ctx.lr = 0x831E1E50;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1E50: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1E54: 48061319  bl 0x8324316c
	ctx.lr = 0x831E1E58;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1E58: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1E5C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1E60: 4BFC6354  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1E68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1E68 size=240
    let mut pc: u32 = 0x831E1E68;
    'dispatch: loop {
        match pc {
            0x831E1E68 => {
    //   block [0x831E1E68..0x831E1F58)
	// 831E1E68: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1E6C: 4BFC62FD  bl 0x831a8168
	ctx.lr = 0x831E1E70;
	sub_831A8130(ctx, base);
	// 831E1E70: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1E74: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E1E78: 480612E5  bl 0x8324315c
	ctx.lr = 0x831E1E7C;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E1E7C: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1E80: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E1E84: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E1E88: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E1E8C: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1E90: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E1E94: 419A0010  beq cr6, 0x831e1ea4
	if ctx.cr[6].eq {
	pc = 0x831E1EA4; continue 'dispatch;
	}
	// 831E1E98: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1E9C: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1EA0: 419A001C  beq cr6, 0x831e1ebc
	if ctx.cr[6].eq {
	pc = 0x831E1EBC; continue 'dispatch;
	}
	// 831E1EA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1EA8: 48060BD5  bl 0x83242a7c
	ctx.lr = 0x831E1EAC;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E1EAC: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831E1EB0: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1EB4: 9B9F000C  stb r28, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[28].u8 ) };
	// 831E1EB8: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E1EBC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E1EC0: 397D0004  addi r11, r29, 4
	ctx.r[11].s64 = ctx.r[29].s64 + 4;
	// 831E1EC4: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E1EC8: 813D0004  lwz r9, 4(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1ECC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831E1ED0: 419A0038  beq cr6, 0x831e1f08
	if ctx.cr[6].eq {
	pc = 0x831E1F08; continue 'dispatch;
	}
	// 831E1ED4: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1ED8: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 831E1EDC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E1EE0: 419A0028  beq cr6, 0x831e1f08
	if ctx.cr[6].eq {
	pc = 0x831E1F08; continue 'dispatch;
	}
	// 831E1EE4: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E1EE8: 38A00008  li r5, 8
	ctx.r[5].s64 = 8;
	// 831E1EEC: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 831E1EF0: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831E1EF4: 814B0054  lwz r10, 0x54(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(84 as u32) ) } as u64;
	// 831E1EF8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E1EFC: 4E800421  bctrl
	ctx.lr = 0x831E1F00;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E1F00: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E1F04: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E1F08: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E1F0C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E1F10: 419A003C  beq cr6, 0x831e1f4c
	if ctx.cr[6].eq {
	pc = 0x831E1F4C; continue 'dispatch;
	}
	// 831E1F14: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E1F18: 409A0034  bne cr6, 0x831e1f4c
	if !ctx.cr[6].eq {
	pc = 0x831E1F4C; continue 'dispatch;
	}
	// 831E1F1C: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E1F20: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E1F24: 40820028  bne 0x831e1f4c
	if !ctx.cr[0].eq {
	pc = 0x831E1F4C; continue 'dispatch;
	}
	// 831E1F28: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E1F2C: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E1F30: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E1F34: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E1F38: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1F3C: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E1F40: 48060B2D  bl 0x83242a6c
	ctx.lr = 0x831E1F44;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E1F44: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E1F48: 48061225  bl 0x8324316c
	ctx.lr = 0x831E1F4C;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E1F4C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E1F50: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E1F54: 4BFC6264  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1F58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1F58 size=132
    let mut pc: u32 = 0x831E1F58;
    'dispatch: loop {
        match pc {
            0x831E1F58 => {
    //   block [0x831E1F58..0x831E1FDC)
	// 831E1F58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1F5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E1F60: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E1F64: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E1F68: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1F6C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E1F70: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E1F74: 3D40821A  lis r10, -0x7de6
	ctx.r[10].s64 = -2112225280;
	// 831E1F78: 392B01A8  addi r9, r11, 0x1a8
	ctx.r[9].s64 = ctx.r[11].s64 + 424;
	// 831E1F7C: 390A0148  addi r8, r10, 0x148
	ctx.r[8].s64 = ctx.r[10].s64 + 328;
	// 831E1F80: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E1F84: 387F000C  addi r3, r31, 0xc
	ctx.r[3].s64 = ctx.r[31].s64 + 12;
	// 831E1F88: 911F000C  stw r8, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 831E1F8C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E1F90: 48004B39  bl 0x831e6ac8
	ctx.lr = 0x831E1F94;
	sub_831E6AC8(ctx, base);
	// 831E1F94: 3CE0821A  lis r7, -0x7de6
	ctx.r[7].s64 = -2112225280;
	// 831E1F98: 57C607FE  clrlwi r6, r30, 0x1f
	ctx.r[6].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	// 831E1F9C: 38A7FF64  addi r5, r7, -0x9c
	ctx.r[5].s64 = ctx.r[7].s64 + -156;
	// 831E1FA0: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831E1FA4: 90BF0000  stw r5, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 831E1FA8: 419A0018  beq cr6, 0x831e1fc0
	if ctx.cr[6].eq {
	pc = 0x831E1FC0; continue 'dispatch;
	}
	// 831E1FAC: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E1FB0: 3CA06182  lis r5, 0x6182
	ctx.r[5].s64 = 1635909632;
	// 831E1FB4: 386BD5A4  addi r3, r11, -0x2a5c
	ctx.r[3].s64 = ctx.r[11].s64 + -10844;
	// 831E1FB8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 831E1FBC: 4BFFA705  bl 0x831dc6c0
	ctx.lr = 0x831E1FC0;
	sub_831DC6C0(ctx, base);
	// 831E1FC0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E1FC4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E1FC8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E1FCC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E1FD0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E1FD4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E1FD8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E1FE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E1FE0 size=92
    let mut pc: u32 = 0x831E1FE0;
    'dispatch: loop {
        match pc {
            0x831E1FE0 => {
    //   block [0x831E1FE0..0x831E203C)
	// 831E1FE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E1FE4: 4BFC6189  bl 0x831a816c
	ctx.lr = 0x831E1FE8;
	sub_831A8130(ctx, base);
	// 831E1FE8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E1FEC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E1FF0: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831E1FF4: 480055A5  bl 0x831e7598
	ctx.lr = 0x831E1FF8;
	sub_831E7598(ctx, base);
	// 831E1FF8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E1FFC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831E2000: 419A0030  beq cr6, 0x831e2030
	if ctx.cr[6].eq {
	pc = 0x831E2030; continue 'dispatch;
	}
	// 831E2004: 817E00A0  lwz r11, 0xa0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(160 as u32) ) } as u64;
	// 831E2008: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E200C: 419A0024  beq cr6, 0x831e2030
	if ctx.cr[6].eq {
	pc = 0x831E2030; continue 'dispatch;
	}
	// 831E2010: 815EFFFC  lwz r10, -4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(-4 as u32) ) } as u64;
	// 831E2014: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831E2018: 813F0024  lwz r9, 0x24(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E201C: 93A10058  stw r29, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[29].u32 ) };
	// 831E2020: 91410050  stw r10, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u32 ) };
	// 831E2024: 91210054  stw r9, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[9].u32 ) };
	// 831E2028: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831E202C: 4E800421  bctrl
	ctx.lr = 0x831E2030;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2030: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2034: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E2038: 4BFC6184  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2040(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2040 size=32
    let mut pc: u32 = 0x831E2040;
    'dispatch: loop {
        match pc {
            0x831E2040 => {
    //   block [0x831E2040..0x831E2060)
	// 831E2040: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2044: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 831E2048: 409A0008  bne cr6, 0x831e2050
	if !ctx.cr[6].eq {
	pc = 0x831E2050; continue 'dispatch;
	}
	// 831E204C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2050: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2054: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2058: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E205C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2060(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2060 size=36
    let mut pc: u32 = 0x831E2060;
    'dispatch: loop {
        match pc {
            0x831E2060 => {
    //   block [0x831E2060..0x831E2084)
	// 831E2060: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 831E2064: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2068: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E206C: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E2070: 812B0018  lwz r9, 0x18(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E2074: 91240004  stw r9, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E2078: 810B001C  lwz r8, 0x1c(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E207C: 91040008  stw r8, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E2080: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2088(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2088 size=48
    let mut pc: u32 = 0x831E2088;
    'dispatch: loop {
        match pc {
            0x831E2088 => {
    //   block [0x831E2088..0x831E20B8)
	// 831E2088: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E208C: 3963FFF8  addi r11, r3, -8
	ctx.r[11].s64 = ctx.r[3].s64 + -8;
	// 831E2090: 409A0008  bne cr6, 0x831e2098
	if !ctx.cr[6].eq {
	pc = 0x831E2098; continue 'dispatch;
	}
	// 831E2094: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E2098: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E209C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E20A0: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E20A4: 812B0018  lwz r9, 0x18(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E20A8: 91240004  stw r9, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 831E20AC: 810B001C  lwz r8, 0x1c(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E20B0: 91040008  stw r8, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E20B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E20B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E20B8 size=264
    let mut pc: u32 = 0x831E20B8;
    'dispatch: loop {
        match pc {
            0x831E20B8 => {
    //   block [0x831E20B8..0x831E21C0)
	// 831E20B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E20BC: 4BFC60B1  bl 0x831a816c
	ctx.lr = 0x831E20C0;
	sub_831A8130(ctx, base);
	// 831E20C0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E20C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E20C8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E20CC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 831E20D0: 392B01D4  addi r9, r11, 0x1d4
	ctx.r[9].s64 = ctx.r[11].s64 + 468;
	// 831E20D4: 3D000000  lis r8, 0
	ctx.r[8].s64 = 0;
	// 831E20D8: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E20DC: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831E20E0: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E20E4: 610BBB80  ori r11, r8, 0xbb80
	ctx.r[11].u64 = ctx.r[8].u64 | 48000;
	// 831E20E8: 88E40000  lbz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E20EC: 54E6063E  clrlwi r6, r7, 0x18
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x000000FFu64;
	// 831E20F0: 98FF0008  stb r7, 8(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[7].u8 ) };
	// 831E20F4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 831E20F8: 80640010  lwz r3, 0x10(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E20FC: 907F0020  stw r3, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 831E2100: 9BBF0014  stb r29, 0x14(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u8 ) };
	// 831E2104: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 831E2108: 409A0098  bne cr6, 0x831e21a0
	if !ctx.cr[6].eq {
	pc = 0x831E21A0; continue 'dispatch;
	}
	// 831E210C: 81440008  lwz r10, 8(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2110: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 831E2114: 80C50000  lwz r6, 0(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2118: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 831E211C: 7CEB5396  divwu r7, r11, r10
	ctx.r[7].u32 = ctx.r[11].u32 / ctx.r[10].u32;
	// 831E2120: 89040005  lbz r8, 5(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(5 as u32) ) } as u64;
	// 831E2124: 3BC40004  addi r30, r4, 4
	ctx.r[30].s64 = ctx.r[4].s64 + 4;
	// 831E2128: 7CA93B96  divwu r5, r9, r7
	ctx.r[5].u32 = ctx.r[9].u32 / ctx.r[7].u32;
	// 831E212C: 0CCA0000  twi 6, r10, 0
	// 831E2130: 54A4043E  clrlwi r4, r5, 0x10
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x0000FFFFu64;
	// 831E2134: 81460014  lwz r10, 0x14(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2138: 0CC70000  twi 6, r7, 0
	// 831E213C: 7D6441D6  mullw r11, r4, r8
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831E2140: 392B0020  addi r9, r11, 0x20
	ctx.r[9].s64 = ctx.r[11].s64 + 32;
	// 831E2144: 5524103A  slwi r4, r9, 2
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 831E2148: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E214C: 4E800421  bctrl
	ctx.lr = 0x831E2150;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2150: 3903007F  addi r8, r3, 0x7f
	ctx.r[8].s64 = ctx.r[3].s64 + 127;
	// 831E2154: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E2158: 550B0030  rlwinm r11, r8, 0, 0, 0x18
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831E215C: 419A0028  beq cr6, 0x831e2184
	if ctx.cr[6].eq {
	pc = 0x831E2184; continue 'dispatch;
	}
	// 831E2160: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2164: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2168: 915F000C  stw r10, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 831E216C: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2170: 913F0010  stw r9, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[9].u32 ) };
	// 831E2174: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831E2178: 9BBF0015  stb r29, 0x15(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(21 as u32), ctx.r[29].u8 ) };
	// 831E217C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2180: 4BFC603C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831E2184: 93BF000C  stw r29, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E2188: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E218C: 93BF0010  stw r29, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E2190: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831E2194: 9BBF0015  stb r29, 0x15(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(21 as u32), ctx.r[29].u8 ) };
	// 831E2198: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E219C: 4BFC6020  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831E21A0: 8164000C  lwz r11, 0xc(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E21A4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E21A8: 93BF000C  stw r29, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 831E21AC: 93BF0010  stw r29, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 831E21B0: 9BBF0015  stb r29, 0x15(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(21 as u32), ctx.r[29].u8 ) };
	// 831E21B4: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 831E21B8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E21BC: 4BFC6000  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E21C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E21C0 size=292
    let mut pc: u32 = 0x831E21C0;
    'dispatch: loop {
        match pc {
            0x831E21C0 => {
    //   block [0x831E21C0..0x831E22E4)
	// 831E21C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E21C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E21C8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E21CC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E21D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E21D4: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E21D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E21DC: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 831E21E0: 409A0008  bne cr6, 0x831e21e8
	if !ctx.cr[6].eq {
	pc = 0x831E21E8; continue 'dispatch;
	}
	// 831E21E4: 3BDF000C  addi r30, r31, 0xc
	ctx.r[30].s64 = ctx.r[31].s64 + 12;
	// 831E21E8: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831E21EC: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E21F0: 811F0010  lwz r8, 0x10(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 831E21F4: 39400100  li r10, 0x100
	ctx.r[10].s64 = 256;
	// 831E21F8: 616BBB80  ori r11, r11, 0xbb80
	ctx.r[11].u64 = ctx.r[11].u64 | 48000;
	// 831E21FC: 80FF0018  lwz r7, 0x18(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E2200: 0CC90000  twi 6, r9, 0
	// 831E2204: 887E0001  lbz r3, 1(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E2208: 7C8B4B96  divwu r4, r11, r9
	ctx.r[4].u32 = ctx.r[11].u32 / ctx.r[9].u32;
	// 831E220C: 88DF000D  lbz r6, 0xd(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 831E2210: 7D2B4396  divwu r9, r11, r8
	ctx.r[9].u32 = ctx.r[11].u32 / ctx.r[8].u32;
	// 831E2214: 0CC70000  twi 6, r7, 0
	// 831E2218: 7CEB3B96  divwu r7, r11, r7
	ctx.r[7].u32 = ctx.r[11].u32 / ctx.r[7].u32;
	// 831E221C: 0CC40000  twi 6, r4, 0
	// 831E2220: 7C8A2396  divwu r4, r10, r4
	ctx.r[4].u32 = ctx.r[10].u32 / ctx.r[4].u32;
	// 831E2224: 7D6A4B96  divwu r11, r10, r9
	ctx.r[11].u32 = ctx.r[10].u32 / ctx.r[9].u32;
	// 831E2228: 7D4A3B96  divwu r10, r10, r7
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[7].u32;
	// 831E222C: 0CC90000  twi 6, r9, 0
	// 831E2230: 5489043E  clrlwi r9, r4, 0x10
	ctx.r[9].u64 = ctx.r[4].u32 as u64 & 0x0000FFFFu64;
	// 831E2234: 0CC70000  twi 6, r7, 0
	// 831E2238: 5567043E  clrlwi r7, r11, 0x10
	ctx.r[7].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 831E223C: 5544043E  clrlwi r4, r10, 0x10
	ctx.r[4].u64 = ctx.r[10].u32 as u64 & 0x0000FFFFu64;
	// 831E2240: 7D4919D6  mullw r10, r9, r3
	ctx.r[10].s64 = (ctx.r[9].s32 as i64) * (ctx.r[3].s32 as i64);
	// 831E2244: 0CC80000  twi 6, r8, 0
	// 831E2248: 891F0015  lbz r8, 0x15(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(21 as u32) ) } as u64;
	// 831E224C: 7C6731D6  mullw r3, r7, r6
	ctx.r[3].s64 = (ctx.r[7].s32 as i64) * (ctx.r[6].s32 as i64);
	// 831E2250: 7D6441D6  mullw r11, r4, r8
	ctx.r[11].s64 = (ctx.r[4].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831E2254: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 831E2258: 40990010  ble cr6, 0x831e2268
	if !ctx.cr[6].gt {
	pc = 0x831E2268; continue 'dispatch;
	}
	// 831E225C: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E2260: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E2264: 48000068  b 0x831e22cc
	pc = 0x831E22CC; continue 'dispatch;
	// 831E2268: 54A907FE  clrlwi r9, r5, 0x1f
	ctx.r[9].u64 = ctx.r[5].u32 as u64 & 0x00000001u64;
	// 831E226C: 54A8063E  clrlwi r8, r5, 0x18
	ctx.r[8].u64 = ctx.r[5].u32 as u64 & 0x000000FFu64;
	// 831E2270: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E2274: 409A0018  bne cr6, 0x831e228c
	if !ctx.cr[6].eq {
	pc = 0x831E228C; continue 'dispatch;
	}
	// 831E2278: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831E227C: 40990010  ble cr6, 0x831e228c
	if !ctx.cr[6].gt {
	pc = 0x831E228C; continue 'dispatch;
	}
	// 831E2280: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E2284: 6063FFFF  ori r3, r3, 0xffff
	ctx.r[3].u64 = ctx.r[3].u64 | 65535;
	// 831E2288: 48000044  b 0x831e22cc
	pc = 0x831E22CC; continue 'dispatch;
	// 831E228C: 550807BC  rlwinm r8, r8, 0, 0x1e, 0x1e
	ctx.r[8].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 831E2290: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 831E2294: 419A002C  beq cr6, 0x831e22c0
	if ctx.cr[6].eq {
	pc = 0x831E22C0; continue 'dispatch;
	}
	// 831E2298: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 831E229C: 419A0008  beq cr6, 0x831e22a4
	if ctx.cr[6].eq {
	pc = 0x831E22A4; continue 'dispatch;
	}
	// 831E22A0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E22A4: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 831E22A8: 813F001C  lwz r9, 0x1c(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 831E22AC: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E22B0: 5545103A  slwi r5, r10, 2
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831E22B4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E22B8: 7C6B4A14  add r3, r11, r9
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 831E22BC: 4BFC5F25  bl 0x831a81e0
	ctx.lr = 0x831E22C0;
	sub_831A81E0(ctx, base);
	// 831E22C0: 897E0001  lbz r11, 1(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 831E22C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E22C8: 997F0015  stb r11, 0x15(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(21 as u32), ctx.r[11].u8 ) };
	// 831E22CC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E22D0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E22D4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E22D8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E22DC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E22E0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E22E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E22E8 size=20
    let mut pc: u32 = 0x831E22E8;
    'dispatch: loop {
        match pc {
            0x831E22E8 => {
    //   block [0x831E22E8..0x831E22FC)
	// 831E22E8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E22EC: 3863FFF8  addi r3, r3, -8
	ctx.r[3].s64 = ctx.r[3].s64 + -8;
	// 831E22F0: 409A0008  bne cr6, 0x831e22f8
	if !ctx.cr[6].eq {
	pc = 0x831E22F8; continue 'dispatch;
	}
	// 831E22F4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E22F8: 4BFFFEC8  b 0x831e21c0
	sub_831E21C0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2300(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E2300 size=84
    let mut pc: u32 = 0x831E2300;
    'dispatch: loop {
        match pc {
            0x831E2300 => {
    //   block [0x831E2300..0x831E2354)
	// 831E2300: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2304: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E2308: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E230C: 409A0038  bne cr6, 0x831e2344
	if !ctx.cr[6].eq {
	pc = 0x831E2344; continue 'dispatch;
	}
	// 831E2310: 3D600000  lis r11, 0
	ctx.r[11].s64 = 0;
	// 831E2314: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2318: 39200100  li r9, 0x100
	ctx.r[9].s64 = 256;
	// 831E231C: 89030005  lbz r8, 5(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(5 as u32) ) } as u64;
	// 831E2320: 6167BB80  ori r7, r11, 0xbb80
	ctx.r[7].u64 = ctx.r[11].u64 | 48000;
	// 831E2324: 0CCA0000  twi 6, r10, 0
	// 831E2328: 7CC75396  divwu r6, r7, r10
	ctx.r[6].u32 = ctx.r[7].u32 / ctx.r[10].u32;
	// 831E232C: 7CA93396  divwu r5, r9, r6
	ctx.r[5].u32 = ctx.r[9].u32 / ctx.r[6].u32;
	// 831E2330: 0CC60000  twi 6, r6, 0
	// 831E2334: 54A3043E  clrlwi r3, r5, 0x10
	ctx.r[3].u64 = ctx.r[5].u32 as u64 & 0x0000FFFFu64;
	// 831E2338: 7D6341D6  mullw r11, r3, r8
	ctx.r[11].s64 = (ctx.r[3].s32 as i64) * (ctx.r[8].s32 as i64);
	// 831E233C: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831E2340: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831E2344: 396B0024  addi r11, r11, 0x24
	ctx.r[11].s64 = ctx.r[11].s64 + 36;
	// 831E2348: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E234C: 91640000  stw r11, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E2350: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2358(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2358 size=128
    let mut pc: u32 = 0x831E2358;
    'dispatch: loop {
        match pc {
            0x831E2358 => {
    //   block [0x831E2358..0x831E23D8)
	// 831E2358: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E235C: 4BFC5E11  bl 0x831a816c
	ctx.lr = 0x831E2360;
	sub_831A8130(ctx, base);
	// 831E2360: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2364: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E2368: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E236C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 831E2370: 38800024  li r4, 0x24
	ctx.r[4].s64 = 36;
	// 831E2374: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2378: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E237C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2380: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2384: 4E800421  bctrl
	ctx.lr = 0x831E2388;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2388: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E238C: 419A003C  beq cr6, 0x831e23c8
	if ctx.cr[6].eq {
	pc = 0x831E23C8; continue 'dispatch;
	}
	// 831E2390: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 831E2394: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831E2398: 4BFFFD21  bl 0x831e20b8
	ctx.lr = 0x831E239C;
	sub_831E20B8(ctx, base);
	// 831E239C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E23A0: 419A0028  beq cr6, 0x831e23c8
	if ctx.cr[6].eq {
	pc = 0x831E23C8; continue 'dispatch;
	}
	// 831E23A4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E23A8: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831E23AC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 831E23B0: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E23B4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E23B8: 4E800421  bctrl
	ctx.lr = 0x831E23BC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E23BC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E23C0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E23C4: 4BFC5DF8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831E23C8: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E23CC: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E23D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E23D4: 4BFC5DE8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E23D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E23D8 size=16
    let mut pc: u32 = 0x831E23D8;
    'dispatch: loop {
        match pc {
            0x831E23D8 => {
    //   block [0x831E23D8..0x831E23E8)
	// 831E23D8: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E23DC: 394BFF64  addi r10, r11, -0x9c
	ctx.r[10].s64 = ctx.r[11].s64 + -156;
	// 831E23E0: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E23E4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E23E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E23E8 size=112
    let mut pc: u32 = 0x831E23E8;
    'dispatch: loop {
        match pc {
            0x831E23E8 => {
    //   block [0x831E23E8..0x831E2458)
	// 831E23E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E23EC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E23F0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E23F4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E23F8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E23FC: 3D60821A  lis r11, -0x7de6
	ctx.r[11].s64 = -2112225280;
	// 831E2400: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E2404: 394B01F0  addi r10, r11, 0x1f0
	ctx.r[10].s64 = ctx.r[11].s64 + 496;
	// 831E2408: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E240C: 48001E3D  bl 0x831e4248
	ctx.lr = 0x831E2410;
	sub_831E4248(ctx, base);
	// 831E2410: 817F0044  lwz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E2414: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831E2418: 419A0024  beq cr6, 0x831e243c
	if ctx.cr[6].eq {
	pc = 0x831E243C; continue 'dispatch;
	}
	// 831E241C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2420: 386B0004  addi r3, r11, 4
	ctx.r[3].s64 = ctx.r[11].s64 + 4;
	// 831E2424: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831E2428: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E242C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831E2430: 4E800421  bctrl
	ctx.lr = 0x831E2434;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2434: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 831E2438: 911F0044  stw r8, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[8].u32 ) };
	// 831E243C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2440: 480016E9  bl 0x831e3b28
	ctx.lr = 0x831E2444;
	sub_831E3B28(ctx, base);
	// 831E2444: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2448: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E244C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2450: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2454: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2458(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2458 size=92
    let mut pc: u32 = 0x831E2458;
    'dispatch: loop {
        match pc {
            0x831E2458 => {
    //   block [0x831E2458..0x831E24B4)
	// 831E2458: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E245C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2460: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2464: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2468: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E246C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E2470: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831E2474: 480022CD  bl 0x831e4740
	ctx.lr = 0x831E2478;
	sub_831E4740(ctx, base);
	// 831E2478: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E247C: 41980020  blt cr6, 0x831e249c
	if ctx.cr[6].lt {
	pc = 0x831E249C; continue 'dispatch;
	}
	// 831E2480: 807F0044  lwz r3, 0x44(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 831E2484: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831E2488: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E248C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2490: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E2494: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2498: 4E800421  bctrl
	ctx.lr = 0x831E249C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E249C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E24A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E24A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E24A8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E24AC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E24B0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E24B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E24B8 size=12
    let mut pc: u32 = 0x831E24B8;
    'dispatch: loop {
        match pc {
            0x831E24B8 => {
    //   block [0x831E24B8..0x831E24C4)
	// 831E24B8: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E24BC: 806BD59C  lwz r3, -0x2a64(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-10852 as u32) ) } as u64;
	// 831E24C0: 4BFF7460  b 0x831d9920
	sub_831D9920(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E24C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x831E24C8 size=12
    let mut pc: u32 = 0x831E24C8;
    'dispatch: loop {
        match pc {
            0x831E24C8 => {
    //   block [0x831E24C8..0x831E24D4)
	// 831E24C8: 3C608000  lis r3, -0x8000
	ctx.r[3].s64 = -2147483648;
	// 831E24CC: 60634001  ori r3, r3, 0x4001
	ctx.r[3].u64 = ctx.r[3].u64 | 16385;
	// 831E24D0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E24D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E24D8 size=128
    let mut pc: u32 = 0x831E24D8;
    'dispatch: loop {
        match pc {
            0x831E24D8 => {
    //   block [0x831E24D8..0x831E2558)
	// 831E24D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E24DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E24E0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E24E4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E24E8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E24EC: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E24F0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E24F4: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E24F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E24FC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2500: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 831E2504: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2508: 4E800421  bctrl
	ctx.lr = 0x831E250C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E250C: 89610050  lbz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E2510: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831E2514: 41980028  blt cr6, 0x831e253c
	if ctx.cr[6].lt {
	pc = 0x831E253C; continue 'dispatch;
	}
	// 831E2518: 419A0010  beq cr6, 0x831e2528
	if ctx.cr[6].eq {
	pc = 0x831E2528; continue 'dispatch;
	}
	// 831E251C: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 831E2520: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2524: 4800001C  b 0x831e2540
	pc = 0x831E2540; continue 'dispatch;
	// 831E2528: 897F004C  lbz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 831E252C: 815E007C  lwz r10, 0x7c(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(124 as u32) ) } as u64;
	// 831E2530: 1D6B002C  mulli r11, r11, 0x2c
	ctx.r[11].s64 = ctx.r[11].s64 * 44;
	// 831E2534: 7C6B5214  add r3, r11, r10
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 831E2538: 48000008  b 0x831e2540
	pc = 0x831E2540; continue 'dispatch;
	// 831E253C: 387E0050  addi r3, r30, 0x50
	ctx.r[3].s64 = ctx.r[30].s64 + 80;
	// 831E2540: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E2544: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2548: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E254C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E2550: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2554: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2558 size=48
    let mut pc: u32 = 0x831E2558;
    'dispatch: loop {
        match pc {
            0x831E2558 => {
    //   block [0x831E2558..0x831E2588)
	// 831E2558: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E255C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2560: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2564: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2568: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E256C: 4BFFFE7D  bl 0x831e23e8
	ctx.lr = 0x831E2570;
	sub_831E23E8(ctx, base);
	// 831E2570: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2574: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2578: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E257C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2580: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2584: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2588 size=296
    let mut pc: u32 = 0x831E2588;
    'dispatch: loop {
        match pc {
            0x831E2588 => {
    //   block [0x831E2588..0x831E26B0)
	// 831E2588: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E258C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2590: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E2594: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2598: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E259C: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 831E25A0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831E25A4: 3D400000  lis r10, 0
	ctx.r[10].s64 = 0;
	// 831E25A8: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 831E25AC: 6148BB80  ori r8, r10, 0xbb80
	ctx.r[8].u64 = ctx.r[10].u64 | 48000;
	// 831E25B0: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 831E25B4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E25B8: FBCB0008  std r30, 8(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u64 ) };
	// 831E25BC: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 831E25C0: FBCB0010  std r30, 0x10(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[30].u64 ) };
	// 831E25C4: 9BC10060  stb r30, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u8 ) };
	// 831E25C8: 99210061  stb r9, 0x61(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(97 as u32), ctx.r[9].u8 ) };
	// 831E25CC: 91010064  stw r8, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[8].u32 ) };
	// 831E25D0: 419A001C  beq cr6, 0x831e25ec
	if ctx.cr[6].eq {
	pc = 0x831E25EC; continue 'dispatch;
	}
	// 831E25D4: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E25D8: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E25DC: 81240008  lwz r9, 8(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E25E0: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 831E25E4: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E25E8: 91210074  stw r9, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[9].u32 ) };
	// 831E25EC: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 831E25F0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E25F4: 48002015  bl 0x831e4608
	ctx.lr = 0x831E25F8;
	sub_831E4608(ctx, base);
	// 831E25F8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E25FC: 4198009C  blt cr6, 0x831e2698
	if ctx.cr[6].lt {
	pc = 0x831E2698; continue 'dispatch;
	}
	// 831E2600: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 831E2604: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2608: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 831E260C: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 831E2610: FBCB0000  std r30, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u64 ) };
	// 831E2614: 93CB0008  stw r30, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831E2618: 99410050  stb r10, 0x50(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u8 ) };
	// 831E261C: 93E10054  stw r31, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[31].u32 ) };
	// 831E2620: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2624: 81090014  lwz r8, 0x14(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) } as u64;
	// 831E2628: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831E262C: 4E800421  bctrl
	ctx.lr = 0x831E2630;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2630: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2634: 419A0014  beq cr6, 0x831e2648
	if ctx.cr[6].eq {
	pc = 0x831E2648; continue 'dispatch;
	}
	// 831E2638: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E263C: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2640: 4BFFDD51  bl 0x831e0390
	ctx.lr = 0x831E2644;
	sub_831E0390(ctx, base);
	// 831E2644: 48000008  b 0x831e264c
	pc = 0x831E264C; continue 'dispatch;
	// 831E2648: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E264C: 907F0044  stw r3, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[3].u32 ) };
	// 831E2650: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2654: 409A0010  bne cr6, 0x831e2664
	if !ctx.cr[6].eq {
	pc = 0x831E2664; continue 'dispatch;
	}
	// 831E2658: 3C608007  lis r3, -0x7ff9
	ctx.r[3].s64 = -2147024896;
	// 831E265C: 6063000E  ori r3, r3, 0xe
	ctx.r[3].u64 = ctx.r[3].u64 | 14;
	// 831E2660: 48000038  b 0x831e2698
	pc = 0x831E2698; continue 'dispatch;
	// 831E2664: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2668: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E266C: 80BF0008  lwz r5, 8(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E2670: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831E2674: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2678: 4E800421  bctrl
	ctx.lr = 0x831E267C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E267C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E2680: 41980018  blt cr6, 0x831e2698
	if ctx.cr[6].lt {
	pc = 0x831E2698; continue 'dispatch;
	}
	// 831E2684: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E2688: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E268C: 814B0038  lwz r10, 0x38(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(56 as u32) ) } as u64;
	// 831E2690: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831E2694: 4E800421  bctrl
	ctx.lr = 0x831E2698;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831E2698: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E269C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E26A0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E26A4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E26A8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E26AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E26B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E26B0 size=84
    let mut pc: u32 = 0x831E26B0;
    'dispatch: loop {
        match pc {
            0x831E26B0 => {
    //   block [0x831E26B0..0x831E2704)
	// 831E26B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E26B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E26B8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831E26BC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E26C0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E26C4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831E26C8: 48001291  bl 0x831e3958
	ctx.lr = 0x831E26CC;
	sub_831E3958(ctx, base);
	// 831E26CC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E26D0: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831E26D4: 41980014  blt cr6, 0x831e26e8
	if ctx.cr[6].lt {
	pc = 0x831E26E8; continue 'dispatch;
	}
	// 831E26D8: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831E26DC: 807E0020  lwz r3, 0x20(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E26E0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E26E4: 4BFFFC05  bl 0x831e22e8
	ctx.lr = 0x831E26E8;
	sub_831E22E8(ctx, base);
	// 831E26E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E26EC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831E26F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E26F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E26F8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831E26FC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2700: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2708(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2708 size=104
    let mut pc: u32 = 0x831E2708;
    'dispatch: loop {
        match pc {
            0x831E2708 => {
    //   block [0x831E2708..0x831E2770)
	// 831E2708: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E270C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2710: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E2714: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2718: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831E271C: 897F003D  lbz r11, 0x3d(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(61 as u32) ) } as u64;
	// 831E2720: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831E2724: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831E2728: 419A001C  beq cr6, 0x831e2744
	if ctx.cr[6].eq {
	pc = 0x831E2744; continue 'dispatch;
	}
	// 831E272C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2730: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2734: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2738: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E273C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E2740: 4E800020  blr
	return;
	// 831E2744: 38A00003  li r5, 3
	ctx.r[5].s64 = 3;
	// 831E2748: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 831E274C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 831E2750: 4BFFFB99  bl 0x831e22e8
	ctx.lr = 0x831E2754;
	sub_831E22E8(ctx, base);
	// 831E2754: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2758: 480018C9  bl 0x831e4020
	ctx.lr = 0x831E275C;
	sub_831E4020(ctx, base);
	// 831E275C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831E2760: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E2764: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E2768: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E276C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2770(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2770 size=224
    let mut pc: u32 = 0x831E2770;
    'dispatch: loop {
        match pc {
            0x831E2770 => {
    //   block [0x831E2770..0x831E2850)
	// 831E2770: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2774: 4BFC59F5  bl 0x831a8168
	ctx.lr = 0x831E2778;
	sub_831A8130(ctx, base);
	// 831E2778: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E277C: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831E2780: 480609DD  bl 0x8324315c
	ctx.lr = 0x831E2784;
	// extern call 0x8324315C → crate::xboxkrnl::KeRaiseIrqlToDpcLevel
	crate::xboxkrnl::KeRaiseIrqlToDpcLevel(ctx, base);
	// 831E2784: 3D608343  lis r11, -0x7cbd
	ctx.r[11].s64 = -2092761088;
	// 831E2788: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 831E278C: 3BEBD530  addi r31, r11, -0x2ad0
	ctx.r[31].s64 = ctx.r[11].s64 + -10960;
	// 831E2790: 7DBE6B78  mr r30, r13
	ctx.r[30].u64 = ctx.r[13].u64;
	// 831E2794: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2798: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E279C: 419A0010  beq cr6, 0x831e27ac
	if ctx.cr[6].eq {
	pc = 0x831E27AC; continue 'dispatch;
	}
	// 831E27A0: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E27A4: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E27A8: 419A001C  beq cr6, 0x831e27c4
	if ctx.cr[6].eq {
	pc = 0x831E27C4; continue 'dispatch;
	}
	// 831E27AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E27B0: 480602CD  bl 0x83242a7c
	ctx.lr = 0x831E27B4;
	// extern call 0x83242A7C → crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql
	crate::xboxkrnl::KeAcquireSpinLockAtRaisedIrql(ctx, base);
	// 831E27B4: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 831E27B8: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E27BC: 9BBF000C  stb r29, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u8 ) };
	// 831E27C0: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 831E27C4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831E27C8: 397C0018  addi r11, r28, 0x18
	ctx.r[11].s64 = ctx.r[28].s64 + 24;
	// 831E27CC: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E27D0: 813C0018  lwz r9, 0x18(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(24 as u32) ) } as u64;
	// 831E27D4: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831E27D8: 419A0028  beq cr6, 0x831e2800
	if ctx.cr[6].eq {
	pc = 0x831E2800; continue 'dispatch;
	}
	// 831E27DC: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E27E0: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 831E27E4: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E27E8: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E27EC: 91280000  stw r9, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831E27F0: 916B0004  stw r11, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E27F4: 916B0000  stw r11, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831E27F8: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E27FC: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E2800: 7DAB6B78  mr r11, r13
	ctx.r[11].u64 = ctx.r[13].u64;
	// 831E2804: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831E2808: 419A003C  beq cr6, 0x831e2844
	if ctx.cr[6].eq {
	pc = 0x831E2844; continue 'dispatch;
	}
	// 831E280C: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831E2810: 409A0034  bne cr6, 0x831e2844
	if !ctx.cr[6].eq {
	pc = 0x831E2844; continue 'dispatch;
	}
	// 831E2814: 356AFFFF  addic. r11, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831E2818: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 831E281C: 40820028  bne 0x831e2844
	if !ctx.cr[0].eq {
	pc = 0x831E2844; continue 'dispatch;
	}
	// 831E2820: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E2824: 8BDF000C  lbz r30, 0xc(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831E2828: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831E282C: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 831E2830: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831E2834: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 831E2838: 48060235  bl 0x83242a6c
	ctx.lr = 0x831E283C;
	// extern call 0x83242A6C → crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql
	crate::xboxkrnl::KeReleaseSpinLockFromRaisedIrql(ctx, base);
	// 831E283C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831E2840: 4806092D  bl 0x8324316c
	ctx.lr = 0x831E2844;
	// extern call 0x8324316C → crate::xboxkrnl::KfLowerIrql
	crate::xboxkrnl::KfLowerIrql(ctx, base);
	// 831E2844: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831E2848: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831E284C: 4BFC596C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831E2850(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831E2850 size=148
    let mut pc: u32 = 0x831E2850;
    'dispatch: loop {
        match pc {
            0x831E2850 => {
    //   block [0x831E2850..0x831E28E4)
	// 831E2850: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831E2854: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831E2858: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831E285C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831E2860: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 831E2864: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831E2868: 3D200000  lis r9, 0
	ctx.r[9].s64 = 0;
	// 831E286C: 39000006  li r8, 6
	ctx.r[8].s64 = 6;
	// 831E2870: 6127BB80  ori r7, r9, 0xbb80
	ctx.r[7].u64 = ctx.r[9].u64 | 48000;
	// 831E2874: F96A0000  std r11, 0(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u64 ) };
	// 831E2878: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831E287C: F96A0008  std r11, 8(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[11].u64 ) };
	// 831E2880: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831E2884: F96A0010  std r11, 0x10(r10)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[11].u64 ) };
	// 831E2888: 99610060  stb r11, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u8 ) };
	// 831E288C: 99010061  stb r8, 0x61(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(97 as u32), ctx.r[8].u8 ) };
	// 831E2890: 90E10064  stw r7, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[7].u32 ) };
	// 831E2894: 419A001C  beq cr6, 0x831e28b0
	if ctx.cr[6].eq {
	pc = 0x831E28B0; continue 'dispatch;
	}
	// 831E2898: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831E289C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 831E28A0: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831E28A4: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 831E28A8: 91410070  stw r10, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[10].u32 ) };
	// 831E28AC: 91210074  stw r9, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[9].u32 ) };
	// 831E28B0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 831E28B4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 831E28B8: 48001189  bl 0x831e3a40
	ctx.lr = 0x831E28BC;
	sub_831E3A40(ctx, base);
	// 831E28BC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831E28C0: 41980010  blt cr6, 0x831e28d0
	if ctx.cr[6].lt {
	pc = 0x831E28D0; continue 'dispatch;
	}
	// 831E28C4: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 831E28C8: 394B001C  addi r10, r11, 0x1c
	ctx.r[10].s64 = ctx.r[11].s64 + 28;
	// 831E28CC: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831E28D0: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831E28D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831E28D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831E28DC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831E28E0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}



pub fn sub_82FC7B58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7B58 size=36
    let mut pc: u32 = 0x82FC7B58;
    'dispatch: loop {
        match pc {
            0x82FC7B58 => {
    //   block [0x82FC7B58..0x82FC7B7C)
	// 82FC7B58: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7B5C: D0030000  stfs f0, 0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7B60: C1A40004  lfs f13, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7B64: D1A30004  stfs f13, 4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7B68: C1840008  lfs f12, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7B6C: D1830008  stfs f12, 8(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7B70: C164000C  lfs f11, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7B74: D163000C  stfs f11, 0xc(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7B78: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7B80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7B80 size=68
    let mut pc: u32 = 0x82FC7B80;
    'dispatch: loop {
        match pc {
            0x82FC7B80 => {
    //   block [0x82FC7B80..0x82FC7BC4)
	// 82FC7B80: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7B84: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7B88: ED80682A  fadds f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC7B8C: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7B90: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7B94: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7B98: ED2A582A  fadds f9, f10, f11
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC7B9C: C1030008  lfs f8, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC7BA0: D1230004  stfs f9, 4(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7BA4: C0E40008  lfs f7, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC7BA8: ECC7402A  fadds f6, f7, f8
	ctx.f[6].f64 = ((ctx.f[7].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FC7BAC: C0A3000C  lfs f5, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC7BB0: D0C30008  stfs f6, 8(r3)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7BB4: C084000C  lfs f4, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC7BB8: EC64282A  fadds f3, f4, f5
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[5].f64) as f32) as f64;
	// 82FC7BBC: D063000C  stfs f3, 0xc(r3)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7BC0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7BC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7BC8 size=68
    let mut pc: u32 = 0x82FC7BC8;
    'dispatch: loop {
        match pc {
            0x82FC7BC8 => {
    //   block [0x82FC7BC8..0x82FC7C0C)
	// 82FC7BC8: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7BCC: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7BD0: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC7BD4: C1630004  lfs f11, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7BD8: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7BDC: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7BE0: ED2B5028  fsubs f9, f11, f10
	ctx.f[9].f64 = (((ctx.f[11].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FC7BE4: C1030008  lfs f8, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC7BE8: D1230004  stfs f9, 4(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7BEC: C0E40008  lfs f7, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC7BF0: ECC83828  fsubs f6, f8, f7
	ctx.f[6].f64 = (((ctx.f[8].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FC7BF4: C0A3000C  lfs f5, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC7BF8: D0C30008  stfs f6, 8(r3)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7BFC: C084000C  lfs f4, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC7C00: EC652028  fsubs f3, f5, f4
	ctx.f[3].f64 = (((ctx.f[5].f64 - ctx.f[4].f64) as f32) as f64);
	// 82FC7C04: D063000C  stfs f3, 0xc(r3)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7C08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7C10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7C10 size=52
    let mut pc: u32 = 0x82FC7C10;
    'dispatch: loop {
        match pc {
            0x82FC7C10 => {
    //   block [0x82FC7C10..0x82FC7C44)
	// 82FC7C10: C0030000  lfs f0, 0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7C14: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7C18: ED800072  fmuls f12, f0, f1
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7C1C: C1630008  lfs f11, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7C20: ED4D0072  fmuls f10, f13, f1
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7C24: C123000C  lfs f9, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC7C28: ED0B0072  fmuls f8, f11, f1
	ctx.f[8].f64 = (((ctx.f[11].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7C2C: ECE90072  fmuls f7, f9, f1
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7C30: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7C34: D1430004  stfs f10, 4(r3)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7C38: D1030008  stfs f8, 8(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7C3C: D0E3000C  stfs f7, 0xc(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7C40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7C48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7C48 size=64
    let mut pc: u32 = 0x82FC7C48;
    'dispatch: loop {
        match pc {
            0x82FC7C48 => {
    //   block [0x82FC7C48..0x82FC7C88)
	// 82FC7C48: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC7C4C: C1A30000  lfs f13, 0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7C50: C1830004  lfs f12, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7C54: C1630008  lfs f11, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7C58: C143000C  lfs f10, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7C5C: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7C60: ED200824  fdivs f9, f0, f1
	ctx.f[9].f64 = ((ctx.f[0].f64 / ctx.f[1].f64) as f32) as f64;
	// 82FC7C64: ED0D0272  fmuls f8, f13, f9
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FC7C68: D1030000  stfs f8, 0(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7C6C: ECE90332  fmuls f7, f9, f12
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 82FC7C70: D0E30004  stfs f7, 4(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7C74: ECC902F2  fmuls f6, f9, f11
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC7C78: D0C30008  stfs f6, 8(r3)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7C7C: ECA902B2  fmuls f5, f9, f10
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FC7C80: D0A3000C  stfs f5, 0xc(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7C84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7C88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7C88 size=140
    let mut pc: u32 = 0x82FC7C88;
    'dispatch: loop {
        match pc {
            0x82FC7C88 => {
    //   block [0x82FC7C88..0x82FC7D14)
	// 82FC7C88: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7C8C: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7C90: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7C94: 3901FFF0  addi r8, r1, -0x10
	ctx.r[8].s64 = ctx.r[1].s64 + -16;
	// 82FC7C98: 80E40008  lwz r7, 8(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7C9C: C0050000  lfs f0, 0(r5)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7CA0: 80C4000C  lwz r6, 0xc(r4)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7CA4: C1A50004  lfs f13, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7CA8: C1850008  lfs f12, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7CAC: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7CB0: C165000C  lfs f11, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7CB4: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7CB8: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7CBC: 90CA000C  stw r6, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FC7CC0: C121FFF8  lfs f9, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC7CC4: C101FFFC  lfs f8, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC7CC8: C0E1FFF0  lfs f7, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC7CCC: C141FFF4  lfs f10, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7CD0: ECAD502A  fadds f5, f13, f10
	ctx.f[5].f64 = ((ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FC7CD4: ECC0382A  fadds f6, f0, f7
	ctx.f[6].f64 = ((ctx.f[0].f64 + ctx.f[7].f64) as f32) as f64;
	// 82FC7CD8: D0C1FFF0  stfs f6, -0x10(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7CDC: EC8C482A  fadds f4, f12, f9
	ctx.f[4].f64 = ((ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FC7CE0: D0A1FFF4  stfs f5, -0xc(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7CE4: EC6B402A  fadds f3, f11, f8
	ctx.f[3].f64 = ((ctx.f[11].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FC7CE8: D081FFF8  stfs f4, -8(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7CEC: D061FFFC  stfs f3, -4(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7CF0: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7CF4: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7CF8: 81480008  lwz r10, 8(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7CFC: 80A8000C  lwz r5, 0xc(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7D00: 90A3000C  stw r5, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7D04: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FC7D08: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FC7D0C: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC7D10: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7D18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7D18 size=140
    let mut pc: u32 = 0x82FC7D18;
    'dispatch: loop {
        match pc {
            0x82FC7D18 => {
    //   block [0x82FC7D18..0x82FC7DA4)
	// 82FC7D18: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7D1C: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7D20: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7D24: 3901FFF0  addi r8, r1, -0x10
	ctx.r[8].s64 = ctx.r[1].s64 + -16;
	// 82FC7D28: 80E40008  lwz r7, 8(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7D2C: C0050000  lfs f0, 0(r5)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7D30: 80C4000C  lwz r6, 0xc(r4)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7D34: C1A50004  lfs f13, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7D38: C1850008  lfs f12, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7D3C: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7D40: C165000C  lfs f11, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7D44: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7D48: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7D4C: 90CA000C  stw r6, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FC7D50: C121FFF8  lfs f9, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC7D54: C101FFFC  lfs f8, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC7D58: C0E1FFF0  lfs f7, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC7D5C: C141FFF4  lfs f10, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7D60: ECAA6828  fsubs f5, f10, f13
	ctx.f[5].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC7D64: ECC70028  fsubs f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC7D68: D0C1FFF0  stfs f6, -0x10(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7D6C: EC896028  fsubs f4, f9, f12
	ctx.f[4].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FC7D70: D0A1FFF4  stfs f5, -0xc(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7D74: EC685828  fsubs f3, f8, f11
	ctx.f[3].f64 = (((ctx.f[8].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FC7D78: D081FFF8  stfs f4, -8(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7D7C: D061FFFC  stfs f3, -4(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7D80: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7D84: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7D88: 81480008  lwz r10, 8(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7D8C: 80A8000C  lwz r5, 0xc(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7D90: 90A3000C  stw r5, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7D94: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FC7D98: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FC7D9C: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC7DA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7DA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7DA8 size=124
    let mut pc: u32 = 0x82FC7DA8;
    'dispatch: loop {
        match pc {
            0x82FC7DA8 => {
    //   block [0x82FC7DA8..0x82FC7E24)
	// 82FC7DA8: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7DAC: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7DB0: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7DB4: 3901FFF0  addi r8, r1, -0x10
	ctx.r[8].s64 = ctx.r[1].s64 + -16;
	// 82FC7DB8: 80E40008  lwz r7, 8(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7DBC: 80C4000C  lwz r6, 0xc(r4)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7DC0: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7DC4: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7DC8: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7DCC: 90CA000C  stw r6, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FC7DD0: C1A1FFF8  lfs f13, -8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7DD4: C181FFFC  lfs f12, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7DD8: C161FFF0  lfs f11, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7DDC: C001FFF4  lfs f0, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7DE0: ED200072  fmuls f9, f0, f1
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7DE4: ED4B0072  fmuls f10, f11, f1
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7DE8: D141FFF0  stfs f10, -0x10(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7DEC: ED0D0072  fmuls f8, f13, f1
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7DF0: D121FFF4  stfs f9, -0xc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7DF4: ECEC0072  fmuls f7, f12, f1
	ctx.f[7].f64 = (((ctx.f[12].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7DF8: D101FFF8  stfs f8, -8(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7DFC: D0E1FFFC  stfs f7, -4(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7E00: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7E04: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7E08: 81480008  lwz r10, 8(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7E0C: 80A8000C  lwz r5, 0xc(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7E10: 90A3000C  stw r5, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7E14: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FC7E18: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FC7E1C: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC7E20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7E28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7E28 size=136
    let mut pc: u32 = 0x82FC7E28;
    'dispatch: loop {
        match pc {
            0x82FC7E28 => {
    //   block [0x82FC7E28..0x82FC7EB0)
	// 82FC7E28: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7E2C: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7E30: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7E34: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 82FC7E38: 80E40008  lwz r7, 8(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7E3C: 38C1FFF0  addi r6, r1, -0x10
	ctx.r[6].s64 = ctx.r[1].s64 + -16;
	// 82FC7E40: 80A4000C  lwz r5, 0xc(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7E44: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7E48: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7E4C: C00808A8  lfs f0, 0x8a8(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7E50: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7E54: EC000824  fdivs f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 / ctx.f[1].f64) as f32) as f64;
	// 82FC7E58: 90AA000C  stw r5, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7E5C: C181FFF8  lfs f12, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7E60: C161FFFC  lfs f11, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7E64: C141FFF0  lfs f10, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7E68: C1A1FFF4  lfs f13, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7E6C: ED000372  fmuls f8, f0, f13
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FC7E70: D101FFF4  stfs f8, -0xc(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7E74: ED2002B2  fmuls f9, f0, f10
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FC7E78: D121FFF0  stfs f9, -0x10(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7E7C: ECE00332  fmuls f7, f0, f12
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82FC7E80: D0E1FFF8  stfs f7, -8(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7E84: ECC002F2  fmuls f6, f0, f11
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC7E88: D0C1FFFC  stfs f6, -4(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7E8C: 81660000  lwz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7E90: 81460004  lwz r10, 4(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7E94: 81260008  lwz r9, 8(r6)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7E98: 8086000C  lwz r4, 0xc(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7E9C: 9083000C  stw r4, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FC7EA0: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 82FC7EA4: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FC7EA8: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7EAC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7EB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7EB0 size=124
    let mut pc: u32 = 0x82FC7EB0;
    'dispatch: loop {
        match pc {
            0x82FC7EB0 => {
    //   block [0x82FC7EB0..0x82FC7F2C)
	// 82FC7EB0: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7EB4: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7EB8: 81250004  lwz r9, 4(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7EBC: 3901FFF0  addi r8, r1, -0x10
	ctx.r[8].s64 = ctx.r[1].s64 + -16;
	// 82FC7EC0: 80E50008  lwz r7, 8(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7EC4: 80C5000C  lwz r6, 0xc(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7EC8: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7ECC: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7ED0: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7ED4: 90CA000C  stw r6, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FC7ED8: C1A1FFF8  lfs f13, -8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7EDC: C181FFFC  lfs f12, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7EE0: C161FFF0  lfs f11, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7EE4: C001FFF4  lfs f0, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7EE8: ED200072  fmuls f9, f0, f1
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7EEC: ED4B0072  fmuls f10, f11, f1
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7EF0: D141FFF0  stfs f10, -0x10(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7EF4: ED0D0072  fmuls f8, f13, f1
	ctx.f[8].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7EF8: D121FFF4  stfs f9, -0xc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7EFC: ECEC0072  fmuls f7, f12, f1
	ctx.f[7].f64 = (((ctx.f[12].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FC7F00: D101FFF8  stfs f8, -8(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7F04: D0E1FFFC  stfs f7, -4(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7F08: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7F0C: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7F10: 81480008  lwz r10, 8(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7F14: 80A8000C  lwz r5, 0xc(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7F18: 90A3000C  stw r5, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7F1C: 91430008  stw r10, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FC7F20: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FC7F24: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC7F28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7F30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7F30 size=136
    let mut pc: u32 = 0x82FC7F30;
    'dispatch: loop {
        match pc {
            0x82FC7F30 => {
    //   block [0x82FC7F30..0x82FC7FB8)
	// 82FC7F30: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7F34: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC7F38: 81250004  lwz r9, 4(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7F3C: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 82FC7F40: 80E50008  lwz r7, 8(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7F44: 38C1FFF0  addi r6, r1, -0x10
	ctx.r[6].s64 = ctx.r[1].s64 + -16;
	// 82FC7F48: 80A5000C  lwz r5, 0xc(r5)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7F4C: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7F50: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC7F54: C00808A8  lfs f0, 0x8a8(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7F58: 90EA0008  stw r7, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FC7F5C: EC000824  fdivs f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 / ctx.f[1].f64) as f32) as f64;
	// 82FC7F60: 90AA000C  stw r5, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC7F64: C181FFF8  lfs f12, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC7F68: C161FFFC  lfs f11, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7F6C: C141FFF0  lfs f10, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC7F70: C1A1FFF4  lfs f13, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7F74: ED000372  fmuls f8, f0, f13
	ctx.f[8].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FC7F78: D101FFF4  stfs f8, -0xc(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC7F7C: ED2002B2  fmuls f9, f0, f10
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FC7F80: D121FFF0  stfs f9, -0x10(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC7F84: ECE00332  fmuls f7, f0, f12
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82FC7F88: D0E1FFF8  stfs f7, -8(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC7F8C: ECC002F2  fmuls f6, f0, f11
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC7F90: D0C1FFFC  stfs f6, -4(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC7F94: 81660000  lwz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC7F98: 81460004  lwz r10, 4(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC7F9C: 81260008  lwz r9, 8(r6)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC7FA0: 8086000C  lwz r4, 0xc(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC7FA4: 9083000C  stw r4, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FC7FA8: 91230008  stw r9, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 82FC7FAC: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FC7FB0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC7FB4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7FB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC7FB8 size=52
    let mut pc: u32 = 0x82FC7FB8;
    'dispatch: loop {
        match pc {
            0x82FC7FB8 => {
    //   block [0x82FC7FB8..0x82FC7FEC)
	// 82FC7FB8: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC7FBC: C1A40004  lfs f13, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC7FC0: FD800210  fabs f12, f0
	ctx.f[12].u64 = ctx.f[0].u64 & !0x8000_0000_0000_0000u64;
	// 82FC7FC4: C1640008  lfs f11, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC7FC8: FD406A10  fabs f10, f13
	ctx.f[10].u64 = ctx.f[13].u64 & !0x8000_0000_0000_0000u64;
	// 82FC7FCC: C124000C  lfs f9, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC7FD0: FD005A10  fabs f8, f11
	ctx.f[8].u64 = ctx.f[11].u64 & !0x8000_0000_0000_0000u64;
	// 82FC7FD4: FCE04A10  fabs f7, f9
	ctx.f[7].u64 = ctx.f[9].u64 & !0x8000_0000_0000_0000u64;
	// 82FC7FD8: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC7FDC: D1430004  stfs f10, 4(r3)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC7FE0: D1030008  stfs f8, 8(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC7FE4: D0E3000C  stfs f7, 0xc(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC7FE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC7FF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC7FF0 size=156
    let mut pc: u32 = 0x82FC7FF0;
    'dispatch: loop {
        match pc {
            0x82FC7FF0 => {
    //   block [0x82FC7FF0..0x82FC808C)
	// 82FC7FF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC7FF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FC7FF8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FC7FFC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FC8000: DBA1FFD0  stfd f29, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[29].u64 ) };
	// 82FC8004: DBC1FFD8  stfd f30, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[30].u64 ) };
	// 82FC8008: DBE1FFE0  stfd f31, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 82FC800C: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC8010: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FC8014: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FC8018: C03E000C  lfs f1, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC801C: 481E3CED  bl 0x831abd08
	ctx.lr = 0x82FC8020;
	sub_831ABD08(ctx, base);
	// 82FC8020: C01E0008  lfs f0, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8024: FFE00818  frsp f31, f1
	ctx.f[31].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC8028: FC200090  fmr f1, f0
	ctx.f[1].f64 = ctx.f[0].f64;
	// 82FC802C: 481E3CDD  bl 0x831abd08
	ctx.lr = 0x82FC8030;
	sub_831ABD08(ctx, base);
	// 82FC8030: C1BE0004  lfs f13, 4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8034: FFC00818  frsp f30, f1
	ctx.f[30].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC8038: FC206890  fmr f1, f13
	ctx.f[1].f64 = ctx.f[13].f64;
	// 82FC803C: 481E3CCD  bl 0x831abd08
	ctx.lr = 0x82FC8040;
	sub_831ABD08(ctx, base);
	// 82FC8040: C19E0000  lfs f12, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8044: FFA00818  frsp f29, f1
	ctx.f[29].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC8048: FC206090  fmr f1, f12
	ctx.f[1].f64 = ctx.f[12].f64;
	// 82FC804C: 481E3CBD  bl 0x831abd08
	ctx.lr = 0x82FC8050;
	sub_831ABD08(ctx, base);
	// 82FC8050: FD600818  frsp f11, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[11].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC8054: D17F0000  stfs f11, 0(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8058: D3BF0004  stfs f29, 4(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC805C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FC8060: D3DF0008  stfs f30, 8(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8064: D3FF000C  stfs f31, 0xc(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8068: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FC806C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FC8070: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FC8074: CBA1FFD0  lfd f29, -0x30(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 82FC8078: CBC1FFD8  lfd f30, -0x28(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 82FC807C: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 82FC8080: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FC8084: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FC8088: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8090(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC8090 size=156
    let mut pc: u32 = 0x82FC8090;
    'dispatch: loop {
        match pc {
            0x82FC8090 => {
    //   block [0x82FC8090..0x82FC812C)
	// 82FC8090: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC8094: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FC8098: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FC809C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FC80A0: DBA1FFD0  stfd f29, -0x30(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[29].u64 ) };
	// 82FC80A4: DBC1FFD8  stfd f30, -0x28(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[30].u64 ) };
	// 82FC80A8: DBE1FFE0  stfd f31, -0x20(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-32 as u32), ctx.f[31].u64 ) };
	// 82FC80AC: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC80B0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FC80B4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FC80B8: C03E000C  lfs f1, 0xc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC80BC: 481E39DD  bl 0x831aba98
	ctx.lr = 0x82FC80C0;
	sub_831ABA98(ctx, base);
	// 82FC80C0: C01E0008  lfs f0, 8(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC80C4: FFE00818  frsp f31, f1
	ctx.f[31].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC80C8: FC200090  fmr f1, f0
	ctx.f[1].f64 = ctx.f[0].f64;
	// 82FC80CC: 481E39CD  bl 0x831aba98
	ctx.lr = 0x82FC80D0;
	sub_831ABA98(ctx, base);
	// 82FC80D0: C1BE0004  lfs f13, 4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC80D4: FFC00818  frsp f30, f1
	ctx.f[30].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC80D8: FC206890  fmr f1, f13
	ctx.f[1].f64 = ctx.f[13].f64;
	// 82FC80DC: 481E39BD  bl 0x831aba98
	ctx.lr = 0x82FC80E0;
	sub_831ABA98(ctx, base);
	// 82FC80E0: C19E0000  lfs f12, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC80E4: FFA00818  frsp f29, f1
	ctx.f[29].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC80E8: FC206090  fmr f1, f12
	ctx.f[1].f64 = ctx.f[12].f64;
	// 82FC80EC: 481E39AD  bl 0x831aba98
	ctx.lr = 0x82FC80F0;
	sub_831ABA98(ctx, base);
	// 82FC80F0: FD600818  frsp f11, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[11].f64 = (ctx.f[1].f64 as f32) as f64;
	// 82FC80F4: D17F0000  stfs f11, 0(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC80F8: D3BF0004  stfs f29, 4(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC80FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FC8100: D3DF0008  stfs f30, 8(r31)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8104: D3FF000C  stfs f31, 0xc(r31)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8108: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FC810C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FC8110: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FC8114: CBA1FFD0  lfd f29, -0x30(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 82FC8118: CBC1FFD8  lfd f30, -0x28(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 82FC811C: CBE1FFE0  lfd f31, -0x20(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-32 as u32) ) };
	// 82FC8120: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FC8124: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FC8128: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8130(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8130 size=12
    let mut pc: u32 = 0x82FC8130;
    'dispatch: loop {
        match pc {
            0x82FC8130 => {
    //   block [0x82FC8130..0x82FC813C)
	// 82FC8130: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8134: 7C2B1C2E  lfsx f1, r11, r3
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC8138: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8140(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC8140 size=12
    let mut pc: u32 = 0x82FC8140;
    'dispatch: loop {
        match pc {
            0x82FC8140 => {
    //   block [0x82FC8140..0x82FC814C)
	// 82FC8140: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8144: 7C6B1A14  add r3, r11, r3
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82FC8148: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8150(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8150 size=52
    let mut pc: u32 = 0x82FC8150;
    'dispatch: loop {
        match pc {
            0x82FC8150 => {
    //   block [0x82FC8150..0x82FC8184)
	// 82FC8150: C0030008  lfs f0, 8(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8154: C1A40008  lfs f13, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8158: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FC815C: C163000C  lfs f11, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8160: C144000C  lfs f10, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8164: C1230004  lfs f9, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC8168: C1040004  lfs f8, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC816C: C0E30000  lfs f7, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8170: C0C40000  lfs f6, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC8174: ECAB62BA  fmadds f5, f11, f10, f12
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FC8178: EC892A3A  fmadds f4, f9, f8, f5
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[8].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FC817C: EC2721BA  fmadds f1, f7, f6, f4
	ctx.f[1].f64 = (((ctx.f[7].f64 * ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC8180: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8188(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8188 size=72
    let mut pc: u32 = 0x82FC8188;
    'dispatch: loop {
        match pc {
            0x82FC8188 => {
    //   block [0x82FC8188..0x82FC81D0)
	// 82FC8188: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC818C: C1A40000  lfs f13, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8190: C1850000  lfs f12, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8194: FF0D6000  fcmpu cr6, f13, f12
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[12].f64);
	// 82FC8198: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC819C: D0030000  stfs f0, 0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC81A0: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC81A4: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC81A8: D003000C  stfs f0, 0xc(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC81AC: 40990008  ble cr6, 0x82fc81b4
	if !ctx.cr[6].gt {
	pc = 0x82FC81B4; continue 'dispatch;
	}
	// 82FC81B0: FD806890  fmr f12, f13
	ctx.f[12].f64 = ctx.f[13].f64;
	// 82FC81B4: C0040004  lfs f0, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC81B8: C1A50004  lfs f13, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC81BC: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC81C0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC81C4: 4099000C  ble cr6, 0x82fc81d0
	if !ctx.cr[6].gt {
		sub_82FC81D0(ctx, base);
		return;
	}
	// 82FC81C8: FD800090  fmr f12, f0
	ctx.f[12].f64 = ctx.f[0].f64;
	// 82FC81CC: 48000008  b 0x82fc81d4
	sub_82FC81D0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC81D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC81D0 size=56
    let mut pc: u32 = 0x82FC81D0;
    'dispatch: loop {
        match pc {
            0x82FC81D0 => {
    //   block [0x82FC81D0..0x82FC8208)
	// 82FC81D0: FD806890  fmr f12, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = ctx.f[13].f64;
	// 82FC81D4: C0040008  lfs f0, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC81D8: C1A50008  lfs f13, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC81DC: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC81E0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC81E4: 41990008  bgt cr6, 0x82fc81ec
	if ctx.cr[6].gt {
	pc = 0x82FC81EC; continue 'dispatch;
	}
	// 82FC81E8: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC81EC: C184000C  lfs f12, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC81F0: C165000C  lfs f11, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC81F4: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC81F8: FF0C5800  fcmpu cr6, f12, f11
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[11].f64);
	// 82FC81FC: 4099000C  ble cr6, 0x82fc8208
	if !ctx.cr[6].gt {
		sub_82FC8208(ctx, base);
		return;
	}
	// 82FC8200: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8204: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8208(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8208 size=8
    let mut pc: u32 = 0x82FC8208;
    'dispatch: loop {
        match pc {
            0x82FC8208 => {
    //   block [0x82FC8208..0x82FC8210)
	// 82FC8208: D163000C  stfs f11, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC820C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8210(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8210 size=72
    let mut pc: u32 = 0x82FC8210;
    'dispatch: loop {
        match pc {
            0x82FC8210 => {
    //   block [0x82FC8210..0x82FC8258)
	// 82FC8210: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8214: C1A40000  lfs f13, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8218: C1850000  lfs f12, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC821C: FF0D6000  fcmpu cr6, f13, f12
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[12].f64);
	// 82FC8220: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8224: D0030000  stfs f0, 0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8228: D0030004  stfs f0, 4(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC822C: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8230: D003000C  stfs f0, 0xc(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8234: 40980008  bge cr6, 0x82fc823c
	if !ctx.cr[6].lt {
	pc = 0x82FC823C; continue 'dispatch;
	}
	// 82FC8238: FD806890  fmr f12, f13
	ctx.f[12].f64 = ctx.f[13].f64;
	// 82FC823C: C0040004  lfs f0, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8240: C1A50004  lfs f13, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8244: D1830000  stfs f12, 0(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8248: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC824C: 4098000C  bge cr6, 0x82fc8258
	if !ctx.cr[6].lt {
		sub_82FC8258(ctx, base);
		return;
	}
	// 82FC8250: FD800090  fmr f12, f0
	ctx.f[12].f64 = ctx.f[0].f64;
	// 82FC8254: 48000008  b 0x82fc825c
	sub_82FC8258(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8258(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8258 size=56
    let mut pc: u32 = 0x82FC8258;
    'dispatch: loop {
        match pc {
            0x82FC8258 => {
    //   block [0x82FC8258..0x82FC8290)
	// 82FC8258: FD806890  fmr f12, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = ctx.f[13].f64;
	// 82FC825C: C0040008  lfs f0, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8260: C1A50008  lfs f13, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8264: D1830004  stfs f12, 4(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8268: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC826C: 41980008  blt cr6, 0x82fc8274
	if ctx.cr[6].lt {
	pc = 0x82FC8274; continue 'dispatch;
	}
	// 82FC8270: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC8274: C184000C  lfs f12, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8278: C165000C  lfs f11, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC827C: D0030008  stfs f0, 8(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8280: FF0C5800  fcmpu cr6, f12, f11
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[11].f64);
	// 82FC8284: 4098000C  bge cr6, 0x82fc8290
	if !ctx.cr[6].lt {
		sub_82FC8290(ctx, base);
		return;
	}
	// 82FC8288: D183000C  stfs f12, 0xc(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC828C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8290(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8290 size=8
    let mut pc: u32 = 0x82FC8290;
    'dispatch: loop {
        match pc {
            0x82FC8290 => {
    //   block [0x82FC8290..0x82FC8298)
	// 82FC8290: D163000C  stfs f11, 0xc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8294: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8298(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8298 size=24
    let mut pc: u32 = 0x82FC8298;
    'dispatch: loop {
        match pc {
            0x82FC8298 => {
    //   block [0x82FC8298..0x82FC82B0)
	// 82FC8298: 39630001  addi r11, r3, 1
	ctx.r[11].s64 = ctx.r[3].s64 + 1;
	// 82FC829C: 81060000  lwz r8, 0(r6)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC82A0: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC82A4: 7C0A442E  lfsx f0, r10, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC82A8: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC82AC: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC82B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC82B0 size=52
    let mut pc: u32 = 0x82FC82B0;
    'dispatch: loop {
        match pc {
            0x82FC82B0 => {
    //   block [0x82FC82B0..0x82FC82E4)
	// 82FC82B0: 39430001  addi r10, r3, 1
	ctx.r[10].s64 = ctx.r[3].s64 + 1;
	// 82FC82B4: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 82FC82B8: 7D6A2214  add r11, r10, r4
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 82FC82BC: 7D670E70  srawi r7, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FC82C0: 7C670194  addze r3, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[3].s64 = tmp.s64;
	// 82FC82C4: 546B103A  slwi r11, r3, 2
	ctx.r[11].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC82C8: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FC82CC: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC82D0: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC82D4: 41980010  blt cr6, 0x82fc82e4
	if ctx.cr[6].lt {
		sub_82FC82E4(ctx, base);
		return;
	}
	// 82FC82D8: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC82DC: FF016800  fcmpu cr6, f1, f13
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[13].f64);
	// 82FC82E0: 4D980020  bltlr cr6
	if ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC82E4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC82E4 size=20
    let mut pc: u32 = 0x82FC82E4;
    'dispatch: loop {
        match pc {
            0x82FC82E4 => {
    //   block [0x82FC82E4..0x82FC82F8)
	// 82FC82E4: FF010000  fcmpu cr6, f1, f0
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC82E8: 40980010  bge cr6, 0x82fc82f8
	if !ctx.cr[6].lt {
		sub_82FC82F8(ctx, base);
		return;
	}
	// 82FC82EC: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FC82F0: 7D6A4A14  add r11, r10, r9
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FC82F4: 4BFFFFC8  b 0x82fc82bc
	sub_82FC82B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC82F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC82F8 size=12
    let mut pc: u32 = 0x82FC82F8;
    'dispatch: loop {
        match pc {
            0x82FC82F8 => {
    //   block [0x82FC82F8..0x82FC8304)
	// 82FC82F8: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FC82FC: 7D6A4A14  add r11, r10, r9
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FC8300: 4BFFFFBC  b 0x82fc82bc
	sub_82FC82B0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8304(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC8304 size=4
    let mut pc: u32 = 0x82FC8304;
    'dispatch: loop {
        match pc {
            0x82FC8304 => {
    //   block [0x82FC8304..0x82FC8308)
	// 82FC8304: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8308(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8308 size=460
    let mut pc: u32 = 0x82FC8308;
    'dispatch: loop {
        match pc {
            0x82FC8308 => {
    //   block [0x82FC8308..0x82FC84D4)
	// 82FC8308: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC830C: 481DFE55  bl 0x831a8160
	ctx.lr = 0x82FC8310;
	sub_831A8130(ctx, base);
	// 82FC8310: 3981FFC8  addi r12, r1, -0x38
	ctx.r[12].s64 = ctx.r[1].s64 + -56;
	// 82FC8314: 481E0761  bl 0x831a8a74
	ctx.lr = 0x82FC8318;
	sub_831A8A40(ctx, base);
	// 82FC8318: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC831C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82FC8320: 2F050001  cmpwi cr6, r5, 1
	ctx.cr[6].compare_i32(ctx.r[5].s32, 1, &mut ctx.xer);
	// 82FC8324: C00B08A8  lfs f0, 0x8a8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8328: D0070000  stfs f0, 0(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC832C: 4198019C  blt cr6, 0x82fc84c8
	if ctx.cr[6].lt {
	pc = 0x82FC84C8; continue 'dispatch;
	}
	// 82FC8330: 81660000  lwz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8334: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8338: 3B470004  addi r26, r7, 4
	ctx.r[26].s64 = ctx.r[7].s64 + 4;
	// 82FC833C: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FC8340: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82FC8344: 3B6B0004  addi r27, r11, 4
	ctx.r[27].s64 = ctx.r[11].s64 + 4;
	// 82FC8348: 7D7C5B78  mr r28, r11
	ctx.r[28].u64 = ctx.r[11].u64;
	// 82FC834C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8350: C1AB08A4  lfs f13, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8354: 3961FF94  addi r11, r1, -0x6c
	ctx.r[11].s64 = ctx.r[1].s64 + -108;
	// 82FC8358: C01C0000  lfs f0, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC835C: 3921FF84  addi r9, r1, -0x7c
	ctx.r[9].s64 = ctx.r[1].s64 + -124;
	// 82FC8360: C19B0000  lfs f12, 0(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8364: ED610028  fsubs f11, f1, f0
	ctx.f[11].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8368: 7D5D5A14  add r10, r29, r11
	ctx.r[10].u64 = ctx.r[29].u64 + ctx.r[11].u64;
	// 82FC836C: ED4C0828  fsubs f10, f12, f1
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8370: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82FC8374: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC8378: 2F040004  cmpwi cr6, r4, 4
	ctx.cr[6].compare_i32(ctx.r[4].s32, 4, &mut ctx.xer);
	// 82FC837C: 7D7D5D2E  stfsx f11, r29, r11
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FC8380: 7D5D4D2E  stfsx f10, r29, r9
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FC8384: 419800CC  blt cr6, 0x82fc8450
	if ctx.cr[6].lt {
	pc = 0x82FC8450; continue 'dispatch;
	}
	// 82FC8388: 3964FFFC  addi r11, r4, -4
	ctx.r[11].s64 = ctx.r[4].s64 + -4;
	// 82FC838C: 38C1FF80  addi r6, r1, -0x80
	ctx.r[6].s64 = ctx.r[1].s64 + -128;
	// 82FC8390: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8394: 3BE1FF84  addi r31, r1, -0x7c
	ctx.r[31].s64 = ctx.r[1].s64 + -124;
	// 82FC8398: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FC839C: 3BC1FF88  addi r30, r1, -0x78
	ctx.r[30].s64 = ctx.r[1].s64 + -120;
	// 82FC83A0: 7C673050  subf r3, r7, r6
	ctx.r[3].s64 = ctx.r[6].s64 - ctx.r[7].s64;
	// 82FC83A4: 3901FF84  addi r8, r1, -0x7c
	ctx.r[8].s64 = ctx.r[1].s64 + -124;
	// 82FC83A8: 39670008  addi r11, r7, 8
	ctx.r[11].s64 = ctx.r[7].s64 + 8;
	// 82FC83AC: 394AFFF8  addi r10, r10, -8
	ctx.r[10].s64 = ctx.r[10].s64 + -8;
	// 82FC83B0: 7FE7F850  subf r31, r7, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[7].s64;
	// 82FC83B4: 7FC7F050  subf r30, r7, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[7].s64;
	// 82FC83B8: 5526103A  slwi r6, r9, 2
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FC83BC: C18A0008  lfs f12, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC83C0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC83C4: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC83C8: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FC83CC: C14A0004  lfs f10, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC83D0: ED2B602A  fadds f9, f11, f12
	ctx.f[9].f64 = ((ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC83D4: 7D035C2E  lfsx f8, r3, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC83D8: C0EA0000  lfs f7, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC83DC: ECC8502A  fadds f6, f8, f10
	ctx.f[6].f64 = ((ctx.f[8].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FC83E0: 7CBF5C2E  lfsx f5, r31, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC83E4: EC85382A  fadds f4, f5, f7
	ctx.f[4].f64 = ((ctx.f[5].f64 + ctx.f[7].f64) as f32) as f64;
	// 82FC83E8: C06BFFF8  lfs f3, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC83EC: C04BFFFC  lfs f2, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC83F0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FC83F4: C3CAFFFC  lfs f30, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FC83F8: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FC83FC: 7FBE5C2E  lfsx f29, r30, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FC8400: EF9DF02A  fadds f28, f29, f30
	ctx.f[28].f64 = ((ctx.f[29].f64 + ctx.f[30].f64) as f32) as f64;
	// 82FC8404: C36B0004  lfs f27, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 82FC8408: ED234824  fdivs f9, f3, f9
	ctx.f[9].f64 = ((ctx.f[3].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC840C: ECC23024  fdivs f6, f2, f6
	ctx.f[6].f64 = ((ctx.f[2].f64 / ctx.f[6].f64) as f32) as f64;
	// 82FC8410: EC9F2024  fdivs f4, f31, f4
	ctx.f[4].f64 = ((ctx.f[31].f64 / ctx.f[4].f64) as f32) as f64;
	// 82FC8414: EC7BE024  fdivs f3, f27, f28
	ctx.f[3].f64 = ((ctx.f[27].f64 / ctx.f[28].f64) as f32) as f64;
	// 82FC8418: EC0B027A  fmadds f0, f11, f9, f0
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC841C: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC8420: EC4C0272  fmuls f2, f12, f9
	ctx.f[2].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FC8424: ED8A01B2  fmuls f12, f10, f6
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8428: ED670132  fmuls f11, f7, f4
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FC842C: EC1E00F2  fmuls f0, f30, f3
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FC8430: ED4811BA  fmadds f10, f8, f6, f2
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[2].f64) as f32) as f64);
	// 82FC8434: D14BFFFC  stfs f10, -4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8438: ED25613A  fmadds f9, f5, f4, f12
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[4].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FC843C: D12B0000  stfs f9, 0(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8440: ED1D58FA  fmadds f8, f29, f3, f11
	ctx.f[8].f64 = (((ctx.f[29].f64 * ctx.f[3].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC8444: D10B0004  stfs f8, 4(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8448: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC844C: 4082FF70  bne 0x82fc83bc
	if !ctx.cr[0].eq {
	pc = 0x82FC83BC; continue 'dispatch;
	}
	// 82FC8450: 7F062000  cmpw cr6, r6, r4
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC8454: 40980054  bge cr6, 0x82fc84a8
	if !ctx.cr[6].lt {
	pc = 0x82FC84A8; continue 'dispatch;
	}
	// 82FC8458: 7D462050  subf r10, r6, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[6].s64;
	// 82FC845C: 54CB103A  slwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8460: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC8464: 3921FF90  addi r9, r1, -0x70
	ctx.r[9].s64 = ctx.r[1].s64 + -112;
	// 82FC8468: 38C1FF84  addi r6, r1, -0x7c
	ctx.r[6].s64 = ctx.r[1].s64 + -124;
	// 82FC846C: 7D284A14  add r9, r8, r9
	ctx.r[9].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 82FC8470: 7D6B3A14  add r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82FC8474: 7D073050  subf r8, r7, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[7].s64;
	// 82FC8478: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC847C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC8480: 7D6B442E  lfsx f11, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8484: 3929FFFC  addi r9, r9, -4
	ctx.r[9].s64 = ctx.r[9].s64 + -4;
	// 82FC8488: ED4B602A  fadds f10, f11, f12
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC848C: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC8490: ED095024  fdivs f8, f9, f10
	ctx.f[8].f64 = ((ctx.f[9].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FC8494: ECEB023A  fmadds f7, f11, f8, f0
	ctx.f[7].f64 = (((ctx.f[11].f64 * ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8498: D0EB0000  stfs f7, 0(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC849C: EC0C0232  fmuls f0, f12, f8
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FC84A0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC84A4: 4082FFD4  bne 0x82fc8478
	if !ctx.cr[0].eq {
	pc = 0x82FC8478; continue 'dispatch;
	}
	// 82FC84A8: 38840001  addi r4, r4, 1
	ctx.r[4].s64 = ctx.r[4].s64 + 1;
	// 82FC84AC: D01A0000  stfs f0, 0(r26)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC84B0: 3B9CFFFC  addi r28, r28, -4
	ctx.r[28].s64 = ctx.r[28].s64 + -4;
	// 82FC84B4: 3B7B0004  addi r27, r27, 4
	ctx.r[27].s64 = ctx.r[27].s64 + 4;
	// 82FC84B8: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 82FC84BC: 3B5A0004  addi r26, r26, 4
	ctx.r[26].s64 = ctx.r[26].s64 + 4;
	// 82FC84C0: 7F042800  cmpw cr6, r4, r5
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FC84C4: 4099FE90  ble cr6, 0x82fc8354
	if !ctx.cr[6].gt {
	pc = 0x82FC8354; continue 'dispatch;
	}
	// 82FC84C8: 3981FFC8  addi r12, r1, -0x38
	ctx.r[12].s64 = ctx.r[1].s64 + -56;
	// 82FC84CC: 481E05F5  bl 0x831a8ac0
	ctx.lr = 0x82FC84D0;
	sub_831A8A8C(ctx, base);
	// 82FC84D0: 481DFCE0  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC84D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC84D8 size=1840
    let mut pc: u32 = 0x82FC84D8;
    'dispatch: loop {
        match pc {
            0x82FC84D8 => {
    //   block [0x82FC84D8..0x82FC8C08)
	// 82FC84D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC84DC: 481DFC55  bl 0x831a8130
	ctx.lr = 0x82FC84E0;
	sub_831A8130(ctx, base);
	// 82FC84E0: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 82FC84E4: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 82FC84E8: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 82FC84EC: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC84F0: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82FC84F4: 7CB62B78  mr r22, r5
	ctx.r[22].u64 = ctx.r[5].u64;
	// 82FC84F8: 7CD53378  mr r21, r6
	ctx.r[21].u64 = ctx.r[6].u64;
	// 82FC84FC: 7D134378  mr r19, r8
	ctx.r[19].u64 = ctx.r[8].u64;
	// 82FC8500: 92C10024  stw r22, 0x24(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(36 as u32), ctx.r[22].u32 ) };
	// 82FC8504: C16B08A8  lfs f11, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8508: 92A1002C  stw r21, 0x2c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(44 as u32), ctx.r[21].u32 ) };
	// 82FC850C: C18A08A4  lfs f12, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8510: 9261003C  stw r19, 0x3c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(60 as u32), ctx.r[19].u32 ) };
	// 82FC8514: D161FF10  stfs f11, -0xf0(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-240 as u32), tmp.u32 ) };
	// 82FC8518: 3BE00001  li r31, 1
	ctx.r[31].s64 = 1;
	// 82FC851C: 2F160001  cmpwi cr6, r22, 1
	ctx.cr[6].compare_i32(ctx.r[22].s32, 1, &mut ctx.xer);
	// 82FC8520: 419801C8  blt cr6, 0x82fc86e8
	if ctx.cr[6].lt {
	pc = 0x82FC86E8; continue 'dispatch;
	}
	// 82FC8524: 81670000  lwz r11, 0(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8528: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC852C: 3AE1FF24  addi r23, r1, -0xdc
	ctx.r[23].s64 = ctx.r[1].s64 + -220;
	// 82FC8530: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FC8534: 3B41FF24  addi r26, r1, -0xdc
	ctx.r[26].s64 = ctx.r[1].s64 + -220;
	// 82FC8538: 3B0B0004  addi r24, r11, 4
	ctx.r[24].s64 = ctx.r[11].s64 + 4;
	// 82FC853C: 7D795B78  mr r25, r11
	ctx.r[25].u64 = ctx.r[11].u64;
	// 82FC8540: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FC8544: 3961FED4  addi r11, r1, -0x12c
	ctx.r[11].s64 = ctx.r[1].s64 + -300;
	// 82FC8548: C0190000  lfs f0, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC854C: 3941FEE4  addi r10, r1, -0x11c
	ctx.r[10].s64 = ctx.r[1].s64 + -284;
	// 82FC8550: C1B80000  lfs f13, 0(r24)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8554: ED410028  fsubs f10, f1, f0
	ctx.f[10].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8558: 7D3E5A14  add r9, r30, r11
	ctx.r[9].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FC855C: ED2D0828  fsubs f9, f13, f1
	ctx.f[9].f64 = (((ctx.f[13].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8560: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FC8564: FC006090  fmr f0, f12
	ctx.f[0].f64 = ctx.f[12].f64;
	// 82FC8568: 2F1F0004  cmpwi cr6, r31, 4
	ctx.cr[6].compare_i32(ctx.r[31].s32, 4, &mut ctx.xer);
	// 82FC856C: 7D5E5D2E  stfsx f10, r30, r11
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FC8570: 7D3E552E  stfsx f9, r30, r10
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[30].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FC8574: 419800D0  blt cr6, 0x82fc8644
	if ctx.cr[6].lt {
	pc = 0x82FC8644; continue 'dispatch;
	}
	// 82FC8578: 397FFFFC  addi r11, r31, -4
	ctx.r[11].s64 = ctx.r[31].s64 + -4;
	// 82FC857C: 3881FF14  addi r4, r1, -0xec
	ctx.r[4].s64 = ctx.r[1].s64 + -236;
	// 82FC8580: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8584: 3941FEE8  addi r10, r1, -0x118
	ctx.r[10].s64 = ctx.r[1].s64 + -280;
	// 82FC8588: 386B0001  addi r3, r11, 1
	ctx.r[3].s64 = ctx.r[11].s64 + 1;
	// 82FC858C: 7D7E2214  add r11, r30, r4
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[4].u64;
	// 82FC8590: 7F47D378  mr r7, r26
	ctx.r[7].u64 = ctx.r[26].u64;
	// 82FC8594: 3929FFF8  addi r9, r9, -8
	ctx.r[9].s64 = ctx.r[9].s64 + -8;
	// 82FC8598: 5464103A  slwi r4, r3, 2
	ctx.r[4].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FC859C: C1A90008  lfs f13, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC85A0: 3463FFFF  addic. r3, r3, -1
	ctx.xer.ca = (ctx.r[3].u32 > (!(-1 as u32)));
	ctx.r[3].s64 = ctx.r[3].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82FC85A4: C14AFFFC  lfs f10, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC85A8: ED2A682A  fadds f9, f10, f13
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC85AC: D127FFFC  stfs f9, -4(r7)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC85B0: C10BFFFC  lfs f8, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC85B4: C0E90004  lfs f7, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC85B8: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC85BC: ECA6382A  fadds f5, f6, f7
	ctx.f[5].f64 = ((ctx.f[6].f64 + ctx.f[7].f64) as f32) as f64;
	// 82FC85C0: C06A0004  lfs f3, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC85C4: C0890000  lfs f4, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC85C8: EC43202A  fadds f2, f3, f4
	ctx.f[2].f64 = ((ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64;
	// 82FC85CC: C3E9FFFC  lfs f31, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FC85D0: C3CA0008  lfs f30, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FC85D4: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC85D8: EFBEF82A  fadds f29, f30, f31
	ctx.f[29].f64 = ((ctx.f[30].f64 + ctx.f[31].f64) as f32) as f64;
	// 82FC85DC: 3929FFF0  addi r9, r9, -0x10
	ctx.r[9].s64 = ctx.r[9].s64 + -16;
	// 82FC85E0: ED284824  fdivs f9, f8, f9
	ctx.f[9].f64 = ((ctx.f[8].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC85E4: ED0A027A  fmadds f8, f10, f9, f0
	ctx.f[8].f64 = (((ctx.f[10].f64 * ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC85E8: D10B0000  stfs f8, 0(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC85EC: D0A70000  stfs f5, 0(r7)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC85F0: EC0D0272  fmuls f0, f13, f9
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FC85F4: C1AB000C  lfs f13, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC85F8: ED4D2824  fdivs f10, f13, f5
	ctx.f[10].f64 = ((ctx.f[13].f64 / ctx.f[5].f64) as f32) as f64;
	// 82FC85FC: ED2602BA  fmadds f9, f6, f10, f0
	ctx.f[9].f64 = (((ctx.f[6].f64 * ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8600: D12B0010  stfs f9, 0x10(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FC8604: D0470004  stfs f2, 4(r7)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8608: ED0702B2  fmuls f8, f7, f10
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FC860C: C0EB001C  lfs f7, 0x1c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8610: ECC71024  fdivs f6, f7, f2
	ctx.f[6].f64 = ((ctx.f[7].f64 / ctx.f[2].f64) as f32) as f64;
	// 82FC8614: ECA341BA  fmadds f5, f3, f6, f8
	ctx.f[5].f64 = (((ctx.f[3].f64 * ctx.f[6].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC8618: D0AB0020  stfs f5, 0x20(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82FC861C: D3A70008  stfs f29, 8(r7)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8620: EC8401B2  fmuls f4, f4, f6
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8624: C06B002C  lfs f3, 0x2c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC8628: EC43E824  fdivs f2, f3, f29
	ctx.f[2].f64 = ((ctx.f[3].f64 / ctx.f[29].f64) as f32) as f64;
	// 82FC862C: EC1E20BA  fmadds f0, f30, f2, f4
	ctx.f[0].f64 = (((ctx.f[30].f64 * ctx.f[2].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC8630: D00B0030  stfs f0, 0x30(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 82FC8634: EC1F00B2  fmuls f0, f31, f2
	ctx.f[0].f64 = (((ctx.f[31].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FC8638: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FC863C: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 82FC8640: 4082FF5C  bne 0x82fc859c
	if !ctx.cr[0].eq {
	pc = 0x82FC859C; continue 'dispatch;
	}
	// 82FC8644: 7F04F800  cmpw cr6, r4, r31
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FC8648: 4098007C  bge cr6, 0x82fc86c4
	if !ctx.cr[6].lt {
	pc = 0x82FC86C4; continue 'dispatch;
	}
	// 82FC864C: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8650: 7D3E2214  add r9, r30, r4
	ctx.r[9].u64 = ctx.r[30].u64 + ctx.r[4].u64;
	// 82FC8654: 7D44F850  subf r10, r4, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 82FC8658: 7D0BFA14  add r8, r11, r31
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FC865C: 5524103A  slwi r4, r9, 2
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FC8660: 3921FEE4  addi r9, r1, -0x11c
	ctx.r[9].s64 = ctx.r[1].s64 + -284;
	// 82FC8664: 38E1FF20  addi r7, r1, -0xe0
	ctx.r[7].s64 = ctx.r[1].s64 + -224;
	// 82FC8668: 555D103A  slwi r29, r10, 2
	ctx.r[29].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 82FC866C: 3861FED0  addi r3, r1, -0x130
	ctx.r[3].s64 = ctx.r[1].s64 + -304;
	// 82FC8670: 551B103A  slwi r27, r8, 2
	ctx.r[27].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 82FC8674: 3B81FF10  addi r28, r1, -0xf0
	ctx.r[28].s64 = ctx.r[1].s64 + -240;
	// 82FC8678: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FC867C: 7CE43A14  add r7, r4, r7
	ctx.r[7].u64 = ctx.r[4].u64 + ctx.r[7].u64;
	// 82FC8680: 7C9D1A14  add r4, r29, r3
	ctx.r[4].u64 = ctx.r[29].u64 + ctx.r[3].u64;
	// 82FC8684: 7D7BE214  add r11, r27, r28
	ctx.r[11].u64 = ctx.r[27].u64 + ctx.r[28].u64;
	// 82FC8688: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC868C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC8690: C1490000  lfs f10, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8694: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FC8698: ED2D502A  fadds f9, f13, f10
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FC869C: D1270000  stfs f9, 0(r7)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC86A0: C10BFFFC  lfs f8, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC86A4: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 82FC86A8: 3884FFFC  addi r4, r4, -4
	ctx.r[4].s64 = ctx.r[4].s64 + -4;
	// 82FC86AC: ECE84824  fdivs f7, f8, f9
	ctx.f[7].f64 = ((ctx.f[8].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC86B0: ECCA01FA  fmadds f6, f10, f7, f0
	ctx.f[6].f64 = (((ctx.f[10].f64 * ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC86B4: D0CB0000  stfs f6, 0(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC86B8: EC0D01F2  fmuls f0, f13, f7
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC86BC: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC86C0: 4082FFC8  bne 0x82fc8688
	if !ctx.cr[0].eq {
	pc = 0x82FC8688; continue 'dispatch;
	}
	// 82FC86C4: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FC86C8: D0170000  stfs f0, 0(r23)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC86CC: 3B39FFFC  addi r25, r25, -4
	ctx.r[25].s64 = ctx.r[25].s64 + -4;
	// 82FC86D0: 3B5A0010  addi r26, r26, 0x10
	ctx.r[26].s64 = ctx.r[26].s64 + 16;
	// 82FC86D4: 3B180004  addi r24, r24, 4
	ctx.r[24].s64 = ctx.r[24].s64 + 4;
	// 82FC86D8: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FC86DC: 3AF70014  addi r23, r23, 0x14
	ctx.r[23].s64 = ctx.r[23].s64 + 20;
	// 82FC86E0: 7F1FB000  cmpw cr6, r31, r22
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FC86E4: 4099FE60  ble cr6, 0x82fc8544
	if !ctx.cr[6].gt {
	pc = 0x82FC8544; continue 'dispatch;
	}
	// 82FC86E8: 39760001  addi r11, r22, 1
	ctx.r[11].s64 = ctx.r[22].s64 + 1;
	// 82FC86EC: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FC86F0: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FC86F4: 41980050  blt cr6, 0x82fc8744
	if ctx.cr[6].lt {
	pc = 0x82FC8744; continue 'dispatch;
	}
	// 82FC86F8: 39560001  addi r10, r22, 1
	ctx.r[10].s64 = ctx.r[22].s64 + 1;
	// 82FC86FC: 56C7103A  slwi r7, r22, 2
	ctx.r[7].u32 = ctx.r[22].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC8700: 3961FF20  addi r11, r1, -0xe0
	ctx.r[11].s64 = ctx.r[1].s64 + -224;
	// 82FC8704: 5549F0BE  srwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC8708: 7D675A14  add r11, r7, r11
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 82FC870C: 39530008  addi r10, r19, 8
	ctx.r[10].s64 = ctx.r[19].s64 + 8;
	// 82FC8710: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC8714: C00BFFF0  lfs f0, -0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8718: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC871C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8720: C14B0010  lfs f10, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8724: C12B0020  lfs f9, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC8728: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FC872C: D00AFFF8  stfs f0, -8(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC8730: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8734: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8738: D12A0004  stfs f9, 4(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC873C: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC8740: 4082FFD4  bne 0x82fc8714
	if !ctx.cr[0].eq {
	pc = 0x82FC8714; continue 'dispatch;
	}
	// 82FC8744: 7F07B000  cmpw cr6, r7, r22
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FC8748: 4199003C  bgt cr6, 0x82fc8784
	if ctx.cr[6].gt {
	pc = 0x82FC8784; continue 'dispatch;
	}
	// 82FC874C: 54EB103A  slwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8750: 7C87B050  subf r4, r7, r22
	ctx.r[4].s64 = ctx.r[22].s64 - ctx.r[7].s64;
	// 82FC8754: 7D2BB214  add r9, r11, r22
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 82FC8758: 3941FF10  addi r10, r1, -0xf0
	ctx.r[10].s64 = ctx.r[1].s64 + -240;
	// 82FC875C: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC8760: 7D2B9A14  add r9, r11, r19
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[19].u64;
	// 82FC8764: 7D475214  add r10, r7, r10
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[10].u64;
	// 82FC8768: 39640001  addi r11, r4, 1
	ctx.r[11].s64 = ctx.r[4].s64 + 1;
	// 82FC876C: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8770: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FC8774: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8778: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC877C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FC8780: 4082FFEC  bne 0x82fc876c
	if !ctx.cr[0].eq {
	pc = 0x82FC876C; continue 'dispatch;
	}
	// 82FC8784: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 82FC8788: 2F160000  cmpwi cr6, r22, 0
	ctx.cr[6].compare_i32(ctx.r[22].s32, 0, &mut ctx.xer);
	// 82FC878C: 9301FEC4  stw r24, -0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-316 as u32), ctx.r[24].u32 ) };
	// 82FC8790: 4198037C  blt cr6, 0x82fc8b0c
	if ctx.cr[6].lt {
	pc = 0x82FC8B0C; continue 'dispatch;
	}
	// 82FC8794: 39730010  addi r11, r19, 0x10
	ctx.r[11].s64 = ctx.r[19].s64 + 16;
	// 82FC8798: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FC879C: 9161FED0  stw r11, -0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-304 as u32), ctx.r[11].u32 ) };
	// 82FC87A0: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 82FC87A4: 21560001  subfic r10, r22, 1
	ctx.xer.ca = ctx.r[22].u32 <= 1 as u32;
	ctx.r[10].s64 = (1 as i64) - ctx.r[22].s64;
	// 82FC87A8: 9081FEC0  stw r4, -0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-320 as u32), ctx.r[4].u32 ) };
	// 82FC87AC: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82FC87B0: 9141FEE0  stw r10, -0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-288 as u32), ctx.r[10].u32 ) };
	// 82FC87B4: C1AB9534  lfs f13, -0x6acc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27340 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC87B8: 4800000C  b 0x82fc87c4
	pc = 0x82FC87C4; continue 'dispatch;
	// 82FC87BC: 8301FEC4  lwz r24, -0x13c(r1)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-316 as u32) ) } as u64;
	// 82FC87C0: 8081FEC0  lwz r4, -0x140(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-320 as u32) ) } as u64;
	// 82FC87C4: D161FEF0  stfs f11, -0x110(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-272 as u32), tmp.u32 ) };
	// 82FC87C8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FC87CC: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 82FC87D0: 3A800001  li r20, 1
	ctx.r[20].s64 = 1;
	// 82FC87D4: 2F150001  cmpwi cr6, r21, 1
	ctx.cr[6].compare_i32(ctx.r[21].s32, 1, &mut ctx.xer);
	// 82FC87D8: 4198030C  blt cr6, 0x82fc8ae4
	if ctx.cr[6].lt {
	pc = 0x82FC8AE4; continue 'dispatch;
	}
	// 82FC87DC: 8121FEE0  lwz r9, -0x120(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-288 as u32) ) } as u64;
	// 82FC87E0: 56CA2036  slwi r10, r22, 4
	ctx.r[10].u32 = ctx.r[22].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC87E4: 56CB103A  slwi r11, r22, 2
	ctx.r[11].u32 = ctx.r[22].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC87E8: 8241FED0  lwz r18, -0x130(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-304 as u32) ) } as u64;
	// 82FC87EC: 38F8FFFF  addi r7, r24, -1
	ctx.r[7].s64 = ctx.r[24].s64 + -1;
	// 82FC87F0: 3BA00004  li r29, 4
	ctx.r[29].s64 = 4;
	// 82FC87F4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FC87F8: 3A000010  li r16, 0x10
	ctx.r[16].s64 = 16;
	// 82FC87FC: 3A200000  li r17, 0
	ctx.r[17].s64 = 0;
	// 82FC8800: 3ACBFFFC  addi r22, r11, -4
	ctx.r[22].s64 = ctx.r[11].s64 + -4;
	// 82FC8804: 7DC92214  add r14, r9, r4
	ctx.r[14].u64 = ctx.r[9].u64 + ctx.r[4].u64;
	// 82FC8808: 39E5FFFC  addi r15, r5, -4
	ctx.r[15].s64 = ctx.r[5].s64 + -4;
	// 82FC880C: 3A6AFFF0  addi r19, r10, -0x10
	ctx.r[19].s64 = ctx.r[10].s64 + -16;
	// 82FC8810: 7EA43A14  add r21, r4, r7
	ctx.r[21].u64 = ctx.r[4].u64 + ctx.r[7].u64;
	// 82FC8814: FC006090  fmr f0, f12
	ctx.f[0].f64 = ctx.f[12].f64;
	// 82FC8818: 7F18A000  cmpw cr6, r24, r20
	ctx.cr[6].compare_i32(ctx.r[24].s32, ctx.r[20].s32, &mut ctx.xer);
	// 82FC881C: 4198003C  blt cr6, 0x82fc8858
	if ctx.cr[6].lt {
	pc = 0x82FC8858; continue 'dispatch;
	}
	// 82FC8820: 7D763A14  add r11, r22, r7
	ctx.r[11].u64 = ctx.r[22].u64 + ctx.r[7].u64;
	// 82FC8824: 3941FEF0  addi r10, r1, -0x110
	ctx.r[10].s64 = ctx.r[1].s64 + -272;
	// 82FC8828: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC882C: 3861FF20  addi r3, r1, -0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + -224;
	// 82FC8830: 7D6FAA14  add r11, r15, r21
	ctx.r[11].u64 = ctx.r[15].u64 + ctx.r[21].u64;
	// 82FC8834: 3BE1FF10  addi r31, r1, -0xf0
	ctx.r[31].s64 = ctx.r[1].s64 + -240;
	// 82FC8838: 7C11542E  lfsx f0, r17, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[17].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC883C: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8840: 3961FEF0  addi r11, r1, -0x110
	ctx.r[11].s64 = ctx.r[1].s64 + -272;
	// 82FC8844: 7D491C2E  lfsx f10, r9, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8848: ED205024  fdivs f9, f0, f10
	ctx.f[9].f64 = ((ctx.f[0].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FC884C: 7D0AFC2E  lfsx f8, r10, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC8850: 7D305D2E  stfsx f9, r16, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[16].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FC8854: EC080272  fmuls f0, f8, f9
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FC8858: 2F07FFFF  cmpwi cr6, r7, -1
	ctx.cr[6].compare_i32(ctx.r[7].s32, -1, &mut ctx.xer);
	// 82FC885C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FC8860: 40980008  bge cr6, 0x82fc8868
	if !ctx.cr[6].lt {
	pc = 0x82FC8868; continue 'dispatch;
	}
	// 82FC8864: 7DCB7378  mr r11, r14
	ctx.r[11].u64 = ctx.r[14].u64;
	// 82FC8868: 3958FFFF  addi r10, r24, -1
	ctx.r[10].s64 = ctx.r[24].s64 + -1;
	// 82FC886C: 3AF4FFFF  addi r23, r20, -1
	ctx.r[23].s64 = ctx.r[20].s64 + -1;
	// 82FC8870: 7F0AA800  cmpw cr6, r10, r21
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[21].s32, &mut ctx.xer);
	// 82FC8874: 40990008  ble cr6, 0x82fc887c
	if !ctx.cr[6].gt {
	pc = 0x82FC887C; continue 'dispatch;
	}
	// 82FC8878: 7C972378  mr r23, r4
	ctx.r[23].u64 = ctx.r[4].u64;
	// 82FC887C: 7D4BB850  subf r10, r11, r23
	ctx.r[10].s64 = ctx.r[23].s64 - ctx.r[11].s64;
	// 82FC8880: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC8884: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FC8888: 41980114  blt cr6, 0x82fc899c
	if ctx.cr[6].lt {
	pc = 0x82FC899C; continue 'dispatch;
	}
	// 82FC888C: 7D4BB850  subf r10, r11, r23
	ctx.r[10].s64 = ctx.r[23].s64 - ctx.r[11].s64;
	// 82FC8890: 7D275A14  add r9, r7, r11
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 82FC8894: 388AFFFD  addi r4, r10, -3
	ctx.r[4].s64 = ctx.r[10].s64 + -3;
	// 82FC8898: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC889C: 7D563A14  add r10, r22, r7
	ctx.r[10].u64 = ctx.r[22].u64 + ctx.r[7].u64;
	// 82FC88A0: 5484F0BE  srwi r4, r4, 2
	ctx.r[4].u32 = ctx.r[4].u32.wrapping_shr(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FC88A4: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FC88A8: 7F49AA14  add r26, r9, r21
	ctx.r[26].u64 = ctx.r[9].u64 + ctx.r[21].u64;
	// 82FC88AC: 7F9D5A14  add r28, r29, r11
	ctx.r[28].u64 = ctx.r[29].u64 + ctx.r[11].u64;
	// 82FC88B0: 3BE40001  addi r31, r4, 1
	ctx.r[31].s64 = ctx.r[4].s64 + 1;
	// 82FC88B4: 7F7E5A14  add r27, r30, r11
	ctx.r[27].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FC88B8: 3941FEF4  addi r10, r1, -0x10c
	ctx.r[10].s64 = ctx.r[1].s64 + -268;
	// 82FC88BC: 5463103A  slwi r3, r3, 2
	ctx.r[3].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FC88C0: 5789103A  slwi r9, r28, 2
	ctx.r[9].u32 = ctx.r[28].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC88C4: 5759103A  slwi r25, r26, 2
	ctx.r[25].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[25].u64 = ctx.r[25].u32 as u64;
	// 82FC88C8: 3881FF24  addi r4, r1, -0xdc
	ctx.r[4].s64 = ctx.r[1].s64 + -220;
	// 82FC88CC: 577B103A  slwi r27, r27, 2
	ctx.r[27].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 82FC88D0: 3B81FEF0  addi r28, r1, -0x110
	ctx.r[28].s64 = ctx.r[1].s64 + -272;
	// 82FC88D4: 3B41FF20  addi r26, r1, -0xe0
	ctx.r[26].s64 = ctx.r[1].s64 + -224;
	// 82FC88D8: 57F8103A  slwi r24, r31, 2
	ctx.r[24].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 82FC88DC: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FC88E0: 7C832214  add r4, r3, r4
	ctx.r[4].u64 = ctx.r[3].u64 + ctx.r[4].u64;
	// 82FC88E4: 7D5BE214  add r10, r27, r28
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[28].u64;
	// 82FC88E8: 7C79D214  add r3, r25, r26
	ctx.r[3].u64 = ctx.r[25].u64 + ctx.r[26].u64;
	// 82FC88EC: 7D785A14  add r11, r24, r11
	ctx.r[11].u64 = ctx.r[24].u64 + ctx.r[11].u64;
	// 82FC88F0: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC88F4: 37FFFFFF  addic. r31, r31, -1
	ctx.xer.ca = (ctx.r[31].u32 > (!(-1 as u32)));
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FC88F8: C12AFFFC  lfs f9, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC88FC: ED0A4828  fsubs f8, f10, f9
	ctx.f[8].f64 = (((ctx.f[10].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FC8900: C0E4FFFC  lfs f7, -4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8904: C0C40000  lfs f6, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC8908: C083FFF0  lfs f4, -0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-16 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC890C: C0A40004  lfs f5, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC8910: C0630000  lfs f3, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC8914: C0440008  lfs f2, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC8918: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 82FC891C: C0230010  lfs f1, 0x10(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC8920: C1430020  lfs f10, 0x20(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8924: 38630040  addi r3, r3, 0x40
	ctx.r[3].s64 = ctx.r[3].s64 + 64;
	// 82FC8928: ED283824  fdivs f9, f8, f7
	ctx.f[9].f64 = ((ctx.f[8].f64 / ctx.f[7].f64) as f32) as f64;
	// 82FC892C: D129FFFC  stfs f9, -4(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8930: C0EA0004  lfs f7, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8934: FD004890  fmr f8, f9
	ctx.f[8].f64 = ctx.f[9].f64;
	// 82FC8938: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC893C: ECE74828  fsubs f7, f7, f9
	ctx.f[7].f64 = (((ctx.f[7].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FC8940: ECC73024  fdivs f6, f7, f6
	ctx.f[6].f64 = ((ctx.f[7].f64 / ctx.f[6].f64) as f32) as f64;
	// 82FC8944: D0C90000  stfs f6, 0(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8948: C12A0008  lfs f9, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC894C: ED04023A  fmadds f8, f4, f8, f0
	ctx.f[8].f64 = (((ctx.f[4].f64 * ctx.f[8].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8950: C0EA0004  lfs f7, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8954: ECC93828  fsubs f6, f9, f7
	ctx.f[6].f64 = (((ctx.f[9].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FC8958: ECA62824  fdivs f5, f6, f5
	ctx.f[5].f64 = ((ctx.f[6].f64 / ctx.f[5].f64) as f32) as f64;
	// 82FC895C: C0890000  lfs f4, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC8960: D0A90004  stfs f5, 4(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8964: ED23413A  fmadds f9, f3, f4, f8
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[4].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC8968: C00A000C  lfs f0, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC896C: C10A0008  lfs f8, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC8970: ECE04028  fsubs f7, f0, f8
	ctx.f[7].f64 = (((ctx.f[0].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FC8974: FCC02890  fmr f6, f5
	ctx.f[6].f64 = ctx.f[5].f64;
	// 82FC8978: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC897C: ECA71024  fdivs f5, f7, f2
	ctx.f[5].f64 = ((ctx.f[7].f64 / ctx.f[2].f64) as f32) as f64;
	// 82FC8980: D0A90008  stfs f5, 8(r9)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8984: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FC8988: EC8149BA  fmadds f4, f1, f6, f9
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[6].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FC898C: EC0A217A  fmadds f0, f10, f5, f4
	ctx.f[0].f64 = (((ctx.f[10].f64 * ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC8990: 4082FF60  bne 0x82fc88f0
	if !ctx.cr[0].eq {
	pc = 0x82FC88F0; continue 'dispatch;
	}
	// 82FC8994: 8301FEC4  lwz r24, -0x13c(r1)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-316 as u32) ) } as u64;
	// 82FC8998: 8081FEC0  lwz r4, -0x140(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-320 as u32) ) } as u64;
	// 82FC899C: 7F0BB800  cmpw cr6, r11, r23
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[23].s32, &mut ctx.xer);
	// 82FC89A0: 41990094  bgt cr6, 0x82fc8a34
	if ctx.cr[6].gt {
	pc = 0x82FC8A34; continue 'dispatch;
	}
	// 82FC89A4: 7D275A14  add r9, r7, r11
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 82FC89A8: 7D563A14  add r10, r22, r7
	ctx.r[10].u64 = ctx.r[22].u64 + ctx.r[7].u64;
	// 82FC89AC: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC89B0: 7C7D5A14  add r3, r29, r11
	ctx.r[3].u64 = ctx.r[29].u64 + ctx.r[11].u64;
	// 82FC89B4: 7FFE5A14  add r31, r30, r11
	ctx.r[31].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FC89B8: 7C8A5A14  add r4, r10, r11
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FC89BC: 7D29AA14  add r9, r9, r21
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[21].u64;
	// 82FC89C0: 5479103A  slwi r25, r3, 2
	ctx.r[25].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[25].u64 = ctx.r[25].u32 as u64;
	// 82FC89C4: 57FC103A  slwi r28, r31, 2
	ctx.r[28].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[28].u64 = ctx.r[28].u32 as u64;
	// 82FC89C8: 7D4BB850  subf r10, r11, r23
	ctx.r[10].s64 = ctx.r[23].s64 - ctx.r[11].s64;
	// 82FC89CC: 3861FEF0  addi r3, r1, -0x110
	ctx.r[3].s64 = ctx.r[1].s64 + -272;
	// 82FC89D0: 5484103A  slwi r4, r4, 2
	ctx.r[4].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FC89D4: 3B41FF20  addi r26, r1, -0xe0
	ctx.r[26].s64 = ctx.r[1].s64 + -224;
	// 82FC89D8: 3B61FEF0  addi r27, r1, -0x110
	ctx.r[27].s64 = ctx.r[1].s64 + -272;
	// 82FC89DC: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC89E0: 3BE1FF10  addi r31, r1, -0xf0
	ctx.r[31].s64 = ctx.r[1].s64 + -240;
	// 82FC89E4: 7C791A14  add r3, r25, r3
	ctx.r[3].u64 = ctx.r[25].u64 + ctx.r[3].u64;
	// 82FC89E8: 7C84D214  add r4, r4, r26
	ctx.r[4].u64 = ctx.r[4].u64 + ctx.r[26].u64;
	// 82FC89EC: 7D7CDA14  add r11, r28, r27
	ctx.r[11].u64 = ctx.r[28].u64 + ctx.r[27].u64;
	// 82FC89F0: 7D29FA14  add r9, r9, r31
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[31].u64;
	// 82FC89F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC89F8: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC89FC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC8A00: C12BFFFC  lfs f9, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC8A04: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC8A08: ED0A4828  fsubs f8, f10, f9
	ctx.f[8].f64 = (((ctx.f[10].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FC8A0C: C0E40000  lfs f7, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8A10: C0C90000  lfs f6, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC8A14: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FC8A18: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 82FC8A1C: ECA83824  fdivs f5, f8, f7
	ctx.f[5].f64 = ((ctx.f[8].f64 / ctx.f[7].f64) as f32) as f64;
	// 82FC8A20: D0A30000  stfs f5, 0(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8A24: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 82FC8A28: EC0501BA  fmadds f0, f5, f6, f0
	ctx.f[0].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8A2C: 4082FFCC  bne 0x82fc89f8
	if !ctx.cr[0].eq {
	pc = 0x82FC89F8; continue 'dispatch;
	}
	// 82FC8A30: 8081FEC0  lwz r4, -0x140(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-320 as u32) ) } as u64;
	// 82FC8A34: 7F18A800  cmpw cr6, r24, r21
	ctx.cr[6].compare_i32(ctx.r[24].s32, ctx.r[21].s32, &mut ctx.xer);
	// 82FC8A38: 41990050  bgt cr6, 0x82fc8a88
	if ctx.cr[6].gt {
	pc = 0x82FC8A88; continue 'dispatch;
	}
	// 82FC8A3C: 7D659A14  add r11, r5, r19
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[19].u64;
	// 82FC8A40: 3861FF20  addi r3, r1, -0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + -224;
	// 82FC8A44: 7D5EA214  add r10, r30, r20
	ctx.r[10].u64 = ctx.r[30].u64 + ctx.r[20].u64;
	// 82FC8A48: 3921FEF0  addi r9, r1, -0x110
	ctx.r[9].s64 = ctx.r[1].s64 + -272;
	// 82FC8A4C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8A50: 7FE5AA14  add r31, r5, r21
	ctx.r[31].u64 = ctx.r[5].u64 + ctx.r[21].u64;
	// 82FC8A54: 7D4B1C2E  lfsx f10, r11, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8A58: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FC8A5C: ED2D5024  fdivs f9, f13, f10
	ctx.f[9].f64 = ((ctx.f[13].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FC8A60: 7C7DA214  add r3, r29, r20
	ctx.r[3].u64 = ctx.r[29].u64 + ctx.r[20].u64;
	// 82FC8A64: 57EB103A  slwi r11, r31, 2
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8A68: 3941FF10  addi r10, r1, -0xf0
	ctx.r[10].s64 = ctx.r[1].s64 + -240;
	// 82FC8A6C: 5463103A  slwi r3, r3, 2
	ctx.r[3].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FC8A70: C109FFFC  lfs f8, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC8A74: 3921FEF0  addi r9, r1, -0x110
	ctx.r[9].s64 = ctx.r[1].s64 + -272;
	// 82FC8A78: 7CEB542E  lfsx f7, r11, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC8A7C: ECC90232  fmuls f6, f9, f8
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FC8A80: 7CC34D2E  stfsx f6, r3, r9
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[3].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FC8A84: EC0701BA  fmadds f0, f7, f6, f0
	ctx.f[0].f64 = (((ctx.f[7].f64 * ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8A88: 8061002C  lwz r3, 0x2c(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(44 as u32) ) } as u64;
	// 82FC8A8C: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 82FC8A90: 7E2A8B78  mr r10, r17
	ctx.r[10].u64 = ctx.r[17].u64;
	// 82FC8A94: D0120000  stfs f0, 0(r18)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8A98: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 82FC8A9C: 3A940001  addi r20, r20, 1
	ctx.r[20].s64 = ctx.r[20].s64 + 1;
	// 82FC8AA0: 7CC83378  mr r8, r6
	ctx.r[8].u64 = ctx.r[6].u64;
	// 82FC8AA4: 7E118378  mr r17, r16
	ctx.r[17].u64 = ctx.r[16].u64;
	// 82FC8AA8: 7FBEEB78  mr r30, r29
	ctx.r[30].u64 = ctx.r[29].u64;
	// 82FC8AAC: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 82FC8AB0: 7D505378  mr r16, r10
	ctx.r[16].u64 = ctx.r[10].u64;
	// 82FC8AB4: 7D3D4B78  mr r29, r9
	ctx.r[29].u64 = ctx.r[9].u64;
	// 82FC8AB8: 39CE0001  addi r14, r14, 1
	ctx.r[14].s64 = ctx.r[14].s64 + 1;
	// 82FC8ABC: 3A73FFF0  addi r19, r19, -0x10
	ctx.r[19].s64 = ctx.r[19].s64 + -16;
	// 82FC8AC0: 39EFFFFC  addi r15, r15, -4
	ctx.r[15].s64 = ctx.r[15].s64 + -4;
	// 82FC8AC4: 3AD6FFFC  addi r22, r22, -4
	ctx.r[22].s64 = ctx.r[22].s64 + -4;
	// 82FC8AC8: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 82FC8ACC: 3A520010  addi r18, r18, 0x10
	ctx.r[18].s64 = ctx.r[18].s64 + 16;
	// 82FC8AD0: 7F141800  cmpw cr6, r20, r3
	ctx.cr[6].compare_i32(ctx.r[20].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FC8AD4: 4099FD3C  ble cr6, 0x82fc8810
	if !ctx.cr[6].gt {
	pc = 0x82FC8810; continue 'dispatch;
	}
	// 82FC8AD8: 8261003C  lwz r19, 0x3c(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(60 as u32) ) } as u64;
	// 82FC8ADC: 5475003E  slwi r21, r3, 0
	ctx.r[21].u32 = ctx.r[3].u32.wrapping_shl(0);
	ctx.r[21].u64 = ctx.r[21].u32 as u64;
	// 82FC8AE0: 82C10024  lwz r22, 0x24(r1)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(36 as u32) ) } as u64;
	// 82FC8AE4: 8141FED0  lwz r10, -0x130(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-304 as u32) ) } as u64;
	// 82FC8AE8: 39780001  addi r11, r24, 1
	ctx.r[11].s64 = ctx.r[24].s64 + 1;
	// 82FC8AEC: 3924FFFF  addi r9, r4, -1
	ctx.r[9].s64 = ctx.r[4].s64 + -1;
	// 82FC8AF0: 390A0004  addi r8, r10, 4
	ctx.r[8].s64 = ctx.r[10].s64 + 4;
	// 82FC8AF4: 9161FEC4  stw r11, -0x13c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-316 as u32), ctx.r[11].u32 ) };
	// 82FC8AF8: 9121FEC0  stw r9, -0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-320 as u32), ctx.r[9].u32 ) };
	// 82FC8AFC: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 82FC8B00: 9101FED0  stw r8, -0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-304 as u32), ctx.r[8].u32 ) };
	// 82FC8B04: 7F0BB000  cmpw cr6, r11, r22
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FC8B08: 4099FCB4  ble cr6, 0x82fc87bc
	if !ctx.cr[6].gt {
	pc = 0x82FC87BC; continue 'dispatch;
	}
	// 82FC8B0C: 7EC7B378  mr r7, r22
	ctx.r[7].u64 = ctx.r[22].u64;
	// 82FC8B10: 2F150001  cmpwi cr6, r21, 1
	ctx.cr[6].compare_i32(ctx.r[21].s32, 1, &mut ctx.xer);
	// 82FC8B14: 419800E4  blt cr6, 0x82fc8bf8
	if ctx.cr[6].lt {
	pc = 0x82FC8BF8; continue 'dispatch;
	}
	// 82FC8B18: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 82FC8B1C: 3BF6FFFF  addi r31, r22, -1
	ctx.r[31].s64 = ctx.r[22].s64 + -1;
	// 82FC8B20: 38730010  addi r3, r19, 0x10
	ctx.r[3].s64 = ctx.r[19].s64 + 16;
	// 82FC8B24: 7EA6AB78  mr r6, r21
	ctx.r[6].u64 = ctx.r[21].u64;
	// 82FC8B28: 39760001  addi r11, r22, 1
	ctx.r[11].s64 = ctx.r[22].s64 + 1;
	// 82FC8B2C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FC8B30: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FC8B34: 41980064  blt cr6, 0x82fc8b98
	if ctx.cr[6].lt {
	pc = 0x82FC8B98; continue 'dispatch;
	}
	// 82FC8B38: 7CEB07B4  extsw r11, r7
	ctx.r[11].s64 = ctx.r[7].s32 as i64;
	// 82FC8B3C: 39560001  addi r10, r22, 1
	ctx.r[10].s64 = ctx.r[22].s64 + 1;
	// 82FC8B40: F961FEE0  std r11, -0x120(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-288 as u32), ctx.r[11].u64 ) };
	// 82FC8B44: C801FEE0  lfd f0, -0x120(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-288 as u32) ) };
	// 82FC8B48: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 82FC8B4C: 5549F0BE  srwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC8B50: FC006818  frsp f0, f13
	ctx.f[0].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82FC8B54: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FC8B58: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8B5C: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8B60: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC8B64: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8B68: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC8B6C: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8B70: ED200332  fmuls f9, f0, f12
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 82FC8B74: C10B000C  lfs f8, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC8B78: ECEA0032  fmuls f7, f10, f0
	ctx.f[7].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC8B7C: ECC00232  fmuls f6, f0, f8
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FC8B80: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8B84: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8B88: D0EB0008  stfs f7, 8(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8B8C: D0CB000C  stfs f6, 0xc(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC8B90: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC8B94: 4082FFC8  bne 0x82fc8b5c
	if !ctx.cr[0].eq {
	pc = 0x82FC8B5C; continue 'dispatch;
	}
	// 82FC8B98: 7F0AB000  cmpw cr6, r10, r22
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FC8B9C: 41990044  bgt cr6, 0x82fc8be0
	if ctx.cr[6].gt {
	pc = 0x82FC8BE0; continue 'dispatch;
	}
	// 82FC8BA0: 7CEB07B4  extsw r11, r7
	ctx.r[11].s64 = ctx.r[7].s32 as i64;
	// 82FC8BA4: 7D245214  add r9, r4, r10
	ctx.r[9].u64 = ctx.r[4].u64 + ctx.r[10].u64;
	// 82FC8BA8: F961FED0  std r11, -0x130(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-304 as u32), ctx.r[11].u64 ) };
	// 82FC8BAC: 7D6AB050  subf r11, r10, r22
	ctx.r[11].s64 = ctx.r[22].s64 - ctx.r[10].s64;
	// 82FC8BB0: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC8BB4: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 82FC8BB8: 7D699A14  add r11, r9, r19
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[19].u64;
	// 82FC8BBC: C801FED0  lfd f0, -0x130(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-304 as u32) ) };
	// 82FC8BC0: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 82FC8BC4: FC006818  frsp f0, f13
	ctx.f[0].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82FC8BC8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8BCC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC8BD0: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FC8BD4: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8BD8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC8BDC: 4082FFEC  bne 0x82fc8bc8
	if !ctx.cr[0].eq {
	pc = 0x82FC8BC8; continue 'dispatch;
	}
	// 82FC8BE0: 7CFF39D6  mullw r7, r31, r7
	ctx.r[7].s64 = (ctx.r[31].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FC8BE4: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82FC8BE8: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 82FC8BEC: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 82FC8BF0: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 82FC8BF4: 4082FF34  bne 0x82fc8b28
	if !ctx.cr[0].eq {
	pc = 0x82FC8B28; continue 'dispatch;
	}
	// 82FC8BF8: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 82FC8BFC: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 82FC8C00: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 82FC8C04: 481DF57C  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8C08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC8C08 size=792
    let mut pc: u32 = 0x82FC8C08;
    'dispatch: loop {
        match pc {
            0x82FC8C08 => {
    //   block [0x82FC8C08..0x82FC8F20)
	// 82FC8C08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC8C0C: 481DF559  bl 0x831a8164
	ctx.lr = 0x82FC8C10;
	sub_831A8130(ctx, base);
	// 82FC8C10: 2F060000  cmpwi cr6, r6, 0
	ctx.cr[6].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82FC8C14: 409A0014  bne cr6, 0x82fc8c28
	if !ctx.cr[6].eq {
	pc = 0x82FC8C28; continue 'dispatch;
	}
	// 82FC8C18: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8C1C: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8C20: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC8C24: 419A0028  beq cr6, 0x82fc8c4c
	if ctx.cr[6].eq {
	pc = 0x82FC8C4C; continue 'dispatch;
	}
	// 82FC8C28: 7D632050  subf r11, r3, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[3].s64;
	// 82FC8C2C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FC8C30: 7F065800  cmpw cr6, r6, r11
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FC8C34: 409A0024  bne cr6, 0x82fc8c58
	if !ctx.cr[6].eq {
	pc = 0x82FC8C58; continue 'dispatch;
	}
	// 82FC8C38: 81650000  lwz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8C3C: 548A103A  slwi r10, r4, 2
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8C40: 7C0A5C2E  lfsx f0, r10, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8C44: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC8C48: 409A0010  bne cr6, 0x82fc8c58
	if !ctx.cr[6].eq {
	pc = 0x82FC8C58; continue 'dispatch;
	}
	// 82FC8C4C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8C50: C02B08A8  lfs f1, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC8C54: 481DF560  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 82FC8C58: 83C50000  lwz r30, 0(r5)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8C5C: 54CB103A  slwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8C60: 7F6BF214  add r27, r11, r30
	ctx.r[27].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82FC8C64: 7C0BF42E  lfsx f0, r11, r30
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8C68: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC8C6C: 419802A8  blt cr6, 0x82fc8f14
	if ctx.cr[6].lt {
	pc = 0x82FC8F14; continue 'dispatch;
	}
	// 82FC8C70: 7D633214  add r11, r3, r6
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[6].u64;
	// 82FC8C74: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FC8C78: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8C7C: 7C0AF42E  lfsx f0, r10, r30
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[30].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8C80: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC8C84: 40980290  bge cr6, 0x82fc8f14
	if !ctx.cr[6].lt {
	pc = 0x82FC8F14; continue 'dispatch;
	}
	// 82FC8C88: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8C8C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82FC8C90: C14B08A4  lfs f10, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC8C94: 4198004C  blt cr6, 0x82fc8ce0
	if ctx.cr[6].lt {
	pc = 0x82FC8CE0; continue 'dispatch;
	}
	// 82FC8C98: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 82FC8C9C: 3941FFC0  addi r10, r1, -0x40
	ctx.r[10].s64 = ctx.r[1].s64 + -64;
	// 82FC8CA0: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 82FC8CA4: 39230001  addi r9, r3, 1
	ctx.r[9].s64 = ctx.r[3].s64 + 1;
	// 82FC8CA8: C00808A8  lfs f0, 0x8a8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8CAC: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8CB0: FF016800  fcmpu cr6, f1, f13
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[13].f64);
	// 82FC8CB4: 41980018  blt cr6, 0x82fc8ccc
	if ctx.cr[6].lt {
	pc = 0x82FC8CCC; continue 'dispatch;
	}
	// 82FC8CB8: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8CBC: FF016800  fcmpu cr6, f1, f13
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[13].f64);
	// 82FC8CC0: 4098000C  bge cr6, 0x82fc8ccc
	if !ctx.cr[6].lt {
	pc = 0x82FC8CCC; continue 'dispatch;
	}
	// 82FC8CC4: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8CC8: 48000008  b 0x82fc8cd0
	pc = 0x82FC8CD0; continue 'dispatch;
	// 82FC8CCC: D14A0000  stfs f10, 0(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8CD0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC8CD4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC8CD8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC8CDC: 4082FFD0  bne 0x82fc8cac
	if !ctx.cr[0].eq {
	pc = 0x82FC8CAC; continue 'dispatch;
	}
	// 82FC8CE0: 3B800001  li r28, 1
	ctx.r[28].s64 = 1;
	// 82FC8CE4: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 82FC8CE8: 41980224  blt cr6, 0x82fc8f0c
	if ctx.cr[6].lt {
	pc = 0x82FC8F0C; continue 'dispatch;
	}
	// 82FC8CEC: 39660002  addi r11, r6, 2
	ctx.r[11].s64 = ctx.r[6].s64 + 2;
	// 82FC8CF0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FC8CF4: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8CF8: 7FABF214  add r29, r11, r30
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82FC8CFC: C001FFC0  lfs f0, -0x40(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8D00: FF005000  fcmpu cr6, f0, f10
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[10].f64);
	// 82FC8D04: 409A000C  bne cr6, 0x82fc8d10
	if !ctx.cr[6].eq {
	pc = 0x82FC8D10; continue 'dispatch;
	}
	// 82FC8D08: FC005090  fmr f0, f10
	ctx.f[0].f64 = ctx.f[10].f64;
	// 82FC8D0C: 4800001C  b 0x82fc8d28
	pc = 0x82FC8D28; continue 'dispatch;
	// 82FC8D10: C1BB0000  lfs f13, 0(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8D14: ED816828  fsubs f12, f1, f13
	ctx.f[12].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8D18: C17DFFFC  lfs f11, -4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8D1C: ED2B6828  fsubs f9, f11, f13
	ctx.f[9].f64 = (((ctx.f[11].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8D20: ED0C0032  fmuls f8, f12, f0
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC8D24: EC084824  fdivs f0, f8, f9
	ctx.f[0].f64 = ((ctx.f[8].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8D28: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FC8D2C: 2F1F0004  cmpwi cr6, r31, 4
	ctx.cr[6].compare_i32(ctx.r[31].s32, 4, &mut ctx.xer);
	// 82FC8D30: 4198013C  blt cr6, 0x82fc8e6c
	if ctx.cr[6].lt {
	pc = 0x82FC8E6C; continue 'dispatch;
	}
	// 82FC8D34: 397FFFFC  addi r11, r31, -4
	ctx.r[11].s64 = ctx.r[31].s64 + -4;
	// 82FC8D38: 39460003  addi r10, r6, 3
	ctx.r[10].s64 = ctx.r[6].s64 + 3;
	// 82FC8D3C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8D40: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8D44: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 82FC8D48: 3961FFC4  addi r11, r1, -0x3c
	ctx.r[11].s64 = ctx.r[1].s64 + -60;
	// 82FC8D4C: 393D0008  addi r9, r29, 8
	ctx.r[9].s64 = ctx.r[29].s64 + 8;
	// 82FC8D50: 7D4AF214  add r10, r10, r30
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[30].u64;
	// 82FC8D54: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FC8D58: 38BB0004  addi r5, r27, 4
	ctx.r[5].s64 = ctx.r[27].s64 + 4;
	// 82FC8D5C: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC8D60: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8D64: C1A50000  lfs f13, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8D68: FF0B5000  fcmpu cr6, f11, f10
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[10].f64);
	// 82FC8D6C: C1840000  lfs f12, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8D70: 409A0010  bne cr6, 0x82fc8d80
	if !ctx.cr[6].eq {
	pc = 0x82FC8D80; continue 'dispatch;
	}
	// 82FC8D74: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8D78: FD605090  fmr f11, f10
	ctx.f[11].f64 = ctx.f[10].f64;
	// 82FC8D7C: 48000020  b 0x82fc8d9c
	pc = 0x82FC8D9C; continue 'dispatch;
	// 82FC8D80: ED2C6828  fsubs f9, f12, f13
	ctx.f[9].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8D84: ED0C0828  fsubs f8, f12, f1
	ctx.f[8].f64 = (((ctx.f[12].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8D88: ECE16828  fsubs f7, f1, f13
	ctx.f[7].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8D8C: ECCB4824  fdivs f6, f11, f9
	ctx.f[6].f64 = ((ctx.f[11].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8D90: ECA801BA  fmadds f5, f8, f6, f0
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8D94: D0ABFFFC  stfs f5, -4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8D98: ED6701B2  fmuls f11, f7, f6
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8D9C: C18B0004  lfs f12, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8DA0: C00AFFFC  lfs f0, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8DA4: FF0C5000  fcmpu cr6, f12, f10
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[10].f64);
	// 82FC8DA8: C1A9FFFC  lfs f13, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8DAC: 409A0010  bne cr6, 0x82fc8dbc
	if !ctx.cr[6].eq {
	pc = 0x82FC8DBC; continue 'dispatch;
	}
	// 82FC8DB0: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8DB4: FD605090  fmr f11, f10
	ctx.f[11].f64 = ctx.f[10].f64;
	// 82FC8DB8: 48000020  b 0x82fc8dd8
	pc = 0x82FC8DD8; continue 'dispatch;
	// 82FC8DBC: ED2D0028  fsubs f9, f13, f0
	ctx.f[9].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8DC0: ED0D0828  fsubs f8, f13, f1
	ctx.f[8].f64 = (((ctx.f[13].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8DC4: ECE10028  fsubs f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8DC8: ECCC4824  fdivs f6, f12, f9
	ctx.f[6].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8DCC: ECA859BA  fmadds f5, f8, f6, f11
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC8DD0: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8DD4: ED6701B2  fmuls f11, f7, f6
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8DD8: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8DDC: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8DE0: FF0C5000  fcmpu cr6, f12, f10
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[10].f64);
	// 82FC8DE4: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8DE8: 409A0010  bne cr6, 0x82fc8df8
	if !ctx.cr[6].eq {
	pc = 0x82FC8DF8; continue 'dispatch;
	}
	// 82FC8DEC: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8DF0: FD605090  fmr f11, f10
	ctx.f[11].f64 = ctx.f[10].f64;
	// 82FC8DF4: 48000020  b 0x82fc8e14
	pc = 0x82FC8E14; continue 'dispatch;
	// 82FC8DF8: ED2D0028  fsubs f9, f13, f0
	ctx.f[9].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8DFC: ED0D0828  fsubs f8, f13, f1
	ctx.f[8].f64 = (((ctx.f[13].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8E00: ECE10028  fsubs f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8E04: ECCC4824  fdivs f6, f12, f9
	ctx.f[6].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8E08: ECA859BA  fmadds f5, f8, f6, f11
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC8E0C: D0AB0004  stfs f5, 4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8E10: ED6701B2  fmuls f11, f7, f6
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8E14: C18B000C  lfs f12, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8E18: C00A0004  lfs f0, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC8E1C: FF0C5000  fcmpu cr6, f12, f10
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[10].f64);
	// 82FC8E20: C1A90004  lfs f13, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8E24: 409A0010  bne cr6, 0x82fc8e34
	if !ctx.cr[6].eq {
	pc = 0x82FC8E34; continue 'dispatch;
	}
	// 82FC8E28: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8E2C: FC005090  fmr f0, f10
	ctx.f[0].f64 = ctx.f[10].f64;
	// 82FC8E30: 48000020  b 0x82fc8e50
	pc = 0x82FC8E50; continue 'dispatch;
	// 82FC8E34: ED2D0028  fsubs f9, f13, f0
	ctx.f[9].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8E38: ED0D0828  fsubs f8, f13, f1
	ctx.f[8].f64 = (((ctx.f[13].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8E3C: ECE10028  fsubs f7, f1, f0
	ctx.f[7].f64 = (((ctx.f[1].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC8E40: ECCC4824  fdivs f6, f12, f9
	ctx.f[6].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8E44: ECA859BA  fmadds f5, f8, f6, f11
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC8E48: D0AB0008  stfs f5, 8(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC8E4C: EC0701B2  fmuls f0, f7, f6
	ctx.f[0].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8E50: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FC8E54: 38A50010  addi r5, r5, 0x10
	ctx.r[5].s64 = ctx.r[5].s64 + 16;
	// 82FC8E58: 38840010  addi r4, r4, 0x10
	ctx.r[4].s64 = ctx.r[4].s64 + 16;
	// 82FC8E5C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC8E60: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC8E64: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FC8E68: 4082FEF8  bne 0x82fc8d60
	if !ctx.cr[0].eq {
	pc = 0x82FC8D60; continue 'dispatch;
	}
	// 82FC8E6C: 7F07F800  cmpw cr6, r7, r31
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FC8E70: 40980088  bge cr6, 0x82fc8ef8
	if !ctx.cr[6].lt {
	pc = 0x82FC8EF8; continue 'dispatch;
	}
	// 82FC8E74: 7D67E214  add r11, r7, r28
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[28].u64;
	// 82FC8E78: 7D473214  add r10, r7, r6
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 82FC8E7C: 7D6B3214  add r11, r11, r6
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 82FC8E80: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC8E84: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FC8E88: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC8E8C: 3961FFC0  addi r11, r1, -0x40
	ctx.r[11].s64 = ctx.r[1].s64 + -64;
	// 82FC8E90: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC8E94: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC8E98: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 82FC8E9C: 7D29F214  add r9, r9, r30
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 82FC8EA0: 7D4AF214  add r10, r10, r30
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[30].u64;
	// 82FC8EA4: 7D07F850  subf r8, r7, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[7].s64;
	// 82FC8EA8: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC8EAC: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC8EB0: FF0B5000  fcmpu cr6, f11, f10
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[10].f64);
	// 82FC8EB4: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC8EB8: 409A0010  bne cr6, 0x82fc8ec8
	if !ctx.cr[6].eq {
	pc = 0x82FC8EC8; continue 'dispatch;
	}
	// 82FC8EBC: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8EC0: FC005090  fmr f0, f10
	ctx.f[0].f64 = ctx.f[10].f64;
	// 82FC8EC4: 48000020  b 0x82fc8ee4
	pc = 0x82FC8EE4; continue 'dispatch;
	// 82FC8EC8: ED2C6828  fsubs f9, f12, f13
	ctx.f[9].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8ECC: ED0C0828  fsubs f8, f12, f1
	ctx.f[8].f64 = (((ctx.f[12].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FC8ED0: ECE16828  fsubs f7, f1, f13
	ctx.f[7].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC8ED4: ECCB4824  fdivs f6, f11, f9
	ctx.f[6].f64 = ((ctx.f[11].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FC8ED8: ECA801BA  fmadds f5, f8, f6, f0
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC8EDC: D0AB0000  stfs f5, 0(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8EE0: EC0701B2  fmuls f0, f7, f6
	ctx.f[0].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC8EE4: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FC8EE8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC8EEC: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FC8EF0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC8EF4: 4082FFB4  bne 0x82fc8ea8
	if !ctx.cr[0].eq {
	pc = 0x82FC8EA8; continue 'dispatch;
	}
	// 82FC8EF8: 3B9C0001  addi r28, r28, 1
	ctx.r[28].s64 = ctx.r[28].s64 + 1;
	// 82FC8EFC: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 82FC8F00: 3BFFFFFF  addi r31, r31, -1
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	// 82FC8F04: 7F1C1800  cmpw cr6, r28, r3
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FC8F08: 4099FDF4  ble cr6, 0x82fc8cfc
	if !ctx.cr[6].gt {
	pc = 0x82FC8CFC; continue 'dispatch;
	}
	// 82FC8F0C: C021FFC0  lfs f1, -0x40(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC8F10: 481DF2A4  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 82FC8F14: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8F18: C02B08A4  lfs f1, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC8F1C: 481DF298  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC8F20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC8F20 size=1040
    let mut pc: u32 = 0x82FC8F20;
    'dispatch: loop {
        match pc {
            0x82FC8F20 => {
    //   block [0x82FC8F20..0x82FC9330)
	// 82FC8F20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC8F24: 481DF231  bl 0x831a8154
	ctx.lr = 0x82FC8F28;
	sub_831A8130(ctx, base);
	// 82FC8F28: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 82FC8F2C: 9421FF00  stwu r1, -0x100(r1)
	ea = ctx.r[1].u32.wrapping_add(-256 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC8F30: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82FC8F34: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 82FC8F38: 7D3D4B78  mr r29, r9
	ctx.r[29].u64 = ctx.r[9].u64;
	// 82FC8F3C: 7F08F800  cmpw cr6, r8, r31
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FC8F40: 7D1E4378  mr r30, r8
	ctx.r[30].u64 = ctx.r[8].u64;
	// 82FC8F44: 41980008  blt cr6, 0x82fc8f4c
	if ctx.cr[6].lt {
	pc = 0x82FC8F4C; continue 'dispatch;
	}
	// 82FC8F48: 7FFEFB78  mr r30, r31
	ctx.r[30].u64 = ctx.r[31].u64;
	// 82FC8F4C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC8F50: 3B5F0001  addi r26, r31, 1
	ctx.r[26].s64 = ctx.r[31].s64 + 1;
	// 82FC8F54: 7F1A4000  cmpw cr6, r26, r8
	ctx.cr[6].compare_i32(ctx.r[26].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FC8F58: C3EB08A4  lfs f31, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FC8F5C: 41990034  bgt cr6, 0x82fc8f90
	if ctx.cr[6].gt {
	pc = 0x82FC8F90; continue 'dispatch;
	}
	// 82FC8F60: 574B2036  slwi r11, r26, 4
	ctx.r[11].u32 = ctx.r[26].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC8F64: 7D5A4050  subf r10, r26, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[26].s64;
	// 82FC8F68: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82FC8F6C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC8F70: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82FC8F74: D3EBFFF8  stfs f31, -8(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC8F78: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC8F7C: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8F80: D3EB0000  stfs f31, 0(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8F84: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8F88: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC8F8C: 4082FFE8  bne 0x82fc8f74
	if !ctx.cr[0].eq {
	pc = 0x82FC8F74; continue 'dispatch;
	}
	// 82FC8F90: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 82FC8F94: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FC8F98: 4BFFF301  bl 0x82fc8298
	ctx.lr = 0x82FC8F9C;
	sub_82FC8298(ctx, base);
	// 82FC8F9C: 7CA72B78  mr r7, r5
	ctx.r[7].u64 = ctx.r[5].u64;
	// 82FC8FA0: 39010060  addi r8, r1, 0x60
	ctx.r[8].s64 = ctx.r[1].s64 + 96;
	// 82FC8FA4: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 82FC8FA8: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82FC8FAC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FC8FB0: 4BFFF529  bl 0x82fc84d8
	ctx.lr = 0x82FC8FB4;
	sub_82FC84D8(ctx, base);
	// 82FC8FB4: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FC8FB8: 4198036C  blt cr6, 0x82fc9324
	if ctx.cr[6].lt {
	pc = 0x82FC9324; continue 'dispatch;
	}
	// 82FC8FBC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FC8FC0: 38610064  addi r3, r1, 0x64
	ctx.r[3].s64 = ctx.r[1].s64 + 100;
	// 82FC8FC4: 397D0008  addi r11, r29, 8
	ctx.r[11].s64 = ctx.r[29].s64 + 8;
	// 82FC8FC8: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82FC8FCC: D3EB0000  stfs f31, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC8FD0: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FC8FD4: D3EBFFF8  stfs f31, -8(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC8FD8: 2F1A0004  cmpwi cr6, r26, 4
	ctx.cr[6].compare_i32(ctx.r[26].s32, 4, &mut ctx.xer);
	// 82FC8FDC: D3EBFFFC  stfs f31, -4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC8FE0: D3EB0004  stfs f31, 4(r11)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC8FE4: 41980260  blt cr6, 0x82fc9244
	if ctx.cr[6].lt {
	pc = 0x82FC9244; continue 'dispatch;
	}
	// 82FC8FE8: 7D5FE050  subf r10, r31, r28
	ctx.r[10].s64 = ctx.r[28].s64 - ctx.r[31].s64;
	// 82FC8FEC: 811B0000  lwz r8, 0(r27)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC8FF0: 393F0001  addi r9, r31, 1
	ctx.r[9].s64 = ctx.r[31].s64 + 1;
	// 82FC8FF4: 38CA0002  addi r6, r10, 2
	ctx.r[6].s64 = ctx.r[10].s64 + 2;
	// 82FC8FF8: 5527F0BE  srwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC8FFC: 54CA2036  slwi r10, r6, 4
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC9000: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FC9004: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FC9008: 54E8103A  slwi r8, r7, 2
	ctx.r[8].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC900C: 80CAFFE0  lwz r6, -0x20(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-32 as u32) ) } as u64;
	// 82FC9010: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82FC9014: 83AAFFE4  lwz r29, -0x1c(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-28 as u32) ) } as u64;
	// 82FC9018: C169FFFC  lfs f11, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC901C: 832AFFE8  lwz r25, -0x18(r10)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-24 as u32) ) } as u64;
	// 82FC9020: C14BFFF8  lfs f10, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9024: 830AFFEC  lwz r24, -0x14(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FC9028: C12BFFFC  lfs f9, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC902C: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9030: 3AE10050  addi r23, r1, 0x50
	ctx.r[23].s64 = ctx.r[1].s64 + 80;
	// 82FC9034: 90C50000  stw r6, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82FC9038: C0EB0004  lfs f7, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC903C: 93A50004  stw r29, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FC9040: C0C90000  lfs f6, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC9044: 93250008  stw r25, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 82FC9048: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 82FC904C: 9305000C  stw r24, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FC9050: C0810058  lfs f4, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC9054: C0410050  lfs f2, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC9058: 38AAFFE0  addi r5, r10, -0x20
	ctx.r[5].s64 = ctx.r[10].s64 + -32;
	// 82FC905C: C061005C  lfs f3, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC9060: C0A10054  lfs f5, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9064: EDA502F2  fmuls f13, f5, f11
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC9068: EC0202F2  fmuls f0, f2, f11
	ctx.f[0].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC906C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9070: ED8402F2  fmuls f12, f4, f11
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC9074: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9078: ED6302F2  fmuls f11, f3, f11
	ctx.f[11].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC907C: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9080: EC89682A  fadds f4, f9, f13
	ctx.f[4].f64 = ((ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC9084: D08BFFFC  stfs f4, -4(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC9088: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC908C: C0A90004  lfs f5, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9090: EC2A002A  fadds f1, f10, f0
	ctx.f[1].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC9094: D02BFFF8  stfs f1, -8(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC9098: EC68602A  fadds f3, f8, f12
	ctx.f[3].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC909C: D06B0000  stfs f3, 0(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC90A0: EC47582A  fadds f2, f7, f11
	ctx.f[2].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC90A4: D04B0004  stfs f2, 4(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC90A8: 80AAFFF8  lwz r5, -8(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FC90AC: 83AAFFFC  lwz r29, -4(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FC90B0: 832AFFF4  lwz r25, -0xc(r10)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FC90B4: 830AFFF0  lwz r24, -0x10(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FC90B8: 93170000  stw r24, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FC90BC: FD400890  fmr f10, f1
	ctx.f[10].f64 = ctx.f[1].f64;
	// 82FC90C0: 93370004  stw r25, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[25].u32 ) };
	// 82FC90C4: 90B70008  stw r5, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 82FC90C8: FC202090  fmr f1, f4
	ctx.f[1].f64 = ctx.f[4].f64;
	// 82FC90CC: 93B7000C  stw r29, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 82FC90D0: FD201890  fmr f9, f3
	ctx.f[9].f64 = ctx.f[3].f64;
	// 82FC90D4: FD001090  fmr f8, f2
	ctx.f[8].f64 = ctx.f[2].f64;
	// 82FC90D8: C0810058  lfs f4, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC90DC: C061005C  lfs f3, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC90E0: C0410050  lfs f2, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC90E4: C0E10054  lfs f7, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC90E8: EDA701B2  fmuls f13, f7, f6
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC90EC: EC0201B2  fmuls f0, f2, f6
	ctx.f[0].f64 = (((ctx.f[2].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC90F0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC90F4: ED6301B2  fmuls f11, f3, f6
	ctx.f[11].f64 = (((ctx.f[3].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC90F8: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC90FC: ED8401B2  fmuls f12, f4, f6
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9100: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9104: ECE1682A  fadds f7, f1, f13
	ctx.f[7].f64 = ((ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC9108: D0EBFFFC  stfs f7, -4(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC910C: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9110: EC0A002A  fadds f0, f10, f0
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC9114: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC9118: EC88582A  fadds f4, f8, f11
	ctx.f[4].f64 = ((ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC911C: D08B0004  stfs f4, 4(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC9120: ECC9602A  fadds f6, f9, f12
	ctx.f[6].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC9124: D0CB0000  stfs f6, 0(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9128: 83AA0004  lwz r29, 4(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC912C: FC603890  fmr f3, f7
	ctx.f[3].f64 = ctx.f[7].f64;
	// 82FC9130: 80AA0000  lwz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9134: 832A0008  lwz r25, 8(r10)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9138: 830A000C  lwz r24, 0xc(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC913C: 90A60000  stw r5, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 82FC9140: FD400090  fmr f10, f0
	ctx.f[10].f64 = ctx.f[0].f64;
	// 82FC9144: 93A60004  stw r29, 4(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FC9148: FC403090  fmr f2, f6
	ctx.f[2].f64 = ctx.f[6].f64;
	// 82FC914C: FC202090  fmr f1, f4
	ctx.f[1].f64 = ctx.f[4].f64;
	// 82FC9150: 93260008  stw r25, 8(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), ctx.r[25].u32 ) };
	// 82FC9154: 38AA0010  addi r5, r10, 0x10
	ctx.r[5].s64 = ctx.r[10].s64 + 16;
	// 82FC9158: 9306000C  stw r24, 0xc(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FC915C: C1A10054  lfs f13, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9160: C121005C  lfs f9, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9164: 3BA10050  addi r29, r1, 0x50
	ctx.r[29].s64 = ctx.r[1].s64 + 80;
	// 82FC9168: C1810058  lfs f12, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC916C: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FC9170: C1610050  lfs f11, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9174: EC0B0172  fmuls f0, f11, f5
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC9178: EDAD0172  fmuls f13, f13, f5
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC917C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9180: ED690172  fmuls f11, f9, f5
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC9184: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9188: ED8C0172  fmuls f12, f12, f5
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC918C: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9190: ED0A002A  fadds f8, f10, f0
	ctx.f[8].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC9194: D10BFFF8  stfs f8, -8(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC9198: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC919C: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FC91A0: C0C90008  lfs f6, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC91A4: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FC91A8: ECA3682A  fadds f5, f3, f13
	ctx.f[5].f64 = ((ctx.f[3].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC91AC: D0ABFFFC  stfs f5, -4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC91B0: EC61582A  fadds f3, f1, f11
	ctx.f[3].f64 = ((ctx.f[1].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC91B4: D06B0004  stfs f3, 4(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC91B8: EC82602A  fadds f4, f2, f12
	ctx.f[4].f64 = ((ctx.f[2].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC91BC: D08B0000  stfs f4, 0(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC91C0: 83250000  lwz r25, 0(r5)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC91C4: FCE04090  fmr f7, f8
	ctx.f[7].f64 = ctx.f[8].f64;
	// 82FC91C8: 80C50008  lwz r6, 8(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC91CC: 83050004  lwz r24, 4(r5)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC91D0: 80A5000C  lwz r5, 0xc(r5)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC91D4: 931D0004  stw r24, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FC91D8: 933D0000  stw r25, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 82FC91DC: FC202890  fmr f1, f5
	ctx.f[1].f64 = ctx.f[5].f64;
	// 82FC91E0: 90DD0008  stw r6, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FC91E4: FD402090  fmr f10, f4
	ctx.f[10].f64 = ctx.f[4].f64;
	// 82FC91E8: 90BD000C  stw r5, 0xc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FC91EC: C0A1005C  lfs f5, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC91F0: FC401890  fmr f2, f3
	ctx.f[2].f64 = ctx.f[3].f64;
	// 82FC91F4: C1010058  lfs f8, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC91F8: C0810050  lfs f4, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC91FC: C1210054  lfs f9, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9200: EC0401B2  fmuls f0, f4, f6
	ctx.f[0].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9204: EDA901B2  fmuls f13, f9, f6
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9208: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC920C: ED8801B2  fmuls f12, f8, f6
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9210: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9214: ED6501B2  fmuls f11, f5, f6
	ctx.f[11].f64 = (((ctx.f[5].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9218: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC921C: EC67002A  fadds f3, f7, f0
	ctx.f[3].f64 = ((ctx.f[7].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC9220: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9224: EC21682A  fadds f1, f1, f13
	ctx.f[1].f64 = ((ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC9228: D06BFFF8  stfs f3, -8(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC922C: D02BFFFC  stfs f1, -4(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC9230: EC0A602A  fadds f0, f10, f12
	ctx.f[0].f64 = ((ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC9234: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9238: EDA2582A  fadds f13, f2, f11
	ctx.f[13].f64 = ((ctx.f[2].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC923C: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC9240: 4082FDCC  bne 0x82fc900c
	if !ctx.cr[0].eq {
	pc = 0x82FC900C; continue 'dispatch;
	}
	// 82FC9244: 7F08F800  cmpw cr6, r8, r31
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FC9248: 419900C8  bgt cr6, 0x82fc9310
	if ctx.cr[6].gt {
	pc = 0x82FC9310; continue 'dispatch;
	}
	// 82FC924C: 7D5F4050  subf r10, r31, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 82FC9250: 80FB0000  lwz r7, 0(r27)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9254: 7D244214  add r9, r4, r8
	ctx.r[9].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 82FC9258: 7CCAE214  add r6, r10, r28
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[28].u64;
	// 82FC925C: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9260: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 82FC9264: 7CA8F850  subf r5, r8, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[8].s64;
	// 82FC9268: 54C62036  slwi r6, r6, 4
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FC926C: 7D095214  add r8, r9, r10
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FC9270: 7D463A14  add r10, r6, r7
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FC9274: 39250001  addi r9, r5, 1
	ctx.r[9].s64 = ctx.r[5].s64 + 1;
	// 82FC9278: 80EA0004  lwz r7, 4(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC927C: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 82FC9280: 80AA0008  lwz r5, 8(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9284: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9288: 832A0000  lwz r25, 0(r10)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC928C: C14BFFF8  lfs f10, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9290: 83AA000C  lwz r29, 0xc(r10)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9294: C12BFFFC  lfs f9, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9298: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC929C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC92A0: 90E60004  stw r7, 4(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FC92A4: C0EB0004  lfs f7, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC92A8: 90A60008  stw r5, 8(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 82FC92AC: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC92B0: 93260000  stw r25, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 82FC92B4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 82FC92B8: 93A6000C  stw r29, 0xc(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 82FC92BC: C0610050  lfs f3, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC92C0: C081005C  lfs f4, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC92C4: C0C10054  lfs f6, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC92C8: C0A10058  lfs f5, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC92CC: EDA602F2  fmuls f13, f6, f11
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC92D0: ED8502F2  fmuls f12, f5, f11
	ctx.f[12].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC92D4: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC92D8: EC0302F2  fmuls f0, f3, f11
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC92DC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC92E0: ED6402F2  fmuls f11, f4, f11
	ctx.f[11].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FC92E4: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC92E8: EC29682A  fadds f1, f9, f13
	ctx.f[1].f64 = ((ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC92EC: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC92F0: D02BFFFC  stfs f1, -4(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC92F4: EC4A002A  fadds f2, f10, f0
	ctx.f[2].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC92F8: D04BFFF8  stfs f2, -8(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC92FC: EC08602A  fadds f0, f8, f12
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC9300: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9304: EDA7582A  fadds f13, f7, f11
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC9308: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC930C: 4082FF6C  bne 0x82fc9278
	if !ctx.cr[0].eq {
	pc = 0x82FC9278; continue 'dispatch;
	}
	// 82FC9310: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FC9314: 38630010  addi r3, r3, 0x10
	ctx.r[3].s64 = ctx.r[3].s64 + 16;
	// 82FC9318: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC931C: 38840004  addi r4, r4, 4
	ctx.r[4].s64 = ctx.r[4].s64 + 4;
	// 82FC9320: 4082FCAC  bne 0x82fc8fcc
	if !ctx.cr[0].eq {
	pc = 0x82FC8FCC; continue 'dispatch;
	}
	// 82FC9324: 38210100  addi r1, r1, 0x100
	ctx.r[1].s64 = ctx.r[1].s64 + 256;
	// 82FC9328: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 82FC932C: 481DEE78  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC9330 size=912
    let mut pc: u32 = 0x82FC9330;
    'dispatch: loop {
        match pc {
            0x82FC9330 => {
    //   block [0x82FC9330..0x82FC96C0)
	// 82FC9330: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC9334: 481DEE0D  bl 0x831a8140
	ctx.lr = 0x82FC9338;
	sub_831A8130(ctx, base);
	// 82FC9338: 9421FF10  stwu r1, -0xf0(r1)
	ea = ctx.r[1].u32.wrapping_add(-240 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC933C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FC9340: FD800890  fmr f12, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].f64 = ctx.f[1].f64;
	// 82FC9344: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82FC9348: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 82FC934C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FC9350: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 82FC9354: 4BFFEF45  bl 0x82fc8298
	ctx.lr = 0x82FC9358;
	sub_82FC8298(ctx, base);
	// 82FC9358: 38E10060  addi r7, r1, 0x60
	ctx.r[7].s64 = ctx.r[1].s64 + 96;
	// 82FC935C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FC9360: 4BFFEFA9  bl 0x82fc8308
	ctx.lr = 0x82FC9364;
	sub_82FC8308(ctx, base);
	// 82FC9364: 7D25F050  subf r9, r5, r30
	ctx.r[9].s64 = ctx.r[30].s64 - ctx.r[5].s64;
	// 82FC9368: 811C0000  lwz r8, 0(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC936C: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82FC9370: 552B2036  slwi r11, r9, 4
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC9374: C0010060  lfs f0, 0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9378: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 82FC937C: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FC9380: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FC9384: 2F050004  cmpwi cr6, r5, 4
	ctx.cr[6].compare_i32(ctx.r[5].s32, 4, &mut ctx.xer);
	// 82FC9388: 808B0000  lwz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC938C: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9390: 83AB0008  lwz r29, 8(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9394: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9398: 90870000  stw r4, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC939C: 90670004  stw r3, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FC93A0: 93A70008  stw r29, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82FC93A4: 9167000C  stw r11, 0xc(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82FC93A8: C1410058  lfs f10, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC93AC: C121005C  lfs f9, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC93B0: C1010050  lfs f8, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC93B4: C1610054  lfs f11, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC93B8: ECCB0032  fmuls f6, f11, f0
	ctx.f[6].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC93BC: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC93C0: D0E10050  stfs f7, 0x50(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC93C4: ECAA0032  fmuls f5, f10, f0
	ctx.f[5].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC93C8: D0C10054  stfs f6, 0x54(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC93CC: EC890032  fmuls f4, f9, f0
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC93D0: D0A10058  stfs f5, 0x58(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC93D4: D081005C  stfs f4, 0x5c(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC93D8: 80860000  lwz r4, 0(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC93DC: 80660004  lwz r3, 4(r6)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC93E0: 81660008  lwz r11, 8(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC93E4: 80E6000C  lwz r7, 0xc(r6)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC93E8: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FC93EC: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FC93F0: 907F0004  stw r3, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FC93F4: 909F0000  stw r4, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FC93F8: 419801F8  blt cr6, 0x82fc95f0
	if ctx.cr[6].lt {
	pc = 0x82FC95F0; continue 'dispatch;
	}
	// 82FC93FC: 39690003  addi r11, r9, 3
	ctx.r[11].s64 = ctx.r[9].s64 + 3;
	// 82FC9400: C01F0000  lfs f0, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9404: 54AA003A  rlwinm r10, r5, 0, 0, 0x1d
	ctx.r[10].u64 = ctx.r[5].u32 as u64 & 0xFFFFFFFFu64;
	// 82FC9408: C1BF0004  lfs f13, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC940C: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC9410: C19F0008  lfs f12, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9414: C17F000C  lfs f11, 0xc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9418: 39210068  addi r9, r1, 0x68
	ctx.r[9].s64 = ctx.r[1].s64 + 104;
	// 82FC941C: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FC9420: 54A7F0BE  srwi r7, r5, 2
	ctx.r[7].u32 = ctx.r[5].u32.wrapping_shr(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC9424: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC9428: 836BFFE0  lwz r27, -0x20(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-32 as u32) ) } as u64;
	// 82FC942C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FC9430: 80CBFFE4  lwz r6, -0x1c(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-28 as u32) ) } as u64;
	// 82FC9434: 3BA10050  addi r29, r1, 0x50
	ctx.r[29].s64 = ctx.r[1].s64 + 80;
	// 82FC9438: 806BFFE8  lwz r3, -0x18(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24 as u32) ) } as u64;
	// 82FC943C: C0E9FFFC  lfs f7, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9440: 838BFFEC  lwz r28, -0x14(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FC9444: 3B410050  addi r26, r1, 0x50
	ctx.r[26].s64 = ctx.r[1].s64 + 80;
	// 82FC9448: 832BFFF0  lwz r25, -0x10(r11)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FC944C: C0C90000  lfs f6, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC9450: 93640000  stw r27, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82FC9454: C0A90004  lfs f5, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9458: 90C40004  stw r6, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82FC945C: 38CB0010  addi r6, r11, 0x10
	ctx.r[6].s64 = ctx.r[11].s64 + 16;
	// 82FC9460: 90640008  stw r3, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FC9464: 386BFFE0  addi r3, r11, -0x20
	ctx.r[3].s64 = ctx.r[11].s64 + -32;
	// 82FC9468: 9384000C  stw r28, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 82FC946C: C041005C  lfs f2, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC9470: 806BFFF4  lwz r3, -0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FC9474: C0210050  lfs f1, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC9478: 838BFFF8  lwz r28, -8(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FC947C: ED4101F2  fmuls f10, f1, f7
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9480: C0610058  lfs f3, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC9484: 836BFFFC  lwz r27, -4(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FC9488: C0810054  lfs f4, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC948C: ED2401F2  fmuls f9, f4, f7
	ctx.f[9].f64 = (((ctx.f[4].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9490: ED0301F2  fmuls f8, f3, f7
	ctx.f[8].f64 = (((ctx.f[3].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9494: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9498: ECE201F2  fmuls f7, f2, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC949C: D1210054  stfs f9, 0x54(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC94A0: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC94A4: 830B0000  lwz r24, 0(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC94A8: D0E1005C  stfs f7, 0x5c(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC94AC: 933D0000  stw r25, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 82FC94B0: 907D0004  stw r3, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FC94B4: ED40502A  fadds f10, f0, f10
	ctx.f[10].f64 = ((ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FC94B8: 939D0008  stw r28, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 82FC94BC: ED2D482A  fadds f9, f13, f9
	ctx.f[9].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FC94C0: 937D000C  stw r27, 0xc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[27].u32 ) };
	// 82FC94C4: C0610058  lfs f3, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC94C8: C0210050  lfs f1, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC94CC: 82EB0004  lwz r23, 4(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC94D0: C041005C  lfs f2, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC94D4: 82CB0008  lwz r22, 8(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC94D8: 82AB000C  lwz r21, 0xc(r11)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC94DC: C0810054  lfs f4, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC94E0: ED0C402A  fadds f8, f12, f8
	ctx.f[8].f64 = ((ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FC94E4: 82860000  lwz r20, 0(r6)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC94E8: ECEB382A  fadds f7, f11, f7
	ctx.f[7].f64 = ((ctx.f[11].f64 + ctx.f[7].f64) as f32) as f64;
	// 82FC94EC: 82660004  lwz r19, 4(r6)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC94F0: EDA401B2  fmuls f13, f4, f6
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC94F4: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC94F8: ED8301B2  fmuls f12, f3, f6
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC94FC: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9500: ED6201B2  fmuls f11, f2, f6
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9504: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9508: EC0101B2  fmuls f0, f1, f6
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC950C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9510: 931A0000  stw r24, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FC9514: EC29682A  fadds f1, f9, f13
	ctx.f[1].f64 = ((ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC9518: 92FA0004  stw r23, 4(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(4 as u32), ctx.r[23].u32 ) };
	// 82FC951C: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FC9520: 92DA0008  stw r22, 8(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(8 as u32), ctx.r[22].u32 ) };
	// 82FC9524: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FC9528: 92BA000C  stw r21, 0xc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[21].u32 ) };
	// 82FC952C: C0610058  lfs f3, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC9530: C0410050  lfs f2, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FC9534: 82460008  lwz r18, 8(r6)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9538: C0810054  lfs f4, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC953C: EDA40172  fmuls f13, f4, f5
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC9540: ECCA002A  fadds f6, f10, f0
	ctx.f[6].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC9544: C141005C  lfs f10, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9548: ED28602A  fadds f9, f8, f12
	ctx.f[9].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC954C: 80C6000C  lwz r6, 0xc(r6)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9550: EC020172  fmuls f0, f2, f5
	ctx.f[0].f64 = (((ctx.f[2].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC9554: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9558: ED830172  fmuls f12, f3, f5
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC955C: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9560: ED07582A  fadds f8, f7, f11
	ctx.f[8].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC9564: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9568: ED6A0172  fmuls f11, f10, f5
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC956C: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9570: 92840000  stw r20, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 82FC9574: 92640004  stw r19, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[19].u32 ) };
	// 82FC9578: ECA1682A  fadds f5, f1, f13
	ctx.f[5].f64 = ((ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC957C: 92440008  stw r18, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[18].u32 ) };
	// 82FC9580: C0E90008  lfs f7, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9584: 90C4000C  stw r6, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FC9588: C0610058  lfs f3, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC958C: C0210050  lfs f1, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC9590: EC49602A  fadds f2, f9, f12
	ctx.f[2].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC9594: C141005C  lfs f10, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9598: ECC6002A  fadds f6, f6, f0
	ctx.f[6].f64 = ((ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC959C: C0810054  lfs f4, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC95A0: ED28582A  fadds f9, f8, f11
	ctx.f[9].f64 = ((ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC95A4: EDA401F2  fmuls f13, f4, f7
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC95A8: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC95AC: EC0101F2  fmuls f0, f1, f7
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC95B0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC95B4: ED8301F2  fmuls f12, f3, f7
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC95B8: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC95BC: ED6A01F2  fmuls f11, f10, f7
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC95C0: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC95C4: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FC95C8: EDA5682A  fadds f13, f5, f13
	ctx.f[13].f64 = ((ctx.f[5].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FC95CC: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FC95D0: EC06002A  fadds f0, f6, f0
	ctx.f[0].f64 = ((ctx.f[6].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FC95D4: ED82602A  fadds f12, f2, f12
	ctx.f[12].f64 = ((ctx.f[2].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FC95D8: ED69582A  fadds f11, f9, f11
	ctx.f[11].f64 = ((ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FC95DC: 4082FE4C  bne 0x82fc9428
	if !ctx.cr[0].eq {
	pc = 0x82FC9428; continue 'dispatch;
	}
	// 82FC95E0: D01F0000  stfs f0, 0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC95E4: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC95E8: D19F0008  stfs f12, 8(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC95EC: D17F000C  stfs f11, 0xc(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC95F0: 7F0A2800  cmpw cr6, r10, r5
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FC95F4: 419900C0  bgt cr6, 0x82fc96b4
	if ctx.cr[6].gt {
	pc = 0x82FC96B4; continue 'dispatch;
	}
	// 82FC95F8: 7D655050  subf r11, r5, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[5].s64;
	// 82FC95FC: C01F0000  lfs f0, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9600: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9604: C1BF0004  lfs f13, 4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9608: 7CEBF214  add r7, r11, r30
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82FC960C: C19F0008  lfs f12, 8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9610: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 82FC9614: C17F000C  lfs f11, 0xc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9618: 54E72036  slwi r7, r7, 4
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FC961C: 7D4A2850  subf r10, r10, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[10].s64;
	// 82FC9620: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82FC9624: 7D674214  add r11, r7, r8
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FC9628: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC962C: 80CB0004  lwz r6, 4(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9630: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82FC9634: 808B000C  lwz r4, 0xc(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9638: C0E90000  lfs f7, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC963C: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9640: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC9644: 80AB0008  lwz r5, 8(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9648: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC964C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FC9650: 90C70004  stw r6, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82FC9654: 9087000C  stw r4, 0xc(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FC9658: 91070000  stw r8, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FC965C: 90A70008  stw r5, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 82FC9660: C0A10058  lfs f5, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9664: ED0501F2  fmuls f8, f5, f7
	ctx.f[8].f64 = (((ctx.f[5].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9668: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC966C: C0610050  lfs f3, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC9670: ED8C402A  fadds f12, f12, f8
	ctx.f[12].f64 = ((ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FC9674: C081005C  lfs f4, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC9678: C0C10054  lfs f6, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC967C: ED2601F2  fmuls f9, f6, f7
	ctx.f[9].f64 = (((ctx.f[6].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9680: ED4301F2  fmuls f10, f3, f7
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9684: D1210054  stfs f9, 0x54(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9688: ECE401F2  fmuls f7, f4, f7
	ctx.f[7].f64 = (((ctx.f[4].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC968C: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9690: D0E1005C  stfs f7, 0x5c(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9694: EDAD482A  fadds f13, f13, f9
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FC9698: EC00502A  fadds f0, f0, f10
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FC969C: ED6B382A  fadds f11, f11, f7
	ctx.f[11].f64 = ((ctx.f[11].f64 + ctx.f[7].f64) as f32) as f64;
	// 82FC96A0: 4082FF8C  bne 0x82fc962c
	if !ctx.cr[0].eq {
	pc = 0x82FC962C; continue 'dispatch;
	}
	// 82FC96A4: D01F0000  stfs f0, 0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC96A8: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC96AC: D19F0008  stfs f12, 8(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC96B0: D17F000C  stfs f11, 0xc(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC96B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FC96B8: 382100F0  addi r1, r1, 0xf0
	ctx.r[1].s64 = ctx.r[1].s64 + 240;
	// 82FC96BC: 481DEAD4  b 0x831a8190
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC96C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC96C0 size=132
    let mut pc: u32 = 0x82FC96C0;
    'dispatch: loop {
        match pc {
            0x82FC96C0 => {
    //   block [0x82FC96C0..0x82FC9744)
	// 82FC96C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC96C4: 481DEA99  bl 0x831a815c
	ctx.lr = 0x82FC96C8;
	sub_831A8130(ctx, base);
	// 82FC96C8: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC96CC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FC96D0: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82FC96D4: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82FC96D8: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 82FC96DC: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FC96E0: 4198005C  blt cr6, 0x82fc973c
	if ctx.cr[6].lt {
	pc = 0x82FC973C; continue 'dispatch;
	}
	// 82FC96E4: 83A80000  lwz r29, 0(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC96E8: 3BC70001  addi r30, r7, 1
	ctx.r[30].s64 = ctx.r[7].s64 + 1;
	// 82FC96EC: 83E90000  lwz r31, 0(r9)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC96F0: 7F27CB78  mr r7, r25
	ctx.r[7].u64 = ctx.r[25].u64;
	// 82FC96F4: C03D0000  lfs f1, 0(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FC96F8: 7F46D378  mr r6, r26
	ctx.r[6].u64 = ctx.r[26].u64;
	// 82FC96FC: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82FC9700: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FC9704: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FC9708: 4BFFFC29  bl 0x82fc9330
	ctx.lr = 0x82FC970C;
	sub_82FC9330(ctx, base);
	// 82FC970C: C0030000  lfs f0, 0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9710: D01F0000  stfs f0, 0(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9714: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FC9718: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC971C: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 82FC9720: D1BF0004  stfs f13, 4(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC9724: C1830008  lfs f12, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9728: D19F0008  stfs f12, 8(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FC972C: C163000C  lfs f11, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9730: D17F000C  stfs f11, 0xc(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FC9734: 3BFF0010  addi r31, r31, 0x10
	ctx.r[31].s64 = ctx.r[31].s64 + 16;
	// 82FC9738: 4082FFB8  bne 0x82fc96f0
	if !ctx.cr[0].eq {
	pc = 0x82FC96F0; continue 'dispatch;
	}
	// 82FC973C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 82FC9740: 481DEA6C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9748(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9748 size=44
    let mut pc: u32 = 0x82FC9748;
    'dispatch: loop {
        match pc {
            0x82FC9748 => {
    //   block [0x82FC9748..0x82FC9774)
	// 82FC9748: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC974C: 54A8103A  slwi r8, r5, 2
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC9750: 7CA70E70  srawi r7, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 82FC9754: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FC9758: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 82FC975C: 7D670194  addze r11, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[11].s64 = tmp.s64;
	// 82FC9760: 7C084C2E  lfsx f0, r8, r9
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9764: FF000800  fcmpu cr6, f0, f1
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[1].f64);
	// 82FC9768: 4098000C  bge cr6, 0x82fc9774
	if !ctx.cr[6].lt {
		sub_82FC9774(ctx, base);
		return;
	}
	// 82FC976C: 38650001  addi r3, r5, 1
	ctx.r[3].s64 = ctx.r[5].s64 + 1;
	// 82FC9770: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9774(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9774 size=20
    let mut pc: u32 = 0x82FC9774;
    'dispatch: loop {
        match pc {
            0x82FC9774 => {
    //   block [0x82FC9774..0x82FC9788)
	// 82FC9774: C0090000  lfs f0, 0(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9778: FF000800  fcmpu cr6, f0, f1
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[1].f64);
	// 82FC977C: 4198000C  blt cr6, 0x82fc9788
	if ctx.cr[6].lt {
		sub_82FC9788(ctx, base);
		return;
	}
	// 82FC9780: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FC9784: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9788 size=8
    let mut pc: u32 = 0x82FC9788;
    'dispatch: loop {
        match pc {
            0x82FC9788 => {
    //   block [0x82FC9788..0x82FC9790)
	// 82FC9788: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FC978C: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9790(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9790 size=24
    let mut pc: u32 = 0x82FC9790;
    'dispatch: loop {
        match pc {
            0x82FC9790 => {
    //   block [0x82FC9790..0x82FC97A8)
	// 82FC9790: 5568103A  slwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC9794: 7C084C2E  lfsx f0, r8, r9
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9798: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FC979C: 4199000C  bgt cr6, 0x82fc97a8
	if ctx.cr[6].gt {
		sub_82FC97A8(ctx, base);
		return;
	}
	// 82FC97A0: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FC97A4: 48000008  b 0x82fc97ac
	sub_82FC97A8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC97A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC97A8 size=28
    let mut pc: u32 = 0x82FC97A8;
    'dispatch: loop {
        match pc {
            0x82FC97A8 => {
    //   block [0x82FC97A8..0x82FC97C4)
	// 82FC97A8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 82FC97AC: 7D635214  add r11, r3, r10
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[10].u64;
	// 82FC97B0: 7D680E70  srawi r8, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FC97B4: 7D680194  addze r11, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[11].s64 = tmp.s64;
	// 82FC97B8: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FC97BC: 409AFFD4  bne cr6, 0x82fc9790
	if !ctx.cr[6].eq {
		sub_82FC9790(ctx, base);
		return;
	}
	// 82FC97C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC97C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC97C8 size=136
    let mut pc: u32 = 0x82FC97C8;
    'dispatch: loop {
        match pc {
            0x82FC97C8 => {
    //   block [0x82FC97C8..0x82FC9850)
	// 82FC97C8: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FC97CC: 7F032000  cmpw cr6, r3, r4
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC97D0: 41990038  bgt cr6, 0x82fc9808
	if ctx.cr[6].gt {
	pc = 0x82FC9808; continue 'dispatch;
	}
	// 82FC97D4: 81250000  lwz r9, 0(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC97D8: 546B103A  slwi r11, r3, 2
	ctx.r[11].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC97DC: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FC97E0: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FC97E4: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC97E8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC97EC: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC97F0: 409A0018  bne cr6, 0x82fc9808
	if !ctx.cr[6].eq {
	pc = 0x82FC9808; continue 'dispatch;
	}
	// 82FC97F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC97F8: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC97FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC9800: 7F0A2000  cmpw cr6, r10, r4
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC9804: 4099FFE4  ble cr6, 0x82fc97e8
	if !ctx.cr[6].gt {
	pc = 0x82FC97E8; continue 'dispatch;
	}
	// 82FC9808: 3563FFFF  addic. r11, r3, -1
	ctx.xer.ca = (ctx.r[3].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[3].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FC980C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FC9810: 41800034  blt 0x82fc9844
	if ctx.cr[0].lt {
	pc = 0x82FC9844; continue 'dispatch;
	}
	// 82FC9814: 81050000  lwz r8, 0(r5)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9818: 5466103A  slwi r6, r3, 2
	ctx.r[6].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FC981C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 82FC9820: 7C06442E  lfsx f0, r6, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9824: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9828: 7DA9442E  lfsx f13, r9, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC982C: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC9830: 409A0014  bne cr6, 0x82fc9844
	if !ctx.cr[6].eq {
	pc = 0x82FC9844; continue 'dispatch;
	}
	// 82FC9834: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FC9838: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC983C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 82FC9840: 4080FFE4  bge 0x82fc9824
	if !ctx.cr[0].lt {
	pc = 0x82FC9824; continue 'dispatch;
	}
	// 82FC9844: 7D6A3A14  add r11, r10, r7
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 82FC9848: 386BFFFF  addi r3, r11, -1
	ctx.r[3].s64 = ctx.r[11].s64 + -1;
	// 82FC984C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9850(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9850 size=184
    let mut pc: u32 = 0x82FC9850;
    'dispatch: loop {
        match pc {
            0x82FC9850 => {
    //   block [0x82FC9850..0x82FC9908)
	// 82FC9850: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FC9854: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FC9858: 2F040004  cmpwi cr6, r4, 4
	ctx.cr[6].compare_i32(ctx.r[4].s32, 4, &mut ctx.xer);
	// 82FC985C: 4198006C  blt cr6, 0x82fc98c8
	if ctx.cr[6].lt {
	pc = 0x82FC98C8; continue 'dispatch;
	}
	// 82FC9860: 3944FFFC  addi r10, r4, -4
	ctx.r[10].s64 = ctx.r[4].s64 + -4;
	// 82FC9864: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9868: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC986C: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82FC9870: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FC9874: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FC9878: C1ABFFFC  lfs f13, -4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC987C: C00BFFF8  lfs f0, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9880: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC9884: 419A0008  beq cr6, 0x82fc988c
	if ctx.cr[6].eq {
	pc = 0x82FC988C; continue 'dispatch;
	}
	// 82FC9888: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC988C: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9890: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9894: 419A0008  beq cr6, 0x82fc989c
	if ctx.cr[6].eq {
	pc = 0x82FC989C; continue 'dispatch;
	}
	// 82FC9898: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC989C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC98A0: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC98A4: 419A0008  beq cr6, 0x82fc98ac
	if ctx.cr[6].eq {
	pc = 0x82FC98AC; continue 'dispatch;
	}
	// 82FC98A8: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC98AC: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC98B0: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC98B4: 419A0008  beq cr6, 0x82fc98bc
	if ctx.cr[6].eq {
	pc = 0x82FC98BC; continue 'dispatch;
	}
	// 82FC98B8: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC98BC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC98C0: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC98C4: 4082FFB4  bne 0x82fc9878
	if !ctx.cr[0].eq {
	pc = 0x82FC9878; continue 'dispatch;
	}
	// 82FC98C8: 7F082000  cmpw cr6, r8, r4
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC98CC: 40980034  bge cr6, 0x82fc9900
	if !ctx.cr[6].lt {
	pc = 0x82FC9900; continue 'dispatch;
	}
	// 82FC98D0: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC98D4: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC98D8: 7D482050  subf r10, r8, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FC98DC: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FC98E0: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC98E4: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC98E8: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC98EC: 419A0008  beq cr6, 0x82fc98f4
	if ctx.cr[6].eq {
	pc = 0x82FC98F4; continue 'dispatch;
	}
	// 82FC98F0: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FC98F4: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC98F8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC98FC: 4082FFE4  bne 0x82fc98e0
	if !ctx.cr[0].eq {
	pc = 0x82FC98E0; continue 'dispatch;
	}
	// 82FC9900: 38670001  addi r3, r7, 1
	ctx.r[3].s64 = ctx.r[7].s64 + 1;
	// 82FC9904: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9908(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9908 size=24
    let mut pc: u32 = 0x82FC9908;
    'dispatch: loop {
        match pc {
            0x82FC9908 => {
    //   block [0x82FC9908..0x82FC9920)
	// 82FC9908: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC990C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FC9910: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82FC9914: 91440004  stw r10, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FC9918: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FC991C: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9920(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9920 size=44
    let mut pc: u32 = 0x82FC9920;
    'dispatch: loop {
        match pc {
            0x82FC9920 => {
    //   block [0x82FC9920..0x82FC994C)
	// 82FC9920: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC9924: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9928: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FC992C: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FC9930: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC9934: C0090004  lfs f0, 4(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9938: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC993C: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9940: 7F0B4800  cmpw cr6, r11, r9
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FC9944: 4198FFE0  blt cr6, 0x82fc9924
	if ctx.cr[6].lt {
	pc = 0x82FC9924; continue 'dispatch;
	}
	// 82FC9948: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9950(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9950 size=72
    let mut pc: u32 = 0x82FC9950;
    'dispatch: loop {
        match pc {
            0x82FC9950 => {
    //   block [0x82FC9950..0x82FC9998)
	// 82FC9950: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9954: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FC9958: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 82FC995C: 91440004  stw r10, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FC9960: 7F035000  cmpw cr6, r3, r10
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FC9964: 4098002C  bge cr6, 0x82fc9990
	if !ctx.cr[6].lt {
	pc = 0x82FC9990; continue 'dispatch;
	}
	// 82FC9968: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC996C: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9970: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FC9974: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FC9978: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC997C: 81090004  lwz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9980: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FC9984: 80E40004  lwz r7, 4(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9988: 7F0B3800  cmpw cr6, r11, r7
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[7].s32, &mut ctx.xer);
	// 82FC998C: 4198FFE0  blt cr6, 0x82fc996c
	if ctx.cr[6].lt {
	pc = 0x82FC996C; continue 'dispatch;
	}
	// 82FC9990: 7F032800  cmpw cr6, r3, r5
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FC9994: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9998 size=44
    let mut pc: u32 = 0x82FC9998;
    'dispatch: loop {
        match pc {
            0x82FC9998 => {
    //   block [0x82FC9998..0x82FC99C4)
	// 82FC9998: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC999C: 7D632850  subf r11, r3, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[3].s64;
	// 82FC99A0: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC99A4: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FC99A8: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FC99AC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC99B0: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC99B4: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82FC99B8: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FC99BC: 4082FFE4  bne 0x82fc99a0
	if !ctx.cr[0].eq {
	pc = 0x82FC99A0; continue 'dispatch;
	}
	// 82FC99C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC99C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC99C8 size=52
    let mut pc: u32 = 0x82FC99C8;
    'dispatch: loop {
        match pc {
            0x82FC99C8 => {
    //   block [0x82FC99C8..0x82FC99FC)
	// 82FC99C8: 7F043000  cmpw cr6, r4, r6
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FC99CC: 419A0024  beq cr6, 0x82fc99f0
	if ctx.cr[6].eq {
	pc = 0x82FC99F0; continue 'dispatch;
	}
	// 82FC99D0: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC99D4: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC99D8: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FC99DC: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC99E0: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC99E4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FC99E8: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FC99EC: 419A0008  beq cr6, 0x82fc99f4
	if ctx.cr[6].eq {
	pc = 0x82FC99F4; continue 'dispatch;
	}
	// 82FC99F0: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FC99F4: 99630000  stb r11, 0(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FC99F8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9A00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9A00 size=16
    let mut pc: u32 = 0x82FC9A00;
    'dispatch: loop {
        match pc {
            0x82FC9A00 => {
    //   block [0x82FC9A00..0x82FC9A10)
	// 82FC9A00: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82FC9A04: 4199000C  bgt cr6, 0x82fc9a10
	if ctx.cr[6].gt {
		sub_82FC9A10(ctx, base);
		return;
	}
	// 82FC9A08: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FC9A0C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9A10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9A10 size=140
    let mut pc: u32 = 0x82FC9A10;
    'dispatch: loop {
        match pc {
            0x82FC9A10 => {
    //   block [0x82FC9A10..0x82FC9A9C)
	// 82FC9A10: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9A14: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 82FC9A18: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FC9A1C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FC9A20: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FC9A24: C0080000  lfs f0, 0(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9A28: 4198006C  blt cr6, 0x82fc9a94
	if ctx.cr[6].lt {
	pc = 0x82FC9A94; continue 'dispatch;
	}
	// 82FC9A2C: 3924FFFD  addi r9, r4, -3
	ctx.r[9].s64 = ctx.r[4].s64 + -3;
	// 82FC9A30: 3948000C  addi r10, r8, 0xc
	ctx.r[10].s64 = ctx.r[8].s64 + 12;
	// 82FC9A34: C1AAFFF8  lfs f13, -8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9A38: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9A3C: 4098000C  bge cr6, 0x82fc9a48
	if !ctx.cr[6].lt {
	pc = 0x82FC9A48; continue 'dispatch;
	}
	// 82FC9A40: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9A44: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FC9A48: C1AAFFFC  lfs f13, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9A4C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9A50: 4098000C  bge cr6, 0x82fc9a5c
	if !ctx.cr[6].lt {
	pc = 0x82FC9A5C; continue 'dispatch;
	}
	// 82FC9A54: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9A58: 386B0001  addi r3, r11, 1
	ctx.r[3].s64 = ctx.r[11].s64 + 1;
	// 82FC9A5C: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9A60: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9A64: 4098000C  bge cr6, 0x82fc9a70
	if !ctx.cr[6].lt {
	pc = 0x82FC9A70; continue 'dispatch;
	}
	// 82FC9A68: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9A6C: 386B0002  addi r3, r11, 2
	ctx.r[3].s64 = ctx.r[11].s64 + 2;
	// 82FC9A70: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9A74: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9A78: 4098000C  bge cr6, 0x82fc9a84
	if !ctx.cr[6].lt {
	pc = 0x82FC9A84; continue 'dispatch;
	}
	// 82FC9A7C: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9A80: 386B0003  addi r3, r11, 3
	ctx.r[3].s64 = ctx.r[11].s64 + 3;
	// 82FC9A84: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC9A88: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC9A8C: 7F0B4800  cmpw cr6, r11, r9
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FC9A90: 4198FFA4  blt cr6, 0x82fc9a34
	if ctx.cr[6].lt {
	pc = 0x82FC9A34; continue 'dispatch;
	}
	// 82FC9A94: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC9A98: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9A9C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9A9C size=48
    let mut pc: u32 = 0x82FC9A9C;
    'dispatch: loop {
        match pc {
            0x82FC9A9C => {
    //   block [0x82FC9A9C..0x82FC9ACC)
	// 82FC9A9C: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC9AA0: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FC9AA4: C1AA0000  lfs f13, 0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9AA8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9AAC: 4098000C  bge cr6, 0x82fc9ab8
	if !ctx.cr[6].lt {
	pc = 0x82FC9AB8; continue 'dispatch;
	}
	// 82FC9AB0: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9AB4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FC9AB8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FC9ABC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC9AC0: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC9AC4: 4198FFE0  blt cr6, 0x82fc9aa4
	if ctx.cr[6].lt {
	pc = 0x82FC9AA4; continue 'dispatch;
	}
	// 82FC9AC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9AD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FC9AD0 size=16
    let mut pc: u32 = 0x82FC9AD0;
    'dispatch: loop {
        match pc {
            0x82FC9AD0 => {
    //   block [0x82FC9AD0..0x82FC9AE0)
	// 82FC9AD0: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82FC9AD4: 4199000C  bgt cr6, 0x82fc9ae0
	if ctx.cr[6].gt {
		sub_82FC9AE0(ctx, base);
		return;
	}
	// 82FC9AD8: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FC9ADC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9AE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9AE0 size=140
    let mut pc: u32 = 0x82FC9AE0;
    'dispatch: loop {
        match pc {
            0x82FC9AE0 => {
    //   block [0x82FC9AE0..0x82FC9B6C)
	// 82FC9AE0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9AE4: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 82FC9AE8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FC9AEC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FC9AF0: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FC9AF4: C0080000  lfs f0, 0(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9AF8: 4198006C  blt cr6, 0x82fc9b64
	if ctx.cr[6].lt {
	pc = 0x82FC9B64; continue 'dispatch;
	}
	// 82FC9AFC: 3924FFFD  addi r9, r4, -3
	ctx.r[9].s64 = ctx.r[4].s64 + -3;
	// 82FC9B00: 3948000C  addi r10, r8, 0xc
	ctx.r[10].s64 = ctx.r[8].s64 + 12;
	// 82FC9B04: C1AAFFF8  lfs f13, -8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9B08: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9B0C: 4099000C  ble cr6, 0x82fc9b18
	if !ctx.cr[6].gt {
	pc = 0x82FC9B18; continue 'dispatch;
	}
	// 82FC9B10: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9B14: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FC9B18: C1AAFFFC  lfs f13, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9B1C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9B20: 4099000C  ble cr6, 0x82fc9b2c
	if !ctx.cr[6].gt {
	pc = 0x82FC9B2C; continue 'dispatch;
	}
	// 82FC9B24: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9B28: 386B0001  addi r3, r11, 1
	ctx.r[3].s64 = ctx.r[11].s64 + 1;
	// 82FC9B2C: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9B30: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9B34: 4099000C  ble cr6, 0x82fc9b40
	if !ctx.cr[6].gt {
	pc = 0x82FC9B40; continue 'dispatch;
	}
	// 82FC9B38: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9B3C: 386B0002  addi r3, r11, 2
	ctx.r[3].s64 = ctx.r[11].s64 + 2;
	// 82FC9B40: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9B44: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9B48: 4099000C  ble cr6, 0x82fc9b54
	if !ctx.cr[6].gt {
	pc = 0x82FC9B54; continue 'dispatch;
	}
	// 82FC9B4C: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9B50: 386B0003  addi r3, r11, 3
	ctx.r[3].s64 = ctx.r[11].s64 + 3;
	// 82FC9B54: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC9B58: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC9B5C: 7F0B4800  cmpw cr6, r11, r9
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FC9B60: 4198FFA4  blt cr6, 0x82fc9b04
	if ctx.cr[6].lt {
	pc = 0x82FC9B04; continue 'dispatch;
	}
	// 82FC9B64: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC9B68: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9B6C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9B6C size=48
    let mut pc: u32 = 0x82FC9B6C;
    'dispatch: loop {
        match pc {
            0x82FC9B6C => {
    //   block [0x82FC9B6C..0x82FC9B9C)
	// 82FC9B6C: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC9B70: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FC9B74: C1AA0000  lfs f13, 0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9B78: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FC9B7C: 4099000C  ble cr6, 0x82fc9b88
	if !ctx.cr[6].gt {
	pc = 0x82FC9B88; continue 'dispatch;
	}
	// 82FC9B80: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 82FC9B84: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FC9B88: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FC9B8C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FC9B90: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FC9B94: 4198FFE0  blt cr6, 0x82fc9b74
	if ctx.cr[6].lt {
	pc = 0x82FC9B74; continue 'dispatch;
	}
	// 82FC9B98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9BA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9BA0 size=36
    let mut pc: u32 = 0x82FC9BA0;
    'dispatch: loop {
        match pc {
            0x82FC9BA0 => {
    //   block [0x82FC9BA0..0x82FC9BC4)
	// 82FC9BA0: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9BA4: EDA00032  fmuls f13, f0, f0
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC9BA8: C1830000  lfs f12, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9BAC: C1630008  lfs f11, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9BB0: C143000C  lfs f10, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9BB4: ED2C6B3A  fmadds f9, f12, f12, f13
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FC9BB8: ED0B4AFA  fmadds f8, f11, f11, f9
	ctx.f[8].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FC9BBC: EC2A42BA  fmadds f1, f10, f10, f8
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC9BC0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9BC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9BC8 size=40
    let mut pc: u32 = 0x82FC9BC8;
    'dispatch: loop {
        match pc {
            0x82FC9BC8 => {
    //   block [0x82FC9BC8..0x82FC9BF0)
	// 82FC9BC8: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9BCC: EDA00032  fmuls f13, f0, f0
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC9BD0: C1830000  lfs f12, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9BD4: C1630008  lfs f11, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9BD8: C143000C  lfs f10, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9BDC: ED2C6B3A  fmadds f9, f12, f12, f13
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FC9BE0: ED0B4AFA  fmadds f8, f11, f11, f9
	ctx.f[8].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FC9BE4: ECEA42BA  fmadds f7, f10, f10, f8
	ctx.f[7].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC9BE8: EC20382C  fsqrts f1, f7
	ctx.f[1].f64 = ((ctx.f[7].f64).sqrt() as f32) as f64;
	// 82FC9BEC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9BF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9BF0 size=172
    let mut pc: u32 = 0x82FC9BF0;
    'dispatch: loop {
        match pc {
            0x82FC9BF0 => {
    //   block [0x82FC9BF0..0x82FC9C9C)
	// 82FC9BF0: C0040004  lfs f0, 4(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9BF4: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9BF8: EDA00032  fmuls f13, f0, f0
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC9BFC: C1840000  lfs f12, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9C00: 81440004  lwz r10, 4(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9C04: 3921FFF0  addi r9, r1, -0x10
	ctx.r[9].s64 = ctx.r[1].s64 + -16;
	// 82FC9C08: 81040008  lwz r8, 8(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9C0C: C1640008  lfs f11, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9C10: 80E4000C  lwz r7, 0xc(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9C14: C144000C  lfs f10, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9C18: 3CC08200  lis r6, -0x7e00
	ctx.r[6].s64 = -2113929216;
	// 82FC9C1C: 38A1FFF0  addi r5, r1, -0x10
	ctx.r[5].s64 = ctx.r[1].s64 + -16;
	// 82FC9C20: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC9C24: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FC9C28: 91090008  stw r8, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FC9C2C: 90E9000C  stw r7, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FC9C30: C121FFF0  lfs f9, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9C34: ED0C6B3A  fmadds f8, f12, f12, f13
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FC9C38: C0E1FFF4  lfs f7, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9C3C: C0C1FFF8  lfs f6, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC9C40: C0A1FFFC  lfs f5, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9C44: C00608A8  lfs f0, 0x8a8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9C48: EC8B42FA  fmadds f4, f11, f11, f8
	ctx.f[4].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC9C4C: EC6A22BA  fmadds f3, f10, f10, f4
	ctx.f[3].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC9C50: EC40182C  fsqrts f2, f3
	ctx.f[2].f64 = ((ctx.f[3].f64).sqrt() as f32) as f64;
	// 82FC9C54: EC201024  fdivs f1, f0, f2
	ctx.f[1].f64 = ((ctx.f[0].f64 / ctx.f[2].f64) as f32) as f64;
	// 82FC9C58: EC010272  fmuls f0, f1, f9
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FC9C5C: D001FFF0  stfs f0, -0x10(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FC9C60: EDA101F2  fmuls f13, f1, f7
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FC9C64: D1A1FFF4  stfs f13, -0xc(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FC9C68: ED8101B2  fmuls f12, f1, f6
	ctx.f[12].f64 = (((ctx.f[1].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9C6C: D181FFF8  stfs f12, -8(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FC9C70: ED610172  fmuls f11, f1, f5
	ctx.f[11].f64 = (((ctx.f[1].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FC9C74: D161FFFC  stfs f11, -4(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC9C78: 8165000C  lwz r11, 0xc(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9C7C: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9C80: 81250004  lwz r9, 4(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9C84: 80850008  lwz r4, 8(r5)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9C88: 90830008  stw r4, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FC9C8C: 91230004  stw r9, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC9C90: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FC9C94: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82FC9C98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9CA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9CA0 size=108
    let mut pc: u32 = 0x82FC9CA0;
    'dispatch: loop {
        match pc {
            0x82FC9CA0 => {
    //   block [0x82FC9CA0..0x82FC9D0C)
	// 82FC9CA0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9CA4: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC9CA8: 81230004  lwz r9, 4(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9CAC: C0040004  lfs f0, 4(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9CB0: 81030008  lwz r8, 8(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9CB4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9CB8: 80E3000C  lwz r7, 0xc(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9CBC: C1840008  lfs f12, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9CC0: C164000C  lfs f11, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9CC4: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC9CC8: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC9CCC: 910A0008  stw r8, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FC9CD0: 90EA000C  stw r7, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FC9CD4: C141FFF0  lfs f10, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9CD8: C121FFF8  lfs f9, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9CDC: C101FFFC  lfs f8, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9CE0: C0E1FFF4  lfs f7, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9CE4: ECC70028  fsubs f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC9CE8: ECAA6828  fsubs f5, f10, f13
	ctx.f[5].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC9CEC: EC8601B2  fmuls f4, f6, f6
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9CF0: EC696028  fsubs f3, f9, f12
	ctx.f[3].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FC9CF4: EC485828  fsubs f2, f8, f11
	ctx.f[2].f64 = (((ctx.f[8].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FC9CF8: EC25217A  fmadds f1, f5, f5, f4
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC9CFC: EC0308FA  fmadds f0, f3, f3, f1
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FC9D00: EDA200BA  fmadds f13, f2, f2, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[2].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC9D04: EC20682C  fsqrts f1, f13
	ctx.f[1].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 82FC9D08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9D10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9D10 size=116
    let mut pc: u32 = 0x82FC9D10;
    'dispatch: loop {
        match pc {
            0x82FC9D10 => {
    //   block [0x82FC9D10..0x82FC9D84)
	// 82FC9D10: C1240000  lfs f9, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9D14: C0030004  lfs f0, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9D18: FCC04890  fmr f6, f9
	ctx.f[6].f64 = ctx.f[9].f64;
	// 82FC9D1C: C1A40004  lfs f13, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9D20: ED800032  fmuls f12, f0, f0
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC9D24: ED6D0372  fmuls f11, f13, f13
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FC9D28: C1430000  lfs f10, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9D2C: C0E40008  lfs f7, 8(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9D30: FC206890  fmr f1, f13
	ctx.f[1].f64 = ctx.f[13].f64;
	// 82FC9D34: FC403890  fmr f2, f7
	ctx.f[2].f64 = ctx.f[7].f64;
	// 82FC9D38: C1030008  lfs f8, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9D3C: C064000C  lfs f3, 0xc(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FC9D40: C083000C  lfs f4, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC9D44: ECAA01B2  fmuls f5, f10, f6
	ctx.f[5].f64 = (((ctx.f[10].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9D48: EDAA62BA  fmadds f13, f10, f10, f12
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FC9D4C: ED695A7A  fmadds f11, f9, f9, f11
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC9D50: FD801890  fmr f12, f3
	ctx.f[12].f64 = ctx.f[3].f64;
	// 82FC9D54: ED4828BA  fmadds f10, f8, f2, f5
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[2].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FC9D58: ED286A3A  fmadds f9, f8, f8, f13
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[8].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FC9D5C: ED0759FA  fmadds f8, f7, f7, f11
	ctx.f[8].f64 = (((ctx.f[7].f64 * ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FC9D60: ECE1503A  fmadds f7, f1, f0, f10
	ctx.f[7].f64 = (((ctx.f[1].f64 * ctx.f[0].f64 + ctx.f[10].f64) as f32) as f64);
	// 82FC9D64: ECC4493A  fmadds f6, f4, f4, f9
	ctx.f[6].f64 = (((ctx.f[4].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FC9D68: ECA340FA  fmadds f5, f3, f3, f8
	ctx.f[5].f64 = (((ctx.f[3].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FC9D6C: EC843B3A  fmadds f4, f4, f12, f7
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64);
	// 82FC9D70: EC60302C  fsqrts f3, f6
	ctx.f[3].f64 = ((ctx.f[6].f64).sqrt() as f32) as f64;
	// 82FC9D74: EC40282C  fsqrts f2, f5
	ctx.f[2].f64 = ((ctx.f[5].f64).sqrt() as f32) as f64;
	// 82FC9D78: EC2300B2  fmuls f1, f3, f2
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FC9D7C: EC240824  fdivs f1, f4, f1
	ctx.f[1].f64 = ((ctx.f[4].f64 / ctx.f[1].f64) as f32) as f64;
	// 82FC9D80: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9D88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FC9D88 size=520
    let mut pc: u32 = 0x82FC9D88;
    'dispatch: loop {
        match pc {
            0x82FC9D88 => {
    //   block [0x82FC9D88..0x82FC9F90)
	// 82FC9D88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FC9D8C: 481DE3DD  bl 0x831a8168
	ctx.lr = 0x82FC9D90;
	sub_831A8130(ctx, base);
	// 82FC9D90: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FC9D94: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82FC9D98: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FC9D9C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FC9DA0: 3BDD0001  addi r30, r29, 1
	ctx.r[30].s64 = ctx.r[29].s64 + 1;
	// 82FC9DA4: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9DA8: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FC9DAC: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FC9DB0: 40980024  bge cr6, 0x82fc9dd4
	if !ctx.cr[6].lt {
	pc = 0x82FC9DD4; continue 'dispatch;
	}
	// 82FC9DB4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC9DB8: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FC9DBC: 41980008  blt cr6, 0x82fc9dc4
	if ctx.cr[6].lt {
	pc = 0x82FC9DC4; continue 'dispatch;
	}
	// 82FC9DC0: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82FC9DC4: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FC9DC8: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FC9DCC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FC9DD0: 4BEDCA29  bl 0x82ea67f8
	ctx.lr = 0x82FC9DD4;
	sub_82EA67F8(ctx, base);
	// 82FC9DD4: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC9DD8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9DDC: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FC9DE0: 2F1D0001  cmpwi cr6, r29, 1
	ctx.cr[6].compare_i32(ctx.r[29].s32, 1, &mut ctx.xer);
	// 82FC9DE4: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9DE8: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9DEC: 419800B8  blt cr6, 0x82fc9ea4
	if ctx.cr[6].lt {
	pc = 0x82FC9EA4; continue 'dispatch;
	}
	// 82FC9DF0: 815C0000  lwz r10, 0(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9DF4: 39000004  li r8, 4
	ctx.r[8].s64 = 4;
	// 82FC9DF8: 7FA9EB78  mr r9, r29
	ctx.r[9].u64 = ctx.r[29].u64;
	// 82FC9DFC: 396A0010  addi r11, r10, 0x10
	ctx.r[11].s64 = ctx.r[10].s64 + 16;
	// 82FC9E00: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 82FC9E04: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9E08: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82FC9E0C: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9E10: C00AFFFC  lfs f0, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9E14: 806B0008  lwz r3, 8(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9E18: C1AAFFF8  lfs f13, -8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9E1C: 83CB000C  lwz r30, 0xc(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9E20: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9E24: C16A0004  lfs f11, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9E28: 80FF0000  lwz r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9E2C: 90C50000  stw r6, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82FC9E30: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FC9E34: 90850004  stw r4, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 82FC9E38: 7CE83A14  add r7, r8, r7
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82FC9E3C: 90650008  stw r3, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FC9E40: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC9E44: 93C5000C  stw r30, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[30].u32 ) };
	// 82FC9E48: C1410050  lfs f10, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9E4C: C1210058  lfs f9, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9E50: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FC9E54: C101005C  lfs f8, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9E58: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 82FC9E5C: C0E10054  lfs f7, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9E60: EC070028  fsubs f0, f7, f0
	ctx.f[0].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC9E64: EDAA6828  fsubs f13, f10, f13
	ctx.f[13].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC9E68: C0C7FFFC  lfs f6, -4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FC9E6C: ECA00032  fmuls f5, f0, f0
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FC9E70: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FC9E74: ED896028  fsubs f12, f9, f12
	ctx.f[12].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FC9E78: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FC9E7C: ED685828  fsubs f11, f8, f11
	ctx.f[11].f64 = (((ctx.f[8].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FC9E80: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FC9E84: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FC9E88: EC8D2B7A  fmadds f4, f13, f13, f5
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FC9E8C: EC6C233A  fmadds f3, f12, f12, f4
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC9E90: EC4B1AFA  fmadds f2, f11, f11, f3
	ctx.f[2].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FC9E94: EC20102C  fsqrts f1, f2
	ctx.f[1].f64 = ((ctx.f[2].f64).sqrt() as f32) as f64;
	// 82FC9E98: EC01302A  fadds f0, f1, f6
	ctx.f[0].f64 = ((ctx.f[1].f64 + ctx.f[6].f64) as f32) as f64;
	// 82FC9E9C: D0070000  stfs f0, 0(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FC9EA0: 4082FF64  bne 0x82fc9e04
	if !ctx.cr[0].eq {
	pc = 0x82FC9E04; continue 'dispatch;
	}
	// 82FC9EA4: 397DFFFF  addi r11, r29, -1
	ctx.r[11].s64 = ctx.r[29].s64 + -1;
	// 82FC9EA8: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82FC9EAC: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FC9EB0: 41980090  blt cr6, 0x82fc9f40
	if ctx.cr[6].lt {
	pc = 0x82FC9F40; continue 'dispatch;
	}
	// 82FC9EB4: 397DFFFB  addi r11, r29, -5
	ctx.r[11].s64 = ctx.r[29].s64 + -5;
	// 82FC9EB8: 57AA103A  slwi r10, r29, 2
	ctx.r[10].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FC9EBC: 5569F0BE  srwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9EC0: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 82FC9EC4: 38E90001  addi r7, r9, 1
	ctx.r[7].s64 = ctx.r[9].s64 + 1;
	// 82FC9EC8: 54E9103A  slwi r9, r7, 2
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9ECC: 38890001  addi r4, r9, 1
	ctx.r[4].s64 = ctx.r[9].s64 + 1;
	// 82FC9ED0: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9ED4: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 82FC9ED8: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FC9EDC: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9EE0: 7DAA442E  lfsx f13, r10, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9EE4: ED806824  fdivs f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 82FC9EE8: 7D8B452E  stfsx f12, r11, r8
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FC9EEC: 80DF0000  lwz r6, 0(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9EF0: 7D6A342E  lfsx f11, r10, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9EF4: 7D0B3214  add r8, r11, r6
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 82FC9EF8: C1480004  lfs f10, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9EFC: ED2A5824  fdivs f9, f10, f11
	ctx.f[9].f64 = ((ctx.f[10].f64 / ctx.f[11].f64) as f32) as f64;
	// 82FC9F00: D1280004  stfs f9, 4(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FC9F04: 80DF0000  lwz r6, 0(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9F08: 38A80004  addi r5, r8, 4
	ctx.r[5].s64 = ctx.r[8].s64 + 4;
	// 82FC9F0C: 7D093214  add r8, r9, r6
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 82FC9F10: 7D0A342E  lfsx f8, r10, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9F14: 38A8FFFC  addi r5, r8, -4
	ctx.r[5].s64 = ctx.r[8].s64 + -4;
	// 82FC9F18: C0E8FFFC  lfs f7, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9F1C: ECC74024  fdivs f6, f7, f8
	ctx.f[6].f64 = ((ctx.f[7].f64 / ctx.f[8].f64) as f32) as f64;
	// 82FC9F20: D0C8FFFC  stfs f6, -4(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FC9F24: 80DF0000  lwz r6, 0(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9F28: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FC9F2C: 7CA9342E  lfsx f5, r9, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FC9F30: 7C8A342E  lfsx f4, r10, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FC9F34: EC652024  fdivs f3, f5, f4
	ctx.f[3].f64 = ((ctx.f[5].f64 / ctx.f[4].f64) as f32) as f64;
	// 82FC9F38: 7C69352E  stfsx f3, r9, r6
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 82FC9F3C: 4082FF94  bne 0x82fc9ed0
	if !ctx.cr[0].eq {
	pc = 0x82FC9ED0; continue 'dispatch;
	}
	// 82FC9F40: 7F04E800  cmpw cr6, r4, r29
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FC9F44: 40980030  bge cr6, 0x82fc9f74
	if !ctx.cr[6].lt {
	pc = 0x82FC9F74; continue 'dispatch;
	}
	// 82FC9F48: 57A9103A  slwi r9, r29, 2
	ctx.r[9].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9F4C: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FC9F50: 7D44E850  subf r10, r4, r29
	ctx.r[10].s64 = ctx.r[29].s64 - ctx.r[4].s64;
	// 82FC9F54: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9F58: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FC9F5C: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9F60: 7DA84C2E  lfsx f13, r8, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9F64: ED806824  fdivs f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 82FC9F68: 7D8B452E  stfsx f12, r11, r8
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FC9F6C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FC9F70: 4082FFE4  bne 0x82fc9f54
	if !ctx.cr[0].eq {
	pc = 0x82FC9F54; continue 'dispatch;
	}
	// 82FC9F74: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FC9F78: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9F7C: 57A9103A  slwi r9, r29, 2
	ctx.r[9].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FC9F80: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9F84: 7C09552E  stfsx f0, r9, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FC9F88: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82FC9F8C: 481DE22C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FC9F90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FC9F90 size=108
    let mut pc: u32 = 0x82FC9F90;
    'dispatch: loop {
        match pc {
            0x82FC9F90 => {
    //   block [0x82FC9F90..0x82FC9FFC)
	// 82FC9F90: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FC9F94: 3941FFF0  addi r10, r1, -0x10
	ctx.r[10].s64 = ctx.r[1].s64 + -16;
	// 82FC9F98: 81240004  lwz r9, 4(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FC9F9C: C0030004  lfs f0, 4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FC9FA0: 81040008  lwz r8, 8(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FC9FA4: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FC9FA8: 80E4000C  lwz r7, 0xc(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FC9FAC: C1830008  lfs f12, 8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FC9FB0: C163000C  lfs f11, 0xc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FC9FB4: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FC9FB8: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FC9FBC: 910A0008  stw r8, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FC9FC0: 90EA000C  stw r7, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FC9FC4: C141FFF0  lfs f10, -0x10(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FC9FC8: C121FFF8  lfs f9, -8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FC9FCC: C101FFFC  lfs f8, -4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FC9FD0: C0E1FFF4  lfs f7, -0xc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FC9FD4: ECC70028  fsubs f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FC9FD8: ECAA6828  fsubs f5, f10, f13
	ctx.f[5].f64 = (((ctx.f[10].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FC9FDC: EC8601B2  fmuls f4, f6, f6
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FC9FE0: EC696028  fsubs f3, f9, f12
	ctx.f[3].f64 = (((ctx.f[9].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FC9FE4: EC485828  fsubs f2, f8, f11
	ctx.f[2].f64 = (((ctx.f[8].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FC9FE8: EC25217A  fmadds f1, f5, f5, f4
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FC9FEC: EC0308FA  fmadds f0, f3, f3, f1
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FC9FF0: EDA200BA  fmadds f13, f2, f2, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[2].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FC9FF4: EC20682C  fsqrts f1, f13
	ctx.f[1].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 82FC9FF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA000(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCA000 size=56
    let mut pc: u32 = 0x82FCA000;
    'dispatch: loop {
        match pc {
            0x82FCA000 => {
    //   block [0x82FCA000..0x82FCA038)
	// 82FCA000: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA004: 7F032800  cmpw cr6, r3, r5
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FCA008: 419A0020  beq cr6, 0x82fca028
	if ctx.cr[6].eq {
	pc = 0x82FCA028; continue 'dispatch;
	}
	// 82FCA00C: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA010: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCA014: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA018: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA01C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCA020: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA024: 419A0008  beq cr6, 0x82fca02c
	if ctx.cr[6].eq {
	pc = 0x82FCA02C; continue 'dispatch;
	}
	// 82FCA028: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCA02C: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCA030: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCA034: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA038(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FCA038 size=12
    let mut pc: u32 = 0x82FCA038;
    'dispatch: loop {
        match pc {
            0x82FCA038 => {
    //   block [0x82FCA038..0x82FCA044)
	// 82FCA038: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 82FCA03C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCA040: 4BFFFFC4  b 0x82fca004
	sub_82FCA000(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA044(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FCA044 size=4
    let mut pc: u32 = 0x82FCA044;
    'dispatch: loop {
        match pc {
            0x82FCA044 => {
    //   block [0x82FCA044..0x82FCA048)
	// 82FCA044: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA048(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA048 size=468
    let mut pc: u32 = 0x82FCA048;
    'dispatch: loop {
        match pc {
            0x82FCA048 => {
    //   block [0x82FCA048..0x82FCA21C)
	// 82FCA048: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA04C: 481DE119  bl 0x831a8164
	ctx.lr = 0x82FCA050;
	sub_831A8130(ctx, base);
	// 82FCA050: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA054: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCA058: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FCA05C: 4BFFF7F5  bl 0x82fc9850
	ctx.lr = 0x82FCA060;
	sub_82FC9850(ctx, base);
	// 82FCA060: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 82FCA064: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA068: 7F9BF214  add r28, r27, r30
	ctx.r[28].u64 = ctx.r[27].u64 + ctx.r[30].u64;
	// 82FCA06C: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCA070: 3BBC0001  addi r29, r28, 1
	ctx.r[29].s64 = ctx.r[28].s64 + 1;
	// 82FCA074: 7F0BE800  cmpw cr6, r11, r29
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCA078: 40980024  bge cr6, 0x82fca09c
	if !ctx.cr[6].lt {
	pc = 0x82FCA09C; continue 'dispatch;
	}
	// 82FCA07C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCA080: 7F1D5800  cmpw cr6, r29, r11
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCA084: 41980008  blt cr6, 0x82fca08c
	if ctx.cr[6].lt {
	pc = 0x82FCA08C; continue 'dispatch;
	}
	// 82FCA088: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCA08C: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCA090: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCA094: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCA098: 4BEDC761  bl 0x82ea67f8
	ctx.lr = 0x82FCA09C;
	sub_82EA67F8(ctx, base);
	// 82FCA09C: 93BF0004  stw r29, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCA0A0: 7F87E378  mr r7, r28
	ctx.r[7].u64 = ctx.r[28].u64;
	// 82FCA0A4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCA0A8: 2F1E0004  cmpwi cr6, r30, 4
	ctx.cr[6].compare_i32(ctx.r[30].s32, 4, &mut ctx.xer);
	// 82FCA0AC: 41980118  blt cr6, 0x82fca1c4
	if ctx.cr[6].lt {
	pc = 0x82FCA1C4; continue 'dispatch;
	}
	// 82FCA0B0: 397EFFFC  addi r11, r30, -4
	ctx.r[11].s64 = ctx.r[30].s64 + -4;
	// 82FCA0B4: 393EFFFE  addi r9, r30, -2
	ctx.r[9].s64 = ctx.r[30].s64 + -2;
	// 82FCA0B8: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCA0BC: 54EA103A  slwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA0C0: 38AB0001  addi r5, r11, 1
	ctx.r[5].s64 = ctx.r[11].s64 + 1;
	// 82FCA0C4: 552B103A  slwi r11, r9, 2
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCA0C8: 54A8103A  slwi r8, r5, 2
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCA0CC: 7C88F050  subf r4, r8, r30
	ctx.r[4].s64 = ctx.r[30].s64 - ctx.r[8].s64;
	// 82FCA0D0: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA0D4: 392B0008  addi r9, r11, 8
	ctx.r[9].s64 = ctx.r[11].s64 + 8;
	// 82FCA0D8: 7CC94214  add r6, r9, r8
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82FCA0DC: 7C09442E  lfsx f0, r9, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA0E0: C1A6FFFC  lfs f13, -4(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA0E4: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA0E8: 419A0010  beq cr6, 0x82fca0f8
	if ctx.cr[6].eq {
	pc = 0x82FCA0F8; continue 'dispatch;
	}
	// 82FCA0EC: 7C0A452E  stfsx f0, r10, r8
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCA0F0: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 82FCA0F4: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA0F8: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA0FC: 38C7FFFF  addi r6, r7, -1
	ctx.r[6].s64 = ctx.r[7].s64 + -1;
	// 82FCA100: 7C09442E  lfsx f0, r9, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA104: 7C0A452E  stfsx f0, r10, r8
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCA108: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA10C: 7DAB442E  lfsx f13, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA110: 7CE94214  add r7, r9, r8
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82FCA114: C007FFFC  lfs f0, -4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA118: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA11C: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA120: 419A0010  beq cr6, 0x82fca130
	if ctx.cr[6].eq {
	pc = 0x82FCA130; continue 'dispatch;
	}
	// 82FCA124: 7C0A452E  stfsx f0, r10, r8
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCA128: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 82FCA12C: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA130: 80FF0000  lwz r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA134: 390BFFFC  addi r8, r11, -4
	ctx.r[8].s64 = ctx.r[11].s64 + -4;
	// 82FCA138: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 82FCA13C: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 82FCA140: C009FFFC  lfs f0, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA144: 7C0A3D2E  stfsx f0, r10, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCA148: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA14C: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA150: 7DA84C2E  lfsx f13, r8, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA154: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA158: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA15C: 419A0010  beq cr6, 0x82fca16c
	if ctx.cr[6].eq {
	pc = 0x82FCA16C; continue 'dispatch;
	}
	// 82FCA160: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA164: 38C6FFFF  addi r6, r6, -1
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	// 82FCA168: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA16C: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA170: 38E6FFFF  addi r7, r6, -1
	ctx.r[7].s64 = ctx.r[6].s64 + -1;
	// 82FCA174: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA178: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA17C: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA180: 7C084C2E  lfsx f0, r8, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA184: 7CCB4A14  add r6, r11, r9
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCA188: C1A6FFF8  lfs f13, -8(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA18C: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA190: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA194: 419A0010  beq cr6, 0x82fca1a4
	if ctx.cr[6].eq {
	pc = 0x82FCA1A4; continue 'dispatch;
	}
	// 82FCA198: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA19C: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 82FCA1A0: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA1A4: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA1A8: 34A5FFFF  addic. r5, r5, -1
	ctx.xer.ca = (ctx.r[5].u32 > (!(-1 as u32)));
	ctx.r[5].s64 = ctx.r[5].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 82FCA1AC: 38E7FFFF  addi r7, r7, -1
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	// 82FCA1B0: 396BFFF0  addi r11, r11, -0x10
	ctx.r[11].s64 = ctx.r[11].s64 + -16;
	// 82FCA1B4: 7C084C2E  lfsx f0, r8, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA1B8: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA1BC: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA1C0: 4082FF10  bne 0x82fca0d0
	if !ctx.cr[0].eq {
	pc = 0x82FCA0D0; continue 'dispatch;
	}
	// 82FCA1C4: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82FCA1C8: 40990048  ble cr6, 0x82fca210
	if !ctx.cr[6].gt {
	pc = 0x82FCA210; continue 'dispatch;
	}
	// 82FCA1CC: 54EA103A  slwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA1D0: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCA1D4: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA1D8: 7D0B4A14  add r8, r11, r9
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCA1DC: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA1E0: C1A8FFFC  lfs f13, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA1E4: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA1E8: 419A000C  beq cr6, 0x82fca1f4
	if ctx.cr[6].eq {
	pc = 0x82FCA1F4; continue 'dispatch;
	}
	// 82FCA1EC: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA1F0: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA1F4: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA1F8: 3484FFFF  addic. r4, r4, -1
	ctx.xer.ca = (ctx.r[4].u32 > (!(-1 as u32)));
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82FCA1FC: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA200: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 82FCA204: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCA208: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCA20C: 4181FFC8  bgt 0x82fca1d4
	if ctx.cr[0].gt {
	pc = 0x82FCA1D4; continue 'dispatch;
	}
	// 82FCA210: 387BFFFE  addi r3, r27, -2
	ctx.r[3].s64 = ctx.r[27].s64 + -2;
	// 82FCA214: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FCA218: 481DDF9C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA220(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA220 size=380
    let mut pc: u32 = 0x82FCA220;
    'dispatch: loop {
        match pc {
            0x82FCA220 => {
    //   block [0x82FCA220..0x82FCA39C)
	// 82FCA220: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA224: 481DDF45  bl 0x831a8168
	ctx.lr = 0x82FCA228;
	sub_831A8130(ctx, base);
	// 82FCA228: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA22C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FCA230: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FCA234: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCA238: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82FCA23C: 2F1C0004  cmpwi cr6, r28, 4
	ctx.cr[6].compare_i32(ctx.r[28].s32, 4, &mut ctx.xer);
	// 82FCA240: 419800BC  blt cr6, 0x82fca2fc
	if ctx.cr[6].lt {
	pc = 0x82FCA2FC; continue 'dispatch;
	}
	// 82FCA244: 395CFFFC  addi r10, r28, -4
	ctx.r[10].s64 = ctx.r[28].s64 + -4;
	// 82FCA248: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCA24C: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA250: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82FCA254: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 82FCA258: 54C5103A  slwi r5, r6, 2
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCA25C: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA260: 3909FFF8  addi r8, r9, -8
	ctx.r[8].s64 = ctx.r[9].s64 + -8;
	// 82FCA264: 7CE85214  add r7, r8, r10
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82FCA268: 7C08542E  lfsx f0, r8, r10
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA26C: C1A70004  lfs f13, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA270: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA274: 409A0010  bne cr6, 0x82fca284
	if !ctx.cr[6].eq {
	pc = 0x82FCA284; continue 'dispatch;
	}
	// 82FCA278: 7C0B552E  stfsx f0, r11, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCA27C: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA280: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCA284: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA288: 7D085214  add r8, r8, r10
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82FCA28C: 7DA9542E  lfsx f13, r9, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA290: C0080004  lfs f0, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA294: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA298: 409A0010  bne cr6, 0x82fca2a8
	if !ctx.cr[6].eq {
	pc = 0x82FCA2A8; continue 'dispatch;
	}
	// 82FCA29C: 7C0B552E  stfsx f0, r11, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCA2A0: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA2A4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCA2A8: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA2AC: 39090004  addi r8, r9, 4
	ctx.r[8].s64 = ctx.r[9].s64 + 4;
	// 82FCA2B0: 7C09542E  lfsx f0, r9, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA2B4: 7DA8542E  lfsx f13, r8, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA2B8: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA2BC: 409A0010  bne cr6, 0x82fca2cc
	if !ctx.cr[6].eq {
	pc = 0x82FCA2CC; continue 'dispatch;
	}
	// 82FCA2C0: 7C0B552E  stfsx f0, r11, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCA2C4: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA2C8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCA2CC: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA2D0: 7CE95214  add r7, r9, r10
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCA2D4: 7C08542E  lfsx f0, r8, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA2D8: C1A70008  lfs f13, 8(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA2DC: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA2E0: 409A0010  bne cr6, 0x82fca2f0
	if !ctx.cr[6].eq {
	pc = 0x82FCA2F0; continue 'dispatch;
	}
	// 82FCA2E4: 7C0B552E  stfsx f0, r11, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCA2E8: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA2EC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCA2F0: 34C6FFFF  addic. r6, r6, -1
	ctx.xer.ca = (ctx.r[6].u32 > (!(-1 as u32)));
	ctx.r[6].s64 = ctx.r[6].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82FCA2F4: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FCA2F8: 4082FF64  bne 0x82fca25c
	if !ctx.cr[0].eq {
	pc = 0x82FCA25C; continue 'dispatch;
	}
	// 82FCA2FC: 7F05E000  cmpw cr6, r5, r28
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[28].s32, &mut ctx.xer);
	// 82FCA300: 40980040  bge cr6, 0x82fca340
	if !ctx.cr[6].lt {
	pc = 0x82FCA340; continue 'dispatch;
	}
	// 82FCA304: 57E8103A  slwi r8, r31, 2
	ctx.r[8].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCA308: 54AA103A  slwi r10, r5, 2
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA30C: 7CE5E050  subf r7, r5, r28
	ctx.r[7].s64 = ctx.r[28].s64 - ctx.r[5].s64;
	// 82FCA310: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA314: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCA318: 7C0A5C2E  lfsx f0, r10, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA31C: C1A90004  lfs f13, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA320: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCA324: 409A0010  bne cr6, 0x82fca334
	if !ctx.cr[6].eq {
	pc = 0x82FCA334; continue 'dispatch;
	}
	// 82FCA328: 7C085D2E  stfsx f0, r8, r11
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCA32C: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA330: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 82FCA334: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCA338: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCA33C: 4082FFD4  bne 0x82fca310
	if !ctx.cr[0].eq {
	pc = 0x82FCA310; continue 'dispatch;
	}
	// 82FCA340: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA344: 578A103A  slwi r10, r28, 2
	ctx.r[10].u32 = ctx.r[28].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCA348: 57E9103A  slwi r9, r31, 2
	ctx.r[9].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCA34C: 3BDF0001  addi r30, r31, 1
	ctx.r[30].s64 = ctx.r[31].s64 + 1;
	// 82FCA350: 7C0A5C2E  lfsx f0, r10, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA354: 7C095D2E  stfsx f0, r9, r11
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCA358: 811D0008  lwz r8, 8(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA35C: 550B00BE  clrlwi r11, r8, 2
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCA360: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FCA364: 40980024  bge cr6, 0x82fca388
	if !ctx.cr[6].lt {
	pc = 0x82FCA388; continue 'dispatch;
	}
	// 82FCA368: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCA36C: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCA370: 41980008  blt cr6, 0x82fca378
	if ctx.cr[6].lt {
	pc = 0x82FCA378; continue 'dispatch;
	}
	// 82FCA374: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82FCA378: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCA37C: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCA380: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FCA384: 4BEDC475  bl 0x82ea67f8
	ctx.lr = 0x82FCA388;
	sub_82EA67F8(ctx, base);
	// 82FCA388: 7D7FE050  subf r11, r31, r28
	ctx.r[11].s64 = ctx.r[28].s64 - ctx.r[31].s64;
	// 82FCA38C: 93DD0004  stw r30, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FCA390: 386BFFFF  addi r3, r11, -1
	ctx.r[3].s64 = ctx.r[11].s64 + -1;
	// 82FCA394: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FCA398: 481DDE20  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA3A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA3A0 size=856
    let mut pc: u32 = 0x82FCA3A0;
    'dispatch: loop {
        match pc {
            0x82FCA3A0 => {
    //   block [0x82FCA3A0..0x82FCA6F8)
	// 82FCA3A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA3A4: 481DDDB1  bl 0x831a8154
	ctx.lr = 0x82FCA3A8;
	sub_831A8130(ctx, base);
	// 82FCA3A8: 3981FFB0  addi r12, r1, -0x50
	ctx.r[12].s64 = ctx.r[1].s64 + -80;
	// 82FCA3AC: 481DE6AD  bl 0x831a8a58
	ctx.lr = 0x82FCA3B0;
	sub_831A8A40(ctx, base);
	// 82FCA3B0: 9421FEA0  stwu r1, -0x160(r1)
	ea = ctx.r[1].u32.wrapping_add(-352 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA3B4: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 82FCA3B8: FEA00890  fmr f21, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[21].f64 = ctx.f[1].f64;
	// 82FCA3BC: 7D374B78  mr r23, r9
	ctx.r[23].u64 = ctx.r[9].u64;
	// 82FCA3C0: FE801090  fmr f20, f2
	ctx.f[20].f64 = ctx.f[2].f64;
	// 82FCA3C4: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 82FCA3C8: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 82FCA3CC: 3D208213  lis r9, -0x7ded
	ctx.r[9].s64 = -2112684032;
	// 82FCA3D0: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA3D4: 7D1E4378  mr r30, r8
	ctx.r[30].u64 = ctx.r[8].u64;
	// 82FCA3D8: 7D5BD214  add r10, r27, r26
	ctx.r[10].u64 = ctx.r[27].u64 + ctx.r[26].u64;
	// 82FCA3DC: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 82FCA3E0: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 82FCA3E4: C3A96900  lfs f29, 0x6900(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(26880 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FCA3E8: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCA3EC: C3CB0000  lfs f30, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCA3F0: 3B0A0001  addi r24, r10, 1
	ctx.r[24].s64 = ctx.r[10].s64 + 1;
	// 82FCA3F4: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCA3F8: 419800F4  blt cr6, 0x82fca4ec
	if ctx.cr[6].lt {
	pc = 0x82FCA4EC; continue 'dispatch;
	}
	// 82FCA3FC: 7FCA07B4  extsw r10, r30
	ctx.r[10].s64 = ctx.r[30].s32 as i64;
	// 82FCA400: FF80F090  fmr f28, f30
	ctx.f[28].f64 = ctx.f[30].f64;
	// 82FCA404: 5709103A  slwi r9, r24, 2
	ctx.r[9].u32 = ctx.r[24].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCA408: C37D0000  lfs f27, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 82FCA40C: F9410050  std r10, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u64 ) };
	// 82FCA410: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 82FCA414: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 82FCA418: C33D0004  lfs f25, 4(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 82FCA41C: 7D895C2E  lfsx f12, r9, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCA420: FF406818  frsp f26, f13
	ctx.f[26].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82FCA424: C2FD0008  lfs f23, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[23].f64 = (tmp.f32 as f64);
	// 82FCA428: EF0CE028  fsubs f24, f12, f28
	ctx.f[24].f64 = (((ctx.f[12].f64 - ctx.f[28].f64) as f32) as f64);
	// 82FCA42C: C2DD000C  lfs f22, 0xc(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) };
	ctx.f[22].f64 = (tmp.f32 as f64);
	// 82FCA430: 7FEB07B4  extsw r11, r31
	ctx.r[11].s64 = ctx.r[31].s32 as i64;
	// 82FCA434: 7F27CB78  mr r7, r25
	ctx.r[7].u64 = ctx.r[25].u64;
	// 82FCA438: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 82FCA43C: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 82FCA440: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 82FCA444: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 82FCA448: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82FCA44C: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 82FCA450: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCA454: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82FCA458: ED6CD024  fdivs f11, f12, f26
	ctx.f[11].f64 = ((ctx.f[12].f64 / ctx.f[26].f64) as f32) as f64;
	// 82FCA45C: EFEBE63A  fmadds f31, f11, f24, f28
	ctx.f[31].f64 = (((ctx.f[11].f64 * ctx.f[24].f64 + ctx.f[28].f64) as f32) as f64);
	// 82FCA460: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCA464: 4BFFEECD  bl 0x82fc9330
	ctx.lr = 0x82FCA468;
	sub_82FC9330(ctx, base);
	// 82FCA468: 39410070  addi r10, r1, 0x70
	ctx.r[10].s64 = ctx.r[1].s64 + 112;
	// 82FCA46C: C1410070  lfs f10, 0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCA470: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82FCA474: ED2AD828  fsubs f9, f10, f27
	ctx.f[9].f64 = (((ctx.f[10].f64 - ctx.f[27].f64) as f32) as f64);
	// 82FCA478: 810A0000  lwz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA47C: 80EA0004  lwz r7, 4(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCA480: 80CA0008  lwz r6, 8(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA484: 80AA000C  lwz r5, 0xc(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCA488: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCA48C: 90E90004  stw r7, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FCA490: 90C90008  stw r6, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FCA494: 90A9000C  stw r5, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FCA498: C1010068  lfs f8, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCA49C: C0E1006C  lfs f7, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCA4A0: C0C10064  lfs f6, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCA4A4: EC06C828  fsubs f0, f6, f25
	ctx.f[0].f64 = (((ctx.f[6].f64 - ctx.f[25].f64) as f32) as f64);
	// 82FCA4A8: ECA00032  fmuls f5, f0, f0
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCA4AC: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82FCA4B0: EDA8B828  fsubs f13, f8, f23
	ctx.f[13].f64 = (((ctx.f[8].f64 - ctx.f[23].f64) as f32) as f64);
	// 82FCA4B4: D1A10068  stfs f13, 0x68(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82FCA4B8: ED87B028  fsubs f12, f7, f22
	ctx.f[12].f64 = (((ctx.f[7].f64 - ctx.f[22].f64) as f32) as f64);
	// 82FCA4BC: D181006C  stfs f12, 0x6c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 82FCA4C0: EC892A7A  fmadds f4, f9, f9, f5
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA4C4: EC6D237A  fmadds f3, f13, f13, f4
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA4C8: EC4C1B3A  fmadds f2, f12, f12, f3
	ctx.f[2].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCA4CC: EC00102C  fsqrts f0, f2
	ctx.f[0].f64 = ((ctx.f[2].f64).sqrt() as f32) as f64;
	// 82FCA4D0: FF00E800  fcmpu cr6, f0, f29
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[29].f64);
	// 82FCA4D4: 4098000C  bge cr6, 0x82fca4e0
	if !ctx.cr[6].lt {
	pc = 0x82FCA4E0; continue 'dispatch;
	}
	// 82FCA4D8: FFA00090  fmr f29, f0
	ctx.f[29].f64 = ctx.f[0].f64;
	// 82FCA4DC: FFC0F890  fmr f30, f31
	ctx.f[30].f64 = ctx.f[31].f64;
	// 82FCA4E0: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA4E4: 7F1FF000  cmpw cr6, r31, r30
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FCA4E8: 4099FF48  ble cr6, 0x82fca430
	if !ctx.cr[6].gt {
	pc = 0x82FCA430; continue 'dispatch;
	}
	// 82FCA4EC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCA4F0: 2F170000  cmpwi cr6, r23, 0
	ctx.cr[6].compare_i32(ctx.r[23].s32, 0, &mut ctx.xer);
	// 82FCA4F4: 409901F0  ble cr6, 0x82fca6e4
	if !ctx.cr[6].gt {
	pc = 0x82FCA6E4; continue 'dispatch;
	}
	// 82FCA4F8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCA4FC: C3EB08A4  lfs f31, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCA500: D3E10080  stfs f31, 0x80(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCA504: 39210080  addi r9, r1, 0x80
	ctx.r[9].s64 = ctx.r[1].s64 + 128;
	// 82FCA508: D3E10084  stfs f31, 0x84(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCA50C: 39000002  li r8, 2
	ctx.r[8].s64 = 2;
	// 82FCA510: D3E10088  stfs f31, 0x88(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCA514: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82FCA518: D3E1008C  stfs f31, 0x8c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCA51C: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82FCA520: D3E10090  stfs f31, 0x90(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCA524: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 82FCA528: D3E10094  stfs f31, 0x94(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCA52C: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82FCA530: D3E10098  stfs f31, 0x98(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCA534: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCA538: D3E1009C  stfs f31, 0x9c(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCA53C: D3E100A0  stfs f31, 0xa0(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 82FCA540: D3E100A4  stfs f31, 0xa4(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCA544: D3E100A8  stfs f31, 0xa8(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCA548: D3E100AC  stfs f31, 0xac(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCA54C: 4BFFE9D5  bl 0x82fc8f20
	ctx.lr = 0x82FCA550;
	sub_82FC8F20(ctx, base);
	// 82FCA550: C01D0004  lfs f0, 4(r29)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA554: C1A10084  lfs f13, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA558: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCA55C: ED6D0028  fsubs f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCA560: C19D0000  lfs f12, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCA564: C1410080  lfs f10, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCA568: ED4A6028  fsubs f10, f10, f12
	ctx.f[10].f64 = (((ctx.f[10].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCA56C: C13D0008  lfs f9, 8(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCA570: C1010088  lfs f8, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCA574: ED284828  fsubs f9, f8, f9
	ctx.f[9].f64 = (((ctx.f[8].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FCA578: C0FD000C  lfs f7, 0xc(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCA57C: C0C1008C  lfs f6, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCA580: ED863828  fsubs f12, f6, f7
	ctx.f[12].f64 = (((ctx.f[6].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FCA584: ECAB02F2  fmuls f5, f11, f11
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCA588: EC8A2ABA  fmadds f4, f10, f10, f5
	ctx.f[4].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA58C: EC69227A  fmadds f3, f9, f9, f4
	ctx.f[3].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA590: EC4C1B3A  fmadds f2, f12, f12, f3
	ctx.f[2].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCA594: EC20102C  fsqrts f1, f2
	ctx.f[1].f64 = ((ctx.f[2].f64).sqrt() as f32) as f64;
	// 82FCA598: FF01A800  fcmpu cr6, f1, f21
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[21].f64);
	// 82FCA59C: 40990008  ble cr6, 0x82fca5a4
	if !ctx.cr[6].gt {
	pc = 0x82FCA5A4; continue 'dispatch;
	}
	// 82FCA5A0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCA5A4: C1010094  lfs f8, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCA5A8: ECCB02F2  fmuls f6, f11, f11
	ctx.f[6].f64 = (((ctx.f[11].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCA5AC: ECA80232  fmuls f5, f8, f8
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCA5B0: C1A10090  lfs f13, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA5B4: C0E10098  lfs f7, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCA5B8: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82FCA5BC: EC870272  fmuls f4, f7, f9
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCA5C0: C001009C  lfs f0, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA5C4: EC6A32BA  fmadds f3, f10, f10, f6
	ctx.f[3].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[6].f64) as f32) as f64);
	// 82FCA5C8: EC4D2B7A  fmadds f2, f13, f13, f5
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA5CC: EC20233A  fmadds f1, f0, f12, f4
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA5D0: ECC91A7A  fmadds f6, f9, f9, f3
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCA5D4: ECA711FA  fmadds f5, f7, f7, f2
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[7].f64 + ctx.f[2].f64) as f32) as f64);
	// 82FCA5D8: EC880AFA  fmadds f4, f8, f11, f1
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FCA5DC: EC6C333A  fmadds f3, f12, f12, f6
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 82FCA5E0: EC40283A  fmadds f2, f0, f0, f5
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA5E4: EC2D22BA  fmadds f1, f13, f10, f4
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[10].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA5E8: ECC0182C  fsqrts f6, f3
	ctx.f[6].f64 = ((ctx.f[3].f64).sqrt() as f32) as f64;
	// 82FCA5EC: ECA0102C  fsqrts f5, f2
	ctx.f[5].f64 = ((ctx.f[2].f64).sqrt() as f32) as f64;
	// 82FCA5F0: EC8501B2  fmuls f4, f5, f6
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCA5F4: EC612024  fdivs f3, f1, f4
	ctx.f[3].f64 = ((ctx.f[1].f64 / ctx.f[4].f64) as f32) as f64;
	// 82FCA5F8: FF03A000  fcmpu cr6, f3, f20
	ctx.cr[6].compare_f64(ctx.f[3].f64, ctx.f[20].f64);
	// 82FCA5FC: 40990008  ble cr6, 0x82fca604
	if !ctx.cr[6].gt {
	pc = 0x82FCA604; continue 'dispatch;
	}
	// 82FCA600: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FCA604: 7D6A0774  extsb r10, r11
	ctx.r[10].s64 = ctx.r[11].s8 as i64;
	// 82FCA608: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCA60C: 419A0010  beq cr6, 0x82fca61c
	if ctx.cr[6].eq {
	pc = 0x82FCA61C; continue 'dispatch;
	}
	// 82FCA610: 7D2B0774  extsb r11, r9
	ctx.r[11].s64 = ctx.r[9].s8 as i64;
	// 82FCA614: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCA618: 409A00CC  bne cr6, 0x82fca6e4
	if !ctx.cr[6].eq {
	pc = 0x82FCA6E4; continue 'dispatch;
	}
	// 82FCA61C: C0C100A8  lfs f6, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCA620: ECA70272  fmuls f5, f7, f9
	ctx.f[5].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCA624: EC860272  fmuls f4, f6, f9
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCA628: C06100AC  lfs f3, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCA62C: C04100A4  lfs f2, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCA630: ED280232  fmuls f9, f8, f8
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCA634: C02100A0  lfs f1, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCA638: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA63C: 5708103A  slwi r8, r24, 2
	ctx.r[8].u32 = ctx.r[24].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCA640: FCC0F090  fmr f6, f30
	ctx.f[6].f64 = ctx.f[30].f64;
	// 82FCA644: C3AB0000  lfs f29, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FCA648: 7F885C2E  lfsx f28, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82FCA64C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCA650: ECA02B3A  fmadds f5, f0, f12, f5
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA654: EC83233A  fmadds f4, f3, f12, f4
	ctx.f[4].f64 = (((ctx.f[3].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA658: EC6D4B7A  fmadds f3, f13, f13, f9
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FCA65C: ED882AFA  fmadds f12, f8, f11, f5
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[11].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA660: ED6222FA  fmadds f11, f2, f11, f4
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA664: ED2719FA  fmadds f9, f7, f7, f3
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[7].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCA668: ECAD62BA  fmadds f5, f13, f10, f12
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCA66C: EC815ABA  fmadds f4, f1, f10, f11
	ctx.f[4].f64 = (((ctx.f[1].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 82FCA670: EC60483A  fmadds f3, f0, f0, f9
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64);
	// 82FCA674: EC4D237A  fmadds f2, f13, f13, f4
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA678: EC20182C  fsqrts f1, f3
	ctx.f[1].f64 = ((ctx.f[3].f64).sqrt() as f32) as f64;
	// 82FCA67C: EDA8123A  fmadds f13, f8, f8, f2
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[8].f64 + ctx.f[2].f64) as f32) as f64);
	// 82FCA680: ED8769FA  fmadds f12, f7, f7, f13
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FCA684: ED60603A  fmadds f11, f0, f0, f12
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCA688: ED455824  fdivs f10, f5, f11
	ctx.f[10].f64 = ((ctx.f[5].f64 / ctx.f[11].f64) as f32) as f64;
	// 82FCA68C: ED3E5028  fsubs f9, f30, f10
	ctx.f[9].f64 = (((ctx.f[30].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCA690: ED09E828  fsubs f8, f9, f29
	ctx.f[8].f64 = (((ctx.f[9].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCA694: FCE8EA6E  fsel f7, f8, f9, f29
	ctx.f[7].f64 = if ctx.f[8].f64 >= 0.0 { ctx.f[9].f64 } else { ctx.f[29].f64 };
	// 82FCA698: ECA7E028  fsubs f5, f7, f28
	ctx.f[5].f64 = (((ctx.f[7].f64 - ctx.f[28].f64) as f32) as f64);
	// 82FCA69C: FFC53F2E  fsel f30, f5, f28, f7
	ctx.f[30].f64 = if ctx.f[5].f64 >= 0.0 { ctx.f[28].f64 } else { ctx.f[7].f64 };
	// 82FCA6A0: EC9E3028  fsubs f4, f30, f6
	ctx.f[4].f64 = (((ctx.f[30].f64 - ctx.f[6].f64) as f32) as f64);
	// 82FCA6A4: FC602210  fabs f3, f4
	ctx.f[3].u64 = ctx.f[4].u64 & !0x8000_0000_0000_0000u64;
	// 82FCA6A8: EC4100F2  fmuls f2, f1, f3
	ctx.f[2].f64 = (((ctx.f[1].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCA6AC: FF02A800  fcmpu cr6, f2, f21
	ctx.cr[6].compare_f64(ctx.f[2].f64, ctx.f[21].f64);
	// 82FCA6B0: 40990008  ble cr6, 0x82fca6b8
	if !ctx.cr[6].gt {
	pc = 0x82FCA6B8; continue 'dispatch;
	}
	// 82FCA6B4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCA6B8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCA6BC: 409A0028  bne cr6, 0x82fca6e4
	if !ctx.cr[6].eq {
	pc = 0x82FCA6E4; continue 'dispatch;
	}
	// 82FCA6C0: 7D2A0774  extsb r10, r9
	ctx.r[10].s64 = ctx.r[9].s8 as i64;
	// 82FCA6C4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCA6C8: 409A001C  bne cr6, 0x82fca6e4
	if !ctx.cr[6].eq {
	pc = 0x82FCA6E4; continue 'dispatch;
	}
	// 82FCA6CC: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCA6D0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCA6D4: 409A0010  bne cr6, 0x82fca6e4
	if !ctx.cr[6].eq {
	pc = 0x82FCA6E4; continue 'dispatch;
	}
	// 82FCA6D8: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCA6DC: 7F1FB800  cmpw cr6, r31, r23
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[23].s32, &mut ctx.xer);
	// 82FCA6E0: 4198FE20  blt cr6, 0x82fca500
	if ctx.cr[6].lt {
	pc = 0x82FCA500; continue 'dispatch;
	}
	// 82FCA6E4: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCA6E8: 38210160  addi r1, r1, 0x160
	ctx.r[1].s64 = ctx.r[1].s64 + 352;
	// 82FCA6EC: 3981FFB0  addi r12, r1, -0x50
	ctx.r[12].s64 = ctx.r[1].s64 + -80;
	// 82FCA6F0: 481DE3B5  bl 0x831a8aa4
	ctx.lr = 0x82FCA6F4;
	sub_831A8A8C(ctx, base);
	// 82FCA6F4: 481DDAB0  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA6F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA6F8 size=372
    let mut pc: u32 = 0x82FCA6F8;
    'dispatch: loop {
        match pc {
            0x82FCA6F8 => {
    //   block [0x82FCA6F8..0x82FCA86C)
	// 82FCA6F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA6FC: 481DDA49  bl 0x831a8144
	ctx.lr = 0x82FCA700;
	sub_831A8130(ctx, base);
	// 82FCA700: DBA1FF78  stfd f29, -0x88(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.f[29].u64 ) };
	// 82FCA704: DBC1FF80  stfd f30, -0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.f[30].u64 ) };
	// 82FCA708: DBE1FF88  stfd f31, -0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.f[31].u64 ) };
	// 82FCA70C: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA710: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FCA714: FFC00890  fmr f30, f1
	ctx.f[30].f64 = ctx.f[1].f64;
	// 82FCA718: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82FCA71C: FFA01090  fmr f29, f2
	ctx.f[29].f64 = ctx.f[2].f64;
	// 82FCA720: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 82FCA724: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 82FCA728: 7D184378  mr r24, r8
	ctx.r[24].u64 = ctx.r[8].u64;
	// 82FCA72C: 7D364B78  mr r22, r9
	ctx.r[22].u64 = ctx.r[9].u64;
	// 82FCA730: 7D575378  mr r23, r10
	ctx.r[23].u64 = ctx.r[10].u64;
	// 82FCA734: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82FCA738: 41980120  blt cr6, 0x82fca858
	if ctx.cr[6].lt {
	pc = 0x82FCA858; continue 'dispatch;
	}
	// 82FCA73C: 89610187  lbz r11, 0x187(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(391 as u32) ) } as u64;
	// 82FCA740: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FCA744: 82A1016C  lwz r21, 0x16c(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(364 as u32) ) } as u64;
	// 82FCA748: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCA74C: 82810164  lwz r20, 0x164(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(356 as u32) ) } as u64;
	// 82FCA750: 7D730774  extsb r19, r11
	ctx.r[19].s64 = ctx.r[11].s8 as i64;
	// 82FCA754: 3BA30001  addi r29, r3, 1
	ctx.r[29].s64 = ctx.r[3].s64 + 1;
	// 82FCA758: 2F130000  cmpwi cr6, r19, 0
	ctx.cr[6].compare_i32(ctx.r[19].s32, 0, &mut ctx.xer);
	// 82FCA75C: 419A0038  beq cr6, 0x82fca794
	if ctx.cr[6].eq {
	pc = 0x82FCA794; continue 'dispatch;
	}
	// 82FCA760: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA764: 7EA9AB78  mr r9, r21
	ctx.r[9].u64 = ctx.r[21].u64;
	// 82FCA768: 7E88A378  mr r8, r20
	ctx.r[8].u64 = ctx.r[20].u64;
	// 82FCA76C: FC40E890  fmr f2, f29
	ctx.f[2].f64 = ctx.f[29].f64;
	// 82FCA770: 7CEBFA14  add r7, r11, r31
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FCA774: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCA778: 7F06C378  mr r6, r24
	ctx.r[6].u64 = ctx.r[24].u64;
	// 82FCA77C: 7F25CB78  mr r5, r25
	ctx.r[5].u64 = ctx.r[25].u64;
	// 82FCA780: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 82FCA784: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 82FCA788: 4BFFFC19  bl 0x82fca3a0
	ctx.lr = 0x82FCA78C;
	sub_82FCA3A0(ctx, base);
	// 82FCA78C: FFE00890  fmr f31, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCA790: 4800000C  b 0x82fca79c
	pc = 0x82FCA79C; continue 'dispatch;
	// 82FCA794: 81770000  lwz r11, 0(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA798: 7FEBF42E  lfsx f31, r11, r30
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32)) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCA79C: 7F07C378  mr r7, r24
	ctx.r[7].u64 = ctx.r[24].u64;
	// 82FCA7A0: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCA7A4: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82FCA7A8: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 82FCA7AC: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCA7B0: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82FCA7B4: 4BFFEB7D  bl 0x82fc9330
	ctx.lr = 0x82FCA7B8;
	sub_82FC9330(ctx, base);
	// 82FCA7B8: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA7BC: 81570000  lwz r10, 0(r23)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA7C0: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82FCA7C4: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FCA7C8: C0010074  lfs f0, 0x74(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA7CC: C1A10070  lfs f13, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA7D0: 81160000  lwz r8, 0(r22)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA7D4: C1010078  lfs f8, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCA7D8: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82FCA7DC: C0C1007C  lfs f6, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCA7E0: 3BFF0010  addi r31, r31, 0x10
	ctx.r[31].s64 = ctx.r[31].s64 + 16;
	// 82FCA7E4: 7FEAF52E  stfsx f31, r10, r30
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[30].u32), tmp.u32) };
	// 82FCA7E8: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA7EC: 80AB0004  lwz r5, 4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCA7F0: 808B0008  lwz r4, 8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA7F4: 80EB000C  lwz r7, 0xc(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCA7F8: 90E9000C  stw r7, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FCA7FC: 90890008  stw r4, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCA800: 90A90004  stw r5, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCA804: 90C90000  stw r6, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82FCA808: C1810060  lfs f12, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCA80C: C1610068  lfs f11, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCA810: C141006C  lfs f10, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCA814: C1210064  lfs f9, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCA818: EC090028  fsubs f0, f9, f0
	ctx.f[0].f64 = (((ctx.f[9].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCA81C: EDAC6828  fsubs f13, f12, f13
	ctx.f[13].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCA820: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82FCA824: ECE00032  fmuls f7, f0, f0
	ctx.f[7].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCA828: D1A10060  stfs f13, 0x60(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), tmp.u32 ) };
	// 82FCA82C: ED8B4028  fsubs f12, f11, f8
	ctx.f[12].f64 = (((ctx.f[11].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FCA830: D1810068  stfs f12, 0x68(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82FCA834: ED6A3028  fsubs f11, f10, f6
	ctx.f[11].f64 = (((ctx.f[10].f64 - ctx.f[6].f64) as f32) as f64);
	// 82FCA838: D161006C  stfs f11, 0x6c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 82FCA83C: ECAD3B7A  fmadds f5, f13, f13, f7
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[7].f64) as f32) as f64);
	// 82FCA840: EC8C2B3A  fmadds f4, f12, f12, f5
	ctx.f[4].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCA844: EC6B22FA  fmadds f3, f11, f11, f4
	ctx.f[3].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA848: EC40182C  fsqrts f2, f3
	ctx.f[2].f64 = ((ctx.f[3].f64).sqrt() as f32) as f64;
	// 82FCA84C: 7C48F52E  stfsx f2, r8, r30
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[30].u32), tmp.u32) };
	// 82FCA850: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FCA854: 4082FF04  bne 0x82fca758
	if !ctx.cr[0].eq {
	pc = 0x82FCA758; continue 'dispatch;
	}
	// 82FCA858: 38210110  addi r1, r1, 0x110
	ctx.r[1].s64 = ctx.r[1].s64 + 272;
	// 82FCA85C: CBA1FF78  lfd f29, -0x88(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 82FCA860: CBC1FF80  lfd f30, -0x80(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-128 as u32) ) };
	// 82FCA864: CBE1FF88  lfd f31, -0x78(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-120 as u32) ) };
	// 82FCA868: 481DD92C  b 0x831a8194
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA870 size=272
    let mut pc: u32 = 0x82FCA870;
    'dispatch: loop {
        match pc {
            0x82FCA870 => {
    //   block [0x82FCA870..0x82FCA980)
	// 82FCA870: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA874: 481DD8E1  bl 0x831a8154
	ctx.lr = 0x82FCA878;
	sub_831A8130(ctx, base);
	// 82FCA878: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 82FCA87C: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA880: 7C781B78  mr r24, r3
	ctx.r[24].u64 = ctx.r[3].u64;
	// 82FCA884: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCA888: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FCA88C: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82FCA890: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 82FCA894: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 82FCA898: 99780000  stb r11, 0(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FCA89C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCA8A0: 419800D0  blt cr6, 0x82fca970
	if ctx.cr[6].lt {
	pc = 0x82FCA970; continue 'dispatch;
	}
	// 82FCA8A4: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 82FCA8A8: 83CA0000  lwz r30, 0(r10)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA8AC: 83E90000  lwz r31, 0(r9)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA8B0: 3BA80001  addi r29, r8, 1
	ctx.r[29].s64 = ctx.r[8].s64 + 1;
	// 82FCA8B4: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 82FCA8B8: C00B0A94  lfs f0, 0xa94(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2708 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCA8BC: EFE10032  fmuls f31, f1, f0
	ctx.f[31].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCA8C0: 7F47D378  mr r7, r26
	ctx.r[7].u64 = ctx.r[26].u64;
	// 82FCA8C4: C03E0000  lfs f1, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCA8C8: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82FCA8CC: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82FCA8D0: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCA8D4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FCA8D8: 4BFFEA59  bl 0x82fc9330
	ctx.lr = 0x82FCA8DC;
	sub_82FC9330(ctx, base);
	// 82FCA8DC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA8E0: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCA8E4: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 82FCA8E8: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA8EC: C1210064  lfs f9, 0x64(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCA8F0: 80FF000C  lwz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCA8F4: C1010060  lfs f8, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCA8F8: C0E10068  lfs f7, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCA8FC: C0A1006C  lfs f5, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCA900: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCA904: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCA908: 91090008  stw r8, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FCA90C: 90E9000C  stw r7, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FCA910: C1A10050  lfs f13, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCA914: C1810058  lfs f12, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCA918: C161005C  lfs f11, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCA91C: C1410054  lfs f10, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCA920: EC0A4828  fsubs f0, f10, f9
	ctx.f[0].f64 = (((ctx.f[10].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FCA924: EDAD4028  fsubs f13, f13, f8
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FCA928: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCA92C: ECC00032  fmuls f6, f0, f0
	ctx.f[6].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCA930: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCA934: ED8C3828  fsubs f12, f12, f7
	ctx.f[12].f64 = (((ctx.f[12].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FCA938: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCA93C: ED6B2828  fsubs f11, f11, f5
	ctx.f[11].f64 = (((ctx.f[11].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCA940: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCA944: EC8D337A  fmadds f4, f13, f13, f6
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[6].f64) as f32) as f64);
	// 82FCA948: EC6C233A  fmadds f3, f12, f12, f4
	ctx.f[3].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCA94C: EC4B1AFA  fmadds f2, f11, f11, f3
	ctx.f[2].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCA950: EC20102C  fsqrts f1, f2
	ctx.f[1].f64 = ((ctx.f[2].f64).sqrt() as f32) as f64;
	// 82FCA954: FF01F800  fcmpu cr6, f1, f31
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[31].f64);
	// 82FCA958: 40990008  ble cr6, 0x82fca960
	if !ctx.cr[6].gt {
	pc = 0x82FCA960; continue 'dispatch;
	}
	// 82FCA95C: 9AF80000  stb r23, 0(r24)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[23].u8 ) };
	// 82FCA960: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82FCA964: 3BFF0010  addi r31, r31, 0x10
	ctx.r[31].s64 = ctx.r[31].s64 + 16;
	// 82FCA968: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FCA96C: 4082FF54  bne 0x82fca8c0
	if !ctx.cr[0].eq {
	pc = 0x82FCA8C0; continue 'dispatch;
	}
	// 82FCA970: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 82FCA974: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82FCA978: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 82FCA97C: 481DD828  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCA980(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCA980 size=312
    let mut pc: u32 = 0x82FCA980;
    'dispatch: loop {
        match pc {
            0x82FCA980 => {
    //   block [0x82FCA980..0x82FCAAB8)
	// 82FCA980: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCA984: 481DD7CD  bl 0x831a8150
	ctx.lr = 0x82FCA988;
	sub_831A8130(ctx, base);
	// 82FCA988: DBE1FFA0  stfd f31, -0x60(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-96 as u32), ctx.f[31].u64 ) };
	// 82FCA98C: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCA990: 7D174378  mr r23, r8
	ctx.r[23].u64 = ctx.r[8].u64;
	// 82FCA994: 7C761B78  mr r22, r3
	ctx.r[22].u64 = ctx.r[3].u64;
	// 82FCA998: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82FCA99C: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82FCA9A0: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 82FCA9A4: 7CF83B78  mr r24, r7
	ctx.r[24].u64 = ctx.r[7].u64;
	// 82FCA9A8: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82FCA9AC: 2F170000  cmpwi cr6, r23, 0
	ctx.cr[6].compare_i32(ctx.r[23].s32, 0, &mut ctx.xer);
	// 82FCA9B0: 419800D8  blt cr6, 0x82fcaa88
	if ctx.cr[6].lt {
	pc = 0x82FCAA88; continue 'dispatch;
	}
	// 82FCA9B4: 81610124  lwz r11, 0x124(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(292 as u32) ) } as u64;
	// 82FCA9B8: 814A0000  lwz r10, 0(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA9BC: 83E90000  lwz r31, 0(r9)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA9C0: 83CB0000  lwz r30, 0(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA9C4: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 82FCA9C8: 7F9E5050  subf r28, r30, r10
	ctx.r[28].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 82FCA9CC: C3EB9F7C  lfs f31, -0x6084(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24708 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCA9D0: 7F27CB78  mr r7, r25
	ctx.r[7].u64 = ctx.r[25].u64;
	// 82FCA9D4: 7C3CF42E  lfsx f1, r28, r30
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[30].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCA9D8: 7F06C378  mr r6, r24
	ctx.r[6].u64 = ctx.r[24].u64;
	// 82FCA9DC: 7F45D378  mr r5, r26
	ctx.r[5].u64 = ctx.r[26].u64;
	// 82FCA9E0: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCA9E4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FCA9E8: 4BFFE949  bl 0x82fc9330
	ctx.lr = 0x82FCA9EC;
	sub_82FC9330(ctx, base);
	// 82FCA9EC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCA9F0: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCA9F4: 39210050  addi r9, r1, 0x50
	ctx.r[9].s64 = ctx.r[1].s64 + 80;
	// 82FCA9F8: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCA9FC: C01E0000  lfs f0, 0(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCAA00: 80FF000C  lwz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAA04: C0A10064  lfs f5, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCAA08: ED40F82A  fadds f10, f0, f31
	ctx.f[10].f64 = ((ctx.f[0].f64 + ctx.f[31].f64) as f32) as f64;
	// 82FCAA0C: C0810060  lfs f4, 0x60(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAA10: C0610068  lfs f3, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCAA14: 91690000  stw r11, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCAA18: C021006C  lfs f1, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCAA1C: 91490004  stw r10, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCAA20: 91090008  stw r8, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FCAA24: 90E9000C  stw r7, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FCAA28: C1210050  lfs f9, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCAA2C: C1010058  lfs f8, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAA30: C0E1005C  lfs f7, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCAA34: C0C10054  lfs f6, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCAA38: EC062828  fsubs f0, f6, f5
	ctx.f[0].f64 = (((ctx.f[6].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCAA3C: EDA92028  fsubs f13, f9, f4
	ctx.f[13].f64 = (((ctx.f[9].f64 - ctx.f[4].f64) as f32) as f64);
	// 82FCAA40: D0010054  stfs f0, 0x54(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCAA44: EC400032  fmuls f2, f0, f0
	ctx.f[2].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCAA48: D1A10050  stfs f13, 0x50(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCAA4C: ED881828  fsubs f12, f8, f3
	ctx.f[12].f64 = (((ctx.f[8].f64 - ctx.f[3].f64) as f32) as f64);
	// 82FCAA50: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCAA54: ED670828  fsubs f11, f7, f1
	ctx.f[11].f64 = (((ctx.f[7].f64 - ctx.f[1].f64) as f32) as f64);
	// 82FCAA58: D161005C  stfs f11, 0x5c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCAA5C: EC0D137A  fmadds f0, f13, f13, f2
	ctx.f[0].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[2].f64) as f32) as f64);
	// 82FCAA60: EDAC033A  fmadds f13, f12, f12, f0
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FCAA64: ED8B6AFA  fmadds f12, f11, f11, f13
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FCAA68: ED60602C  fsqrts f11, f12
	ctx.f[11].f64 = ((ctx.f[12].f64).sqrt() as f32) as f64;
	// 82FCAA6C: FF0B5000  fcmpu cr6, f11, f10
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[10].f64);
	// 82FCAA70: 41990030  bgt cr6, 0x82fcaaa0
	if ctx.cr[6].gt {
	pc = 0x82FCAAA0; continue 'dispatch;
	}
	// 82FCAA74: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82FCAA78: 3BFF0010  addi r31, r31, 0x10
	ctx.r[31].s64 = ctx.r[31].s64 + 16;
	// 82FCAA7C: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FCAA80: 7F1DB800  cmpw cr6, r29, r23
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[23].s32, &mut ctx.xer);
	// 82FCAA84: 4099FF4C  ble cr6, 0x82fca9d0
	if !ctx.cr[6].gt {
	pc = 0x82FCA9D0; continue 'dispatch;
	}
	// 82FCAA88: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCAA8C: 7EC3B378  mr r3, r22
	ctx.r[3].u64 = ctx.r[22].u64;
	// 82FCAA90: 99760000  stb r11, 0(r22)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FCAA94: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82FCAA98: CBE1FFA0  lfd f31, -0x60(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-96 as u32) ) };
	// 82FCAA9C: 481DD704  b 0x831a81a0
	sub_831A8180(ctx, base);
	return;
	// 82FCAAA0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCAAA4: 7EC3B378  mr r3, r22
	ctx.r[3].u64 = ctx.r[22].u64;
	// 82FCAAA8: 99760000  stb r11, 0(r22)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FCAAAC: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82FCAAB0: CBE1FFA0  lfd f31, -0x60(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-96 as u32) ) };
	// 82FCAAB4: 481DD6EC  b 0x831a81a0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCAAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCAAB8 size=360
    let mut pc: u32 = 0x82FCAAB8;
    'dispatch: loop {
        match pc {
            0x82FCAAB8 => {
    //   block [0x82FCAAB8..0x82FCAC20)
	// 82FCAAB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCAABC: 481DD68D  bl 0x831a8148
	ctx.lr = 0x82FCAAC0;
	sub_831A8130(ctx, base);
	// 82FCAAC0: DBC1FF88  stfd f30, -0x78(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-120 as u32), ctx.f[30].u64 ) };
	// 82FCAAC4: DBE1FF90  stfd f31, -0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-112 as u32), ctx.f[31].u64 ) };
	// 82FCAAC8: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCAACC: 7D184378  mr r24, r8
	ctx.r[24].u64 = ctx.r[8].u64;
	// 82FCAAD0: FFC00890  fmr f30, f1
	ctx.f[30].f64 = ctx.f[1].f64;
	// 82FCAAD4: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 82FCAAD8: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 82FCAADC: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82FCAAE0: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FCAAE4: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 82FCAAE8: 7D3A4B78  mr r26, r9
	ctx.r[26].u64 = ctx.r[9].u64;
	// 82FCAAEC: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 82FCAAF0: 2F180000  cmpwi cr6, r24, 0
	ctx.cr[6].compare_i32(ctx.r[24].s32, 0, &mut ctx.xer);
	// 82FCAAF4: 41980108  blt cr6, 0x82fcabfc
	if ctx.cr[6].lt {
	pc = 0x82FCABFC; continue 'dispatch;
	}
	// 82FCAAF8: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 82FCAAFC: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 82FCAB00: C3EBCC2C  lfs f31, -0x33d4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-13268 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCAB04: 817A0000  lwz r11, 0(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAB08: 39410080  addi r10, r1, 0x80
	ctx.r[10].s64 = ctx.r[1].s64 + 128;
	// 82FCAB0C: 3920000A  li r9, 0xa
	ctx.r[9].s64 = 10;
	// 82FCAB10: FC40F890  fmr f2, f31
	ctx.f[2].f64 = ctx.f[31].f64;
	// 82FCAB14: 7CFB5A14  add r7, r27, r11
	ctx.r[7].u64 = ctx.r[27].u64 + ctx.r[11].u64;
	// 82FCAB18: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCAB1C: 39000064  li r8, 0x64
	ctx.r[8].s64 = 100;
	// 82FCAB20: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82FCAB24: 7D7B582E  lwzx r11, r27, r11
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FCAB28: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 82FCAB2C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCAB30: 82C70004  lwz r22, 4(r7)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCAB34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCAB38: 82A70008  lwz r21, 8(r7)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAB3C: 8287000C  lwz r20, 0xc(r7)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAB40: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCAB44: 92CA0004  stw r22, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[22].u32 ) };
	// 82FCAB48: 92AA0008  stw r21, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[21].u32 ) };
	// 82FCAB4C: 928A000C  stw r20, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[20].u32 ) };
	// 82FCAB50: 4BFFF851  bl 0x82fca3a0
	ctx.lr = 0x82FCAB54;
	sub_82FCA3A0(ctx, base);
	// 82FCAB54: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 82FCAB58: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 82FCAB5C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82FCAB60: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCAB64: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82FCAB68: 4BFFE7C9  bl 0x82fc9330
	ctx.lr = 0x82FCAB6C;
	sub_82FC9330(ctx, base);
	// 82FCAB6C: 39410080  addi r10, r1, 0x80
	ctx.r[10].s64 = ctx.r[1].s64 + 128;
	// 82FCAB70: 39210060  addi r9, r1, 0x60
	ctx.r[9].s64 = ctx.r[1].s64 + 96;
	// 82FCAB74: C1210074  lfs f9, 0x74(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCAB78: C1A10080  lfs f13, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCAB7C: C1010070  lfs f8, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAB80: ECED4028  fsubs f7, f13, f8
	ctx.f[7].f64 = (((ctx.f[13].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FCAB84: C0C10078  lfs f6, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCAB88: 810A0000  lwz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAB8C: C081007C  lfs f4, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAB90: 80EA0004  lwz r7, 4(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCAB94: 80CA0008  lwz r6, 8(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAB98: 80AA000C  lwz r5, 0xc(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAB9C: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCABA0: 90E90004  stw r7, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FCABA4: 90C90008  stw r6, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FCABA8: 90A9000C  stw r5, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FCABAC: C1810068  lfs f12, 0x68(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCABB0: C161006C  lfs f11, 0x6c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCABB4: C1410064  lfs f10, 0x64(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCABB8: EC0A4828  fsubs f0, f10, f9
	ctx.f[0].f64 = (((ctx.f[10].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FCABBC: ECA00032  fmuls f5, f0, f0
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCABC0: D0010064  stfs f0, 0x64(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), tmp.u32 ) };
	// 82FCABC4: EDAC3028  fsubs f13, f12, f6
	ctx.f[13].f64 = (((ctx.f[12].f64 - ctx.f[6].f64) as f32) as f64);
	// 82FCABC8: D1A10068  stfs f13, 0x68(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), tmp.u32 ) };
	// 82FCABCC: ED8B2028  fsubs f12, f11, f4
	ctx.f[12].f64 = (((ctx.f[11].f64 - ctx.f[4].f64) as f32) as f64);
	// 82FCABD0: D181006C  stfs f12, 0x6c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), tmp.u32 ) };
	// 82FCABD4: EC6729FA  fmadds f3, f7, f7, f5
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[7].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCABD8: EC4D1B7A  fmadds f2, f13, f13, f3
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[13].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCABDC: EC2C133A  fmadds f1, f12, f12, f2
	ctx.f[1].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[2].f64) as f32) as f64);
	// 82FCABE0: EC00082C  fsqrts f0, f1
	ctx.f[0].f64 = ((ctx.f[1].f64).sqrt() as f32) as f64;
	// 82FCABE4: FF00F000  fcmpu cr6, f0, f30
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[30].f64);
	// 82FCABE8: 41990030  bgt cr6, 0x82fcac18
	if ctx.cr[6].gt {
	pc = 0x82FCAC18; continue 'dispatch;
	}
	// 82FCABEC: 3B390001  addi r25, r25, 1
	ctx.r[25].s64 = ctx.r[25].s64 + 1;
	// 82FCABF0: 3B7B0010  addi r27, r27, 0x10
	ctx.r[27].s64 = ctx.r[27].s64 + 16;
	// 82FCABF4: 7F19C000  cmpw cr6, r25, r24
	ctx.cr[6].compare_i32(ctx.r[25].s32, ctx.r[24].s32, &mut ctx.xer);
	// 82FCABF8: 4099FF0C  ble cr6, 0x82fcab04
	if !ctx.cr[6].gt {
	pc = 0x82FCAB04; continue 'dispatch;
	}
	// 82FCABFC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCAC00: 99770000  stb r11, 0(r23)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FCAC04: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 82FCAC08: 38210110  addi r1, r1, 0x110
	ctx.r[1].s64 = ctx.r[1].s64 + 272;
	// 82FCAC0C: CBC1FF88  lfd f30, -0x78(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-120 as u32) ) };
	// 82FCAC10: CBE1FF90  lfd f31, -0x70(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-112 as u32) ) };
	// 82FCAC14: 481DD584  b 0x831a8198
	sub_831A8180(ctx, base);
	return;
	// 82FCAC18: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCAC1C: 4BFFFFE4  b 0x82fcac00
	pc = 0x82FCAC00; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCAC20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCAC20 size=2828
    let mut pc: u32 = 0x82FCAC20;
    'dispatch: loop {
        match pc {
            0x82FCAC20 => {
    //   block [0x82FCAC20..0x82FCB72C)
	// 82FCAC20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCAC24: 481DD50D  bl 0x831a8130
	ctx.lr = 0x82FCAC28;
	sub_831A8130(ctx, base);
	// 82FCAC28: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 82FCAC2C: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 82FCAC30: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 82FCAC34: 9421FDA0  stwu r1, -0x260(r1)
	ea = ctx.r[1].u32.wrapping_add(-608 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCAC38: 550B083C  slwi r11, r8, 1
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCAC3C: 90610274  stw r3, 0x274(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(628 as u32), ctx.r[3].u32 ) };
	// 82FCAC40: 7CB02B78  mr r16, r5
	ctx.r[16].u64 = ctx.r[5].u64;
	// 82FCAC44: 9101029C  stw r8, 0x29c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(668 as u32), ctx.r[8].u32 ) };
	// 82FCAC48: 7CE45850  subf r7, r4, r11
	ctx.r[7].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 82FCAC4C: 914102AC  stw r10, 0x2ac(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(684 as u32), ctx.r[10].u32 ) };
	// 82FCAC50: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 82FCAC54: 92010284  stw r16, 0x284(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(644 as u32), ctx.r[16].u32 ) };
	// 82FCAC58: 7CA93850  subf r5, r9, r7
	ctx.r[5].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 82FCAC5C: 7D632214  add r11, r3, r4
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[4].u64;
	// 82FCAC60: 93C1028C  stw r30, 0x28c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(652 as u32), ctx.r[30].u32 ) };
	// 82FCAC64: 3CC08200  lis r6, -0x7e00
	ctx.r[6].s64 = -2113929216;
	// 82FCAC68: 7CA30E70  srawi r3, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[3].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 82FCAC6C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCAC70: 3A840001  addi r20, r4, 1
	ctx.r[20].s64 = ctx.r[4].s64 + 1;
	// 82FCAC74: 7E694050  subf r19, r9, r8
	ctx.r[19].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 82FCAC78: 91610104  stw r11, 0x104(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), ctx.r[11].u32 ) };
	// 82FCAC7C: 7CE30194  addze r7, r3
	tmp.s64 = ctx.r[3].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[3].u32);
	ctx.r[7].s64 = tmp.s64;
	// 82FCAC80: C00608A4  lfs f0, 0x8a4(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCAC84: D0010140  stfs f0, 0x140(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), tmp.u32 ) };
	// 82FCAC88: 928100F4  stw r20, 0xf4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), ctx.r[20].u32 ) };
	// 82FCAC8C: D0010144  stfs f0, 0x144(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), tmp.u32 ) };
	// 82FCAC90: 926100FC  stw r19, 0xfc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(252 as u32), ctx.r[19].u32 ) };
	// 82FCAC94: D0010148  stfs f0, 0x148(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), tmp.u32 ) };
	// 82FCAC98: 90E100F0  stw r7, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[7].u32 ) };
	// 82FCAC9C: D001014C  stfs f0, 0x14c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), tmp.u32 ) };
	// 82FCACA0: 7EE44050  subf r23, r4, r8
	ctx.r[23].s64 = ctx.r[8].s64 - ctx.r[4].s64;
	// 82FCACA4: D0010150  stfs f0, 0x150(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), tmp.u32 ) };
	// 82FCACA8: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCACAC: D0010154  stfs f0, 0x154(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), tmp.u32 ) };
	// 82FCACB0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCACB4: D0010158  stfs f0, 0x158(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), tmp.u32 ) };
	// 82FCACB8: D001015C  stfs f0, 0x15c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), tmp.u32 ) };
	// 82FCACBC: D0010160  stfs f0, 0x160(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 82FCACC0: D0010164  stfs f0, 0x164(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), tmp.u32 ) };
	// 82FCACC4: D0010168  stfs f0, 0x168(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), tmp.u32 ) };
	// 82FCACC8: D001016C  stfs f0, 0x16c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), tmp.u32 ) };
	// 82FCACCC: D0010170  stfs f0, 0x170(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), tmp.u32 ) };
	// 82FCACD0: D0010174  stfs f0, 0x174(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(372 as u32), tmp.u32 ) };
	// 82FCACD4: D0010178  stfs f0, 0x178(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), tmp.u32 ) };
	// 82FCACD8: D001017C  stfs f0, 0x17c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(380 as u32), tmp.u32 ) };
	// 82FCACDC: D0010180  stfs f0, 0x180(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), tmp.u32 ) };
	// 82FCACE0: D0010184  stfs f0, 0x184(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(388 as u32), tmp.u32 ) };
	// 82FCACE4: D0010188  stfs f0, 0x188(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), tmp.u32 ) };
	// 82FCACE8: D001018C  stfs f0, 0x18c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), tmp.u32 ) };
	// 82FCACEC: D0010190  stfs f0, 0x190(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), tmp.u32 ) };
	// 82FCACF0: D0010194  stfs f0, 0x194(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), tmp.u32 ) };
	// 82FCACF4: D0010198  stfs f0, 0x198(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), tmp.u32 ) };
	// 82FCACF8: D001019C  stfs f0, 0x19c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), tmp.u32 ) };
	// 82FCACFC: D00101A0  stfs f0, 0x1a0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(416 as u32), tmp.u32 ) };
	// 82FCAD00: D00101A4  stfs f0, 0x1a4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(420 as u32), tmp.u32 ) };
	// 82FCAD04: D00101A8  stfs f0, 0x1a8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(424 as u32), tmp.u32 ) };
	// 82FCAD08: D00101AC  stfs f0, 0x1ac(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(428 as u32), tmp.u32 ) };
	// 82FCAD0C: 40990718  ble cr6, 0x82fcb424
	if !ctx.cr[6].gt {
	pc = 0x82FCB424; continue 'dispatch;
	}
	// 82FCAD10: 7D69A050  subf r11, r9, r20
	ctx.r[11].s64 = ctx.r[20].s64 - ctx.r[9].s64;
	// 82FCAD14: 56FD2036  slwi r29, r23, 4
	ctx.r[29].u32 = ctx.r[23].u32.wrapping_shl(4);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 82FCAD18: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCAD1C: 56F2103A  slwi r18, r23, 2
	ctx.r[18].u32 = ctx.r[23].u32.wrapping_shl(2);
	ctx.r[18].u64 = ctx.r[18].u32 as u64;
	// 82FCAD20: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 82FCAD24: 5571103A  slwi r17, r11, 2
	ctx.r[17].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[17].u64 = ctx.r[17].u32 as u64;
	// 82FCAD28: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCAD2C: 9241005C  stw r18, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[18].u32 ) };
	// 82FCAD30: 3AD7FFFF  addi r22, r23, -1
	ctx.r[22].s64 = ctx.r[23].s64 + -1;
	// 82FCAD34: 92210058  stw r17, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[17].u32 ) };
	// 82FCAD38: 56752036  slwi r21, r19, 4
	ctx.r[21].u32 = ctx.r[19].u32.wrapping_shl(4);
	ctx.r[21].u64 = ctx.r[21].u32 as u64;
	// 82FCAD3C: 92C10054  stw r22, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[22].u32 ) };
	// 82FCAD40: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCAD44: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCAD48: 7F13FA14  add r24, r19, r31
	ctx.r[24].u64 = ctx.r[19].u64 + ctx.r[31].u64;
	// 82FCAD4C: 833E0000  lwz r25, 0(r30)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAD50: 39410150  addi r10, r1, 0x150
	ctx.r[10].s64 = ctx.r[1].s64 + 336;
	// 82FCAD54: 7CF6C050  subf r7, r22, r24
	ctx.r[7].s64 = ctx.r[24].s64 - ctx.r[22].s64;
	// 82FCAD58: 7D7DCA14  add r11, r29, r25
	ctx.r[11].u64 = ctx.r[29].u64 + ctx.r[25].u64;
	// 82FCAD5C: 54E62036  slwi r6, r7, 4
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCAD60: 90E10100  stw r7, 0x100(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), ctx.r[7].u32 ) };
	// 82FCAD64: 7D35CA14  add r9, r21, r25
	ctx.r[9].u64 = ctx.r[21].u64 + ctx.r[25].u64;
	// 82FCAD68: 7D465214  add r10, r6, r10
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[10].u64;
	// 82FCAD6C: 7F97C050  subf r28, r23, r24
	ctx.r[28].s64 = ctx.r[24].s64 - ctx.r[23].s64;
	// 82FCAD70: C1ABFFF0  lfs f13, -0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCAD74: 38CBFFF0  addi r6, r11, -0x10
	ctx.r[6].s64 = ctx.r[11].s64 + -16;
	// 82FCAD78: C18BFFF4  lfs f12, -0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCAD7C: 938100F8  stw r28, 0xf8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), ctx.r[28].u32 ) };
	// 82FCAD80: C16BFFF8  lfs f11, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCAD84: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCAD88: C14BFFFC  lfs f10, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCAD8C: 7F1AC378  mr r26, r24
	ctx.r[26].u64 = ctx.r[24].u64;
	// 82FCAD90: C1290010  lfs f9, 0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCAD94: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 82FCAD98: C1090014  lfs f8, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAD9C: 7CE43B78  mr r4, r7
	ctx.r[4].u64 = ctx.r[7].u64;
	// 82FCADA0: C0E90018  lfs f7, 0x18(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(24 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCADA4: 7F1CF800  cmpw cr6, r28, r31
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCADA8: C0C9001C  lfs f6, 0x1c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCADAC: D1A10140  stfs f13, 0x140(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), tmp.u32 ) };
	// 82FCADB0: D1810144  stfs f12, 0x144(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(324 as u32), tmp.u32 ) };
	// 82FCADB4: D1610148  stfs f11, 0x148(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(328 as u32), tmp.u32 ) };
	// 82FCADB8: D141014C  stfs f10, 0x14c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(332 as u32), tmp.u32 ) };
	// 82FCADBC: D12A0000  stfs f9, 0(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCADC0: D10A0004  stfs f8, 4(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCADC4: D0EA0008  stfs f7, 8(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCADC8: D0CA000C  stfs f6, 0xc(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCADCC: 409902FC  ble cr6, 0x82fcb0c8
	if !ctx.cr[6].gt {
	pc = 0x82FCB0C8; continue 'dispatch;
	}
	// 82FCADD0: 7D7FBA14  add r11, r31, r23
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[23].u64;
	// 82FCADD4: 80D00000  lwz r6, 0(r16)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCADD8: 7D1FC050  subf r8, r31, r24
	ctx.r[8].s64 = ctx.r[24].s64 - ctx.r[31].s64;
	// 82FCADDC: 7CEBA214  add r7, r11, r20
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[20].u64;
	// 82FCADE0: 39610148  addi r11, r1, 0x148
	ctx.r[11].s64 = ctx.r[1].s64 + 328;
	// 82FCADE4: 548A2036  slwi r10, r4, 4
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCADE8: 5508103A  slwi r8, r8, 2
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCADEC: 54E3103A  slwi r3, r7, 2
	ctx.r[3].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FCADF0: 7CFDCA14  add r7, r29, r25
	ctx.r[7].u64 = ctx.r[29].u64 + ctx.r[25].u64;
	// 82FCADF4: 7FD23214  add r30, r18, r6
	ctx.r[30].u64 = ctx.r[18].u64 + ctx.r[6].u64;
	// 82FCADF8: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCADFC: 7F883214  add r28, r8, r6
	ctx.r[28].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 82FCAE00: 7FB13214  add r29, r17, r6
	ctx.r[29].u64 = ctx.r[17].u64 + ctx.r[6].u64;
	// 82FCAE04: 39610154  addi r11, r1, 0x154
	ctx.r[11].s64 = ctx.r[1].s64 + 340;
	// 82FCAE08: 7CC33214  add r6, r3, r6
	ctx.r[6].u64 = ctx.r[3].u64 + ctx.r[6].u64;
	// 82FCAE0C: 810BFFEC  lwz r8, -0x14(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCAE10: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 82FCAE14: 82CBFFF0  lwz r22, -0x10(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCAE18: 3AA10070  addi r21, r1, 0x70
	ctx.r[21].s64 = ctx.r[1].s64 + 112;
	// 82FCAE1C: 828BFFF4  lwz r20, -0xc(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCAE20: C1BE0000  lfs f13, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCAE24: 826BFFF8  lwz r19, -8(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCAE28: C1860000  lfs f12, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCAE2C: 82470000  lwz r18, 0(r7)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAE30: ED4C6828  fsubs f10, f12, f13
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCAE34: 91030000  stw r8, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCAE38: ED616828  fsubs f11, f1, f13
	ctx.f[11].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCAE3C: 92C30004  stw r22, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[22].u32 ) };
	// 82FCAE40: C0BC0000  lfs f5, 0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCAE44: 92830008  stw r20, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[20].u32 ) };
	// 82FCAE48: C09D0000  lfs f4, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAE4C: 9263000C  stw r19, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCAE50: C10100A8  lfs f8, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAE54: C0C100A0  lfs f6, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCAE58: 80670004  lwz r3, 4(r7)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCAE5C: C0E100AC  lfs f7, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCAE60: 82870008  lwz r20, 8(r7)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAE64: 8267000C  lwz r19, 0xc(r7)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAE68: EDA42828  fsubs f13, f4, f5
	ctx.f[13].f64 = (((ctx.f[4].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCAE6C: 92550000  stw r18, 0(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[18].u32 ) };
	// 82FCAE70: EC612828  fsubs f3, f1, f5
	ctx.f[3].f64 = (((ctx.f[1].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCAE74: C12100A4  lfs f9, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCAE78: 39010070  addi r8, r1, 0x70
	ctx.r[8].s64 = ctx.r[1].s64 + 112;
	// 82FCAE7C: 90750004  stw r3, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FCAE80: 3AC10110  addi r22, r1, 0x110
	ctx.r[22].s64 = ctx.r[1].s64 + 272;
	// 82FCAE84: 92950008  stw r20, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[20].u32 ) };
	// 82FCAE88: ED8B5024  fdivs f12, f11, f10
	ctx.f[12].f64 = ((ctx.f[11].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FCAE8C: 9275000C  stw r19, 0xc(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCAE90: C0A10070  lfs f5, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCAE94: C0810074  lfs f4, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAE98: 80690000  lwz r3, 0(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAE9C: C3E10078  lfs f31, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCAEA0: 82A90004  lwz r21, 4(r9)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCAEA4: C3C1007C  lfs f30, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCAEA8: 3A810090  addi r20, r1, 0x90
	ctx.r[20].s64 = ctx.r[1].s64 + 144;
	// 82FCAEAC: 3A6BFFEC  addi r19, r11, -0x14
	ctx.r[19].s64 = ctx.r[11].s64 + -20;
	// 82FCAEB0: 82490008  lwz r18, 8(r9)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAEB4: 3A6A0008  addi r19, r10, 8
	ctx.r[19].s64 = ctx.r[10].s64 + 8;
	// 82FCAEB8: EC636824  fdivs f3, f3, f13
	ctx.f[3].f64 = ((ctx.f[3].f64 / ctx.f[13].f64) as f32) as f64;
	// 82FCAEBC: 3A6100B0  addi r19, r1, 0xb0
	ctx.r[19].s64 = ctx.r[1].s64 + 176;
	// 82FCAEC0: 90740000  stw r3, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 82FCAEC4: ED406028  fsubs f10, f0, f12
	ctx.f[10].f64 = (((ctx.f[0].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCAEC8: 92B40004  stw r21, 4(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), ctx.r[21].u32 ) };
	// 82FCAECC: EFA06024  fdivs f29, f0, f12
	ctx.f[29].f64 = ((ctx.f[0].f64 / ctx.f[12].f64) as f32) as f64;
	// 82FCAED0: ED8902B2  fmuls f12, f9, f10
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCAED4: D18100A4  stfs f12, 0xa4(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCAED8: EDA602B2  fmuls f13, f6, f10
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCAEDC: D1A100A0  stfs f13, 0xa0(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 82FCAEE0: ED6802B2  fmuls f11, f8, f10
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCAEE4: D16100A8  stfs f11, 0xa8(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCAEE8: ED4702B2  fmuls f10, f7, f10
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCAEEC: D14100AC  stfs f10, 0xac(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCAEF0: ED246028  fsubs f9, f4, f12
	ctx.f[9].f64 = (((ctx.f[4].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCAEF4: D1210074  stfs f9, 0x74(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCAEF8: EDA56828  fsubs f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCAEFC: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCAF00: ED1F5828  fsubs f8, f31, f11
	ctx.f[8].f64 = (((ctx.f[31].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCAF04: D1010078  stfs f8, 0x78(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCAF08: ECFE5028  fsubs f7, f30, f10
	ctx.f[7].f64 = (((ctx.f[30].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCAF0C: D0E1007C  stfs f7, 0x7c(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCAF10: 80680008  lwz r3, 8(r8)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAF14: 82A8000C  lwz r21, 0xc(r8)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAF18: 82280000  lwz r17, 0(r8)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCAF1C: 81080004  lwz r8, 4(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCAF20: 90760008  stw r3, 8(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCAF24: 92B6000C  stw r21, 0xc(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(12 as u32), ctx.r[21].u32 ) };
	// 82FCAF28: ECDD0372  fmuls f6, f29, f13
	ctx.f[6].f64 = (((ctx.f[29].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCAF2C: 92360000  stw r17, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[17].u32 ) };
	// 82FCAF30: D0CBFFFC  stfs f6, -4(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCAF34: 91160004  stw r8, 4(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCAF38: C0A10114  lfs f5, 0x114(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(276 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCAF3C: EDA50772  fmuls f13, f5, f29
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[29].f64) as f32) as f64);
	// 82FCAF40: C0810118  lfs f4, 0x118(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAF44: 8069000C  lwz r3, 0xc(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAF48: C161011C  lfs f11, 0x11c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(284 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCAF4C: D1A10114  stfs f13, 0x114(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), tmp.u32 ) };
	// 82FCAF50: ED840772  fmuls f12, f4, f29
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[29].f64) as f32) as f64);
	// 82FCAF54: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCAF58: ED6B0772  fmuls f11, f11, f29
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[29].f64) as f32) as f64);
	// 82FCAF5C: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCAF60: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCAF64: 810A0014  lwz r8, 0x14(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCAF68: 82AA000C  lwz r21, 0xc(r10)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCAF6C: D161011C  stfs f11, 0x11c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(284 as u32), tmp.u32 ) };
	// 82FCAF70: 82CA0008  lwz r22, 8(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCAF74: D1810118  stfs f12, 0x118(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), tmp.u32 ) };
	// 82FCAF78: 9074000C  stw r3, 0xc(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 82FCAF7C: 3A210090  addi r17, r1, 0x90
	ctx.r[17].s64 = ctx.r[1].s64 + 144;
	// 82FCAF80: 806A0010  lwz r3, 0x10(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCAF84: ED201828  fsubs f9, f0, f3
	ctx.f[9].f64 = (((ctx.f[0].f64 - ctx.f[3].f64) as f32) as f64);
	// 82FCAF88: 90730008  stw r3, 8(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCAF8C: 38A50001  addi r5, r5, 1
	ctx.r[5].s64 = ctx.r[5].s64 + 1;
	// 82FCAF90: 9113000C  stw r8, 0xc(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCAF94: 3B5AFFFF  addi r26, r26, -1
	ctx.r[26].s64 = ctx.r[26].s64 + -1;
	// 82FCAF98: 92B30004  stw r21, 4(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), ctx.r[21].u32 ) };
	// 82FCAF9C: 3AA10130  addi r21, r1, 0x130
	ctx.r[21].s64 = ctx.r[1].s64 + 304;
	// 82FCAFA0: 92D30000  stw r22, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[22].u32 ) };
	// 82FCAFA4: C18100B4  lfs f12, 0xb4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCAFA8: 92540008  stw r18, 8(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), ctx.r[18].u32 ) };
	// 82FCAFAC: C0A10098  lfs f5, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCAFB0: ED8C00F2  fmuls f12, f12, f3
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCAFB4: C0E1009C  lfs f7, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCAFB8: C0C100B8  lfs f6, 0xb8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCAFBC: 7D05D050  subf r8, r5, r26
	ctx.r[8].s64 = ctx.r[26].s64 - ctx.r[5].s64;
	// 82FCAFC0: ED6600F2  fmuls f11, f6, f3
	ctx.f[11].f64 = (((ctx.f[6].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCAFC4: C0C10094  lfs f6, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCAFC8: C08100B0  lfs f4, 0xb0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCAFCC: 7F08F800  cmpw cr6, r8, r31
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCAFD0: C10100BC  lfs f8, 0xbc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAFD4: ED4800F2  fmuls f10, f8, f3
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCAFD8: EDA400F2  fmuls f13, f4, f3
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCAFDC: C1010090  lfs f8, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCAFE0: D1A100B0  stfs f13, 0xb0(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), tmp.u32 ) };
	// 82FCAFE4: ECA55828  fsubs f5, f5, f11
	ctx.f[5].f64 = (((ctx.f[5].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCAFE8: ECE75028  fsubs f7, f7, f10
	ctx.f[7].f64 = (((ctx.f[7].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCAFEC: D0E1009C  stfs f7, 0x9c(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCAFF0: EC666028  fsubs f3, f6, f12
	ctx.f[3].f64 = (((ctx.f[6].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCAFF4: D0A10098  stfs f5, 0x98(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCAFF8: D0610094  stfs f3, 0x94(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCAFFC: EC804824  fdivs f4, f0, f9
	ctx.f[4].f64 = ((ctx.f[0].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FCB000: D14100BC  stfs f10, 0xbc(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), tmp.u32 ) };
	// 82FCB004: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 82FCB008: D16100B8  stfs f11, 0xb8(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), tmp.u32 ) };
	// 82FCB00C: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FCB010: D18100B4  stfs f12, 0xb4(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), tmp.u32 ) };
	// 82FCB014: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 82FCB018: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 82FCB01C: 3BBDFFFC  addi r29, r29, -4
	ctx.r[29].s64 = ctx.r[29].s64 + -4;
	// 82FCB020: EDA86828  fsubs f13, f8, f13
	ctx.f[13].f64 = (((ctx.f[8].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCB024: D1A10090  stfs f13, 0x90(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCB028: 80710008  lwz r3, 8(r17)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB02C: EDA40372  fmuls f13, f4, f13
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCB030: 90750008  stw r3, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCB034: D1AAFFF8  stfs f13, -8(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCB038: 80710000  lwz r3, 0(r17)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB03C: 3B9CFFFC  addi r28, r28, -4
	ctx.r[28].s64 = ctx.r[28].s64 + -4;
	// 82FCB040: 90750000  stw r3, 0(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 82FCB044: 3929FFF0  addi r9, r9, -0x10
	ctx.r[9].s64 = ctx.r[9].s64 + -16;
	// 82FCB048: 8071000C  lwz r3, 0xc(r17)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB04C: 3884FFFF  addi r4, r4, -1
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	// 82FCB050: 81110004  lwz r8, 4(r17)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB054: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCB058: 91150004  stw r8, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCB05C: 9075000C  stw r3, 0xc(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 82FCB060: C1210134  lfs f9, 0x134(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(308 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCB064: C161013C  lfs f11, 0x13c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(316 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB068: ED6B0132  fmuls f11, f11, f4
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCB06C: C1410138  lfs f10, 0x138(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB070: EDA90132  fmuls f13, f9, f4
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCB074: ED8A0132  fmuls f12, f10, f4
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCB078: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCB07C: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB080: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB084: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCB088: D1A10134  stfs f13, 0x134(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), tmp.u32 ) };
	// 82FCB08C: D1810138  stfs f12, 0x138(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), tmp.u32 ) };
	// 82FCB090: D161013C  stfs f11, 0x13c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), tmp.u32 ) };
	// 82FCB094: 4199FD78  bgt cr6, 0x82fcae0c
	if ctx.cr[6].gt {
	pc = 0x82FCAE0C; continue 'dispatch;
	}
	// 82FCB098: 80E10100  lwz r7, 0x100(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(256 as u32) ) } as u64;
	// 82FCB09C: 82210058  lwz r17, 0x58(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82FCB0A0: 82A10060  lwz r21, 0x60(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCB0A4: 82C10054  lwz r22, 0x54(r1)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 82FCB0A8: 8241005C  lwz r18, 0x5c(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 82FCB0AC: 83A10050  lwz r29, 0x50(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FCB0B0: 838100F8  lwz r28, 0xf8(r1)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(248 as u32) ) } as u64;
	// 82FCB0B4: 826100FC  lwz r19, 0xfc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(252 as u32) ) } as u64;
	// 82FCB0B8: 828100F4  lwz r20, 0xf4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(244 as u32) ) } as u64;
	// 82FCB0BC: 82010284  lwz r16, 0x284(r1)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(644 as u32) ) } as u64;
	// 82FCB0C0: 83C1028C  lwz r30, 0x28c(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(652 as u32) ) } as u64;
	// 82FCB0C4: 8101029C  lwz r8, 0x29c(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(668 as u32) ) } as u64;
	// 82FCB0C8: 7D65D050  subf r11, r5, r26
	ctx.r[11].s64 = ctx.r[26].s64 - ctx.r[5].s64;
	// 82FCB0CC: 7F0BF800  cmpw cr6, r11, r31
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCB0D0: 409800A0  bge cr6, 0x82fcb170
	if !ctx.cr[6].lt {
	pc = 0x82FCB170; continue 'dispatch;
	}
	// 82FCB0D4: 548A2036  slwi r10, r4, 4
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB0D8: 39610150  addi r11, r1, 0x150
	ctx.r[11].s64 = ctx.r[1].s64 + 336;
	// 82FCB0DC: 392100C0  addi r9, r1, 0xc0
	ctx.r[9].s64 = ctx.r[1].s64 + 192;
	// 82FCB0E0: 7CCA5A14  add r6, r10, r11
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCB0E4: 576A2036  slwi r10, r27, 4
	ctx.r[10].u32 = ctx.r[27].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB0E8: 39610140  addi r11, r1, 0x140
	ctx.r[11].s64 = ctx.r[1].s64 + 320;
	// 82FCB0EC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCB0F0: 80A60008  lwz r5, 8(r6)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB0F4: 8086000C  lwz r4, 0xc(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB0F8: 394BFFF0  addi r10, r11, -0x10
	ctx.r[10].s64 = ctx.r[11].s64 + -16;
	// 82FCB0FC: 80660004  lwz r3, 4(r6)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB100: 81460000  lwz r10, 0(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB104: C1ABFFF4  lfs f13, -0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB108: 90A90008  stw r5, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 82FCB10C: C18BFFF0  lfs f12, -0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCB110: 9089000C  stw r4, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FCB114: C16BFFF8  lfs f11, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB118: 90690004  stw r3, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FCB11C: C14BFFFC  lfs f10, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB120: 91490000  stw r10, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCB124: C0C100C4  lfs f6, 0xc4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCB128: EDA66828  fsubs f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCB12C: D1A100C4  stfs f13, 0xc4(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(196 as u32), tmp.u32 ) };
	// 82FCB130: C0E100C8  lfs f7, 0xc8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCB134: ECAD0372  fmuls f5, f13, f13
	ctx.f[5].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCB138: C12100CC  lfs f9, 0xcc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(204 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCB13C: C10100C0  lfs f8, 0xc0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCB140: ED886028  fsubs f12, f8, f12
	ctx.f[12].f64 = (((ctx.f[8].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCB144: ED675828  fsubs f11, f7, f11
	ctx.f[11].f64 = (((ctx.f[7].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCB148: D18100C0  stfs f12, 0xc0(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 82FCB14C: EC8C2B3A  fmadds f4, f12, f12, f5
	ctx.f[4].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCB150: D16100C8  stfs f11, 0xc8(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), tmp.u32 ) };
	// 82FCB154: ED495028  fsubs f10, f9, f10
	ctx.f[10].f64 = (((ctx.f[9].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCB158: D14100CC  stfs f10, 0xcc(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(204 as u32), tmp.u32 ) };
	// 82FCB15C: EC6B22FA  fmadds f3, f11, f11, f4
	ctx.f[3].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCB160: EDAA1ABA  fmadds f13, f10, f10, f3
	ctx.f[13].f64 = (((ctx.f[10].f64 * ctx.f[10].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCB164: ED80682C  fsqrts f12, f13
	ctx.f[12].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 82FCB168: FF0C1000  fcmpu cr6, f12, f2
	ctx.cr[6].compare_f64(ctx.f[12].f64, ctx.f[2].f64);
	// 82FCB16C: 480001CC  b 0x82fcb338
	pc = 0x82FCB338; continue 'dispatch;
	// 82FCB170: 7D7BFA14  add r11, r27, r31
	ctx.r[11].u64 = ctx.r[27].u64 + ctx.r[31].u64;
	// 82FCB174: 80D00000  lwz r6, 0(r16)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB178: 54BA103A  slwi r26, r5, 2
	ctx.r[26].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[26].u64 = ctx.r[26].u32 as u64;
	// 82FCB17C: 55692036  slwi r9, r11, 4
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCB180: 7D65FA14  add r11, r5, r31
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[31].u64;
	// 82FCB184: 39410150  addi r10, r1, 0x150
	ctx.r[10].s64 = ctx.r[1].s64 + 336;
	// 82FCB188: 7DEBA214  add r15, r11, r20
	ctx.r[15].u64 = ctx.r[11].u64 + ctx.r[20].u64;
	// 82FCB18C: 7C695214  add r3, r9, r10
	ctx.r[3].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCB190: 7DBA342E  lfsx f13, r26, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[26].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB194: 55EF103A  slwi r15, r15, 2
	ctx.r[15].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[15].u64 = ctx.r[15].u32 as u64;
	// 82FCB198: ED816828  fsubs f12, f1, f13
	ctx.f[12].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCB19C: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 82FCB1A0: 7D29502E  lwzx r9, r9, r10
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCB1A4: 576A2036  slwi r10, r27, 4
	ctx.r[10].u32 = ctx.r[27].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB1A8: 39610140  addi r11, r1, 0x140
	ctx.r[11].s64 = ctx.r[1].s64 + 320;
	// 82FCB1AC: 83630004  lwz r27, 4(r3)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB1B0: 3B4100D0  addi r26, r1, 0xd0
	ctx.r[26].s64 = ctx.r[1].s64 + 208;
	// 82FCB1B4: 7D6F342E  lfsx f11, r15, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[15].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB1B8: 81C30008  lwz r14, 8(r3)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB1BC: ED4B6828  fsubs f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCB1C0: 8063000C  lwz r3, 0xc(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB1C4: 91240000  stw r9, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82FCB1C8: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCB1CC: 394100E0  addi r10, r1, 0xe0
	ctx.r[10].s64 = ctx.r[1].s64 + 224;
	// 82FCB1D0: 93640004  stw r27, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[27].u32 ) };
	// 82FCB1D4: 392BFFF0  addi r9, r11, -0x10
	ctx.r[9].s64 = ctx.r[11].s64 + -16;
	// 82FCB1D8: 91C40008  stw r14, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[14].u32 ) };
	// 82FCB1DC: 54AB2036  slwi r11, r5, 4
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB1E0: 9064000C  stw r3, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 82FCB1E4: C0610088  lfs f3, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCB1E8: C161008C  lfs f11, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB1EC: 7D6BCA14  add r11, r11, r25
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[25].u64;
	// 82FCB1F0: C1A10080  lfs f13, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB1F4: 38C10080  addi r6, r1, 0x80
	ctx.r[6].s64 = ctx.r[1].s64 + 128;
	// 82FCB1F8: 80890000  lwz r4, 0(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB1FC: 38A100D0  addi r5, r1, 0xd0
	ctx.r[5].s64 = ctx.r[1].s64 + 208;
	// 82FCB200: 80690004  lwz r3, 4(r9)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB204: 3B210120  addi r25, r1, 0x120
	ctx.r[25].s64 = ctx.r[1].s64 + 288;
	// 82FCB208: ECEC5024  fdivs f7, f12, f10
	ctx.f[7].f64 = ((ctx.f[12].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FCB20C: C1410084  lfs f10, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB210: 83690008  lwz r27, 8(r9)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB214: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCB218: C0CB0004  lfs f6, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCB21C: 8129000C  lwz r9, 0xc(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB220: 908A0000  stw r4, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCB224: C0AB0008  lfs f5, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCB228: 906A0004  stw r3, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FCB22C: C08B000C  lfs f4, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCB230: 936A0008  stw r27, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[27].u32 ) };
	// 82FCB234: 912A000C  stw r9, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 82FCB238: EDAD01F2  fmuls f13, f13, f7
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB23C: D1A10080  stfs f13, 0x80(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCB240: ED8301F2  fmuls f12, f3, f7
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB244: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCB248: ED2B01F2  fmuls f9, f11, f7
	ctx.f[9].f64 = (((ctx.f[11].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB24C: D121008C  stfs f9, 0x8c(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCB250: EC6A01F2  fmuls f3, f10, f7
	ctx.f[3].f64 = (((ctx.f[10].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB254: D0610084  stfs f3, 0x84(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCB258: 8086000C  lwz r4, 0xc(r6)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB25C: C16100E0  lfs f11, 0xe0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB260: 81660000  lwz r11, 0(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB264: C14100E4  lfs f10, 0xe4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB268: C06100EC  lfs f3, 0xec(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(236 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCB26C: ECE03828  fsubs f7, f0, f7
	ctx.f[7].f64 = (((ctx.f[0].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FCB270: 80660008  lwz r3, 8(r6)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB274: C3E100E8  lfs f31, 0xe8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCB278: 90650008  stw r3, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCB27C: 81460004  lwz r10, 4(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB280: ED8B01F2  fmuls f12, f11, f7
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB284: 91450004  stw r10, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCB288: ED6A01F2  fmuls f11, f10, f7
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB28C: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCB290: ED5F01F2  fmuls f10, f31, f7
	ctx.f[10].f64 = (((ctx.f[31].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB294: 9085000C  stw r4, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FCB298: ED2301F2  fmuls f9, f3, f7
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCB29C: D18100E0  stfs f12, 0xe0(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 82FCB2A0: EDAD602A  fadds f13, f13, f12
	ctx.f[13].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCB2A4: D16100E4  stfs f11, 0xe4(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 82FCB2A8: D14100E8  stfs f10, 0xe8(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 82FCB2AC: D12100EC  stfs f9, 0xec(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 82FCB2B0: C0E100D4  lfs f7, 0xd4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCB2B4: ED87582A  fadds f12, f7, f11
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCB2B8: C16100DC  lfs f11, 0xdc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB2BC: ED2B482A  fadds f9, f11, f9
	ctx.f[9].f64 = ((ctx.f[11].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FCB2C0: D1A100D0  stfs f13, 0xd0(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 82FCB2C4: D18100D4  stfs f12, 0xd4(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 82FCB2C8: ED0D4028  fsubs f8, f13, f8
	ctx.f[8].f64 = (((ctx.f[13].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FCB2CC: D12100DC  stfs f9, 0xdc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 82FCB2D0: C06100D8  lfs f3, 0xd8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCB2D4: ED43502A  fadds f10, f3, f10
	ctx.f[10].f64 = ((ctx.f[3].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCB2D8: D14100D8  stfs f10, 0xd8(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 82FCB2DC: 80DA000C  lwz r6, 0xc(r26)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCB2E0: 80BA0004  lwz r5, 4(r26)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB2E4: 809A0008  lwz r4, 8(r26)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB2E8: 813A0000  lwz r9, 0(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB2EC: 91390000  stw r9, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82FCB2F0: 90D9000C  stw r6, 0xc(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FCB2F4: 90B90004  stw r5, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCB2F8: 90990008  stw r4, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCB2FC: C0E10124  lfs f7, 0x124(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(292 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCB300: EDA73028  fsubs f13, f7, f6
	ctx.f[13].f64 = (((ctx.f[7].f64 - ctx.f[6].f64) as f32) as f64);
	// 82FCB304: C0C10128  lfs f6, 0x128(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(296 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCB308: ED862828  fsubs f12, f6, f5
	ctx.f[12].f64 = (((ctx.f[6].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCB30C: C0A1012C  lfs f5, 0x12c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(300 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCB310: ED652028  fsubs f11, f5, f4
	ctx.f[11].f64 = (((ctx.f[5].f64 - ctx.f[4].f64) as f32) as f64);
	// 82FCB314: D1A10124  stfs f13, 0x124(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(292 as u32), tmp.u32 ) };
	// 82FCB318: D1810128  stfs f12, 0x128(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), tmp.u32 ) };
	// 82FCB31C: D161012C  stfs f11, 0x12c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(300 as u32), tmp.u32 ) };
	// 82FCB320: EC8D0372  fmuls f4, f13, f13
	ctx.f[4].f64 = (((ctx.f[13].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCB324: EC68223A  fmadds f3, f8, f8, f4
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCB328: EDAC1B3A  fmadds f13, f12, f12, f3
	ctx.f[13].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 82FCB32C: ED8B6AFA  fmadds f12, f11, f11, f13
	ctx.f[12].f64 = (((ctx.f[11].f64 * ctx.f[11].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FCB330: ED60602C  fsqrts f11, f12
	ctx.f[11].f64 = ((ctx.f[12].f64).sqrt() as f32) as f64;
	// 82FCB334: FF0B1000  fcmpu cr6, f11, f2
	ctx.cr[6].compare_f64(ctx.f[11].f64, ctx.f[2].f64);
	// 82FCB338: 419900E4  bgt cr6, 0x82fcb41c
	if ctx.cr[6].gt {
	pc = 0x82FCB41C; continue 'dispatch;
	}
	// 82FCB33C: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCB340: 7F1CF800  cmpw cr6, r28, r31
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCB344: 4099009C  ble cr6, 0x82fcb3e0
	if !ctx.cr[6].gt {
	pc = 0x82FCB3E0; continue 'dispatch;
	}
	// 82FCB348: 7D36B850  subf r9, r22, r23
	ctx.r[9].s64 = ctx.r[23].s64 - ctx.r[22].s64;
	// 82FCB34C: 54EA2036  slwi r10, r7, 4
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB350: 39610148  addi r11, r1, 0x148
	ctx.r[11].s64 = ctx.r[1].s64 + 328;
	// 82FCB354: 55242036  slwi r4, r9, 4
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCB358: 39210148  addi r9, r1, 0x148
	ctx.r[9].s64 = ctx.r[1].s64 + 328;
	// 82FCB35C: 7D4A5A14  add r10, r10, r11
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCB360: 7EA6AB78  mr r6, r21
	ctx.r[6].u64 = ctx.r[21].u64;
	// 82FCB364: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 82FCB368: 7D644A14  add r11, r4, r9
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[9].u64;
	// 82FCB36C: 813E0000  lwz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB370: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB374: C18BFFF8  lfs f12, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCB378: 38A50001  addi r5, r5, 1
	ctx.r[5].s64 = ctx.r[5].s64 + 1;
	// 82FCB37C: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 82FCB380: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB384: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB388: 3B18FFFF  addi r24, r24, -1
	ctx.r[24].s64 = ctx.r[24].s64 + -1;
	// 82FCB38C: C12AFFF8  lfs f9, -8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCB390: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 82FCB394: 7C85C050  subf r4, r5, r24
	ctx.r[4].s64 = ctx.r[24].s64 - ctx.r[5].s64;
	// 82FCB398: C10AFFFC  lfs f8, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCB39C: C0EA0000  lfs f7, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCB3A0: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCB3A4: D1A90004  stfs f13, 4(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB3A8: 7F04F800  cmpw cr6, r4, r31
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCB3AC: D1890000  stfs f12, 0(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB3B0: D169000C  stfs f11, 0xc(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCB3B4: D1490008  stfs f10, 8(r9)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCB3B8: C0CA0004  lfs f6, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCB3BC: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCB3C0: 813E0000  lwz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB3C4: 7D293214  add r9, r9, r6
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 82FCB3C8: 38C6FFF0  addi r6, r6, -0x10
	ctx.r[6].s64 = ctx.r[6].s64 + -16;
	// 82FCB3CC: D1290000  stfs f9, 0(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB3D0: D1090004  stfs f8, 4(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB3D4: D0E90008  stfs f7, 8(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCB3D8: D0C9000C  stfs f6, 0xc(r9)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCB3DC: 4199FF90  bgt cr6, 0x82fcb36c
	if ctx.cr[6].gt {
	pc = 0x82FCB36C; continue 'dispatch;
	}
	// 82FCB3E0: 816102AC  lwz r11, 0x2ac(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(684 as u32) ) } as u64;
	// 82FCB3E4: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCB3E8: 3AD6FFFF  addi r22, r22, -1
	ctx.r[22].s64 = ctx.r[22].s64 + -1;
	// 82FCB3EC: 3A52FFFC  addi r18, r18, -4
	ctx.r[18].s64 = ctx.r[18].s64 + -4;
	// 82FCB3F0: 3BBDFFF0  addi r29, r29, -0x10
	ctx.r[29].s64 = ctx.r[29].s64 + -16;
	// 82FCB3F4: 92C10054  stw r22, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[22].u32 ) };
	// 82FCB3F8: 3A310004  addi r17, r17, 4
	ctx.r[17].s64 = ctx.r[17].s64 + 4;
	// 82FCB3FC: 9241005C  stw r18, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[18].u32 ) };
	// 82FCB400: 3AB50010  addi r21, r21, 0x10
	ctx.r[21].s64 = ctx.r[21].s64 + 16;
	// 82FCB404: 93A10050  stw r29, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[29].u32 ) };
	// 82FCB408: 3AF7FFFF  addi r23, r23, -1
	ctx.r[23].s64 = ctx.r[23].s64 + -1;
	// 82FCB40C: 92210058  stw r17, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[17].u32 ) };
	// 82FCB410: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCB414: 7F1F5800  cmpw cr6, r31, r11
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCB418: 4198F930  blt cr6, 0x82fcad48
	if ctx.cr[6].lt {
	pc = 0x82FCAD48; continue 'dispatch;
	}
	// 82FCB41C: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCB420: 409A001C  bne cr6, 0x82fcb43c
	if !ctx.cr[6].eq {
	pc = 0x82FCB43C; continue 'dispatch;
	}
	// 82FCB424: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FCB428: 38210260  addi r1, r1, 0x260
	ctx.r[1].s64 = ctx.r[1].s64 + 608;
	// 82FCB42C: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 82FCB430: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 82FCB434: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 82FCB438: 481DCD48  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
	// 82FCB43C: 80810104  lwz r4, 0x104(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(260 as u32) ) } as u64;
	// 82FCB440: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82FCB444: 7D682050  subf r11, r8, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FCB448: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCB44C: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCB450: 41980080  blt cr6, 0x82fcb4d0
	if ctx.cr[6].lt {
	pc = 0x82FCB4D0; continue 'dispatch;
	}
	// 82FCB454: 7D682050  subf r11, r8, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FCB458: 7D5F4050  subf r10, r31, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 82FCB45C: 392BFFFD  addi r9, r11, -3
	ctx.r[9].s64 = ctx.r[11].s64 + -3;
	// 82FCB460: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB464: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCB468: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB46C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCB470: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCB474: 7D074214  add r8, r7, r8
	ctx.r[8].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCB478: 80B00000  lwz r5, 0(r16)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB47C: 38EB000C  addi r7, r11, 0xc
	ctx.r[7].s64 = ctx.r[11].s64 + 12;
	// 82FCB480: 38CA000C  addi r6, r10, 0xc
	ctx.r[6].s64 = ctx.r[10].s64 + 12;
	// 82FCB484: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCB488: 7C055C2E  lfsx f0, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCB48C: 7C05552E  stfsx f0, r5, r10
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCB490: 80B00000  lwz r5, 0(r16)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB494: 7C655A14  add r3, r5, r11
	ctx.r[3].u64 = ctx.r[5].u64 + ctx.r[11].u64;
	// 82FCB498: 7CA55214  add r5, r5, r10
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[10].u64;
	// 82FCB49C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCB4A0: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCB4A4: C1A30004  lfs f13, 4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB4A8: D1A50004  stfs f13, 4(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB4AC: 80B00000  lwz r5, 0(r16)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB4B0: 7C653A14  add r3, r5, r7
	ctx.r[3].u64 = ctx.r[5].u64 + ctx.r[7].u64;
	// 82FCB4B4: 7CA53214  add r5, r5, r6
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 82FCB4B8: C183FFFC  lfs f12, -4(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCB4BC: D185FFFC  stfs f12, -4(r5)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCB4C0: 80700000  lwz r3, 0(r16)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB4C4: 7D633C2E  lfsx f11, r3, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB4C8: 7D63352E  stfsx f11, r3, r6
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[3].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 82FCB4CC: 4082FFAC  bne 0x82fcb478
	if !ctx.cr[0].eq {
	pc = 0x82FCB478; continue 'dispatch;
	}
	// 82FCB4D0: 7F082000  cmpw cr6, r8, r4
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FCB4D4: 41990034  bgt cr6, 0x82fcb508
	if ctx.cr[6].gt {
	pc = 0x82FCB508; continue 'dispatch;
	}
	// 82FCB4D8: 7D3F4050  subf r9, r31, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[31].s64;
	// 82FCB4DC: 7D682050  subf r11, r8, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FCB4E0: 550A103A  slwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB4E4: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCB4E8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCB4EC: 81100000  lwz r8, 0(r16)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB4F0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCB4F4: 7C08542E  lfsx f0, r8, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCB4F8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCB4FC: 7C084D2E  stfsx f0, r8, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCB500: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FCB504: 4082FFE8  bne 0x82fcb4ec
	if !ctx.cr[0].eq {
	pc = 0x82FCB4EC; continue 'dispatch;
	}
	// 82FCB508: 814100F0  lwz r10, 0xf0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) } as u64;
	// 82FCB50C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCB510: 2F1F0001  cmpwi cr6, r31, 1
	ctx.cr[6].compare_i32(ctx.r[31].s32, 1, &mut ctx.xer);
	// 82FCB514: 7D5D5378  mr r29, r10
	ctx.r[29].u64 = ctx.r[10].u64;
	// 82FCB518: 40990028  ble cr6, 0x82fcb540
	if !ctx.cr[6].gt {
	pc = 0x82FCB540; continue 'dispatch;
	}
	// 82FCB51C: 556907FE  clrlwi r9, r11, 0x1f
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 82FCB520: 2F090001  cmpwi cr6, r9, 1
	ctx.cr[6].compare_i32(ctx.r[9].s32, 1, &mut ctx.xer);
	// 82FCB524: 409A000C  bne cr6, 0x82fcb530
	if !ctx.cr[6].eq {
	pc = 0x82FCB530; continue 'dispatch;
	}
	// 82FCB528: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCB52C: 48000008  b 0x82fcb534
	pc = 0x82FCB534; continue 'dispatch;
	// 82FCB530: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 82FCB534: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCB538: 7F0BF800  cmpw cr6, r11, r31
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCB53C: 4198FFE0  blt cr6, 0x82fcb51c
	if ctx.cr[6].lt {
	pc = 0x82FCB51C; continue 'dispatch;
	}
	// 82FCB540: 80610274  lwz r3, 0x274(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(628 as u32) ) } as u64;
	// 82FCB544: 388A0001  addi r4, r10, 1
	ctx.r[4].s64 = ctx.r[10].s64 + 1;
	// 82FCB548: 7D641850  subf r11, r4, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[4].s64;
	// 82FCB54C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCB550: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCB554: 419800F0  blt cr6, 0x82fcb644
	if ctx.cr[6].lt {
	pc = 0x82FCB644; continue 'dispatch;
	}
	// 82FCB558: 7D441850  subf r10, r4, r3
	ctx.r[10].s64 = ctx.r[3].s64 - ctx.r[4].s64;
	// 82FCB55C: 57AB2036  slwi r11, r29, 4
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB560: 392AFFFD  addi r9, r10, -3
	ctx.r[9].s64 = ctx.r[10].s64 + -3;
	// 82FCB564: 548A2036  slwi r10, r4, 4
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB568: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCB56C: 38E90001  addi r7, r9, 1
	ctx.r[7].s64 = ctx.r[9].s64 + 1;
	// 82FCB570: 54E9103A  slwi r9, r7, 2
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCB574: 7FA9EA14  add r29, r9, r29
	ctx.r[29].u64 = ctx.r[9].u64 + ctx.r[29].u64;
	// 82FCB578: 7C892214  add r4, r9, r4
	ctx.r[4].u64 = ctx.r[9].u64 + ctx.r[4].u64;
	// 82FCB57C: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB580: 38CA0030  addi r6, r10, 0x30
	ctx.r[6].s64 = ctx.r[10].s64 + 48;
	// 82FCB584: 38AB0030  addi r5, r11, 0x30
	ctx.r[5].s64 = ctx.r[11].s64 + 48;
	// 82FCB588: 7D2A4214  add r9, r10, r8
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FCB58C: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCB590: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCB594: C0090000  lfs f0, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCB598: D0080000  stfs f0, 0(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB59C: C1A90004  lfs f13, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB5A0: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB5A4: C1890008  lfs f12, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCB5A8: D1880008  stfs f12, 8(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCB5AC: C169000C  lfs f11, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB5B0: D168000C  stfs f11, 0xc(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCB5B4: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB5B8: 7D2A4214  add r9, r10, r8
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FCB5BC: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCB5C0: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCB5C4: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCB5C8: C1490010  lfs f10, 0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCB5CC: D1480010  stfs f10, 0x10(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCB5D0: C1290014  lfs f9, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCB5D4: D1280014  stfs f9, 0x14(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCB5D8: C1090018  lfs f8, 0x18(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(24 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCB5DC: D1080018  stfs f8, 0x18(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82FCB5E0: C0E9001C  lfs f7, 0x1c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCB5E4: D0E8001C  stfs f7, 0x1c(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82FCB5E8: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB5EC: 7D264214  add r9, r6, r8
	ctx.r[9].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 82FCB5F0: 7D054214  add r8, r5, r8
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[8].u64;
	// 82FCB5F4: C0C9FFF0  lfs f6, -0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-16 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCB5F8: D0C8FFF0  stfs f6, -0x10(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FCB5FC: C0A9FFF4  lfs f5, -0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCB600: D0A8FFF4  stfs f5, -0xc(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FCB604: C089FFF8  lfs f4, -8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-8 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCB608: D088FFF8  stfs f4, -8(r8)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCB60C: C069FFFC  lfs f3, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCB610: D068FFFC  stfs f3, -4(r8)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCB614: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB618: 7D264214  add r9, r6, r8
	ctx.r[9].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 82FCB61C: 7D054214  add r8, r5, r8
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[8].u64;
	// 82FCB620: C0490000  lfs f2, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCB624: D0480000  stfs f2, 0(r8)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB628: C0290004  lfs f1, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCB62C: D0280004  stfs f1, 4(r8)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB630: C0090008  lfs f0, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCB634: D0080008  stfs f0, 8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCB638: C1A9000C  lfs f13, 0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB63C: D1A8000C  stfs f13, 0xc(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCB640: 4082FF3C  bne 0x82fcb57c
	if !ctx.cr[0].eq {
	pc = 0x82FCB57C; continue 'dispatch;
	}
	// 82FCB644: 7F041800  cmpw cr6, r4, r3
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FCB648: 41990050  bgt cr6, 0x82fcb698
	if ctx.cr[6].gt {
	pc = 0x82FCB698; continue 'dispatch;
	}
	// 82FCB64C: 7D641850  subf r11, r4, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[4].s64;
	// 82FCB650: 57A82036  slwi r8, r29, 4
	ctx.r[8].u32 = ctx.r[29].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCB654: 54872036  slwi r7, r4, 4
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCB658: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FCB65C: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB660: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCB664: 7D675214  add r11, r7, r10
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[10].u64;
	// 82FCB668: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82FCB66C: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCB670: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 82FCB674: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCB678: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCB67C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCB680: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCB684: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCB688: D18A0008  stfs f12, 8(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCB68C: C16B000C  lfs f11, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCB690: D16A000C  stfs f11, 0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCB694: 4082FFC8  bne 0x82fcb65c
	if !ctx.cr[0].eq {
	pc = 0x82FCB65C; continue 'dispatch;
	}
	// 82FCB698: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB69C: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB6A0: 838102AC  lwz r28, 0x2ac(r1)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(684 as u32) ) } as u64;
	// 82FCB6A4: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCB6A8: 7FBC5050  subf r29, r28, r10
	ctx.r[29].s64 = ctx.r[10].s64 - ctx.r[28].s64;
	// 82FCB6AC: 7F0BE800  cmpw cr6, r11, r29
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCB6B0: 40980024  bge cr6, 0x82fcb6d4
	if !ctx.cr[6].lt {
	pc = 0x82FCB6D4; continue 'dispatch;
	}
	// 82FCB6B4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB6B8: 7F1D5800  cmpw cr6, r29, r11
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCB6BC: 41980008  blt cr6, 0x82fcb6c4
	if ctx.cr[6].lt {
	pc = 0x82FCB6C4; continue 'dispatch;
	}
	// 82FCB6C0: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCB6C4: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82FCB6C8: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCB6CC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCB6D0: 4BEDB129  bl 0x82ea67f8
	ctx.lr = 0x82FCB6D4;
	sub_82EA67F8(ctx, base);
	// 82FCB6D4: 93BE0004  stw r29, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCB6D8: 81300008  lwz r9, 8(r16)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCB6DC: 81500004  lwz r10, 4(r16)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCB6E0: 7FDC5050  subf r30, r28, r10
	ctx.r[30].s64 = ctx.r[10].s64 - ctx.r[28].s64;
	// 82FCB6E4: 552B00BE  clrlwi r11, r9, 2
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCB6E8: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FCB6EC: 40980024  bge cr6, 0x82fcb710
	if !ctx.cr[6].lt {
	pc = 0x82FCB710; continue 'dispatch;
	}
	// 82FCB6F0: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB6F4: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCB6F8: 41980008  blt cr6, 0x82fcb700
	if ctx.cr[6].lt {
	pc = 0x82FCB700; continue 'dispatch;
	}
	// 82FCB6FC: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82FCB700: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCB704: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCB708: 7E038378  mr r3, r16
	ctx.r[3].u64 = ctx.r[16].u64;
	// 82FCB70C: 4BEDB0ED  bl 0x82ea67f8
	ctx.lr = 0x82FCB710;
	sub_82EA67F8(ctx, base);
	// 82FCB710: 93D00004  stw r30, 4(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FCB714: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCB718: 38210260  addi r1, r1, 0x260
	ctx.r[1].s64 = ctx.r[1].s64 + 608;
	// 82FCB71C: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 82FCB720: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 82FCB724: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 82FCB728: 481DCA58  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCB730(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCB730 size=7572
    let mut pc: u32 = 0x82FCB730;
    'dispatch: loop {
        match pc {
            0x82FCB730 => {
    //   block [0x82FCB730..0x82FCD4C4)
	// 82FCB730: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCB734: 481DC9FD  bl 0x831a8130
	ctx.lr = 0x82FCB738;
	sub_831A8130(ctx, base);
	// 82FCB738: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82FCB73C: 481DD33D  bl 0x831a8a78
	ctx.lr = 0x82FCB740;
	sub_831A8A40(ctx, base);
	// 82FCB740: 9421FC70  stwu r1, -0x390(r1)
	ea = ctx.r[1].u32.wrapping_add(-912 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCB744: 7CD33378  mr r19, r6
	ctx.r[19].u64 = ctx.r[6].u64;
	// 82FCB748: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB74C: 7C902378  mr r16, r4
	ctx.r[16].u64 = ctx.r[4].u64;
	// 82FCB750: 906103A4  stw r3, 0x3a4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(932 as u32), ctx.r[3].u32 ) };
	// 82FCB754: 7CEF3B78  mr r15, r7
	ctx.r[15].u64 = ctx.r[7].u64;
	// 82FCB758: 926103BC  stw r19, 0x3bc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(956 as u32), ctx.r[19].u32 ) };
	// 82FCB75C: 7D668214  add r11, r6, r16
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[16].u64;
	// 82FCB760: 7CB12B78  mr r17, r5
	ctx.r[17].u64 = ctx.r[5].u64;
	// 82FCB764: 91E103C4  stw r15, 0x3c4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(964 as u32), ctx.r[15].u32 ) };
	// 82FCB768: 388B0001  addi r4, r11, 1
	ctx.r[4].s64 = ctx.r[11].s64 + 1;
	// 82FCB76C: 922103B4  stw r17, 0x3b4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(948 as u32), ctx.r[17].u32 ) };
	// 82FCB770: 2F0F0000  cmpwi cr6, r15, 0
	ctx.cr[6].compare_i32(ctx.r[15].s32, 0, &mut ctx.xer);
	// 82FCB774: 908100BC  stw r4, 0xbc(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(188 as u32), ctx.r[4].u32 ) };
	// 82FCB778: 419A1D3C  beq cr6, 0x82fcd4b4
	if ctx.cr[6].eq {
	pc = 0x82FCD4B4; continue 'dispatch;
	}
	// 82FCB77C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCB780: 7E238B78  mr r3, r17
	ctx.r[3].u64 = ctx.r[17].u64;
	// 82FCB784: C38B08A4  lfs f28, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 82FCB788: D38100D0  stfs f28, 0xd0(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 82FCB78C: D38100D4  stfs f28, 0xd4(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 82FCB790: D38100D8  stfs f28, 0xd8(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 82FCB794: D38100DC  stfs f28, 0xdc(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 82FCB798: D38100E0  stfs f28, 0xe0(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 82FCB79C: D38100E4  stfs f28, 0xe4(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 82FCB7A0: D38100E8  stfs f28, 0xe8(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 82FCB7A4: D38100EC  stfs f28, 0xec(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 82FCB7A8: D38100F0  stfs f28, 0xf0(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), tmp.u32 ) };
	// 82FCB7AC: D38100F4  stfs f28, 0xf4(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(244 as u32), tmp.u32 ) };
	// 82FCB7B0: D38100F8  stfs f28, 0xf8(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(248 as u32), tmp.u32 ) };
	// 82FCB7B4: D38100FC  stfs f28, 0xfc(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(252 as u32), tmp.u32 ) };
	// 82FCB7B8: D3810100  stfs f28, 0x100(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 82FCB7BC: D3810104  stfs f28, 0x104(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 82FCB7C0: D3810108  stfs f28, 0x108(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 82FCB7C4: D381010C  stfs f28, 0x10c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(268 as u32), tmp.u32 ) };
	// 82FCB7C8: D3810240  stfs f28, 0x240(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(576 as u32), tmp.u32 ) };
	// 82FCB7CC: D3810244  stfs f28, 0x244(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(580 as u32), tmp.u32 ) };
	// 82FCB7D0: D3810248  stfs f28, 0x248(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(584 as u32), tmp.u32 ) };
	// 82FCB7D4: D381024C  stfs f28, 0x24c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(588 as u32), tmp.u32 ) };
	// 82FCB7D8: D3810250  stfs f28, 0x250(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(592 as u32), tmp.u32 ) };
	// 82FCB7DC: D3810254  stfs f28, 0x254(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(596 as u32), tmp.u32 ) };
	// 82FCB7E0: D3810258  stfs f28, 0x258(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(600 as u32), tmp.u32 ) };
	// 82FCB7E4: D381025C  stfs f28, 0x25c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(604 as u32), tmp.u32 ) };
	// 82FCB7E8: D3810260  stfs f28, 0x260(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(608 as u32), tmp.u32 ) };
	// 82FCB7EC: D3810264  stfs f28, 0x264(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(612 as u32), tmp.u32 ) };
	// 82FCB7F0: D3810268  stfs f28, 0x268(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(616 as u32), tmp.u32 ) };
	// 82FCB7F4: D381026C  stfs f28, 0x26c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(620 as u32), tmp.u32 ) };
	// 82FCB7F8: D3810270  stfs f28, 0x270(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(624 as u32), tmp.u32 ) };
	// 82FCB7FC: D3810274  stfs f28, 0x274(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(628 as u32), tmp.u32 ) };
	// 82FCB800: D3810278  stfs f28, 0x278(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(632 as u32), tmp.u32 ) };
	// 82FCB804: D381027C  stfs f28, 0x27c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(636 as u32), tmp.u32 ) };
	// 82FCB808: D3810170  stfs f28, 0x170(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(368 as u32), tmp.u32 ) };
	// 82FCB80C: D3810174  stfs f28, 0x174(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(372 as u32), tmp.u32 ) };
	// 82FCB810: D3810178  stfs f28, 0x178(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), tmp.u32 ) };
	// 82FCB814: D381017C  stfs f28, 0x17c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(380 as u32), tmp.u32 ) };
	// 82FCB818: D3810180  stfs f28, 0x180(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(384 as u32), tmp.u32 ) };
	// 82FCB81C: D3810184  stfs f28, 0x184(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(388 as u32), tmp.u32 ) };
	// 82FCB820: D3810188  stfs f28, 0x188(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(392 as u32), tmp.u32 ) };
	// 82FCB824: D381018C  stfs f28, 0x18c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), tmp.u32 ) };
	// 82FCB828: D3810190  stfs f28, 0x190(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(400 as u32), tmp.u32 ) };
	// 82FCB82C: D3810194  stfs f28, 0x194(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), tmp.u32 ) };
	// 82FCB830: D3810198  stfs f28, 0x198(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(408 as u32), tmp.u32 ) };
	// 82FCB834: D381019C  stfs f28, 0x19c(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), tmp.u32 ) };
	// 82FCB838: D38101A0  stfs f28, 0x1a0(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(416 as u32), tmp.u32 ) };
	// 82FCB83C: D38101A4  stfs f28, 0x1a4(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(420 as u32), tmp.u32 ) };
	// 82FCB840: D38101A8  stfs f28, 0x1a8(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(424 as u32), tmp.u32 ) };
	// 82FCB844: D38101AC  stfs f28, 0x1ac(r1)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(428 as u32), tmp.u32 ) };
	// 82FCB848: 4BFFE009  bl 0x82fc9850
	ctx.lr = 0x82FCB84C;
	sub_82FC9850(ctx, base);
	// 82FCB84C: 3943FFFF  addi r10, r3, -1
	ctx.r[10].s64 = ctx.r[3].s64 + -1;
	// 82FCB850: 83AD0000  lwz r29, 0(r13)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCB854: 3BE00014  li r31, 0x14
	ctx.r[31].s64 = 20;
	// 82FCB858: 7D6A79D6  mullw r11, r10, r15
	ctx.r[11].s64 = (ctx.r[10].s32 as i64) * (ctx.r[15].s32 as i64);
	// 82FCB85C: 93A10114  stw r29, 0x114(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), ctx.r[29].u32 ) };
	// 82FCB860: 7C7FE82E  lwzx r3, r31, r29
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82FCB864: 7FCB3214  add r30, r11, r6
	ctx.r[30].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 82FCB868: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCB86C: 7D7E8214  add r11, r30, r16
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[16].u64;
	// 82FCB870: 93C101F8  stw r30, 0x1f8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(504 as u32), ctx.r[30].u32 ) };
	// 82FCB874: 7D6B7A14  add r11, r11, r15
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[15].u64;
	// 82FCB878: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FCB87C: 5564103A  slwi r4, r11, 2
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCB880: 916101E0  stw r11, 0x1e0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(480 as u32), ctx.r[11].u32 ) };
	// 82FCB884: 4BED4EAD  bl 0x82ea0730
	ctx.lr = 0x82FCB888;
	sub_82EA0730(ctx, base);
	// 82FCB888: 7D3FE82E  lwzx r9, r31, r29
	ctx.r[9].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[31].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82FCB88C: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 82FCB890: 90610118  stw r3, 0x118(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[3].u32 ) };
	// 82FCB894: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCB898: 55642036  slwi r4, r11, 4
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCB89C: 7D234B78  mr r3, r9
	ctx.r[3].u64 = ctx.r[9].u64;
	// 82FCB8A0: 4BED4E91  bl 0x82ea0730
	ctx.lr = 0x82FCB8A4;
	sub_82EA0730(ctx, base);
	// 82FCB8A4: 7FF07A14  add r31, r16, r15
	ctx.r[31].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCB8A8: 7C6E1B78  mr r14, r3
	ctx.r[14].u64 = ctx.r[3].u64;
	// 82FCB8AC: 57EB103A  slwi r11, r31, 2
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCB8B0: 91C10230  stw r14, 0x230(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(560 as u32), ctx.r[14].u32 ) };
	// 82FCB8B4: 7FE80E70  srawi r8, r31, 1
	ctx.xer.ca = (ctx.r[31].s32 < 0) && ((ctx.r[31].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[31].s32 >> 1) as i64;
	// 82FCB8B8: 7CEB8214  add r7, r11, r16
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[16].u64;
	// 82FCB8BC: 3CC08200  lis r6, -0x7e00
	ctx.r[6].s64 = -2113929216;
	// 82FCB8C0: 54E5103A  slwi r5, r7, 2
	ctx.r[5].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCB8C4: C3E608A8  lfs f31, 0x8a8(r6)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(2216 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCB8C8: 38810290  addi r4, r1, 0x290
	ctx.r[4].s64 = ctx.r[1].s64 + 656;
	// 82FCB8CC: 7E480194  addze r18, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[18].s64 = tmp.s64;
	// 82FCB8D0: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 82FCB8D4: 2F120001  cmpwi cr6, r18, 1
	ctx.cr[6].compare_i32(ctx.r[18].s32, 1, &mut ctx.xer);
	// 82FCB8D8: 7FE5252E  stfsx f31, r5, r4
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 82FCB8DC: D3E10290  stfs f31, 0x290(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(656 as u32), tmp.u32 ) };
	// 82FCB8E0: 41980198  blt cr6, 0x82fcba78
	if ctx.cr[6].lt {
	pc = 0x82FCBA78; continue 'dispatch;
	}
	// 82FCB8E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCB8E8: 4BFFC151  bl 0x82fc7a38
	ctx.lr = 0x82FCB8EC;
	sub_82FC7A38(ctx, base);
	// 82FCB8EC: 7C711B78  mr r17, r3
	ctx.r[17].u64 = ctx.r[3].u64;
	// 82FCB8F0: 3AA00004  li r21, 4
	ctx.r[21].s64 = 4;
	// 82FCB8F4: 22CF0001  subfic r22, r15, 1
	ctx.xer.ca = ctx.r[15].u32 <= 1 as u32;
	ctx.r[22].s64 = (1 as i64) - ctx.r[15].s64;
	// 82FCB8F8: 3A7FFFFF  addi r19, r31, -1
	ctx.r[19].s64 = ctx.r[31].s64 + -1;
	// 82FCB8FC: 7E907850  subf r20, r16, r15
	ctx.r[20].s64 = ctx.r[15].s64 - ctx.r[16].s64;
	// 82FCB900: 7E639B78  mr r3, r19
	ctx.r[3].u64 = ctx.r[19].u64;
	// 82FCB904: 4BFFC135  bl 0x82fc7a38
	ctx.lr = 0x82FCB908;
	sub_82FC7A38(ctx, base);
	// 82FCB908: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCB90C: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 82FCB910: 4BFFC129  bl 0x82fc7a38
	ctx.lr = 0x82FCB914;
	sub_82FC7A38(ctx, base);
	// 82FCB914: 7D5F19D6  mullw r10, r31, r3
	ctx.r[10].s64 = (ctx.r[31].s32 as i64) * (ctx.r[3].s32 as i64);
	// 82FCB918: 7D3153D6  divw r9, r17, r10
	ctx.r[9].s32 = ctx.r[17].s32 / ctx.r[10].s32;
	// 82FCB91C: 562B083E  rotlwi r11, r17, 1
	ctx.r[11].u64 = ((ctx.r[17].u32).rotate_left(1)) as u64;
	// 82FCB920: 7D2807B4  extsw r8, r9
	ctx.r[8].s64 = ctx.r[9].s32 as i64;
	// 82FCB924: 38EBFFFF  addi r7, r11, -1
	ctx.r[7].s64 = ctx.r[11].s64 + -1;
	// 82FCB928: F90101F0  std r8, 0x1f0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), ctx.r[8].u64 ) };
	// 82FCB92C: C80101F0  lfd f0, 0x1f0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(496 as u32) ) };
	// 82FCB930: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 82FCB934: 7D463878  andc r6, r10, r7
	ctx.r[6].u64 = ctx.r[10].u64 & !ctx.r[7].u64;
	// 82FCB938: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 82FCB93C: 0CCA0000  twi 6, r10, 0
	// 82FCB940: 0CA6FFFF  twi 5, r6, -1
	// 82FCB944: 7F10C000  cmpw cr6, r16, r24
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[24].s32, &mut ctx.xer);
	// 82FCB948: 7E178378  mr r23, r16
	ctx.r[23].u64 = ctx.r[16].u64;
	// 82FCB94C: EC1F6024  fdivs f0, f31, f12
	ctx.f[0].f64 = ((ctx.f[31].f64 / ctx.f[12].f64) as f32) as f64;
	// 82FCB950: 41980008  blt cr6, 0x82fcb958
	if ctx.cr[6].lt {
	pc = 0x82FCB958; continue 'dispatch;
	}
	// 82FCB954: 7F17C378  mr r23, r24
	ctx.r[23].u64 = ctx.r[24].u64;
	// 82FCB958: 2F160000  cmpwi cr6, r22, 0
	ctx.cr[6].compare_i32(ctx.r[22].s32, 0, &mut ctx.xer);
	// 82FCB95C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCB960: 41980008  blt cr6, 0x82fcb968
	if ctx.cr[6].lt {
	pc = 0x82FCB968; continue 'dispatch;
	}
	// 82FCB964: 7EDFB378  mr r31, r22
	ctx.r[31].u64 = ctx.r[22].u64;
	// 82FCB968: 7F1FB800  cmpw cr6, r31, r23
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[23].s32, &mut ctx.xer);
	// 82FCB96C: 419900E8  bgt cr6, 0x82fcba54
	if ctx.cr[6].gt {
	pc = 0x82FCBA54; continue 'dispatch;
	}
	// 82FCB970: 7DE37B78  mr r3, r15
	ctx.r[3].u64 = ctx.r[15].u64;
	// 82FCB974: 4BFFC0C5  bl 0x82fc7a38
	ctx.lr = 0x82FCB978;
	sub_82FC7A38(ctx, base);
	// 82FCB978: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 82FCB97C: 7E038378  mr r3, r16
	ctx.r[3].u64 = ctx.r[16].u64;
	// 82FCB980: 4BFFC0B9  bl 0x82fc7a38
	ctx.lr = 0x82FCB984;
	sub_82FC7A38(ctx, base);
	// 82FCB984: 7D55FA14  add r10, r21, r31
	ctx.r[10].u64 = ctx.r[21].u64 + ctx.r[31].u64;
	// 82FCB988: 39610290  addi r11, r1, 0x290
	ctx.r[11].s64 = ctx.r[1].s64 + 656;
	// 82FCB98C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCB990: 7D38F850  subf r9, r24, r31
	ctx.r[9].s64 = ctx.r[31].s64 - ctx.r[24].s64;
	// 82FCB994: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 82FCB998: 7FDF8050  subf r30, r31, r16
	ctx.r[30].s64 = ctx.r[16].s64 - ctx.r[31].s64;
	// 82FCB99C: 7F8A5A14  add r28, r10, r11
	ctx.r[28].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCB9A0: 7FA97A14  add r29, r9, r15
	ctx.r[29].u64 = ctx.r[9].u64 + ctx.r[15].u64;
	// 82FCB9A4: 7F34B214  add r25, r20, r22
	ctx.r[25].u64 = ctx.r[20].u64 + ctx.r[22].u64;
	// 82FCB9A8: 7C79F214  add r3, r25, r30
	ctx.r[3].u64 = ctx.r[25].u64 + ctx.r[30].u64;
	// 82FCB9AC: 4BFFC08D  bl 0x82fc7a38
	ctx.lr = 0x82FCB9B0;
	sub_82FC7A38(ctx, base);
	// 82FCB9B0: 7C6E1B78  mr r14, r3
	ctx.r[14].u64 = ctx.r[3].u64;
	// 82FCB9B4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FCB9B8: 4BFFC081  bl 0x82fc7a38
	ctx.lr = 0x82FCB9BC;
	sub_82FC7A38(ctx, base);
	// 82FCB9BC: 7D4E19D6  mullw r10, r14, r3
	ctx.r[10].s64 = (ctx.r[14].s32 as i64) * (ctx.r[3].s32 as i64);
	// 82FCB9C0: 7D3B53D6  divw r9, r27, r10
	ctx.r[9].s32 = ctx.r[27].s32 / ctx.r[10].s32;
	// 82FCB9C4: 576B083E  rotlwi r11, r27, 1
	ctx.r[11].u64 = ((ctx.r[27].u32).rotate_left(1)) as u64;
	// 82FCB9C8: 7D2807B4  extsw r8, r9
	ctx.r[8].s64 = ctx.r[9].s32 as i64;
	// 82FCB9CC: 38EBFFFF  addi r7, r11, -1
	ctx.r[7].s64 = ctx.r[11].s64 + -1;
	// 82FCB9D0: F90101E8  std r8, 0x1e8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), ctx.r[8].u64 ) };
	// 82FCB9D4: C9A101E8  lfd f13, 0x1e8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(488 as u32) ) };
	// 82FCB9D8: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 82FCB9DC: 7D463878  andc r6, r10, r7
	ctx.r[6].u64 = ctx.r[10].u64 & !ctx.r[7].u64;
	// 82FCB9E0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCB9E4: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 82FCB9E8: 0CCA0000  twi 6, r10, 0
	// 82FCB9EC: 0CA6FFFF  twi 5, r6, -1
	// 82FCB9F0: 4BFFC049  bl 0x82fc7a38
	ctx.lr = 0x82FCB9F4;
	sub_82FC7A38(ctx, base);
	// 82FCB9F4: 7C6E1B78  mr r14, r3
	ctx.r[14].u64 = ctx.r[3].u64;
	// 82FCB9F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCB9FC: 4BFFC03D  bl 0x82fc7a38
	ctx.lr = 0x82FCBA00;
	sub_82FC7A38(ctx, base);
	// 82FCBA00: 7CAE19D6  mullw r5, r14, r3
	ctx.r[5].s64 = (ctx.r[14].s32 as i64) * (ctx.r[3].s32 as i64);
	// 82FCBA04: 7C9A2BD6  divw r4, r26, r5
	ctx.r[4].s32 = ctx.r[26].s32 / ctx.r[5].s32;
	// 82FCBA08: 574B083E  rotlwi r11, r26, 1
	ctx.r[11].u64 = ((ctx.r[26].u32).rotate_left(1)) as u64;
	// 82FCBA0C: 7C8307B4  extsw r3, r4
	ctx.r[3].s64 = ctx.r[4].s32 as i64;
	// 82FCBA10: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FCBA14: F8610140  std r3, 0x140(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[3].u64 ) };
	// 82FCBA18: C9410140  lfd f10, 0x140(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(320 as u32) ) };
	// 82FCBA1C: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 82FCBA20: 7CAA5878  andc r10, r5, r11
	ctx.r[10].u64 = ctx.r[5].u64 & !ctx.r[11].u64;
	// 82FCBA24: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 82FCBA28: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCBA2C: 0CC50000  twi 6, r5, 0
	// 82FCBA30: 0CAAFFFF  twi 5, r10, -1
	// 82FCBA34: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82FCBA38: 3BDEFFFF  addi r30, r30, -1
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	// 82FCBA3C: 7F1FB800  cmpw cr6, r31, r23
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[23].s32, &mut ctx.xer);
	// 82FCBA40: ECEB0232  fmuls f7, f11, f8
	ctx.f[7].f64 = (((ctx.f[11].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCBA44: ECC70032  fmuls f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCBA48: D0DC0000  stfs f6, 0(r28)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBA4C: 3B9C0004  addi r28, r28, 4
	ctx.r[28].s64 = ctx.r[28].s64 + 4;
	// 82FCBA50: 4099FF58  ble cr6, 0x82fcb9a8
	if !ctx.cr[6].gt {
	pc = 0x82FCB9A8; continue 'dispatch;
	}
	// 82FCBA54: 3B180001  addi r24, r24, 1
	ctx.r[24].s64 = ctx.r[24].s64 + 1;
	// 82FCBA58: 3A73FFFF  addi r19, r19, -1
	ctx.r[19].s64 = ctx.r[19].s64 + -1;
	// 82FCBA5C: 3AD60001  addi r22, r22, 1
	ctx.r[22].s64 = ctx.r[22].s64 + 1;
	// 82FCBA60: 3AB50004  addi r21, r21, 4
	ctx.r[21].s64 = ctx.r[21].s64 + 4;
	// 82FCBA64: 7F189000  cmpw cr6, r24, r18
	ctx.cr[6].compare_i32(ctx.r[24].s32, ctx.r[18].s32, &mut ctx.xer);
	// 82FCBA68: 4099FE98  ble cr6, 0x82fcb900
	if !ctx.cr[6].gt {
	pc = 0x82FCB900; continue 'dispatch;
	}
	// 82FCBA6C: 81C10230  lwz r14, 0x230(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(560 as u32) ) } as u64;
	// 82FCBA70: 822103B4  lwz r17, 0x3b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(948 as u32) ) } as u64;
	// 82FCBA74: 826103BC  lwz r19, 0x3bc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(956 as u32) ) } as u64;
	// 82FCBA78: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCBA7C: 3BD20001  addi r30, r18, 1
	ctx.r[30].s64 = ctx.r[18].s64 + 1;
	// 82FCBA80: 3B8BFFFF  addi r28, r11, -1
	ctx.r[28].s64 = ctx.r[11].s64 + -1;
	// 82FCBA84: 7F1EE000  cmpw cr6, r30, r28
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[28].s32, &mut ctx.xer);
	// 82FCBA88: 41990118  bgt cr6, 0x82fcbba0
	if ctx.cr[6].gt {
	pc = 0x82FCBBA0; continue 'dispatch;
	}
	// 82FCBA8C: 7D7E5850  subf r11, r30, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 82FCBA90: 57C3103A  slwi r3, r30, 2
	ctx.r[3].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FCBA94: 7FAFF050  subf r29, r15, r30
	ctx.r[29].s64 = ctx.r[30].s64 - ctx.r[15].s64;
	// 82FCBA98: 557F103A  slwi r31, r11, 2
	ctx.r[31].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FCBA9C: 7F10F000  cmpw cr6, r16, r30
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FCBAA0: 7E048378  mr r4, r16
	ctx.r[4].u64 = ctx.r[16].u64;
	// 82FCBAA4: 41980008  blt cr6, 0x82fcbaac
	if ctx.cr[6].lt {
	pc = 0x82FCBAAC; continue 'dispatch;
	}
	// 82FCBAA8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCBAAC: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82FCBAB0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCBAB4: 41980008  blt cr6, 0x82fcbabc
	if ctx.cr[6].lt {
	pc = 0x82FCBABC; continue 'dispatch;
	}
	// 82FCBAB8: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCBABC: 7D4B2050  subf r10, r11, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82FCBAC0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCBAC4: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FCBAC8: 41980074  blt cr6, 0x82fcbb3c
	if ctx.cr[6].lt {
	pc = 0x82FCBB3C; continue 'dispatch;
	}
	// 82FCBACC: 7D4B2050  subf r10, r11, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82FCBAD0: 7D2BF850  subf r9, r11, r31
	ctx.r[9].s64 = ctx.r[31].s64 - ctx.r[11].s64;
	// 82FCBAD4: 390AFFFD  addi r8, r10, -3
	ctx.r[8].s64 = ctx.r[10].s64 + -3;
	// 82FCBAD8: 7D498214  add r10, r9, r16
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[16].u64;
	// 82FCBADC: 5509F0BE  srwi r9, r8, 2
	ctx.r[9].u32 = ctx.r[8].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCBAE0: 7CE35A14  add r7, r3, r11
	ctx.r[7].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 82FCBAE4: 38CAFFFE  addi r6, r10, -2
	ctx.r[6].s64 = ctx.r[10].s64 + -2;
	// 82FCBAE8: 39090001  addi r8, r9, 1
	ctx.r[8].s64 = ctx.r[9].s64 + 1;
	// 82FCBAEC: 39410294  addi r10, r1, 0x294
	ctx.r[10].s64 = ctx.r[1].s64 + 660;
	// 82FCBAF0: 54E9103A  slwi r9, r7, 2
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCBAF4: 54C6103A  slwi r6, r6, 2
	ctx.r[6].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCBAF8: 38E10290  addi r7, r1, 0x290
	ctx.r[7].s64 = ctx.r[1].s64 + 656;
	// 82FCBAFC: 5505103A  slwi r5, r8, 2
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCBB00: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCBB04: 7D463A14  add r10, r6, r7
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FCBB08: 7D655A14  add r11, r5, r11
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[11].u64;
	// 82FCBB0C: C00A0008  lfs f0, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBB10: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCBB14: D009FFFC  stfs f0, -4(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCBB18: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBB1C: D1A90000  stfs f13, 0(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBB20: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCBB24: D1890004  stfs f12, 4(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCBB28: C16AFFFC  lfs f11, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCBB2C: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCBB30: D1690008  stfs f11, 8(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCBB34: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FCBB38: 4082FFD4  bne 0x82fcbb0c
	if !ctx.cr[0].eq {
	pc = 0x82FCBB0C; continue 'dispatch;
	}
	// 82FCBB3C: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FCBB40: 41990048  bgt cr6, 0x82fcbb88
	if ctx.cr[6].gt {
	pc = 0x82FCBB88; continue 'dispatch;
	}
	// 82FCBB44: 7D4BF850  subf r10, r11, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[11].s64;
	// 82FCBB48: 7D235A14  add r9, r3, r11
	ctx.r[9].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 82FCBB4C: 7D0A8214  add r8, r10, r16
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[16].u64;
	// 82FCBB50: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCBB54: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCBB58: 39410290  addi r10, r1, 0x290
	ctx.r[10].s64 = ctx.r[1].s64 + 656;
	// 82FCBB5C: 39010290  addi r8, r1, 0x290
	ctx.r[8].s64 = ctx.r[1].s64 + 656;
	// 82FCBB60: 7D6B2050  subf r11, r11, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82FCBB64: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCBB68: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCBB6C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCBB70: C0090000  lfs f0, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBB74: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCBB78: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBB7C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCBB80: 3929FFFC  addi r9, r9, -4
	ctx.r[9].s64 = ctx.r[9].s64 + -4;
	// 82FCBB84: 4082FFEC  bne 0x82fcbb70
	if !ctx.cr[0].eq {
	pc = 0x82FCBB70; continue 'dispatch;
	}
	// 82FCBB88: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82FCBB8C: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82FCBB90: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 82FCBB94: 3BFFFFFC  addi r31, r31, -4
	ctx.r[31].s64 = ctx.r[31].s64 + -4;
	// 82FCBB98: 7F1EE000  cmpw cr6, r30, r28
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[28].s32, &mut ctx.xer);
	// 82FCBB9C: 4099FF00  ble cr6, 0x82fcba9c
	if !ctx.cr[6].gt {
	pc = 0x82FCBA9C; continue 'dispatch;
	}
	// 82FCBBA0: 81530000  lwz r10, 0(r19)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBBA4: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCBBA8: 81310000  lwz r9, 0(r17)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBBAC: 3BF00001  addi r31, r16, 1
	ctx.r[31].s64 = ctx.r[16].s64 + 1;
	// 82FCBBB0: 3A8B0001  addi r20, r11, 1
	ctx.r[20].s64 = ctx.r[11].s64 + 1;
	// 82FCBBB4: 7E128378  mr r18, r16
	ctx.r[18].u64 = ctx.r[16].u64;
	// 82FCBBB8: 7FF5FB78  mr r21, r31
	ctx.r[21].u64 = ctx.r[31].u64;
	// 82FCBBBC: 928101F0  stw r20, 0x1f0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(496 as u32), ctx.r[20].u32 ) };
	// 82FCBBC0: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBBC4: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 82FCBBC8: C3A90000  lfs f29, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FCBBCC: 928100B4  stw r20, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[20].u32 ) };
	// 82FCBBD0: D00E0000  stfs f0, 0(r14)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBBD4: 3AC0FFFF  li r22, -1
	ctx.r[22].s64 = -1;
	// 82FCBBD8: C1AA0004  lfs f13, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBBDC: 92410140  stw r18, 0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[18].u32 ) };
	// 82FCBBE0: D1AE0004  stfs f13, 4(r14)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCBBE4: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCBBE8: C18A0008  lfs f12, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCBBEC: 910100B0  stw r8, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[8].u32 ) };
	// 82FCBBF0: D18E0008  stfs f12, 8(r14)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCBBF4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCBBF8: C16A000C  lfs f11, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCBBFC: D16E000C  stfs f11, 0xc(r14)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[14].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCBC00: 41980020  blt cr6, 0x82fcbc20
	if ctx.cr[6].lt {
	pc = 0x82FCBC20; continue 'dispatch;
	}
	// 82FCBC04: 80810118  lwz r4, 0x118(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCBC08: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCBC0C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FCBC10: 38640004  addi r3, r4, 4
	ctx.r[3].s64 = ctx.r[4].s64 + 4;
	// 82FCBC14: 5565003A  rlwinm r5, r11, 0, 0, 0x1d
	ctx.r[5].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCBC18: D3A40000  stfs f29, 0(r4)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBC1C: 481DCD7D  bl 0x831a8998
	ctx.lr = 0x82FCBC20;
	sub_831A8998(ctx, base);
	// 82FCBC20: 3AE00000  li r23, 0
	ctx.r[23].s64 = 0;
	// 82FCBC24: 2F1F0004  cmpwi cr6, r31, 4
	ctx.cr[6].compare_i32(ctx.r[31].s32, 4, &mut ctx.xer);
	// 82FCBC28: 4198011C  blt cr6, 0x82fcbd44
	if ctx.cr[6].lt {
	pc = 0x82FCBD44; continue 'dispatch;
	}
	// 82FCBC2C: 39700001  addi r11, r16, 1
	ctx.r[11].s64 = ctx.r[16].s64 + 1;
	// 82FCBC30: 81330000  lwz r9, 0(r19)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBC34: 390100D4  addi r8, r1, 0xd4
	ctx.r[8].s64 = ctx.r[1].s64 + 212;
	// 82FCBC38: 38A100DC  addi r5, r1, 0xdc
	ctx.r[5].s64 = ctx.r[1].s64 + 220;
	// 82FCBC3C: 388100E0  addi r4, r1, 0xe0
	ctx.r[4].s64 = ctx.r[1].s64 + 224;
	// 82FCBC40: 386100E4  addi r3, r1, 0xe4
	ctx.r[3].s64 = ctx.r[1].s64 + 228;
	// 82FCBC44: 3BE100EC  addi r31, r1, 0xec
	ctx.r[31].s64 = ctx.r[1].s64 + 236;
	// 82FCBC48: 3BC100F0  addi r30, r1, 0xf0
	ctx.r[30].s64 = ctx.r[1].s64 + 240;
	// 82FCBC4C: 3BA100F4  addi r29, r1, 0xf4
	ctx.r[29].s64 = ctx.r[1].s64 + 244;
	// 82FCBC50: 3B8100FC  addi r28, r1, 0xfc
	ctx.r[28].s64 = ctx.r[1].s64 + 252;
	// 82FCBC54: 3B610100  addi r27, r1, 0x100
	ctx.r[27].s64 = ctx.r[1].s64 + 256;
	// 82FCBC58: 3B410104  addi r26, r1, 0x104
	ctx.r[26].s64 = ctx.r[1].s64 + 260;
	// 82FCBC5C: 3B2100D8  addi r25, r1, 0xd8
	ctx.r[25].s64 = ctx.r[1].s64 + 216;
	// 82FCBC60: 3B0100E8  addi r24, r1, 0xe8
	ctx.r[24].s64 = ctx.r[1].s64 + 232;
	// 82FCBC64: 3AE100F8  addi r23, r1, 0xf8
	ctx.r[23].s64 = ctx.r[1].s64 + 248;
	// 82FCBC68: 5567F0BE  srwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCBC6C: 7CC94050  subf r6, r9, r8
	ctx.r[6].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 82FCBC70: 39690008  addi r11, r9, 8
	ctx.r[11].s64 = ctx.r[9].s64 + 8;
	// 82FCBC74: 39490018  addi r10, r9, 0x18
	ctx.r[10].s64 = ctx.r[9].s64 + 24;
	// 82FCBC78: 7CA92850  subf r5, r9, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[9].s64;
	// 82FCBC7C: 7C892050  subf r4, r9, r4
	ctx.r[4].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 82FCBC80: 7C691850  subf r3, r9, r3
	ctx.r[3].s64 = ctx.r[3].s64 - ctx.r[9].s64;
	// 82FCBC84: 7FE9F850  subf r31, r9, r31
	ctx.r[31].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82FCBC88: 7FC9F050  subf r30, r9, r30
	ctx.r[30].s64 = ctx.r[30].s64 - ctx.r[9].s64;
	// 82FCBC8C: 7FA9E850  subf r29, r9, r29
	ctx.r[29].s64 = ctx.r[29].s64 - ctx.r[9].s64;
	// 82FCBC90: 7F89E050  subf r28, r9, r28
	ctx.r[28].s64 = ctx.r[28].s64 - ctx.r[9].s64;
	// 82FCBC94: 7F69D850  subf r27, r9, r27
	ctx.r[27].s64 = ctx.r[27].s64 - ctx.r[9].s64;
	// 82FCBC98: 7F49D050  subf r26, r9, r26
	ctx.r[26].s64 = ctx.r[26].s64 - ctx.r[9].s64;
	// 82FCBC9C: 7F29C850  subf r25, r9, r25
	ctx.r[25].s64 = ctx.r[25].s64 - ctx.r[9].s64;
	// 82FCBCA0: 7F09C050  subf r24, r9, r24
	ctx.r[24].s64 = ctx.r[24].s64 - ctx.r[9].s64;
	// 82FCBCA4: 7D29B850  subf r9, r9, r23
	ctx.r[9].s64 = ctx.r[23].s64 - ctx.r[9].s64;
	// 82FCBCA8: 390100D8  addi r8, r1, 0xd8
	ctx.r[8].s64 = ctx.r[1].s64 + 216;
	// 82FCBCAC: 54F7103A  slwi r23, r7, 2
	ctx.r[23].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[23].u64 = ctx.r[23].u32 as u64;
	// 82FCBCB0: C00BFFF8  lfs f0, -8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBCB4: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCBCB8: D008FFF8  stfs f0, -8(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCBCBC: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBCC0: D1A8FFFC  stfs f13, -4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCBCC4: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCBCC8: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBCCC: 39080040  addi r8, r8, 0x40
	ctx.r[8].s64 = ctx.r[8].s64 + 64;
	// 82FCBCD0: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCBCD4: 7D665D2E  stfsx f11, r6, r11
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCBCD8: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCBCDC: 7D4BCD2E  stfsx f10, r11, r25
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[25].u32), tmp.u32) };
	// 82FCBCE0: C12AFFFC  lfs f9, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCBCE4: 7D255D2E  stfsx f9, r5, r11
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCBCE8: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCBCEC: 7D045D2E  stfsx f8, r4, r11
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[4].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCBCF0: C0EA0004  lfs f7, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCBCF4: 7CEB1D2E  stfsx f7, r11, r3
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCBCF8: C0CB0018  lfs f6, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCBCFC: 7CCBC52E  stfsx f6, r11, r24
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[24].u32), tmp.u32) };
	// 82FCBD00: C0AA000C  lfs f5, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCBD04: 7CABFD2E  stfsx f5, r11, r31
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32), tmp.u32) };
	// 82FCBD08: C08A0010  lfs f4, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCBD0C: 7C8BF52E  stfsx f4, r11, r30
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32), tmp.u32) };
	// 82FCBD10: C06A0014  lfs f3, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCBD14: C04B0028  lfs f2, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCBD18: 7C6BED2E  stfsx f3, r11, r29
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[29].u32), tmp.u32) };
	// 82FCBD1C: C02A001C  lfs f1, 0x1c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCBD20: 7C4B4D2E  stfsx f2, r11, r9
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCBD24: C00A0020  lfs f0, 0x20(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBD28: 7C2BE52E  stfsx f1, r11, r28
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32), tmp.u32) };
	// 82FCBD2C: C1AA0024  lfs f13, 0x24(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBD30: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCBD34: 7C0BDD2E  stfsx f0, r11, r27
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[27].u32), tmp.u32) };
	// 82FCBD38: 7DABD52E  stfsx f13, r11, r26
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[26].u32), tmp.u32) };
	// 82FCBD3C: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCBD40: 4082FF70  bne 0x82fcbcb0
	if !ctx.cr[0].eq {
	pc = 0x82FCBCB0; continue 'dispatch;
	}
	// 82FCBD44: 7F178000  cmpw cr6, r23, r16
	ctx.cr[6].compare_i32(ctx.r[23].s32, ctx.r[16].s32, &mut ctx.xer);
	// 82FCBD48: 4199005C  bgt cr6, 0x82fcbda4
	if ctx.cr[6].gt {
	pc = 0x82FCBDA4; continue 'dispatch;
	}
	// 82FCBD4C: 81330000  lwz r9, 0(r19)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBD50: 56EB2036  slwi r11, r23, 4
	ctx.r[11].u32 = ctx.r[23].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCBD54: 390100D8  addi r8, r1, 0xd8
	ctx.r[8].s64 = ctx.r[1].s64 + 216;
	// 82FCBD58: 38C100D8  addi r6, r1, 0xd8
	ctx.r[6].s64 = ctx.r[1].s64 + 216;
	// 82FCBD5C: 7D495A14  add r10, r9, r11
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82FCBD60: 7CF78050  subf r7, r23, r16
	ctx.r[7].s64 = ctx.r[16].s64 - ctx.r[23].s64;
	// 82FCBD64: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCBD68: 7D064850  subf r8, r6, r9
	ctx.r[8].s64 = ctx.r[9].s64 - ctx.r[6].s64;
	// 82FCBD6C: 394A0008  addi r10, r10, 8
	ctx.r[10].s64 = ctx.r[10].s64 + 8;
	// 82FCBD70: 39270001  addi r9, r7, 1
	ctx.r[9].s64 = ctx.r[7].s64 + 1;
	// 82FCBD74: 7C085C2E  lfsx f0, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBD78: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCBD7C: C1AAFFFC  lfs f13, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBD80: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCBD84: C16A0004  lfs f11, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCBD88: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCBD8C: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCBD90: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCBD94: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBD98: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCBD9C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCBDA0: 4082FFD4  bne 0x82fcbd74
	if !ctx.cr[0].eq {
	pc = 0x82FCBD74; continue 'dispatch;
	}
	// 82FCBDA4: 816100BC  lwz r11, 0xbc(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 82FCBDA8: 7F155800  cmpw cr6, r21, r11
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCBDAC: 4098167C  bge cr6, 0x82fcd428
	if !ctx.cr[6].lt {
	pc = 0x82FCD428; continue 'dispatch;
	}
	// 82FCBDB0: 810100BC  lwz r8, 0xbc(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 82FCBDB4: 7EA9AB78  mr r9, r21
	ctx.r[9].u64 = ctx.r[21].u64;
	// 82FCBDB8: 7D754050  subf r11, r21, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[21].s64;
	// 82FCBDBC: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCBDC0: 41980060  blt cr6, 0x82fcbe20
	if ctx.cr[6].lt {
	pc = 0x82FCBE20; continue 'dispatch;
	}
	// 82FCBDC4: 39550002  addi r10, r21, 2
	ctx.r[10].s64 = ctx.r[21].s64 + 2;
	// 82FCBDC8: 81710000  lwz r11, 0(r17)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBDCC: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCBDD0: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCBDD4: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBDD8: C00BFFF8  lfs f0, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBDDC: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCBDE0: 409A008C  bne cr6, 0x82fcbe6c
	if !ctx.cr[6].eq {
	pc = 0x82FCBE6C; continue 'dispatch;
	}
	// 82FCBDE4: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBDE8: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FCBDEC: 409A006C  bne cr6, 0x82fcbe58
	if !ctx.cr[6].eq {
	pc = 0x82FCBE58; continue 'dispatch;
	}
	// 82FCBDF0: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBDF4: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCBDF8: 409A0068  bne cr6, 0x82fcbe60
	if !ctx.cr[6].eq {
	pc = 0x82FCBE60; continue 'dispatch;
	}
	// 82FCBDFC: C00B0008  lfs f0, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBE00: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FCBE04: 409A0064  bne cr6, 0x82fcbe68
	if !ctx.cr[6].eq {
	pc = 0x82FCBE68; continue 'dispatch;
	}
	// 82FCBE08: 3AB50004  addi r21, r21, 4
	ctx.r[21].s64 = ctx.r[21].s64 + 4;
	// 82FCBE0C: 3948FFFD  addi r10, r8, -3
	ctx.r[10].s64 = ctx.r[8].s64 + -3;
	// 82FCBE10: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCBE14: 7F155000  cmpw cr6, r21, r10
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FCBE18: 4198FFBC  blt cr6, 0x82fcbdd4
	if ctx.cr[6].lt {
	pc = 0x82FCBDD4; continue 'dispatch;
	}
	// 82FCBE1C: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCBE20: 7F154000  cmpw cr6, r21, r8
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FCBE24: 4098004C  bge cr6, 0x82fcbe70
	if !ctx.cr[6].lt {
	pc = 0x82FCBE70; continue 'dispatch;
	}
	// 82FCBE28: 81710000  lwz r11, 0(r17)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBE2C: 56AA103A  slwi r10, r21, 2
	ctx.r[10].u32 = ctx.r[21].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCBE30: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCBE34: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCBE38: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBE3C: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCBE40: 409A002C  bne cr6, 0x82fcbe6c
	if !ctx.cr[6].eq {
	pc = 0x82FCBE6C; continue 'dispatch;
	}
	// 82FCBE44: 3AB50001  addi r21, r21, 1
	ctx.r[21].s64 = ctx.r[21].s64 + 1;
	// 82FCBE48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCBE4C: 7F154000  cmpw cr6, r21, r8
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FCBE50: 4198FFE4  blt cr6, 0x82fcbe34
	if ctx.cr[6].lt {
	pc = 0x82FCBE34; continue 'dispatch;
	}
	// 82FCBE54: 48000018  b 0x82fcbe6c
	pc = 0x82FCBE6C; continue 'dispatch;
	// 82FCBE58: 3AB50001  addi r21, r21, 1
	ctx.r[21].s64 = ctx.r[21].s64 + 1;
	// 82FCBE5C: 48000010  b 0x82fcbe6c
	pc = 0x82FCBE6C; continue 'dispatch;
	// 82FCBE60: 3AB50002  addi r21, r21, 2
	ctx.r[21].s64 = ctx.r[21].s64 + 2;
	// 82FCBE64: 48000008  b 0x82fcbe6c
	pc = 0x82FCBE6C; continue 'dispatch;
	// 82FCBE68: 3AB50003  addi r21, r21, 3
	ctx.r[21].s64 = ctx.r[21].s64 + 3;
	// 82FCBE6C: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCBE70: 7D69A850  subf r11, r9, r21
	ctx.r[11].s64 = ctx.r[21].s64 - ctx.r[9].s64;
	// 82FCBE74: 81310000  lwz r9, 0(r17)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBE78: 56AA103A  slwi r10, r21, 2
	ctx.r[10].u32 = ctx.r[21].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCBE7C: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 82FCBE80: 7EDAB378  mr r26, r22
	ctx.r[26].u64 = ctx.r[22].u64;
	// 82FCBE84: 7C668050  subf r3, r6, r16
	ctx.r[3].s64 = ctx.r[16].s64 - ctx.r[6].s64;
	// 82FCBE88: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 82FCBE8C: 7C761B78  mr r22, r3
	ctx.r[22].u64 = ctx.r[3].u64;
	// 82FCBE90: 7FCA4C2E  lfsx f30, r10, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCBE94: 92C100C0  stw r22, 0xc0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[22].u32 ) };
	// 82FCBE98: 40990014  ble cr6, 0x82fcbeac
	if !ctx.cr[6].gt {
	pc = 0x82FCBEAC; continue 'dispatch;
	}
	// 82FCBE9C: 397A0002  addi r11, r26, 2
	ctx.r[11].s64 = ctx.r[26].s64 + 2;
	// 82FCBEA0: 7D6A0E70  srawi r10, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[10].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FCBEA4: 7F2A0194  addze r25, r10
	tmp.s64 = ctx.r[10].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[10].u32);
	ctx.r[25].s64 = tmp.s64;
	// 82FCBEA8: 48000008  b 0x82fcbeb0
	pc = 0x82FCBEB0; continue 'dispatch;
	// 82FCBEAC: 3B200001  li r25, 1
	ctx.r[25].s64 = 1;
	// 82FCBEB0: 932100B8  stw r25, 0xb8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[25].u32 ) };
	// 82FCBEB4: 2F160000  cmpwi cr6, r22, 0
	ctx.cr[6].compare_i32(ctx.r[22].s32, 0, &mut ctx.xer);
	// 82FCBEB8: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCBEBC: 4099001C  ble cr6, 0x82fcbed8
	if !ctx.cr[6].gt {
	pc = 0x82FCBED8; continue 'dispatch;
	}
	// 82FCBEC0: 39560001  addi r10, r22, 1
	ctx.r[10].s64 = ctx.r[22].s64 + 1;
	// 82FCBEC4: 7D480E70  srawi r8, r10, 1
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[10].s32 >> 1) as i64;
	// 82FCBEC8: 7CE80194  addze r7, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[7].s64 = tmp.s64;
	// 82FCBECC: 7CA75850  subf r5, r7, r11
	ctx.r[5].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 82FCBED0: 90A10110  stw r5, 0x110(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[5].u32 ) };
	// 82FCBED4: 48000008  b 0x82fcbedc
	pc = 0x82FCBEDC; continue 'dispatch;
	// 82FCBED8: 91610110  stw r11, 0x110(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[11].u32 ) };
	// 82FCBEDC: 2F160000  cmpwi cr6, r22, 0
	ctx.cr[6].compare_i32(ctx.r[22].s32, 0, &mut ctx.xer);
	// 82FCBEE0: 40990760  ble cr6, 0x82fcc640
	if !ctx.cr[6].gt {
	pc = 0x82FCC640; continue 'dispatch;
	}
	// 82FCBEE4: EC1EE828  fsubs f0, f30, f29
	ctx.f[0].f64 = (((ctx.f[30].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBEE8: 7E078378  mr r7, r16
	ctx.r[7].u64 = ctx.r[16].u64;
	// 82FCBEEC: 2F030004  cmpwi cr6, r3, 4
	ctx.cr[6].compare_i32(ctx.r[3].s32, 4, &mut ctx.xer);
	// 82FCBEF0: 4198009C  blt cr6, 0x82fcbf8c
	if ctx.cr[6].lt {
	pc = 0x82FCBF8C; continue 'dispatch;
	}
	// 82FCBEF4: 7D468050  subf r10, r6, r16
	ctx.r[10].s64 = ctx.r[16].s64 - ctx.r[6].s64;
	// 82FCBEF8: 7D728214  add r11, r18, r16
	ctx.r[11].u64 = ctx.r[18].u64 + ctx.r[16].u64;
	// 82FCBEFC: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCBF00: 390BFFFE  addi r8, r11, -2
	ctx.r[8].s64 = ctx.r[11].s64 + -2;
	// 82FCBF04: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCBF08: 38A3FFFE  addi r5, r3, -2
	ctx.r[5].s64 = ctx.r[3].s64 + -2;
	// 82FCBF0C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCBF10: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCBF14: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCBF18: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCBF1C: 7D0B4A14  add r8, r11, r9
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCBF20: 38A10280  addi r5, r1, 0x280
	ctx.r[5].s64 = ctx.r[1].s64 + 640;
	// 82FCBF24: 555F103A  slwi r31, r10, 2
	ctx.r[31].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FCBF28: 7D274A14  add r9, r7, r9
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 82FCBF2C: 7D642A14  add r11, r4, r5
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[5].u64;
	// 82FCBF30: 3908FFFC  addi r8, r8, -4
	ctx.r[8].s64 = ctx.r[8].s64 + -4;
	// 82FCBF34: 7CFF8050  subf r7, r31, r16
	ctx.r[7].s64 = ctx.r[16].s64 - ctx.r[31].s64;
	// 82FCBF38: C1A90008  lfs f13, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBF3C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCBF40: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCBF44: ED6DE828  fsubs f11, f13, f29
	ctx.f[11].f64 = (((ctx.f[13].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBF48: C1490000  lfs f10, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCBF4C: ED2CE828  fsubs f9, f12, f29
	ctx.f[9].f64 = (((ctx.f[12].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBF50: C109FFFC  lfs f8, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCBF54: ECEAE828  fsubs f7, f10, f29
	ctx.f[7].f64 = (((ctx.f[10].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBF58: ECC8E828  fsubs f6, f8, f29
	ctx.f[6].f64 = (((ctx.f[8].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBF5C: 3908FFF0  addi r8, r8, -0x10
	ctx.r[8].s64 = ctx.r[8].s64 + -16;
	// 82FCBF60: 3929FFF0  addi r9, r9, -0x10
	ctx.r[9].s64 = ctx.r[9].s64 + -16;
	// 82FCBF64: ECA05824  fdivs f5, f0, f11
	ctx.f[5].f64 = ((ctx.f[0].f64 / ctx.f[11].f64) as f32) as f64;
	// 82FCBF68: D0AB0004  stfs f5, 4(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCBF6C: EC804824  fdivs f4, f0, f9
	ctx.f[4].f64 = ((ctx.f[0].f64 / ctx.f[9].f64) as f32) as f64;
	// 82FCBF70: D08B0000  stfs f4, 0(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBF74: EC603824  fdivs f3, f0, f7
	ctx.f[3].f64 = ((ctx.f[0].f64 / ctx.f[7].f64) as f32) as f64;
	// 82FCBF78: D06BFFFC  stfs f3, -4(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCBF7C: EC403024  fdivs f2, f0, f6
	ctx.f[2].f64 = ((ctx.f[0].f64 / ctx.f[6].f64) as f32) as f64;
	// 82FCBF80: D04BFFF8  stfs f2, -8(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCBF84: 396BFFF0  addi r11, r11, -0x10
	ctx.r[11].s64 = ctx.r[11].s64 + -16;
	// 82FCBF88: 4082FFB0  bne 0x82fcbf38
	if !ctx.cr[0].eq {
	pc = 0x82FCBF38; continue 'dispatch;
	}
	// 82FCBF8C: 7F073000  cmpw cr6, r7, r6
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FCBF90: 40990048  ble cr6, 0x82fcbfd8
	if !ctx.cr[6].gt {
	pc = 0x82FCBFD8; continue 'dispatch;
	}
	// 82FCBF94: 7D663850  subf r11, r6, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[6].s64;
	// 82FCBF98: 81110000  lwz r8, 0(r17)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCBF9C: 39410280  addi r10, r1, 0x280
	ctx.r[10].s64 = ctx.r[1].s64 + 640;
	// 82FCBFA0: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCBFA4: 7CE79214  add r7, r7, r18
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[18].u64;
	// 82FCBFA8: 7D295214  add r9, r9, r10
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCBFAC: 54E7103A  slwi r7, r7, 2
	ctx.r[7].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCBFB0: 3929FFFC  addi r9, r9, -4
	ctx.r[9].s64 = ctx.r[9].s64 + -4;
	// 82FCBFB4: 7D474214  add r10, r7, r8
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCBFB8: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCBFBC: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCBFC0: ED8DE828  fsubs f12, f13, f29
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCBFC4: 394AFFFC  addi r10, r10, -4
	ctx.r[10].s64 = ctx.r[10].s64 + -4;
	// 82FCBFC8: ED606024  fdivs f11, f0, f12
	ctx.f[11].f64 = ((ctx.f[0].f64 / ctx.f[12].f64) as f32) as f64;
	// 82FCBFCC: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCBFD0: 3929FFFC  addi r9, r9, -4
	ctx.r[9].s64 = ctx.r[9].s64 + -4;
	// 82FCBFD4: 4082FFE4  bne 0x82fcbfb8
	if !ctx.cr[0].eq {
	pc = 0x82FCBFB8; continue 'dispatch;
	}
	// 82FCBFD8: 2F160001  cmpwi cr6, r22, 1
	ctx.cr[6].compare_i32(ctx.r[22].s32, 1, &mut ctx.xer);
	// 82FCBFDC: 41980664  blt cr6, 0x82fcc640
	if ctx.cr[6].lt {
	pc = 0x82FCC640; continue 'dispatch;
	}
	// 82FCBFE0: 3903FFFD  addi r8, r3, -3
	ctx.r[8].s64 = ctx.r[3].s64 + -3;
	// 82FCBFE4: 560A2036  slwi r10, r16, 4
	ctx.r[10].u32 = ctx.r[16].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCBFE8: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCBFEC: 396100D0  addi r11, r1, 0xd0
	ctx.r[11].s64 = ctx.r[1].s64 + 208;
	// 82FCBFF0: 56C92036  slwi r9, r22, 4
	ctx.r[9].u32 = ctx.r[22].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCBFF4: 39010280  addi r8, r1, 0x280
	ctx.r[8].s64 = ctx.r[1].s64 + 640;
	// 82FCBFF8: 7CAA5A14  add r5, r10, r11
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCBFFC: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 82FCC000: 3BC9FFF0  addi r30, r9, -0x10
	ctx.r[30].s64 = ctx.r[9].s64 + -16;
	// 82FCC004: 7C874214  add r4, r7, r8
	ctx.r[4].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCC008: 7EDFB378  mr r31, r22
	ctx.r[31].u64 = ctx.r[22].u64;
	// 82FCC00C: 7E078378  mr r7, r16
	ctx.r[7].u64 = ctx.r[16].u64;
	// 82FCC010: 2F030004  cmpwi cr6, r3, 4
	ctx.cr[6].compare_i32(ctx.r[3].s32, 4, &mut ctx.xer);
	// 82FCC014: 41980494  blt cr6, 0x82fcc4a8
	if ctx.cr[6].lt {
	pc = 0x82FCC4A8; continue 'dispatch;
	}
	// 82FCC018: 7D668050  subf r11, r6, r16
	ctx.r[11].s64 = ctx.r[16].s64 - ctx.r[6].s64;
	// 82FCC01C: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 82FCC020: 392BFFFD  addi r9, r11, -3
	ctx.r[9].s64 = ctx.r[11].s64 + -3;
	// 82FCC024: 3965FFF8  addi r11, r5, -8
	ctx.r[11].s64 = ctx.r[5].s64 + -8;
	// 82FCC028: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCC02C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCC030: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCC034: 7CE88050  subf r7, r8, r16
	ctx.r[7].s64 = ctx.r[16].s64 - ctx.r[8].s64;
	// 82FCC038: 810B0008  lwz r8, 8(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC03C: 3BA10050  addi r29, r1, 0x50
	ctx.r[29].s64 = ctx.r[1].s64 + 80;
	// 82FCC040: 838B000C  lwz r28, 0xc(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC044: 3B610050  addi r27, r1, 0x50
	ctx.r[27].s64 = ctx.r[1].s64 + 80;
	// 82FCC048: 830B0010  lwz r24, 0x10(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCC04C: C1AA0008  lfs f13, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC050: 82EB0014  lwz r23, 0x14(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCC054: 3A810070  addi r20, r1, 0x70
	ctx.r[20].s64 = ctx.r[1].s64 + 112;
	// 82FCC058: 82ABFFF8  lwz r21, -8(r11)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC05C: 3AC100A0  addi r22, r1, 0xa0
	ctx.r[22].s64 = ctx.r[1].s64 + 160;
	// 82FCC060: 911D0000  stw r8, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCC064: 390BFFF8  addi r8, r11, -8
	ctx.r[8].s64 = ctx.r[11].s64 + -8;
	// 82FCC068: 939D0004  stw r28, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[28].u32 ) };
	// 82FCC06C: 390B0008  addi r8, r11, 8
	ctx.r[8].s64 = ctx.r[11].s64 + 8;
	// 82FCC070: 931D0008  stw r24, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCC074: 390BFFE8  addi r8, r11, -0x18
	ctx.r[8].s64 = ctx.r[11].s64 + -24;
	// 82FCC078: 92FD000C  stw r23, 0xc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[23].u32 ) };
	// 82FCC07C: C0E1005C  lfs f7, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC080: C0C10050  lfs f6, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC084: 83ABFFFC  lwz r29, -4(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC088: C1010058  lfs f8, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC08C: EC880372  fmuls f4, f8, f13
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC090: C1210054  lfs f9, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC094: EC060372  fmuls f0, f6, f13
	ctx.f[0].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC098: ECA90372  fmuls f5, f9, f13
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC09C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCC0A0: EC670372  fmuls f3, f7, f13
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC0A4: D0A10054  stfs f5, 0x54(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCC0A8: D0810058  stfs f4, 0x58(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCC0AC: 838B0000  lwz r28, 0(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC0B0: D061005C  stfs f3, 0x5c(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCC0B4: 82FB0008  lwz r23, 8(r27)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC0B8: 827B000C  lwz r19, 0xc(r27)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC0BC: ED5F6828  fsubs f10, f31, f13
	ctx.f[10].f64 = (((ctx.f[31].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCC0C0: 92B40000  stw r21, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[21].u32 ) };
	// 82FCC0C4: C04A0004  lfs f2, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC0C8: 93B40004  stw r29, 4(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCC0CC: 3A410050  addi r18, r1, 0x50
	ctx.r[18].s64 = ctx.r[1].s64 + 80;
	// 82FCC0D0: 93940008  stw r28, 8(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 82FCC0D4: EC3F1028  fsubs f1, f31, f2
	ctx.f[1].f64 = (((ctx.f[31].f64 - ctx.f[2].f64) as f32) as f64);
	// 82FCC0D8: 811B0000  lwz r8, 0(r27)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC0DC: 91160000  stw r8, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCC0E0: 810B0004  lwz r8, 4(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC0E4: 831B0004  lwz r24, 4(r27)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC0E8: 3B610070  addi r27, r1, 0x70
	ctx.r[27].s64 = ctx.r[1].s64 + 112;
	// 82FCC0EC: 93160004  stw r24, 4(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCC0F0: 9114000C  stw r8, 0xc(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCC0F4: C1810074  lfs f12, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCC0F8: C1610078  lfs f11, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCC0FC: 92F60008  stw r23, 8(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 82FCC100: C121007C  lfs f9, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC104: 9276000C  stw r19, 0xc(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCC108: C10100A8  lfs f8, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC10C: 3AC10050  addi r22, r1, 0x50
	ctx.r[22].s64 = ctx.r[1].s64 + 80;
	// 82FCC110: C0E100AC  lfs f7, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC114: C0C10070  lfs f6, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC118: EDA602B2  fmuls f13, f6, f10
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC11C: ED8C02B2  fmuls f12, f12, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC120: C0A100A4  lfs f5, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC124: ED6B02B2  fmuls f11, f11, f10
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC128: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCC12C: ED4902B2  fmuls f10, f9, f10
	ctx.f[10].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC130: D1810074  stfs f12, 0x74(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCC134: EC80682A  fadds f4, f0, f13
	ctx.f[4].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC138: D08B0008  stfs f4, 8(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCC13C: D1610078  stfs f11, 0x78(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCC140: D141007C  stfs f10, 0x7c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCC144: EC05602A  fadds f0, f5, f12
	ctx.f[0].f64 = ((ctx.f[5].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC148: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCC14C: EDA8582A  fadds f13, f8, f11
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC150: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCC154: ED87502A  fadds f12, f7, f10
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCC158: D18B0014  stfs f12, 0x14(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCC15C: 83ABFFEC  lwz r29, -0x14(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCC160: D00100A4  stfs f0, 0xa4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCC164: 838BFFF0  lwz r28, -0x10(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCC168: D1A100A8  stfs f13, 0xa8(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCC16C: 830BFFF4  lwz r24, -0xc(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCC170: D18100AC  stfs f12, 0xac(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCC174: 82EB0004  lwz r23, 4(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC178: 82ABFFF8  lwz r21, -8(r11)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC17C: 826BFFFC  lwz r19, -4(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC180: 3A8100A0  addi r20, r1, 0xa0
	ctx.r[20].s64 = ctx.r[1].s64 + 160;
	// 82FCC184: 81EB0000  lwz r15, 0(r11)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC188: 3A210050  addi r17, r1, 0x50
	ctx.r[17].s64 = ctx.r[1].s64 + 80;
	// 82FCC18C: 92F2000C  stw r23, 0xc(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(12 as u32), ctx.r[23].u32 ) };
	// 82FCC190: C06A0000  lfs f3, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCC194: 92B20000  stw r21, 0(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), ctx.r[21].u32 ) };
	// 82FCC198: 390BFFD8  addi r8, r11, -0x28
	ctx.r[8].s64 = ctx.r[11].s64 + -40;
	// 82FCC19C: 93BB0004  stw r29, 4(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCC1A0: C12AFFFC  lfs f9, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC1A4: 92720004  stw r19, 4(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(4 as u32), ctx.r[19].u32 ) };
	// 82FCC1A8: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82FCC1AC: 91F20008  stw r15, 8(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(8 as u32), ctx.r[15].u32 ) };
	// 82FCC1B0: ED1F1828  fsubs f8, f31, f3
	ctx.f[8].f64 = (((ctx.f[31].f64 - ctx.f[3].f64) as f32) as f64);
	// 82FCC1B4: 81CBFFE8  lwz r14, -0x18(r11)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24 as u32) ) } as u64;
	// 82FCC1B8: 931B000C  stw r24, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCC1BC: 939B0008  stw r28, 8(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 82FCC1C0: 91DB0000  stw r14, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[14].u32 ) };
	// 82FCC1C4: 3B610070  addi r27, r1, 0x70
	ctx.r[27].s64 = ctx.r[1].s64 + 112;
	// 82FCC1C8: C0010050  lfs f0, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCC1CC: C0810058  lfs f4, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC1D0: C0A10054  lfs f5, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC1D4: C0E1005C  lfs f7, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC1D8: ECC700B2  fmuls f6, f7, f2
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCC1DC: ED4000B2  fmuls f10, f0, f2
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCC1E0: D1410050  stfs f10, 0x50(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCC1E4: EDA500B2  fmuls f13, f5, f2
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCC1E8: D1A10054  stfs f13, 0x54(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCC1EC: ED8400B2  fmuls f12, f4, f2
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCC1F0: D1810058  stfs f12, 0x58(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCC1F4: D0C1005C  stfs f6, 0x5c(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCC1F8: 83B60008  lwz r29, 8(r22)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC1FC: C1610070  lfs f11, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCC200: C0E10074  lfs f7, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC204: EC0B0072  fmuls f0, f11, f1
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCC208: C0A1007C  lfs f5, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC20C: C0C10078  lfs f6, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC210: ED860072  fmuls f12, f6, f1
	ctx.f[12].f64 = (((ctx.f[6].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCC214: D0010070  stfs f0, 0x70(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCC218: D1810078  stfs f12, 0x78(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCC21C: EC4A002A  fadds f2, f10, f0
	ctx.f[2].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FCC220: D04BFFF8  stfs f2, -8(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC224: 83960000  lwz r28, 0(r22)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC228: 82F60004  lwz r23, 4(r22)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC22C: 8316000C  lwz r24, 0xc(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC230: 9314000C  stw r24, 0xc(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCC234: 93B40008  stw r29, 8(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82FCC238: EDA70072  fmuls f13, f7, f1
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCC23C: 93940000  stw r28, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[28].u32 ) };
	// 82FCC240: ED650072  fmuls f11, f5, f1
	ctx.f[11].f64 = (((ctx.f[5].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCC244: 92F40004  stw r23, 4(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), ctx.r[23].u32 ) };
	// 82FCC248: C14100AC  lfs f10, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC24C: D1A10074  stfs f13, 0x74(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCC250: 3B8100A0  addi r28, r1, 0xa0
	ctx.r[28].s64 = ctx.r[1].s64 + 160;
	// 82FCC254: D161007C  stfs f11, 0x7c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCC258: 3BA10070  addi r29, r1, 0x70
	ctx.r[29].s64 = ctx.r[1].s64 + 112;
	// 82FCC25C: C08100A8  lfs f4, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC260: C02100A4  lfs f1, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC264: EC01682A  fadds f0, f1, f13
	ctx.f[0].f64 = ((ctx.f[1].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC268: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC26C: EDA4602A  fadds f13, f4, f12
	ctx.f[13].f64 = ((ctx.f[4].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC270: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC274: ED8A582A  fadds f12, f10, f11
	ctx.f[12].f64 = ((ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC278: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC27C: 82EBFFE8  lwz r23, -0x18(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24 as u32) ) } as u64;
	// 82FCC280: 82CBFFEC  lwz r22, -0x14(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCC284: D00100A4  stfs f0, 0xa4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCC288: 82ABFFF0  lwz r21, -0x10(r11)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCC28C: D1A100A8  stfs f13, 0xa8(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCC290: 830BFFF4  lwz r24, -0xc(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCC294: D18100AC  stfs f12, 0xac(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCC298: 9311000C  stw r24, 0xc(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCC29C: 92B10008  stw r21, 8(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(8 as u32), ctx.r[21].u32 ) };
	// 82FCC2A0: 92D10004  stw r22, 4(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(4 as u32), ctx.r[22].u32 ) };
	// 82FCC2A4: 92F10000  stw r23, 0(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 82FCC2A8: 828BFFDC  lwz r20, -0x24(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-36 as u32) ) } as u64;
	// 82FCC2AC: 826BFFE0  lwz r19, -0x20(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-32 as u32) ) } as u64;
	// 82FCC2B0: 830BFFE4  lwz r24, -0x1c(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-28 as u32) ) } as u64;
	// 82FCC2B4: C0E10050  lfs f7, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC2B8: EC0700F2  fmuls f0, f7, f3
	ctx.f[0].f64 = (((ctx.f[7].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCC2BC: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCC2C0: 82EBFFD8  lwz r23, -0x28(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-40 as u32) ) } as u64;
	// 82FCC2C4: C0C10054  lfs f6, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC2C8: 92FB0000  stw r23, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 82FCC2CC: EC4600F2  fmuls f2, f6, f3
	ctx.f[2].f64 = (((ctx.f[6].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCC2D0: 927B0008  stw r19, 8(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), ctx.r[19].u32 ) };
	// 82FCC2D4: C081005C  lfs f4, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC2D8: 931B000C  stw r24, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCC2DC: C0A10058  lfs f5, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC2E0: 929B0004  stw r20, 4(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), ctx.r[20].u32 ) };
	// 82FCC2E4: EDA400F2  fmuls f13, f4, f3
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCC2E8: D0410054  stfs f2, 0x54(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCC2EC: EC2500F2  fmuls f1, f5, f3
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCC2F0: D1A1005C  stfs f13, 0x5c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCC2F4: 3B010050  addi r24, r1, 0x50
	ctx.r[24].s64 = ctx.r[1].s64 + 80;
	// 82FCC2F8: D0210058  stfs f1, 0x58(r1)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCC2FC: 82E80004  lwz r23, 4(r8)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC300: 92FC0004  stw r23, 4(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(4 as u32), ctx.r[23].u32 ) };
	// 82FCC304: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCC308: C0C10074  lfs f6, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC30C: 83680000  lwz r27, 0(r8)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC310: C0E1007C  lfs f7, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC314: 937C0000  stw r27, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82FCC318: 83680008  lwz r27, 8(r8)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC31C: C1610070  lfs f11, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCC320: 8108000C  lwz r8, 0xc(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC324: C1410078  lfs f10, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC328: 937C0008  stw r27, 8(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[27].u32 ) };
	// 82FCC32C: EDAB0232  fmuls f13, f11, f8
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCC330: 911C000C  stw r8, 0xc(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCC334: ED860232  fmuls f12, f6, f8
	ctx.f[12].f64 = (((ctx.f[6].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCC338: ED6A0232  fmuls f11, f10, f8
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCC33C: C04100A4  lfs f2, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC340: ED470232  fmuls f10, f7, f8
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCC344: D1810074  stfs f12, 0x74(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCC348: C02100A8  lfs f1, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC34C: EC60682A  fadds f3, f0, f13
	ctx.f[3].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC350: D06BFFE8  stfs f3, -0x18(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 82FCC354: ED82602A  fadds f12, f2, f12
	ctx.f[12].f64 = ((ctx.f[2].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC358: D1610078  stfs f11, 0x78(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCC35C: EC9F4828  fsubs f4, f31, f9
	ctx.f[4].f64 = (((ctx.f[31].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FCC360: C0A100AC  lfs f5, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC364: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82FCC368: D18BFFEC  stfs f12, -0x14(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-20 as u32), tmp.u32 ) };
	// 82FCC36C: 3B8100A0  addi r28, r1, 0xa0
	ctx.r[28].s64 = ctx.r[1].s64 + 160;
	// 82FCC370: D141007C  stfs f10, 0x7c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCC374: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCC378: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCC37C: D18100A4  stfs f12, 0xa4(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCC380: ED61582A  fadds f11, f1, f11
	ctx.f[11].f64 = ((ctx.f[1].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC384: D16BFFF0  stfs f11, -0x10(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FCC388: ED45502A  fadds f10, f5, f10
	ctx.f[10].f64 = ((ctx.f[5].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCC38C: D14BFFF4  stfs f10, -0xc(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FCC390: 836BFFE0  lwz r27, -0x20(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-32 as u32) ) } as u64;
	// 82FCC394: D14100AC  stfs f10, 0xac(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCC398: 93780008  stw r27, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[27].u32 ) };
	// 82FCC39C: D16100A8  stfs f11, 0xa8(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCC3A0: 836BFFDC  lwz r27, -0x24(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-36 as u32) ) } as u64;
	// 82FCC3A4: 82EBFFE4  lwz r23, -0x1c(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-28 as u32) ) } as u64;
	// 82FCC3A8: 82CBFFD8  lwz r22, -0x28(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-40 as u32) ) } as u64;
	// 82FCC3AC: 92D80000  stw r22, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[22].u32 ) };
	// 82FCC3B0: 93780004  stw r27, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[27].u32 ) };
	// 82FCC3B4: 92F8000C  stw r23, 0xc(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[23].u32 ) };
	// 82FCC3B8: C1A10054  lfs f13, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC3BC: C1810050  lfs f12, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCC3C0: 82EBFFD4  lwz r23, -0x2c(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-44 as u32) ) } as u64;
	// 82FCC3C4: C1410058  lfs f10, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC3C8: 82CBFFD0  lwz r22, -0x30(r11)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-48 as u32) ) } as u64;
	// 82FCC3CC: C0E1005C  lfs f7, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC3D0: 830BFFCC  lwz r24, -0x34(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-52 as u32) ) } as u64;
	// 82FCC3D4: 836BFFC8  lwz r27, -0x38(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-56 as u32) ) } as u64;
	// 82FCC3D8: 937D0000  stw r27, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82FCC3DC: EC0C0272  fmuls f0, f12, f9
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCC3E0: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCC3E4: ED6D0272  fmuls f11, f13, f9
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCC3E8: D1610054  stfs f11, 0x54(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCC3EC: ED0A0272  fmuls f8, f10, f9
	ctx.f[8].f64 = (((ctx.f[10].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCC3F0: D1010058  stfs f8, 0x58(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCC3F4: 931D0004  stw r24, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCC3F8: ECC70272  fmuls f6, f7, f9
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCC3FC: 92DD0008  stw r22, 8(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(8 as u32), ctx.r[22].u32 ) };
	// 82FCC400: 92FD000C  stw r23, 0xc(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(12 as u32), ctx.r[23].u32 ) };
	// 82FCC404: D0C1005C  stfs f6, 0x5c(r1)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCC408: 83A80004  lwz r29, 4(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC40C: 93BC0004  stw r29, 4(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCC410: C0A10070  lfs f5, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC414: 83A80000  lwz r29, 0(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC418: C0610074  lfs f3, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCC41C: 93BC0000  stw r29, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 82FCC420: EDA50132  fmuls f13, f5, f4
	ctx.f[13].f64 = (((ctx.f[5].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCC424: 83A8000C  lwz r29, 0xc(r8)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC428: C0410078  lfs f2, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC42C: 81080008  lwz r8, 8(r8)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC430: C021007C  lfs f1, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC434: 93BC000C  stw r29, 0xc(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 82FCC438: ED830132  fmuls f12, f3, f4
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCC43C: 911C0008  stw r8, 8(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 82FCC440: ED620132  fmuls f11, f2, f4
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCC444: ED410132  fmuls f10, f1, f4
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCC448: C0E100A4  lfs f7, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC44C: EC00682A  fadds f0, f0, f13
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC450: D00BFFD8  stfs f0, -0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-40 as u32), tmp.u32 ) };
	// 82FCC454: EC07602A  fadds f0, f7, f12
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC458: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCC45C: C10100A8  lfs f8, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC460: C12100AC  lfs f9, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC464: EDA8582A  fadds f13, f8, f11
	ctx.f[13].f64 = ((ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC468: D00BFFDC  stfs f0, -0x24(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-36 as u32), tmp.u32 ) };
	// 82FCC46C: D1810074  stfs f12, 0x74(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCC470: ED89502A  fadds f12, f9, f10
	ctx.f[12].f64 = ((ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCC474: D1ABFFE0  stfs f13, -0x20(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-32 as u32), tmp.u32 ) };
	// 82FCC478: D18BFFE4  stfs f12, -0x1c(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-28 as u32), tmp.u32 ) };
	// 82FCC47C: 396BFFC0  addi r11, r11, -0x40
	ctx.r[11].s64 = ctx.r[11].s64 + -64;
	// 82FCC480: D1610078  stfs f11, 0x78(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCC484: D141007C  stfs f10, 0x7c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCC488: D1A100A8  stfs f13, 0xa8(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCC48C: D00100A4  stfs f0, 0xa4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCC490: D18100AC  stfs f12, 0xac(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCC494: 4082FBA4  bne 0x82fcc038
	if !ctx.cr[0].eq {
	pc = 0x82FCC038; continue 'dispatch;
	}
	// 82FCC498: 81E103C4  lwz r15, 0x3c4(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(964 as u32) ) } as u64;
	// 82FCC49C: 828100B4  lwz r20, 0xb4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 82FCC4A0: 82C100C0  lwz r22, 0xc0(r1)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCC4A4: 82A10060  lwz r21, 0x60(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCC4A8: 7F073000  cmpw cr6, r7, r6
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FCC4AC: 41980148  blt cr6, 0x82fcc5f4
	if ctx.cr[6].lt {
	pc = 0x82FCC5F4; continue 'dispatch;
	}
	// 82FCC4B0: 7D463850  subf r10, r6, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[6].s64;
	// 82FCC4B4: 54E92036  slwi r9, r7, 4
	ctx.r[9].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCC4B8: 396100D4  addi r11, r1, 0xd4
	ctx.r[11].s64 = ctx.r[1].s64 + 212;
	// 82FCC4BC: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCC4C0: 39010280  addi r8, r1, 0x280
	ctx.r[8].s64 = ctx.r[1].s64 + 640;
	// 82FCC4C4: 7D695A14  add r11, r9, r11
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82FCC4C8: 7D274214  add r9, r7, r8
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCC4CC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCC4D0: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC4D4: 38E10050  addi r7, r1, 0x50
	ctx.r[7].s64 = ctx.r[1].s64 + 80;
	// 82FCC4D8: 83ABFFFC  lwz r29, -4(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC4DC: 3AE10070  addi r23, r1, 0x70
	ctx.r[23].s64 = ctx.r[1].s64 + 112;
	// 82FCC4E0: 838B0008  lwz r28, 8(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC4E4: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC4E8: 830B0004  lwz r24, 4(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC4EC: 3B610050  addi r27, r1, 0x50
	ctx.r[27].s64 = ctx.r[1].s64 + 80;
	// 82FCC4F0: 826BFFEC  lwz r19, -0x14(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCC4F4: 3A4100A0  addi r18, r1, 0xa0
	ctx.r[18].s64 = ctx.r[1].s64 + 160;
	// 82FCC4F8: 91070004  stw r8, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCC4FC: 390BFFFC  addi r8, r11, -4
	ctx.r[8].s64 = ctx.r[11].s64 + -4;
	// 82FCC500: 93A70000  stw r29, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 82FCC504: ED7F6828  fsubs f11, f31, f13
	ctx.f[11].f64 = (((ctx.f[31].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCC508: 9387000C  stw r28, 0xc(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[28].u32 ) };
	// 82FCC50C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCC510: 93070008  stw r24, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCC514: 3929FFFC  addi r9, r9, -4
	ctx.r[9].s64 = ctx.r[9].s64 + -4;
	// 82FCC518: 83ABFFF4  lwz r29, -0xc(r11)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCC51C: 80EBFFF8  lwz r7, -8(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC520: 810BFFF0  lwz r8, -0x10(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCC524: 92770000  stw r19, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82FCC528: 93B70008  stw r29, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82FCC52C: 90F7000C  stw r7, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 82FCC530: 91170004  stw r8, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCC534: C0E1005C  lfs f7, 0x5c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC538: C0C10054  lfs f6, 0x54(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC53C: C1010050  lfs f8, 0x50(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC540: EC080372  fmuls f0, f8, f13
	ctx.f[0].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC544: C1210058  lfs f9, 0x58(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC548: EC670372  fmuls f3, f7, f13
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC54C: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FCC550: ECA60372  fmuls f5, f6, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC554: D061005C  stfs f3, 0x5c(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 82FCC558: EC890372  fmuls f4, f9, f13
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC55C: D0A10054  stfs f5, 0x54(r1)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 82FCC560: D0810058  stfs f4, 0x58(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 82FCC564: 83BB0000  lwz r29, 0(r27)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC568: 811B000C  lwz r8, 0xc(r27)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC56C: C1A1007C  lfs f13, 0x7c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC570: 9112000C  stw r8, 0xc(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCC574: C0410070  lfs f2, 0x70(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC578: 80FB0004  lwz r7, 4(r27)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC57C: C0210078  lfs f1, 0x78(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC580: 90F20004  stw r7, 4(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FCC584: C1410074  lfs f10, 0x74(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC588: 80FB0008  lwz r7, 8(r27)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC58C: ED8A02F2  fmuls f12, f10, f11
	ctx.f[12].f64 = (((ctx.f[10].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCC590: 90F20008  stw r7, 8(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FCC594: ED4D02F2  fmuls f10, f13, f11
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCC598: 93B20000  stw r29, 0(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 82FCC59C: C0C100A8  lfs f6, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC5A0: EDA202F2  fmuls f13, f2, f11
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCC5A4: C10100A4  lfs f8, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC5A8: ED6102F2  fmuls f11, f1, f11
	ctx.f[11].f64 = (((ctx.f[1].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCC5AC: D1810074  stfs f12, 0x74(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 82FCC5B0: D1A10070  stfs f13, 0x70(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), tmp.u32 ) };
	// 82FCC5B4: D141007C  stfs f10, 0x7c(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 82FCC5B8: D1610078  stfs f11, 0x78(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 82FCC5BC: ECE0682A  fadds f7, f0, f13
	ctx.f[7].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC5C0: D0EBFFFC  stfs f7, -4(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC5C4: EC08602A  fadds f0, f8, f12
	ctx.f[0].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC5C8: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC5CC: C12100AC  lfs f9, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC5D0: EDA6582A  fadds f13, f6, f11
	ctx.f[13].f64 = ((ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC5D4: ED89502A  fadds f12, f9, f10
	ctx.f[12].f64 = ((ctx.f[9].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCC5D8: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC5DC: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCC5E0: 396BFFF0  addi r11, r11, -0x10
	ctx.r[11].s64 = ctx.r[11].s64 + -16;
	// 82FCC5E4: D00100A4  stfs f0, 0xa4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCC5E8: D1A100A8  stfs f13, 0xa8(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCC5EC: D18100AC  stfs f12, 0xac(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCC5F0: 4082FEE0  bne 0x82fcc4d0
	if !ctx.cr[0].eq {
	pc = 0x82FCC4D0; continue 'dispatch;
	}
	// 82FCC5F4: 39610170  addi r11, r1, 0x170
	ctx.r[11].s64 = ctx.r[1].s64 + 368;
	// 82FCC5F8: C0050000  lfs f0, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCC5FC: C1A50004  lfs f13, 4(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC600: 37FFFFFF  addic. r31, r31, -1
	ctx.xer.ca = (ctx.r[31].u32 > (!(-1 as u32)));
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCC604: 7D7E5A14  add r11, r30, r11
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FCC608: C1850008  lfs f12, 8(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCC60C: C165000C  lfs f11, 0xc(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCC610: 3884FFFC  addi r4, r4, -4
	ctx.r[4].s64 = ctx.r[4].s64 + -4;
	// 82FCC614: 3BDEFFF0  addi r30, r30, -0x10
	ctx.r[30].s64 = ctx.r[30].s64 + -16;
	// 82FCC618: 3863FFFF  addi r3, r3, -1
	ctx.r[3].s64 = ctx.r[3].s64 + -1;
	// 82FCC61C: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 82FCC620: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC624: D1AB0004  stfs f13, 4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC628: D18B0008  stfs f12, 8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCC62C: D16B000C  stfs f11, 0xc(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCC630: 4082F9DC  bne 0x82fcc00c
	if !ctx.cr[0].eq {
	pc = 0x82FCC00C; continue 'dispatch;
	}
	// 82FCC634: 81C10230  lwz r14, 0x230(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(560 as u32) ) } as u64;
	// 82FCC638: 822103B4  lwz r17, 0x3b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(948 as u32) ) } as u64;
	// 82FCC63C: 826103BC  lwz r19, 0x3bc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(956 as u32) ) } as u64;
	// 82FCC640: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCC644: 7F3DCB78  mr r29, r25
	ctx.r[29].u64 = ctx.r[25].u64;
	// 82FCC648: 7F195800  cmpw cr6, r25, r11
	ctx.cr[6].compare_i32(ctx.r[25].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCC64C: 419904B4  bgt cr6, 0x82fccb00
	if ctx.cr[6].gt {
	pc = 0x82FCCB00; continue 'dispatch;
	}
	// 82FCC650: 572A2036  slwi r10, r25, 4
	ctx.r[10].u32 = ctx.r[25].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCC654: 39610248  addi r11, r1, 0x248
	ctx.r[11].s64 = ctx.r[1].s64 + 584;
	// 82FCC658: 573E103A  slwi r30, r25, 2
	ctx.r[30].u32 = ctx.r[25].u32.wrapping_shl(2);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 82FCC65C: 7F8FC850  subf r28, r15, r25
	ctx.r[28].s64 = ctx.r[25].s64 - ctx.r[15].s64;
	// 82FCC660: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCC664: D38B0000  stfs f28, 0(r11)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC668: 7F10E800  cmpw cr6, r16, r29
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCC66C: D38BFFF8  stfs f28, -8(r11)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC670: 7E1F8378  mr r31, r16
	ctx.r[31].u64 = ctx.r[16].u64;
	// 82FCC674: D38BFFFC  stfs f28, -4(r11)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC678: D38B0004  stfs f28, 4(r11)
	tmp.f32 = (ctx.f[28].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC67C: 41980008  blt cr6, 0x82fcc684
	if ctx.cr[6].lt {
	pc = 0x82FCC684; continue 'dispatch;
	}
	// 82FCC680: 7FBFEB78  mr r31, r29
	ctx.r[31].u64 = ctx.r[29].u64;
	// 82FCC684: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 82FCC688: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FCC68C: 41980008  blt cr6, 0x82fcc694
	if ctx.cr[6].lt {
	pc = 0x82FCC694; continue 'dispatch;
	}
	// 82FCC690: 7F89E378  mr r9, r28
	ctx.r[9].u64 = ctx.r[28].u64;
	// 82FCC694: 7D49F850  subf r10, r9, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82FCC698: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCC69C: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FCC6A0: 41980340  blt cr6, 0x82fcc9e0
	if ctx.cr[6].lt {
	pc = 0x82FCC9E0; continue 'dispatch;
	}
	// 82FCC6A4: 7D49F850  subf r10, r9, r31
	ctx.r[10].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82FCC6A8: 7CBE4A14  add r5, r30, r9
	ctx.r[5].u64 = ctx.r[30].u64 + ctx.r[9].u64;
	// 82FCC6AC: 388AFFFD  addi r4, r10, -3
	ctx.r[4].s64 = ctx.r[10].s64 + -3;
	// 82FCC6B0: 55262036  slwi r6, r9, 4
	ctx.r[6].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCC6B4: 548AF0BE  srwi r10, r4, 2
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCC6B8: 390100E0  addi r8, r1, 0xe0
	ctx.r[8].s64 = ctx.r[1].s64 + 224;
	// 82FCC6BC: 38EA0001  addi r7, r10, 1
	ctx.r[7].s64 = ctx.r[10].s64 + 1;
	// 82FCC6C0: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCC6C4: 38A10294  addi r5, r1, 0x294
	ctx.r[5].s64 = ctx.r[1].s64 + 660;
	// 82FCC6C8: 54E3103A  slwi r3, r7, 2
	ctx.r[3].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FCC6CC: 7D464214  add r10, r6, r8
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 82FCC6D0: 7D042A14  add r8, r4, r5
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[5].u64;
	// 82FCC6D4: 7D234A14  add r9, r3, r9
	ctx.r[9].u64 = ctx.r[3].u64 + ctx.r[9].u64;
	// 82FCC6D8: 808AFFF8  lwz r4, -8(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC6DC: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 82FCC6E0: 836AFFFC  lwz r27, -4(r10)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC6E4: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FCC6E8: 826B0004  lwz r19, 4(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC6EC: C1A8FFFC  lfs f13, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCC6F0: 9263000C  stw r19, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCC6F4: 3AE10090  addi r23, r1, 0x90
	ctx.r[23].s64 = ctx.r[1].s64 + 144;
	// 82FCC6F8: 80CAFFF4  lwz r6, -0xc(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCC6FC: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC700: 90850008  stw r4, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCC704: 9365000C  stw r27, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[27].u32 ) };
	// 82FCC708: 808BFFF8  lwz r4, -8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC70C: 836B0000  lwz r27, 0(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC710: 90C50004  stw r6, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82FCC714: 38CAFFF0  addi r6, r10, -0x10
	ctx.r[6].s64 = ctx.r[10].s64 + -16;
	// 82FCC718: 80CBFFFC  lwz r6, -4(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC71C: 830AFFF0  lwz r24, -0x10(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCC720: 90830000  stw r4, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCC724: 93630008  stw r27, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[27].u32 ) };
	// 82FCC728: 808A0004  lwz r4, 4(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC72C: 90C30004  stw r6, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82FCC730: 93050000  stw r24, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FCC734: 3B010080  addi r24, r1, 0x80
	ctx.r[24].s64 = ctx.r[1].s64 + 128;
	// 82FCC738: 806A0008  lwz r3, 8(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCC73C: 38A10090  addi r5, r1, 0x90
	ctx.r[5].s64 = ctx.r[1].s64 + 144;
	// 82FCC740: 80CA000C  lwz r6, 0xc(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCC744: 824A0000  lwz r18, 0(r10)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC748: 836A0010  lwz r27, 0x10(r10)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCC74C: 826A0014  lwz r19, 0x14(r10)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCC750: 822A0018  lwz r17, 0x18(r10)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FCC754: C0410084  lfs f2, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC758: 81EA001C  lwz r15, 0x1c(r10)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) } as u64;
	// 82FCC75C: C0C1008C  lfs f6, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC760: C0E10088  lfs f7, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC764: C0610080  lfs f3, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCC768: C1010098  lfs f8, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC76C: C0A10090  lfs f5, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC770: ED880372  fmuls f12, f8, f13
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC774: C121009C  lfs f9, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC778: EC050372  fmuls f0, f5, f13
	ctx.f[0].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC77C: C0810094  lfs f4, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC780: ED690372  fmuls f11, f9, f13
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC784: EDA40372  fmuls f13, f4, f13
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCC788: D1810098  stfs f12, 0x98(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCC78C: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCC790: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCC794: D161009C  stfs f11, 0x9c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCC798: 90770008  stw r3, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCC79C: 90D7000C  stw r6, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FCC7A0: 90970004  stw r4, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 82FCC7A4: 92570000  stw r18, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[18].u32 ) };
	// 82FCC7A8: EC00182A  fadds f0, f0, f3
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[3].f64) as f32) as f64;
	// 82FCC7AC: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC7B0: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCC7B4: EDA2682A  fadds f13, f2, f13
	ctx.f[13].f64 = ((ctx.f[2].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC7B8: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC7BC: ED87602A  fadds f12, f7, f12
	ctx.f[12].f64 = ((ctx.f[7].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC7C0: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC7C4: ED66582A  fadds f11, f6, f11
	ctx.f[11].f64 = ((ctx.f[6].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC7C8: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC7CC: C0210094  lfs f1, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC7D0: C0010090  lfs f0, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCC7D4: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCC7D8: C1810098  lfs f12, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCC7DC: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCC7E0: ED8C02B2  fmuls f12, f12, f10
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC7E4: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCC7E8: D1810098  stfs f12, 0x98(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCC7EC: 806BFFFC  lwz r3, -4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC7F0: 80CB0000  lwz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC7F4: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC7F8: 9098000C  stw r4, 0xc(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FCC7FC: 808BFFF8  lwz r4, -8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC800: EC0002B2  fmuls f0, f0, f10
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC804: EDA102B2  fmuls f13, f1, f10
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC808: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCC80C: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCC810: 90980000  stw r4, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCC814: 90D80008  stw r6, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FCC818: 90780004  stw r3, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 82FCC81C: C161009C  lfs f11, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCC820: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FCC824: ED6B02B2  fmuls f11, f11, f10
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCC828: C1410084  lfs f10, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC82C: C1210080  lfs f9, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC830: EDAA682A  fadds f13, f10, f13
	ctx.f[13].f64 = ((ctx.f[10].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC834: C1010088  lfs f8, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC838: EC00482A  fadds f0, f0, f9
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FCC83C: C0E1008C  lfs f7, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC840: ED88602A  fadds f12, f8, f12
	ctx.f[12].f64 = ((ctx.f[8].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC844: D161009C  stfs f11, 0x9c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCC848: 93650000  stw r27, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82FCC84C: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC850: 92650004  stw r19, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[19].u32 ) };
	// 82FCC854: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC858: 92250008  stw r17, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[17].u32 ) };
	// 82FCC85C: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC860: 91E5000C  stw r15, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[15].u32 ) };
	// 82FCC864: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCC868: 80CA0020  lwz r6, 0x20(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 82FCC86C: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCC870: 80AA0024  lwz r5, 0x24(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) } as u64;
	// 82FCC874: ED67582A  fadds f11, f7, f11
	ctx.f[11].f64 = ((ctx.f[7].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC878: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC87C: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCC880: 808A0028  lwz r4, 0x28(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) } as u64;
	// 82FCC884: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCC888: 836A002C  lwz r27, 0x2c(r10)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(44 as u32) ) } as u64;
	// 82FCC88C: C0C80004  lfs f6, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC890: 3B010090  addi r24, r1, 0x90
	ctx.r[24].s64 = ctx.r[1].s64 + 144;
	// 82FCC894: 3AE10080  addi r23, r1, 0x80
	ctx.r[23].s64 = ctx.r[1].s64 + 128;
	// 82FCC898: C0A80008  lfs f5, 8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCC89C: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCC8A0: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCC8A4: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCC8A8: C041009C  lfs f2, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC8AC: C0810094  lfs f4, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC8B0: ED6201B2  fmuls f11, f2, f6
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCC8B4: C0610098  lfs f3, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCC8B8: EDA401B2  fmuls f13, f4, f6
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCC8BC: 824BFFFC  lwz r18, -4(r11)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC8C0: C0210090  lfs f1, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC8C4: 92430004  stw r18, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[18].u32 ) };
	// 82FCC8C8: EC0101B2  fmuls f0, f1, f6
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCC8CC: 826B0004  lwz r19, 4(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC8D0: ED8301B2  fmuls f12, f3, f6
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCC8D4: 824BFFF8  lwz r18, -8(r11)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC8D8: D161009C  stfs f11, 0x9c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCC8DC: 822B0000  lwz r17, 0(r11)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC8E0: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCC8E4: 92230008  stw r17, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[17].u32 ) };
	// 82FCC8E8: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCC8EC: 9263000C  stw r19, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCC8F0: D1810098  stfs f12, 0x98(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCC8F4: 92430000  stw r18, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[18].u32 ) };
	// 82FCC8F8: C141008C  lfs f10, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC8FC: 90D80000  stw r6, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 82FCC900: C1210088  lfs f9, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC904: ED6A582A  fadds f11, f10, f11
	ctx.f[11].f64 = ((ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC908: C1010080  lfs f8, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC90C: ED89602A  fadds f12, f9, f12
	ctx.f[12].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC910: C0E10084  lfs f7, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCC914: EC00402A  fadds f0, f0, f8
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FCC918: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC91C: EDA7682A  fadds f13, f7, f13
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC920: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC924: 90B80004  stw r5, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCC928: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC92C: 90980008  stw r4, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCC930: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC934: 9378000C  stw r27, 0xc(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[27].u32 ) };
	// 82FCC938: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCC93C: 808BFFF8  lwz r4, -8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCC940: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCC944: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCC948: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCC94C: C0C10090  lfs f6, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCC950: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCC954: 90770008  stw r3, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCC958: 80CB0004  lwz r6, 4(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCC95C: 80ABFFFC  lwz r5, -4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCC960: 90D7000C  stw r6, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FCC964: C0810094  lfs f4, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCC968: 90B70004  stw r5, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCC96C: C0610098  lfs f3, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCC970: 90970000  stw r4, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCC974: C041009C  lfs f2, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCC978: EC060172  fmuls f0, f6, f5
	ctx.f[0].f64 = (((ctx.f[6].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FCC97C: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCC980: EDA40172  fmuls f13, f4, f5
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FCC984: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCC988: ED830172  fmuls f12, f3, f5
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FCC98C: D1810098  stfs f12, 0x98(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCC990: ED620172  fmuls f11, f2, f5
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FCC994: D161009C  stfs f11, 0x9c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCC998: C1210088  lfs f9, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCC99C: C1410084  lfs f10, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCC9A0: C101008C  lfs f8, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCC9A4: EDAA682A  fadds f13, f10, f13
	ctx.f[13].f64 = ((ctx.f[10].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCC9A8: C0210080  lfs f1, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCC9AC: EC00082A  fadds f0, f0, f1
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[1].f64) as f32) as f64;
	// 82FCC9B0: ED89602A  fadds f12, f9, f12
	ctx.f[12].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCC9B4: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCC9B8: ED68582A  fadds f11, f8, f11
	ctx.f[11].f64 = ((ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCC9BC: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCC9C0: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCC9C4: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCC9C8: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCC9CC: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCC9D0: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCC9D4: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCC9D8: 4082FD00  bne 0x82fcc6d8
	if !ctx.cr[0].eq {
	pc = 0x82FCC6D8; continue 'dispatch;
	}
	// 82FCC9DC: 81E103C4  lwz r15, 0x3c4(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(964 as u32) ) } as u64;
	// 82FCC9E0: 7F09F800  cmpw cr6, r9, r31
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCC9E4: 419900F4  bgt cr6, 0x82fccad8
	if ctx.cr[6].gt {
	pc = 0x82FCCAD8; continue 'dispatch;
	}
	// 82FCC9E8: 7CFE4A14  add r7, r30, r9
	ctx.r[7].u64 = ctx.r[30].u64 + ctx.r[9].u64;
	// 82FCC9EC: 55282036  slwi r8, r9, 4
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCC9F0: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCC9F4: 394100D0  addi r10, r1, 0xd0
	ctx.r[10].s64 = ctx.r[1].s64 + 208;
	// 82FCC9F8: 38E10290  addi r7, r1, 0x290
	ctx.r[7].s64 = ctx.r[1].s64 + 656;
	// 82FCC9FC: 7D29F850  subf r9, r9, r31
	ctx.r[9].s64 = ctx.r[31].s64 - ctx.r[9].s64;
	// 82FCCA00: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82FCCA04: 7D063A14  add r8, r6, r7
	ctx.r[8].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FCCA08: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCCA0C: 80EBFFF8  lwz r7, -8(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCCA10: 38C10080  addi r6, r1, 0x80
	ctx.r[6].s64 = ctx.r[1].s64 + 128;
	// 82FCCA14: 80ABFFFC  lwz r5, -4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCCA18: 38810090  addi r4, r1, 0x90
	ctx.r[4].s64 = ctx.r[1].s64 + 144;
	// 82FCCA1C: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCA20: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCCA24: 83EB0004  lwz r31, 4(r11)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCA28: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCCA2C: 836A0000  lwz r27, 0(r10)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCA30: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 82FCCA34: 90E60000  stw r7, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 82FCCA38: 90A60004  stw r5, 4(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCA3C: 90660008  stw r3, 8(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 82FCCA40: 93E6000C  stw r31, 0xc(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), ctx.r[31].u32 ) };
	// 82FCCA44: 80CA0008  lwz r6, 8(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCA48: 80AA000C  lwz r5, 0xc(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCA4C: 93640000  stw r27, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[27].u32 ) };
	// 82FCCA50: 80EA0004  lwz r7, 4(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCA54: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCCA58: 90C40008  stw r6, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FCCA5C: 90A4000C  stw r5, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FCCA60: 90E40004  stw r7, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FCCA64: C1410088  lfs f10, 0x88(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCCA68: C121008C  lfs f9, 0x8c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCCA6C: C0E10084  lfs f7, 0x84(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(132 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCA70: C1010080  lfs f8, 0x80(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCCA74: C0810098  lfs f4, 0x98(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCCA78: C0C10094  lfs f6, 0x94(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(148 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCCA7C: C0A10090  lfs f5, 0x90(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCA80: EDA602F2  fmuls f13, f6, f11
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCA84: C061009C  lfs f3, 0x9c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(156 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCA88: EC0502F2  fmuls f0, f5, f11
	ctx.f[0].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCA8C: D0010090  stfs f0, 0x90(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), tmp.u32 ) };
	// 82FCCA90: D1A10094  stfs f13, 0x94(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(148 as u32), tmp.u32 ) };
	// 82FCCA94: EDA7682A  fadds f13, f7, f13
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCCA98: D1A10084  stfs f13, 0x84(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), tmp.u32 ) };
	// 82FCCA9C: EC00402A  fadds f0, f0, f8
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FCCAA0: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCCAA4: ED8402F2  fmuls f12, f4, f11
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCAA8: D1810098  stfs f12, 0x98(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), tmp.u32 ) };
	// 82FCCAAC: ED6302F2  fmuls f11, f3, f11
	ctx.f[11].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCAB0: D161009C  stfs f11, 0x9c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 82FCCAB4: D0010080  stfs f0, 0x80(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 82FCCAB8: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCCABC: ED8A602A  fadds f12, f10, f12
	ctx.f[12].f64 = ((ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCCAC0: D1810088  stfs f12, 0x88(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 82FCCAC4: ED69582A  fadds f11, f9, f11
	ctx.f[11].f64 = ((ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCCAC8: D161008C  stfs f11, 0x8c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 82FCCACC: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCCAD0: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCCAD4: 4082FF38  bne 0x82fcca0c
	if !ctx.cr[0].eq {
	pc = 0x82FCCA0C; continue 'dispatch;
	}
	// 82FCCAD8: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82FCCADC: 7D507A14  add r10, r16, r15
	ctx.r[10].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCCAE0: 3B9C0001  addi r28, r28, 1
	ctx.r[28].s64 = ctx.r[28].s64 + 1;
	// 82FCCAE4: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCCAE8: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FCCAEC: 7F1D5000  cmpw cr6, r29, r10
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FCCAF0: 4099FB74  ble cr6, 0x82fcc664
	if !ctx.cr[6].gt {
	pc = 0x82FCC664; continue 'dispatch;
	}
	// 82FCCAF4: 81C10230  lwz r14, 0x230(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(560 as u32) ) } as u64;
	// 82FCCAF8: 822103B4  lwz r17, 0x3b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(948 as u32) ) } as u64;
	// 82FCCAFC: 826103BC  lwz r19, 0x3bc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(956 as u32) ) } as u64;
	// 82FCCB00: 2F1A0001  cmpwi cr6, r26, 1
	ctx.cr[6].compare_i32(ctx.r[26].s32, 1, &mut ctx.xer);
	// 82FCCB04: 40990464  ble cr6, 0x82fccf68
	if !ctx.cr[6].gt {
	pc = 0x82FCCF68; continue 'dispatch;
	}
	// 82FCCB08: 81410118  lwz r10, 0x118(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCCB0C: EC1EE828  fsubs f0, f30, f29
	ctx.f[0].f64 = (((ctx.f[30].f64 - ctx.f[29].f64) as f32) as f64);
	// 82FCCB10: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCCB14: 3B94FFFE  addi r28, r20, -2
	ctx.r[28].s64 = ctx.r[20].s64 + -2;
	// 82FCCB18: 7D2B5214  add r9, r11, r10
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCCB1C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FCCB20: 2F1A0001  cmpwi cr6, r26, 1
	ctx.cr[6].compare_i32(ctx.r[26].s32, 1, &mut ctx.xer);
	// 82FCCB24: C1A9FFFC  lfs f13, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCCB28: ED9E6828  fsubs f12, f30, f13
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCCB2C: ED1F0024  fdivs f8, f31, f0
	ctx.f[8].f64 = ((ctx.f[31].f64 / ctx.f[0].f64) as f32) as f64;
	// 82FCCB30: EC0C0232  fmuls f0, f12, f8
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCCB34: 40990434  ble cr6, 0x82fccf68
	if !ctx.cr[6].gt {
	pc = 0x82FCCF68; continue 'dispatch;
	}
	// 82FCCB38: 578B2036  slwi r11, r28, 4
	ctx.r[11].u32 = ctx.r[28].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCCB3C: 5549003E  slwi r9, r10, 0
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCCB40: 578A103A  slwi r10, r28, 2
	ctx.r[10].u32 = ctx.r[28].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCCB44: 7D6B7214  add r11, r11, r14
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[14].u64;
	// 82FCCB48: 7FEA4A14  add r31, r10, r9
	ctx.r[31].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FCCB4C: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 82FCCB50: 3BA10258  addi r29, r1, 0x258
	ctx.r[29].s64 = ctx.r[1].s64 + 600;
	// 82FCCB54: 3B74FFFF  addi r27, r20, -1
	ctx.r[27].s64 = ctx.r[20].s64 + -1;
	// 82FCCB58: 7D3B1A14  add r9, r27, r3
	ctx.r[9].u64 = ctx.r[27].u64 + ctx.r[3].u64;
	// 82FCCB5C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCCB60: 7D7C4850  subf r11, r28, r9
	ctx.r[11].s64 = ctx.r[9].s64 - ctx.r[28].s64;
	// 82FCCB64: 7F0B1800  cmpw cr6, r11, r3
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FCCB68: 409903E4  ble cr6, 0x82fccf4c
	if !ctx.cr[6].gt {
	pc = 0x82FCCF4C; continue 'dispatch;
	}
	// 82FCCB6C: 81410118  lwz r10, 0x118(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCCB70: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCCB74: 3914FFFF  addi r8, r20, -1
	ctx.r[8].s64 = ctx.r[20].s64 + -1;
	// 82FCCB78: 7CCB5214  add r6, r11, r10
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCCB7C: 7FE7FB78  mr r7, r31
	ctx.r[7].u64 = ctx.r[31].u64;
	// 82FCCB80: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 82FCCB84: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 82FCCB88: 38C6FFFC  addi r6, r6, -4
	ctx.r[6].s64 = ctx.r[6].s64 + -4;
	// 82FCCB8C: 80A100B0  lwz r5, 0xb0(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCCB90: 7F042800  cmpw cr6, r4, r5
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FCCB94: 4098012C  bge cr6, 0x82fcccc0
	if !ctx.cr[6].lt {
	pc = 0x82FCCCC0; continue 'dispatch;
	}
	// 82FCCB98: 80ABFFFC  lwz r5, -4(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCCB9C: 3B010150  addi r24, r1, 0x150
	ctx.r[24].s64 = ctx.r[1].s64 + 336;
	// 82FCCBA0: 82EB0000  lwz r23, 0(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCBA4: C1A70000  lfs f13, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCCBA8: 826B0008  lwz r19, 8(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCBAC: ED9E6828  fsubs f12, f30, f13
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCCBB0: 824B0004  lwz r18, 4(r11)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCBB4: ED7D6828  fsubs f11, f29, f13
	ctx.f[11].f64 = (((ctx.f[29].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCCBB8: 81CBFFEC  lwz r14, -0x14(r11)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCCBBC: 3A210150  addi r17, r1, 0x150
	ctx.r[17].s64 = ctx.r[1].s64 + 336;
	// 82FCCBC0: 90B80000  stw r5, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 82FCCBC4: 38A10210  addi r5, r1, 0x210
	ctx.r[5].s64 = ctx.r[1].s64 + 528;
	// 82FCCBC8: 92F80004  stw r23, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[23].u32 ) };
	// 82FCCBCC: 3AE101D0  addi r23, r1, 0x1d0
	ctx.r[23].s64 = ctx.r[1].s64 + 464;
	// 82FCCBD0: 9278000C  stw r19, 0xc(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCCBD4: 92580008  stw r18, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[18].u32 ) };
	// 82FCCBD8: 90A101E8  stw r5, 0x1e8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(488 as u32), ctx.r[5].u32 ) };
	// 82FCCBDC: 38ABFFFC  addi r5, r11, -4
	ctx.r[5].s64 = ctx.r[11].s64 + -4;
	// 82FCCBE0: 80ABFFF0  lwz r5, -0x10(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCCBE4: 830BFFF4  lwz r24, -0xc(r11)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCCBE8: 91D70000  stw r14, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[14].u32 ) };
	// 82FCCBEC: ED4C5824  fdivs f10, f12, f11
	ctx.f[10].f64 = ((ctx.f[12].f64 / ctx.f[11].f64) as f32) as f64;
	// 82FCCBF0: 826BFFF8  lwz r19, -8(r11)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCCBF4: 90B70004  stw r5, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCBF8: 93170008  stw r24, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCCBFC: 9277000C  stw r19, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCCC00: 826101E8  lwz r19, 0x1e8(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(488 as u32) ) } as u64;
	// 82FCCC04: ED3F5028  fsubs f9, f31, f10
	ctx.f[9].f64 = (((ctx.f[31].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCCC08: C0A10154  lfs f5, 0x154(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(340 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCC0C: EC2502B2  fmuls f1, f5, f10
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCCC10: D0210154  stfs f1, 0x154(r1)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(340 as u32), tmp.u32 ) };
	// 82FCCC14: C0E10150  lfs f7, 0x150(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(336 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCC18: C0C1015C  lfs f6, 0x15c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(348 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCCC1C: EDA702B2  fmuls f13, f7, f10
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCCC20: C0610158  lfs f3, 0x158(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(344 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCC24: EC8602B2  fmuls f4, f6, f10
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCCC28: EC4302B2  fmuls f2, f3, f10
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[10].f64) as f32) as f64);
	// 82FCCC2C: D1A10150  stfs f13, 0x150(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(336 as u32), tmp.u32 ) };
	// 82FCCC30: D081015C  stfs f4, 0x15c(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(348 as u32), tmp.u32 ) };
	// 82FCCC34: D0410158  stfs f2, 0x158(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(344 as u32), tmp.u32 ) };
	// 82FCCC38: C18101D0  lfs f12, 0x1d0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(464 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCCC3C: C14101D8  lfs f10, 0x1d8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(472 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCCC40: C0E101DC  lfs f7, 0x1dc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(476 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCC44: C16101D4  lfs f11, 0x1d4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(468 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCCC48: ED6B0272  fmuls f11, f11, f9
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCC4C: D16101D4  stfs f11, 0x1d4(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(468 as u32), tmp.u32 ) };
	// 82FCCC50: 82F10008  lwz r23, 8(r17)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCC54: 80B10004  lwz r5, 4(r17)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCC58: 90B30004  stw r5, 4(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCC5C: 83110000  lwz r24, 0(r17)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCC60: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCC64: 80B1000C  lwz r5, 0xc(r17)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCC68: ED4A0272  fmuls f10, f10, f9
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCC6C: 92F30008  stw r23, 8(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 82FCCC70: ED270272  fmuls f9, f7, f9
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCC74: 93130000  stw r24, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FCCC78: D18101D0  stfs f12, 0x1d0(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(464 as u32), tmp.u32 ) };
	// 82FCCC7C: 90B3000C  stw r5, 0xc(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FCCC80: D14101D8  stfs f10, 0x1d8(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(472 as u32), tmp.u32 ) };
	// 82FCCC84: C0610214  lfs f3, 0x214(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(532 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCC88: ECCD602A  fadds f6, f13, f12
	ctx.f[6].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCCC8C: C0A10218  lfs f5, 0x218(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(536 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCC90: EDA3582A  fadds f13, f3, f11
	ctx.f[13].f64 = ((ctx.f[3].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCCC94: C081021C  lfs f4, 0x21c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(540 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCCC98: ED85502A  fadds f12, f5, f10
	ctx.f[12].f64 = ((ctx.f[5].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCCC9C: ED64482A  fadds f11, f4, f9
	ctx.f[11].f64 = ((ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FCCCA0: D12101DC  stfs f9, 0x1dc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(476 as u32), tmp.u32 ) };
	// 82FCCCA4: D0CBFFFC  stfs f6, -4(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCCCA8: D1A10214  stfs f13, 0x214(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(532 as u32), tmp.u32 ) };
	// 82FCCCAC: D1810218  stfs f12, 0x218(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(536 as u32), tmp.u32 ) };
	// 82FCCCB0: D161021C  stfs f11, 0x21c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(540 as u32), tmp.u32 ) };
	// 82FCCCB4: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCCCB8: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCCCBC: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCCCC0: 7F09C800  cmpw cr6, r9, r25
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCCCC4: 41980254  blt cr6, 0x82fccf18
	if ctx.cr[6].lt {
	pc = 0x82FCCF18; continue 'dispatch;
	}
	// 82FCCCC8: 7CB07A14  add r5, r16, r15
	ctx.r[5].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCCCCC: 81E103C4  lwz r15, 0x3c4(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(964 as u32) ) } as u64;
	// 82FCCCD0: 7CA5D050  subf r5, r5, r26
	ctx.r[5].s64 = ctx.r[26].s64 - ctx.r[5].s64;
	// 82FCCCD4: 7CA5A214  add r5, r5, r20
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[20].u64;
	// 82FCCCD8: 7F082800  cmpw cr6, r8, r5
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FCCCDC: 41990120  bgt cr6, 0x82fccdfc
	if ctx.cr[6].gt {
	pc = 0x82FCCDFC; continue 'dispatch;
	}
	// 82FCCCE0: 80AAFFFC  lwz r5, -4(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCCCE4: 3B210130  addi r25, r1, 0x130
	ctx.r[25].s64 = ctx.r[1].s64 + 304;
	// 82FCCCE8: 830A0000  lwz r24, 0(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCCEC: C1A60000  lfs f13, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCCCF0: 82EA0004  lwz r23, 4(r10)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCCF4: ED9E6828  fsubs f12, f30, f13
	ctx.f[12].f64 = (((ctx.f[30].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCCCF8: 82CAFFF8  lwz r22, -8(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCCCFC: 3A610130  addi r19, r1, 0x130
	ctx.r[19].s64 = ctx.r[1].s64 + 304;
	// 82FCCD00: 82AA0008  lwz r21, 8(r10)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCD04: 3A410200  addi r18, r1, 0x200
	ctx.r[18].s64 = ctx.r[1].s64 + 512;
	// 82FCCD08: 90B90004  stw r5, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCD0C: 38A101B0  addi r5, r1, 0x1b0
	ctx.r[5].s64 = ctx.r[1].s64 + 432;
	// 82FCCD10: 93190008  stw r24, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCCD14: 92F9000C  stw r23, 0xc(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[23].u32 ) };
	// 82FCCD18: 92D90000  stw r22, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[22].u32 ) };
	// 82FCCD1C: 830A000C  lwz r24, 0xc(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCD20: 82EA0010  lwz r23, 0x10(r10)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCCD24: 82CA0014  lwz r22, 0x14(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCCD28: ED6C0232  fmuls f11, f12, f8
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCCD2C: 92A50000  stw r21, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[21].u32 ) };
	// 82FCCD30: 832100B8  lwz r25, 0xb8(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 82FCCD34: 93050004  stw r24, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCCD38: 92E50008  stw r23, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 82FCCD3C: 92C5000C  stw r22, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[22].u32 ) };
	// 82FCCD40: 82A10060  lwz r21, 0x60(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCCD44: 82C100C0  lwz r22, 0xc0(r1)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCCD48: 828100B4  lwz r20, 0xb4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 82FCCD4C: ED3F5828  fsubs f9, f31, f11
	ctx.f[9].f64 = (((ctx.f[31].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCCD50: C0C10134  lfs f6, 0x134(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(308 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCCD54: C0A10138  lfs f5, 0x138(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCD58: EC8602F2  fmuls f4, f6, f11
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCD5C: EC4502F2  fmuls f2, f5, f11
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCD60: D0810134  stfs f4, 0x134(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), tmp.u32 ) };
	// 82FCCD64: D0410138  stfs f2, 0x138(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), tmp.u32 ) };
	// 82FCCD68: C0E10130  lfs f7, 0x130(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCD6C: C061013C  lfs f3, 0x13c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(316 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCD70: EDA702F2  fmuls f13, f7, f11
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCD74: EC2302F2  fmuls f1, f3, f11
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 82FCCD78: D1A10130  stfs f13, 0x130(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), tmp.u32 ) };
	// 82FCCD7C: D021013C  stfs f1, 0x13c(r1)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(316 as u32), tmp.u32 ) };
	// 82FCCD80: C14101B8  lfs f10, 0x1b8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(440 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCCD84: C0E101BC  lfs f7, 0x1bc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(444 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCD88: C18101B0  lfs f12, 0x1b0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(432 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCCD8C: C16101B4  lfs f11, 0x1b4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(436 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCCD90: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCD94: ED6B0272  fmuls f11, f11, f9
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCD98: D16101B4  stfs f11, 0x1b4(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(436 as u32), tmp.u32 ) };
	// 82FCCD9C: D18101B0  stfs f12, 0x1b0(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(432 as u32), tmp.u32 ) };
	// 82FCCDA0: ECCD602A  fadds f6, f13, f12
	ctx.f[6].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCCDA4: 80B30000  lwz r5, 0(r19)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCDA8: 83130004  lwz r24, 4(r19)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCDAC: 82F30008  lwz r23, 8(r19)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCDB0: 8273000C  lwz r19, 0xc(r19)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCDB4: 93120004  stw r24, 4(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCCDB8: 90B20000  stw r5, 0(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 82FCCDBC: ED4A0272  fmuls f10, f10, f9
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCDC0: 92F20008  stw r23, 8(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(8 as u32), ctx.r[23].u32 ) };
	// 82FCCDC4: ED270272  fmuls f9, f7, f9
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCDC8: 9272000C  stw r19, 0xc(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(12 as u32), ctx.r[19].u32 ) };
	// 82FCCDCC: D14101B8  stfs f10, 0x1b8(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(440 as u32), tmp.u32 ) };
	// 82FCCDD0: D12101BC  stfs f9, 0x1bc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(444 as u32), tmp.u32 ) };
	// 82FCCDD4: C0A1020C  lfs f5, 0x20c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(524 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCDD8: C0810204  lfs f4, 0x204(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(516 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCCDDC: EDA4582A  fadds f13, f4, f11
	ctx.f[13].f64 = ((ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCCDE0: C0610208  lfs f3, 0x208(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(520 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCDE4: ED65482A  fadds f11, f5, f9
	ctx.f[11].f64 = ((ctx.f[5].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FCCDE8: ED83502A  fadds f12, f3, f10
	ctx.f[12].f64 = ((ctx.f[3].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCCDEC: D1A10204  stfs f13, 0x204(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(516 as u32), tmp.u32 ) };
	// 82FCCDF0: D1810208  stfs f12, 0x208(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(520 as u32), tmp.u32 ) };
	// 82FCCDF4: D161020C  stfs f11, 0x20c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(524 as u32), tmp.u32 ) };
	// 82FCCDF8: 48000110  b 0x82fccf08
	pc = 0x82FCCF08; continue 'dispatch;
	// 82FCCDFC: 80AAFFF8  lwz r5, -8(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCCE00: 3B210160  addi r25, r1, 0x160
	ctx.r[25].s64 = ctx.r[1].s64 + 352;
	// 82FCCE04: 830AFFFC  lwz r24, -4(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) } as u64;
	// 82FCCE08: 3A8101C0  addi r20, r1, 0x1c0
	ctx.r[20].s64 = ctx.r[1].s64 + 448;
	// 82FCCE0C: 82CA0000  lwz r22, 0(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCE10: 3AE10160  addi r23, r1, 0x160
	ctx.r[23].s64 = ctx.r[1].s64 + 352;
	// 82FCCE14: 82AA0004  lwz r21, 4(r10)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCE18: 3A610220  addi r19, r1, 0x220
	ctx.r[19].s64 = ctx.r[1].s64 + 544;
	// 82FCCE1C: 824A0008  lwz r18, 8(r10)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCE20: ED3F0028  fsubs f9, f31, f0
	ctx.f[9].f64 = (((ctx.f[31].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCCE24: 90B90000  stw r5, 0(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 82FCCE28: 93190004  stw r24, 4(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCCE2C: 92D90008  stw r22, 8(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(8 as u32), ctx.r[22].u32 ) };
	// 82FCCE30: 92B9000C  stw r21, 0xc(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(12 as u32), ctx.r[21].u32 ) };
	// 82FCCE34: 830A0010  lwz r24, 0x10(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCCE38: 82CA0014  lwz r22, 0x14(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCCE3C: 92540000  stw r18, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[18].u32 ) };
	// 82FCCE40: 80AA000C  lwz r5, 0xc(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCE44: 832100B8  lwz r25, 0xb8(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 82FCCE48: 93140008  stw r24, 8(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCCE4C: 92D4000C  stw r22, 0xc(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), ctx.r[22].u32 ) };
	// 82FCCE50: 82A10060  lwz r21, 0x60(r1)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCCE54: 90B40004  stw r5, 4(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCE58: 82C100C0  lwz r22, 0xc0(r1)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCCE5C: 828100B4  lwz r20, 0xb4(r1)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 82FCCE60: C0E10160  lfs f7, 0x160(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(352 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCE64: C0C10168  lfs f6, 0x168(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(360 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCCE68: EDA70032  fmuls f13, f7, f0
	ctx.f[13].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCCE6C: C0A1016C  lfs f5, 0x16c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(364 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCE70: EC860032  fmuls f4, f6, f0
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCCE74: C0610164  lfs f3, 0x164(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(356 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCE78: EC450032  fmuls f2, f5, f0
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCCE7C: EC230032  fmuls f1, f3, f0
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCCE80: D1A10160  stfs f13, 0x160(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(352 as u32), tmp.u32 ) };
	// 82FCCE84: D0810168  stfs f4, 0x168(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(360 as u32), tmp.u32 ) };
	// 82FCCE88: D041016C  stfs f2, 0x16c(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(364 as u32), tmp.u32 ) };
	// 82FCCE8C: D0210164  stfs f1, 0x164(r1)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(356 as u32), tmp.u32 ) };
	// 82FCCE90: C14101C8  lfs f10, 0x1c8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(456 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCCE94: C18101C0  lfs f12, 0x1c0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(448 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCCE98: C16101C4  lfs f11, 0x1c4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(452 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCCE9C: ED8C0272  fmuls f12, f12, f9
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCEA0: C0E101CC  lfs f7, 0x1cc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(460 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCCEA4: ED6B0272  fmuls f11, f11, f9
	ctx.f[11].f64 = (((ctx.f[11].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCEA8: D16101C4  stfs f11, 0x1c4(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(452 as u32), tmp.u32 ) };
	// 82FCCEAC: D18101C0  stfs f12, 0x1c0(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(448 as u32), tmp.u32 ) };
	// 82FCCEB0: ECCD602A  fadds f6, f13, f12
	ctx.f[6].f64 = ((ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCCEB4: 80B70004  lwz r5, 4(r23)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCCEB8: 8317000C  lwz r24, 0xc(r23)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCCEBC: 82570008  lwz r18, 8(r23)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCCEC0: 82F70000  lwz r23, 0(r23)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCCEC4: 90B30004  stw r5, 4(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCCEC8: 9313000C  stw r24, 0xc(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCCECC: ED4A0272  fmuls f10, f10, f9
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCED0: 92530008  stw r18, 8(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), ctx.r[18].u32 ) };
	// 82FCCED4: ED270272  fmuls f9, f7, f9
	ctx.f[9].f64 = (((ctx.f[7].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCCED8: 92F30000  stw r23, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 82FCCEDC: D14101C8  stfs f10, 0x1c8(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(456 as u32), tmp.u32 ) };
	// 82FCCEE0: D12101CC  stfs f9, 0x1cc(r1)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(460 as u32), tmp.u32 ) };
	// 82FCCEE4: C0810224  lfs f4, 0x224(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(548 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCCEE8: C0A1022C  lfs f5, 0x22c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(556 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCCEEC: EDA4582A  fadds f13, f4, f11
	ctx.f[13].f64 = ((ctx.f[4].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCCEF0: C0610228  lfs f3, 0x228(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(552 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCCEF4: ED65482A  fadds f11, f5, f9
	ctx.f[11].f64 = ((ctx.f[5].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FCCEF8: ED83502A  fadds f12, f3, f10
	ctx.f[12].f64 = ((ctx.f[3].f64 + ctx.f[10].f64) as f32) as f64;
	// 82FCCEFC: D1A10224  stfs f13, 0x224(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(548 as u32), tmp.u32 ) };
	// 82FCCF00: D1810228  stfs f12, 0x228(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(552 as u32), tmp.u32 ) };
	// 82FCCF04: D161022C  stfs f11, 0x22c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(556 as u32), tmp.u32 ) };
	// 82FCCF08: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCCF0C: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCCF10: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCCF14: D0CAFFF8  stfs f6, -8(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCCF18: 38840001  addi r4, r4, 1
	ctx.r[4].s64 = ctx.r[4].s64 + 1;
	// 82FCCF1C: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 82FCCF20: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 82FCCF24: 7CA44850  subf r5, r4, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[4].s64;
	// 82FCCF28: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCCF2C: 38C6FFFC  addi r6, r6, -4
	ctx.r[6].s64 = ctx.r[6].s64 + -4;
	// 82FCCF30: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCCF34: 3908FFFF  addi r8, r8, -1
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	// 82FCCF38: 7F051800  cmpw cr6, r5, r3
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FCCF3C: 4199FC50  bgt cr6, 0x82fccb8c
	if ctx.cr[6].gt {
	pc = 0x82FCCB8C; continue 'dispatch;
	}
	// 82FCCF40: 81C10230  lwz r14, 0x230(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(560 as u32) ) } as u64;
	// 82FCCF44: 822103B4  lwz r17, 0x3b4(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(948 as u32) ) } as u64;
	// 82FCCF48: 826103BC  lwz r19, 0x3bc(r1)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(956 as u32) ) } as u64;
	// 82FCCF4C: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 82FCCF50: 3B9CFFFF  addi r28, r28, -1
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	// 82FCCF54: 3BFFFFFC  addi r31, r31, -4
	ctx.r[31].s64 = ctx.r[31].s64 + -4;
	// 82FCCF58: 3BDEFFF0  addi r30, r30, -0x10
	ctx.r[30].s64 = ctx.r[30].s64 + -16;
	// 82FCCF5C: 3BBD0010  addi r29, r29, 0x10
	ctx.r[29].s64 = ctx.r[29].s64 + 16;
	// 82FCCF60: 7F03D000  cmpw cr6, r3, r26
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[26].s32, &mut ctx.xer);
	// 82FCCF64: 4198FBF4  blt cr6, 0x82fccb58
	if ctx.cr[6].lt {
	pc = 0x82FCCB58; continue 'dispatch;
	}
	// 82FCCF68: 82410140  lwz r18, 0x140(r1)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(320 as u32) ) } as u64;
	// 82FCCF6C: 7F128000  cmpw cr6, r18, r16
	ctx.cr[6].compare_i32(ctx.r[18].s32, ctx.r[16].s32, &mut ctx.xer);
	// 82FCCF70: 419A003C  beq cr6, 0x82fccfac
	if ctx.cr[6].eq {
	pc = 0x82FCCFAC; continue 'dispatch;
	}
	// 82FCCF74: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCCF78: 7FFA5851  subf. r31, r26, r11
	ctx.r[31].s64 = ctx.r[11].s64 - ctx.r[26].s64;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCCF7C: 40810030  ble 0x82fccfac
	if !ctx.cr[0].gt {
	pc = 0x82FCCFAC; continue 'dispatch;
	}
	// 82FCCF80: 81210118  lwz r9, 0x118(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCCF84: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCCF88: 57EA103A  slwi r10, r31, 2
	ctx.r[10].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCCF8C: 7C8B4A14  add r4, r11, r9
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCCF90: 390AFFFF  addi r8, r10, -1
	ctx.r[8].s64 = ctx.r[10].s64 + -1;
	// 82FCCF94: 38640004  addi r3, r4, 4
	ctx.r[3].s64 = ctx.r[4].s64 + 4;
	// 82FCCF98: 5505003A  rlwinm r5, r8, 0, 0, 0x1d
	ctx.r[5].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCCF9C: D3A40000  stfs f29, 0(r4)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCCFA0: 481DB9F9  bl 0x831a8998
	ctx.lr = 0x82FCCFA4;
	sub_831A8998(ctx, base);
	// 82FCCFA4: 7E9FA214  add r20, r31, r20
	ctx.r[20].u64 = ctx.r[31].u64 + ctx.r[20].u64;
	// 82FCCFA8: 928100B4  stw r20, 0xb4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(180 as u32), ctx.r[20].u32 ) };
	// 82FCCFAC: 80810110  lwz r4, 0x110(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(272 as u32) ) } as u64;
	// 82FCCFB0: 7F28CB78  mr r8, r25
	ctx.r[8].u64 = ctx.r[25].u64;
	// 82FCCFB4: 7D792050  subf r11, r25, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[25].s64;
	// 82FCCFB8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCCFBC: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCCFC0: 419800D4  blt cr6, 0x82fcd094
	if ctx.cr[6].lt {
	pc = 0x82FCD094; continue 'dispatch;
	}
	// 82FCCFC4: 7D792050  subf r11, r25, r4
	ctx.r[11].s64 = ctx.r[4].s64 - ctx.r[25].s64;
	// 82FCCFC8: 80A100B0  lwz r5, 0xb0(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCCFCC: 57262036  slwi r6, r25, 4
	ctx.r[6].u32 = ctx.r[25].u32.wrapping_shl(4);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCCFD0: 396BFFFD  addi r11, r11, -3
	ctx.r[11].s64 = ctx.r[11].s64 + -3;
	// 82FCCFD4: 38E10248  addi r7, r1, 0x248
	ctx.r[7].s64 = ctx.r[1].s64 + 584;
	// 82FCCFD8: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCCFDC: 54AA2036  slwi r10, r5, 4
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCCFE0: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FCCFE4: 7D663A14  add r11, r6, r7
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FCCFE8: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCCFEC: 7D4A7214  add r10, r10, r14
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[14].u64;
	// 82FCCFF0: 7CC82A14  add r6, r8, r5
	ctx.r[6].u64 = ctx.r[8].u64 + ctx.r[5].u64;
	// 82FCCFF4: 394A0018  addi r10, r10, 0x18
	ctx.r[10].s64 = ctx.r[10].s64 + 24;
	// 82FCCFF8: 90C100B0  stw r6, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[6].u32 ) };
	// 82FCCFFC: 7D08CA14  add r8, r8, r25
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[25].u64;
	// 82FCD000: C00BFFF8  lfs f0, -8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD004: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCD008: D00AFFE8  stfs f0, -0x18(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-24 as u32), tmp.u32 ) };
	// 82FCD00C: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD010: D1AAFFEC  stfs f13, -0x14(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-20 as u32), tmp.u32 ) };
	// 82FCD014: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD018: D18AFFF0  stfs f12, -0x10(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-16 as u32), tmp.u32 ) };
	// 82FCD01C: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD020: D16AFFF4  stfs f11, -0xc(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FCD024: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCD028: D14AFFF8  stfs f10, -8(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCD02C: C12B000C  lfs f9, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD030: D12AFFFC  stfs f9, -4(r10)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD034: C10B0010  lfs f8, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD038: D10A0000  stfs f8, 0(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD03C: C0EB0014  lfs f7, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD040: D0EA0004  stfs f7, 4(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD044: C0CB0018  lfs f6, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD048: D0CA0008  stfs f6, 8(r10)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCD04C: C0AB001C  lfs f5, 0x1c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD050: D0AA000C  stfs f5, 0xc(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCD054: C08B0020  lfs f4, 0x20(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD058: D08A0010  stfs f4, 0x10(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCD05C: C06B0024  lfs f3, 0x24(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCD060: C04B0028  lfs f2, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCD064: D06A0014  stfs f3, 0x14(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCD068: C02B002C  lfs f1, 0x2c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCD06C: D04A0018  stfs f2, 0x18(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82FCD070: C00B0030  lfs f0, 0x30(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD074: D02A001C  stfs f1, 0x1c(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82FCD078: C1AB0034  lfs f13, 0x34(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD07C: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCD080: D00A0020  stfs f0, 0x20(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82FCD084: D1AA0024  stfs f13, 0x24(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82FCD088: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCD08C: 4082FF74  bne 0x82fcd000
	if !ctx.cr[0].eq {
	pc = 0x82FCD000; continue 'dispatch;
	}
	// 82FCD090: 48000008  b 0x82fcd098
	pc = 0x82FCD098; continue 'dispatch;
	// 82FCD094: 80C100B0  lwz r6, 0xb0(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCD098: 7F082000  cmpw cr6, r8, r4
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FCD09C: 4199005C  bgt cr6, 0x82fcd0f8
	if ctx.cr[6].gt {
	pc = 0x82FCD0F8; continue 'dispatch;
	}
	// 82FCD0A0: 7D482050  subf r10, r8, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FCD0A4: 54CB2036  slwi r11, r6, 4
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD0A8: 392A0001  addi r9, r10, 1
	ctx.r[9].s64 = ctx.r[10].s64 + 1;
	// 82FCD0AC: 7D6B7214  add r11, r11, r14
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[14].u64;
	// 82FCD0B0: 55072036  slwi r7, r8, 4
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCD0B4: 39010248  addi r8, r1, 0x248
	ctx.r[8].s64 = ctx.r[1].s64 + 584;
	// 82FCD0B8: 7CC93214  add r6, r9, r6
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[6].u64;
	// 82FCD0BC: 394B0008  addi r10, r11, 8
	ctx.r[10].s64 = ctx.r[11].s64 + 8;
	// 82FCD0C0: 7D674214  add r11, r7, r8
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[8].u64;
	// 82FCD0C4: 90C100B0  stw r6, 0xb0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[6].u32 ) };
	// 82FCD0C8: C00BFFF8  lfs f0, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD0CC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCD0D0: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD0D4: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD0D8: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD0DC: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCD0E0: D00AFFF8  stfs f0, -8(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCD0E4: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD0E8: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD0EC: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD0F0: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCD0F4: 4082FFD4  bne 0x82fcd0c8
	if !ctx.cr[0].eq {
	pc = 0x82FCD0C8; continue 'dispatch;
	}
	// 82FCD0F8: 83E100BC  lwz r31, 0xbc(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 82FCD0FC: 7F15F800  cmpw cr6, r21, r31
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCD100: 409802EC  bge cr6, 0x82fcd3ec
	if !ctx.cr[6].lt {
	pc = 0x82FCD3EC; continue 'dispatch;
	}
	// 82FCD104: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FCD108: 2F160004  cmpwi cr6, r22, 4
	ctx.cr[6].compare_i32(ctx.r[22].s32, 4, &mut ctx.xer);
	// 82FCD10C: 41980124  blt cr6, 0x82fcd230
	if ctx.cr[6].lt {
	pc = 0x82FCD230; continue 'dispatch;
	}
	// 82FCD110: 3956FFFC  addi r10, r22, -4
	ctx.r[10].s64 = ctx.r[22].s64 + -4;
	// 82FCD114: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCD118: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD11C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCD120: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCD124: 39010170  addi r8, r1, 0x170
	ctx.r[8].s64 = ctx.r[1].s64 + 368;
	// 82FCD128: 38E100D0  addi r7, r1, 0xd0
	ctx.r[7].s64 = ctx.r[1].s64 + 208;
	// 82FCD12C: 38C10174  addi r6, r1, 0x174
	ctx.r[6].s64 = ctx.r[1].s64 + 372;
	// 82FCD130: 38A100D4  addi r5, r1, 0xd4
	ctx.r[5].s64 = ctx.r[1].s64 + 212;
	// 82FCD134: 38810178  addi r4, r1, 0x178
	ctx.r[4].s64 = ctx.r[1].s64 + 376;
	// 82FCD138: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD13C: 386100D8  addi r3, r1, 0xd8
	ctx.r[3].s64 = ctx.r[1].s64 + 216;
	// 82FCD140: 7C0B3D2E  stfsx f0, r11, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD144: 3901017C  addi r8, r1, 0x17c
	ctx.r[8].s64 = ctx.r[1].s64 + 380;
	// 82FCD148: 38E100DC  addi r7, r1, 0xdc
	ctx.r[7].s64 = ctx.r[1].s64 + 220;
	// 82FCD14C: 7DAB342E  lfsx f13, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD150: 7DAB2D2E  stfsx f13, r11, r5
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD154: 38C10180  addi r6, r1, 0x180
	ctx.r[6].s64 = ctx.r[1].s64 + 384;
	// 82FCD158: 7D8B242E  lfsx f12, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD15C: 38A100E0  addi r5, r1, 0xe0
	ctx.r[5].s64 = ctx.r[1].s64 + 224;
	// 82FCD160: 7D8B1D2E  stfsx f12, r11, r3
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD164: 38810184  addi r4, r1, 0x184
	ctx.r[4].s64 = ctx.r[1].s64 + 388;
	// 82FCD168: 7D6B442E  lfsx f11, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD16C: 386100E4  addi r3, r1, 0xe4
	ctx.r[3].s64 = ctx.r[1].s64 + 228;
	// 82FCD170: 7D6B3D2E  stfsx f11, r11, r7
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD174: 39010188  addi r8, r1, 0x188
	ctx.r[8].s64 = ctx.r[1].s64 + 392;
	// 82FCD178: 38E100E8  addi r7, r1, 0xe8
	ctx.r[7].s64 = ctx.r[1].s64 + 232;
	// 82FCD17C: 7D4B342E  lfsx f10, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCD180: 7D4B2D2E  stfsx f10, r11, r5
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD184: 38C1018C  addi r6, r1, 0x18c
	ctx.r[6].s64 = ctx.r[1].s64 + 396;
	// 82FCD188: 7D2B242E  lfsx f9, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD18C: 38A100EC  addi r5, r1, 0xec
	ctx.r[5].s64 = ctx.r[1].s64 + 236;
	// 82FCD190: 7D2B1D2E  stfsx f9, r11, r3
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD194: 38810190  addi r4, r1, 0x190
	ctx.r[4].s64 = ctx.r[1].s64 + 400;
	// 82FCD198: 7D0B442E  lfsx f8, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD19C: 386100F0  addi r3, r1, 0xf0
	ctx.r[3].s64 = ctx.r[1].s64 + 240;
	// 82FCD1A0: 7D0B3D2E  stfsx f8, r11, r7
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD1A4: 39010194  addi r8, r1, 0x194
	ctx.r[8].s64 = ctx.r[1].s64 + 404;
	// 82FCD1A8: 38E100F4  addi r7, r1, 0xf4
	ctx.r[7].s64 = ctx.r[1].s64 + 244;
	// 82FCD1AC: 7CEB342E  lfsx f7, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD1B0: 7CEB2D2E  stfsx f7, r11, r5
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD1B4: 38C10198  addi r6, r1, 0x198
	ctx.r[6].s64 = ctx.r[1].s64 + 408;
	// 82FCD1B8: 7CCB242E  lfsx f6, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD1BC: 38A100F8  addi r5, r1, 0xf8
	ctx.r[5].s64 = ctx.r[1].s64 + 248;
	// 82FCD1C0: 7CCB1D2E  stfsx f6, r11, r3
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD1C4: 3881019C  addi r4, r1, 0x19c
	ctx.r[4].s64 = ctx.r[1].s64 + 412;
	// 82FCD1C8: 7CAB442E  lfsx f5, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD1CC: 386100FC  addi r3, r1, 0xfc
	ctx.r[3].s64 = ctx.r[1].s64 + 252;
	// 82FCD1D0: 7CAB3D2E  stfsx f5, r11, r7
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD1D4: 390101A0  addi r8, r1, 0x1a0
	ctx.r[8].s64 = ctx.r[1].s64 + 416;
	// 82FCD1D8: 38E10100  addi r7, r1, 0x100
	ctx.r[7].s64 = ctx.r[1].s64 + 256;
	// 82FCD1DC: 7C8B342E  lfsx f4, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD1E0: 7C8B2D2E  stfsx f4, r11, r5
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD1E4: 38C101A4  addi r6, r1, 0x1a4
	ctx.r[6].s64 = ctx.r[1].s64 + 420;
	// 82FCD1E8: 7C6B242E  lfsx f3, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCD1EC: 38A10104  addi r5, r1, 0x104
	ctx.r[5].s64 = ctx.r[1].s64 + 260;
	// 82FCD1F0: 7C6B1D2E  stfsx f3, r11, r3
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD1F4: 388101A8  addi r4, r1, 0x1a8
	ctx.r[4].s64 = ctx.r[1].s64 + 424;
	// 82FCD1F8: 7C4B442E  lfsx f2, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCD1FC: 38610108  addi r3, r1, 0x108
	ctx.r[3].s64 = ctx.r[1].s64 + 264;
	// 82FCD200: 7C4B3D2E  stfsx f2, r11, r7
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD204: 390101AC  addi r8, r1, 0x1ac
	ctx.r[8].s64 = ctx.r[1].s64 + 428;
	// 82FCD208: 38E1010C  addi r7, r1, 0x10c
	ctx.r[7].s64 = ctx.r[1].s64 + 268;
	// 82FCD20C: 7C2B342E  lfsx f1, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCD210: 7C2B2D2E  stfsx f1, r11, r5
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD214: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCD218: 7C0B242E  lfsx f0, r11, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD21C: 7C0B1D2E  stfsx f0, r11, r3
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD220: 7DAB442E  lfsx f13, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD224: 7DAB3D2E  stfsx f13, r11, r7
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCD228: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCD22C: 4082FEF8  bne 0x82fcd124
	if !ctx.cr[0].eq {
	pc = 0x82FCD124; continue 'dispatch;
	}
	// 82FCD230: 7F09B000  cmpw cr6, r9, r22
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FCD234: 40980058  bge cr6, 0x82fcd28c
	if !ctx.cr[6].lt {
	pc = 0x82FCD28C; continue 'dispatch;
	}
	// 82FCD238: 552B2036  slwi r11, r9, 4
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD23C: 7D49B050  subf r10, r9, r22
	ctx.r[10].s64 = ctx.r[22].s64 - ctx.r[9].s64;
	// 82FCD240: 39210170  addi r9, r1, 0x170
	ctx.r[9].s64 = ctx.r[1].s64 + 368;
	// 82FCD244: 39010174  addi r8, r1, 0x174
	ctx.r[8].s64 = ctx.r[1].s64 + 372;
	// 82FCD248: 38E10178  addi r7, r1, 0x178
	ctx.r[7].s64 = ctx.r[1].s64 + 376;
	// 82FCD24C: 38C1017C  addi r6, r1, 0x17c
	ctx.r[6].s64 = ctx.r[1].s64 + 380;
	// 82FCD250: 38A100D0  addi r5, r1, 0xd0
	ctx.r[5].s64 = ctx.r[1].s64 + 208;
	// 82FCD254: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD258: 388100D4  addi r4, r1, 0xd4
	ctx.r[4].s64 = ctx.r[1].s64 + 212;
	// 82FCD25C: 386100D8  addi r3, r1, 0xd8
	ctx.r[3].s64 = ctx.r[1].s64 + 216;
	// 82FCD260: 7DAB442E  lfsx f13, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD264: 392100DC  addi r9, r1, 0xdc
	ctx.r[9].s64 = ctx.r[1].s64 + 220;
	// 82FCD268: 7D8B3C2E  lfsx f12, r11, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD26C: 7D6B342E  lfsx f11, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD270: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCD274: 7C0B2D2E  stfsx f0, r11, r5
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCD278: 7DAB252E  stfsx f13, r11, r4
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 82FCD27C: 7D8B1D2E  stfsx f12, r11, r3
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCD280: 7D6B4D2E  stfsx f11, r11, r9
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCD284: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCD288: 4082FFB8  bne 0x82fcd240
	if !ctx.cr[0].eq {
	pc = 0x82FCD240; continue 'dispatch;
	}
	// 82FCD28C: 7D768050  subf r11, r22, r16
	ctx.r[11].s64 = ctx.r[16].s64 - ctx.r[22].s64;
	// 82FCD290: 7EC7B378  mr r7, r22
	ctx.r[7].u64 = ctx.r[22].u64;
	// 82FCD294: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCD298: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCD29C: 419800D8  blt cr6, 0x82fcd374
	if ctx.cr[6].lt {
	pc = 0x82FCD374; continue 'dispatch;
	}
	// 82FCD2A0: 7D70A850  subf r11, r16, r21
	ctx.r[11].s64 = ctx.r[21].s64 - ctx.r[16].s64;
	// 82FCD2A4: 81530000  lwz r10, 0(r19)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD2A8: 7D368050  subf r9, r22, r16
	ctx.r[9].s64 = ctx.r[16].s64 - ctx.r[22].s64;
	// 82FCD2AC: 7D0BB214  add r8, r11, r22
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 82FCD2B0: 3929FFFD  addi r9, r9, -3
	ctx.r[9].s64 = ctx.r[9].s64 + -3;
	// 82FCD2B4: 550B2036  slwi r11, r8, 4
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD2B8: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCD2BC: 7D4B5214  add r10, r11, r10
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCD2C0: 39090001  addi r8, r9, 1
	ctx.r[8].s64 = ctx.r[9].s64 + 1;
	// 82FCD2C4: 392100D8  addi r9, r1, 0xd8
	ctx.r[9].s64 = ctx.r[1].s64 + 216;
	// 82FCD2C8: 56CB2036  slwi r11, r22, 4
	ctx.r[11].u32 = ctx.r[22].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD2CC: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCD2D0: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCD2D4: 392A0008  addi r9, r10, 8
	ctx.r[9].s64 = ctx.r[10].s64 + 8;
	// 82FCD2D8: 394A0018  addi r10, r10, 0x18
	ctx.r[10].s64 = ctx.r[10].s64 + 24;
	// 82FCD2DC: 7CE7B214  add r7, r7, r22
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[22].u64;
	// 82FCD2E0: C009FFF8  lfs f0, -8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD2E4: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCD2E8: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCD2EC: C1A9FFFC  lfs f13, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD2F0: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD2F4: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD2F8: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD2FC: C1690004  lfs f11, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD300: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD304: C1490008  lfs f10, 8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCD308: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCD30C: C12AFFFC  lfs f9, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD310: D12B000C  stfs f9, 0xc(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCD314: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD318: D10B0010  stfs f8, 0x10(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCD31C: C0EA0004  lfs f7, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD320: D0EB0014  stfs f7, 0x14(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCD324: C0C90018  lfs f6, 0x18(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(24 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD328: D0CB0018  stfs f6, 0x18(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82FCD32C: C0AA000C  lfs f5, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD330: D0AB001C  stfs f5, 0x1c(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82FCD334: C08A0010  lfs f4, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD338: D08B0020  stfs f4, 0x20(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82FCD33C: C06A0014  lfs f3, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCD340: C0490028  lfs f2, 0x28(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(40 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCD344: 39290040  addi r9, r9, 0x40
	ctx.r[9].s64 = ctx.r[9].s64 + 64;
	// 82FCD348: D06B0024  stfs f3, 0x24(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82FCD34C: C02A001C  lfs f1, 0x1c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCD350: D04B0028  stfs f2, 0x28(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82FCD354: C00A0020  lfs f0, 0x20(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD358: D02B002C  stfs f1, 0x2c(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 82FCD35C: C1AA0024  lfs f13, 0x24(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD360: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCD364: D00B0030  stfs f0, 0x30(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 82FCD368: D1AB0034  stfs f13, 0x34(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 82FCD36C: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCD370: 4082FF70  bne 0x82fcd2e0
	if !ctx.cr[0].eq {
	pc = 0x82FCD2E0; continue 'dispatch;
	}
	// 82FCD374: 7F078000  cmpw cr6, r7, r16
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[16].s32, &mut ctx.xer);
	// 82FCD378: 4199005C  bgt cr6, 0x82fcd3d4
	if ctx.cr[6].gt {
	pc = 0x82FCD3D4; continue 'dispatch;
	}
	// 82FCD37C: 7D703850  subf r11, r16, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[16].s64;
	// 82FCD380: 81130000  lwz r8, 0(r19)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD384: 54EA2036  slwi r10, r7, 4
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD388: 7D6BAA14  add r11, r11, r21
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[21].u64;
	// 82FCD38C: 38C100D8  addi r6, r1, 0xd8
	ctx.r[6].s64 = ctx.r[1].s64 + 216;
	// 82FCD390: 556B2036  slwi r11, r11, 4
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD394: 7D278050  subf r9, r7, r16
	ctx.r[9].s64 = ctx.r[16].s64 - ctx.r[7].s64;
	// 82FCD398: 7D4A3214  add r10, r10, r6
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 82FCD39C: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCD3A0: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCD3A4: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD3A8: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCD3AC: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD3B0: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD3B4: C16B000C  lfs f11, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD3B8: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCD3BC: D00AFFF8  stfs f0, -8(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCD3C0: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD3C4: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD3C8: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD3CC: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCD3D0: 4082FFD4  bne 0x82fcd3a4
	if !ctx.cr[0].eq {
	pc = 0x82FCD3A4; continue 'dispatch;
	}
	// 82FCD3D4: 7EB2AB78  mr r18, r21
	ctx.r[18].u64 = ctx.r[21].u64;
	// 82FCD3D8: FFA0F090  fmr f29, f30
	ctx.f[29].f64 = ctx.f[30].f64;
	// 82FCD3DC: 3AB50001  addi r21, r21, 1
	ctx.r[21].s64 = ctx.r[21].s64 + 1;
	// 82FCD3E0: 92410140  stw r18, 0x140(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(320 as u32), ctx.r[18].u32 ) };
	// 82FCD3E4: 92A10060  stw r21, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[21].u32 ) };
	// 82FCD3E8: 48000038  b 0x82fcd420
	pc = 0x82FCD420; continue 'dispatch;
	// 82FCD3EC: 7D707A14  add r11, r16, r15
	ctx.r[11].u64 = ctx.r[16].u64 + ctx.r[15].u64;
	// 82FCD3F0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCD3F4: 4198002C  blt cr6, 0x82fcd420
	if ctx.cr[6].lt {
	pc = 0x82FCD420; continue 'dispatch;
	}
	// 82FCD3F8: 81610118  lwz r11, 0x118(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCD3FC: 568A103A  slwi r10, r20, 2
	ctx.r[10].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD400: 812101F0  lwz r9, 0x1f0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(496 as u32) ) } as u64;
	// 82FCD404: 7C8A5A14  add r4, r10, r11
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCD408: 552B103A  slwi r11, r9, 2
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD40C: 38640004  addi r3, r4, 4
	ctx.r[3].s64 = ctx.r[4].s64 + 4;
	// 82FCD410: 390BFFFF  addi r8, r11, -1
	ctx.r[8].s64 = ctx.r[11].s64 + -1;
	// 82FCD414: D3C40000  stfs f30, 0(r4)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD418: 5505003A  rlwinm r5, r8, 0, 0, 0x1d
	ctx.r[5].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCD41C: 481DB57D  bl 0x831a8998
	ctx.lr = 0x82FCD420;
	sub_831A8998(ctx, base);
	// 82FCD420: 7F15F800  cmpw cr6, r21, r31
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCD424: 4198E98C  blt cr6, 0x82fcbdb0
	if ctx.cr[6].lt {
	pc = 0x82FCBDB0; continue 'dispatch;
	}
	// 82FCD428: 812101F8  lwz r9, 0x1f8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(504 as u32) ) } as u64;
	// 82FCD42C: 81730008  lwz r11, 8(r19)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD430: 39490001  addi r10, r9, 1
	ctx.r[10].s64 = ctx.r[9].s64 + 1;
	// 82FCD434: 80930000  lwz r4, 0(r19)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD438: 91D30000  stw r14, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[14].u32 ) };
	// 82FCD43C: 55680000  rlwinm r8, r11, 0, 0, 0
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCD440: 91530004  stw r10, 4(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCD444: 91530008  stw r10, 8(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FCD448: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCD44C: 814101E0  lwz r10, 0x1e0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(480 as u32) ) } as u64;
	// 82FCD450: 80E10118  lwz r7, 0x118(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(280 as u32) ) } as u64;
	// 82FCD454: 80C103A4  lwz r6, 0x3a4(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(932 as u32) ) } as u64;
	// 82FCD458: 91510004  stw r10, 4(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCD45C: 83D10000  lwz r30, 0(r17)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD460: 83F10008  lwz r31, 8(r17)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[17].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD464: 90F10000  stw r7, 0(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 82FCD468: 91510008  stw r10, 8(r17)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[17].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FCD46C: 91260000  stw r9, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82FCD470: 409A001C  bne cr6, 0x82fcd48c
	if !ctx.cr[6].eq {
	pc = 0x82FCD48C; continue 'dispatch;
	}
	// 82FCD474: 81210114  lwz r9, 0x114(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(276 as u32) ) } as u64;
	// 82FCD478: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 82FCD47C: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCD480: 55652036  slwi r5, r11, 4
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCD484: 7C6A482E  lwzx r3, r10, r9
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 82FCD488: 4BED3329  bl 0x82ea07b0
	ctx.lr = 0x82FCD48C;
	sub_82EA07B0(ctx, base);
	// 82FCD48C: 57EB0000  rlwinm r11, r31, 0, 0, 0
	ctx.r[11].u64 = ctx.r[31].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCD490: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCD494: 409A0020  bne cr6, 0x82fcd4b4
	if !ctx.cr[6].eq {
	pc = 0x82FCD4B4; continue 'dispatch;
	}
	// 82FCD498: 81410114  lwz r10, 0x114(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(276 as u32) ) } as u64;
	// 82FCD49C: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCD4A0: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCD4A4: 57E5103A  slwi r5, r31, 2
	ctx.r[5].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCD4A8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCD4AC: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCD4B0: 4BED3301  bl 0x82ea07b0
	ctx.lr = 0x82FCD4B4;
	sub_82EA07B0(ctx, base);
	// 82FCD4B4: 38210390  addi r1, r1, 0x390
	ctx.r[1].s64 = ctx.r[1].s64 + 912;
	// 82FCD4B8: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82FCD4BC: 481DB609  bl 0x831a8ac4
	ctx.lr = 0x82FCD4C0;
	sub_831A8A8C(ctx, base);
	// 82FCD4C0: 481DACC0  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCD4C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCD4C8 size=1552
    let mut pc: u32 = 0x82FCD4C8;
    'dispatch: loop {
        match pc {
            0x82FCD4C8 => {
    //   block [0x82FCD4C8..0x82FCDAD8)
	// 82FCD4C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCD4CC: 481DAC75  bl 0x831a8140
	ctx.lr = 0x82FCD4D0;
	sub_831A8130(ctx, base);
	// 82FCD4D0: DBA1FF70  stfd f29, -0x90(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-144 as u32), ctx.f[29].u64 ) };
	// 82FCD4D4: DBC1FF78  stfd f30, -0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-136 as u32), ctx.f[30].u64 ) };
	// 82FCD4D8: DBE1FF80  stfd f31, -0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-128 as u32), ctx.f[31].u64 ) };
	// 82FCD4DC: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82FCD4E0: 83860000  lwz r28, 0(r6)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD4E4: 7D494050  subf r10, r9, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 82FCD4E8: 7D634050  subf r11, r3, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[3].s64;
	// 82FCD4EC: 55472036  slwi r7, r10, 4
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(4);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCD4F0: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 82FCD4F4: 38C1FF10  addi r6, r1, -0xf0
	ctx.r[6].s64 = ctx.r[1].s64 + -240;
	// 82FCD4F8: 7C895050  subf r4, r9, r10
	ctx.r[4].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 82FCD4FC: 55292036  slwi r9, r9, 4
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(4);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCD500: 549F2036  slwi r31, r4, 4
	ctx.r[31].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FCD504: 7D09E214  add r8, r9, r28
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[28].u64;
	// 82FCD508: 7D27E214  add r9, r7, r28
	ctx.r[9].u64 = ctx.r[7].u64 + ctx.r[28].u64;
	// 82FCD50C: 3FC08200  lis r30, -0x7e00
	ctx.r[30].s64 = -2113929216;
	// 82FCD510: 7CFF3214  add r7, r31, r6
	ctx.r[7].u64 = ctx.r[31].u64 + ctx.r[6].u64;
	// 82FCD514: 3FE08200  lis r31, -0x7e00
	ctx.r[31].s64 = -2113929216;
	// 82FCD518: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD51C: 7F2B5051  subf. r25, r11, r10
	ctx.r[25].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[25].s32, 0, &mut ctx.xer);
	// 82FCD520: C1880004  lfs f12, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD524: 3B430001  addi r26, r3, 1
	ctx.r[26].s64 = ctx.r[3].s64 + 1;
	// 82FCD528: C01E08A4  lfs f0, 0x8a4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD52C: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 82FCD530: C1680008  lfs f11, 8(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD534: 7D5D5378  mr r29, r10
	ctx.r[29].u64 = ctx.r[10].u64;
	// 82FCD538: C148000C  lfs f10, 0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCD53C: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 82FCD540: D001FF10  stfs f0, -0xf0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-240 as u32), tmp.u32 ) };
	// 82FCD544: D001FF14  stfs f0, -0xec(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-236 as u32), tmp.u32 ) };
	// 82FCD548: D001FF18  stfs f0, -0xe8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-232 as u32), tmp.u32 ) };
	// 82FCD54C: D001FF1C  stfs f0, -0xe4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-228 as u32), tmp.u32 ) };
	// 82FCD550: D001FF20  stfs f0, -0xe0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-224 as u32), tmp.u32 ) };
	// 82FCD554: D001FF24  stfs f0, -0xdc(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-220 as u32), tmp.u32 ) };
	// 82FCD558: D001FF28  stfs f0, -0xd8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-216 as u32), tmp.u32 ) };
	// 82FCD55C: D001FF2C  stfs f0, -0xd4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-212 as u32), tmp.u32 ) };
	// 82FCD560: D001FF30  stfs f0, -0xd0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-208 as u32), tmp.u32 ) };
	// 82FCD564: D001FF34  stfs f0, -0xcc(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-204 as u32), tmp.u32 ) };
	// 82FCD568: D001FF38  stfs f0, -0xc8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-200 as u32), tmp.u32 ) };
	// 82FCD56C: D001FF3C  stfs f0, -0xc4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-196 as u32), tmp.u32 ) };
	// 82FCD570: D001FF40  stfs f0, -0xc0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-192 as u32), tmp.u32 ) };
	// 82FCD574: D001FF44  stfs f0, -0xbc(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-188 as u32), tmp.u32 ) };
	// 82FCD578: D001FF48  stfs f0, -0xb8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-184 as u32), tmp.u32 ) };
	// 82FCD57C: D001FF4C  stfs f0, -0xb4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-180 as u32), tmp.u32 ) };
	// 82FCD580: D001FF50  stfs f0, -0xb0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), tmp.u32 ) };
	// 82FCD584: D001FF54  stfs f0, -0xac(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-172 as u32), tmp.u32 ) };
	// 82FCD588: D001FF58  stfs f0, -0xa8(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), tmp.u32 ) };
	// 82FCD58C: D001FF5C  stfs f0, -0xa4(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-164 as u32), tmp.u32 ) };
	// 82FCD590: D001FF60  stfs f0, -0xa0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), tmp.u32 ) };
	// 82FCD594: D001FF64  stfs f0, -0x9c(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-156 as u32), tmp.u32 ) };
	// 82FCD598: D001FF68  stfs f0, -0x98(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-152 as u32), tmp.u32 ) };
	// 82FCD59C: D001FF6C  stfs f0, -0x94(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-148 as u32), tmp.u32 ) };
	// 82FCD5A0: C1290010  lfs f9, 0x10(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD5A4: C1090014  lfs f8, 0x14(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(20 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD5A8: C0E90018  lfs f7, 0x18(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(24 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD5AC: C0C9001C  lfs f6, 0x1c(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD5B0: D1A1FF00  stfs f13, -0x100(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 82FCD5B4: D181FF04  stfs f12, -0xfc(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-252 as u32), tmp.u32 ) };
	// 82FCD5B8: D161FF08  stfs f11, -0xf8(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-248 as u32), tmp.u32 ) };
	// 82FCD5BC: D141FF0C  stfs f10, -0xf4(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-244 as u32), tmp.u32 ) };
	// 82FCD5C0: C01F08A8  lfs f0, 0x8a8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD5C4: D1270000  stfs f9, 0(r7)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD5C8: D1070004  stfs f8, 4(r7)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD5CC: D0E70008  stfs f7, 8(r7)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCD5D0: D0C7000C  stfs f6, 0xc(r7)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCD5D4: 408102D0  ble 0x82fcd8a4
	if !ctx.cr[0].gt {
	pc = 0x82FCD8A4; continue 'dispatch;
	}
	// 82FCD5D8: 7C6AD214  add r3, r10, r26
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[26].u64;
	// 82FCD5DC: 80E50000  lwz r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD5E0: 7EEBD214  add r23, r11, r26
	ctx.r[23].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 82FCD5E4: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD5E8: 55682036  slwi r8, r11, 4
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCD5EC: 3BE1FF08  addi r31, r1, -0xf8
	ctx.r[31].s64 = ctx.r[1].s64 + -248;
	// 82FCD5F0: 54992036  slwi r25, r4, 4
	ctx.r[25].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[25].u64 = ctx.r[25].u32 as u64;
	// 82FCD5F4: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD5F8: 5478103A  slwi r24, r3, 2
	ctx.r[24].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 82FCD5FC: 7FCA3A14  add r30, r10, r7
	ctx.r[30].u64 = ctx.r[10].u64 + ctx.r[7].u64;
	// 82FCD600: 56F7103A  slwi r23, r23, 2
	ctx.r[23].u32 = ctx.r[23].u32.wrapping_shl(2);
	ctx.r[23].u64 = ctx.r[23].u32 as u64;
	// 82FCD604: 7D59FA14  add r10, r25, r31
	ctx.r[10].u64 = ctx.r[25].u64 + ctx.r[31].u64;
	// 82FCD608: 7C6B3A14  add r3, r11, r7
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[7].u64;
	// 82FCD60C: 7FF83A14  add r31, r24, r7
	ctx.r[31].u64 = ctx.r[24].u64 + ctx.r[7].u64;
	// 82FCD610: 7D08E214  add r8, r8, r28
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[28].u64;
	// 82FCD614: 3961FF14  addi r11, r1, -0xec
	ctx.r[11].s64 = ctx.r[1].s64 + -236;
	// 82FCD618: 7CF73A14  add r7, r23, r7
	ctx.r[7].u64 = ctx.r[23].u64 + ctx.r[7].u64;
	// 82FCD61C: 832BFFEC  lwz r25, -0x14(r11)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-20 as u32) ) } as u64;
	// 82FCD620: 3B01FEE0  addi r24, r1, -0x120
	ctx.r[24].s64 = ctx.r[1].s64 + -288;
	// 82FCD624: 82EBFFF0  lwz r23, -0x10(r11)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) } as u64;
	// 82FCD628: 3AC1FED0  addi r22, r1, -0x130
	ctx.r[22].s64 = ctx.r[1].s64 + -304;
	// 82FCD62C: 82ABFFF4  lwz r21, -0xc(r11)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) } as u64;
	// 82FCD630: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD634: 828BFFF8  lwz r20, -8(r11)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCD638: C1870000  lfs f12, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD63C: 82680000  lwz r19, 0(r8)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD640: ED4C6828  fsubs f10, f12, f13
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD644: 93380000  stw r25, 0(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 82FCD648: C0BE0000  lfs f5, 0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD64C: 92F80004  stw r23, 4(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(4 as u32), ctx.r[23].u32 ) };
	// 82FCD650: C09F0000  lfs f4, 0(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD654: 92B80008  stw r21, 8(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(8 as u32), ctx.r[21].u32 ) };
	// 82FCD658: ED616828  fsubs f11, f1, f13
	ctx.f[11].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD65C: 9298000C  stw r20, 0xc(r24)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[24].u32.wrapping_add(12 as u32), ctx.r[20].u32 ) };
	// 82FCD660: C101FEE8  lfs f8, -0x118(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-280 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD664: C0E1FEEC  lfs f7, -0x114(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-276 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD668: 83080004  lwz r24, 4(r8)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD66C: C0C1FEE0  lfs f6, -0x120(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-288 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD670: 82A80008  lwz r21, 8(r8)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD674: 8288000C  lwz r20, 0xc(r8)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD678: EC442828  fsubs f2, f4, f5
	ctx.f[2].f64 = (((ctx.f[4].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCD67C: 92760000  stw r19, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[19].u32 ) };
	// 82FCD680: EC612828  fsubs f3, f1, f5
	ctx.f[3].f64 = (((ctx.f[1].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCD684: C121FEE4  lfs f9, -0x11c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-284 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD688: 3B21FED0  addi r25, r1, -0x130
	ctx.r[25].s64 = ctx.r[1].s64 + -304;
	// 82FCD68C: 93160004  stw r24, 4(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), ctx.r[24].u32 ) };
	// 82FCD690: 3AE1FEF0  addi r23, r1, -0x110
	ctx.r[23].s64 = ctx.r[1].s64 + -272;
	// 82FCD694: 92B60008  stw r21, 8(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(8 as u32), ctx.r[21].u32 ) };
	// 82FCD698: 3AA1FEB0  addi r21, r1, -0x150
	ctx.r[21].s64 = ctx.r[1].s64 + -336;
	// 82FCD69C: 9296000C  stw r20, 0xc(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(12 as u32), ctx.r[20].u32 ) };
	// 82FCD6A0: C0A1FED0  lfs f5, -0x130(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-304 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD6A4: C081FED4  lfs f4, -0x12c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-300 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD6A8: EDAB5024  fdivs f13, f11, f10
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FCD6AC: C3E1FED8  lfs f31, -0x128(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-296 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCD6B0: 83090000  lwz r24, 0(r9)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD6B4: C3C1FEDC  lfs f30, -0x124(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-292 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCD6B8: 82C90004  lwz r22, 4(r9)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD6BC: 3A8BFFEC  addi r20, r11, -0x14
	ctx.r[20].s64 = ctx.r[11].s64 + -20;
	// 82FCD6C0: 82690008  lwz r19, 8(r9)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD6C4: 3A8A0008  addi r20, r10, 8
	ctx.r[20].s64 = ctx.r[10].s64 + 8;
	// 82FCD6C8: EC631024  fdivs f3, f3, f2
	ctx.f[3].f64 = ((ctx.f[3].f64 / ctx.f[2].f64) as f32) as f64;
	// 82FCD6CC: 3A81FEC0  addi r20, r1, -0x140
	ctx.r[20].s64 = ctx.r[1].s64 + -320;
	// 82FCD6D0: 93150000  stw r24, 0(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FCD6D4: 92D50004  stw r22, 4(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(4 as u32), ctx.r[22].u32 ) };
	// 82FCD6D8: EC406828  fsubs f2, f0, f13
	ctx.f[2].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD6DC: EFA06824  fdivs f29, f0, f13
	ctx.f[29].f64 = ((ctx.f[0].f64 / ctx.f[13].f64) as f32) as f64;
	// 82FCD6E0: ED8900B2  fmuls f12, f9, f2
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCD6E4: D181FEE4  stfs f12, -0x11c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-284 as u32), tmp.u32 ) };
	// 82FCD6E8: EDA600B2  fmuls f13, f6, f2
	ctx.f[13].f64 = (((ctx.f[6].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCD6EC: D1A1FEE0  stfs f13, -0x120(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-288 as u32), tmp.u32 ) };
	// 82FCD6F0: ED6800B2  fmuls f11, f8, f2
	ctx.f[11].f64 = (((ctx.f[8].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCD6F4: D161FEE8  stfs f11, -0x118(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-280 as u32), tmp.u32 ) };
	// 82FCD6F8: ED4700B2  fmuls f10, f7, f2
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[2].f64) as f32) as f64);
	// 82FCD6FC: D141FEEC  stfs f10, -0x114(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-276 as u32), tmp.u32 ) };
	// 82FCD700: ED846028  fsubs f12, f4, f12
	ctx.f[12].f64 = (((ctx.f[4].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCD704: D181FED4  stfs f12, -0x12c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-300 as u32), tmp.u32 ) };
	// 82FCD708: EDA56828  fsubs f13, f5, f13
	ctx.f[13].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD70C: D1A1FED0  stfs f13, -0x130(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-304 as u32), tmp.u32 ) };
	// 82FCD710: ED7F5828  fsubs f11, f31, f11
	ctx.f[11].f64 = (((ctx.f[31].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCD714: D161FED8  stfs f11, -0x128(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-296 as u32), tmp.u32 ) };
	// 82FCD718: ED5E5028  fsubs f10, f30, f10
	ctx.f[10].f64 = (((ctx.f[30].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCD71C: D141FEDC  stfs f10, -0x124(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-292 as u32), tmp.u32 ) };
	// 82FCD720: 83190008  lwz r24, 8(r25)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD724: 82D9000C  lwz r22, 0xc(r25)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD728: 82590000  lwz r18, 0(r25)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD72C: 83390004  lwz r25, 4(r25)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD730: 93370004  stw r25, 4(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(4 as u32), ctx.r[25].u32 ) };
	// 82FCD734: 92570000  stw r18, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[18].u32 ) };
	// 82FCD738: ED3D0372  fmuls f9, f29, f13
	ctx.f[9].f64 = (((ctx.f[29].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCD73C: 93170008  stw r24, 8(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCD740: D12BFFFC  stfs f9, -4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD744: 92D7000C  stw r22, 0xc(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(12 as u32), ctx.r[22].u32 ) };
	// 82FCD748: C101FEF4  lfs f8, -0x10c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-268 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD74C: EDBD0232  fmuls f13, f29, f8
	ctx.f[13].f64 = (((ctx.f[29].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCD750: C0E1FEF8  lfs f7, -0x108(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-264 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD754: 8329000C  lwz r25, 0xc(r9)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD758: C0C1FEFC  lfs f6, -0x104(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-260 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD75C: D1A1FEF4  stfs f13, -0x10c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-268 as u32), tmp.u32 ) };
	// 82FCD760: ED9D01F2  fmuls f12, f29, f7
	ctx.f[12].f64 = (((ctx.f[29].f64 * ctx.f[7].f64) as f32) as f64);
	// 82FCD764: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD768: ED7D01B2  fmuls f11, f29, f6
	ctx.f[11].f64 = (((ctx.f[29].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCD76C: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD770: 9335000C  stw r25, 0xc(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(12 as u32), ctx.r[25].u32 ) };
	// 82FCD774: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCD778: 832A0014  lwz r25, 0x14(r10)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCD77C: D181FEF8  stfs f12, -0x108(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-264 as u32), tmp.u32 ) };
	// 82FCD780: 82CA000C  lwz r22, 0xc(r10)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD784: D161FEFC  stfs f11, -0x104(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-260 as u32), tmp.u32 ) };
	// 82FCD788: 82EA0008  lwz r23, 8(r10)
	ctx.r[23].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD78C: 3A41FEB0  addi r18, r1, -0x150
	ctx.r[18].s64 = ctx.r[1].s64 + -336;
	// 82FCD790: 830A0010  lwz r24, 0x10(r10)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCD794: ECA01828  fsubs f5, f0, f3
	ctx.f[5].f64 = (((ctx.f[0].f64 - ctx.f[3].f64) as f32) as f64);
	// 82FCD798: 93140008  stw r24, 8(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCD79C: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 82FCD7A0: 9334000C  stw r25, 0xc(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(12 as u32), ctx.r[25].u32 ) };
	// 82FCD7A4: 3BBDFFFF  addi r29, r29, -1
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	// 82FCD7A8: 92D40004  stw r22, 4(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(4 as u32), ctx.r[22].u32 ) };
	// 82FCD7AC: 3AC1FEA0  addi r22, r1, -0x160
	ctx.r[22].s64 = ctx.r[1].s64 + -352;
	// 82FCD7B0: 92F40000  stw r23, 0(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 82FCD7B4: C0E1FEC4  lfs f7, -0x13c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-316 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD7B8: 92750008  stw r19, 8(r21)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[21].u32.wrapping_add(8 as u32), ctx.r[19].u32 ) };
	// 82FCD7BC: C041FEBC  lfs f2, -0x144(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-324 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCD7C0: C0C1FEB0  lfs f6, -0x150(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-336 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD7C4: 7F26E851  subf. r25, r6, r29
	ctx.r[25].s64 = ctx.r[29].s64 - ctx.r[6].s64;
	ctx.cr[0].compare_i32(ctx.r[25].s32, 0, &mut ctx.xer);
	// 82FCD7C8: C101FEC0  lfs f8, -0x140(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-320 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD7CC: EDA800F2  fmuls f13, f8, f3
	ctx.f[13].f64 = (((ctx.f[8].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCD7D0: C181FEC8  lfs f12, -0x138(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-312 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD7D4: 38E70004  addi r7, r7, 4
	ctx.r[7].s64 = ctx.r[7].s64 + 4;
	// 82FCD7D8: C081FECC  lfs f4, -0x134(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-308 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD7DC: ED6C00F2  fmuls f11, f12, f3
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCD7E0: ED4400F2  fmuls f10, f4, f3
	ctx.f[10].f64 = (((ctx.f[4].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCD7E4: C121FEB8  lfs f9, -0x148(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-328 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCD7E8: ED8700F2  fmuls f12, f7, f3
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCD7EC: C061FEB4  lfs f3, -0x14c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-332 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCD7F0: EC825028  fsubs f4, f2, f10
	ctx.f[4].f64 = (((ctx.f[2].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCD7F4: D1A1FEC0  stfs f13, -0x140(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-320 as u32), tmp.u32 ) };
	// 82FCD7F8: EDA66828  fsubs f13, f6, f13
	ctx.f[13].f64 = (((ctx.f[6].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD7FC: D1A1FEB0  stfs f13, -0x150(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-336 as u32), tmp.u32 ) };
	// 82FCD800: EC495828  fsubs f2, f9, f11
	ctx.f[2].f64 = (((ctx.f[9].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCD804: D081FEBC  stfs f4, -0x144(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-324 as u32), tmp.u32 ) };
	// 82FCD808: D041FEB8  stfs f2, -0x148(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-328 as u32), tmp.u32 ) };
	// 82FCD80C: ED202824  fdivs f9, f0, f5
	ctx.f[9].f64 = ((ctx.f[0].f64 / ctx.f[5].f64) as f32) as f64;
	// 82FCD810: D181FEC4  stfs f12, -0x13c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-316 as u32), tmp.u32 ) };
	// 82FCD814: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 82FCD818: D161FEC8  stfs f11, -0x138(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-312 as u32), tmp.u32 ) };
	// 82FCD81C: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCD820: D141FECC  stfs f10, -0x134(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-308 as u32), tmp.u32 ) };
	// 82FCD824: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 82FCD828: 3BFFFFFC  addi r31, r31, -4
	ctx.r[31].s64 = ctx.r[31].s64 + -4;
	// 82FCD82C: 3BDEFFFC  addi r30, r30, -4
	ctx.r[30].s64 = ctx.r[30].s64 + -4;
	// 82FCD830: ED036028  fsubs f8, f3, f12
	ctx.f[8].f64 = (((ctx.f[3].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCD834: D101FEB4  stfs f8, -0x14c(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-332 as u32), tmp.u32 ) };
	// 82FCD838: 83120008  lwz r24, 8(r18)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD83C: 3929FFF0  addi r9, r9, -0x10
	ctx.r[9].s64 = ctx.r[9].s64 + -16;
	// 82FCD840: 93160008  stw r24, 8(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(8 as u32), ctx.r[24].u32 ) };
	// 82FCD844: 3884FFFF  addi r4, r4, -1
	ctx.r[4].s64 = ctx.r[4].s64 + -1;
	// 82FCD848: 83120000  lwz r24, 0(r18)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD84C: ECE90372  fmuls f7, f9, f13
	ctx.f[7].f64 = (((ctx.f[9].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCD850: 93160000  stw r24, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 82FCD854: D0EAFFF8  stfs f7, -8(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCD858: 8312000C  lwz r24, 0xc(r18)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD85C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCD860: 83320004  lwz r25, 4(r18)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD864: 93360004  stw r25, 4(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(4 as u32), ctx.r[25].u32 ) };
	// 82FCD868: 9316000C  stw r24, 0xc(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(12 as u32), ctx.r[24].u32 ) };
	// 82FCD86C: C081FEA4  lfs f4, -0x15c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-348 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCD870: C0C1FEAC  lfs f6, -0x154(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-340 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD874: ED6901B2  fmuls f11, f9, f6
	ctx.f[11].f64 = (((ctx.f[9].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCD878: C0A1FEA8  lfs f5, -0x158(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-344 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD87C: EDA90132  fmuls f13, f9, f4
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCD880: ED890172  fmuls f12, f9, f5
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[5].f64) as f32) as f64);
	// 82FCD884: D1AAFFFC  stfs f13, -4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCD888: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCD88C: D16A0004  stfs f11, 4(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCD890: 394AFFF0  addi r10, r10, -0x10
	ctx.r[10].s64 = ctx.r[10].s64 + -16;
	// 82FCD894: D1A1FEA4  stfs f13, -0x15c(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-348 as u32), tmp.u32 ) };
	// 82FCD898: D181FEA8  stfs f12, -0x158(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-344 as u32), tmp.u32 ) };
	// 82FCD89C: D161FEAC  stfs f11, -0x154(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-340 as u32), tmp.u32 ) };
	// 82FCD8A0: 4181FD7C  bgt 0x82fcd61c
	if ctx.cr[0].gt {
	pc = 0x82FCD61C; continue 'dispatch;
	}
	// 82FCD8A4: 7D66E851  subf. r11, r6, r29
	ctx.r[11].s64 = ctx.r[29].s64 - ctx.r[6].s64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCD8A8: 40800084  bge 0x82fcd92c
	if !ctx.cr[0].lt {
	pc = 0x82FCD92C; continue 'dispatch;
	}
	// 82FCD8AC: 548A2036  slwi r10, r4, 4
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD8B0: 3961FF10  addi r11, r1, -0xf0
	ctx.r[11].s64 = ctx.r[1].s64 + -240;
	// 82FCD8B4: 3921FEA0  addi r9, r1, -0x160
	ctx.r[9].s64 = ctx.r[1].s64 + -352;
	// 82FCD8B8: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCD8BC: 576A2036  slwi r10, r27, 4
	ctx.r[10].u32 = ctx.r[27].u32.wrapping_shl(4);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCD8C0: 3961FF00  addi r11, r1, -0x100
	ctx.r[11].s64 = ctx.r[1].s64 + -256;
	// 82FCD8C4: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FCD8C8: 80E80008  lwz r7, 8(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD8CC: 80A80004  lwz r5, 4(r8)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD8D0: 394BFFF0  addi r10, r11, -0x10
	ctx.r[10].s64 = ctx.r[11].s64 + -16;
	// 82FCD8D4: 80880000  lwz r4, 0(r8)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD8D8: 80C8000C  lwz r6, 0xc(r8)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD8DC: C00BFFFC  lfs f0, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCD8E0: 90E90008  stw r7, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FCD8E4: C1ABFFF8  lfs f13, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD8E8: 90A90004  stw r5, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCD8EC: C18BFFF0  lfs f12, -0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD8F0: 90890000  stw r4, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCD8F4: C16BFFF4  lfs f11, -0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCD8F8: 90C9000C  stw r6, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FCD8FC: C141FEA0  lfs f10, -0x160(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-352 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCD900: C101FEA4  lfs f8, -0x15c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-348 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD904: C0E1FEAC  lfs f7, -0x154(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-340 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD908: ECC70028  fsubs f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCD90C: C0A1FEA8  lfs f5, -0x158(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-344 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD910: EC8601B2  fmuls f4, f6, f6
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[6].f64) as f32) as f64);
	// 82FCD914: EC656828  fsubs f3, f5, f13
	ctx.f[3].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD918: ED2A6028  fsubs f9, f10, f12
	ctx.f[9].f64 = (((ctx.f[10].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCD91C: EC485828  fsubs f2, f8, f11
	ctx.f[2].f64 = (((ctx.f[8].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCD920: EC2320FA  fmadds f1, f3, f3, f4
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCD924: EC090A7A  fmadds f0, f9, f9, f1
	ctx.f[0].f64 = (((ctx.f[9].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FCD928: 48000198  b 0x82fcdac0
	pc = 0x82FCDAC0; continue 'dispatch;
	// 82FCD92C: 576B2036  slwi r11, r27, 4
	ctx.r[11].u32 = ctx.r[27].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD930: 81250000  lwz r9, 0(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD934: 3941FF10  addi r10, r1, -0xf0
	ctx.r[10].s64 = ctx.r[1].s64 + -240;
	// 82FCD938: 7CA6D214  add r5, r6, r26
	ctx.r[5].u64 = ctx.r[6].u64 + ctx.r[26].u64;
	// 82FCD93C: 7CEB5214  add r7, r11, r10
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCD940: 54C4103A  slwi r4, r6, 2
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCD944: 54A5103A  slwi r5, r5, 2
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCD948: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCD94C: 3941FF00  addi r10, r1, -0x100
	ctx.r[10].s64 = ctx.r[1].s64 + -256;
	// 82FCD950: 3901FEB0  addi r8, r1, -0x150
	ctx.r[8].s64 = ctx.r[1].s64 + -336;
	// 82FCD954: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCD958: 8147000C  lwz r10, 0xc(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD95C: 83E70004  lwz r31, 4(r7)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD960: 7DA44C2E  lfsx f13, r4, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCD964: 83A70008  lwz r29, 8(r7)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD968: 7D854C2E  lfsx f12, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD96C: ED4C6828  fsubs f10, f12, f13
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD970: 392BFFF0  addi r9, r11, -0x10
	ctx.r[9].s64 = ctx.r[11].s64 + -16;
	// 82FCD974: 90680000  stw r3, 0(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 82FCD978: ED616828  fsubs f11, f1, f13
	ctx.f[11].f64 = (((ctx.f[1].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCD97C: 9148000C  stw r10, 0xc(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82FCD980: 3BC1FEA0  addi r30, r1, -0x160
	ctx.r[30].s64 = ctx.r[1].s64 + -352;
	// 82FCD984: 93E80004  stw r31, 4(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[31].u32 ) };
	// 82FCD988: 54CB2036  slwi r11, r6, 4
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCD98C: 93A80008  stw r29, 8(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[29].u32 ) };
	// 82FCD990: C181FEB4  lfs f12, -0x14c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-332 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCD994: C061FEB0  lfs f3, -0x150(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-336 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCD998: 80890008  lwz r4, 8(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCD99C: C021FEBC  lfs f1, -0x144(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-324 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCD9A0: 8149000C  lwz r10, 0xc(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCD9A4: C041FEB8  lfs f2, -0x148(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-328 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCD9A8: 81090000  lwz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCD9AC: 81290004  lwz r9, 4(r9)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCD9B0: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 82FCD9B4: 909E0008  stw r4, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCD9B8: 38E1FEB0  addi r7, r1, -0x150
	ctx.r[7].s64 = ctx.r[1].s64 + -336;
	// 82FCD9BC: 915E000C  stw r10, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82FCD9C0: 38A1FEC0  addi r5, r1, -0x140
	ctx.r[5].s64 = ctx.r[1].s64 + -320;
	// 82FCD9C4: ED2B5024  fdivs f9, f11, f10
	ctx.f[9].f64 = ((ctx.f[11].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FCD9C8: 911E0000  stw r8, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCD9CC: 913E0004  stw r9, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 82FCD9D0: 3861FEC0  addi r3, r1, -0x140
	ctx.r[3].s64 = ctx.r[1].s64 + -320;
	// 82FCD9D4: C0AB0000  lfs f5, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCD9D8: 38C1FEA0  addi r6, r1, -0x160
	ctx.r[6].s64 = ctx.r[1].s64 + -352;
	// 82FCD9DC: C10B0004  lfs f8, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCD9E0: C0EB0008  lfs f7, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCD9E4: C0CB000C  lfs f6, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCD9E8: EDA20272  fmuls f13, f2, f9
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCD9EC: D1A1FEB8  stfs f13, -0x148(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-328 as u32), tmp.u32 ) };
	// 82FCD9F0: ED6C0272  fmuls f11, f12, f9
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCD9F4: D161FEB4  stfs f11, -0x14c(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-332 as u32), tmp.u32 ) };
	// 82FCD9F8: EC804828  fsubs f4, f0, f9
	ctx.f[4].f64 = (((ctx.f[0].f64 - ctx.f[9].f64) as f32) as f64);
	// 82FCD9FC: C041FEA8  lfs f2, -0x158(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-344 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCDA00: EC030272  fmuls f0, f3, f9
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCDA04: D001FEB0  stfs f0, -0x150(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-336 as u32), tmp.u32 ) };
	// 82FCDA08: ED410272  fmuls f10, f1, f9
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[9].f64) as f32) as f64);
	// 82FCDA0C: D141FEBC  stfs f10, -0x144(r1)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-324 as u32), tmp.u32 ) };
	// 82FCDA10: 81070000  lwz r8, 0(r7)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDA14: C121FEA0  lfs f9, -0x160(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-352 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCDA18: 80870008  lwz r4, 8(r7)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCDA1C: C061FEA4  lfs f3, -0x15c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-348 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCDA20: 81670004  lwz r11, 4(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCDA24: C021FEAC  lfs f1, -0x154(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-340 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCDA28: 91050000  stw r8, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCDA2C: 8147000C  lwz r10, 0xc(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCDA30: EDA90132  fmuls f13, f9, f4
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCDA34: 90850008  stw r4, 8(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(8 as u32), ctx.r[4].u32 ) };
	// 82FCDA38: ED830132  fmuls f12, f3, f4
	ctx.f[12].f64 = (((ctx.f[3].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCDA3C: 91650004  stw r11, 4(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FCDA40: ED620132  fmuls f11, f2, f4
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCDA44: 9145000C  stw r10, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82FCDA48: EC410132  fmuls f2, f1, f4
	ctx.f[2].f64 = (((ctx.f[1].f64 * ctx.f[4].f64) as f32) as f64);
	// 82FCDA4C: EC00682A  fadds f0, f0, f13
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 82FCDA50: C121FEC4  lfs f9, -0x13c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-316 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCDA54: C141FEC8  lfs f10, -0x138(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-312 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCDA58: EC69602A  fadds f3, f9, f12
	ctx.f[3].f64 = ((ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCDA5C: C1A1FECC  lfs f13, -0x134(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-308 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCDA60: EC2A582A  fadds f1, f10, f11
	ctx.f[1].f64 = ((ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FCDA64: D001FEC0  stfs f0, -0x140(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-320 as u32), tmp.u32 ) };
	// 82FCDA68: D061FEC4  stfs f3, -0x13c(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-316 as u32), tmp.u32 ) };
	// 82FCDA6C: ED802828  fsubs f12, f0, f5
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[5].f64) as f32) as f64);
	// 82FCDA70: ED6D102A  fadds f11, f13, f2
	ctx.f[11].f64 = ((ctx.f[13].f64 + ctx.f[2].f64) as f32) as f64;
	// 82FCDA74: D021FEC8  stfs f1, -0x138(r1)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-312 as u32), tmp.u32 ) };
	// 82FCDA78: D161FECC  stfs f11, -0x134(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-308 as u32), tmp.u32 ) };
	// 82FCDA7C: 81230008  lwz r9, 8(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCDA80: 8103000C  lwz r8, 0xc(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCDA84: 9106000C  stw r8, 0xc(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCDA88: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDA8C: 91260008  stw r9, 8(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 82FCDA90: 80A30004  lwz r5, 4(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCDA94: 90E60000  stw r7, 0(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 82FCDA98: 90A60004  stw r5, 4(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 82FCDA9C: C141FEA8  lfs f10, -0x158(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-344 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCDAA0: EC6A3828  fsubs f3, f10, f7
	ctx.f[3].f64 = (((ctx.f[10].f64 - ctx.f[7].f64) as f32) as f64);
	// 82FCDAA4: C121FEA4  lfs f9, -0x15c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-348 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCDAA8: ED094028  fsubs f8, f9, f8
	ctx.f[8].f64 = (((ctx.f[9].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FCDAAC: ECA80232  fmuls f5, f8, f8
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[8].f64) as f32) as f64);
	// 82FCDAB0: C081FEAC  lfs f4, -0x154(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-340 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCDAB4: EC443028  fsubs f2, f4, f6
	ctx.f[2].f64 = (((ctx.f[4].f64 - ctx.f[6].f64) as f32) as f64);
	// 82FCDAB8: EC2C2B3A  fmadds f1, f12, f12, f5
	ctx.f[1].f64 = (((ctx.f[12].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCDABC: EC0308FA  fmadds f0, f3, f3, f1
	ctx.f[0].f64 = (((ctx.f[3].f64 * ctx.f[3].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FCDAC0: EDA200BA  fmadds f13, f2, f2, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[2].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FCDAC4: EC20682C  fsqrts f1, f13
	ctx.f[1].f64 = ((ctx.f[13].f64).sqrt() as f32) as f64;
	// 82FCDAC8: CBA1FF70  lfd f29, -0x90(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-144 as u32) ) };
	// 82FCDACC: CBC1FF78  lfd f30, -0x88(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-136 as u32) ) };
	// 82FCDAD0: CBE1FF80  lfd f31, -0x80(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-128 as u32) ) };
	// 82FCDAD4: 481DA6BC  b 0x831a8190
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCDAD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCDAD8 size=344
    let mut pc: u32 = 0x82FCDAD8;
    'dispatch: loop {
        match pc {
            0x82FCDAD8 => {
    //   block [0x82FCDAD8..0x82FCDC30)
	// 82FCDAD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCDADC: 481DA671  bl 0x831a814c
	ctx.lr = 0x82FCDAE0;
	sub_831A8130(ctx, base);
	// 82FCDAE0: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCDAE4: 7D394B78  mr r25, r9
	ctx.r[25].u64 = ctx.r[9].u64;
	// 82FCDAE8: 7C781B78  mr r24, r3
	ctx.r[24].u64 = ctx.r[3].u64;
	// 82FCDAEC: 7C972378  mr r23, r4
	ctx.r[23].u64 = ctx.r[4].u64;
	// 82FCDAF0: 7D48C850  subf r10, r8, r25
	ctx.r[10].s64 = ctx.r[25].s64 - ctx.r[8].s64;
	// 82FCDAF4: 7D78BA14  add r11, r24, r23
	ctx.r[11].u64 = ctx.r[24].u64 + ctx.r[23].u64;
	// 82FCDAF8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCDAFC: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82FCDB00: 7CD53378  mr r21, r6
	ctx.r[21].u64 = ctx.r[6].u64;
	// 82FCDB04: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 82FCDB08: 3ACB0001  addi r22, r11, 1
	ctx.r[22].s64 = ctx.r[11].s64 + 1;
	// 82FCDB0C: 7D094378  mr r9, r8
	ctx.r[9].u64 = ctx.r[8].u64;
	// 82FCDB10: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FCDB14: 41980050  blt cr6, 0x82fcdb64
	if ctx.cr[6].lt {
	pc = 0x82FCDB64; continue 'dispatch;
	}
	// 82FCDB18: 7D68C850  subf r11, r8, r25
	ctx.r[11].s64 = ctx.r[25].s64 - ctx.r[8].s64;
	// 82FCDB1C: 813A0000  lwz r9, 0(r26)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDB20: 39480002  addi r10, r8, 2
	ctx.r[10].s64 = ctx.r[8].s64 + 2;
	// 82FCDB24: 38EBFFFD  addi r7, r11, -3
	ctx.r[7].s64 = ctx.r[11].s64 + -3;
	// 82FCDB28: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCDB2C: 54EAF0BE  srwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCDB30: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCDB34: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCDB38: 3CE08213  lis r7, -0x7ded
	ctx.r[7].s64 = -2112684032;
	// 82FCDB3C: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCDB40: 7D294214  add r9, r9, r8
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82FCDB44: C0076900  lfs f0, 0x6900(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(26880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDB48: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCDB4C: D00BFFF8  stfs f0, -8(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCDB50: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCDB54: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCDB58: D00B0004  stfs f0, 4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCDB5C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCDB60: 4082FFE4  bne 0x82fcdb44
	if !ctx.cr[0].eq {
	pc = 0x82FCDB44; continue 'dispatch;
	}
	// 82FCDB64: 7F09C800  cmpw cr6, r9, r25
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCDB68: 41990034  bgt cr6, 0x82fcdb9c
	if ctx.cr[6].gt {
	pc = 0x82FCDB9C; continue 'dispatch;
	}
	// 82FCDB6C: 815A0000  lwz r10, 0(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDB70: 552B103A  slwi r11, r9, 2
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCDB74: 7D29C850  subf r9, r9, r25
	ctx.r[9].s64 = ctx.r[25].s64 - ctx.r[9].s64;
	// 82FCDB78: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCDB7C: 35490001  addic. r10, r9, 1
	ctx.xer.ca = (ctx.r[9].u32 > (!(1 as u32)));
	ctx.r[10].s64 = ctx.r[9].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCDB80: 3D207F7F  lis r9, 0x7f7f
	ctx.r[9].s64 = 2139029504;
	// 82FCDB84: 6129FFEE  ori r9, r9, 0xffee
	ctx.r[9].u64 = ctx.r[9].u64 | 65518;
	// 82FCDB88: 41820014  beq 0x82fcdb9c
	if ctx.cr[0].eq {
	pc = 0x82FCDB9C; continue 'dispatch;
	}
	// 82FCDB8C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 82FCDB90: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 82FCDB94: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCDB98: 4200FFF8  bdnz 0x82fcdb90
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCDB90; continue 'dispatch;
	}
	// 82FCDB9C: 7D1E4378  mr r30, r8
	ctx.r[30].u64 = ctx.r[8].u64;
	// 82FCDBA0: 7F08C800  cmpw cr6, r8, r25
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCDBA4: 41990084  bgt cr6, 0x82fcdc28
	if ctx.cr[6].gt {
	pc = 0x82FCDC28; continue 'dispatch;
	}
	// 82FCDBA8: 551F103A  slwi r31, r8, 2
	ctx.r[31].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FCDBAC: 7F1EB000  cmpw cr6, r30, r22
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[22].s32, &mut ctx.xer);
	// 82FCDBB0: 419A0020  beq cr6, 0x82fcdbd0
	if ctx.cr[6].eq {
	pc = 0x82FCDBD0; continue 'dispatch;
	}
	// 82FCDBB4: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDBB8: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FCDBBC: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDBC0: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCDBC4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCDBC8: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCDBCC: 419A0008  beq cr6, 0x82fcdbd4
	if ctx.cr[6].eq {
	pc = 0x82FCDBD4; continue 'dispatch;
	}
	// 82FCDBD0: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCDBD4: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCDBD8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCDBDC: 419A003C  beq cr6, 0x82fcdc18
	if ctx.cr[6].eq {
	pc = 0x82FCDC18; continue 'dispatch;
	}
	// 82FCDBE0: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82FCDBE4: 839B0000  lwz r28, 0(r27)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDBE8: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FCDBEC: 83BA0000  lwz r29, 0(r26)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDBF0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCDBF4: 4BFFBBD5  bl 0x82fc97c8
	ctx.lr = 0x82FCDBF8;
	sub_82FC97C8(ctx, base);
	// 82FCDBF8: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FCDBFC: 7FC8F378  mr r8, r30
	ctx.r[8].u64 = ctx.r[30].u64;
	// 82FCDC00: 7C3CFC2E  lfsx f1, r28, r31
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCDC04: 7EA6AB78  mr r6, r21
	ctx.r[6].u64 = ctx.r[21].u64;
	// 82FCDC08: 7EE4BB78  mr r4, r23
	ctx.r[4].u64 = ctx.r[23].u64;
	// 82FCDC0C: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 82FCDC10: 4BFFF8B9  bl 0x82fcd4c8
	ctx.lr = 0x82FCDC14;
	sub_82FCD4C8(ctx, base);
	// 82FCDC14: 7C3FED2E  stfsx f1, r31, r29
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[29].u32), tmp.u32) };
	// 82FCDC18: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82FCDC1C: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 82FCDC20: 7F1EC800  cmpw cr6, r30, r25
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCDC24: 4099FF88  ble cr6, 0x82fcdbac
	if !ctx.cr[6].gt {
	pc = 0x82FCDBAC; continue 'dispatch;
	}
	// 82FCDC28: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 82FCDC2C: 481DA570  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCDC30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCDC30 size=424
    let mut pc: u32 = 0x82FCDC30;
    'dispatch: loop {
        match pc {
            0x82FCDC30 => {
    //   block [0x82FCDC30..0x82FCDDD8)
	// 82FCDC30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCDC34: 481DA515  bl 0x831a8148
	ctx.lr = 0x82FCDC38;
	sub_831A8130(ctx, base);
	// 82FCDC38: DBE1FF90  stfd f31, -0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-112 as u32), ctx.f[31].u64 ) };
	// 82FCDC3C: 9421FF40  stwu r1, -0xc0(r1)
	ea = ctx.r[1].u32.wrapping_add(-192 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCDC40: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FCDC44: 82AD0000  lwz r21, 0(r13)
	ctx.r[21].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDC48: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82FCDC4C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCDC50: 3AC00014  li r22, 0x14
	ctx.r[22].s64 = 20;
	// 82FCDC54: 3B5D0001  addi r26, r29, 1
	ctx.r[26].s64 = ctx.r[29].s64 + 1;
	// 82FCDC58: 7D7DFA14  add r11, r29, r31
	ctx.r[11].u64 = ctx.r[29].u64 + ctx.r[31].u64;
	// 82FCDC5C: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDC60: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 82FCDC64: 7C741B78  mr r20, r3
	ctx.r[20].u64 = ctx.r[3].u64;
	// 82FCDC68: 7C76A82E  lwzx r3, r22, r21
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[21].u32)) } as u64;
	// 82FCDC6C: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 82FCDC70: 7CFE3B78  mr r30, r7
	ctx.r[30].u64 = ctx.r[7].u64;
	// 82FCDC74: 7D1C4378  mr r28, r8
	ctx.r[28].u64 = ctx.r[8].u64;
	// 82FCDC78: 3B2B0001  addi r25, r11, 1
	ctx.r[25].s64 = ctx.r[11].s64 + 1;
	// 82FCDC7C: 4BED2AB5  bl 0x82ea0730
	ctx.lr = 0x82FCDC80;
	sub_82EA0730(ctx, base);
	// 82FCDC80: 7C781B78  mr r24, r3
	ctx.r[24].u64 = ctx.r[3].u64;
	// 82FCDC84: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 82FCDC88: 40990024  ble cr6, 0x82fcdcac
	if !ctx.cr[6].gt {
	pc = 0x82FCDCAC; continue 'dispatch;
	}
	// 82FCDC8C: 7F0BC378  mr r11, r24
	ctx.r[11].u64 = ctx.r[24].u64;
	// 82FCDC90: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCDC94: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 82FCDC98: 419A0014  beq cr6, 0x82fcdcac
	if ctx.cr[6].eq {
	pc = 0x82FCDCAC; continue 'dispatch;
	}
	// 82FCDC9C: 7F4903A6  mtctr r26
	ctx.ctr.u64 = ctx.r[26].u64;
	// 82FCDCA0: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 82FCDCA4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCDCA8: 4200FFF8  bdnz 0x82fcdca0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCDCA0; continue 'dispatch;
	}
	// 82FCDCAC: 3AE00001  li r23, 1
	ctx.r[23].s64 = 1;
	// 82FCDCB0: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCDCB4: 41980074  blt cr6, 0x82fcdd28
	if ctx.cr[6].lt {
	pc = 0x82FCDD28; continue 'dispatch;
	}
	// 82FCDCB8: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 82FCDCBC: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82FCDCC0: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDCC4: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 82FCDCC8: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCDCCC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FCDCD0: 7C255C2E  lfsx f1, r5, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCDCD4: 4BFFA5C5  bl 0x82fc8298
	ctx.lr = 0x82FCDCD8;
	sub_82FC8298(ctx, base);
	// 82FCDCD8: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDCDC: 546A103A  slwi r10, r3, 2
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCDCE0: 7F03C800  cmpw cr6, r3, r25
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCDCE4: 7C0A5C2E  lfsx f0, r10, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDCE8: 7F2ACB78  mr r10, r25
	ctx.r[10].u64 = ctx.r[25].u64;
	// 82FCDCEC: EC00F82A  fadds f0, f0, f31
	ctx.f[0].f64 = ((ctx.f[0].f64 + ctx.f[31].f64) as f32) as f64;
	// 82FCDCF0: 419A0008  beq cr6, 0x82fcdcf8
	if ctx.cr[6].eq {
	pc = 0x82FCDCF8; continue 'dispatch;
	}
	// 82FCDCF4: 39430001  addi r10, r3, 1
	ctx.r[10].s64 = ctx.r[3].s64 + 1;
	// 82FCDCF8: FF010000  fcmpu cr6, f1, f0
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[0].f64);
	// 82FCDCFC: 41980020  blt cr6, 0x82fcdd1c
	if ctx.cr[6].lt {
	pc = 0x82FCDD1C; continue 'dispatch;
	}
	// 82FCDD00: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCDD04: 7C0A5C2E  lfsx f0, r10, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDD08: EDA0F828  fsubs f13, f0, f31
	ctx.f[13].f64 = (((ctx.f[0].f64 - ctx.f[31].f64) as f32) as f64);
	// 82FCDD0C: FF016800  fcmpu cr6, f1, f13
	ctx.cr[6].compare_f64(ctx.f[1].f64, ctx.f[13].f64);
	// 82FCDD10: 4199000C  bgt cr6, 0x82fcdd1c
	if ctx.cr[6].gt {
	pc = 0x82FCDD1C; continue 'dispatch;
	}
	// 82FCDD14: 7D7FC050  subf r11, r31, r24
	ctx.r[11].s64 = ctx.r[24].s64 - ctx.r[31].s64;
	// 82FCDD18: 7EEB19AE  stbx r23, r11, r3
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), ctx.r[23].u8) };
	// 82FCDD1C: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCDD20: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 82FCDD24: 4082FF9C  bne 0x82fcdcc0
	if !ctx.cr[0].eq {
	pc = 0x82FCDCC0; continue 'dispatch;
	}
	// 82FCDD28: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FCDD2C: 2F1D0000  cmpwi cr6, r29, 0
	ctx.cr[6].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 82FCDD30: 41980068  blt cr6, 0x82fcdd98
	if ctx.cr[6].lt {
	pc = 0x82FCDD98; continue 'dispatch;
	}
	// 82FCDD34: 7F09C378  mr r9, r24
	ctx.r[9].u64 = ctx.r[24].u64;
	// 82FCDD38: 57EA103A  slwi r10, r31, 2
	ctx.r[10].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCDD3C: 7CF8F850  subf r7, r24, r31
	ctx.r[7].s64 = ctx.r[31].s64 - ctx.r[24].s64;
	// 82FCDD40: 7D674A14  add r11, r7, r9
	ctx.r[11].u64 = ctx.r[7].u64 + ctx.r[9].u64;
	// 82FCDD44: 7F0BC800  cmpw cr6, r11, r25
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[25].s32, &mut ctx.xer);
	// 82FCDD48: 419A0020  beq cr6, 0x82fcdd68
	if ctx.cr[6].eq {
	pc = 0x82FCDD68; continue 'dispatch;
	}
	// 82FCDD4C: 817B0000  lwz r11, 0(r27)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDD50: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCDD54: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDD58: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCDD5C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCDD60: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCDD64: 419A0008  beq cr6, 0x82fcdd6c
	if ctx.cr[6].eq {
	pc = 0x82FCDD6C; continue 'dispatch;
	}
	// 82FCDD68: 7EEBBB78  mr r11, r23
	ctx.r[11].u64 = ctx.r[23].u64;
	// 82FCDD6C: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCDD70: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCDD74: 419A0010  beq cr6, 0x82fcdd84
	if ctx.cr[6].eq {
	pc = 0x82FCDD84; continue 'dispatch;
	}
	// 82FCDD78: 89690000  lbz r11, 0(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDD7C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FCDD80: 419A004C  beq cr6, 0x82fcddcc
	if ctx.cr[6].eq {
	pc = 0x82FCDDCC; continue 'dispatch;
	}
	// 82FCDD84: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82FCDD88: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCDD8C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCDD90: 7F08E800  cmpw cr6, r8, r29
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCDD94: 4099FFAC  ble cr6, 0x82fcdd40
	if !ctx.cr[6].gt {
	pc = 0x82FCDD40; continue 'dispatch;
	}
	// 82FCDD98: 9AF40000  stb r23, 0(r20)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[23].u8 ) };
	// 82FCDD9C: 574B0000  rlwinm r11, r26, 0, 0, 0
	ctx.r[11].u64 = ctx.r[26].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCDDA0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCDDA4: 409A0018  bne cr6, 0x82fcddbc
	if !ctx.cr[6].eq {
	pc = 0x82FCDDBC; continue 'dispatch;
	}
	// 82FCDDA8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCDDAC: 7C76A82E  lwzx r3, r22, r21
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[22].u32.wrapping_add(ctx.r[21].u32)) } as u64;
	// 82FCDDB0: 574500BE  clrlwi r5, r26, 2
	ctx.r[5].u64 = ctx.r[26].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCDDB4: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 82FCDDB8: 4BED29F9  bl 0x82ea07b0
	ctx.lr = 0x82FCDDBC;
	sub_82EA07B0(ctx, base);
	// 82FCDDBC: 7E83A378  mr r3, r20
	ctx.r[3].u64 = ctx.r[20].u64;
	// 82FCDDC0: 382100C0  addi r1, r1, 0xc0
	ctx.r[1].s64 = ctx.r[1].s64 + 192;
	// 82FCDDC4: CBE1FF90  lfd f31, -0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-112 as u32) ) };
	// 82FCDDC8: 481DA3D0  b 0x831a8198
	sub_831A8180(ctx, base);
	return;
	// 82FCDDCC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCDDD0: 99540000  stb r10, 0(r20)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[20].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 82FCDDD4: 4BFFFFC8  b 0x82fcdd9c
	pc = 0x82FCDD9C; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCDDD8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCDDD8 size=1876
    let mut pc: u32 = 0x82FCDDD8;
    'dispatch: loop {
        match pc {
            0x82FCDDD8 => {
    //   block [0x82FCDDD8..0x82FCE52C)
	// 82FCDDD8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCDDDC: 481DA355  bl 0x831a8130
	ctx.lr = 0x82FCDDE0;
	sub_831A8130(ctx, base);
	// 82FCDDE0: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 82FCDDE4: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 82FCDDE8: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 82FCDDEC: 9421FEA0  stwu r1, -0x160(r1)
	ea = ctx.r[1].u32.wrapping_add(-352 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCDDF0: 7C701B78  mr r16, r3
	ctx.r[16].u64 = ctx.r[3].u64;
	// 82FCDDF4: 81CD0000  lwz r14, 0(r13)
	ctx.r[14].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDDF8: 7C962378  mr r22, r4
	ctx.r[22].u64 = ctx.r[4].u64;
	// 82FCDDFC: 9101019C  stw r8, 0x19c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(412 as u32), ctx.r[8].u32 ) };
	// 82FCDE00: 7D344B78  mr r20, r9
	ctx.r[20].u64 = ctx.r[9].u64;
	// 82FCDE04: FFA00890  fmr f29, f1
	ctx.f[29].f64 = ctx.f[1].f64;
	// 82FCDE08: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FCDE0C: 7CB72B78  mr r23, r5
	ctx.r[23].u64 = ctx.r[5].u64;
	// 82FCDE10: 81700000  lwz r11, 0(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDE14: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 82FCDE18: 7CFF3B78  mr r31, r7
	ctx.r[31].u64 = ctx.r[7].u64;
	// 82FCDE1C: 7D4BB214  add r10, r11, r22
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 82FCDE20: 9361018C  stw r27, 0x18c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(396 as u32), ctx.r[27].u32 ) };
	// 82FCDE24: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDE28: 7C69702E  lwzx r3, r9, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCDE2C: 3A4A0001  addi r18, r10, 1
	ctx.r[18].s64 = ctx.r[10].s64 + 1;
	// 82FCDE30: 93E10194  stw r31, 0x194(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(404 as u32), ctx.r[31].u32 ) };
	// 82FCDE34: 91610068  stw r11, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[11].u32 ) };
	// 82FCDE38: 3BD20001  addi r30, r18, 1
	ctx.r[30].s64 = ctx.r[18].s64 + 1;
	// 82FCDE3C: 57C4103A  slwi r4, r30, 2
	ctx.r[4].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCDE40: 93C10060  stw r30, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u32 ) };
	// 82FCDE44: 4BED28ED  bl 0x82ea0730
	ctx.lr = 0x82FCDE48;
	sub_82EA0730(ctx, base);
	// 82FCDE48: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FCDE4C: 93C10074  stw r30, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[30].u32 ) };
	// 82FCDE50: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCDE54: 93810070  stw r28, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[28].u32 ) };
	// 82FCDE58: 93C10078  stw r30, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[30].u32 ) };
	// 82FCDE5C: 40990028  ble cr6, 0x82fcde84
	if !ctx.cr[6].gt {
	pc = 0x82FCDE84; continue 'dispatch;
	}
	// 82FCDE60: 3D407F7F  lis r10, 0x7f7f
	ctx.r[10].s64 = 2139029504;
	// 82FCDE64: 7F8BE378  mr r11, r28
	ctx.r[11].u64 = ctx.r[28].u64;
	// 82FCDE68: 614AFFEE  ori r10, r10, 0xffee
	ctx.r[10].u64 = ctx.r[10].u64 | 65518;
	// 82FCDE6C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82FCDE70: 419A0014  beq cr6, 0x82fcde84
	if ctx.cr[6].eq {
	pc = 0x82FCDE84; continue 'dispatch;
	}
	// 82FCDE74: 7FC903A6  mtctr r30
	ctx.ctr.u64 = ctx.r[30].u64;
	// 82FCDE78: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCDE7C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCDE80: 4200FFF8  bdnz 0x82fcde78
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCDE78; continue 'dispatch;
	}
	// 82FCDE84: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCDE88: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCDE8C: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDE90: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCDE94: 93E10064  stw r31, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[31].u32 ) };
	// 82FCDE98: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCDE9C: 4BED2895  bl 0x82ea0730
	ctx.lr = 0x82FCDEA0;
	sub_82EA0730(ctx, base);
	// 82FCDEA0: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FCDEA4: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCDEA8: 91610080  stw r11, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 82FCDEAC: 40990020  ble cr6, 0x82fcdecc
	if !ctx.cr[6].gt {
	pc = 0x82FCDECC; continue 'dispatch;
	}
	// 82FCDEB0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCDEB4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82FCDEB8: 419A0014  beq cr6, 0x82fcdecc
	if ctx.cr[6].eq {
	pc = 0x82FCDECC; continue 'dispatch;
	}
	// 82FCDEBC: 7FE903A6  mtctr r31
	ctx.ctr.u64 = ctx.r[31].u64;
	// 82FCDEC0: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCDEC4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCDEC8: 4200FFF8  bdnz 0x82fcdec0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCDEC0; continue 'dispatch;
	}
	// 82FCDECC: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCDED0: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDED4: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCDED8: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCDEDC: 4BED2855  bl 0x82ea0730
	ctx.lr = 0x82FCDEE0;
	sub_82EA0730(ctx, base);
	// 82FCDEE0: 7C731B78  mr r19, r3
	ctx.r[19].u64 = ctx.r[3].u64;
	// 82FCDEE4: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCDEE8: 40990024  ble cr6, 0x82fcdf0c
	if !ctx.cr[6].gt {
	pc = 0x82FCDF0C; continue 'dispatch;
	}
	// 82FCDEEC: 7E6B9B78  mr r11, r19
	ctx.r[11].u64 = ctx.r[19].u64;
	// 82FCDEF0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCDEF4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82FCDEF8: 419A0014  beq cr6, 0x82fcdf0c
	if ctx.cr[6].eq {
	pc = 0x82FCDF0C; continue 'dispatch;
	}
	// 82FCDEFC: 7FE903A6  mtctr r31
	ctx.ctr.u64 = ctx.r[31].u64;
	// 82FCDF00: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCDF04: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCDF08: 4200FFF8  bdnz 0x82fcdf00
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCDF00; continue 'dispatch;
	}
	// 82FCDF0C: 3BA00014  li r29, 0x14
	ctx.r[29].s64 = 20;
	// 82FCDF10: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDF14: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCDF18: 7C7D702E  lwzx r3, r29, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCDF1C: 4BED2815  bl 0x82ea0730
	ctx.lr = 0x82FCDF20;
	sub_82EA0730(ctx, base);
	// 82FCDF20: 7D7D702E  lwzx r11, r29, r14
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCDF24: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCDF28: 906100A0  stw r3, 0xa0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[3].u32 ) };
	// 82FCDF2C: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCDF30: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FCDF34: 4BED27FD  bl 0x82ea0730
	ctx.lr = 0x82FCDF38;
	sub_82EA0730(ctx, base);
	// 82FCDF38: 7D769050  subf r11, r22, r18
	ctx.r[11].s64 = ctx.r[18].s64 - ctx.r[22].s64;
	// 82FCDF3C: 39160001  addi r8, r22, 1
	ctx.r[8].s64 = ctx.r[22].s64 + 1;
	// 82FCDF40: 90610090  stw r3, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[3].u32 ) };
	// 82FCDF44: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 82FCDF48: 80700000  lwz r3, 0(r16)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDF4C: 38E10070  addi r7, r1, 0x70
	ctx.r[7].s64 = ctx.r[1].s64 + 112;
	// 82FCDF50: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 82FCDF54: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCDF58: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FCDF5C: 4BFFFB7D  bl 0x82fcdad8
	ctx.lr = 0x82FCDF60;
	sub_82FCDAD8(ctx, base);
	// 82FCDF60: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCDF64: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82FCDF68: 4BFFBA99  bl 0x82fc9a00
	ctx.lr = 0x82FCDF6C;
	sub_82FC9A00(ctx, base);
	// 82FCDF6C: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCDF70: 7E449378  mr r4, r18
	ctx.r[4].u64 = ctx.r[18].u64;
	// 82FCDF74: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 82FCDF78: 4BFFB851  bl 0x82fc97c8
	ctx.lr = 0x82FCDF7C;
	sub_82FC97C8(ctx, base);
	// 82FCDF7C: 5758103A  slwi r24, r26, 2
	ctx.r[24].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 82FCDF80: 3DE08213  lis r15, -0x7ded
	ctx.r[15].s64 = -2112684032;
	// 82FCDF84: 7F38E214  add r25, r24, r28
	ctx.r[25].u64 = ctx.r[24].u64 + ctx.r[28].u64;
	// 82FCDF88: 7C751B78  mr r21, r3
	ctx.r[21].u64 = ctx.r[3].u64;
	// 82FCDF8C: 7C18E42E  lfsx f0, r24, r28
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[28].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDF90: C1AF6900  lfs f13, 0x6900(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(26880 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCDF94: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCDF98: 419A04B4  beq cr6, 0x82fce44c
	if ctx.cr[6].eq {
	pc = 0x82FCE44C; continue 'dispatch;
	}
	// 82FCDF9C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCDFA0: 82210060  lwz r17, 0x60(r1)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCDFA4: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82FCDFA8: C3CB08A8  lfs f30, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCDFAC: C3EA08A4  lfs f31, 0x8a4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FCDFB0: 7D75B214  add r11, r21, r22
	ctx.r[11].u64 = ctx.r[21].u64 + ctx.r[22].u64;
	// 82FCDFB4: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 82FCDFB8: 7D490E70  srawi r9, r10, 1
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[10].s32 >> 1) as i64;
	// 82FCDFBC: 7D090194  addze r8, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[8].s64 = tmp.s64;
	// 82FCDFC0: 5507083C  slwi r7, r8, 1
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCDFC4: 7CC75051  subf. r6, r7, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82FCDFC8: 40820018  bne 0x82fcdfe0
	if !ctx.cr[0].eq {
	pc = 0x82FCDFE0; continue 'dispatch;
	}
	// 82FCDFCC: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FCDFD0: FDA0F890  fmr f13, f31
	ctx.f[13].f64 = ctx.f[31].f64;
	// 82FCDFD4: 7D4B0194  addze r10, r11
	tmp.s64 = ctx.r[11].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[11].u32);
	ctx.r[10].s64 = tmp.s64;
	// 82FCDFD8: 7CCAD050  subf r6, r10, r26
	ctx.r[6].s64 = ctx.r[26].s64 - ctx.r[10].s64;
	// 82FCDFDC: 4800004C  b 0x82fce028
	pc = 0x82FCE028; continue 'dispatch;
	// 82FCDFE0: 39760001  addi r11, r22, 1
	ctx.r[11].s64 = ctx.r[22].s64 + 1;
	// 82FCDFE4: 81370000  lwz r9, 0(r23)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCDFE8: 7D0BAA14  add r8, r11, r21
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[21].u64;
	// 82FCDFEC: 7D070E70  srawi r7, r8, 1
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[8].s32 >> 1) as i64;
	// 82FCDFF0: 7C09C42E  lfsx f0, r9, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCDFF4: 7D670194  addze r11, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[11].s64 = tmp.s64;
	// 82FCDFF8: 7D6BD050  subf r11, r11, r26
	ctx.r[11].s64 = ctx.r[26].s64 - ctx.r[11].s64;
	// 82FCDFFC: 7D4BB214  add r10, r11, r22
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 82FCE000: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 82FCE004: 38AA0002  addi r5, r10, 2
	ctx.r[5].s64 = ctx.r[10].s64 + 2;
	// 82FCE008: 54C4103A  slwi r4, r6, 2
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCE00C: 54A3103A  slwi r3, r5, 2
	ctx.r[3].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FCE010: 38CB0001  addi r6, r11, 1
	ctx.r[6].s64 = ctx.r[11].s64 + 1;
	// 82FCE014: 7DA44C2E  lfsx f13, r4, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE018: 7D834C2E  lfsx f12, r3, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE01C: ED606828  fsubs f11, f0, f13
	ctx.f[11].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCE020: ED4C6828  fsubs f10, f12, f13
	ctx.f[10].f64 = (((ctx.f[12].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCE024: EDAB5024  fdivs f13, f11, f10
	ctx.f[13].f64 = ((ctx.f[11].f64 / ctx.f[10].f64) as f32) as f64;
	// 82FCE028: 83F70000  lwz r31, 0(r23)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE02C: 54CB103A  slwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCE030: 80A10194  lwz r5, 0x194(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(404 as u32) ) } as u64;
	// 82FCE034: 8081019C  lwz r4, 0x19c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(412 as u32) ) } as u64;
	// 82FCE038: 7C2BFC2E  lfsx f1, r11, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE03C: 4BFFB70D  bl 0x82fc9748
	ctx.lr = 0x82FCE040;
	sub_82FC9748(ctx, base);
	// 82FCE040: 7D66B214  add r11, r6, r22
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[22].u64;
	// 82FCE044: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FCE048: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 82FCE04C: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCE050: 7C29FC2E  lfsx f1, r9, r31
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE054: 4BFFB6F5  bl 0x82fc9748
	ctx.lr = 0x82FCE058;
	sub_82FC9748(ctx, base);
	// 82FCE058: 3B63FFFF  addi r27, r3, -1
	ctx.r[27].s64 = ctx.r[3].s64 + -1;
	// 82FCE05C: FC80F890  fmr f4, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[4].f64 = ctx.f[31].f64;
	// 82FCE060: 7F1CD800  cmpw cr6, r28, r27
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[27].s32, &mut ctx.xer);
	// 82FCE064: 41990070  bgt cr6, 0x82fce0d4
	if ctx.cr[6].gt {
	pc = 0x82FCE0D4; continue 'dispatch;
	}
	// 82FCE068: 81410080  lwz r10, 0x80(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCE06C: 7D7CD850  subf r11, r28, r27
	ctx.r[11].s64 = ctx.r[27].s64 - ctx.r[28].s64;
	// 82FCE070: EC7E6828  fsubs f3, f30, f13
	ctx.f[3].f64 = (((ctx.f[30].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCE074: 579F103A  slwi r31, r28, 2
	ctx.r[31].u32 = ctx.r[28].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FCE078: 7FB35050  subf r29, r19, r10
	ctx.r[29].s64 = ctx.r[10].s64 - ctx.r[19].s64;
	// 82FCE07C: 3BCB0001  addi r30, r11, 1
	ctx.r[30].s64 = ctx.r[11].s64 + 1;
	// 82FCE080: 8161019C  lwz r11, 0x19c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(412 as u32) ) } as u64;
	// 82FCE084: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCE088: 7E449378  mr r4, r18
	ctx.r[4].u64 = ctx.r[18].u64;
	// 82FCE08C: 7EC3B378  mr r3, r22
	ctx.r[3].u64 = ctx.r[22].u64;
	// 82FCE090: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE094: 7C2AFC2E  lfsx f1, r10, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE098: 4BFFAB71  bl 0x82fc8c08
	ctx.lr = 0x82FCE09C;
	sub_82FC8C08(ctx, base);
	// 82FCE09C: EC0100F2  fmuls f0, f1, f3
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[3].f64) as f32) as f64);
	// 82FCE0A0: 7D7F9A14  add r11, r31, r19
	ctx.r[11].u64 = ctx.r[31].u64 + ctx.r[19].u64;
	// 82FCE0A4: C1B90000  lfs f13, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE0A8: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCE0AC: ED800372  fmuls f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64) as f32) as f64);
	// 82FCE0B0: 7D9D5D2E  stfsx f12, r29, r11
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32), tmp.u32) };
	// 82FCE0B4: 81340000  lwz r9, 0(r20)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE0B8: 7D69FC2E  lfsx f11, r9, r31
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[31].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCE0BC: ED4B602A  fadds f10, f11, f12
	ctx.f[10].f64 = ((ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64;
	// 82FCE0C0: ED245028  fsubs f9, f4, f10
	ctx.f[9].f64 = (((ctx.f[4].f64 - ctx.f[10].f64) as f32) as f64);
	// 82FCE0C4: 7D5F9D2E  stfsx f10, r31, r19
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[19].u32), tmp.u32) };
	// 82FCE0C8: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 82FCE0CC: FC89512E  fsel f4, f9, f4, f10
	ctx.f[4].f64 = if ctx.f[9].f64 >= 0.0 { ctx.f[4].f64 } else { ctx.f[10].f64 };
	// 82FCE0D0: 4082FFB0  bne 0x82fce080
	if !ctx.cr[0].eq {
	pc = 0x82FCE080; continue 'dispatch;
	}
	// 82FCE0D4: FF04E800  fcmpu cr6, f4, f29
	ctx.cr[6].compare_f64(ctx.f[4].f64, ctx.f[29].f64);
	// 82FCE0D8: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCE0DC: 40990008  ble cr6, 0x82fce0e4
	if !ctx.cr[6].gt {
	pc = 0x82FCE0E4; continue 'dispatch;
	}
	// 82FCE0E0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCE0E4: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCE0E8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE0EC: 419A02F4  beq cr6, 0x82fce3e0
	if ctx.cr[6].eq {
	pc = 0x82FCE3E0; continue 'dispatch;
	}
	// 82FCE0F0: 81340004  lwz r9, 4(r20)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE0F4: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FCE0F8: 3FC08000  lis r30, -0x8000
	ctx.r[30].s64 = -2147483648;
	// 82FCE0FC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCE100: 40990024  ble cr6, 0x82fce124
	if !ctx.cr[6].gt {
	pc = 0x82FCE124; continue 'dispatch;
	}
	// 82FCE104: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE108: 5524103A  slwi r4, r9, 2
	ctx.r[4].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCE10C: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCE110: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE114: 4BED261D  bl 0x82ea0730
	ctx.lr = 0x82FCE118;
	sub_82EA0730(ctx, base);
	// 82FCE118: 81340004  lwz r9, 4(r20)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE11C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCE120: 7D3E4B78  mr r30, r9
	ctx.r[30].u64 = ctx.r[9].u64;
	// 82FCE124: 80D40000  lwz r6, 0(r20)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE128: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FCE12C: 2F090004  cmpwi cr6, r9, 4
	ctx.cr[6].compare_i32(ctx.r[9].s32, 4, &mut ctx.xer);
	// 82FCE130: 41980050  blt cr6, 0x82fce180
	if ctx.cr[6].lt {
	pc = 0x82FCE180; continue 'dispatch;
	}
	// 82FCE134: 3969FFFC  addi r11, r9, -4
	ctx.r[11].s64 = ctx.r[9].s64 + -4;
	// 82FCE138: 3946000C  addi r10, r6, 0xc
	ctx.r[10].s64 = ctx.r[6].s64 + 12;
	// 82FCE13C: 5568F0BE  srwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCE140: 397F0004  addi r11, r31, 4
	ctx.r[11].s64 = ctx.r[31].s64 + 4;
	// 82FCE144: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82FCE148: 7CBF3050  subf r5, r31, r6
	ctx.r[5].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 82FCE14C: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCE150: C00AFFF4  lfs f0, -0xc(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE154: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCE158: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCE15C: 7DA55C2E  lfsx f13, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE160: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE164: C18AFFFC  lfs f12, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE168: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCE16C: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCE170: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCE174: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCE178: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCE17C: 4082FFD4  bne 0x82fce150
	if !ctx.cr[0].eq {
	pc = 0x82FCE150; continue 'dispatch;
	}
	// 82FCE180: 7F074800  cmpw cr6, r7, r9
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FCE184: 40980028  bge cr6, 0x82fce1ac
	if !ctx.cr[6].lt {
	pc = 0x82FCE1AC; continue 'dispatch;
	}
	// 82FCE188: 54EB103A  slwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCE18C: 7D1F3050  subf r8, r31, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[31].s64;
	// 82FCE190: 7D6BFA14  add r11, r11, r31
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FCE194: 7D474850  subf r10, r7, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[7].s64;
	// 82FCE198: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE19C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCE1A0: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE1A4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCE1A8: 4082FFF0  bne 0x82fce198
	if !ctx.cr[0].eq {
	pc = 0x82FCE198; continue 'dispatch;
	}
	// 82FCE1AC: 7D7CD850  subf r11, r28, r27
	ctx.r[11].s64 = ctx.r[27].s64 - ctx.r[28].s64;
	// 82FCE1B0: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCE1B4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCE1B8: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 82FCE1BC: 4198007C  blt cr6, 0x82fce238
	if ctx.cr[6].lt {
	pc = 0x82FCE238; continue 'dispatch;
	}
	// 82FCE1C0: 7D7CD850  subf r11, r28, r27
	ctx.r[11].s64 = ctx.r[27].s64 - ctx.r[28].s64;
	// 82FCE1C4: 395C0002  addi r10, r28, 2
	ctx.r[10].s64 = ctx.r[28].s64 + 2;
	// 82FCE1C8: 390BFFFD  addi r8, r11, -3
	ctx.r[8].s64 = ctx.r[11].s64 + -3;
	// 82FCE1CC: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCE1D0: 550BF0BE  srwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCE1D4: 20D30004  subfic r6, r19, 4
	ctx.xer.ca = ctx.r[19].u32 <= 4 as u32;
	ctx.r[6].s64 = (4 as i64) - ctx.r[19].s64;
	// 82FCE1D8: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 82FCE1DC: 7D699A14  add r11, r9, r19
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[19].u64;
	// 82FCE1E0: 5548103A  slwi r8, r10, 2
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCE1E4: 20B3FFF8  subfic r5, r19, -8
	ctx.xer.ca = ctx.r[19].u32 <= -8 as u32;
	ctx.r[5].s64 = (-8 as i64) - ctx.r[19].s64;
	// 82FCE1E8: 7C88E214  add r4, r8, r28
	ctx.r[4].u64 = ctx.r[8].u64 + ctx.r[28].u64;
	// 82FCE1EC: 80F40000  lwz r7, 0(r20)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE1F0: 7D055A14  add r8, r5, r11
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[11].u64;
	// 82FCE1F4: C00BFFF8  lfs f0, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE1F8: 7C665A14  add r3, r6, r11
	ctx.r[3].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 82FCE1FC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCE200: 7C083D2E  stfsx f0, r8, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCE204: 80F40000  lwz r7, 0(r20)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE208: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE20C: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82FCE210: D1A80004  stfs f13, 4(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCE214: 80F40000  lwz r7, 0(r20)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE218: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE21C: 7D893D2E  stfsx f12, r9, r7
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCE220: 81140000  lwz r8, 0(r20)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE224: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCE228: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FCE22C: 7D63452E  stfsx f11, r3, r8
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[3].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCE230: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCE234: 4082FFB8  bne 0x82fce1ec
	if !ctx.cr[0].eq {
	pc = 0x82FCE1EC; continue 'dispatch;
	}
	// 82FCE238: 7F04D800  cmpw cr6, r4, r27
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[27].s32, &mut ctx.xer);
	// 82FCE23C: 41990028  bgt cr6, 0x82fce264
	if ctx.cr[6].gt {
	pc = 0x82FCE264; continue 'dispatch;
	}
	// 82FCE240: 7D44D850  subf r10, r4, r27
	ctx.r[10].s64 = ctx.r[27].s64 - ctx.r[4].s64;
	// 82FCE244: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCE248: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCE24C: 81340000  lwz r9, 0(r20)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE250: 7C0B9C2E  lfsx f0, r11, r19
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[19].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE254: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCE258: 7C0B4D2E  stfsx f0, r11, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCE25C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCE260: 4082FFEC  bne 0x82fce24c
	if !ctx.cr[0].eq {
	pc = 0x82FCE24C; continue 'dispatch;
	}
	// 82FCE264: 81770000  lwz r11, 0(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE268: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FCE26C: 83A1018C  lwz r29, 0x18c(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(396 as u32) ) } as u64;
	// 82FCE270: 7EA9AB78  mr r9, r21
	ctx.r[9].u64 = ctx.r[21].u64;
	// 82FCE274: 7F48D378  mr r8, r26
	ctx.r[8].u64 = ctx.r[26].u64;
	// 82FCE278: 80700000  lwz r3, 0(r16)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE27C: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82FCE280: C04F6900  lfs f2, 0x6900(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(26880 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCE284: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCE288: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FCE28C: 7C2BC42E  lfsx f1, r11, r24
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[24].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE290: 4BFFC991  bl 0x82fcac20
	ctx.lr = 0x82FCE294;
	sub_82FCAC20(ctx, base);
	// 82FCE294: 81700000  lwz r11, 0(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE298: 39560001  addi r10, r22, 1
	ctx.r[10].s64 = ctx.r[22].s64 + 1;
	// 82FCE29C: 3A31FFFF  addi r17, r17, -1
	ctx.r[17].s64 = ctx.r[17].s64 + -1;
	// 82FCE2A0: 5549083C  slwi r9, r10, 1
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCE2A4: 390BFFFF  addi r8, r11, -1
	ctx.r[8].s64 = ctx.r[11].s64 + -1;
	// 82FCE2A8: 3A52FFFF  addi r18, r18, -1
	ctx.r[18].s64 = ctx.r[18].s64 + -1;
	// 82FCE2AC: 7F114800  cmpw cr6, r17, r9
	ctx.cr[6].compare_i32(ctx.r[17].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FCE2B0: 91100000  stw r8, 0(r16)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[16].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCE2B4: 40990174  ble cr6, 0x82fce428
	if !ctx.cr[6].gt {
	pc = 0x82FCE428; continue 'dispatch;
	}
	// 82FCE2B8: 81610074  lwz r11, 0x74(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 82FCE2BC: 394BFFFF  addi r10, r11, -1
	ctx.r[10].s64 = ctx.r[11].s64 + -1;
	// 82FCE2C0: 91410074  stw r10, 0x74(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[10].u32 ) };
	// 82FCE2C4: 7F1A5000  cmpw cr6, r26, r10
	ctx.cr[6].compare_i32(ctx.r[26].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FCE2C8: 40980020  bge cr6, 0x82fce2e8
	if !ctx.cr[6].lt {
	pc = 0x82FCE2E8; continue 'dispatch;
	}
	// 82FCE2CC: 7F2BCB78  mr r11, r25
	ctx.r[11].u64 = ctx.r[25].u64;
	// 82FCE2D0: 7D5A5050  subf r10, r26, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[26].s64;
	// 82FCE2D4: C00B0004  lfs f0, 4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE2D8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCE2DC: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE2E0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCE2E4: 4082FFF0  bne 0x82fce2d4
	if !ctx.cr[0].eq {
	pc = 0x82FCE2D4; continue 'dispatch;
	}
	// 82FCE2E8: 7D76D050  subf r11, r22, r26
	ctx.r[11].s64 = ctx.r[26].s64 - ctx.r[22].s64;
	// 82FCE2EC: 39560001  addi r10, r22, 1
	ctx.r[10].s64 = ctx.r[22].s64 + 1;
	// 82FCE2F0: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FCE2F4: 40990008  ble cr6, 0x82fce2fc
	if !ctx.cr[6].gt {
	pc = 0x82FCE2FC; continue 'dispatch;
	}
	// 82FCE2F8: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 82FCE2FC: 7D75D050  subf r11, r21, r26
	ctx.r[11].s64 = ctx.r[26].s64 - ctx.r[21].s64;
	// 82FCE300: 80700000  lwz r3, 0(r16)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE304: 7D6BB214  add r11, r11, r22
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 82FCE308: 7F0B1800  cmpw cr6, r11, r3
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[3].s32, &mut ctx.xer);
	// 82FCE30C: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 82FCE310: 41980008  blt cr6, 0x82fce318
	if ctx.cr[6].lt {
	pc = 0x82FCE318; continue 'dispatch;
	}
	// 82FCE314: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FCE318: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 82FCE31C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCE320: 7F089000  cmpw cr6, r8, r18
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[18].s32, &mut ctx.xer);
	// 82FCE324: 419A0020  beq cr6, 0x82fce344
	if ctx.cr[6].eq {
	pc = 0x82FCE344; continue 'dispatch;
	}
	// 82FCE328: 81770000  lwz r11, 0(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE32C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCE330: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE334: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE338: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCE33C: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCE340: 419A0008  beq cr6, 0x82fce348
	if ctx.cr[6].eq {
	pc = 0x82FCE348; continue 'dispatch;
	}
	// 82FCE344: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCE348: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCE34C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE350: 409A0010  bne cr6, 0x82fce360
	if !ctx.cr[6].eq {
	pc = 0x82FCE360; continue 'dispatch;
	}
	// 82FCE354: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82FCE358: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCE35C: 4BFFFFC4  b 0x82fce320
	pc = 0x82FCE320; continue 'dispatch;
	// 82FCE360: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCE364: 7F099000  cmpw cr6, r9, r18
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[18].s32, &mut ctx.xer);
	// 82FCE368: 419A0020  beq cr6, 0x82fce388
	if ctx.cr[6].eq {
	pc = 0x82FCE388; continue 'dispatch;
	}
	// 82FCE36C: 81770000  lwz r11, 0(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE370: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FCE374: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE378: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE37C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCE380: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 82FCE384: 419A0008  beq cr6, 0x82fce38c
	if ctx.cr[6].eq {
	pc = 0x82FCE38C; continue 'dispatch;
	}
	// 82FCE388: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FCE38C: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 82FCE390: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE394: 409A0010  bne cr6, 0x82fce3a4
	if !ctx.cr[6].eq {
	pc = 0x82FCE3A4; continue 'dispatch;
	}
	// 82FCE398: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCE39C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCE3A0: 4BFFFFC4  b 0x82fce364
	pc = 0x82FCE364; continue 'dispatch;
	// 82FCE3A4: 38E10070  addi r7, r1, 0x70
	ctx.r[7].s64 = ctx.r[1].s64 + 112;
	// 82FCE3A8: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 82FCE3AC: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCE3B0: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FCE3B4: 4BFFF725  bl 0x82fcdad8
	ctx.lr = 0x82FCE3B8;
	sub_82FCDAD8(ctx, base);
	// 82FCE3B8: 57CB0000  rlwinm r11, r30, 0, 0, 0
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE3BC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE3C0: 409A0028  bne cr6, 0x82fce3e8
	if !ctx.cr[6].eq {
	pc = 0x82FCE3E8; continue 'dispatch;
	}
	// 82FCE3C4: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE3C8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE3CC: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE3D0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCE3D4: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE3D8: 4BED23D9  bl 0x82ea07b0
	ctx.lr = 0x82FCE3DC;
	sub_82EA07B0(ctx, base);
	// 82FCE3DC: 4800000C  b 0x82fce3e8
	pc = 0x82FCE3E8; continue 'dispatch;
	// 82FCE3E0: C00F6900  lfs f0, 0x6900(r15)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(26880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE3E4: D0190000  stfs f0, 0(r25)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE3E8: 7E248B78  mr r4, r17
	ctx.r[4].u64 = ctx.r[17].u64;
	// 82FCE3EC: 38610070  addi r3, r1, 0x70
	ctx.r[3].s64 = ctx.r[1].s64 + 112;
	// 82FCE3F0: 4BFFB611  bl 0x82fc9a00
	ctx.lr = 0x82FCE3F4;
	sub_82FC9A00(ctx, base);
	// 82FCE3F4: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCE3F8: 7E449378  mr r4, r18
	ctx.r[4].u64 = ctx.r[18].u64;
	// 82FCE3FC: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 82FCE400: 4BFFB3C9  bl 0x82fc97c8
	ctx.lr = 0x82FCE404;
	sub_82FC97C8(ctx, base);
	// 82FCE404: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCE408: 5758103A  slwi r24, r26, 2
	ctx.r[24].u32 = ctx.r[26].u32.wrapping_shl(2);
	ctx.r[24].u64 = ctx.r[24].u32 as u64;
	// 82FCE40C: C00F6900  lfs f0, 0x6900(r15)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(26880 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE410: 7C751B78  mr r21, r3
	ctx.r[21].u64 = ctx.r[3].u64;
	// 82FCE414: 7F385A14  add r25, r24, r11
	ctx.r[25].u64 = ctx.r[24].u64 + ctx.r[11].u64;
	// 82FCE418: C1B90000  lfs f13, 0(r25)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE41C: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 82FCE420: 409AFB90  bne cr6, 0x82fcdfb0
	if !ctx.cr[6].eq {
	pc = 0x82FCDFB0; continue 'dispatch;
	}
	// 82FCE424: 48000028  b 0x82fce44c
	pc = 0x82FCE44C; continue 'dispatch;
	// 82FCE428: 57CB0000  rlwinm r11, r30, 0, 0, 0
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE42C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE430: 409A001C  bne cr6, 0x82fce44c
	if !ctx.cr[6].eq {
	pc = 0x82FCE44C; continue 'dispatch;
	}
	// 82FCE434: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE438: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE43C: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE440: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCE444: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE448: 4BED2369  bl 0x82ea07b0
	ctx.lr = 0x82FCE44C;
	sub_82EA07B0(ctx, base);
	// 82FCE44C: 83C10064  lwz r30, 0x64(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 82FCE450: 81700000  lwz r11, 0(r16)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[16].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE454: 81410068  lwz r10, 0x68(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCE458: 57C90000  rlwinm r9, r30, 0, 0, 0
	ctx.r[9].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE45C: 7FEB5050  subf r31, r11, r10
	ctx.r[31].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 82FCE460: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCE464: 409A001C  bne cr6, 0x82fce480
	if !ctx.cr[6].eq {
	pc = 0x82FCE480; continue 'dispatch;
	}
	// 82FCE468: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE46C: 80810090  lwz r4, 0x90(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCE470: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE474: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE478: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE47C: 4BED2335  bl 0x82ea07b0
	ctx.lr = 0x82FCE480;
	sub_82EA07B0(ctx, base);
	// 82FCE480: 57CB0000  rlwinm r11, r30, 0, 0, 0
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE484: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE488: 409A001C  bne cr6, 0x82fce4a4
	if !ctx.cr[6].eq {
	pc = 0x82FCE4A4; continue 'dispatch;
	}
	// 82FCE48C: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE490: 808100A0  lwz r4, 0xa0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 82FCE494: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE498: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE49C: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE4A0: 4BED2311  bl 0x82ea07b0
	ctx.lr = 0x82FCE4A4;
	sub_82EA07B0(ctx, base);
	// 82FCE4A4: 57CB0000  rlwinm r11, r30, 0, 0, 0
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE4A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE4AC: 409A001C  bne cr6, 0x82fce4c8
	if !ctx.cr[6].eq {
	pc = 0x82FCE4C8; continue 'dispatch;
	}
	// 82FCE4B0: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE4B4: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE4B8: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE4BC: 7E649B78  mr r4, r19
	ctx.r[4].u64 = ctx.r[19].u64;
	// 82FCE4C0: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE4C4: 4BED22ED  bl 0x82ea07b0
	ctx.lr = 0x82FCE4C8;
	sub_82EA07B0(ctx, base);
	// 82FCE4C8: 57CB0000  rlwinm r11, r30, 0, 0, 0
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE4CC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE4D0: 409A001C  bne cr6, 0x82fce4ec
	if !ctx.cr[6].eq {
	pc = 0x82FCE4EC; continue 'dispatch;
	}
	// 82FCE4D4: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE4D8: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCE4DC: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE4E0: 57C5103A  slwi r5, r30, 2
	ctx.r[5].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE4E4: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE4E8: 4BED22C9  bl 0x82ea07b0
	ctx.lr = 0x82FCE4EC;
	sub_82EA07B0(ctx, base);
	// 82FCE4EC: 81410060  lwz r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCE4F0: 554B0000  rlwinm r11, r10, 0, 0, 0
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCE4F4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCE4F8: 409A001C  bne cr6, 0x82fce514
	if !ctx.cr[6].eq {
	pc = 0x82FCE514; continue 'dispatch;
	}
	// 82FCE4FC: 39600014  li r11, 0x14
	ctx.r[11].s64 = 20;
	// 82FCE500: 80810070  lwz r4, 0x70(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCE504: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCE508: 5545103A  slwi r5, r10, 2
	ctx.r[5].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE50C: 7C6B702E  lwzx r3, r11, r14
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[14].u32)) } as u64;
	// 82FCE510: 4BED22A1  bl 0x82ea07b0
	ctx.lr = 0x82FCE514;
	sub_82EA07B0(ctx, base);
	// 82FCE514: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCE518: 38210160  addi r1, r1, 0x160
	ctx.r[1].s64 = ctx.r[1].s64 + 352;
	// 82FCE51C: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 82FCE520: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 82FCE524: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 82FCE528: 481D9C58  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCE530(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCE530 size=2092
    let mut pc: u32 = 0x82FCE530;
    'dispatch: loop {
        match pc {
            0x82FCE530 => {
    //   block [0x82FCE530..0x82FCED5C)
	// 82FCE530: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCE534: 481D9BFD  bl 0x831a8130
	ctx.lr = 0x82FCE538;
	sub_831A8130(ctx, base);
	// 82FCE538: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82FCE53C: 481DA53D  bl 0x831a8a78
	ctx.lr = 0x82FCE540;
	sub_831A8A40(ctx, base);
	// 82FCE540: 9421FE00  stwu r1, -0x200(r1)
	ea = ctx.r[1].u32.wrapping_add(-512 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCE544: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FCE548: FFA00890  fmr f29, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[29].f64 = ctx.f[1].f64;
	// 82FCE54C: 7C982378  mr r24, r4
	ctx.r[24].u64 = ctx.r[4].u64;
	// 82FCE550: FF801090  fmr f28, f2
	ctx.f[28].f64 = ctx.f[2].f64;
	// 82FCE554: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 82FCE558: 93A10214  stw r29, 0x214(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(532 as u32), ctx.r[29].u32 ) };
	// 82FCE55C: 7D124378  mr r18, r8
	ctx.r[18].u64 = ctx.r[8].u64;
	// 82FCE560: 7D394B78  mr r25, r9
	ctx.r[25].u64 = ctx.r[9].u64;
	// 82FCE564: 93C1022C  stw r30, 0x22c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(556 as u32), ctx.r[30].u32 ) };
	// 82FCE568: 7CB72B78  mr r23, r5
	ctx.r[23].u64 = ctx.r[5].u64;
	// 82FCE56C: 7CF63B78  mr r22, r7
	ctx.r[22].u64 = ctx.r[7].u64;
	// 82FCE570: 93210244  stw r25, 0x244(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(580 as u32), ctx.r[25].u32 ) };
	// 82FCE574: 7D555378  mr r21, r10
	ctx.r[21].u64 = ctx.r[10].u64;
	// 82FCE578: 7F189000  cmpw cr6, r24, r18
	ctx.cr[6].compare_i32(ctx.r[24].s32, ctx.r[18].s32, &mut ctx.xer);
	// 82FCE57C: 4099001C  ble cr6, 0x82fce598
	if !ctx.cr[6].gt {
	pc = 0x82FCE598; continue 'dispatch;
	}
	// 82FCE580: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCE584: 997D0000  stb r11, 0(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 82FCE588: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 82FCE58C: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82FCE590: 481DA535  bl 0x831a8ac4
	ctx.lr = 0x82FCE594;
	sub_831A8A8C(ctx, base);
	// 82FCE594: 481D9BEC  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
	// 82FCE598: 39E00000  li r15, 0
	ctx.r[15].s64 = 0;
	// 82FCE59C: 3DC08000  lis r14, -0x8000
	ctx.r[14].s64 = -2147483648;
	// 82FCE5A0: 3B58FFFF  addi r26, r24, -1
	ctx.r[26].s64 = ctx.r[24].s64 + -1;
	// 82FCE5A4: 91E10110  stw r15, 0x110(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(272 as u32), ctx.r[15].u32 ) };
	// 82FCE5A8: 3972FFFF  addi r11, r18, -1
	ctx.r[11].s64 = ctx.r[18].s64 + -1;
	// 82FCE5AC: 91E10114  stw r15, 0x114(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(276 as u32), ctx.r[15].u32 ) };
	// 82FCE5B0: 93410138  stw r26, 0x138(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(312 as u32), ctx.r[26].u32 ) };
	// 82FCE5B4: 3B600001  li r27, 1
	ctx.r[27].s64 = 1;
	// 82FCE5B8: 91C10118  stw r14, 0x118(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(280 as u32), ctx.r[14].u32 ) };
	// 82FCE5BC: 2F120001  cmpwi cr6, r18, 1
	ctx.cr[6].compare_i32(ctx.r[18].s32, 1, &mut ctx.xer);
	// 82FCE5C0: 91E1011C  stw r15, 0x11c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(284 as u32), ctx.r[15].u32 ) };
	// 82FCE5C4: 91E10120  stw r15, 0x120(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(288 as u32), ctx.r[15].u32 ) };
	// 82FCE5C8: 91C10124  stw r14, 0x124(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(292 as u32), ctx.r[14].u32 ) };
	// 82FCE5CC: 91E10128  stw r15, 0x128(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(296 as u32), ctx.r[15].u32 ) };
	// 82FCE5D0: 91E1012C  stw r15, 0x12c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(300 as u32), ctx.r[15].u32 ) };
	// 82FCE5D4: 91C10130  stw r14, 0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[14].u32 ) };
	// 82FCE5D8: 91610134  stw r11, 0x134(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), ctx.r[11].u32 ) };
	// 82FCE5DC: 4099006C  ble cr6, 0x82fce648
	if !ctx.cr[6].gt {
	pc = 0x82FCE648; continue 'dispatch;
	}
	// 82FCE5E0: 3BE00001  li r31, 1
	ctx.r[31].s64 = 1;
	// 82FCE5E4: 2F180001  cmpwi cr6, r24, 1
	ctx.cr[6].compare_i32(ctx.r[24].s32, 1, &mut ctx.xer);
	// 82FCE5E8: 40990054  ble cr6, 0x82fce63c
	if !ctx.cr[6].gt {
	pc = 0x82FCE63C; continue 'dispatch;
	}
	// 82FCE5EC: 7D78BA14  add r11, r24, r23
	ctx.r[11].u64 = ctx.r[24].u64 + ctx.r[23].u64;
	// 82FCE5F0: 577E103A  slwi r30, r27, 2
	ctx.r[30].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 82FCE5F4: 3BAB0001  addi r29, r11, 1
	ctx.r[29].s64 = ctx.r[11].s64 + 1;
	// 82FCE5F8: 3B9BFFFF  addi r28, r27, -1
	ctx.r[28].s64 = ctx.r[27].s64 + -1;
	// 82FCE5FC: 81750000  lwz r11, 0(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE600: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCE604: 7EC5B378  mr r5, r22
	ctx.r[5].u64 = ctx.r[22].u64;
	// 82FCE608: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FCE60C: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 82FCE610: 7C3E5C2E  lfsx f1, r30, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[30].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE614: 4BFFA5F5  bl 0x82fc8c08
	ctx.lr = 0x82FCE618;
	sub_82FC8C08(ctx, base);
	// 82FCE618: 38BFFFFF  addi r5, r31, -1
	ctx.r[5].s64 = ctx.r[31].s64 + -1;
	// 82FCE61C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCE620: 38610110  addi r3, r1, 0x110
	ctx.r[3].s64 = ctx.r[1].s64 + 272;
	// 82FCE624: 480013FD  bl 0x82fcfa20
	ctx.lr = 0x82FCE628;
	sub_82FCFA20(ctx, base);
	// 82FCE628: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FCE62C: 7F1FC000  cmpw cr6, r31, r24
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[24].s32, &mut ctx.xer);
	// 82FCE630: 4198FFCC  blt cr6, 0x82fce5fc
	if ctx.cr[6].lt {
	pc = 0x82FCE5FC; continue 'dispatch;
	}
	// 82FCE634: 83C1022C  lwz r30, 0x22c(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(556 as u32) ) } as u64;
	// 82FCE638: 83A10214  lwz r29, 0x214(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(532 as u32) ) } as u64;
	// 82FCE63C: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 82FCE640: 7F1B9000  cmpw cr6, r27, r18
	ctx.cr[6].compare_i32(ctx.r[27].s32, ctx.r[18].s32, &mut ctx.xer);
	// 82FCE644: 4198FF9C  blt cr6, 0x82fce5e0
	if ctx.cr[6].lt {
	pc = 0x82FCE5E0; continue 'dispatch;
	}
	// 82FCE648: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCE64C: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCE650: 7F44D378  mr r4, r26
	ctx.r[4].u64 = ctx.r[26].u64;
	// 82FCE654: 386100B0  addi r3, r1, 0xb0
	ctx.r[3].s64 = ctx.r[1].s64 + 176;
	// 82FCE658: C3CB08A4  lfs f30, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCE65C: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCE660: 480014B9  bl 0x82fcfb18
	ctx.lr = 0x82FCE664;
	sub_82FCFB18(ctx, base);
	// 82FCE664: 822D0000  lwz r17, 0(r13)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE668: 3A000014  li r16, 0x14
	ctx.r[16].s64 = 20;
	// 82FCE66C: 3B520001  addi r26, r18, 1
	ctx.r[26].s64 = ctx.r[18].s64 + 1;
	// 82FCE670: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCE674: 57442036  slwi r4, r26, 4
	ctx.r[4].u32 = ctx.r[26].u32.wrapping_shl(4);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCE678: 934100F0  stw r26, 0xf0(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[26].u32 ) };
	// 82FCE67C: 7C70882E  lwzx r3, r16, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCE680: 4BED20B1  bl 0x82ea0730
	ctx.lr = 0x82FCE684;
	sub_82EA0730(ctx, base);
	// 82FCE684: 7C731B78  mr r19, r3
	ctx.r[19].u64 = ctx.r[3].u64;
	// 82FCE688: 56542036  slwi r20, r18, 4
	ctx.r[20].u32 = ctx.r[18].u32.wrapping_shl(4);
	ctx.r[20].u64 = ctx.r[20].u32 as u64;
	// 82FCE68C: 2F120001  cmpwi cr6, r18, 1
	ctx.cr[6].compare_i32(ctx.r[18].s32, 1, &mut ctx.xer);
	// 82FCE690: 7D749A14  add r11, r20, r19
	ctx.r[11].u64 = ctx.r[20].u64 + ctx.r[19].u64;
	// 82FCE694: 7FD49D2E  stfsx f30, r20, r19
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[20].u32.wrapping_add(ctx.r[19].u32), tmp.u32) };
	// 82FCE698: D3CB0004  stfs f30, 4(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCE69C: D3CB0008  stfs f30, 8(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCE6A0: D3CB000C  stfs f30, 0xc(r11)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCE6A4: D3D30000  stfs f30, 0(r19)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE6A8: C00B0004  lfs f0, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE6AC: D0130004  stfs f0, 4(r19)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCE6B0: C1AB0008  lfs f13, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE6B4: D1B30008  stfs f13, 8(r19)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCE6B8: C18B000C  lfs f12, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE6BC: D193000C  stfs f12, 0xc(r19)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCE6C0: 409901DC  ble cr6, 0x82fce89c
	if !ctx.cr[6].gt {
	pc = 0x82FCE89C; continue 'dispatch;
	}
	// 82FCE6C4: 83F90000  lwz r31, 0(r25)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE6C8: 7D78BA14  add r11, r24, r23
	ctx.r[11].u64 = ctx.r[24].u64 + ctx.r[23].u64;
	// 82FCE6CC: 3B600004  li r27, 4
	ctx.r[27].s64 = 4;
	// 82FCE6D0: 7F9FA214  add r28, r31, r20
	ctx.r[28].u64 = ctx.r[31].u64 + ctx.r[20].u64;
	// 82FCE6D4: 3B2B0001  addi r25, r11, 1
	ctx.r[25].s64 = ctx.r[11].s64 + 1;
	// 82FCE6D8: 3BDF0010  addi r30, r31, 0x10
	ctx.r[30].s64 = ctx.r[31].s64 + 16;
	// 82FCE6DC: 3BB30018  addi r29, r19, 0x18
	ctx.r[29].s64 = ctx.r[19].s64 + 24;
	// 82FCE6E0: 3B52FFFF  addi r26, r18, -1
	ctx.r[26].s64 = ctx.r[18].s64 + -1;
	// 82FCE6E4: 81750000  lwz r11, 0(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE6E8: 7F06C378  mr r6, r24
	ctx.r[6].u64 = ctx.r[24].u64;
	// 82FCE6EC: 7EC5B378  mr r5, r22
	ctx.r[5].u64 = ctx.r[22].u64;
	// 82FCE6F0: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 82FCE6F4: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 82FCE6F8: 7C9B5C2E  lfsx f4, r27, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCE6FC: FC202090  fmr f1, f4
	ctx.f[1].f64 = ctx.f[4].f64;
	// 82FCE700: 4BFFA509  bl 0x82fc8c08
	ctx.lr = 0x82FCE704;
	sub_82FC8C08(ctx, base);
	// 82FCE704: 815C0000  lwz r10, 0(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE708: 392100E0  addi r9, r1, 0xe0
	ctx.r[9].s64 = ctx.r[1].s64 + 224;
	// 82FCE70C: 811C0004  lwz r8, 4(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE710: FC000890  fmr f0, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].f64 = ctx.f[1].f64;
	// 82FCE714: 80FC0008  lwz r7, 8(r28)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCE718: FC202090  fmr f1, f4
	ctx.f[1].f64 = ctx.f[4].f64;
	// 82FCE71C: 817C000C  lwz r11, 0xc(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCE720: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82FCE724: 7EC5B378  mr r5, r22
	ctx.r[5].u64 = ctx.r[22].u64;
	// 82FCE728: 91490000  stw r10, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCE72C: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 82FCE730: 91090004  stw r8, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCE734: 90E90008  stw r7, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FCE738: 9169000C  stw r11, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82FCE73C: C18100EC  lfs f12, 0xec(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(236 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE740: C16100E0  lfs f11, 0xe0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCE744: C14100E8  lfs f10, 0xe8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCE748: C1A100E4  lfs f13, 0xe4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(228 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE74C: EC6D0032  fmuls f3, f13, f0
	ctx.f[3].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCE750: EC8B0032  fmuls f4, f11, f0
	ctx.f[4].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCE754: D08100E0  stfs f4, 0xe0(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 82FCE758: EC4A0032  fmuls f2, f10, f0
	ctx.f[2].f64 = (((ctx.f[10].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCE75C: D06100E4  stfs f3, 0xe4(r1)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(228 as u32), tmp.u32 ) };
	// 82FCE760: EFEC0032  fmuls f31, f12, f0
	ctx.f[31].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 82FCE764: D04100E8  stfs f2, 0xe8(r1)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), tmp.u32 ) };
	// 82FCE768: D3E100EC  stfs f31, 0xec(r1)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(236 as u32), tmp.u32 ) };
	// 82FCE76C: 4BFFA49D  bl 0x82fc8c08
	ctx.lr = 0x82FCE770;
	sub_82FC8C08(ctx, base);
	// 82FCE770: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE774: 392100A0  addi r9, r1, 0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + 160;
	// 82FCE778: 811F0004  lwz r8, 4(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE77C: 38E100D0  addi r7, r1, 0xd0
	ctx.r[7].s64 = ctx.r[1].s64 + 208;
	// 82FCE780: 80DF0008  lwz r6, 8(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCE784: 388100D0  addi r4, r1, 0xd0
	ctx.r[4].s64 = ctx.r[1].s64 + 208;
	// 82FCE788: 80BF000C  lwz r5, 0xc(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCE78C: 39610100  addi r11, r1, 0x100
	ctx.r[11].s64 = ctx.r[1].s64 + 256;
	// 82FCE790: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE794: 3B7B0004  addi r27, r27, 4
	ctx.r[27].s64 = ctx.r[27].s64 + 4;
	// 82FCE798: 91490000  stw r10, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCE79C: 375AFFFF  addic. r26, r26, -1
	ctx.xer.ca = (ctx.r[26].u32 > (!(-1 as u32)));
	ctx.r[26].s64 = ctx.r[26].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 82FCE7A0: 91090004  stw r8, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCE7A4: 90C90008  stw r6, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 82FCE7A8: 90A9000C  stw r5, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 82FCE7AC: C0C100A0  lfs f6, 0xa0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCE7B0: C10100A8  lfs f8, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCE7B4: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE7B8: C0E100AC  lfs f7, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCE7BC: 813E0008  lwz r9, 8(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCE7C0: 811E000C  lwz r8, 0xc(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCE7C4: C12100A4  lfs f9, 0xa4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCE7C8: 90670000  stw r3, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 82FCE7CC: EDA90072  fmuls f13, f9, f1
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE7D0: 91470004  stw r10, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 82FCE7D4: EC060072  fmuls f0, f6, f1
	ctx.f[0].f64 = (((ctx.f[6].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE7D8: 91270008  stw r9, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 82FCE7DC: D00100A0  stfs f0, 0xa0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 82FCE7E0: 9107000C  stw r8, 0xc(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 82FCE7E4: C0A100D4  lfs f5, 0xd4(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(212 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCE7E8: C14100D8  lfs f10, 0xd8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCE7EC: ED880072  fmuls f12, f8, f1
	ctx.f[12].f64 = (((ctx.f[8].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE7F0: C12100D0  lfs f9, 0xd0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCE7F4: ED670072  fmuls f11, f7, f1
	ctx.f[11].f64 = (((ctx.f[7].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE7F8: C0C100DC  lfs f6, 0xdc(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(220 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCE7FC: 3BDE0010  addi r30, r30, 0x10
	ctx.r[30].s64 = ctx.r[30].s64 + 16;
	// 82FCE800: D1A100A4  stfs f13, 0xa4(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCE804: D18100A8  stfs f12, 0xa8(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCE808: D16100AC  stfs f11, 0xac(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCE80C: EC090028  fsubs f0, f9, f0
	ctx.f[0].f64 = (((ctx.f[9].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCE810: D00100D0  stfs f0, 0xd0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), tmp.u32 ) };
	// 82FCE814: ED056828  fsubs f8, f5, f13
	ctx.f[8].f64 = (((ctx.f[5].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FCE818: D10100D4  stfs f8, 0xd4(r1)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(212 as u32), tmp.u32 ) };
	// 82FCE81C: ECA02028  fsubs f5, f0, f4
	ctx.f[5].f64 = (((ctx.f[0].f64 - ctx.f[4].f64) as f32) as f64);
	// 82FCE820: ECEA6028  fsubs f7, f10, f12
	ctx.f[7].f64 = (((ctx.f[10].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FCE824: EC865828  fsubs f4, f6, f11
	ctx.f[4].f64 = (((ctx.f[6].f64 - ctx.f[11].f64) as f32) as f64);
	// 82FCE828: D0E100D8  stfs f7, 0xd8(r1)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), tmp.u32 ) };
	// 82FCE82C: D08100DC  stfs f4, 0xdc(r1)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 82FCE830: 80E40008  lwz r7, 8(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCE834: 80C4000C  lwz r6, 0xc(r4)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCE838: D0BDFFF8  stfs f5, -8(r29)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FCE83C: 80A40000  lwz r5, 0(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE840: 80840004  lwz r4, 4(r4)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE844: 908B0004  stw r4, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 82FCE848: 90AB0000  stw r5, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 82FCE84C: 90EB0008  stw r7, 8(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 82FCE850: 90CB000C  stw r6, 0xc(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 82FCE854: C0010104  lfs f0, 0x104(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(260 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCE858: C1A10108  lfs f13, 0x108(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(264 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCE85C: C021010C  lfs f1, 0x10c(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(268 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE860: ED81F828  fsubs f12, f1, f31
	ctx.f[12].f64 = (((ctx.f[1].f64 - ctx.f[31].f64) as f32) as f64);
	// 82FCE864: EC001828  fsubs f0, f0, f3
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[3].f64) as f32) as f64);
	// 82FCE868: D01DFFFC  stfs f0, -4(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCE86C: EDAD1028  fsubs f13, f13, f2
	ctx.f[13].f64 = (((ctx.f[13].f64 - ctx.f[2].f64) as f32) as f64);
	// 82FCE870: D1BD0000  stfs f13, 0(r29)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCE874: D19D0004  stfs f12, 4(r29)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCE878: 3BBD0010  addi r29, r29, 0x10
	ctx.r[29].s64 = ctx.r[29].s64 + 16;
	// 82FCE87C: D0010104  stfs f0, 0x104(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 82FCE880: D1A10108  stfs f13, 0x108(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 82FCE884: D181010C  stfs f12, 0x10c(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(268 as u32), tmp.u32 ) };
	// 82FCE888: 4082FE5C  bne 0x82fce6e4
	if !ctx.cr[0].eq {
	pc = 0x82FCE6E4; continue 'dispatch;
	}
	// 82FCE88C: 834100F0  lwz r26, 0xf0(r1)
	ctx.r[26].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) } as u64;
	// 82FCE890: 83210244  lwz r25, 0x244(r1)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(580 as u32) ) } as u64;
	// 82FCE894: 83C1022C  lwz r30, 0x22c(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(556 as u32) ) } as u64;
	// 82FCE898: 83A10214  lwz r29, 0x214(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(532 as u32) ) } as u64;
	// 82FCE89C: 2F180001  cmpwi cr6, r24, 1
	ctx.cr[6].compare_i32(ctx.r[24].s32, 1, &mut ctx.xer);
	// 82FCE8A0: 40990138  ble cr6, 0x82fce9d8
	if !ctx.cr[6].gt {
	pc = 0x82FCE9D8; continue 'dispatch;
	}
	// 82FCE8A4: 7DFC7B78  mr r28, r15
	ctx.r[28].u64 = ctx.r[15].u64;
	// 82FCE8A8: FC80F090  fmr f4, f30
	ctx.f[4].f64 = ctx.f[30].f64;
	// 82FCE8AC: 2F120001  cmpwi cr6, r18, 1
	ctx.cr[6].compare_i32(ctx.r[18].s32, 1, &mut ctx.xer);
	// 82FCE8B0: FC60F090  fmr f3, f30
	ctx.f[3].f64 = ctx.f[30].f64;
	// 82FCE8B4: FC40F090  fmr f2, f30
	ctx.f[2].f64 = ctx.f[30].f64;
	// 82FCE8B8: FFE0F090  fmr f31, f30
	ctx.f[31].f64 = ctx.f[30].f64;
	// 82FCE8BC: 409900B0  ble cr6, 0x82fce96c
	if !ctx.cr[6].gt {
	pc = 0x82FCE96C; continue 'dispatch;
	}
	// 82FCE8C0: 81550000  lwz r10, 0(r21)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE8C4: 7D78BA14  add r11, r24, r23
	ctx.r[11].u64 = ctx.r[24].u64 + ctx.r[23].u64;
	// 82FCE8C8: 3BF30010  addi r31, r19, 0x10
	ctx.r[31].s64 = ctx.r[19].s64 + 16;
	// 82FCE8CC: 3BAA0004  addi r29, r10, 4
	ctx.r[29].s64 = ctx.r[10].s64 + 4;
	// 82FCE8D0: 3B6B0001  addi r27, r11, 1
	ctx.r[27].s64 = ctx.r[11].s64 + 1;
	// 82FCE8D4: 3BD2FFFF  addi r30, r18, -1
	ctx.r[30].s64 = ctx.r[18].s64 + -1;
	// 82FCE8D8: 38DC0001  addi r6, r28, 1
	ctx.r[6].s64 = ctx.r[28].s64 + 1;
	// 82FCE8DC: C03D0000  lfs f1, 0(r29)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCE8E0: 7EC5B378  mr r5, r22
	ctx.r[5].u64 = ctx.r[22].u64;
	// 82FCE8E4: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCE8E8: 7EE3BB78  mr r3, r23
	ctx.r[3].u64 = ctx.r[23].u64;
	// 82FCE8EC: 4BFFA31D  bl 0x82fc8c08
	ctx.lr = 0x82FCE8F0;
	sub_82FC8C08(ctx, base);
	// 82FCE8F0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCE8F4: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCE8F8: 392100A0  addi r9, r1, 0xa0
	ctx.r[9].s64 = ctx.r[1].s64 + 160;
	// 82FCE8FC: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCE900: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCE904: 80FF0004  lwz r7, 4(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE908: 3BFF0010  addi r31, r31, 0x10
	ctx.r[31].s64 = ctx.r[31].s64 + 16;
	// 82FCE90C: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 82FCE910: 91690008  stw r11, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FCE914: 9149000C  stw r10, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82FCE918: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FCE91C: 90E90004  stw r7, 4(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 82FCE920: C12100A4  lfs f9, 0xa4(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(164 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCE924: C18100A8  lfs f12, 0xa8(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCE928: C14100AC  lfs f10, 0xac(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(172 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCE92C: C16100A0  lfs f11, 0xa0(r1)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCE930: EC0B0072  fmuls f0, f11, f1
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE934: EDA90072  fmuls f13, f9, f1
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE938: D00100A0  stfs f0, 0xa0(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), tmp.u32 ) };
	// 82FCE93C: ED8C0072  fmuls f12, f12, f1
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE940: D1A100A4  stfs f13, 0xa4(r1)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(164 as u32), tmp.u32 ) };
	// 82FCE944: ED6A0072  fmuls f11, f10, f1
	ctx.f[11].f64 = (((ctx.f[10].f64 * ctx.f[1].f64) as f32) as f64);
	// 82FCE948: D18100A8  stfs f12, 0xa8(r1)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), tmp.u32 ) };
	// 82FCE94C: D16100AC  stfs f11, 0xac(r1)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(172 as u32), tmp.u32 ) };
	// 82FCE950: EC80202A  fadds f4, f0, f4
	ctx.f[4].f64 = ((ctx.f[0].f64 + ctx.f[4].f64) as f32) as f64;
	// 82FCE954: EC6D182A  fadds f3, f13, f3
	ctx.f[3].f64 = ((ctx.f[13].f64 + ctx.f[3].f64) as f32) as f64;
	// 82FCE958: EC4C102A  fadds f2, f12, f2
	ctx.f[2].f64 = ((ctx.f[12].f64 + ctx.f[2].f64) as f32) as f64;
	// 82FCE95C: EFEBF82A  fadds f31, f11, f31
	ctx.f[31].f64 = ((ctx.f[11].f64 + ctx.f[31].f64) as f32) as f64;
	// 82FCE960: 4082FF78  bne 0x82fce8d8
	if !ctx.cr[0].eq {
	pc = 0x82FCE8D8; continue 'dispatch;
	}
	// 82FCE964: 83C1022C  lwz r30, 0x22c(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(556 as u32) ) } as u64;
	// 82FCE968: 83A10214  lwz r29, 0x214(r1)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(532 as u32) ) } as u64;
	// 82FCE96C: 816100C0  lwz r11, 0xc0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCE970: 814100B0  lwz r10, 0xb0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCE974: 7D3C59D6  mullw r9, r28, r11
	ctx.r[9].s64 = (ctx.r[28].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82FCE978: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCE97C: 7C88552E  stfsx f4, r8, r10
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCE980: 80C100B0  lwz r6, 0xb0(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCE984: 80E100C0  lwz r7, 0xc0(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCE988: 7D7C39D6  mullw r11, r28, r7
	ctx.r[11].s64 = (ctx.r[28].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCE98C: 38AB0001  addi r5, r11, 1
	ctx.r[5].s64 = ctx.r[11].s64 + 1;
	// 82FCE990: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCE994: 7C64352E  stfsx f3, r4, r6
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[4].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 82FCE998: 816100C0  lwz r11, 0xc0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCE99C: 806100B0  lwz r3, 0xb0(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCE9A0: 7D7C59D6  mullw r11, r28, r11
	ctx.r[11].s64 = (ctx.r[28].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82FCE9A4: 394B0002  addi r10, r11, 2
	ctx.r[10].s64 = ctx.r[11].s64 + 2;
	// 82FCE9A8: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCE9AC: 7C491D2E  stfsx f2, r9, r3
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCE9B0: 80E100C0  lwz r7, 0xc0(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCE9B4: 810100B0  lwz r8, 0xb0(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCE9B8: 7D7C39D6  mullw r11, r28, r7
	ctx.r[11].s64 = (ctx.r[28].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCE9BC: 38CB0003  addi r6, r11, 3
	ctx.r[6].s64 = ctx.r[11].s64 + 3;
	// 82FCE9C0: 3B9C0001  addi r28, r28, 1
	ctx.r[28].s64 = ctx.r[28].s64 + 1;
	// 82FCE9C4: 54C5103A  slwi r5, r6, 2
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCE9C8: 389C0001  addi r4, r28, 1
	ctx.r[4].s64 = ctx.r[28].s64 + 1;
	// 82FCE9CC: 7F04C000  cmpw cr6, r4, r24
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[24].s32, &mut ctx.xer);
	// 82FCE9D0: 7FE5452E  stfsx f31, r5, r8
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCE9D4: 4198FED4  blt cr6, 0x82fce8a8
	if ctx.cr[6].lt {
	pc = 0x82FCE8A8; continue 'dispatch;
	}
	// 82FCE9D8: 81750004  lwz r11, 4(r21)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCE9DC: 7EA8AB78  mr r8, r21
	ctx.r[8].u64 = ctx.r[21].u64;
	// 82FCE9E0: 7EC6B378  mr r6, r22
	ctx.r[6].u64 = ctx.r[22].u64;
	// 82FCE9E4: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 82FCE9E8: 38EBFFFF  addi r7, r11, -1
	ctx.r[7].s64 = ctx.r[11].s64 + -1;
	// 82FCE9EC: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCE9F0: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 82FCE9F4: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FCE9F8: 4BFFF239  bl 0x82fcdc30
	ctx.lr = 0x82FCE9FC;
	sub_82FCDC30(ctx, base);
	// 82FCE9FC: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEA00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FCEA04: 409A000C  bne cr6, 0x82fcea10
	if !ctx.cr[6].eq {
	pc = 0x82FCEA10; continue 'dispatch;
	}
	// 82FCEA08: 99FD0000  stb r15, 0(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[15].u8 ) };
	// 82FCEA0C: 480002F0  b 0x82fcecfc
	pc = 0x82FCECFC; continue 'dispatch;
	// 82FCEA10: 816100BC  lwz r11, 0xbc(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(188 as u32) ) } as u64;
	// 82FCEA14: 812100C0  lwz r9, 0xc0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FCEA18: 91E10080  stw r15, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[15].u32 ) };
	// 82FCEA1C: 7FEB49D7  mullw. r31, r11, r9
	ctx.r[31].s64 = (ctx.r[11].s32 as i64) * (ctx.r[9].s32 as i64);
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCEA20: 91E10084  stw r15, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[15].u32 ) };
	// 82FCEA24: 91C10088  stw r14, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[14].u32 ) };
	// 82FCEA28: 9161008C  stw r11, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[11].u32 ) };
	// 82FCEA2C: 91210090  stw r9, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[9].u32 ) };
	// 82FCEA30: 40810024  ble 0x82fcea54
	if !ctx.cr[0].gt {
	pc = 0x82FCEA54; continue 'dispatch;
	}
	// 82FCEA34: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCEA38: 7DE47B78  mr r4, r15
	ctx.r[4].u64 = ctx.r[15].u64;
	// 82FCEA3C: 41980008  blt cr6, 0x82fcea44
	if ctx.cr[6].lt {
	pc = 0x82FCEA44; continue 'dispatch;
	}
	// 82FCEA40: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCEA44: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCEA48: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FCEA4C: 4BED7DAD  bl 0x82ea67f8
	ctx.lr = 0x82FCEA50;
	sub_82EA67F8(ctx, base);
	// 82FCEA50: 81210090  lwz r9, 0x90(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEA54: 8161008C  lwz r11, 0x8c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 82FCEA58: 7DE87B78  mr r8, r15
	ctx.r[8].u64 = ctx.r[15].u64;
	// 82FCEA5C: 93E10084  stw r31, 0x84(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(132 as u32), ctx.r[31].u32 ) };
	// 82FCEA60: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCEA64: 40990060  ble cr6, 0x82fceac4
	if !ctx.cr[6].gt {
	pc = 0x82FCEAC4; continue 'dispatch;
	}
	// 82FCEA68: 7DE77B78  mr r7, r15
	ctx.r[7].u64 = ctx.r[15].u64;
	// 82FCEA6C: 7DEB7B78  mr r11, r15
	ctx.r[11].u64 = ctx.r[15].u64;
	// 82FCEA70: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCEA74: 4099003C  ble cr6, 0x82fceab0
	if !ctx.cr[6].gt {
	pc = 0x82FCEAB0; continue 'dispatch;
	}
	// 82FCEA78: 81590000  lwz r10, 0(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEA7C: 7D475214  add r10, r7, r10
	ctx.r[10].u64 = ctx.r[7].u64 + ctx.r[10].u64;
	// 82FCEA80: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCEA84: 7D2941D6  mullw r9, r9, r8
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[8].s32 as i64);
	// 82FCEA88: 80C10080  lwz r6, 0x80(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCEA8C: C00A0000  lfs f0, 0(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEA90: 7CA95A14  add r5, r9, r11
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82FCEA94: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCEA98: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCEA9C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCEAA0: 7C04352E  stfsx f0, r4, r6
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[4].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 82FCEAA4: 81210090  lwz r9, 0x90(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEAA8: 7F0B4800  cmpw cr6, r11, r9
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FCEAAC: 4198FFD8  blt cr6, 0x82fcea84
	if ctx.cr[6].lt {
	pc = 0x82FCEA84; continue 'dispatch;
	}
	// 82FCEAB0: 8161008C  lwz r11, 0x8c(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(140 as u32) ) } as u64;
	// 82FCEAB4: 39080001  addi r8, r8, 1
	ctx.r[8].s64 = ctx.r[8].s64 + 1;
	// 82FCEAB8: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 82FCEABC: 7F085800  cmpw cr6, r8, r11
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCEAC0: 4198FFAC  blt cr6, 0x82fcea6c
	if ctx.cr[6].lt {
	pc = 0x82FCEA6C; continue 'dispatch;
	}
	// 82FCEAC4: 38E00032  li r7, 0x32
	ctx.r[7].s64 = 50;
	// 82FCEAC8: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 82FCEACC: 38C100B0  addi r6, r1, 0xb0
	ctx.r[6].s64 = ctx.r[1].s64 + 176;
	// 82FCEAD0: 38A10080  addi r5, r1, 0x80
	ctx.r[5].s64 = ctx.r[1].s64 + 128;
	// 82FCEAD4: 38810110  addi r4, r1, 0x110
	ctx.r[4].s64 = ctx.r[1].s64 + 272;
	// 82FCEAD8: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FCEADC: 48001B7D  bl 0x82fd0658
	ctx.lr = 0x82FCEAE0;
	sub_82FD0658(ctx, base);
	// 82FCEAE0: 89610060  lbz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCEAE4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FCEAE8: 409A000C  bne cr6, 0x82fceaf4
	if !ctx.cr[6].eq {
	pc = 0x82FCEAF4; continue 'dispatch;
	}
	// 82FCEAEC: 99FD0000  stb r15, 0(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[15].u8 ) };
	// 82FCEAF0: 480001E8  b 0x82fcecd8
	pc = 0x82FCECD8; continue 'dispatch;
	// 82FCEAF4: 7DE97B78  mr r9, r15
	ctx.r[9].u64 = ctx.r[15].u64;
	// 82FCEAF8: 91E1006C  stw r15, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[15].u32 ) };
	// 82FCEAFC: 37F80001  addic. r31, r24, 1
	ctx.xer.ca = (ctx.r[24].u32 > (!(1 as u32)));
	ctx.r[31].s64 = ctx.r[24].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCEB00: 91C10070  stw r14, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[14].u32 ) };
	// 82FCEB04: 91210068  stw r9, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[9].u32 ) };
	// 82FCEB08: 40810024  ble 0x82fceb2c
	if !ctx.cr[0].gt {
	pc = 0x82FCEB2C; continue 'dispatch;
	}
	// 82FCEB0C: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 82FCEB10: 7DE47B78  mr r4, r15
	ctx.r[4].u64 = ctx.r[15].u64;
	// 82FCEB14: 41980008  blt cr6, 0x82fceb1c
	if ctx.cr[6].lt {
	pc = 0x82FCEB1C; continue 'dispatch;
	}
	// 82FCEB18: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FCEB1C: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82FCEB20: 38610068  addi r3, r1, 0x68
	ctx.r[3].s64 = ctx.r[1].s64 + 104;
	// 82FCEB24: 4BED7CD5  bl 0x82ea67f8
	ctx.lr = 0x82FCEB28;
	sub_82EA67F8(ctx, base);
	// 82FCEB28: 81210068  lwz r9, 0x68(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEB2C: 93E1006C  stw r31, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[31].u32 ) };
	// 82FCEB30: 7D274B78  mr r7, r9
	ctx.r[7].u64 = ctx.r[9].u64;
	// 82FCEB34: 81790000  lwz r11, 0(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEB38: 57082036  slwi r8, r24, 4
	ctx.r[8].u32 = ctx.r[24].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCEB3C: 2F180001  cmpwi cr6, r24, 1
	ctx.cr[6].compare_i32(ctx.r[24].s32, 1, &mut ctx.xer);
	// 82FCEB40: 7D4BA214  add r10, r11, r20
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[20].u64;
	// 82FCEB44: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEB48: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEB4C: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEB50: D1A70004  stfs f13, 4(r7)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEB54: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCEB58: D1870008  stfs f12, 8(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEB5C: C16B000C  lfs f11, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCEB60: D167000C  stfs f11, 0xc(r7)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEB64: 81210068  lwz r9, 0x68(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEB68: 7D4BA42E  lfsx f10, r11, r20
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[20].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCEB6C: 7D684A14  add r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 82FCEB70: 7D484D2E  stfsx f10, r8, r9
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCEB74: C12A0004  lfs f9, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCEB78: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEB7C: C10A0008  lfs f8, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCEB80: D10B0008  stfs f8, 8(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEB84: C0EA000C  lfs f7, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCEB88: D0EB000C  stfs f7, 0xc(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEB8C: 409900A8  ble cr6, 0x82fcec34
	if !ctx.cr[6].gt {
	pc = 0x82FCEC34; continue 'dispatch;
	}
	// 82FCEB90: 7DEB7B78  mr r11, r15
	ctx.r[11].u64 = ctx.r[15].u64;
	// 82FCEB94: 39400010  li r10, 0x10
	ctx.r[10].s64 = 16;
	// 82FCEB98: 3938FFFF  addi r9, r24, -1
	ctx.r[9].s64 = ctx.r[24].s64 + -1;
	// 82FCEB9C: 80E10090  lwz r7, 0x90(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEBA0: 390A000C  addi r8, r10, 0xc
	ctx.r[8].s64 = ctx.r[10].s64 + 12;
	// 82FCEBA4: 80C10080  lwz r6, 0x80(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCEBA8: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCEBAC: 7CAB39D6  mullw r5, r11, r7
	ctx.r[5].s64 = (ctx.r[11].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCEBB0: 80810068  lwz r4, 0x68(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEBB4: 54A3103A  slwi r3, r5, 2
	ctx.r[3].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FCEBB8: 7C03342E  lfsx f0, r3, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEBBC: 7C0A252E  stfsx f0, r10, r4
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 82FCEBC0: 80E10090  lwz r7, 0x90(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEBC4: 80C10068  lwz r6, 0x68(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEBC8: 7CEB39D6  mullw r7, r11, r7
	ctx.r[7].s64 = (ctx.r[11].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCEBCC: 80A10080  lwz r5, 0x80(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCEBD0: 38870001  addi r4, r7, 1
	ctx.r[4].s64 = ctx.r[7].s64 + 1;
	// 82FCEBD4: 7C6A3214  add r3, r10, r6
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 82FCEBD8: 5487103A  slwi r7, r4, 2
	ctx.r[7].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCEBDC: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCEBE0: 7DA72C2E  lfsx f13, r7, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEBE4: D1A30004  stfs f13, 4(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEBE8: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCEBEC: 80C10068  lwz r6, 0x68(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEBF0: 80A10090  lwz r5, 0x90(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEBF4: 7CEB29D6  mullw r7, r11, r5
	ctx.r[7].s64 = (ctx.r[11].s32 as i64) * (ctx.r[5].s32 as i64);
	// 82FCEBF8: 38670002  addi r3, r7, 2
	ctx.r[3].s64 = ctx.r[7].s64 + 2;
	// 82FCEBFC: 7CE83214  add r7, r8, r6
	ctx.r[7].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 82FCEC00: 5466103A  slwi r6, r3, 2
	ctx.r[6].u32 = ctx.r[3].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCEC04: 7D86242E  lfsx f12, r6, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCEC08: D187FFFC  stfs f12, -4(r7)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCEC0C: 80A10090  lwz r5, 0x90(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) } as u64;
	// 82FCEC10: 7CEB29D6  mullw r7, r11, r5
	ctx.r[7].s64 = (ctx.r[11].s32 as i64) * (ctx.r[5].s32 as i64);
	// 82FCEC14: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCEC18: 80610068  lwz r3, 0x68(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEC1C: 38E70003  addi r7, r7, 3
	ctx.r[7].s64 = ctx.r[7].s64 + 3;
	// 82FCEC20: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCEC24: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCEC28: 7D66242E  lfsx f11, r6, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCEC2C: 7D681D2E  stfsx f11, r8, r3
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCEC30: 4082FF6C  bne 0x82fceb9c
	if !ctx.cr[0].eq {
	pc = 0x82FCEB9C; continue 'dispatch;
	}
	// 82FCEC34: 7EAAAB78  mr r10, r21
	ctx.r[10].u64 = ctx.r[21].u64;
	// 82FCEC38: FC20E090  fmr f1, f28
	ctx.f[1].f64 = ctx.f[28].f64;
	// 82FCEC3C: 7F29CB78  mr r9, r25
	ctx.r[9].u64 = ctx.r[25].u64;
	// 82FCEC40: 7E489378  mr r8, r18
	ctx.r[8].u64 = ctx.r[18].u64;
	// 82FCEC44: 7EC7B378  mr r7, r22
	ctx.r[7].u64 = ctx.r[22].u64;
	// 82FCEC48: 38C10068  addi r6, r1, 0x68
	ctx.r[6].s64 = ctx.r[1].s64 + 104;
	// 82FCEC4C: 7EE5BB78  mr r5, r23
	ctx.r[5].u64 = ctx.r[23].u64;
	// 82FCEC50: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 82FCEC54: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FCEC58: 4BFFBC19  bl 0x82fca870
	ctx.lr = 0x82FCEC5C;
	sub_82FCA870(ctx, base);
	// 82FCEC5C: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEC60: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FCEC64: 419A004C  beq cr6, 0x82fcecb0
	if ctx.cr[6].eq {
	pc = 0x82FCECB0; continue 'dispatch;
	}
	// 82FCEC68: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCEC6C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FCEC70: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEC74: 813E0004  lwz r9, 4(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCEC78: 55680000  rlwinm r8, r11, 0, 0, 0
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCEC7C: 80E10068  lwz r7, 0x68(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCEC80: 80C1006C  lwz r6, 0x6c(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 82FCEC84: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCEC88: 80A10070  lwz r5, 0x70(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCEC8C: 90810068  stw r4, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[4].u32 ) };
	// 82FCEC90: 9121006C  stw r9, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[9].u32 ) };
	// 82FCEC94: 90FE0000  stw r7, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 82FCEC98: 90DE0004  stw r6, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 82FCEC9C: 90BE0008  stw r5, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 82FCECA0: 995D0000  stb r10, 0(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 82FCECA4: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 82FCECA8: 409A0030  bne cr6, 0x82fcecd8
	if !ctx.cr[6].eq {
	pc = 0x82FCECD8; continue 'dispatch;
	}
	// 82FCECAC: 4800001C  b 0x82fcecc8
	pc = 0x82FCECC8; continue 'dispatch;
	// 82FCECB0: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCECB4: 99FD0000  stb r15, 0(r29)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[15].u8 ) };
	// 82FCECB8: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCECBC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCECC0: 409A0018  bne cr6, 0x82fcecd8
	if !ctx.cr[6].eq {
	pc = 0x82FCECD8; continue 'dispatch;
	}
	// 82FCECC4: 80810068  lwz r4, 0x68(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCECC8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCECCC: 7C70882E  lwzx r3, r16, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCECD0: 55652036  slwi r5, r11, 4
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCECD4: 4BED1ADD  bl 0x82ea07b0
	ctx.lr = 0x82FCECD8;
	sub_82EA07B0(ctx, base);
	// 82FCECD8: 81610088  lwz r11, 0x88(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 82FCECDC: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCECE0: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCECE4: 409A0018  bne cr6, 0x82fcecfc
	if !ctx.cr[6].eq {
	pc = 0x82FCECFC; continue 'dispatch;
	}
	// 82FCECE8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCECEC: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCECF0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCECF4: 7C70882E  lwzx r3, r16, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCECF8: 4BED1AB9  bl 0x82ea07b0
	ctx.lr = 0x82FCECFC;
	sub_82EA07B0(ctx, base);
	// 82FCECFC: 574B0000  rlwinm r11, r26, 0, 0, 0
	ctx.r[11].u64 = ctx.r[26].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCED00: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCED04: 409A0018  bne cr6, 0x82fced1c
	if !ctx.cr[6].eq {
	pc = 0x82FCED1C; continue 'dispatch;
	}
	// 82FCED08: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCED0C: 7C70882E  lwzx r3, r16, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCED10: 57452036  slwi r5, r26, 4
	ctx.r[5].u32 = ctx.r[26].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCED14: 7E649B78  mr r4, r19
	ctx.r[4].u64 = ctx.r[19].u64;
	// 82FCED18: 4BED1A99  bl 0x82ea07b0
	ctx.lr = 0x82FCED1C;
	sub_82EA07B0(ctx, base);
	// 82FCED1C: 816100B8  lwz r11, 0xb8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) } as u64;
	// 82FCED20: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCED24: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCED28: 409A0018  bne cr6, 0x82fced40
	if !ctx.cr[6].eq {
	pc = 0x82FCED40; continue 'dispatch;
	}
	// 82FCED2C: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCED30: 808100B0  lwz r4, 0xb0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) } as u64;
	// 82FCED34: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCED38: 7C70882E  lwzx r3, r16, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[16].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCED3C: 4BED1A75  bl 0x82ea07b0
	ctx.lr = 0x82FCED40;
	sub_82EA07B0(ctx, base);
	// 82FCED40: 38610110  addi r3, r1, 0x110
	ctx.r[3].s64 = ctx.r[1].s64 + 272;
	// 82FCED44: 48000C2D  bl 0x82fcf970
	ctx.lr = 0x82FCED48;
	sub_82FCF970(ctx, base);
	// 82FCED48: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FCED4C: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 82FCED50: 3981FF68  addi r12, r1, -0x98
	ctx.r[12].s64 = ctx.r[1].s64 + -152;
	// 82FCED54: 481D9D71  bl 0x831a8ac4
	ctx.lr = 0x82FCED58;
	sub_831A8A8C(ctx, base);
	// 82FCED58: 481D9428  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCED60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCED60 size=1376
    let mut pc: u32 = 0x82FCED60;
    'dispatch: loop {
        match pc {
            0x82FCED60 => {
    //   block [0x82FCED60..0x82FCF2C0)
	// 82FCED60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCED64: 481D93CD  bl 0x831a8130
	ctx.lr = 0x82FCED68;
	sub_831A8130(ctx, base);
	// 82FCED68: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 82FCED6C: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 82FCED70: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 82FCED74: 9421FEB0  stwu r1, -0x150(r1)
	ea = ctx.r[1].u32.wrapping_add(-336 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCED78: 7D3C4B78  mr r28, r9
	ctx.r[28].u64 = ctx.r[9].u64;
	// 82FCED7C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCED80: 7D5E5378  mr r30, r10
	ctx.r[30].u64 = ctx.r[10].u64;
	// 82FCED84: 7C741B78  mr r20, r3
	ctx.r[20].u64 = ctx.r[3].u64;
	// 82FCED88: 7CCE3378  mr r14, r6
	ctx.r[14].u64 = ctx.r[6].u64;
	// 82FCED8C: 3BB40003  addi r29, r20, 3
	ctx.r[29].s64 = ctx.r[20].s64 + 3;
	// 82FCED90: 929C0000  stw r20, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[20].u32 ) };
	// 82FCED94: 7C932378  mr r19, r4
	ctx.r[19].u64 = ctx.r[4].u64;
	// 82FCED98: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCED9C: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCEDA0: 7CB22B78  mr r18, r5
	ctx.r[18].u64 = ctx.r[5].u64;
	// 82FCEDA4: 99C1017F  stb r14, 0x17f(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(383 as u32), ctx.r[14].u8 ) };
	// 82FCEDA8: 7CF03B78  mr r16, r7
	ctx.r[16].u64 = ctx.r[7].u64;
	// 82FCEDAC: 7F0BE800  cmpw cr6, r11, r29
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCEDB0: 40980024  bge cr6, 0x82fcedd4
	if !ctx.cr[6].lt {
	pc = 0x82FCEDD4; continue 'dispatch;
	}
	// 82FCEDB4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCEDB8: 7F1D5800  cmpw cr6, r29, r11
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCEDBC: 41980008  blt cr6, 0x82fcedc4
	if ctx.cr[6].lt {
	pc = 0x82FCEDC4; continue 'dispatch;
	}
	// 82FCEDC0: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCEDC4: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCEDC8: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCEDCC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCEDD0: 4BED7A29  bl 0x82ea67f8
	ctx.lr = 0x82FCEDD4;
	sub_82EA67F8(ctx, base);
	// 82FCEDD4: 83E101A4  lwz r31, 0x1a4(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(420 as u32) ) } as u64;
	// 82FCEDD8: 93BE0004  stw r29, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCEDDC: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEDE0: 3BAB0001  addi r29, r11, 1
	ctx.r[29].s64 = ctx.r[11].s64 + 1;
	// 82FCEDE4: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCEDE8: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCEDEC: 7F0BE800  cmpw cr6, r11, r29
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[29].s32, &mut ctx.xer);
	// 82FCEDF0: 40980024  bge cr6, 0x82fcee14
	if !ctx.cr[6].lt {
	pc = 0x82FCEE14; continue 'dispatch;
	}
	// 82FCEDF4: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCEDF8: 7F1D5800  cmpw cr6, r29, r11
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCEDFC: 41980008  blt cr6, 0x82fcee04
	if ctx.cr[6].lt {
	pc = 0x82FCEE04; continue 'dispatch;
	}
	// 82FCEE00: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCEE04: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82FCEE08: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCEE0C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCEE10: 4BED79E9  bl 0x82ea67f8
	ctx.lr = 0x82FCEE14;
	sub_82EA67F8(ctx, base);
	// 82FCEE14: 93BF0004  stw r29, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCEE18: 39740002  addi r11, r20, 2
	ctx.r[11].s64 = ctx.r[20].s64 + 2;
	// 82FCEE1C: 5689103A  slwi r9, r20, 2
	ctx.r[9].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCEE20: 5568103A  slwi r8, r11, 2
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCEE24: 39F40001  addi r15, r20, 1
	ctx.r[15].s64 = ctx.r[20].s64 + 1;
	// 82FCEE28: 3AA00000  li r21, 0
	ctx.r[21].s64 = 0;
	// 82FCEE2C: 2F0F0004  cmpwi cr6, r15, 4
	ctx.cr[6].compare_i32(ctx.r[15].s32, 4, &mut ctx.xer);
	// 82FCEE30: 82D20000  lwz r22, 0(r18)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEE34: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEE38: C0160000  lfs f0, 0(r22)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEE3C: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEE40: 80FE0000  lwz r7, 0(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEE44: 7DA9B42E  lfsx f13, r9, r22
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[22].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEE48: 7DA83D2E  stfsx f13, r8, r7
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FCEE4C: 41980144  blt cr6, 0x82fcef90
	if ctx.cr[6].lt {
	pc = 0x82FCEF90; continue 'dispatch;
	}
	// 82FCEE50: 81530000  lwz r10, 0(r19)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEE54: 39740001  addi r11, r20, 1
	ctx.r[11].s64 = ctx.r[20].s64 + 1;
	// 82FCEE58: 38C00008  li r6, 8
	ctx.r[6].s64 = 8;
	// 82FCEE5C: 23AA0018  subfic r29, r10, 0x18
	ctx.xer.ca = ctx.r[10].u32 <= 24 as u32;
	ctx.r[29].s64 = (24 as i64) - ctx.r[10].s64;
	// 82FCEE60: 236A0028  subfic r27, r10, 0x28
	ctx.xer.ca = ctx.r[10].u32 <= 40 as u32;
	ctx.r[27].s64 = (40 as i64) - ctx.r[10].s64;
	// 82FCEE64: 234AFFF8  subfic r26, r10, -8
	ctx.xer.ca = ctx.r[10].u32 <= -8 as u32;
	ctx.r[26].s64 = (-8 as i64) - ctx.r[10].s64;
	// 82FCEE68: 5567F0BE  srwi r7, r11, 2
	ctx.r[7].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCEE6C: 23360004  subfic r25, r22, 4
	ctx.xer.ca = ctx.r[22].u32 <= 4 as u32;
	ctx.r[25].s64 = (4 as i64) - ctx.r[22].s64;
	// 82FCEE70: 23160008  subfic r24, r22, 8
	ctx.xer.ca = ctx.r[22].u32 <= 8 as u32;
	ctx.r[24].s64 = (8 as i64) - ctx.r[22].s64;
	// 82FCEE74: 396A0008  addi r11, r10, 8
	ctx.r[11].s64 = ctx.r[10].s64 + 8;
	// 82FCEE78: 39360008  addi r9, r22, 8
	ctx.r[9].s64 = ctx.r[22].s64 + 8;
	// 82FCEE7C: 394A0018  addi r10, r10, 0x18
	ctx.r[10].s64 = ctx.r[10].s64 + 24;
	// 82FCEE80: 22F6FFF8  subfic r23, r22, -8
	ctx.xer.ca = ctx.r[22].u32 <= -8 as u32;
	ctx.r[23].s64 = (-8 as i64) - ctx.r[22].s64;
	// 82FCEE84: 54F5103A  slwi r21, r7, 2
	ctx.r[21].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[21].u64 = ctx.r[21].u32 as u64;
	// 82FCEE88: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEE8C: 7C89BA14  add r4, r9, r23
	ctx.r[4].u64 = ctx.r[9].u64 + ctx.r[23].u64;
	// 82FCEE90: C009FFF8  lfs f0, -8(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEE94: 7CABD214  add r5, r11, r26
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[26].u64;
	// 82FCEE98: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 82FCEE9C: 7E29CA14  add r17, r9, r25
	ctx.r[17].u64 = ctx.r[9].u64 + ctx.r[25].u64;
	// 82FCEEA0: 7C6BEA14  add r3, r11, r29
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82FCEEA4: 7DC9C214  add r14, r9, r24
	ctx.r[14].u64 = ctx.r[9].u64 + ctx.r[24].u64;
	// 82FCEEA8: 7C8BDA14  add r4, r11, r27
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 82FCEEAC: D0080004  stfs f0, 4(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEEB0: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCEEB4: C1ABFFF8  lfs f13, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEEB8: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEEBC: 7D054214  add r8, r5, r8
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[8].u64;
	// 82FCEEC0: D1A80000  stfs f13, 0(r8)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEEC4: C18BFFFC  lfs f12, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCEEC8: D1880004  stfs f12, 4(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEECC: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCEED0: D1680008  stfs f11, 8(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEED4: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCEED8: D148000C  stfs f10, 0xc(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEEDC: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEEE0: C129FFFC  lfs f9, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCEEE4: 7D26452E  stfsx f9, r6, r8
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[6].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCEEE8: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEEEC: 7D054214  add r8, r5, r8
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[8].u64;
	// 82FCEEF0: C10B0008  lfs f8, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCEEF4: 38C60010  addi r6, r6, 0x10
	ctx.r[6].s64 = ctx.r[6].s64 + 16;
	// 82FCEEF8: D1080010  stfs f8, 0x10(r8)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCEEFC: C0EAFFFC  lfs f7, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCEF00: D0E80014  stfs f7, 0x14(r8)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCEF04: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCEF08: D0C80018  stfs f6, 0x18(r8)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82FCEF0C: C0AA0004  lfs f5, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCEF10: D0A8001C  stfs f5, 0x1c(r8)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82FCEF14: 80BE0000  lwz r5, 0(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEF18: C0890000  lfs f4, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCEF1C: 7C912D2E  stfsx f4, r17, r5
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[17].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCEF20: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEF24: 7D034214  add r8, r3, r8
	ctx.r[8].u64 = ctx.r[3].u64 + ctx.r[8].u64;
	// 82FCEF28: C06B0018  lfs f3, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCEF2C: D0680000  stfs f3, 0(r8)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEF30: C04A000C  lfs f2, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCEF34: D0480004  stfs f2, 4(r8)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEF38: C02A0010  lfs f1, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCEF3C: D0280008  stfs f1, 8(r8)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEF40: C00A0014  lfs f0, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEF44: D008000C  stfs f0, 0xc(r8)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEF48: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEF4C: C1A90004  lfs f13, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEF50: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FCEF54: 7DAE1D2E  stfsx f13, r14, r3
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[14].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FCEF58: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEF5C: 7D044214  add r8, r4, r8
	ctx.r[8].u64 = ctx.r[4].u64 + ctx.r[8].u64;
	// 82FCEF60: C18B0028  lfs f12, 0x28(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCEF64: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCEF68: D1880000  stfs f12, 0(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEF6C: C16A001C  lfs f11, 0x1c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCEF70: D1680004  stfs f11, 4(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEF74: C14A0020  lfs f10, 0x20(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCEF78: D1480008  stfs f10, 8(r8)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEF7C: C12A0024  lfs f9, 0x24(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCEF80: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCEF84: D128000C  stfs f9, 0xc(r8)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEF88: 4082FF00  bne 0x82fcee88
	if !ctx.cr[0].eq {
	pc = 0x82FCEE88; continue 'dispatch;
	}
	// 82FCEF8C: 89C1017F  lbz r14, 0x17f(r1)
	ctx.r[14].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(383 as u32) ) } as u64;
	// 82FCEF90: 7F15A000  cmpw cr6, r21, r20
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[20].s32, &mut ctx.xer);
	// 82FCEF94: 4199006C  bgt cr6, 0x82fcf000
	if ctx.cr[6].gt {
	pc = 0x82FCF000; continue 'dispatch;
	}
	// 82FCEF98: 80D30000  lwz r6, 0(r19)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEF9C: 56A82036  slwi r8, r21, 4
	ctx.r[8].u32 = ctx.r[21].u32.wrapping_shl(4);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCEFA0: 7D55A050  subf r10, r21, r20
	ctx.r[10].s64 = ctx.r[20].s64 - ctx.r[21].s64;
	// 82FCEFA4: 7D664214  add r11, r6, r8
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[8].u64;
	// 82FCEFA8: 56A9103A  slwi r9, r21, 2
	ctx.r[9].u32 = ctx.r[21].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCEFAC: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 82FCEFB0: 38EA0001  addi r7, r10, 1
	ctx.r[7].s64 = ctx.r[10].s64 + 1;
	// 82FCEFB4: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEFB8: 7C09B42E  lfsx f0, r9, r22
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[22].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCEFBC: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCEFC0: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 82FCEFC4: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FCEFC8: D00A0004  stfs f0, 4(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEFCC: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCEFD0: 7DA8342E  lfsx f13, r8, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCEFD4: 7D485214  add r10, r8, r10
	ctx.r[10].u64 = ctx.r[8].u64 + ctx.r[10].u64;
	// 82FCEFD8: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCEFDC: D1AA0000  stfs f13, 0(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCEFE0: C18BFFFC  lfs f12, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCEFE4: D18A0004  stfs f12, 4(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCEFE8: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCEFEC: D16A0008  stfs f11, 8(r10)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCEFF0: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCEFF4: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCEFF8: D14A000C  stfs f10, 0xc(r10)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCEFFC: 4082FFB8  bne 0x82fcefb4
	if !ctx.cr[0].eq {
	pc = 0x82FCEFB4; continue 'dispatch;
	}
	// 82FCF000: 822D0000  lwz r17, 0(r13)
	ctx.r[17].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF004: 3AA00014  li r21, 0x14
	ctx.r[21].s64 = 20;
	// 82FCF008: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCF00C: 55E4103A  slwi r4, r15, 2
	ctx.r[4].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCF010: 7C75882E  lwzx r3, r21, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCF014: 4BED171D  bl 0x82ea0730
	ctx.lr = 0x82FCF018;
	sub_82EA0730(ctx, base);
	// 82FCF018: 7C761B78  mr r22, r3
	ctx.r[22].u64 = ctx.r[3].u64;
	// 82FCF01C: 91E1008C  stw r15, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[15].u32 ) };
	// 82FCF020: 91E10090  stw r15, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[15].u32 ) };
	// 82FCF024: 2F0F0000  cmpwi cr6, r15, 0
	ctx.cr[6].compare_i32(ctx.r[15].s32, 0, &mut ctx.xer);
	// 82FCF028: 92C10088  stw r22, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[22].u32 ) };
	// 82FCF02C: 40990024  ble cr6, 0x82fcf050
	if !ctx.cr[6].gt {
	pc = 0x82FCF050; continue 'dispatch;
	}
	// 82FCF030: 7ECBB378  mr r11, r22
	ctx.r[11].u64 = ctx.r[22].u64;
	// 82FCF034: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCF038: 2B0F0000  cmplwi cr6, r15, 0
	ctx.cr[6].compare_u32(ctx.r[15].u32, 0 as u32, &mut ctx.xer);
	// 82FCF03C: 419A0014  beq cr6, 0x82fcf050
	if ctx.cr[6].eq {
	pc = 0x82FCF050; continue 'dispatch;
	}
	// 82FCF040: 7DE903A6  mtctr r15
	ctx.ctr.u64 = ctx.r[15].u64;
	// 82FCF044: 914B0000  stw r10, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCF048: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCF04C: 4200FFF8  bdnz 0x82fcf044
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x82FCF044; continue 'dispatch;
	}
	// 82FCF050: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 82FCF054: 2F100001  cmpwi cr6, r16, 1
	ctx.cr[6].compare_i32(ctx.r[16].s32, 1, &mut ctx.xer);
	// 82FCF058: 41980234  blt cr6, 0x82fcf28c
	if ctx.cr[6].lt {
	pc = 0x82FCF28C; continue 'dispatch;
	}
	// 82FCF05C: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCF060: 3D408201  lis r10, -0x7dff
	ctx.r[10].s64 = -2113863680;
	// 82FCF064: 3B00000A  li r24, 0xa
	ctx.r[24].s64 = 10;
	// 82FCF068: 3B200064  li r25, 0x64
	ctx.r[25].s64 = 100;
	// 82FCF06C: C3CB08A0  lfs f30, 0x8a0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2208 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 82FCF070: C3AAC0B0  lfs f29, -0x3f50(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-16208 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FCF074: 39210088  addi r9, r1, 0x88
	ctx.r[9].s64 = ctx.r[1].s64 + 136;
	// 82FCF078: 92610054  stw r19, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[19].u32 ) };
	// 82FCF07C: 7E489378  mr r8, r18
	ctx.r[8].u64 = ctx.r[18].u64;
	// 82FCF080: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCF084: 7E87A378  mr r7, r20
	ctx.r[7].u64 = ctx.r[20].u64;
	// 82FCF088: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCF08C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82FCF090: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FCF094: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82FCF098: 4BFFED41  bl 0x82fcddd8
	ctx.lr = 0x82FCF09C;
	sub_82FCDDD8(ctx, base);
	// 82FCF09C: 7C771B78  mr r23, r3
	ctx.r[23].u64 = ctx.r[3].u64;
	// 82FCF0A0: 7F1D8000  cmpw cr6, r29, r16
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[16].s32, &mut ctx.xer);
	// 82FCF0A4: 419A0154  beq cr6, 0x82fcf1f8
	if ctx.cr[6].eq {
	pc = 0x82FCF1F8; continue 'dispatch;
	}
	// 82FCF0A8: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF0AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCF0B0: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82FCF0B4: 388B0001  addi r4, r11, 1
	ctx.r[4].s64 = ctx.r[11].s64 + 1;
	// 82FCF0B8: 4BFFAF91  bl 0x82fca048
	ctx.lr = 0x82FCF0BC;
	sub_82FCA048(ctx, base);
	// 82FCF0BC: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF0C0: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82FCF0C4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCF0C8: 917C0000  stw r11, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCF0CC: 3B6B0001  addi r27, r11, 1
	ctx.r[27].s64 = ctx.r[11].s64 + 1;
	// 82FCF0D0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCF0D4: 556B00BE  clrlwi r11, r11, 2
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCF0D8: 7F0BD800  cmpw cr6, r11, r27
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[27].s32, &mut ctx.xer);
	// 82FCF0DC: 40980024  bge cr6, 0x82fcf100
	if !ctx.cr[6].lt {
	pc = 0x82FCF100; continue 'dispatch;
	}
	// 82FCF0E0: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCF0E4: 7F1B5800  cmpw cr6, r27, r11
	ctx.cr[6].compare_i32(ctx.r[27].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCF0E8: 41980008  blt cr6, 0x82fcf0f0
	if ctx.cr[6].lt {
	pc = 0x82FCF0F0; continue 'dispatch;
	}
	// 82FCF0EC: 7F6BDB78  mr r11, r27
	ctx.r[11].u64 = ctx.r[27].u64;
	// 82FCF0F0: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82FCF0F4: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCF0F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCF0FC: 4BED76FD  bl 0x82ea67f8
	ctx.lr = 0x82FCF100;
	sub_82EA67F8(ctx, base);
	// 82FCF100: 937F0004  stw r27, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[27].u32 ) };
	// 82FCF104: 3B7D0001  addi r27, r29, 1
	ctx.r[27].s64 = ctx.r[29].s64 + 1;
	// 82FCF108: 7E4A9378  mr r10, r18
	ctx.r[10].u64 = ctx.r[18].u64;
	// 82FCF10C: FC40F890  fmr f2, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[31].f64;
	// 82FCF110: 7E699B78  mr r9, r19
	ctx.r[9].u64 = ctx.r[19].u64;
	// 82FCF114: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 82FCF118: 7E88A378  mr r8, r20
	ctx.r[8].u64 = ctx.r[20].u64;
	// 82FCF11C: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82FCF120: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCF124: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82FCF128: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FCF12C: 809C0000  lwz r4, 0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF130: 4BFFF401  bl 0x82fce530
	ctx.lr = 0x82FCF134;
	sub_82FCE530(ctx, base);
	// 82FCF134: 89610080  lbz r11, 0x80(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FCF138: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FCF13C: 409A0078  bne cr6, 0x82fcf1b4
	if !ctx.cr[6].eq {
	pc = 0x82FCF1B4; continue 'dispatch;
	}
	// 82FCF140: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF144: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCF148: 7D6BEA14  add r11, r11, r29
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 82FCF14C: 388B0001  addi r4, r11, 1
	ctx.r[4].s64 = ctx.r[11].s64 + 1;
	// 82FCF150: 4BFFB0D1  bl 0x82fca220
	ctx.lr = 0x82FCF154;
	sub_82FCA220(ctx, base);
	// 82FCF154: 817C0000  lwz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF158: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FCF15C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FCF160: 917C0000  stw r11, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCF164: 3B4B0001  addi r26, r11, 1
	ctx.r[26].s64 = ctx.r[11].s64 + 1;
	// 82FCF168: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCF16C: 554B00BE  clrlwi r11, r10, 2
	ctx.r[11].u64 = ctx.r[10].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCF170: 7F0BD000  cmpw cr6, r11, r26
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[26].s32, &mut ctx.xer);
	// 82FCF174: 40980024  bge cr6, 0x82fcf198
	if !ctx.cr[6].lt {
	pc = 0x82FCF198; continue 'dispatch;
	}
	// 82FCF178: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCF17C: 7F1A5800  cmpw cr6, r26, r11
	ctx.cr[6].compare_i32(ctx.r[26].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FCF180: 41980008  blt cr6, 0x82fcf188
	if ctx.cr[6].lt {
	pc = 0x82FCF188; continue 'dispatch;
	}
	// 82FCF184: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 82FCF188: 38A00010  li r5, 0x10
	ctx.r[5].s64 = 16;
	// 82FCF18C: 7D645B78  mr r4, r11
	ctx.r[4].u64 = ctx.r[11].u64;
	// 82FCF190: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCF194: 4BED7665  bl 0x82ea67f8
	ctx.lr = 0x82FCF198;
	sub_82EA67F8(ctx, base);
	// 82FCF198: 935F0004  stw r26, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[26].u32 ) };
	// 82FCF19C: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 82FCF1A0: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCF1A4: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82FCF1A8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FCF1AC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82FCF1B0: 4BFFC581  bl 0x82fcb730
	ctx.lr = 0x82FCF1B4;
	sub_82FCB730(ctx, base);
	// 82FCF1B4: 93210054  stw r25, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[25].u32 ) };
	// 82FCF1B8: 7E4A9378  mr r10, r18
	ctx.r[10].u64 = ctx.r[18].u64;
	// 82FCF1BC: 99C10077  stb r14, 0x77(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(119 as u32), ctx.r[14].u8 ) };
	// 82FCF1C0: 39210088  addi r9, r1, 0x88
	ctx.r[9].s64 = ctx.r[1].s64 + 136;
	// 82FCF1C4: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 82FCF1C8: 80BC0000  lwz r5, 0(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF1CC: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82FCF1D0: 9301005C  stw r24, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[24].u32 ) };
	// 82FCF1D4: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 82FCF1D8: FC40F090  fmr f2, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[30].f64;
	// 82FCF1DC: 7E649B78  mr r4, r19
	ctx.r[4].u64 = ctx.r[19].u64;
	// 82FCF1E0: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCF1E4: 7E83A378  mr r3, r20
	ctx.r[3].u64 = ctx.r[20].u64;
	// 82FCF1E8: 4BFFB511  bl 0x82fca6f8
	ctx.lr = 0x82FCF1EC;
	sub_82FCA6F8(ctx, base);
	// 82FCF1EC: 7F7DDB78  mr r29, r27
	ctx.r[29].u64 = ctx.r[27].u64;
	// 82FCF1F0: 7F1B8000  cmpw cr6, r27, r16
	ctx.cr[6].compare_i32(ctx.r[27].s32, ctx.r[16].s32, &mut ctx.xer);
	// 82FCF1F4: 4099FE80  ble cr6, 0x82fcf074
	if !ctx.cr[6].gt {
	pc = 0x82FCF074; continue 'dispatch;
	}
	// 82FCF1F8: 2F170000  cmpwi cr6, r23, 0
	ctx.cr[6].compare_i32(ctx.r[23].s32, 0, &mut ctx.xer);
	// 82FCF1FC: 419A0090  beq cr6, 0x82fcf28c
	if ctx.cr[6].eq {
	pc = 0x82FCF28C; continue 'dispatch;
	}
	// 82FCF200: 7E4A9378  mr r10, r18
	ctx.r[10].u64 = ctx.r[18].u64;
	// 82FCF204: 809C0000  lwz r4, 0(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF208: 7E699B78  mr r9, r19
	ctx.r[9].u64 = ctx.r[19].u64;
	// 82FCF20C: FC40F890  fmr f2, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[31].f64;
	// 82FCF210: 7E88A378  mr r8, r20
	ctx.r[8].u64 = ctx.r[20].u64;
	// 82FCF214: FC20E890  fmr f1, f29
	ctx.f[1].f64 = ctx.f[29].f64;
	// 82FCF218: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82FCF21C: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCF220: 7E058378  mr r5, r16
	ctx.r[5].u64 = ctx.r[16].u64;
	// 82FCF224: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FCF228: 4BFFF309  bl 0x82fce530
	ctx.lr = 0x82FCF22C;
	sub_82FCE530(ctx, base);
	// 82FCF22C: 99C10077  stb r14, 0x77(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(119 as u32), ctx.r[14].u8 ) };
	// 82FCF230: 7E4A9378  mr r10, r18
	ctx.r[10].u64 = ctx.r[18].u64;
	// 82FCF234: 80BC0000  lwz r5, 0(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF238: 39210088  addi r9, r1, 0x88
	ctx.r[9].s64 = ctx.r[1].s64 + 136;
	// 82FCF23C: 9301005C  stw r24, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[24].u32 ) };
	// 82FCF240: 7FE8FB78  mr r8, r31
	ctx.r[8].u64 = ctx.r[31].u64;
	// 82FCF244: 93210054  stw r25, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[25].u32 ) };
	// 82FCF248: 7FC7F378  mr r7, r30
	ctx.r[7].u64 = ctx.r[30].u64;
	// 82FCF24C: FC40F090  fmr f2, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[2].f64 = ctx.f[30].f64;
	// 82FCF250: 7E068378  mr r6, r16
	ctx.r[6].u64 = ctx.r[16].u64;
	// 82FCF254: FC20F090  fmr f1, f30
	ctx.f[1].f64 = ctx.f[30].f64;
	// 82FCF258: 7E649B78  mr r4, r19
	ctx.r[4].u64 = ctx.r[19].u64;
	// 82FCF25C: 7E83A378  mr r3, r20
	ctx.r[3].u64 = ctx.r[20].u64;
	// 82FCF260: 4BFFB499  bl 0x82fca6f8
	ctx.lr = 0x82FCF264;
	sub_82FCA6F8(ctx, base);
	// 82FCF264: 39210088  addi r9, r1, 0x88
	ctx.r[9].s64 = ctx.r[1].s64 + 136;
	// 82FCF268: 7E489378  mr r8, r18
	ctx.r[8].u64 = ctx.r[18].u64;
	// 82FCF26C: 92610054  stw r19, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[19].u32 ) };
	// 82FCF270: 7E87A378  mr r7, r20
	ctx.r[7].u64 = ctx.r[20].u64;
	// 82FCF274: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCF278: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 82FCF27C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82FCF280: 7E048378  mr r4, r16
	ctx.r[4].u64 = ctx.r[16].u64;
	// 82FCF284: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82FCF288: 4BFFEB51  bl 0x82fcddd8
	ctx.lr = 0x82FCF28C;
	sub_82FCDDD8(ctx, base);
	// 82FCF28C: 55EB0000  rlwinm r11, r15, 0, 0, 0
	ctx.r[11].u64 = ctx.r[15].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF290: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCF294: 409A0018  bne cr6, 0x82fcf2ac
	if !ctx.cr[6].eq {
	pc = 0x82FCF2AC; continue 'dispatch;
	}
	// 82FCF298: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF29C: 7C75882E  lwzx r3, r21, r17
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[17].u32)) } as u64;
	// 82FCF2A0: 55E5103A  slwi r5, r15, 2
	ctx.r[5].u32 = ctx.r[15].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF2A4: 7EC4B378  mr r4, r22
	ctx.r[4].u64 = ctx.r[22].u64;
	// 82FCF2A8: 4BED1509  bl 0x82ea07b0
	ctx.lr = 0x82FCF2AC;
	sub_82EA07B0(ctx, base);
	// 82FCF2AC: 38210150  addi r1, r1, 0x150
	ctx.r[1].s64 = ctx.r[1].s64 + 336;
	// 82FCF2B0: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 82FCF2B4: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 82FCF2B8: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 82FCF2BC: 481D8EC4  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF2C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FCF2C0 size=200
    let mut pc: u32 = 0x82FCF2C0;
    'dispatch: loop {
        match pc {
            0x82FCF2C0 => {
    //   block [0x82FCF2C0..0x82FCF388)
	// 82FCF2C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCF2C4: 481D8E91  bl 0x831a8154
	ctx.lr = 0x82FCF2C8;
	sub_831A8130(ctx, base);
	// 82FCF2C8: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 82FCF2CC: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCF2D0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FCF2D4: 83AD0000  lwz r29, 0(r13)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF2D8: 3B800014  li r28, 0x14
	ctx.r[28].s64 = 20;
	// 82FCF2DC: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCF2E0: 3BFE0001  addi r31, r30, 1
	ctx.r[31].s64 = ctx.r[30].s64 + 1;
	// 82FCF2E4: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82FCF2E8: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 82FCF2EC: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCF2F0: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCF2F4: 7C7CE82E  lwzx r3, r28, r29
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82FCF2F8: 7CF93B78  mr r25, r7
	ctx.r[25].u64 = ctx.r[7].u64;
	// 82FCF2FC: 7D184378  mr r24, r8
	ctx.r[24].u64 = ctx.r[8].u64;
	// 82FCF300: 7D374B78  mr r23, r9
	ctx.r[23].u64 = ctx.r[9].u64;
	// 82FCF304: 4BED142D  bl 0x82ea0730
	ctx.lr = 0x82FCF308;
	sub_82EA0730(ctx, base);
	// 82FCF308: 90610068  stw r3, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[3].u32 ) };
	// 82FCF30C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCF310: 93E1006C  stw r31, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[31].u32 ) };
	// 82FCF314: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCF318: 93E10070  stw r31, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[31].u32 ) };
	// 82FCF31C: 38A10068  addi r5, r1, 0x68
	ctx.r[5].s64 = ctx.r[1].s64 + 104;
	// 82FCF320: 4BFFAA69  bl 0x82fc9d88
	ctx.lr = 0x82FCF324;
	sub_82FC9D88(ctx, base);
	// 82FCF324: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 82FCF328: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82FCF32C: 92E10054  stw r23, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[23].u32 ) };
	// 82FCF330: 7F0AC378  mr r10, r24
	ctx.r[10].u64 = ctx.r[24].u64;
	// 82FCF334: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCF338: 99210060  stb r9, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u8 ) };
	// 82FCF33C: 7F29CB78  mr r9, r25
	ctx.r[9].u64 = ctx.r[25].u64;
	// 82FCF340: 7F47D378  mr r7, r26
	ctx.r[7].u64 = ctx.r[26].u64;
	// 82FCF344: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF348: 38A10068  addi r5, r1, 0x68
	ctx.r[5].s64 = ctx.r[1].s64 + 104;
	// 82FCF34C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCF350: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCF354: 4BFFFA0D  bl 0x82fced60
	ctx.lr = 0x82FCF358;
	sub_82FCED60(ctx, base);
	// 82FCF358: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCF35C: 55680000  rlwinm r8, r11, 0, 0, 0
	ctx.r[8].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF360: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCF364: 409A0018  bne cr6, 0x82fcf37c
	if !ctx.cr[6].eq {
	pc = 0x82FCF37C; continue 'dispatch;
	}
	// 82FCF368: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF36C: 7C7CE82E  lwzx r3, r28, r29
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[28].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 82FCF370: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF374: 80810068  lwz r4, 0x68(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCF378: 4BED1439  bl 0x82ea07b0
	ctx.lr = 0x82FCF37C;
	sub_82EA07B0(ctx, base);
	// 82FCF37C: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82FCF380: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 82FCF384: 481D8E20  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF388(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCF388 size=368
    let mut pc: u32 = 0x82FCF388;
    'dispatch: loop {
        match pc {
            0x82FCF388 => {
    //   block [0x82FCF388..0x82FCF4F8)
	// 82FCF388: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCF38C: 481D8DC9  bl 0x831a8154
	ctx.lr = 0x82FCF390;
	sub_831A8130(ctx, base);
	// 82FCF390: DBE1FFA8  stfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-88 as u32), ctx.f[31].u64 ) };
	// 82FCF394: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCF398: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82FCF39C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCF3A0: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FCF3A4: 3FA08000  lis r29, -0x8000
	ctx.r[29].s64 = -2147483648;
	// 82FCF3A8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FCF3AC: 93C10068  stw r30, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[30].u32 ) };
	// 82FCF3B0: 7C9B2378  mr r27, r4
	ctx.r[27].u64 = ctx.r[4].u64;
	// 82FCF3B4: 93A10070  stw r29, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[29].u32 ) };
	// 82FCF3B8: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCF3BC: 7CDA3378  mr r26, r6
	ctx.r[26].u64 = ctx.r[6].u64;
	// 82FCF3C0: 7D194378  mr r25, r8
	ctx.r[25].u64 = ctx.r[8].u64;
	// 82FCF3C4: 7D384B78  mr r24, r9
	ctx.r[24].u64 = ctx.r[9].u64;
	// 82FCF3C8: 7D575378  mr r23, r10
	ctx.r[23].u64 = ctx.r[10].u64;
	// 82FCF3CC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCF3D0: 40990030  ble cr6, 0x82fcf400
	if !ctx.cr[6].gt {
	pc = 0x82FCF400; continue 'dispatch;
	}
	// 82FCF3D4: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF3D8: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FCF3DC: 5564103A  slwi r4, r11, 2
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCF3E0: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCF3E4: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCF3E8: 4BED1349  bl 0x82ea0730
	ctx.lr = 0x82FCF3EC;
	sub_82EA0730(ctx, base);
	// 82FCF3EC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCF3F0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FCF3F4: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 82FCF3F8: 93C10068  stw r30, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[30].u32 ) };
	// 82FCF3FC: 93A10070  stw r29, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[29].u32 ) };
	// 82FCF400: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 82FCF404: 80DF0000  lwz r6, 0(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF408: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FCF40C: 90E1006C  stw r7, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[7].u32 ) };
	// 82FCF410: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 82FCF414: 41980050  blt cr6, 0x82fcf464
	if ctx.cr[6].lt {
	pc = 0x82FCF464; continue 'dispatch;
	}
	// 82FCF418: 3967FFFC  addi r11, r7, -4
	ctx.r[11].s64 = ctx.r[7].s64 + -4;
	// 82FCF41C: 3946000C  addi r10, r6, 0xc
	ctx.r[10].s64 = ctx.r[6].s64 + 12;
	// 82FCF420: 5569F0BE  srwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCF424: 397E0004  addi r11, r30, 4
	ctx.r[11].s64 = ctx.r[30].s64 + 4;
	// 82FCF428: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCF42C: 7CBE3050  subf r5, r30, r6
	ctx.r[5].s64 = ctx.r[6].s64 - ctx.r[30].s64;
	// 82FCF430: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCF434: C00AFFF4  lfs f0, -0xc(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF438: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCF43C: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF440: 7DA55C2E  lfsx f13, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF444: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF448: C18AFFFC  lfs f12, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF44C: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF450: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF454: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCF458: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCF45C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCF460: 4082FFD4  bne 0x82fcf434
	if !ctx.cr[0].eq {
	pc = 0x82FCF434; continue 'dispatch;
	}
	// 82FCF464: 7F083800  cmpw cr6, r8, r7
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[7].s32, &mut ctx.xer);
	// 82FCF468: 40980028  bge cr6, 0x82fcf490
	if !ctx.cr[6].lt {
	pc = 0x82FCF490; continue 'dispatch;
	}
	// 82FCF46C: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCF470: 7D3E3050  subf r9, r30, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[30].s64;
	// 82FCF474: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82FCF478: 7D483850  subf r10, r8, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[8].s64;
	// 82FCF47C: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF480: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF484: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF488: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCF48C: 4082FFF0  bne 0x82fcf47c
	if !ctx.cr[0].eq {
	pc = 0x82FCF47C; continue 'dispatch;
	}
	// 82FCF490: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 82FCF494: 92E10054  stw r23, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[23].u32 ) };
	// 82FCF498: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FCF49C: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCF4A0: 7F0AC378  mr r10, r24
	ctx.r[10].u64 = ctx.r[24].u64;
	// 82FCF4A4: 99210060  stb r9, 0x60(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[9].u8 ) };
	// 82FCF4A8: 7F29CB78  mr r9, r25
	ctx.r[9].u64 = ctx.r[25].u64;
	// 82FCF4AC: 7F47D378  mr r7, r26
	ctx.r[7].u64 = ctx.r[26].u64;
	// 82FCF4B0: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF4B4: 38A10068  addi r5, r1, 0x68
	ctx.r[5].s64 = ctx.r[1].s64 + 104;
	// 82FCF4B8: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCF4BC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 82FCF4C0: 4BFFF8A1  bl 0x82fced60
	ctx.lr = 0x82FCF4C4;
	sub_82FCED60(ctx, base);
	// 82FCF4C4: 57A80000  rlwinm r8, r29, 0, 0, 0
	ctx.r[8].u64 = ctx.r[29].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF4C8: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCF4CC: 409A0020  bne cr6, 0x82fcf4ec
	if !ctx.cr[6].eq {
	pc = 0x82FCF4EC; continue 'dispatch;
	}
	// 82FCF4D0: 816D0000  lwz r11, 0(r13)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF4D4: 39400014  li r10, 0x14
	ctx.r[10].s64 = 20;
	// 82FCF4D8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF4DC: 57A5103A  slwi r5, r29, 2
	ctx.r[5].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF4E0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCF4E4: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FCF4E8: 4BED12C9  bl 0x82ea07b0
	ctx.lr = 0x82FCF4EC;
	sub_82EA07B0(ctx, base);
	// 82FCF4EC: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 82FCF4F0: CBE1FFA8  lfd f31, -0x58(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-88 as u32) ) };
	// 82FCF4F4: 481D8CB0  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF4F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCF4F8 size=852
    let mut pc: u32 = 0x82FCF4F8;
    'dispatch: loop {
        match pc {
            0x82FCF4F8 => {
    //   block [0x82FCF4F8..0x82FCF84C)
	// 82FCF4F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCF4FC: 481D8C4D  bl 0x831a8148
	ctx.lr = 0x82FCF500;
	sub_831A8130(ctx, base);
	// 82FCF500: DBE1FF90  stfd f31, -0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-112 as u32), ctx.f[31].u64 ) };
	// 82FCF504: 9421FEF0  stwu r1, -0x110(r1)
	ea = ctx.r[1].u32.wrapping_add(-272 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCF508: 82CD0000  lwz r22, 0(r13)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF50C: 3AA00014  li r21, 0x14
	ctx.r[21].s64 = 20;
	// 82FCF510: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCF514: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCF518: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FCF51C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82FCF520: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCF524: 57E42036  slwi r4, r31, 4
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(4);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCF528: 7C75B02E  lwzx r3, r21, r22
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF52C: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 82FCF530: 7D174378  mr r23, r8
	ctx.r[23].u64 = ctx.r[8].u64;
	// 82FCF534: 7D344B78  mr r20, r9
	ctx.r[20].u64 = ctx.r[9].u64;
	// 82FCF538: 7D5A5378  mr r26, r10
	ctx.r[26].u64 = ctx.r[10].u64;
	// 82FCF53C: 4BED11F5  bl 0x82ea0730
	ctx.lr = 0x82FCF540;
	sub_82EA0730(ctx, base);
	// 82FCF540: 7D75B02E  lwzx r11, r21, r22
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF544: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 82FCF548: 38A00017  li r5, 0x17
	ctx.r[5].s64 = 23;
	// 82FCF54C: 93E1008C  stw r31, 0x8c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(140 as u32), ctx.r[31].u32 ) };
	// 82FCF550: 57E4103A  slwi r4, r31, 2
	ctx.r[4].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FCF554: 93610088  stw r27, 0x88(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[27].u32 ) };
	// 82FCF558: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FCF55C: 93E10090  stw r31, 0x90(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[31].u32 ) };
	// 82FCF560: 4BED11D1  bl 0x82ea0730
	ctx.lr = 0x82FCF564;
	sub_82EA0730(ctx, base);
	// 82FCF564: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FCF568: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 82FCF56C: 93E1007C  stw r31, 0x7c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(124 as u32), ctx.r[31].u32 ) };
	// 82FCF570: 93810078  stw r28, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[28].u32 ) };
	// 82FCF574: 2F1F0004  cmpwi cr6, r31, 4
	ctx.cr[6].compare_i32(ctx.r[31].s32, 4, &mut ctx.xer);
	// 82FCF578: 7F06C378  mr r6, r24
	ctx.r[6].u64 = ctx.r[24].u64;
	// 82FCF57C: 93E10080  stw r31, 0x80(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[31].u32 ) };
	// 82FCF580: 419800E4  blt cr6, 0x82fcf664
	if ctx.cr[6].lt {
	pc = 0x82FCF664; continue 'dispatch;
	}
	// 82FCF584: 397FFFFC  addi r11, r31, -4
	ctx.r[11].s64 = ctx.r[31].s64 + -4;
	// 82FCF588: 391D000C  addi r8, r29, 0xc
	ctx.r[8].s64 = ctx.r[29].s64 + 12;
	// 82FCF58C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCF590: 393C0004  addi r9, r28, 4
	ctx.r[9].s64 = ctx.r[28].s64 + 4;
	// 82FCF594: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 82FCF598: 395E000C  addi r10, r30, 0xc
	ctx.r[10].s64 = ctx.r[30].s64 + 12;
	// 82FCF59C: 397B0004  addi r11, r27, 4
	ctx.r[11].s64 = ctx.r[27].s64 + 4;
	// 82FCF5A0: 7CBBF050  subf r5, r27, r30
	ctx.r[5].s64 = ctx.r[30].s64 - ctx.r[27].s64;
	// 82FCF5A4: 7C9CE850  subf r4, r28, r29
	ctx.r[4].s64 = ctx.r[29].s64 - ctx.r[28].s64;
	// 82FCF5A8: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCF5AC: C008FFF4  lfs f0, -0xc(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF5B0: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 82FCF5B4: D009FFFC  stfs f0, -4(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF5B8: C1AAFFF4  lfs f13, -0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF5BC: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF5C0: 7D855C2E  lfsx f12, r5, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF5C4: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF5C8: C16AFFFC  lfs f11, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF5CC: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF5D0: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCF5D4: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCF5D8: 7D244C2E  lfsx f9, r4, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCF5DC: D1290000  stfs f9, 0(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF5E0: C10A0004  lfs f8, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCF5E4: D10B000C  stfs f8, 0xc(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FCF5E8: C0EA0008  lfs f7, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCF5EC: D0EB0010  stfs f7, 0x10(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 82FCF5F0: C0CA000C  lfs f6, 0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCF5F4: D0CB0014  stfs f6, 0x14(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 82FCF5F8: C0AA0010  lfs f5, 0x10(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCF5FC: D0AB0018  stfs f5, 0x18(r11)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), tmp.u32 ) };
	// 82FCF600: C088FFFC  lfs f4, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCF604: D0890004  stfs f4, 4(r9)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF608: C06A0014  lfs f3, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 82FCF60C: D06B001C  stfs f3, 0x1c(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 82FCF610: C04A0018  lfs f2, 0x18(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCF614: D04B0020  stfs f2, 0x20(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(32 as u32), tmp.u32 ) };
	// 82FCF618: C02A001C  lfs f1, 0x1c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCF61C: D02B0024  stfs f1, 0x24(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(36 as u32), tmp.u32 ) };
	// 82FCF620: C00A0020  lfs f0, 0x20(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF624: D00B0028  stfs f0, 0x28(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 82FCF628: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF62C: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCF630: D1A90008  stfs f13, 8(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCF634: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FCF638: C18A0024  lfs f12, 0x24(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF63C: D18B002C  stfs f12, 0x2c(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 82FCF640: C16A0028  lfs f11, 0x28(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(40 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF644: D16B0030  stfs f11, 0x30(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), tmp.u32 ) };
	// 82FCF648: C14A002C  lfs f10, 0x2c(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(44 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCF64C: D14B0034  stfs f10, 0x34(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(52 as u32), tmp.u32 ) };
	// 82FCF650: C12A0030  lfs f9, 0x30(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(48 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCF654: 394A0040  addi r10, r10, 0x40
	ctx.r[10].s64 = ctx.r[10].s64 + 64;
	// 82FCF658: D12B0038  stfs f9, 0x38(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(56 as u32), tmp.u32 ) };
	// 82FCF65C: 396B0040  addi r11, r11, 0x40
	ctx.r[11].s64 = ctx.r[11].s64 + 64;
	// 82FCF660: 4082FF4C  bne 0x82fcf5ac
	if !ctx.cr[0].eq {
	pc = 0x82FCF5AC; continue 'dispatch;
	}
	// 82FCF664: 7F06F800  cmpw cr6, r6, r31
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[31].s32, &mut ctx.xer);
	// 82FCF668: 40980068  bge cr6, 0x82fcf6d0
	if !ctx.cr[6].lt {
	pc = 0x82FCF6D0; continue 'dispatch;
	}
	// 82FCF66C: 54CB2036  slwi r11, r6, 4
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(4);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCF670: 54C9103A  slwi r9, r6, 2
	ctx.r[9].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCF674: 7D4BF214  add r10, r11, r30
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 82FCF678: 7D6BDA14  add r11, r11, r27
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 82FCF67C: 7D29E214  add r9, r9, r28
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[28].u64;
	// 82FCF680: 394A000C  addi r10, r10, 0xc
	ctx.r[10].s64 = ctx.r[10].s64 + 12;
	// 82FCF684: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCF688: 7CFBF050  subf r7, r27, r30
	ctx.r[7].s64 = ctx.r[30].s64 - ctx.r[27].s64;
	// 82FCF68C: 7CBCE850  subf r5, r28, r29
	ctx.r[5].s64 = ctx.r[29].s64 - ctx.r[28].s64;
	// 82FCF690: 7D06F850  subf r8, r6, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[6].s64;
	// 82FCF694: 7C054C2E  lfsx f0, r5, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF698: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCF69C: D0090000  stfs f0, 0(r9)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF6A0: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FCF6A4: C1AAFFF4  lfs f13, -0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF6A8: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF6AC: 7D8B3C2E  lfsx f12, r11, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF6B0: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF6B4: C16AFFFC  lfs f11, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF6B8: D16B0004  stfs f11, 4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF6BC: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCF6C0: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCF6C4: D14B0008  stfs f10, 8(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCF6C8: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCF6CC: 4082FFC8  bne 0x82fcf694
	if !ctx.cr[0].eq {
	pc = 0x82FCF694; continue 'dispatch;
	}
	// 82FCF6D0: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 82FCF6D4: 93010058  stw r24, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[24].u32 ) };
	// 82FCF6D8: 9301005C  stw r24, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[24].u32 ) };
	// 82FCF6DC: 39410058  addi r10, r1, 0x58
	ctx.r[10].s64 = ctx.r[1].s64 + 88;
	// 82FCF6E0: 91610060  stw r11, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[11].u32 ) };
	// 82FCF6E4: 39210068  addi r9, r1, 0x68
	ctx.r[9].s64 = ctx.r[1].s64 + 104;
	// 82FCF6E8: 93010068  stw r24, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[24].u32 ) };
	// 82FCF6EC: 39010050  addi r8, r1, 0x50
	ctx.r[8].s64 = ctx.r[1].s64 + 80;
	// 82FCF6F0: 9301006C  stw r24, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[24].u32 ) };
	// 82FCF6F4: 7F26CB78  mr r6, r25
	ctx.r[6].u64 = ctx.r[25].u64;
	// 82FCF6F8: 91610070  stw r11, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[11].u32 ) };
	// 82FCF6FC: 38A10078  addi r5, r1, 0x78
	ctx.r[5].s64 = ctx.r[1].s64 + 120;
	// 82FCF700: 38810088  addi r4, r1, 0x88
	ctx.r[4].s64 = ctx.r[1].s64 + 136;
	// 82FCF704: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FCF708: 387FFFFF  addi r3, r31, -1
	ctx.r[3].s64 = ctx.r[31].s64 + -1;
	// 82FCF70C: 4BFFFC7D  bl 0x82fcf388
	ctx.lr = 0x82FCF710;
	sub_82FCF388(ctx, base);
	// 82FCF710: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FCF714: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82FCF718: 7F09C378  mr r9, r24
	ctx.r[9].u64 = ctx.r[24].u64;
	// 82FCF71C: 7D4BCA14  add r10, r11, r25
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[25].u64;
	// 82FCF720: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FCF724: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FCF728: 917A0000  stw r11, 0(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FCF72C: 91570000  stw r10, 0(r23)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 82FCF730: 811A0000  lwz r8, 0(r26)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF734: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCF738: 4099004C  ble cr6, 0x82fcf784
	if !ctx.cr[6].gt {
	pc = 0x82FCF784; continue 'dispatch;
	}
	// 82FCF73C: 81010164  lwz r8, 0x164(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(356 as u32) ) } as u64;
	// 82FCF740: 3944000C  addi r10, r4, 0xc
	ctx.r[10].s64 = ctx.r[4].s64 + 12;
	// 82FCF744: 39680004  addi r11, r8, 4
	ctx.r[11].s64 = ctx.r[8].s64 + 4;
	// 82FCF748: 7D082050  subf r8, r8, r4
	ctx.r[8].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 82FCF74C: C00AFFF4  lfs f0, -0xc(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF750: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FCF754: D00BFFFC  stfs f0, -4(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF758: 7DA85C2E  lfsx f13, r8, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF75C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF760: C18AFFFC  lfs f12, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF764: D18B0004  stfs f12, 4(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF768: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF76C: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCF770: D16B0008  stfs f11, 8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCF774: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCF778: 80FA0000  lwz r7, 0(r26)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF77C: 7F093800  cmpw cr6, r9, r7
	ctx.cr[6].compare_i32(ctx.r[9].s32, ctx.r[7].s32, &mut ctx.xer);
	// 82FCF780: 4198FFCC  blt cr6, 0x82fcf74c
	if ctx.cr[6].lt {
	pc = 0x82FCF74C; continue 'dispatch;
	}
	// 82FCF784: 81770000  lwz r11, 0(r23)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF788: 7F0AC378  mr r10, r24
	ctx.r[10].u64 = ctx.r[24].u64;
	// 82FCF78C: 81010068  lwz r8, 0x68(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FCF790: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCF794: 40990028  ble cr6, 0x82fcf7bc
	if !ctx.cr[6].gt {
	pc = 0x82FCF7BC; continue 'dispatch;
	}
	// 82FCF798: 7E8BA378  mr r11, r20
	ctx.r[11].u64 = ctx.r[20].u64;
	// 82FCF79C: 7D344050  subf r9, r20, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[20].s64;
	// 82FCF7A0: 7C095C2E  lfsx f0, r9, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF7A4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCF7A8: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF7AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCF7B0: 80F70000  lwz r7, 0(r23)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[23].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF7B4: 7F0A3800  cmpw cr6, r10, r7
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[7].s32, &mut ctx.xer);
	// 82FCF7B8: 4198FFE8  blt cr6, 0x82fcf7a0
	if ctx.cr[6].lt {
	pc = 0x82FCF7A0; continue 'dispatch;
	}
	// 82FCF7BC: 81610070  lwz r11, 0x70(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 82FCF7C0: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF7C4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF7C8: 409A001C  bne cr6, 0x82fcf7e4
	if !ctx.cr[6].eq {
	pc = 0x82FCF7E4; continue 'dispatch;
	}
	// 82FCF7CC: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF7D0: 7C75B02E  lwzx r3, r21, r22
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF7D4: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF7D8: 7D044378  mr r4, r8
	ctx.r[4].u64 = ctx.r[8].u64;
	// 82FCF7DC: 4BED0FD5  bl 0x82ea07b0
	ctx.lr = 0x82FCF7E0;
	sub_82EA07B0(ctx, base);
	// 82FCF7E0: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82FCF7E4: 81610060  lwz r11, 0x60(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FCF7E8: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF7EC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF7F0: 409A0014  bne cr6, 0x82fcf804
	if !ctx.cr[6].eq {
	pc = 0x82FCF804; continue 'dispatch;
	}
	// 82FCF7F4: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF7F8: 7C75B02E  lwzx r3, r21, r22
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF7FC: 55652036  slwi r5, r11, 4
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF800: 4BED0FB1  bl 0x82ea07b0
	ctx.lr = 0x82FCF804;
	sub_82EA07B0(ctx, base);
	// 82FCF804: 57FE0000  rlwinm r30, r31, 0, 0, 0
	ctx.r[30].u64 = ctx.r[31].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF808: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCF80C: 409A0034  bne cr6, 0x82fcf840
	if !ctx.cr[6].eq {
	pc = 0x82FCF840; continue 'dispatch;
	}
	// 82FCF810: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF814: 7C75B02E  lwzx r3, r21, r22
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF818: 57E5103A  slwi r5, r31, 2
	ctx.r[5].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF81C: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCF820: 4BED0F91  bl 0x82ea07b0
	ctx.lr = 0x82FCF824;
	sub_82EA07B0(ctx, base);
	// 82FCF824: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCF828: 409A0018  bne cr6, 0x82fcf840
	if !ctx.cr[6].eq {
	pc = 0x82FCF840; continue 'dispatch;
	}
	// 82FCF82C: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF830: 7C75B02E  lwzx r3, r21, r22
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[21].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 82FCF834: 57E52036  slwi r5, r31, 4
	ctx.r[5].u32 = ctx.r[31].u32.wrapping_shl(4);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF838: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FCF83C: 4BED0F75  bl 0x82ea07b0
	ctx.lr = 0x82FCF840;
	sub_82EA07B0(ctx, base);
	// 82FCF840: 38210110  addi r1, r1, 0x110
	ctx.r[1].s64 = ctx.r[1].s64 + 272;
	// 82FCF844: CBE1FF90  lfd f31, -0x70(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-112 as u32) ) };
	// 82FCF848: 481D8950  b 0x831a8198
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF850(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FCF850 size=40
    let mut pc: u32 = 0x82FCF850;
    'dispatch: loop {
        match pc {
            0x82FCF850 => {
    //   block [0x82FCF850..0x82FCF878)
	// 82FCF850: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCF854: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FCF858: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCF85C: 816100B4  lwz r11, 0xb4(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(180 as u32) ) } as u64;
	// 82FCF860: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 82FCF864: 4BFFFC95  bl 0x82fcf4f8
	ctx.lr = 0x82FCF868;
	sub_82FCF4F8(ctx, base);
	// 82FCF868: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FCF86C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCF870: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FCF874: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF878(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FCF878 size=20
    let mut pc: u32 = 0x82FCF878;
    'dispatch: loop {
        match pc {
            0x82FCF878 => {
    //   block [0x82FCF878..0x82FCF88C)
	// 82FCF878: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCF87C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FCF880: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCF884: 7D0959D7  mullw. r8, r9, r11
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCF888: 4C810020  blelr
	if !ctx.cr[0].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF88C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCF88C size=64
    let mut pc: u32 = 0x82FCF88C;
    'dispatch: loop {
        match pc {
            0x82FCF88C => {
    //   block [0x82FCF88C..0x82FCF8CC)
	// 82FCF88C: 81040000  lwz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF890: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCF894: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF898: 7C0B442E  lfsx f0, r11, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF89C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCF8A0: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCF8A4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCF8A8: C1A90000  lfs f13, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF8AC: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FCF8B0: D1890000  stfs f12, 0(r9)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCF8B4: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCF8B8: 80E30010  lwz r7, 0x10(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCF8BC: 7CC939D6  mullw r6, r9, r7
	ctx.r[6].s64 = (ctx.r[9].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCF8C0: 7F0A3000  cmpw cr6, r10, r6
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FCF8C4: 4198FFD0  blt cr6, 0x82fcf894
	if ctx.cr[6].lt {
	pc = 0x82FCF894; continue 'dispatch;
	}
	// 82FCF8C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF8D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCF8D0 size=124
    let mut pc: u32 = 0x82FCF8D0;
    'dispatch: loop {
        match pc {
            0x82FCF8D0 => {
    //   block [0x82FCF8D0..0x82FCF94C)
	// 82FCF8D0: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCF8D4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82FCF8D8: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCF8DC: 7CEB51D6  mullw r7, r11, r10
	ctx.r[7].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82FCF8E0: 2F070004  cmpwi cr6, r7, 4
	ctx.cr[6].compare_i32(ctx.r[7].s32, 4, &mut ctx.xer);
	// 82FCF8E4: 41980060  blt cr6, 0x82fcf944
	if ctx.cr[6].lt {
	pc = 0x82FCF944; continue 'dispatch;
	}
	// 82FCF8E8: 3947FFFC  addi r10, r7, -4
	ctx.r[10].s64 = ctx.r[7].s64 + -4;
	// 82FCF8EC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FCF8F0: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCF8F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCF8F8: 5546103A  slwi r6, r10, 2
	ctx.r[6].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FCF8FC: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF900: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF904: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 82FCF908: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF90C: 7C0B452E  stfsx f0, r11, r8
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCF910: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF914: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCF918: 7CAB4214  add r5, r11, r8
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCF91C: D1A50004  stfs f13, 4(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCF920: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF924: C1840000  lfs f12, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCF928: 7D094214  add r8, r9, r8
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82FCF92C: D188FFFC  stfs f12, -4(r8)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCF930: 80A30000  lwz r5, 0(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF934: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCF938: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCF93C: 7D692D2E  stfsx f11, r9, r5
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[5].u32), tmp.u32) };
	// 82FCF940: 4082FFBC  bne 0x82fcf8fc
	if !ctx.cr[0].eq {
	pc = 0x82FCF8FC; continue 'dispatch;
	}
	// 82FCF944: 7F063800  cmpw cr6, r6, r7
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[7].s32, &mut ctx.xer);
	// 82FCF948: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF94C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCF94C size=36
    let mut pc: u32 = 0x82FCF94C;
    'dispatch: loop {
        match pc {
            0x82FCF94C => {
    //   block [0x82FCF94C..0x82FCF970)
	// 82FCF94C: 54CA103A  slwi r10, r6, 2
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCF950: 7D663850  subf r11, r6, r7
	ctx.r[11].s64 = ctx.r[7].s64 - ctx.r[6].s64;
	// 82FCF954: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF958: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCF95C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCF960: 7C0A4D2E  stfsx f0, r10, r9
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCF964: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCF968: 4082FFEC  bne 0x82fcf954
	if !ctx.cr[0].eq {
	pc = 0x82FCF954; continue 'dispatch;
	}
	// 82FCF96C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCF970(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FCF970 size=172
    let mut pc: u32 = 0x82FCF970;
    'dispatch: loop {
        match pc {
            0x82FCF970 => {
    //   block [0x82FCF970..0x82FCFA1C)
	// 82FCF970: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCF974: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FCF978: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FCF97C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCF980: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCF984: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 82FCF988: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF98C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF990: 409A0020  bne cr6, 0x82fcf9b0
	if !ctx.cr[6].eq {
	pc = 0x82FCF9B0; continue 'dispatch;
	}
	// 82FCF994: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF998: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FCF99C: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF9A0: 809F0018  lwz r4, 0x18(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FCF9A4: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF9A8: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCF9AC: 4BED0E05  bl 0x82ea07b0
	ctx.lr = 0x82FCF9B0;
	sub_82EA07B0(ctx, base);
	// 82FCF9B0: 817F0014  lwz r11, 0x14(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCF9B4: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF9B8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF9BC: 409A0020  bne cr6, 0x82fcf9dc
	if !ctx.cr[6].eq {
	pc = 0x82FCF9DC; continue 'dispatch;
	}
	// 82FCF9C0: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF9C4: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FCF9C8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF9CC: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCF9D0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCF9D4: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCF9D8: 4BED0DD9  bl 0x82ea07b0
	ctx.lr = 0x82FCF9DC;
	sub_82EA07B0(ctx, base);
	// 82FCF9DC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCF9E0: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FCF9E4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCF9E8: 409A0020  bne cr6, 0x82fcfa08
	if !ctx.cr[6].eq {
	pc = 0x82FCFA08; continue 'dispatch;
	}
	// 82FCF9EC: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF9F0: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FCF9F4: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FCF9F8: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCF9FC: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FCFA00: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FCFA04: 4BED0DAD  bl 0x82ea07b0
	ctx.lr = 0x82FCFA08;
	sub_82EA07B0(ctx, base);
	// 82FCFA08: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FCFA0C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCFA10: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FCFA14: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FCFA18: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFA20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCFA20 size=248
    let mut pc: u32 = 0x82FCFA20;
    'dispatch: loop {
        match pc {
            0x82FCFA20 => {
    //   block [0x82FCFA20..0x82FCFB18)
	// 82FCFA20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFA24: 481D8741  bl 0x831a8164
	ctx.lr = 0x82FCFA28;
	sub_831A8130(ctx, base);
	// 82FCFA28: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 82FCFA2C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCFA30: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCFA34: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FCFA38: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FCFA3C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FCFA40: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 82FCFA44: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFA48: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 82FCFA4C: 419A00C0  beq cr6, 0x82fcfb0c
	if ctx.cr[6].eq {
	pc = 0x82FCFB0C; continue 'dispatch;
	}
	// 82FCFA50: 817D0014  lwz r11, 0x14(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FCFA54: 3BDD000C  addi r30, r29, 0xc
	ctx.r[30].s64 = ctx.r[29].s64 + 12;
	// 82FCFA58: 815D0010  lwz r10, 0x10(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFA5C: 556900BE  clrlwi r9, r11, 2
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCFA60: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FCFA64: 409A0010  bne cr6, 0x82fcfa74
	if !ctx.cr[6].eq {
	pc = 0x82FCFA74; continue 'dispatch;
	}
	// 82FCFA68: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 82FCFA6C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FCFA70: 4BED6E11  bl 0x82ea6880
	ctx.lr = 0x82FCFA74;
	sub_82EA6880(ctx, base);
	// 82FCFA74: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFA78: 3BFD0018  addi r31, r29, 0x18
	ctx.r[31].s64 = ctx.r[29].s64 + 24;
	// 82FCFA7C: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFA80: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCFA84: 7F89512E  stwx r28, r9, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32), ctx.r[28].u32) };
	// 82FCFA88: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFA8C: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 82FCFA90: 911E0004  stw r8, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCFA94: 80FD001C  lwz r7, 0x1c(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(28 as u32) ) } as u64;
	// 82FCFA98: 80DD0020  lwz r6, 0x20(r29)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(32 as u32) ) } as u64;
	// 82FCFA9C: 54C500BE  clrlwi r5, r6, 2
	ctx.r[5].u64 = ctx.r[6].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCFAA0: 7F072800  cmpw cr6, r7, r5
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FCFAA4: 409A0010  bne cr6, 0x82fcfab4
	if !ctx.cr[6].eq {
	pc = 0x82FCFAB4; continue 'dispatch;
	}
	// 82FCFAA8: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 82FCFAAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFAB0: 4BED6DD1  bl 0x82ea6880
	ctx.lr = 0x82FCFAB4;
	sub_82EA6880(ctx, base);
	// 82FCFAB4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFAB8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFABC: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCFAC0: 7F69512E  stwx r27, r9, r10
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32), ctx.r[27].u32) };
	// 82FCFAC4: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFAC8: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 82FCFACC: 911F0004  stw r8, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCFAD0: 80FD0008  lwz r7, 8(r29)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FCFAD4: 54E600BE  clrlwi r6, r7, 2
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x3FFFFFFFu64;
	// 82FCFAD8: 80BD0004  lwz r5, 4(r29)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFADC: 7F053000  cmpw cr6, r5, r6
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FCFAE0: 409A0010  bne cr6, 0x82fcfaf0
	if !ctx.cr[6].eq {
	pc = 0x82FCFAF0; continue 'dispatch;
	}
	// 82FCFAE4: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 82FCFAE8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FCFAEC: 4BED6D95  bl 0x82ea6880
	ctx.lr = 0x82FCFAF0;
	sub_82EA6880(ctx, base);
	// 82FCFAF0: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFAF4: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFAF8: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCFAFC: 7FE9552E  stfsx f31, r9, r10
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCFB00: 817D0004  lwz r11, 4(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FCFB04: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 82FCFB08: 911D0004  stw r8, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[8].u32 ) };
	// 82FCFB0C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82FCFB10: CBE1FFC8  lfd f31, -0x38(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 82FCFB14: 481D86A0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFB18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCFB18 size=232
    let mut pc: u32 = 0x82FCFB18;
    'dispatch: loop {
        match pc {
            0x82FCFB18 => {
    //   block [0x82FCFB18..0x82FCFC00)
	// 82FCFB18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFB1C: 481D8651  bl 0x831a816c
	ctx.lr = 0x82FCFB20;
	sub_831A8130(ctx, base);
	// 82FCFB20: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 82FCFB24: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCFB28: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCFB2C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FCFB30: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82FCFB34: 7FC429D6  mullw r30, r4, r5
	ctx.r[30].s64 = (ctx.r[4].s32 as i64) * (ctx.r[5].s32 as i64);
	// 82FCFB38: 909F000C  stw r4, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 82FCFB3C: 90BF0010  stw r5, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[5].u32 ) };
	// 82FCFB40: 93BF0000  stw r29, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 82FCFB44: 93BF0004  stw r29, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 82FCFB48: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 82FCFB4C: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCFB50: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FCFB54: 4099001C  ble cr6, 0x82fcfb70
	if !ctx.cr[6].gt {
	pc = 0x82FCFB70; continue 'dispatch;
	}
	// 82FCFB58: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FCFB5C: 41980008  blt cr6, 0x82fcfb64
	if ctx.cr[6].lt {
	pc = 0x82FCFB64; continue 'dispatch;
	}
	// 82FCFB60: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCFB64: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCFB68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFB6C: 4BED6C8D  bl 0x82ea67f8
	ctx.lr = 0x82FCFB70;
	sub_82EA67F8(ctx, base);
	// 82FCFB70: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FCFB74: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 82FCFB78: 2F1E0004  cmpwi cr6, r30, 4
	ctx.cr[6].compare_i32(ctx.r[30].s32, 4, &mut ctx.xer);
	// 82FCFB7C: 41980050  blt cr6, 0x82fcfbcc
	if ctx.cr[6].lt {
	pc = 0x82FCFBCC; continue 'dispatch;
	}
	// 82FCFB80: 395EFFFC  addi r10, r30, -4
	ctx.r[10].s64 = ctx.r[30].s64 + -4;
	// 82FCFB84: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FCFB88: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCFB8C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCFB90: 5547103A  slwi r7, r10, 2
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FCFB94: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFB98: 392B000C  addi r9, r11, 0xc
	ctx.r[9].s64 = ctx.r[11].s64 + 12;
	// 82FCFB9C: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCFBA0: 7FEB452E  stfsx f31, r11, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCFBA4: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFBA8: 7CCB4214  add r6, r11, r8
	ctx.r[6].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 82FCFBAC: D3E60004  stfs f31, 4(r6)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCFBB0: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFBB4: 7CA94214  add r5, r9, r8
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[8].u64;
	// 82FCFBB8: D3E5FFFC  stfs f31, -4(r5)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCFBBC: 809F0000  lwz r4, 0(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFBC0: 7FE9252E  stfsx f31, r9, r4
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[4].u32), tmp.u32) };
	// 82FCFBC4: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCFBC8: 4082FFCC  bne 0x82fcfb94
	if !ctx.cr[0].eq {
	pc = 0x82FCFB94; continue 'dispatch;
	}
	// 82FCFBCC: 7F07F000  cmpw cr6, r7, r30
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FCFBD0: 40980020  bge cr6, 0x82fcfbf0
	if !ctx.cr[6].lt {
	pc = 0x82FCFBF0; continue 'dispatch;
	}
	// 82FCFBD4: 54EA103A  slwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FCFBD8: 7D67F050  subf r11, r7, r30
	ctx.r[11].s64 = ctx.r[30].s64 - ctx.r[7].s64;
	// 82FCFBDC: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFBE0: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FCFBE4: 7FEA4D2E  stfsx f31, r10, r9
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FCFBE8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FCFBEC: 4082FFF0  bne 0x82fcfbdc
	if !ctx.cr[0].eq {
	pc = 0x82FCFBDC; continue 'dispatch;
	}
	// 82FCFBF0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFBF4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FCFBF8: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 82FCFBFC: 481D85C0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFC00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FCFC00 size=120
    let mut pc: u32 = 0x82FCFC00;
    'dispatch: loop {
        match pc {
            0x82FCFC00 => {
    //   block [0x82FCFC00..0x82FCFC78)
	// 82FCFC00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFC04: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FCFC08: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FCFC0C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FCFC10: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCFC14: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCFC18: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 82FCFC1C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FCFC20: 3D408000  lis r10, -0x8000
	ctx.r[10].s64 = -2147483648;
	// 82FCFC24: 7FCB29D7  mullw. r30, r11, r5
	ctx.r[30].s64 = (ctx.r[11].s32 as i64) * (ctx.r[5].s32 as i64);
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCFC28: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 82FCFC2C: 90BF0010  stw r5, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[5].u32 ) };
	// 82FCFC30: 909F0000  stw r4, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[4].u32 ) };
	// 82FCFC34: 909F0004  stw r4, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 82FCFC38: 915F0008  stw r10, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 82FCFC3C: 4081001C  ble 0x82fcfc58
	if !ctx.cr[0].gt {
	pc = 0x82FCFC58; continue 'dispatch;
	}
	// 82FCFC40: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCFC44: 41980008  blt cr6, 0x82fcfc4c
	if ctx.cr[6].lt {
	pc = 0x82FCFC4C; continue 'dispatch;
	}
	// 82FCFC48: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCFC4C: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCFC50: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFC54: 4BED6BA5  bl 0x82ea67f8
	ctx.lr = 0x82FCFC58;
	sub_82EA67F8(ctx, base);
	// 82FCFC58: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FCFC5C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFC60: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FCFC64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FCFC68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FCFC6C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FCFC70: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FCFC74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFC78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FCFC78 size=180
    let mut pc: u32 = 0x82FCFC78;
    'dispatch: loop {
        match pc {
            0x82FCFC78 => {
    //   block [0x82FCFC78..0x82FCFD2C)
	// 82FCFC78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFC7C: 481D84ED  bl 0x831a8168
	ctx.lr = 0x82FCFC80;
	sub_831A8130(ctx, base);
	// 82FCFC80: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FCFC84: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FCFC88: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FCFC8C: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 82FCFC90: 3D608000  lis r11, -0x8000
	ctx.r[11].s64 = -2147483648;
	// 82FCFC94: 939F0000  stw r28, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[28].u32 ) };
	// 82FCFC98: 939F0004  stw r28, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[28].u32 ) };
	// 82FCFC9C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FCFCA0: 815D000C  lwz r10, 0xc(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFCA4: 5549003E  slwi r9, r10, 0
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCFCA8: 915F000C  stw r10, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 82FCFCAC: 811D0010  lwz r8, 0x10(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFCB0: 7FC941D7  mullw. r30, r9, r8
	ctx.r[30].s64 = (ctx.r[9].s32 as i64) * (ctx.r[8].s32 as i64);
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCFCB4: 911F0010  stw r8, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[8].u32 ) };
	// 82FCFCB8: 40810020  ble 0x82fcfcd8
	if !ctx.cr[0].gt {
	pc = 0x82FCFCD8; continue 'dispatch;
	}
	// 82FCFCBC: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FCFCC0: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FCFCC4: 41980008  blt cr6, 0x82fcfccc
	if ctx.cr[6].lt {
	pc = 0x82FCFCCC; continue 'dispatch;
	}
	// 82FCFCC8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FCFCCC: 38A00004  li r5, 4
	ctx.r[5].s64 = 4;
	// 82FCFCD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFCD4: 4BED6B25  bl 0x82ea67f8
	ctx.lr = 0x82FCFCD8;
	sub_82EA67F8(ctx, base);
	// 82FCFCD8: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFCDC: 7F8AE378  mr r10, r28
	ctx.r[10].u64 = ctx.r[28].u64;
	// 82FCFCE0: 813F000C  lwz r9, 0xc(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFCE4: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 82FCFCE8: 7D0B49D7  mullw. r8, r11, r9
	ctx.r[8].s64 = (ctx.r[11].s32 as i64) * (ctx.r[9].s32 as i64);
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FCFCEC: 40810034  ble 0x82fcfd20
	if !ctx.cr[0].gt {
	pc = 0x82FCFD20; continue 'dispatch;
	}
	// 82FCFCF0: 7F8BE378  mr r11, r28
	ctx.r[11].u64 = ctx.r[28].u64;
	// 82FCFCF4: 813D0000  lwz r9, 0(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFCF8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FCFCFC: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFD00: 7C095C2E  lfsx f0, r9, r11
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFD04: 7C0B452E  stfsx f0, r11, r8
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FCFD08: 80FF000C  lwz r7, 0xc(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFD0C: 80DF0010  lwz r6, 0x10(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFD10: 7CA639D6  mullw r5, r6, r7
	ctx.r[5].s64 = (ctx.r[6].s32 as i64) * (ctx.r[7].s32 as i64);
	// 82FCFD14: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCFD18: 7F0A2800  cmpw cr6, r10, r5
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FCFD1C: 4198FFD8  blt cr6, 0x82fcfcf4
	if ctx.cr[6].lt {
	pc = 0x82FCFCF4; continue 'dispatch;
	}
	// 82FCFD20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FCFD24: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FCFD28: 481D8490  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFD30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCFD30 size=140
    let mut pc: u32 = 0x82FCFD30;
    'dispatch: loop {
        match pc {
            0x82FCFD30 => {
    //   block [0x82FCFD30..0x82FCFDBC)
	// 82FCFD30: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFD34: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 82FCFD38: 8123000C  lwz r9, 0xc(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFD3C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FCFD40: 7CCB49D6  mullw r6, r11, r9
	ctx.r[6].s64 = (ctx.r[11].s32 as i64) * (ctx.r[9].s32 as i64);
	// 82FCFD44: C02A08A4  lfs f1, 0x8a4(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCFD48: 2F060004  cmpwi cr6, r6, 4
	ctx.cr[6].compare_i32(ctx.r[6].s32, 4, &mut ctx.xer);
	// 82FCFD4C: 41980068  blt cr6, 0x82fcfdb4
	if ctx.cr[6].lt {
	pc = 0x82FCFDB4; continue 'dispatch;
	}
	// 82FCFD50: 3966FFFC  addi r11, r6, -4
	ctx.r[11].s64 = ctx.r[6].s64 + -4;
	// 82FCFD54: 80E40000  lwz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFD58: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFD5C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCFD60: 3948000C  addi r10, r8, 0xc
	ctx.r[10].s64 = ctx.r[8].s64 + 12;
	// 82FCFD64: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FCFD68: 39670004  addi r11, r7, 4
	ctx.r[11].s64 = ctx.r[7].s64 + 4;
	// 82FCFD6C: 7CE74050  subf r7, r7, r8
	ctx.r[7].s64 = ctx.r[8].s64 - ctx.r[7].s64;
	// 82FCFD70: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 82FCFD74: C00BFFFC  lfs f0, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFD78: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCFD7C: C1AAFFF4  lfs f13, -0xc(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFD80: ED800B7A  fmadds f12, f0, f13, f1
	ctx.f[12].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FCFD84: 7D675C2E  lfsx f11, r7, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FCFD88: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCFD8C: C12B0004  lfs f9, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCFD90: C10AFFFC  lfs f8, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCFD94: C0EB0008  lfs f7, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 82FCFD98: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCFD9C: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCFDA0: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCFDA4: ECAB62BA  fmadds f5, f11, f10, f12
	ctx.f[5].f64 = (((ctx.f[11].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCFDA8: EC892A3A  fmadds f4, f9, f8, f5
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[8].f64 + ctx.f[5].f64) as f32) as f64);
	// 82FCFDAC: EC2721BA  fmadds f1, f7, f6, f4
	ctx.f[1].f64 = (((ctx.f[7].f64 * ctx.f[6].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCFDB0: 4082FFC4  bne 0x82fcfd74
	if !ctx.cr[0].eq {
	pc = 0x82FCFD74; continue 'dispatch;
	}
	// 82FCFDB4: 7F083000  cmpw cr6, r8, r6
	ctx.cr[6].compare_i32(ctx.r[8].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FCFDB8: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFDBC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCFDBC size=52
    let mut pc: u32 = 0x82FCFDBC;
    'dispatch: loop {
        match pc {
            0x82FCFDBC => {
    //   block [0x82FCFDBC..0x82FCFDF0)
	// 82FCFDBC: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFDC0: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCFDC4: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFDC8: 7D483050  subf r10, r8, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[8].s64;
	// 82FCFDCC: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FCFDD0: 7D293850  subf r9, r9, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[9].s64;
	// 82FCFDD4: 7C0B4C2E  lfsx f0, r11, r9
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFDD8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCFDDC: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFDE0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCFDE4: EC200B7A  fmadds f1, f0, f13, f1
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 82FCFDE8: 4082FFEC  bne 0x82fcfdd4
	if !ctx.cr[0].eq {
	pc = 0x82FCFDD4; continue 'dispatch;
	}
	// 82FCFDEC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFDF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCFDF0 size=284
    let mut pc: u32 = 0x82FCFDF0;
    'dispatch: loop {
        match pc {
            0x82FCFDF0 => {
    //   block [0x82FCFDF0..0x82FCFF0C)
	// 82FCFDF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFDF4: 481D8365  bl 0x831a8158
	ctx.lr = 0x82FCFDF8;
	sub_831A8130(ctx, base);
	// 82FCFDF8: 81640010  lwz r11, 0x10(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFDFC: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 82FCFE00: 8144000C  lwz r10, 0xc(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFE04: 7F4B51D6  mullw r26, r11, r10
	ctx.r[26].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82FCFE08: 2F1A0004  cmpwi cr6, r26, 4
	ctx.cr[6].compare_i32(ctx.r[26].s32, 4, &mut ctx.xer);
	// 82FCFE0C: 419800B4  blt cr6, 0x82fcfec0
	if ctx.cr[6].lt {
	pc = 0x82FCFEC0; continue 'dispatch;
	}
	// 82FCFE10: 397AFFFC  addi r11, r26, -4
	ctx.r[11].s64 = ctx.r[26].s64 + -4;
	// 82FCFE14: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFE18: 80E60000  lwz r7, 0(r6)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFE1C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCFE20: 23E80004  subfic r31, r8, 4
	ctx.xer.ca = ctx.r[8].u32 <= 4 as u32;
	ctx.r[31].s64 = (4 as i64) - ctx.r[8].s64;
	// 82FCFE24: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FCFE28: 23C80008  subfic r30, r8, 8
	ctx.xer.ca = ctx.r[8].u32 <= 8 as u32;
	ctx.r[30].s64 = (8 as i64) - ctx.r[8].s64;
	// 82FCFE2C: 3947000C  addi r10, r7, 0xc
	ctx.r[10].s64 = ctx.r[7].s64 + 12;
	// 82FCFE30: 39680004  addi r11, r8, 4
	ctx.r[11].s64 = ctx.r[8].s64 + 4;
	// 82FCFE34: 7FA83850  subf r29, r8, r7
	ctx.r[29].s64 = ctx.r[7].s64 - ctx.r[8].s64;
	// 82FCFE38: 2388FFFC  subfic r28, r8, -4
	ctx.xer.ca = ctx.r[8].u32 <= -4 as u32;
	ctx.r[28].s64 = (-4 as i64) - ctx.r[8].s64;
	// 82FCFE3C: 553B103A  slwi r27, r9, 2
	ctx.r[27].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[27].u64 = ctx.r[27].u32 as u64;
	// 82FCFE40: 80E40000  lwz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFE44: 7D1C5A14  add r8, r28, r11
	ctx.r[8].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 82FCFE48: C00AFFF4  lfs f0, -0xc(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFE4C: 7F3F5A14  add r25, r31, r11
	ctx.r[25].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 82FCFE50: C1A50000  lfs f13, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFE54: 7F1E5A14  add r24, r30, r11
	ctx.r[24].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FCFE58: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCFE5C: 7D883C2E  lfsx f12, r8, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCFE60: ED60637A  fmadds f11, f0, f13, f12
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCFE64: D16BFFFC  stfs f11, -4(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FCFE68: 7D5D5C2E  lfsx f10, r29, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCFE6C: 80E40000  lwz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFE70: C1250000  lfs f9, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCFE74: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82FCFE78: C1080004  lfs f8, 4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCFE7C: ECEA427A  fmadds f7, f10, f9, f8
	ctx.f[7].f64 = (((ctx.f[10].f64 * ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FCFE80: D0EB0000  stfs f7, 0(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCFE84: 80E40000  lwz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFE88: C0CAFFFC  lfs f6, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCFE8C: C0A50000  lfs f5, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCFE90: 7C993C2E  lfsx f4, r25, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[25].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCFE94: EC66217A  fmadds f3, f6, f5, f4
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCFE98: D06B0004  stfs f3, 4(r11)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCFE9C: 81040000  lwz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFEA0: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCFEA4: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 82FCFEA8: C0250000  lfs f1, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCFEAC: 7C18442E  lfsx f0, r24, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFEB0: EDA100BA  fmadds f13, f1, f2, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[2].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FCFEB4: D1AB0008  stfs f13, 8(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FCFEB8: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCFEBC: 4082FF84  bne 0x82fcfe40
	if !ctx.cr[0].eq {
	pc = 0x82FCFE40; continue 'dispatch;
	}
	// 82FCFEC0: 7F1BD000  cmpw cr6, r27, r26
	ctx.cr[6].compare_i32(ctx.r[27].s32, ctx.r[26].s32, &mut ctx.xer);
	// 82FCFEC4: 40980044  bge cr6, 0x82fcff08
	if !ctx.cr[6].lt {
	pc = 0x82FCFF08; continue 'dispatch;
	}
	// 82FCFEC8: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFECC: 5769103A  slwi r9, r27, 2
	ctx.r[9].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FCFED0: 80E60000  lwz r7, 0(r6)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFED4: 7D5BD050  subf r10, r27, r26
	ctx.r[10].s64 = ctx.r[26].s64 - ctx.r[27].s64;
	// 82FCFED8: 7D684A14  add r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 82FCFEDC: 7D083850  subf r8, r8, r7
	ctx.r[8].s64 = ctx.r[7].s64 - ctx.r[8].s64;
	// 82FCFEE0: 80E40000  lwz r7, 0(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFEE4: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFEE8: C1A50000  lfs f13, 0(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFEEC: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCFEF0: 7D893C2E  lfsx f12, r9, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCFEF4: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 82FCFEF8: ED60637A  fmadds f11, f0, f13, f12
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCFEFC: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCFF00: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FCFF04: 4082FFDC  bne 0x82fcfee0
	if !ctx.cr[0].eq {
	pc = 0x82FCFEE0; continue 'dispatch;
	}
	// 82FCFF08: 481D82A0  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FCFF10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FCFF10 size=264
    let mut pc: u32 = 0x82FCFF10;
    'dispatch: loop {
        match pc {
            0x82FCFF10 => {
    //   block [0x82FCFF10..0x82FD0018)
	// 82FCFF10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FCFF14: 481D8255  bl 0x831a8168
	ctx.lr = 0x82FCFF18;
	sub_831A8130(ctx, base);
	// 82FCFF18: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FCFF1C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82FCFF20: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FCFF24: 7F8B51D6  mullw r28, r11, r10
	ctx.r[28].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82FCFF28: 2F1C0004  cmpwi cr6, r28, 4
	ctx.cr[6].compare_i32(ctx.r[28].s32, 4, &mut ctx.xer);
	// 82FCFF2C: 419800AC  blt cr6, 0x82fcffd8
	if ctx.cr[6].lt {
	pc = 0x82FCFFD8; continue 'dispatch;
	}
	// 82FCFF30: 397CFFFC  addi r11, r28, -4
	ctx.r[11].s64 = ctx.r[28].s64 + -4;
	// 82FCFF34: 81450000  lwz r10, 0(r5)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFF38: 39000008  li r8, 8
	ctx.r[8].s64 = 8;
	// 82FCFF3C: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCFF40: 23EA0004  subfic r31, r10, 4
	ctx.xer.ca = ctx.r[10].u32 <= 4 as u32;
	ctx.r[31].s64 = (4 as i64) - ctx.r[10].s64;
	// 82FCFF44: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 82FCFF48: 396A0008  addi r11, r10, 8
	ctx.r[11].s64 = ctx.r[10].s64 + 8;
	// 82FCFF4C: 23CAFFF8  subfic r30, r10, -8
	ctx.xer.ca = ctx.r[10].u32 <= -8 as u32;
	ctx.r[30].s64 = (-8 as i64) - ctx.r[10].s64;
	// 82FCFF50: 553D103A  slwi r29, r9, 2
	ctx.r[29].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 82FCFF54: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFF58: 7D5E5A14  add r10, r30, r11
	ctx.r[10].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 82FCFF5C: C00BFFF8  lfs f0, -8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFF60: 7CFF5A14  add r7, r31, r11
	ctx.r[7].u64 = ctx.r[31].u64 + ctx.r[11].u64;
	// 82FCFF64: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFF68: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FCFF6C: 7D8A342E  lfsx f12, r10, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FCFF70: ED60637A  fmadds f11, f0, f13, f12
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FCFF74: 7D6A352E  stfsx f11, r10, r6
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32), tmp.u32) };
	// 82FCFF78: C14BFFFC  lfs f10, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FCFF7C: 80C30000  lwz r6, 0(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFF80: C1240000  lfs f9, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FCFF84: 7D4A3214  add r10, r10, r6
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[6].u64;
	// 82FCFF88: C10A0004  lfs f8, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FCFF8C: ECEA427A  fmadds f7, f10, f9, f8
	ctx.f[7].f64 = (((ctx.f[10].f64 * ctx.f[9].f64 + ctx.f[8].f64) as f32) as f64);
	// 82FCFF90: D0EA0004  stfs f7, 4(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FCFF94: 38CA0004  addi r6, r10, 4
	ctx.r[6].s64 = ctx.r[10].s64 + 4;
	// 82FCFF98: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 82FCFF9C: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFFA0: C0A40000  lfs f5, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 82FCFFA4: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FCFFA8: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 82FCFFAC: EC66217A  fmadds f3, f6, f5, f4
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[5].f64 + ctx.f[4].f64) as f32) as f64);
	// 82FCFFB0: D06A0000  stfs f3, 0(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FCFFB4: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFFB8: C04B0004  lfs f2, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 82FCFFBC: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 82FCFFC0: C0240000  lfs f1, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 82FCFFC4: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FCFFC8: 7C07542E  lfsx f0, r7, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFFCC: EDA2007A  fmadds f13, f2, f1, f0
	ctx.f[13].f64 = (((ctx.f[2].f64 * ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64);
	// 82FCFFD0: 7DA7552E  stfsx f13, r7, r10
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[7].u32.wrapping_add(ctx.r[10].u32), tmp.u32) };
	// 82FCFFD4: 4082FF80  bne 0x82fcff54
	if !ctx.cr[0].eq {
	pc = 0x82FCFF54; continue 'dispatch;
	}
	// 82FCFFD8: 7F1DE000  cmpw cr6, r29, r28
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[28].s32, &mut ctx.xer);
	// 82FCFFDC: 40980038  bge cr6, 0x82fd0014
	if !ctx.cr[6].lt {
	pc = 0x82FD0014; continue 'dispatch;
	}
	// 82FCFFE0: 81050000  lwz r8, 0(r5)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFFE4: 57AB103A  slwi r11, r29, 2
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FCFFE8: 7D5DE050  subf r10, r29, r28
	ctx.r[10].s64 = ctx.r[28].s64 - ctx.r[29].s64;
	// 82FCFFEC: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FCFFF0: 7C0B442E  lfsx f0, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FCFFF4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FCFFF8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FCFFFC: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FD0000: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD0004: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD0008: ED60637A  fmadds f11, f0, f13, f12
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 82FD000C: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD0010: 4082FFDC  bne 0x82fcffec
	if !ctx.cr[0].eq {
	pc = 0x82FCFFEC; continue 'dispatch;
	}
	// 82FD0014: 481D81A4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0018(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD0018 size=212
    let mut pc: u32 = 0x82FD0018;
    'dispatch: loop {
        match pc {
            0x82FD0018 => {
    //   block [0x82FD0018..0x82FD00EC)
	// 82FD0018: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD001C: 481D8151  bl 0x831a816c
	ctx.lr = 0x82FD0020;
	sub_831A8130(ctx, base);
	// 82FD0020: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0024: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FD0028: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD002C: 7FCB51D6  mullw r30, r11, r10
	ctx.r[30].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82FD0030: 2F1E0004  cmpwi cr6, r30, 4
	ctx.cr[6].compare_i32(ctx.r[30].s32, 4, &mut ctx.xer);
	// 82FD0034: 41980084  blt cr6, 0x82fd00b8
	if ctx.cr[6].lt {
	pc = 0x82FD00B8; continue 'dispatch;
	}
	// 82FD0038: 397EFFFC  addi r11, r30, -4
	ctx.r[11].s64 = ctx.r[30].s64 + -4;
	// 82FD003C: 81040000  lwz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0040: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82FD0044: 556BF0BE  srwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD0048: 20C80004  subfic r6, r8, 4
	ctx.xer.ca = ctx.r[8].u32 <= 4 as u32;
	ctx.r[6].s64 = (4 as i64) - ctx.r[8].s64;
	// 82FD004C: 394B0001  addi r10, r11, 1
	ctx.r[10].s64 = ctx.r[11].s64 + 1;
	// 82FD0050: 39680008  addi r11, r8, 8
	ctx.r[11].s64 = ctx.r[8].s64 + 8;
	// 82FD0054: 20A8FFF8  subfic r5, r8, -8
	ctx.xer.ca = ctx.r[8].u32 <= -8 as u32;
	ctx.r[5].s64 = (-8 as i64) - ctx.r[8].s64;
	// 82FD0058: 555F103A  slwi r31, r10, 2
	ctx.r[31].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[31].u64 = ctx.r[31].u32 as u64;
	// 82FD005C: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0060: 7D055A14  add r8, r5, r11
	ctx.r[8].u64 = ctx.r[5].u64 + ctx.r[11].u64;
	// 82FD0064: C00BFFF8  lfs f0, -8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD0068: 7FA65A14  add r29, r6, r11
	ctx.r[29].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 82FD006C: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0070: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0074: 7DA83D2E  stfsx f13, r8, r7
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FD0078: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD007C: C18BFFFC  lfs f12, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD0080: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 82FD0084: FD606050  fneg f11, f12
	ctx.f[11].u64 = ctx.f[12].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0088: D1680004  stfs f11, 4(r8)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FD008C: 80E30000  lwz r7, 0(r3)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0090: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FD0094: FD205050  fneg f9, f10
	ctx.f[9].u64 = ctx.f[10].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0098: 7D293D2E  stfsx f9, r9, r7
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FD009C: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD00A0: C10B0004  lfs f8, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FD00A4: FCE04050  fneg f7, f8
	ctx.f[7].u64 = ctx.f[8].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD00A8: 7CFD452E  stfsx f7, r29, r8
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FD00AC: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 82FD00B0: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FD00B4: 4082FFA8  bne 0x82fd005c
	if !ctx.cr[0].eq {
	pc = 0x82FD005C; continue 'dispatch;
	}
	// 82FD00B8: 7F1FF000  cmpw cr6, r31, r30
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[30].s32, &mut ctx.xer);
	// 82FD00BC: 4098002C  bge cr6, 0x82fd00e8
	if !ctx.cr[6].lt {
	pc = 0x82FD00E8; continue 'dispatch;
	}
	// 82FD00C0: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD00C4: 57EB103A  slwi r11, r31, 2
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD00C8: 7D5FF050  subf r10, r31, r30
	ctx.r[10].s64 = ctx.r[30].s64 - ctx.r[31].s64;
	// 82FD00CC: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD00D0: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD00D4: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD00D8: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD00DC: 7DAB452E  stfsx f13, r11, r8
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FD00E0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD00E4: 4082FFE8  bne 0x82fd00cc
	if !ctx.cr[0].eq {
	pc = 0x82FD00CC; continue 'dispatch;
	}
	// 82FD00E8: 481D80D4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD00F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD00F0 size=148
    let mut pc: u32 = 0x82FD00F0;
    'dispatch: loop {
        match pc {
            0x82FD00F0 => {
    //   block [0x82FD00F0..0x82FD0184)
	// 82FD00F0: 81630010  lwz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD00F4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 82FD00F8: 8143000C  lwz r10, 0xc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD00FC: 7CAB51D6  mullw r5, r11, r10
	ctx.r[5].s64 = (ctx.r[11].s32 as i64) * (ctx.r[10].s32 as i64);
	// 82FD0100: 2F050004  cmpwi cr6, r5, 4
	ctx.cr[6].compare_i32(ctx.r[5].s32, 4, &mut ctx.xer);
	// 82FD0104: 41980078  blt cr6, 0x82fd017c
	if ctx.cr[6].lt {
	pc = 0x82FD017C; continue 'dispatch;
	}
	// 82FD0108: 3945FFFC  addi r10, r5, -4
	ctx.r[10].s64 = ctx.r[5].s64 + -4;
	// 82FD010C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0110: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD0114: 390A0001  addi r8, r10, 1
	ctx.r[8].s64 = ctx.r[10].s64 + 1;
	// 82FD0118: 5506103A  slwi r6, r8, 2
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 82FD011C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0120: 394B000C  addi r10, r11, 0xc
	ctx.r[10].s64 = ctx.r[11].s64 + 12;
	// 82FD0124: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FD0128: 7C0B4C2E  lfsx f0, r11, r9
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD012C: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0130: 7DAB4D2E  stfsx f13, r11, r9
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FD0134: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0138: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FD013C: C1890004  lfs f12, 4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD0140: FD606050  fneg f11, f12
	ctx.f[11].u64 = ctx.f[12].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0144: D1690004  stfs f11, 4(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FD0148: 38E90004  addi r7, r9, 4
	ctx.r[7].s64 = ctx.r[9].s64 + 4;
	// 82FD014C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0150: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FD0154: C149FFFC  lfs f10, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FD0158: FD205050  fneg f9, f10
	ctx.f[9].u64 = ctx.f[10].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD015C: D129FFFC  stfs f9, -4(r9)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FD0160: 38E9FFFC  addi r7, r9, -4
	ctx.r[7].s64 = ctx.r[9].s64 + -4;
	// 82FD0164: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0168: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FD016C: 7D0A4C2E  lfsx f8, r10, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FD0170: FCE04050  fneg f7, f8
	ctx.f[7].u64 = ctx.f[8].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0174: 7CEA4D2E  stfsx f7, r10, r9
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32), tmp.u32) };
	// 82FD0178: 4082FFA4  bne 0x82fd011c
	if !ctx.cr[0].eq {
	pc = 0x82FD011C; continue 'dispatch;
	}
	// 82FD017C: 7F062800  cmpw cr6, r6, r5
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[5].s32, &mut ctx.xer);
	// 82FD0180: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0184(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD0184 size=44
    let mut pc: u32 = 0x82FD0184;
    'dispatch: loop {
        match pc {
            0x82FD0184 => {
    //   block [0x82FD0184..0x82FD01B0)
	// 82FD0184: 54CA103A  slwi r10, r6, 2
	ctx.r[10].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD0188: 7D662850  subf r11, r6, r5
	ctx.r[11].s64 = ctx.r[5].s64 - ctx.r[6].s64;
	// 82FD018C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0190: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD0194: 7D2A4A14  add r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 82FD0198: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FD019C: C0090000  lfs f0, 0(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD01A0: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD01A4: D1A90000  stfs f13, 0(r9)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD01A8: 4082FFE4  bne 0x82fd018c
	if !ctx.cr[0].eq {
	pc = 0x82FD018C; continue 'dispatch;
	}
	// 82FD01AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD01B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FD01B0 size=364
    let mut pc: u32 = 0x82FD01B0;
    'dispatch: loop {
        match pc {
            0x82FD01B0 => {
    //   block [0x82FD01B0..0x82FD031C)
	// 82FD01B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD01B4: 481D7FB5  bl 0x831a8168
	ctx.lr = 0x82FD01B8;
	sub_831A8130(ctx, base);
	// 82FD01B8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD01BC: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FD01C0: 7CDE3378  mr r30, r6
	ctx.r[30].u64 = ctx.r[6].u64;
	// 82FD01C4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD01C8: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FD01CC: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FD01D0: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD01D4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD01D8: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FD01DC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82FD01E0: 4BFFF6F1  bl 0x82fcf8d0
	ctx.lr = 0x82FD01E4;
	sub_82FCF8D0(ctx, base);
	// 82FD01E4: 815C0010  lwz r10, 0x10(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD01E8: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FD01EC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD01F0: 4099008C  ble cr6, 0x82fd027c
	if !ctx.cr[6].gt {
	pc = 0x82FD027C; continue 'dispatch;
	}
	// 82FD01F4: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD01F8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD01FC: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FD0200: 4099006C  ble cr6, 0x82fd026c
	if !ctx.cr[6].gt {
	pc = 0x82FD026C; continue 'dispatch;
	}
	// 82FD0204: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0208: 813F000C  lwz r9, 0xc(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD020C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD0210: 80DF0018  lwz r6, 0x18(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FD0214: 80BE0010  lwz r5, 0x10(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0218: 809D0010  lwz r4, 0x10(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD021C: 811E0000  lwz r8, 0(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0220: 7C6B482E  lwzx r3, r11, r9
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 82FD0224: 7CCB302E  lwzx r6, r11, r6
	ctx.r[6].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 82FD0228: 7D2329D6  mullw r9, r3, r5
	ctx.r[9].s64 = (ctx.r[3].s32 as i64) * (ctx.r[5].s32 as i64);
	// 82FD022C: 80BD0000  lwz r5, 0(r29)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0230: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0234: 7C0B1C2E  lfsx f0, r11, r3
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD0238: 7CC621D6  mullw r6, r6, r4
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[4].s32 as i64);
	// 82FD023C: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 82FD0240: 7CC63A14  add r6, r6, r7
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FD0244: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FD0248: 54C4103A  slwi r4, r6, 2
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FD024C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD0250: 7DA9442E  lfsx f13, r9, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD0254: 7D842C2E  lfsx f12, r4, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD0258: ED6C683A  fmadds f11, f12, f0, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FD025C: 7D69452E  stfsx f11, r9, r8
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FD0260: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0264: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FD0268: 4198FFA0  blt cr6, 0x82fd0208
	if ctx.cr[6].lt {
	pc = 0x82FD0208; continue 'dispatch;
	}
	// 82FD026C: 817C0010  lwz r11, 0x10(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0270: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FD0274: 7F075800  cmpw cr6, r7, r11
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FD0278: 4198FF80  blt cr6, 0x82fd01f8
	if ctx.cr[6].lt {
	pc = 0x82FD01F8; continue 'dispatch;
	}
	// 82FD027C: 817C0010  lwz r11, 0x10(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0280: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 82FD0284: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD0288: 4099008C  ble cr6, 0x82fd0314
	if !ctx.cr[6].gt {
	pc = 0x82FD0314; continue 'dispatch;
	}
	// 82FD028C: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0290: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD0294: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FD0298: 4099006C  ble cr6, 0x82fd0304
	if !ctx.cr[6].gt {
	pc = 0x82FD0304; continue 'dispatch;
	}
	// 82FD029C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD02A0: 813F0018  lwz r9, 0x18(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FD02A4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD02A8: 80DF000C  lwz r6, 0xc(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD02AC: 80BC0010  lwz r5, 0x10(r28)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD02B0: 809E0010  lwz r4, 0x10(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD02B4: 811C0000  lwz r8, 0(r28)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD02B8: 7C6B482E  lwzx r3, r11, r9
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 82FD02BC: 7CCB302E  lwzx r6, r11, r6
	ctx.r[6].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) } as u64;
	// 82FD02C0: 7D2329D6  mullw r9, r3, r5
	ctx.r[9].s64 = (ctx.r[3].s32 as i64) * (ctx.r[5].s32 as i64);
	// 82FD02C4: 80BE0000  lwz r5, 0(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD02C8: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD02CC: 7C0B1C2E  lfsx f0, r11, r3
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD02D0: 7CC621D6  mullw r6, r6, r4
	ctx.r[6].s64 = (ctx.r[6].s32 as i64) * (ctx.r[4].s32 as i64);
	// 82FD02D4: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 82FD02D8: 7CC63A14  add r6, r6, r7
	ctx.r[6].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FD02DC: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FD02E0: 54C4103A  slwi r4, r6, 2
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FD02E4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD02E8: 7DA9442E  lfsx f13, r9, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD02EC: 7D842C2E  lfsx f12, r4, r5
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[4].u32.wrapping_add(ctx.r[5].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD02F0: ED6C683A  fmadds f11, f12, f0, f13
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 82FD02F4: 7D69452E  stfsx f11, r9, r8
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[8].u32), tmp.u32) };
	// 82FD02F8: 813F0004  lwz r9, 4(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD02FC: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 82FD0300: 4198FFA0  blt cr6, 0x82fd02a0
	if ctx.cr[6].lt {
	pc = 0x82FD02A0; continue 'dispatch;
	}
	// 82FD0304: 817C0010  lwz r11, 0x10(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0308: 38E70001  addi r7, r7, 1
	ctx.r[7].s64 = ctx.r[7].s64 + 1;
	// 82FD030C: 7F075800  cmpw cr6, r7, r11
	ctx.cr[6].compare_i32(ctx.r[7].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FD0310: 4198FF80  blt cr6, 0x82fd0290
	if ctx.cr[6].lt {
	pc = 0x82FD0290; continue 'dispatch;
	}
	// 82FD0314: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FD0318: 481D7EA0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0320(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FD0320 size=152
    let mut pc: u32 = 0x82FD0320;
    'dispatch: loop {
        match pc {
            0x82FD0320 => {
    //   block [0x82FD0320..0x82FD03B8)
	// 82FD0320: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0324: 481D7E49  bl 0x831a816c
	ctx.lr = 0x82FD0328;
	sub_831A8130(ctx, base);
	// 82FD0328: DBE1FFD8  stfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-40 as u32), ctx.f[31].u64 ) };
	// 82FD032C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0330: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FD0334: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82FD0338: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD033C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0340: C3EB08A4  lfs f31, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 82FD0344: 80BD0010  lwz r5, 0x10(r29)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0348: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FD034C: 809D000C  lwz r4, 0xc(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD0350: 4BFFF7C9  bl 0x82fcfb18
	ctx.lr = 0x82FD0354;
	sub_82FCFB18(ctx, base);
	// 82FD0354: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD0358: 80BD0010  lwz r5, 0x10(r29)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD035C: 809E0024  lwz r4, 0x24(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 82FD0360: FC20F890  fmr f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FD0364: 4BFFF7B5  bl 0x82fcfb18
	ctx.lr = 0x82FD0368;
	sub_82FCFB18(ctx, base);
	// 82FD0368: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 82FD036C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 82FD0370: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD0374: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0378: 4BFFFE39  bl 0x82fd01b0
	ctx.lr = 0x82FD037C;
	sub_82FD01B0(ctx, base);
	// 82FD037C: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 82FD0380: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD0384: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0388: 409A0020  bne cr6, 0x82fd03a8
	if !ctx.cr[6].eq {
	pc = 0x82FD03A8; continue 'dispatch;
	}
	// 82FD038C: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0390: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD0394: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD0398: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FD039C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD03A0: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD03A4: 4BED040D  bl 0x82ea07b0
	ctx.lr = 0x82FD03A8;
	sub_82EA07B0(ctx, base);
	// 82FD03A8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD03AC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82FD03B0: CBE1FFD8  lfd f31, -0x28(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-40 as u32) ) };
	// 82FD03B4: 481D7E08  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD03B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FD03B8 size=668
    let mut pc: u32 = 0x82FD03B8;
    'dispatch: loop {
        match pc {
            0x82FD03B8 => {
    //   block [0x82FD03B8..0x82FD0654)
	// 82FD03B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD03BC: 481D7DA1  bl 0x831a815c
	ctx.lr = 0x82FD03C0;
	sub_831A8130(ctx, base);
	// 82FD03C0: 3981FFC0  addi r12, r1, -0x40
	ctx.r[12].s64 = ctx.r[1].s64 + -64;
	// 82FD03C4: 481D86B5  bl 0x831a8a78
	ctx.lr = 0x82FD03C8;
	sub_831A8A40(ctx, base);
	// 82FD03C8: 9421FEA0  stwu r1, -0x160(r1)
	ea = ctx.r[1].u32.wrapping_add(-352 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD03CC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82FD03D0: FFC00890  fmr f30, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].f64 = ctx.f[1].f64;
	// 82FD03D4: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 82FD03D8: 386100E0  addi r3, r1, 0xe0
	ctx.r[3].s64 = ctx.r[1].s64 + 224;
	// 82FD03DC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD03E0: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 82FD03E4: 83FD000C  lwz r31, 0xc(r29)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD03E8: 7CFA3B78  mr r26, r7
	ctx.r[26].u64 = ctx.r[7].u64;
	// 82FD03EC: 4BFFFF35  bl 0x82fd0320
	ctx.lr = 0x82FD03F0;
	sub_82FD0320(ctx, base);
	// 82FD03F0: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FD03F4: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FD03F8: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD03FC: 4BFFF87D  bl 0x82fcfc78
	ctx.lr = 0x82FD0400;
	sub_82FCFC78(ctx, base);
	// 82FD0400: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FD0404: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD0408: 4BFFF471  bl 0x82fcf878
	ctx.lr = 0x82FD040C;
	sub_82FCF878(ctx, base);
	// 82FD040C: 816100E8  lwz r11, 0xe8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) } as u64;
	// 82FD0410: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD0414: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0418: 409A0020  bne cr6, 0x82fd0438
	if !ctx.cr[6].eq {
	pc = 0x82FD0438; continue 'dispatch;
	}
	// 82FD041C: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0420: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD0424: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD0428: 808100E0  lwz r4, 0xe0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) } as u64;
	// 82FD042C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD0430: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD0434: 4BED037D  bl 0x82ea07b0
	ctx.lr = 0x82FD0438;
	sub_82EA07B0(ctx, base);
	// 82FD0438: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82FD043C: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FD0440: 4BFFF839  bl 0x82fcfc78
	ctx.lr = 0x82FD0444;
	sub_82FCFC78(ctx, base);
	// 82FD0444: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 82FD0448: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD044C: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 82FD0450: 4BFFF7B1  bl 0x82fcfc00
	ctx.lr = 0x82FD0454;
	sub_82FCFC00(ctx, base);
	// 82FD0454: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 82FD0458: 386100C0  addi r3, r1, 0xc0
	ctx.r[3].s64 = ctx.r[1].s64 + 192;
	// 82FD045C: 809E0024  lwz r4, 0x24(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 82FD0460: 4BFFF7A1  bl 0x82fcfc00
	ctx.lr = 0x82FD0464;
	sub_82FCFC00(ctx, base);
	// 82FD0464: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82FD0468: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD046C: 4BFFF8C5  bl 0x82fcfd30
	ctx.lr = 0x82FD0470;
	sub_82FCFD30(ctx, base);
	// 82FD0470: FFE00890  fmr f31, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FD0474: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FD0478: EF9E07B2  fmuls f28, f30, f30
	ctx.f[28].f64 = (((ctx.f[30].f64 * ctx.f[30].f64) as f32) as f64);
	// 82FD047C: 2F1A0000  cmpwi cr6, r26, 0
	ctx.cr[6].compare_i32(ctx.r[26].s32, 0, &mut ctx.xer);
	// 82FD0480: 40990100  ble cr6, 0x82fd0580
	if !ctx.cr[6].gt {
	pc = 0x82FD0580; continue 'dispatch;
	}
	// 82FD0484: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 82FD0488: 3D4051EB  lis r10, 0x51eb
	ctx.r[10].s64 = 1374355456;
	// 82FD048C: 615C851F  ori r28, r10, 0x851f
	ctx.r[28].u64 = ctx.r[10].u64 | 34079;
	// 82FD0490: C3AB08A4  lfs f29, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 82FD0494: FF1FE000  fcmpu cr6, f31, f28
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[28].f64);
	// 82FD0498: 419801B4  blt cr6, 0x82fd064c
	if ctx.cr[6].lt {
	pc = 0x82FD064C; continue 'dispatch;
	}
	// 82FD049C: D3A10050  stfs f29, 0x50(r1)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FD04A0: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FD04A4: 386100A0  addi r3, r1, 0xa0
	ctx.r[3].s64 = ctx.r[1].s64 + 160;
	// 82FD04A8: 4BFFF429  bl 0x82fcf8d0
	ctx.lr = 0x82FD04AC;
	sub_82FCF8D0(ctx, base);
	// 82FD04AC: 38C100C0  addi r6, r1, 0xc0
	ctx.r[6].s64 = ctx.r[1].s64 + 192;
	// 82FD04B0: 38A10080  addi r5, r1, 0x80
	ctx.r[5].s64 = ctx.r[1].s64 + 128;
	// 82FD04B4: 388100A0  addi r4, r1, 0xa0
	ctx.r[4].s64 = ctx.r[1].s64 + 160;
	// 82FD04B8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD04BC: 4BFFFCF5  bl 0x82fd01b0
	ctx.lr = 0x82FD04C0;
	sub_82FD01B0(ctx, base);
	// 82FD04C0: 388100A0  addi r4, r1, 0xa0
	ctx.r[4].s64 = ctx.r[1].s64 + 160;
	// 82FD04C4: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FD04C8: 4BFFF869  bl 0x82fcfd30
	ctx.lr = 0x82FD04CC;
	sub_82FCFD30(ctx, base);
	// 82FD04CC: EFDF0824  fdivs f30, f31, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].f64 = ((ctx.f[31].f64 / ctx.f[1].f64) as f32) as f64;
	// 82FD04D0: D3C10050  stfs f30, 0x50(r1)
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FD04D4: 38A10080  addi r5, r1, 0x80
	ctx.r[5].s64 = ctx.r[1].s64 + 128;
	// 82FD04D8: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FD04DC: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FD04E0: 4BFFFA31  bl 0x82fcff10
	ctx.lr = 0x82FD04E4;
	sub_82FCFF10(ctx, base);
	// 82FD04E4: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FD04E8: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD04EC: 7FE9FB78  mr r9, r31
	ctx.r[9].u64 = ctx.r[31].u64;
	// 82FD04F0: 7D09E096  mulhw r8, r9, r28
	ctx.r[8].s64 = ((ctx.r[9].s32 as i64 * ctx.r[28].s32 as i64) >> 32);
	// 82FD04F4: 7D0B2670  srawi r11, r8, 4
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 4) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[8].s32 >> 4) as i64;
	// 82FD04F8: 556A0FFE  srwi r10, r11, 0x1f
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shr(31);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD04FC: 7CEB5214  add r7, r11, r10
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FD0500: 1CC70032  mulli r6, r7, 0x32
	ctx.r[6].s64 = ctx.r[7].s64 * 50;
	// 82FD0504: 7CA64851  subf. r5, r6, r9
	ctx.r[5].s64 = ctx.r[9].s64 - ctx.r[6].s64;
	ctx.cr[0].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 82FD0508: 4082002C  bne 0x82fd0534
	if !ctx.cr[0].eq {
	pc = 0x82FD0534; continue 'dispatch;
	}
	// 82FD050C: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 82FD0510: 4BFFFB09  bl 0x82fd0018
	ctx.lr = 0x82FD0514;
	sub_82FD0018(ctx, base);
	// 82FD0514: 38C100C0  addi r6, r1, 0xc0
	ctx.r[6].s64 = ctx.r[1].s64 + 192;
	// 82FD0518: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 82FD051C: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82FD0520: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0524: 4BFFFC8D  bl 0x82fd01b0
	ctx.lr = 0x82FD0528;
	sub_82FD01B0(ctx, base);
	// 82FD0528: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD052C: 4BFFFBC5  bl 0x82fd00f0
	ctx.lr = 0x82FD0530;
	sub_82FD00F0(ctx, base);
	// 82FD0530: 48000018  b 0x82fd0548
	pc = 0x82FD0548; continue 'dispatch;
	// 82FD0534: FC00F050  fneg f0, f30
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = ctx.f[30].u64 ^ 0x8000_0000_0000_0000u64;
	// 82FD0538: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FD053C: 38A100A0  addi r5, r1, 0xa0
	ctx.r[5].s64 = ctx.r[1].s64 + 160;
	// 82FD0540: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 82FD0544: 4BFFF9CD  bl 0x82fcff10
	ctx.lr = 0x82FD0548;
	sub_82FCFF10(ctx, base);
	// 82FD0548: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82FD054C: FFC0F890  fmr f30, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[30].f64 = ctx.f[31].f64;
	// 82FD0550: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD0554: 4BFFF7DD  bl 0x82fcfd30
	ctx.lr = 0x82FD0558;
	sub_82FCFD30(ctx, base);
	// 82FD0558: FFE00890  fmr f31, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FD055C: 38C10080  addi r6, r1, 0x80
	ctx.r[6].s64 = ctx.r[1].s64 + 128;
	// 82FD0560: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 82FD0564: 38810060  addi r4, r1, 0x60
	ctx.r[4].s64 = ctx.r[1].s64 + 96;
	// 82FD0568: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FD056C: EC1FF024  fdivs f0, f31, f30
	ctx.f[0].f64 = ((ctx.f[31].f64 / ctx.f[30].f64) as f32) as f64;
	// 82FD0570: D0010050  stfs f0, 0x50(r1)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 82FD0574: 4BFFF87D  bl 0x82fcfdf0
	ctx.lr = 0x82FD0578;
	sub_82FCFDF0(ctx, base);
	// 82FD0578: 7F1FD000  cmpw cr6, r31, r26
	ctx.cr[6].compare_i32(ctx.r[31].s32, ctx.r[26].s32, &mut ctx.xer);
	// 82FD057C: 4198FF18  blt cr6, 0x82fd0494
	if ctx.cr[6].lt {
	pc = 0x82FD0494; continue 'dispatch;
	}
	// 82FD0580: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD0584: 816100C8  lwz r11, 0xc8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 82FD0588: 99590000  stb r10, 0(r25)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[25].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 82FD058C: 55690000  rlwinm r9, r11, 0, 0, 0
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD0590: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FD0594: 409A0020  bne cr6, 0x82fd05b4
	if !ctx.cr[6].eq {
	pc = 0x82FD05B4; continue 'dispatch;
	}
	// 82FD0598: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD059C: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD05A0: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD05A4: 808100C0  lwz r4, 0xc0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 82FD05A8: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD05AC: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD05B0: 4BED0201  bl 0x82ea07b0
	ctx.lr = 0x82FD05B4;
	sub_82EA07B0(ctx, base);
	// 82FD05B4: 816100A8  lwz r11, 0xa8(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) } as u64;
	// 82FD05B8: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD05BC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD05C0: 409A0020  bne cr6, 0x82fd05e0
	if !ctx.cr[6].eq {
	pc = 0x82FD05E0; continue 'dispatch;
	}
	// 82FD05C4: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD05C8: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD05CC: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD05D0: 808100A0  lwz r4, 0xa0(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) } as u64;
	// 82FD05D4: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD05D8: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD05DC: 4BED01D5  bl 0x82ea07b0
	ctx.lr = 0x82FD05E0;
	sub_82EA07B0(ctx, base);
	// 82FD05E0: 81610088  lwz r11, 0x88(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 82FD05E4: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD05E8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD05EC: 409A0020  bne cr6, 0x82fd060c
	if !ctx.cr[6].eq {
	pc = 0x82FD060C; continue 'dispatch;
	}
	// 82FD05F0: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD05F4: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD05F8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD05FC: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FD0600: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD0604: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD0608: 4BED01A9  bl 0x82ea07b0
	ctx.lr = 0x82FD060C;
	sub_82EA07B0(ctx, base);
	// 82FD060C: 81610068  lwz r11, 0x68(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FD0610: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD0614: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0618: 409A0020  bne cr6, 0x82fd0638
	if !ctx.cr[6].eq {
	pc = 0x82FD0638; continue 'dispatch;
	}
	// 82FD061C: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0620: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD0624: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD0628: 80810060  lwz r4, 0x60(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FD062C: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD0630: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD0634: 4BED017D  bl 0x82ea07b0
	ctx.lr = 0x82FD0638;
	sub_82EA07B0(ctx, base);
	// 82FD0638: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 82FD063C: 38210160  addi r1, r1, 0x160
	ctx.r[1].s64 = ctx.r[1].s64 + 352;
	// 82FD0640: 3981FFC0  addi r12, r1, -0x40
	ctx.r[12].s64 = ctx.r[1].s64 + -64;
	// 82FD0644: 481D8481  bl 0x831a8ac4
	ctx.lr = 0x82FD0648;
	sub_831A8A8C(ctx, base);
	// 82FD0648: 481D7B64  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
	// 82FD064C: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FD0650: 4BFFFF34  b 0x82fd0584
	pc = 0x82FD0584; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0658(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x82FD0658 size=440
    let mut pc: u32 = 0x82FD0658;
    'dispatch: loop {
        match pc {
            0x82FD0658 => {
    //   block [0x82FD0658..0x82FD0810)
	// 82FD0658: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD065C: 481D7B05  bl 0x831a8160
	ctx.lr = 0x82FD0660;
	sub_831A8130(ctx, base);
	// 82FD0660: DBE1FFC0  stfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-64 as u32), ctx.f[31].u64 ) };
	// 82FD0664: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0668: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82FD066C: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 82FD0670: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 82FD0674: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 82FD0678: 38610060  addi r3, r1, 0x60
	ctx.r[3].s64 = ctx.r[1].s64 + 96;
	// 82FD067C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 82FD0680: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD0684: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FD0688: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 82FD068C: 4BFFF575  bl 0x82fcfc00
	ctx.lr = 0x82FD0690;
	sub_82FCFC00(ctx, base);
	// 82FD0690: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 82FD0694: 809D000C  lwz r4, 0xc(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD0698: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 82FD069C: 4BFFF565  bl 0x82fcfc00
	ctx.lr = 0x82FD06A0;
	sub_82FCFC00(ctx, base);
	// 82FD06A0: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD06A4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FD06A8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD06AC: 409900EC  ble cr6, 0x82fd0798
	if !ctx.cr[6].gt {
	pc = 0x82FD0798; continue 'dispatch;
	}
	// 82FD06B0: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD06B4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD06B8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD06BC: 4099005C  ble cr6, 0x82fd0718
	if !ctx.cr[6].gt {
	pc = 0x82FD0718; continue 'dispatch;
	}
	// 82FD06C0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD06C4: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD06C8: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD06CC: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82FD06D0: 80E10060  lwz r7, 0x60(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FD06D4: 7CC9F214  add r6, r9, r30
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 82FD06D8: 54C5103A  slwi r5, r6, 2
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD06DC: 7C05442E  lfsx f0, r5, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD06E0: 7C0A3D2E  stfsx f0, r10, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FD06E4: 809D0000  lwz r4, 0(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD06E8: 80610080  lwz r3, 0x80(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FD06EC: 813D0010  lwz r9, 0x10(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD06F0: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82FD06F4: 7D09F214  add r8, r9, r30
	ctx.r[8].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 82FD06F8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD06FC: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FD0700: 7DA7242E  lfsx f13, r7, r4
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[4].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD0704: 7DAA1D2E  stfsx f13, r10, r3
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[3].u32), tmp.u32) };
	// 82FD0708: 80DF000C  lwz r6, 0xc(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD070C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FD0710: 7F0B3000  cmpw cr6, r11, r6
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FD0714: 4198FFB0  blt cr6, 0x82fd06c4
	if ctx.cr[6].lt {
	pc = 0x82FD06C4; continue 'dispatch;
	}
	// 82FD0718: 7F67DB78  mr r7, r27
	ctx.r[7].u64 = ctx.r[27].u64;
	// 82FD071C: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 82FD0720: 38C10080  addi r6, r1, 0x80
	ctx.r[6].s64 = ctx.r[1].s64 + 128;
	// 82FD0724: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 82FD0728: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 82FD072C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD0730: 4BFFFC89  bl 0x82fd03b8
	ctx.lr = 0x82FD0734;
	sub_82FD03B8(ctx, base);
	// 82FD0734: 89630000  lbz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0738: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD073C: 419A00CC  beq cr6, 0x82fd0808
	if ctx.cr[6].eq {
	pc = 0x82FD0808; continue 'dispatch;
	}
	// 82FD0740: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD0744: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0748: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD074C: 4099003C  ble cr6, 0x82fd0788
	if !ctx.cr[6].gt {
	pc = 0x82FD0788; continue 'dispatch;
	}
	// 82FD0750: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD0754: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD0758: 81010060  lwz r8, 0x60(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FD075C: 7D2959D6  mullw r9, r9, r11
	ctx.r[9].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 82FD0760: 80FF0000  lwz r7, 0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0764: 7C0A442E  lfsx f0, r10, r8
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD0768: 7CC9F214  add r6, r9, r30
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 82FD076C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD0770: 54C5103A  slwi r5, r6, 2
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD0774: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 82FD0778: 7C053D2E  stfsx f0, r5, r7
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[5].u32.wrapping_add(ctx.r[7].u32), tmp.u32) };
	// 82FD077C: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 82FD0780: 7F0B2000  cmpw cr6, r11, r4
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[4].s32, &mut ctx.xer);
	// 82FD0784: 4198FFD0  blt cr6, 0x82fd0754
	if ctx.cr[6].lt {
	pc = 0x82FD0754; continue 'dispatch;
	}
	// 82FD0788: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD078C: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 82FD0790: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FD0794: 4198FF1C  blt cr6, 0x82fd06b0
	if ctx.cr[6].lt {
	pc = 0x82FD06B0; continue 'dispatch;
	}
	// 82FD0798: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FD079C: 81610088  lwz r11, 0x88(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) } as u64;
	// 82FD07A0: 995A0000  stb r10, 0(r26)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[26].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 82FD07A4: 55690000  rlwinm r9, r11, 0, 0, 0
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD07A8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FD07AC: 409A0020  bne cr6, 0x82fd07cc
	if !ctx.cr[6].eq {
	pc = 0x82FD07CC; continue 'dispatch;
	}
	// 82FD07B0: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD07B4: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD07B8: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD07BC: 80810080  lwz r4, 0x80(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) } as u64;
	// 82FD07C0: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD07C4: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD07C8: 4BECFFE9  bl 0x82ea07b0
	ctx.lr = 0x82FD07CC;
	sub_82EA07B0(ctx, base);
	// 82FD07CC: 81610068  lwz r11, 0x68(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 82FD07D0: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 82FD07D4: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD07D8: 409A0020  bne cr6, 0x82fd07f8
	if !ctx.cr[6].eq {
	pc = 0x82FD07F8; continue 'dispatch;
	}
	// 82FD07DC: 814D0000  lwz r10, 0(r13)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[13].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD07E0: 39200014  li r9, 0x14
	ctx.r[9].s64 = 20;
	// 82FD07E4: 38C00017  li r6, 0x17
	ctx.r[6].s64 = 23;
	// 82FD07E8: 80810060  lwz r4, 0x60(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 82FD07EC: 5565103A  slwi r5, r11, 2
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD07F0: 7C69502E  lwzx r3, r9, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD07F4: 4BECFFBD  bl 0x82ea07b0
	ctx.lr = 0x82FD07F8;
	sub_82EA07B0(ctx, base);
	// 82FD07F8: 7F43D378  mr r3, r26
	ctx.r[3].u64 = ctx.r[26].u64;
	// 82FD07FC: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 82FD0800: CBE1FFC0  lfd f31, -0x40(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-64 as u32) ) };
	// 82FD0804: 481D79AC  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 82FD0808: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD080C: 4BFFFF90  b 0x82fd079c
	pc = 0x82FD079C; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0810(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD0810 size=120
    let mut pc: u32 = 0x82FD0810;
    'dispatch: loop {
        match pc {
            0x82FD0810 => {
    //   block [0x82FD0810..0x82FD0888)
	// 82FD0810: 548B103A  slwi r11, r4, 2
	ctx.r[11].u32 = ctx.r[4].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD0814: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 82FD0818: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 82FD081C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82FD0820: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 82FD0824: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FD0828: 41980058  blt cr6, 0x82fd0880
	if ctx.cr[6].lt {
	pc = 0x82FD0880; continue 'dispatch;
	}
	// 82FD082C: 3944FFFB  addi r10, r4, -5
	ctx.r[10].s64 = ctx.r[4].s64 + -5;
	// 82FD0830: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD0834: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD0838: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FD083C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FD0840: C00BFFF8  lfs f0, -8(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD0844: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0848: C1ABFFF4  lfs f13, -0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD084C: C18BFFFC  lfs f12, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 82FD0850: ED606828  fsubs f11, f0, f13
	ctx.f[11].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FD0854: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FD0858: ED2C0028  fsubs f9, f12, f0
	ctx.f[9].f64 = (((ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 82FD085C: C10BFFF0  lfs f8, -0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-16 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 82FD0860: ECEA6028  fsubs f7, f10, f12
	ctx.f[7].f64 = (((ctx.f[10].f64 - ctx.f[12].f64) as f32) as f64);
	// 82FD0864: ECCD4028  fsubs f6, f13, f8
	ctx.f[6].f64 = (((ctx.f[13].f64 - ctx.f[8].f64) as f32) as f64);
	// 82FD0868: D16BFFF8  stfs f11, -8(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 82FD086C: D0EB0000  stfs f7, 0(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD0870: D0CBFFF4  stfs f6, -0xc(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-12 as u32), tmp.u32 ) };
	// 82FD0874: D12BFFFC  stfs f9, -4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 82FD0878: 396BFFF0  addi r11, r11, -0x10
	ctx.r[11].s64 = ctx.r[11].s64 + -16;
	// 82FD087C: 4082FFC4  bne 0x82fd0840
	if !ctx.cr[0].eq {
	pc = 0x82FD0840; continue 'dispatch;
	}
	// 82FD0880: 7F092040  cmplw cr6, r9, r4
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[4].u32, &mut ctx.xer);
	// 82FD0884: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0888(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD0888 size=36
    let mut pc: u32 = 0x82FD0888;
    'dispatch: loop {
        match pc {
            0x82FD0888 => {
    //   block [0x82FD0888..0x82FD08AC)
	// 82FD0888: 7D492050  subf r10, r9, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 82FD088C: C00B0000  lfs f0, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD0890: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD0894: C1ABFFFC  lfs f13, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD0898: ED806828  fsubs f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 82FD089C: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD08A0: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 82FD08A4: 4082FFE8  bne 0x82fd088c
	if !ctx.cr[0].eq {
	pc = 0x82FD088C; continue 'dispatch;
	}
	// 82FD08A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD08B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD08B0 size=112
    let mut pc: u32 = 0x82FD08B0;
    'dispatch: loop {
        match pc {
            0x82FD08B0 => {
    //   block [0x82FD08B0..0x82FD0920)
	// 82FD08B0: 3944FFFF  addi r10, r4, -1
	ctx.r[10].s64 = ctx.r[4].s64 + -1;
	// 82FD08B4: C0030000  lfs f0, 0(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 82FD08B8: 39630004  addi r11, r3, 4
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	// 82FD08BC: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82FD08C0: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 82FD08C4: 41980054  blt cr6, 0x82fd0918
	if ctx.cr[6].lt {
	pc = 0x82FD0918; continue 'dispatch;
	}
	// 82FD08C8: 3944FFFB  addi r10, r4, -5
	ctx.r[10].s64 = ctx.r[4].s64 + -5;
	// 82FD08CC: 554AF0BE  srwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD08D0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD08D4: 5549103A  slwi r9, r10, 2
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FD08D8: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FD08DC: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD08E0: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD08E4: ED8D002A  fadds f12, f13, f0
	ctx.f[12].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FD08E8: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 82FD08EC: C14B0008  lfs f10, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 82FD08F0: C12B000C  lfs f9, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 82FD08F4: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD08F8: ED0C582A  fadds f8, f12, f11
	ctx.f[8].f64 = ((ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64;
	// 82FD08FC: D10B0004  stfs f8, 4(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 82FD0900: ECEA402A  fadds f7, f10, f8
	ctx.f[7].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 82FD0904: D0EB0008  stfs f7, 8(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 82FD0908: EC07482A  fadds f0, f7, f9
	ctx.f[0].f64 = ((ctx.f[7].f64 + ctx.f[9].f64) as f32) as f64;
	// 82FD090C: D00B000C  stfs f0, 0xc(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 82FD0910: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 82FD0914: 4082FFC8  bne 0x82fd08dc
	if !ctx.cr[0].eq {
	pc = 0x82FD08DC; continue 'dispatch;
	}
	// 82FD0918: 7F092040  cmplw cr6, r9, r4
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[4].u32, &mut ctx.xer);
	// 82FD091C: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0920(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x82FD0920 size=32
    let mut pc: u32 = 0x82FD0920;
    'dispatch: loop {
        match pc {
            0x82FD0920 => {
    //   block [0x82FD0920..0x82FD0940)
	// 82FD0920: 7D492050  subf r10, r9, r4
	ctx.r[10].s64 = ctx.r[4].s64 - ctx.r[9].s64;
	// 82FD0924: C1AB0000  lfs f13, 0(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 82FD0928: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD092C: EC0D002A  fadds f0, f13, f0
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64;
	// 82FD0930: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 82FD0934: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD0938: 4082FFEC  bne 0x82fd0924
	if !ctx.cr[0].eq {
	pc = 0x82FD0924; continue 'dispatch;
	}
	// 82FD093C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0940 size=4
    let mut pc: u32 = 0x82FD0940;
    'dispatch: loop {
        match pc {
            0x82FD0940 => {
    //   block [0x82FD0940..0x82FD0944)
	// 82FD0940: 481DB830  b 0x831ac170
	sub_831AC170(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0948(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0948 size=8
    let mut pc: u32 = 0x82FD0948;
    'dispatch: loop {
        match pc {
            0x82FD0948 => {
    //   block [0x82FD0948..0x82FD0950)
	// 82FD0948: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD094C: 481DB824  b 0x831ac170
	sub_831AC170(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0950(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0950 size=8
    let mut pc: u32 = 0x82FD0950;
    'dispatch: loop {
        match pc {
            0x82FD0950 => {
    //   block [0x82FD0950..0x82FD0958)
	// 82FD0950: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0954: 82136930  lwz r16, 0x6930(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(26928 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0958(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0958 size=72
    let mut pc: u32 = 0x82FD0958;
    'dispatch: loop {
        match pc {
            0x82FD0958 => {
    //   block [0x82FD0958..0x82FD09A0)
	// 82FD0958: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD095C: 481D7811  bl 0x831a816c
	ctx.lr = 0x82FD0960;
	sub_831A8130(ctx, base);
	// 82FD0960: 3BE1FF90  addi r31, r1, -0x70
	ctx.r[31].s64 = ctx.r[1].s64 + -112;
	// 82FD0964: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0968: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD096C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FD0970: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 82FD0974: 93DF0084  stw r30, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[30].u32 ) };
	// 82FD0978: 480085B9  bl 0x82fd8f30
	ctx.lr = 0x82FD097C;
	sub_82FD8F30(ctx, base);
	// 82FD097C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0980: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0984: 396B691C  addi r11, r11, 0x691c
	ctx.r[11].s64 = ctx.r[11].s64 + 26908;
	// 82FD0988: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD098C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0990: 48008929  bl 0x82fd92b8
	ctx.lr = 0x82FD0994;
	sub_82FD92B8(ctx, base);
	// 82FD0994: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0998: 383F0070  addi r1, r31, 0x70
	ctx.r[1].s64 = ctx.r[31].s64 + 112;
	// 82FD099C: 481D7820  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD09A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD09A0 size=40
    let mut pc: u32 = 0x82FD09A0;
    'dispatch: loop {
        match pc {
            0x82FD09A0 => {
    //   block [0x82FD09A0..0x82FD09C8)
	// 82FD09A0: 3BECFF90  addi r31, r12, -0x70
	ctx.r[31].s64 = ctx.r[12].s64 + -112;
	// 82FD09A4: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD09A8: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD09AC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD09B0: 807F0084  lwz r3, 0x84(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(132 as u32) ) } as u64;
	// 82FD09B4: 480084C5  bl 0x82fd8e78
	ctx.lr = 0x82FD09B8;
	sub_82FD8E78(ctx, base);
	// 82FD09B8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD09BC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD09C0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD09C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD09C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD09C8 size=60
    let mut pc: u32 = 0x82FD09C8;
    'dispatch: loop {
        match pc {
            0x82FD09C8 => {
    //   block [0x82FD09C8..0x82FD0A04)
	// 82FD09C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD09CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD09D0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD09D4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD09D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD09DC: 480085CD  bl 0x82fd8fa8
	ctx.lr = 0x82FD09E0;
	sub_82FD8FA8(ctx, base);
	// 82FD09E0: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD09E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD09E8: 396B691C  addi r11, r11, 0x691c
	ctx.r[11].s64 = ctx.r[11].s64 + 26908;
	// 82FD09EC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD09F0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD09F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD09F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD09FC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0A00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0A08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0A08 size=16
    let mut pc: u32 = 0x82FD0A08;
    'dispatch: loop {
        match pc {
            0x82FD0A08 => {
    //   block [0x82FD0A08..0x82FD0A18)
	// 82FD0A08: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0A0C: 396B691C  addi r11, r11, 0x691c
	ctx.r[11].s64 = ctx.r[11].s64 + 26908;
	// 82FD0A10: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0A14: 48008464  b 0x82fd8e78
	sub_82FD8E78(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0A18 size=8
    let mut pc: u32 = 0x82FD0A18;
    'dispatch: loop {
        match pc {
            0x82FD0A18 => {
    //   block [0x82FD0A18..0x82FD0A20)
	// 82FD0A18: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0A1C: 82136968  lwz r16, 0x6968(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(26984 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0A20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0A20 size=92
    let mut pc: u32 = 0x82FD0A20;
    'dispatch: loop {
        match pc {
            0x82FD0A20 => {
    //   block [0x82FD0A20..0x82FD0A7C)
	// 82FD0A20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0A24: 481D7749  bl 0x831a816c
	ctx.lr = 0x82FD0A28;
	sub_831A8130(ctx, base);
	// 82FD0A28: 3BE1FF80  addi r31, r1, -0x80
	ctx.r[31].s64 = ctx.r[1].s64 + -128;
	// 82FD0A2C: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0A30: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD0A34: 38600018  li r3, 0x18
	ctx.r[3].s64 = 24;
	// 82FD0A38: 809D0014  lwz r4, 0x14(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0A3C: 93BF0094  stw r29, 0x94(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(148 as u32), ctx.r[29].u32 ) };
	// 82FD0A40: 48007859  bl 0x82fd8298
	ctx.lr = 0x82FD0A44;
	sub_82FD8298(ctx, base);
	// 82FD0A44: 7C7E1B79  or. r30, r3, r3
	ctx.r[30].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FD0A48: 93DF0050  stw r30, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82FD0A4C: 41820024  beq 0x82fd0a70
	if ctx.cr[0].eq {
	pc = 0x82FD0A70; continue 'dispatch;
	}
	// 82FD0A50: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0A54: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0A58: 48008551  bl 0x82fd8fa8
	ctx.lr = 0x82FD0A5C;
	sub_82FD8FA8(ctx, base);
	// 82FD0A5C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0A60: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0A64: 396B691C  addi r11, r11, 0x691c
	ctx.r[11].s64 = ctx.r[11].s64 + 26908;
	// 82FD0A68: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0A6C: 48000008  b 0x82fd0a74
	pc = 0x82FD0A74; continue 'dispatch;
	// 82FD0A70: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD0A74: 383F0080  addi r1, r31, 0x80
	ctx.r[1].s64 = ctx.r[31].s64 + 128;
	// 82FD0A78: 481D7744  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0A7C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0A7C size=48
    let mut pc: u32 = 0x82FD0A7C;
    'dispatch: loop {
        match pc {
            0x82FD0A7C => {
    //   block [0x82FD0A7C..0x82FD0AAC)
	// 82FD0A7C: 3BECFF80  addi r31, r12, -0x80
	ctx.r[31].s64 = ctx.r[12].s64 + -128;
	// 82FD0A80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0A84: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0A88: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0A8C: 817F0094  lwz r11, 0x94(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(148 as u32) ) } as u64;
	// 82FD0A90: 808B0014  lwz r4, 0x14(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0A94: 807F0050  lwz r3, 0x50(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FD0A98: 48007849  bl 0x82fd82e0
	ctx.lr = 0x82FD0A9C;
	sub_82FD82E0(ctx, base);
	// 82FD0A9C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0AA0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0AA4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0AA8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0AB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0AB0 size=12
    let mut pc: u32 = 0x82FD0AB0;
    'dispatch: loop {
        match pc {
            0x82FD0AB0 => {
    //   block [0x82FD0AB0..0x82FD0ABC)
	// 82FD0AB0: 3D608214  lis r11, -0x7dec
	ctx.r[11].s64 = -2112618496;
	// 82FD0AB4: 386B8240  addi r3, r11, -0x7dc0
	ctx.r[3].s64 = ctx.r[11].s64 + -32192;
	// 82FD0AB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0AC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0AC0 size=88
    let mut pc: u32 = 0x82FD0AC0;
    'dispatch: loop {
        match pc {
            0x82FD0AC0 => {
    //   block [0x82FD0AC0..0x82FD0B18)
	// 82FD0AC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0AC4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0AC8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD0ACC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD0AD0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0AD4: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0AD8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0ADC: 396B691C  addi r11, r11, 0x691c
	ctx.r[11].s64 = ctx.r[11].s64 + 26908;
	// 82FD0AE0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD0AE4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0AE8: 48008391  bl 0x82fd8e78
	ctx.lr = 0x82FD0AEC;
	sub_82FD8E78(ctx, base);
	// 82FD0AEC: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD0AF0: 4182000C  beq 0x82fd0afc
	if ctx.cr[0].eq {
	pc = 0x82FD0AFC; continue 'dispatch;
	}
	// 82FD0AF4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0AF8: 480077E9  bl 0x82fd82e0
	ctx.lr = 0x82FD0AFC;
	sub_82FD82E0(ctx, base);
	// 82FD0AFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0B00: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD0B04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0B08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0B0C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD0B10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0B14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0B18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0B18 size=104
    let mut pc: u32 = 0x82FD0B18;
    'dispatch: loop {
        match pc {
            0x82FD0B18 => {
    //   block [0x82FD0B18..0x82FD0B80)
	// 82FD0B18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0B1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0B20: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD0B24: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD0B28: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0B2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0B30: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD0B34: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD0B38: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0B3C: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD0B40: 409A000C  bne cr6, 0x82fd0b4c
	if !ctx.cr[6].eq {
	pc = 0x82FD0B4C; continue 'dispatch;
	}
	// 82FD0B44: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82FD0B48: 48008921  bl 0x82fd9468
	ctx.lr = 0x82FD0B4C;
	sub_82FD9468(ctx, base);
	// 82FD0B4C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0B50: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FD0B54: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD0B58: 7FCB532E  sthx r30, r11, r10
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32), ctx.r[30].u16) };
	// 82FD0B5C: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0B60: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD0B64: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FD0B68: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD0B6C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0B70: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0B74: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD0B78: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0B7C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0B80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0B80 size=140
    let mut pc: u32 = 0x82FD0B80;
    'dispatch: loop {
        match pc {
            0x82FD0B80 => {
    //   block [0x82FD0B80..0x82FD0C0C)
	// 82FD0B80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0B84: 481D75E9  bl 0x831a816c
	ctx.lr = 0x82FD0B88;
	sub_831A8130(ctx, base);
	// 82FD0B88: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0B8C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0B90: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 82FD0B94: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82FD0B98: 419A0068  beq cr6, 0x82fd0c00
	if ctx.cr[6].eq {
	pc = 0x82FD0C00; continue 'dispatch;
	}
	// 82FD0B9C: A17F0000  lhz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0BA0: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0BA4: 41820028  beq 0x82fd0bcc
	if ctx.cr[0].eq {
	pc = 0x82FD0BCC; continue 'dispatch;
	}
	// 82FD0BA8: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82FD0BAC: 48000008  b 0x82fd0bb4
	pc = 0x82FD0BB4; continue 'dispatch;
	// 82FD0BB0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD0BB4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0BB8: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0BBC: 4082FFF4  bne 0x82fd0bb0
	if !ctx.cr[0].eq {
	pc = 0x82FD0BB0; continue 'dispatch;
	}
	// 82FD0BC0: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 82FD0BC4: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD0BC8: 48000008  b 0x82fd0bd0
	pc = 0x82FD0BD0; continue 'dispatch;
	// 82FD0BCC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0BD0: 81440000  lwz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0BD4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD0BD8: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82FD0BDC: 557E083C  slwi r30, r11, 1
	ctx.r[30].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 82FD0BE0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 82FD0BE4: 816A0004  lwz r11, 4(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD0BE8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD0BEC: 4E800421  bctrl
	ctx.lr = 0x82FD0BF0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD0BF0: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 82FD0BF4: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD0BF8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD0BFC: 481D7915  bl 0x831a8510
	ctx.lr = 0x82FD0C00;
	sub_831A8510(ctx, base);
	// 82FD0C00: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FD0C04: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD0C08: 481D75B4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0C10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0C10 size=44
    let mut pc: u32 = 0x82FD0C10;
    'dispatch: loop {
        match pc {
            0x82FD0C10 => {
    //   block [0x82FD0C10..0x82FD0C3C)
	// 82FD0C10: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 82FD0C14: 419800A0  blt cr6, 0x82fd0cb4
	if ctx.cr[6].lt {
		sub_82FD0CB4(ctx, base);
		return;
	}
	// 82FD0C18: 2F060000  cmpwi cr6, r6, 0
	ctx.cr[6].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 82FD0C1C: 41980098  blt cr6, 0x82fd0cb4
	if ctx.cr[6].lt {
		sub_82FD0CB4(ctx, base);
		return;
	}
	// 82FD0C20: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C24: 419A0034  beq cr6, 0x82fd0c58
	if ctx.cr[6].eq {
		sub_82FD0C58(ctx, base);
		return;
	}
	// 82FD0C28: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0C2C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C30: 41820028  beq 0x82fd0c58
	if ctx.cr[0].eq {
		sub_82FD0C58(ctx, base);
		return;
	}
	// 82FD0C34: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD0C38: 48000008  b 0x82fd0c40
	sub_82FD0C3C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0C3C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0C3C size=28
    let mut pc: u32 = 0x82FD0C3C;
    'dispatch: loop {
        match pc {
            0x82FD0C3C => {
    //   block [0x82FD0C3C..0x82FD0C58)
	// 82FD0C3C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD0C40: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0C44: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C48: 4082FFF4  bne 0x82fd0c3c
	if !ctx.cr[0].eq {
	pc = 0x82FD0C3C; continue 'dispatch;
	}
	// 82FD0C4C: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD0C50: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD0C54: 48000008  b 0x82fd0c5c
	sub_82FD0C58(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0C58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0C58 size=44
    let mut pc: u32 = 0x82FD0C58;
    'dispatch: loop {
        match pc {
            0x82FD0C58 => {
    //   block [0x82FD0C58..0x82FD0C84)
	// 82FD0C58: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0C5C: 7D443A14  add r10, r4, r7
	ctx.r[10].u64 = ctx.r[4].u64 + ctx.r[7].u64;
	// 82FD0C60: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD0C64: 41990050  bgt cr6, 0x82fd0cb4
	if ctx.cr[6].gt {
		sub_82FD0CB4(ctx, base);
		return;
	}
	// 82FD0C68: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C6C: 419A0034  beq cr6, 0x82fd0ca0
	if ctx.cr[6].eq {
		sub_82FD0CA0(ctx, base);
		return;
	}
	// 82FD0C70: A1650000  lhz r11, 0(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0C74: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C78: 41820028  beq 0x82fd0ca0
	if ctx.cr[0].eq {
		sub_82FD0CA0(ctx, base);
		return;
	}
	// 82FD0C7C: 39650002  addi r11, r5, 2
	ctx.r[11].s64 = ctx.r[5].s64 + 2;
	// 82FD0C80: 48000008  b 0x82fd0c88
	sub_82FD0C84(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0C84(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0C84 size=28
    let mut pc: u32 = 0x82FD0C84;
    'dispatch: loop {
        match pc {
            0x82FD0C84 => {
    //   block [0x82FD0C84..0x82FD0CA0)
	// 82FD0C84: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD0C88: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD0C8C: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD0C90: 4082FFF4  bne 0x82fd0c84
	if !ctx.cr[0].eq {
	pc = 0x82FD0C84; continue 'dispatch;
	}
	// 82FD0C94: 7D655850  subf r11, r5, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[5].s64;
	// 82FD0C98: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD0C9C: 48000008  b 0x82fd0ca4
	sub_82FD0CA0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0CA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0CA0 size=20
    let mut pc: u32 = 0x82FD0CA0;
    'dispatch: loop {
        match pc {
            0x82FD0CA0 => {
    //   block [0x82FD0CA0..0x82FD0CB4)
	// 82FD0CA0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD0CA4: 7D463A14  add r10, r6, r7
	ctx.r[10].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 82FD0CA8: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD0CAC: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD0CB0: 4C990020  blelr cr6
	if !ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0CB4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0CB4 size=8
    let mut pc: u32 = 0x82FD0CB4;
    'dispatch: loop {
        match pc {
            0x82FD0CB4 => {
    //   block [0x82FD0CB4..0x82FD0CBC)
	// 82FD0CB4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD0CB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0CC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0CC0 size=8
    let mut pc: u32 = 0x82FD0CC0;
    'dispatch: loop {
        match pc {
            0x82FD0CC0 => {
    //   block [0x82FD0CC0..0x82FD0CC8)
	// 82FD0CC0: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0CC4: 821369B0  lwz r16, 0x69b0(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27056 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0CC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0CC8 size=72
    let mut pc: u32 = 0x82FD0CC8;
    'dispatch: loop {
        match pc {
            0x82FD0CC8 => {
    //   block [0x82FD0CC8..0x82FD0D10)
	// 82FD0CC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0CCC: 481D74A1  bl 0x831a816c
	ctx.lr = 0x82FD0CD0;
	sub_831A8130(ctx, base);
	// 82FD0CD0: 3BE1FF90  addi r31, r1, -0x70
	ctx.r[31].s64 = ctx.r[1].s64 + -112;
	// 82FD0CD4: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0CD8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD0CDC: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FD0CE0: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 82FD0CE4: 93DF0084  stw r30, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[30].u32 ) };
	// 82FD0CE8: 48008249  bl 0x82fd8f30
	ctx.lr = 0x82FD0CEC;
	sub_82FD8F30(ctx, base);
	// 82FD0CEC: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0CF0: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0CF4: 396B6998  addi r11, r11, 0x6998
	ctx.r[11].s64 = ctx.r[11].s64 + 27032;
	// 82FD0CF8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0CFC: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0D00: 480085B9  bl 0x82fd92b8
	ctx.lr = 0x82FD0D04;
	sub_82FD92B8(ctx, base);
	// 82FD0D04: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0D08: 383F0070  addi r1, r31, 0x70
	ctx.r[1].s64 = ctx.r[31].s64 + 112;
	// 82FD0D0C: 481D74B0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0D10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0D10 size=40
    let mut pc: u32 = 0x82FD0D10;
    'dispatch: loop {
        match pc {
            0x82FD0D10 => {
    //   block [0x82FD0D10..0x82FD0D38)
	// 82FD0D10: 3BECFF90  addi r31, r12, -0x70
	ctx.r[31].s64 = ctx.r[12].s64 + -112;
	// 82FD0D14: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0D18: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0D1C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0D20: 807F0084  lwz r3, 0x84(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(132 as u32) ) } as u64;
	// 82FD0D24: 48008155  bl 0x82fd8e78
	ctx.lr = 0x82FD0D28;
	sub_82FD8E78(ctx, base);
	// 82FD0D28: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0D2C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0D30: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0D34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0D38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0D38 size=60
    let mut pc: u32 = 0x82FD0D38;
    'dispatch: loop {
        match pc {
            0x82FD0D38 => {
    //   block [0x82FD0D38..0x82FD0D74)
	// 82FD0D38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0D3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0D40: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD0D44: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0D48: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0D4C: 4800825D  bl 0x82fd8fa8
	ctx.lr = 0x82FD0D50;
	sub_82FD8FA8(ctx, base);
	// 82FD0D50: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0D54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0D58: 396B6998  addi r11, r11, 0x6998
	ctx.r[11].s64 = ctx.r[11].s64 + 27032;
	// 82FD0D5C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0D60: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0D64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0D68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0D6C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0D70: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0D78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0D78 size=16
    let mut pc: u32 = 0x82FD0D78;
    'dispatch: loop {
        match pc {
            0x82FD0D78 => {
    //   block [0x82FD0D78..0x82FD0D88)
	// 82FD0D78: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0D7C: 396B6998  addi r11, r11, 0x6998
	ctx.r[11].s64 = ctx.r[11].s64 + 27032;
	// 82FD0D80: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0D84: 480080F4  b 0x82fd8e78
	sub_82FD8E78(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0D88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0D88 size=8
    let mut pc: u32 = 0x82FD0D88;
    'dispatch: loop {
        match pc {
            0x82FD0D88 => {
    //   block [0x82FD0D88..0x82FD0D90)
	// 82FD0D88: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0D8C: 821369E8  lwz r16, 0x69e8(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27112 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0D90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0D90 size=92
    let mut pc: u32 = 0x82FD0D90;
    'dispatch: loop {
        match pc {
            0x82FD0D90 => {
    //   block [0x82FD0D90..0x82FD0DEC)
	// 82FD0D90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0D94: 481D73D9  bl 0x831a816c
	ctx.lr = 0x82FD0D98;
	sub_831A8130(ctx, base);
	// 82FD0D98: 3BE1FF80  addi r31, r1, -0x80
	ctx.r[31].s64 = ctx.r[1].s64 + -128;
	// 82FD0D9C: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0DA0: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD0DA4: 38600018  li r3, 0x18
	ctx.r[3].s64 = 24;
	// 82FD0DA8: 809D0014  lwz r4, 0x14(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0DAC: 93BF0094  stw r29, 0x94(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(148 as u32), ctx.r[29].u32 ) };
	// 82FD0DB0: 480074E9  bl 0x82fd8298
	ctx.lr = 0x82FD0DB4;
	sub_82FD8298(ctx, base);
	// 82FD0DB4: 7C7E1B79  or. r30, r3, r3
	ctx.r[30].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FD0DB8: 93DF0050  stw r30, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82FD0DBC: 41820024  beq 0x82fd0de0
	if ctx.cr[0].eq {
	pc = 0x82FD0DE0; continue 'dispatch;
	}
	// 82FD0DC0: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0DC4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0DC8: 480081E1  bl 0x82fd8fa8
	ctx.lr = 0x82FD0DCC;
	sub_82FD8FA8(ctx, base);
	// 82FD0DCC: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0DD0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0DD4: 396B6998  addi r11, r11, 0x6998
	ctx.r[11].s64 = ctx.r[11].s64 + 27032;
	// 82FD0DD8: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0DDC: 48000008  b 0x82fd0de4
	pc = 0x82FD0DE4; continue 'dispatch;
	// 82FD0DE0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD0DE4: 383F0080  addi r1, r31, 0x80
	ctx.r[1].s64 = ctx.r[31].s64 + 128;
	// 82FD0DE8: 481D73D4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0DEC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0DEC size=48
    let mut pc: u32 = 0x82FD0DEC;
    'dispatch: loop {
        match pc {
            0x82FD0DEC => {
    //   block [0x82FD0DEC..0x82FD0E1C)
	// 82FD0DEC: 3BECFF80  addi r31, r12, -0x80
	ctx.r[31].s64 = ctx.r[12].s64 + -128;
	// 82FD0DF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0DF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0DF8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0DFC: 817F0094  lwz r11, 0x94(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(148 as u32) ) } as u64;
	// 82FD0E00: 808B0014  lwz r4, 0x14(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0E04: 807F0050  lwz r3, 0x50(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FD0E08: 480074D9  bl 0x82fd82e0
	ctx.lr = 0x82FD0E0C;
	sub_82FD82E0(ctx, base);
	// 82FD0E0C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0E10: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0E14: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0E18: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0E20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0E20 size=12
    let mut pc: u32 = 0x82FD0E20;
    'dispatch: loop {
        match pc {
            0x82FD0E20 => {
    //   block [0x82FD0E20..0x82FD0E2C)
	// 82FD0E20: 3D608214  lis r11, -0x7dec
	ctx.r[11].s64 = -2112618496;
	// 82FD0E24: 386B82A8  addi r3, r11, -0x7d58
	ctx.r[3].s64 = ctx.r[11].s64 + -32088;
	// 82FD0E28: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0E30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0E30 size=88
    let mut pc: u32 = 0x82FD0E30;
    'dispatch: loop {
        match pc {
            0x82FD0E30 => {
    //   block [0x82FD0E30..0x82FD0E88)
	// 82FD0E30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0E34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0E38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD0E3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD0E40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0E44: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0E48: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0E4C: 396B6998  addi r11, r11, 0x6998
	ctx.r[11].s64 = ctx.r[11].s64 + 27032;
	// 82FD0E50: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD0E54: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0E58: 48008021  bl 0x82fd8e78
	ctx.lr = 0x82FD0E5C;
	sub_82FD8E78(ctx, base);
	// 82FD0E5C: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD0E60: 4182000C  beq 0x82fd0e6c
	if ctx.cr[0].eq {
	pc = 0x82FD0E6C; continue 'dispatch;
	}
	// 82FD0E64: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0E68: 48007479  bl 0x82fd82e0
	ctx.lr = 0x82FD0E6C;
	sub_82FD82E0(ctx, base);
	// 82FD0E6C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0E70: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD0E74: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0E78: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0E7C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD0E80: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0E84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0E88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0E88 size=8
    let mut pc: u32 = 0x82FD0E88;
    'dispatch: loop {
        match pc {
            0x82FD0E88 => {
    //   block [0x82FD0E88..0x82FD0E90)
	// 82FD0E88: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0E8C: 82136A30  lwz r16, 0x6a30(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27184 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0E90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0E90 size=72
    let mut pc: u32 = 0x82FD0E90;
    'dispatch: loop {
        match pc {
            0x82FD0E90 => {
    //   block [0x82FD0E90..0x82FD0ED8)
	// 82FD0E90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0E94: 481D72D9  bl 0x831a816c
	ctx.lr = 0x82FD0E98;
	sub_831A8130(ctx, base);
	// 82FD0E98: 3BE1FF90  addi r31, r1, -0x70
	ctx.r[31].s64 = ctx.r[1].s64 + -112;
	// 82FD0E9C: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0EA0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD0EA4: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FD0EA8: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 82FD0EAC: 93DF0084  stw r30, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[30].u32 ) };
	// 82FD0EB0: 48008081  bl 0x82fd8f30
	ctx.lr = 0x82FD0EB4;
	sub_82FD8F30(ctx, base);
	// 82FD0EB4: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0EB8: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0EBC: 396B6A18  addi r11, r11, 0x6a18
	ctx.r[11].s64 = ctx.r[11].s64 + 27160;
	// 82FD0EC0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0EC4: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0EC8: 480083F1  bl 0x82fd92b8
	ctx.lr = 0x82FD0ECC;
	sub_82FD92B8(ctx, base);
	// 82FD0ECC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0ED0: 383F0070  addi r1, r31, 0x70
	ctx.r[1].s64 = ctx.r[31].s64 + 112;
	// 82FD0ED4: 481D72E8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0ED8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0ED8 size=40
    let mut pc: u32 = 0x82FD0ED8;
    'dispatch: loop {
        match pc {
            0x82FD0ED8 => {
    //   block [0x82FD0ED8..0x82FD0F00)
	// 82FD0ED8: 3BECFF90  addi r31, r12, -0x70
	ctx.r[31].s64 = ctx.r[12].s64 + -112;
	// 82FD0EDC: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0EE0: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0EE4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0EE8: 807F0084  lwz r3, 0x84(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(132 as u32) ) } as u64;
	// 82FD0EEC: 48007F8D  bl 0x82fd8e78
	ctx.lr = 0x82FD0EF0;
	sub_82FD8E78(ctx, base);
	// 82FD0EF0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0EF4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0EF8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0EFC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0F00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0F00 size=60
    let mut pc: u32 = 0x82FD0F00;
    'dispatch: loop {
        match pc {
            0x82FD0F00 => {
    //   block [0x82FD0F00..0x82FD0F3C)
	// 82FD0F00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0F04: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0F08: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD0F0C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0F10: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD0F14: 48008095  bl 0x82fd8fa8
	ctx.lr = 0x82FD0F18;
	sub_82FD8FA8(ctx, base);
	// 82FD0F18: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0F1C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD0F20: 396B6A18  addi r11, r11, 0x6a18
	ctx.r[11].s64 = ctx.r[11].s64 + 27160;
	// 82FD0F24: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0F28: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0F2C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0F30: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0F34: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD0F38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0F40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0F40 size=16
    let mut pc: u32 = 0x82FD0F40;
    'dispatch: loop {
        match pc {
            0x82FD0F40 => {
    //   block [0x82FD0F40..0x82FD0F50)
	// 82FD0F40: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0F44: 396B6A18  addi r11, r11, 0x6a18
	ctx.r[11].s64 = ctx.r[11].s64 + 27160;
	// 82FD0F48: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0F4C: 48007F2C  b 0x82fd8e78
	sub_82FD8E78(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0F50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0F50 size=8
    let mut pc: u32 = 0x82FD0F50;
    'dispatch: loop {
        match pc {
            0x82FD0F50 => {
    //   block [0x82FD0F50..0x82FD0F58)
	// 82FD0F50: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD0F54: 82136A68  lwz r16, 0x6a68(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27240 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0F58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0F58 size=92
    let mut pc: u32 = 0x82FD0F58;
    'dispatch: loop {
        match pc {
            0x82FD0F58 => {
    //   block [0x82FD0F58..0x82FD0FB4)
	// 82FD0F58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0F5C: 481D7211  bl 0x831a816c
	ctx.lr = 0x82FD0F60;
	sub_831A8130(ctx, base);
	// 82FD0F60: 3BE1FF80  addi r31, r1, -0x80
	ctx.r[31].s64 = ctx.r[1].s64 + -128;
	// 82FD0F64: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0F68: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD0F6C: 38600018  li r3, 0x18
	ctx.r[3].s64 = 24;
	// 82FD0F70: 809D0014  lwz r4, 0x14(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0F74: 93BF0094  stw r29, 0x94(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(148 as u32), ctx.r[29].u32 ) };
	// 82FD0F78: 48007321  bl 0x82fd8298
	ctx.lr = 0x82FD0F7C;
	sub_82FD8298(ctx, base);
	// 82FD0F7C: 7C7E1B79  or. r30, r3, r3
	ctx.r[30].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FD0F80: 93DF0050  stw r30, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82FD0F84: 41820024  beq 0x82fd0fa8
	if ctx.cr[0].eq {
	pc = 0x82FD0FA8; continue 'dispatch;
	}
	// 82FD0F88: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD0F8C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0F90: 48008019  bl 0x82fd8fa8
	ctx.lr = 0x82FD0F94;
	sub_82FD8FA8(ctx, base);
	// 82FD0F94: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD0F98: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD0F9C: 396B6A18  addi r11, r11, 0x6a18
	ctx.r[11].s64 = ctx.r[11].s64 + 27160;
	// 82FD0FA0: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD0FA4: 48000008  b 0x82fd0fac
	pc = 0x82FD0FAC; continue 'dispatch;
	// 82FD0FA8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD0FAC: 383F0080  addi r1, r31, 0x80
	ctx.r[1].s64 = ctx.r[31].s64 + 128;
	// 82FD0FB0: 481D720C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0FB4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0FB4 size=48
    let mut pc: u32 = 0x82FD0FB4;
    'dispatch: loop {
        match pc {
            0x82FD0FB4 => {
    //   block [0x82FD0FB4..0x82FD0FE4)
	// 82FD0FB4: 3BECFF80  addi r31, r12, -0x80
	ctx.r[31].s64 = ctx.r[12].s64 + -128;
	// 82FD0FB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0FBC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD0FC0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD0FC4: 817F0094  lwz r11, 0x94(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(148 as u32) ) } as u64;
	// 82FD0FC8: 808B0014  lwz r4, 0x14(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD0FCC: 807F0050  lwz r3, 0x50(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FD0FD0: 48007311  bl 0x82fd82e0
	ctx.lr = 0x82FD0FD4;
	sub_82FD82E0(ctx, base);
	// 82FD0FD4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD0FD8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD0FDC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD0FE0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0FE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD0FE8 size=12
    let mut pc: u32 = 0x82FD0FE8;
    'dispatch: loop {
        match pc {
            0x82FD0FE8 => {
    //   block [0x82FD0FE8..0x82FD0FF4)
	// 82FD0FE8: 3D608214  lis r11, -0x7dec
	ctx.r[11].s64 = -2112618496;
	// 82FD0FEC: 386B84EC  addi r3, r11, -0x7b14
	ctx.r[3].s64 = ctx.r[11].s64 + -31508;
	// 82FD0FF0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD0FF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD0FF8 size=88
    let mut pc: u32 = 0x82FD0FF8;
    'dispatch: loop {
        match pc {
            0x82FD0FF8 => {
    //   block [0x82FD0FF8..0x82FD1050)
	// 82FD0FF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD0FFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD1000: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD1004: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD1008: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD100C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1010: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD1014: 396B6A18  addi r11, r11, 0x6a18
	ctx.r[11].s64 = ctx.r[11].s64 + 27160;
	// 82FD1018: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD101C: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD1020: 48007E59  bl 0x82fd8e78
	ctx.lr = 0x82FD1024;
	sub_82FD8E78(ctx, base);
	// 82FD1024: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1028: 4182000C  beq 0x82fd1034
	if ctx.cr[0].eq {
	pc = 0x82FD1034; continue 'dispatch;
	}
	// 82FD102C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD1030: 480072B1  bl 0x82fd82e0
	ctx.lr = 0x82FD1034;
	sub_82FD82E0(ctx, base);
	// 82FD1034: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD1038: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD103C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1040: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD1044: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD1048: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD104C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1050(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1050 size=8
    let mut pc: u32 = 0x82FD1050;
    'dispatch: loop {
        match pc {
            0x82FD1050 => {
    //   block [0x82FD1050..0x82FD1058)
	// 82FD1050: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD1054: 82136AB0  lwz r16, 0x6ab0(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27312 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1058(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1058 size=72
    let mut pc: u32 = 0x82FD1058;
    'dispatch: loop {
        match pc {
            0x82FD1058 => {
    //   block [0x82FD1058..0x82FD10A0)
	// 82FD1058: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD105C: 481D7111  bl 0x831a816c
	ctx.lr = 0x82FD1060;
	sub_831A8130(ctx, base);
	// 82FD1060: 3BE1FF90  addi r31, r1, -0x70
	ctx.r[31].s64 = ctx.r[1].s64 + -112;
	// 82FD1064: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1068: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD106C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 82FD1070: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 82FD1074: 93DF0084  stw r30, 0x84(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(132 as u32), ctx.r[30].u32 ) };
	// 82FD1078: 48007EB9  bl 0x82fd8f30
	ctx.lr = 0x82FD107C;
	sub_82FD8F30(ctx, base);
	// 82FD107C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1080: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD1084: 396B6A98  addi r11, r11, 0x6a98
	ctx.r[11].s64 = ctx.r[11].s64 + 27288;
	// 82FD1088: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD108C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD1090: 48008229  bl 0x82fd92b8
	ctx.lr = 0x82FD1094;
	sub_82FD92B8(ctx, base);
	// 82FD1094: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD1098: 383F0070  addi r1, r31, 0x70
	ctx.r[1].s64 = ctx.r[31].s64 + 112;
	// 82FD109C: 481D7120  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD10A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD10A0 size=40
    let mut pc: u32 = 0x82FD10A0;
    'dispatch: loop {
        match pc {
            0x82FD10A0 => {
    //   block [0x82FD10A0..0x82FD10C8)
	// 82FD10A0: 3BECFF90  addi r31, r12, -0x70
	ctx.r[31].s64 = ctx.r[12].s64 + -112;
	// 82FD10A4: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD10A8: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD10AC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD10B0: 807F0084  lwz r3, 0x84(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(132 as u32) ) } as u64;
	// 82FD10B4: 48007DC5  bl 0x82fd8e78
	ctx.lr = 0x82FD10B8;
	sub_82FD8E78(ctx, base);
	// 82FD10B8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD10BC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD10C0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD10C4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD10C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD10C8 size=60
    let mut pc: u32 = 0x82FD10C8;
    'dispatch: loop {
        match pc {
            0x82FD10C8 => {
    //   block [0x82FD10C8..0x82FD1104)
	// 82FD10C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD10CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD10D0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD10D4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD10D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD10DC: 48007ECD  bl 0x82fd8fa8
	ctx.lr = 0x82FD10E0;
	sub_82FD8FA8(ctx, base);
	// 82FD10E0: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD10E4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD10E8: 396B6A98  addi r11, r11, 0x6a98
	ctx.r[11].s64 = ctx.r[11].s64 + 27288;
	// 82FD10EC: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD10F0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD10F4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD10F8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD10FC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD1100: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1108 size=16
    let mut pc: u32 = 0x82FD1108;
    'dispatch: loop {
        match pc {
            0x82FD1108 => {
    //   block [0x82FD1108..0x82FD1118)
	// 82FD1108: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD110C: 396B6A98  addi r11, r11, 0x6a98
	ctx.r[11].s64 = ctx.r[11].s64 + 27288;
	// 82FD1110: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD1114: 48007D64  b 0x82fd8e78
	sub_82FD8E78(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1118(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1118 size=8
    let mut pc: u32 = 0x82FD1118;
    'dispatch: loop {
        match pc {
            0x82FD1118 => {
    //   block [0x82FD1118..0x82FD1120)
	// 82FD1118: 831A93F0  lwz r24, -0x6c10(r26)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-27664 as u32) ) } as u64;
	// 82FD111C: 82136AE8  lwz r16, 0x6ae8(r19)
	ctx.r[16].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(27368 as u32) ) } as u64;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1120(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1120 size=92
    let mut pc: u32 = 0x82FD1120;
    'dispatch: loop {
        match pc {
            0x82FD1120 => {
    //   block [0x82FD1120..0x82FD117C)
	// 82FD1120: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1124: 481D7049  bl 0x831a816c
	ctx.lr = 0x82FD1128;
	sub_831A8130(ctx, base);
	// 82FD1128: 3BE1FF80  addi r31, r1, -0x80
	ctx.r[31].s64 = ctx.r[1].s64 + -128;
	// 82FD112C: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1130: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD1134: 38600018  li r3, 0x18
	ctx.r[3].s64 = 24;
	// 82FD1138: 809D0014  lwz r4, 0x14(r29)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD113C: 93BF0094  stw r29, 0x94(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(148 as u32), ctx.r[29].u32 ) };
	// 82FD1140: 48007159  bl 0x82fd8298
	ctx.lr = 0x82FD1144;
	sub_82FD8298(ctx, base);
	// 82FD1144: 7C7E1B79  or. r30, r3, r3
	ctx.r[30].u64 = ctx.r[3].u64 | ctx.r[3].u64;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 82FD1148: 93DF0050  stw r30, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[30].u32 ) };
	// 82FD114C: 41820024  beq 0x82fd1170
	if ctx.cr[0].eq {
	pc = 0x82FD1170; continue 'dispatch;
	}
	// 82FD1150: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD1154: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD1158: 48007E51  bl 0x82fd8fa8
	ctx.lr = 0x82FD115C;
	sub_82FD8FA8(ctx, base);
	// 82FD115C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1160: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD1164: 396B6A98  addi r11, r11, 0x6a98
	ctx.r[11].s64 = ctx.r[11].s64 + 27288;
	// 82FD1168: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD116C: 48000008  b 0x82fd1174
	pc = 0x82FD1174; continue 'dispatch;
	// 82FD1170: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1174: 383F0080  addi r1, r31, 0x80
	ctx.r[1].s64 = ctx.r[31].s64 + 128;
	// 82FD1178: 481D7044  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD117C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD117C size=48
    let mut pc: u32 = 0x82FD117C;
    'dispatch: loop {
        match pc {
            0x82FD117C => {
    //   block [0x82FD117C..0x82FD11AC)
	// 82FD117C: 3BECFF80  addi r31, r12, -0x80
	ctx.r[31].s64 = ctx.r[12].s64 + -128;
	// 82FD1180: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1184: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD1188: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD118C: 817F0094  lwz r11, 0x94(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(148 as u32) ) } as u64;
	// 82FD1190: 808B0014  lwz r4, 0x14(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD1194: 807F0050  lwz r3, 0x50(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 82FD1198: 48007149  bl 0x82fd82e0
	ctx.lr = 0x82FD119C;
	sub_82FD82E0(ctx, base);
	// 82FD119C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD11A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD11A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD11A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD11B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD11B0 size=12
    let mut pc: u32 = 0x82FD11B0;
    'dispatch: loop {
        match pc {
            0x82FD11B0 => {
    //   block [0x82FD11B0..0x82FD11BC)
	// 82FD11B0: 3D608214  lis r11, -0x7dec
	ctx.r[11].s64 = -2112618496;
	// 82FD11B4: 386B83A8  addi r3, r11, -0x7c58
	ctx.r[3].s64 = ctx.r[11].s64 + -31832;
	// 82FD11B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD11C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD11C0 size=88
    let mut pc: u32 = 0x82FD11C0;
    'dispatch: loop {
        match pc {
            0x82FD11C0 => {
    //   block [0x82FD11C0..0x82FD1218)
	// 82FD11C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD11C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD11C8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD11CC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD11D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD11D4: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD11D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD11DC: 396B6A98  addi r11, r11, 0x6a98
	ctx.r[11].s64 = ctx.r[11].s64 + 27288;
	// 82FD11E0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD11E4: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD11E8: 48007C91  bl 0x82fd8e78
	ctx.lr = 0x82FD11EC;
	sub_82FD8E78(ctx, base);
	// 82FD11EC: 57CB07FF  clrlwi. r11, r30, 0x1f
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD11F0: 4182000C  beq 0x82fd11fc
	if ctx.cr[0].eq {
	pc = 0x82FD11FC; continue 'dispatch;
	}
	// 82FD11F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD11F8: 480070E9  bl 0x82fd82e0
	ctx.lr = 0x82FD11FC;
	sub_82FD82E0(ctx, base);
	// 82FD11FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD1200: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD1204: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1208: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD120C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD1210: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD1214: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1218(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1218 size=16
    let mut pc: u32 = 0x82FD1218;
    'dispatch: loop {
        match pc {
            0x82FD1218 => {
    //   block [0x82FD1218..0x82FD1228)
	// 82FD1218: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82FD121C: 409A000C  bne cr6, 0x82fd1228
	if !ctx.cr[6].eq {
		sub_82FD1228(ctx, base);
		return;
	}
	// 82FD1220: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1224: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1228(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1228 size=4
    let mut pc: u32 = 0x82FD1228;
    'dispatch: loop {
        match pc {
            0x82FD1228 => {
    //   block [0x82FD1228..0x82FD122C)
	// 82FD1228: 481DBBA8  b 0x831acdd0
	sub_831ACDD0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1230(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1230 size=12
    let mut pc: u32 = 0x82FD1230;
    'dispatch: loop {
        match pc {
            0x82FD1230 => {
    //   block [0x82FD1230..0x82FD123C)
	// 82FD1230: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1234: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD1238: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD123C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD123C size=56
    let mut pc: u32 = 0x82FD123C;
    'dispatch: loop {
        match pc {
            0x82FD123C => {
    //   block [0x82FD123C..0x82FD1274)
	// 82FD123C: 548A083C  slwi r10, r4, 1
	ctx.r[10].u32 = ctx.r[4].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1240: 7D2A5A14  add r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FD1244: A1490000  lhz r10, 0(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1248: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD124C: 4182001C  beq 0x82fd1268
	if ctx.cr[0].eq {
	pc = 0x82FD1268; continue 'dispatch;
	}
	// 82FD1250: 7D2B4850  subf r9, r11, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 82FD1254: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD1258: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD125C: 7D495A2E  lhzx r10, r9, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD1260: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1264: 4082FFF0  bne 0x82fd1254
	if !ctx.cr[0].eq {
	pc = 0x82FD1254; continue 'dispatch;
	}
	// 82FD1268: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD126C: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD1270: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1278(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1278 size=144
    let mut pc: u32 = 0x82FD1278;
    'dispatch: loop {
        match pc {
            0x82FD1278 => {
    //   block [0x82FD1278..0x82FD1308)
	// 82FD1278: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD127C: 481D6EF1  bl 0x831a816c
	ctx.lr = 0x82FD1280;
	sub_831A8130(ctx, base);
	// 82FD1280: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1284: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD1288: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FD128C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82FD1290: 419A006C  beq cr6, 0x82fd12fc
	if ctx.cr[6].eq {
	pc = 0x82FD12FC; continue 'dispatch;
	}
	// 82FD1294: A17D0000  lhz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1298: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD129C: 41820028  beq 0x82fd12c4
	if ctx.cr[0].eq {
	pc = 0x82FD12C4; continue 'dispatch;
	}
	// 82FD12A0: 397D0002  addi r11, r29, 2
	ctx.r[11].s64 = ctx.r[29].s64 + 2;
	// 82FD12A4: 48000008  b 0x82fd12ac
	pc = 0x82FD12AC; continue 'dispatch;
	// 82FD12A8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD12AC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD12B0: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD12B4: 4082FFF4  bne 0x82fd12a8
	if !ctx.cr[0].eq {
	pc = 0x82FD12A8; continue 'dispatch;
	}
	// 82FD12B8: 7D7D5850  subf r11, r29, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[29].s64;
	// 82FD12BC: 7D7E0E70  srawi r30, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[30].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD12C0: 48000008  b 0x82fd12c8
	pc = 0x82FD12C8; continue 'dispatch;
	// 82FD12C4: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 82FD12C8: 3D407FFF  lis r10, 0x7fff
	ctx.r[10].s64 = 2147418112;
	// 82FD12CC: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 82FD12D0: 614AFFFF  ori r10, r10, 0xffff
	ctx.r[10].u64 = ctx.r[10].u64 | 65535;
	// 82FD12D4: 5563083C  slwi r3, r11, 1
	ctx.r[3].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FD12D8: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82FD12DC: 40990008  ble cr6, 0x82fd12e4
	if !ctx.cr[6].gt {
	pc = 0x82FD12E4; continue 'dispatch;
	}
	// 82FD12E0: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FD12E4: 4B2EF655  bl 0x822c0938
	ctx.lr = 0x82FD12E8;
	sub_822C0938(ctx, base);
	// 82FD12E8: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 82FD12EC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD12F0: 5565083C  slwi r5, r11, 1
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD12F4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD12F8: 481D7219  bl 0x831a8510
	ctx.lr = 0x82FD12FC;
	sub_831A8510(ctx, base);
	// 82FD12FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD1300: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD1304: 481D6EB8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1308(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1308 size=116
    let mut pc: u32 = 0x82FD1308;
    'dispatch: loop {
        match pc {
            0x82FD1308 => {
    //   block [0x82FD1308..0x82FD137C)
	// 82FD1308: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD130C: 481D6E61  bl 0x831a816c
	ctx.lr = 0x82FD1310;
	sub_831A8130(ctx, base);
	// 82FD1310: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1314: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 82FD1318: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82FD131C: 419A0058  beq cr6, 0x82fd1374
	if ctx.cr[6].eq {
	pc = 0x82FD1374; continue 'dispatch;
	}
	// 82FD1320: 7FABEB78  mr r11, r29
	ctx.r[11].u64 = ctx.r[29].u64;
	// 82FD1324: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 82FD1328: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD132C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD1330: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82FD1334: 409AFFF4  bne cr6, 0x82fd1328
	if !ctx.cr[6].eq {
	pc = 0x82FD1328; continue 'dispatch;
	}
	// 82FD1338: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82FD133C: 81440000  lwz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1340: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 82FD1344: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FD1348: 556B003E  slwi r11, r11, 0
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD134C: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD1350: 3BEB0001  addi r31, r11, 1
	ctx.r[31].s64 = ctx.r[11].s64 + 1;
	// 82FD1354: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD1358: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 82FD135C: 4E800421  bctrl
	ctx.lr = 0x82FD1360;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD1360: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 82FD1364: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 82FD1368: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD136C: 481D71A5  bl 0x831a8510
	ctx.lr = 0x82FD1370;
	sub_831A8510(ctx, base);
	// 82FD1370: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD1374: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD1378: 481D6E44  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1380(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1380 size=36
    let mut pc: u32 = 0x82FD1380;
    'dispatch: loop {
        match pc {
            0x82FD1380 => {
    //   block [0x82FD1380..0x82FD13A4)
	// 82FD1380: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1384: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1388: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 82FD138C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82FD1390: 409AFFF4  bne cr6, 0x82fd1384
	if !ctx.cr[6].eq {
	pc = 0x82FD1384; continue 'dispatch;
	}
	// 82FD1394: 7D6B1850  subf r11, r11, r3
	ctx.r[11].s64 = ctx.r[3].s64 - ctx.r[11].s64;
	// 82FD1398: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FD139C: 5563003E  slwi r3, r11, 0
	ctx.r[3].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FD13A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD13A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD13A8 size=32
    let mut pc: u32 = 0x82FD13A8;
    'dispatch: loop {
        match pc {
            0x82FD13A8 => {
    //   block [0x82FD13A8..0x82FD13C8)
	// 82FD13A8: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD13AC: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD13B0: 816BB7C0  lwz r11, -0x4840(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD13B4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD13B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD13BC: 816A0020  lwz r11, 0x20(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 82FD13C0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD13C4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD13C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD13C8 size=36
    let mut pc: u32 = 0x82FD13C8;
    'dispatch: loop {
        match pc {
            0x82FD13C8 => {
    //   block [0x82FD13C8..0x82FD13EC)
	// 82FD13C8: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD13CC: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82FD13D0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD13D4: 816BB7C0  lwz r11, -0x4840(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD13D8: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD13DC: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD13E0: 816A001C  lwz r11, 0x1c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) } as u64;
	// 82FD13E4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD13E8: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD13F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD13F0 size=32
    let mut pc: u32 = 0x82FD13F0;
    'dispatch: loop {
        match pc {
            0x82FD13F0 => {
    //   block [0x82FD13F0..0x82FD1410)
	// 82FD13F0: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD13F4: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD13F8: 816BB7C0  lwz r11, -0x4840(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD13FC: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD1400: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1404: 816A0018  lwz r11, 0x18(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FD1408: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD140C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1410(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1410 size=36
    let mut pc: u32 = 0x82FD1410;
    'dispatch: loop {
        match pc {
            0x82FD1410 => {
    //   block [0x82FD1410..0x82FD1434)
	// 82FD1410: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD1414: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82FD1418: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD141C: 816BB7C0  lwz r11, -0x4840(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD1420: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD1424: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1428: 816A0014  lwz r11, 0x14(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD142C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD1430: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1438(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1438 size=88
    let mut pc: u32 = 0x82FD1438;
    'dispatch: loop {
        match pc {
            0x82FD1438 => {
    //   block [0x82FD1438..0x82FD1490)
	// 82FD1438: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD143C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD1440: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1444: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD1448: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 82FD144C: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 82FD1450: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82FD1454: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD1458: 816BB7C0  lwz r11, -0x4840(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD145C: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD1460: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1464: 816A0010  lwz r11, 0x10(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD1468: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD146C: 4E800421  bctrl
	ctx.lr = 0x82FD1470;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD1470: 546B063E  clrlwi r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	// 82FD1474: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82FD1478: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82FD147C: 69630001  xori r3, r11, 1
	ctx.r[3].u64 = ctx.r[11].u64 ^ 1;
	// 82FD1480: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD1484: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1488: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD148C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1490(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1490 size=28
    let mut pc: u32 = 0x82FD1490;
    'dispatch: loop {
        match pc {
            0x82FD1490 => {
    //   block [0x82FD1490..0x82FD14AC)
	// 82FD1490: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD1494: 419A0034  beq cr6, 0x82fd14c8
	if ctx.cr[6].eq {
		sub_82FD14C8(ctx, base);
		return;
	}
	// 82FD1498: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD149C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD14A0: 41820028  beq 0x82fd14c8
	if ctx.cr[0].eq {
		sub_82FD14C8(ctx, base);
		return;
	}
	// 82FD14A4: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD14A8: 48000008  b 0x82fd14b0
	sub_82FD14AC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD14AC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD14AC size=28
    let mut pc: u32 = 0x82FD14AC;
    'dispatch: loop {
        match pc {
            0x82FD14AC => {
    //   block [0x82FD14AC..0x82FD14C8)
	// 82FD14AC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD14B0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD14B4: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD14B8: 4082FFF4  bne 0x82fd14ac
	if !ctx.cr[0].eq {
	pc = 0x82FD14AC; continue 'dispatch;
	}
	// 82FD14BC: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD14C0: 7D640E70  srawi r4, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD14C4: 48000008  b 0x82fd14cc
	sub_82FD14C8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD14C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD14C8 size=8
    let mut pc: u32 = 0x82FD14C8;
    'dispatch: loop {
        match pc {
            0x82FD14C8 => {
    //   block [0x82FD14C8..0x82FD14D0)
	// 82FD14C8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FD14CC: 48008184  b 0x82fd9650
	sub_82FD9650(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD14D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD14D0 size=28
    let mut pc: u32 = 0x82FD14D0;
    'dispatch: loop {
        match pc {
            0x82FD14D0 => {
    //   block [0x82FD14D0..0x82FD14EC)
	// 82FD14D0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD14D4: 419A0034  beq cr6, 0x82fd1508
	if ctx.cr[6].eq {
		sub_82FD1508(ctx, base);
		return;
	}
	// 82FD14D8: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD14DC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD14E0: 41820028  beq 0x82fd1508
	if ctx.cr[0].eq {
		sub_82FD1508(ctx, base);
		return;
	}
	// 82FD14E4: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD14E8: 48000008  b 0x82fd14f0
	sub_82FD14EC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD14EC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD14EC size=28
    let mut pc: u32 = 0x82FD14EC;
    'dispatch: loop {
        match pc {
            0x82FD14EC => {
    //   block [0x82FD14EC..0x82FD1508)
	// 82FD14EC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD14F0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD14F4: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD14F8: 4082FFF4  bne 0x82fd14ec
	if !ctx.cr[0].eq {
	pc = 0x82FD14EC; continue 'dispatch;
	}
	// 82FD14FC: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD1500: 7D640E70  srawi r4, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1504: 48000008  b 0x82fd150c
	sub_82FD1508(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1508(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1508 size=8
    let mut pc: u32 = 0x82FD1508;
    'dispatch: loop {
        match pc {
            0x82FD1508 => {
    //   block [0x82FD1508..0x82FD1510)
	// 82FD1508: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FD150C: 480081EC  b 0x82fd96f8
	sub_82FD96F8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1510(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1510 size=28
    let mut pc: u32 = 0x82FD1510;
    'dispatch: loop {
        match pc {
            0x82FD1510 => {
    //   block [0x82FD1510..0x82FD152C)
	// 82FD1510: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD1514: 419A0034  beq cr6, 0x82fd1548
	if ctx.cr[6].eq {
		sub_82FD1548(ctx, base);
		return;
	}
	// 82FD1518: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD151C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1520: 41820028  beq 0x82fd1548
	if ctx.cr[0].eq {
		sub_82FD1548(ctx, base);
		return;
	}
	// 82FD1524: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD1528: 48000008  b 0x82fd1530
	sub_82FD152C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD152C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD152C size=28
    let mut pc: u32 = 0x82FD152C;
    'dispatch: loop {
        match pc {
            0x82FD152C => {
    //   block [0x82FD152C..0x82FD1548)
	// 82FD152C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1530: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1534: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1538: 4082FFF4  bne 0x82fd152c
	if !ctx.cr[0].eq {
	pc = 0x82FD152C; continue 'dispatch;
	}
	// 82FD153C: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD1540: 7D640E70  srawi r4, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1544: 48000008  b 0x82fd154c
	sub_82FD1548(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1548(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1548 size=8
    let mut pc: u32 = 0x82FD1548;
    'dispatch: loop {
        match pc {
            0x82FD1548 => {
    //   block [0x82FD1548..0x82FD1550)
	// 82FD1548: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FD154C: 480081FC  b 0x82fd9748
	sub_82FD9748(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1550(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1550 size=44
    let mut pc: u32 = 0x82FD1550;
    'dispatch: loop {
        match pc {
            0x82FD1550 => {
    //   block [0x82FD1550..0x82FD157C)
	// 82FD1550: 546B043E  clrlwi r11, r3, 0x10
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 82FD1554: 2B0B0061  cmplwi cr6, r11, 0x61
	ctx.cr[6].compare_u32(ctx.r[11].u32, 97 as u32, &mut ctx.xer);
	// 82FD1558: 4198000C  blt cr6, 0x82fd1564
	if ctx.cr[6].lt {
	pc = 0x82FD1564; continue 'dispatch;
	}
	// 82FD155C: 2B0B007A  cmplwi cr6, r11, 0x7a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 122 as u32, &mut ctx.xer);
	// 82FD1560: 40990014  ble cr6, 0x82fd1574
	if !ctx.cr[6].gt {
	pc = 0x82FD1574; continue 'dispatch;
	}
	// 82FD1564: 2B0B0041  cmplwi cr6, r11, 0x41
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65 as u32, &mut ctx.xer);
	// 82FD1568: 41980014  blt cr6, 0x82fd157c
	if ctx.cr[6].lt {
		sub_82FD157C(ctx, base);
		return;
	}
	// 82FD156C: 2B0B005A  cmplwi cr6, r11, 0x5a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 90 as u32, &mut ctx.xer);
	// 82FD1570: 4199000C  bgt cr6, 0x82fd157c
	if ctx.cr[6].gt {
		sub_82FD157C(ctx, base);
		return;
	}
	// 82FD1574: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD1578: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD157C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD157C size=8
    let mut pc: u32 = 0x82FD157C;
    'dispatch: loop {
        match pc {
            0x82FD157C => {
    //   block [0x82FD157C..0x82FD1584)
	// 82FD157C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1580: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1588 size=24
    let mut pc: u32 = 0x82FD1588;
    'dispatch: loop {
        match pc {
            0x82FD1588 => {
    //   block [0x82FD1588..0x82FD15A0)
	// 82FD1588: 546B043E  clrlwi r11, r3, 0x10
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 82FD158C: 2B0B0030  cmplwi cr6, r11, 0x30
	ctx.cr[6].compare_u32(ctx.r[11].u32, 48 as u32, &mut ctx.xer);
	// 82FD1590: 41980010  blt cr6, 0x82fd15a0
	if ctx.cr[6].lt {
		sub_82FD15A0(ctx, base);
		return;
	}
	// 82FD1594: 2B0B0039  cmplwi cr6, r11, 0x39
	ctx.cr[6].compare_u32(ctx.r[11].u32, 57 as u32, &mut ctx.xer);
	// 82FD1598: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD159C: 4C990020  blelr cr6
	if !ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD15A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD15A0 size=8
    let mut pc: u32 = 0x82FD15A0;
    'dispatch: loop {
        match pc {
            0x82FD15A0 => {
    //   block [0x82FD15A0..0x82FD15A8)
	// 82FD15A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD15A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD15A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD15A8 size=44
    let mut pc: u32 = 0x82FD15A8;
    'dispatch: loop {
        match pc {
            0x82FD15A8 => {
    //   block [0x82FD15A8..0x82FD15D4)
	// 82FD15A8: 546B043E  clrlwi r11, r3, 0x10
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 82FD15AC: 2B0B0061  cmplwi cr6, r11, 0x61
	ctx.cr[6].compare_u32(ctx.r[11].u32, 97 as u32, &mut ctx.xer);
	// 82FD15B0: 4198000C  blt cr6, 0x82fd15bc
	if ctx.cr[6].lt {
	pc = 0x82FD15BC; continue 'dispatch;
	}
	// 82FD15B4: 2B0B007A  cmplwi cr6, r11, 0x7a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 122 as u32, &mut ctx.xer);
	// 82FD15B8: 40990014  ble cr6, 0x82fd15cc
	if !ctx.cr[6].gt {
	pc = 0x82FD15CC; continue 'dispatch;
	}
	// 82FD15BC: 2B0B0041  cmplwi cr6, r11, 0x41
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65 as u32, &mut ctx.xer);
	// 82FD15C0: 41980014  blt cr6, 0x82fd15d4
	if ctx.cr[6].lt {
		sub_82FD15D4(ctx, base);
		return;
	}
	// 82FD15C4: 2B0B005A  cmplwi cr6, r11, 0x5a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 90 as u32, &mut ctx.xer);
	// 82FD15C8: 4199000C  bgt cr6, 0x82fd15d4
	if ctx.cr[6].gt {
		sub_82FD15D4(ctx, base);
		return;
	}
	// 82FD15CC: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FD15D0: 48000008  b 0x82fd15d8
	sub_82FD15D4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD15D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD15D4 size=60
    let mut pc: u32 = 0x82FD15D4;
    'dispatch: loop {
        match pc {
            0x82FD15D4 => {
    //   block [0x82FD15D4..0x82FD1610)
	// 82FD15D4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD15D8: 554A063F  clrlwi. r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD15DC: 40820028  bne 0x82fd1604
	if !ctx.cr[0].eq {
	pc = 0x82FD1604; continue 'dispatch;
	}
	// 82FD15E0: 2B0B0030  cmplwi cr6, r11, 0x30
	ctx.cr[6].compare_u32(ctx.r[11].u32, 48 as u32, &mut ctx.xer);
	// 82FD15E4: 41980010  blt cr6, 0x82fd15f4
	if ctx.cr[6].lt {
	pc = 0x82FD15F4; continue 'dispatch;
	}
	// 82FD15E8: 2B0B0039  cmplwi cr6, r11, 0x39
	ctx.cr[6].compare_u32(ctx.r[11].u32, 57 as u32, &mut ctx.xer);
	// 82FD15EC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FD15F0: 40990008  ble cr6, 0x82fd15f8
	if !ctx.cr[6].gt {
	pc = 0x82FD15F8; continue 'dispatch;
	}
	// 82FD15F4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD15F8: 556B063F  clrlwi. r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD15FC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD1600: 41820008  beq 0x82fd1608
	if ctx.cr[0].eq {
	pc = 0x82FD1608; continue 'dispatch;
	}
	// 82FD1604: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FD1608: 5563063E  clrlwi r3, r11, 0x18
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82FD160C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1610 size=76
    let mut pc: u32 = 0x82FD1610;
    'dispatch: loop {
        match pc {
            0x82FD1610 => {
    //   block [0x82FD1610..0x82FD165C)
	// 82FD1610: 546B043E  clrlwi r11, r3, 0x10
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 82FD1614: 2B0B0030  cmplwi cr6, r11, 0x30
	ctx.cr[6].compare_u32(ctx.r[11].u32, 48 as u32, &mut ctx.xer);
	// 82FD1618: 41980010  blt cr6, 0x82fd1628
	if ctx.cr[6].lt {
	pc = 0x82FD1628; continue 'dispatch;
	}
	// 82FD161C: 2B0B0039  cmplwi cr6, r11, 0x39
	ctx.cr[6].compare_u32(ctx.r[11].u32, 57 as u32, &mut ctx.xer);
	// 82FD1620: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 82FD1624: 40990008  ble cr6, 0x82fd162c
	if !ctx.cr[6].gt {
	pc = 0x82FD162C; continue 'dispatch;
	}
	// 82FD1628: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD162C: 554A063F  clrlwi. r10, r10, 0x18
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD1630: 4082002C  bne 0x82fd165c
	if !ctx.cr[0].eq {
		sub_82FD165C(ctx, base);
		return;
	}
	// 82FD1634: 2B0B0061  cmplwi cr6, r11, 0x61
	ctx.cr[6].compare_u32(ctx.r[11].u32, 97 as u32, &mut ctx.xer);
	// 82FD1638: 4198000C  blt cr6, 0x82fd1644
	if ctx.cr[6].lt {
	pc = 0x82FD1644; continue 'dispatch;
	}
	// 82FD163C: 2B0B0066  cmplwi cr6, r11, 0x66
	ctx.cr[6].compare_u32(ctx.r[11].u32, 102 as u32, &mut ctx.xer);
	// 82FD1640: 4099001C  ble cr6, 0x82fd165c
	if !ctx.cr[6].gt {
		sub_82FD165C(ctx, base);
		return;
	}
	// 82FD1644: 2B0B0041  cmplwi cr6, r11, 0x41
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65 as u32, &mut ctx.xer);
	// 82FD1648: 4198000C  blt cr6, 0x82fd1654
	if ctx.cr[6].lt {
	pc = 0x82FD1654; continue 'dispatch;
	}
	// 82FD164C: 2B0B0046  cmplwi cr6, r11, 0x46
	ctx.cr[6].compare_u32(ctx.r[11].u32, 70 as u32, &mut ctx.xer);
	// 82FD1650: 4099000C  ble cr6, 0x82fd165c
	if !ctx.cr[6].gt {
		sub_82FD165C(ctx, base);
		return;
	}
	// 82FD1654: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD1658: 48000008  b 0x82fd1660
	sub_82FD165C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD165C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD165C size=12
    let mut pc: u32 = 0x82FD165C;
    'dispatch: loop {
        match pc {
            0x82FD165C => {
    //   block [0x82FD165C..0x82FD1668)
	// 82FD165C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FD1660: 5563063E  clrlwi r3, r11, 0x18
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82FD1664: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1668(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1668 size=28
    let mut pc: u32 = 0x82FD1668;
    'dispatch: loop {
        match pc {
            0x82FD1668 => {
    //   block [0x82FD1668..0x82FD1684)
	// 82FD1668: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD166C: 419A0034  beq cr6, 0x82fd16a0
	if ctx.cr[6].eq {
		sub_82FD16A0(ctx, base);
		return;
	}
	// 82FD1670: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1674: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1678: 41820028  beq 0x82fd16a0
	if ctx.cr[0].eq {
		sub_82FD16A0(ctx, base);
		return;
	}
	// 82FD167C: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD1680: 48000008  b 0x82fd1688
	sub_82FD1684(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1684(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1684 size=28
    let mut pc: u32 = 0x82FD1684;
    'dispatch: loop {
        match pc {
            0x82FD1684 => {
    //   block [0x82FD1684..0x82FD16A0)
	// 82FD1684: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1688: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD168C: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1690: 4082FFF4  bne 0x82fd1684
	if !ctx.cr[0].eq {
	pc = 0x82FD1684; continue 'dispatch;
	}
	// 82FD1694: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD1698: 7D640E70  srawi r4, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD169C: 48000008  b 0x82fd16a4
	sub_82FD16A0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD16A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD16A0 size=8
    let mut pc: u32 = 0x82FD16A0;
    'dispatch: loop {
        match pc {
            0x82FD16A0 => {
    //   block [0x82FD16A0..0x82FD16A8)
	// 82FD16A0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 82FD16A4: 48007F64  b 0x82fd9608
	sub_82FD9608(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD16A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD16A8 size=448
    let mut pc: u32 = 0x82FD16A8;
    'dispatch: loop {
        match pc {
            0x82FD16A8 => {
    //   block [0x82FD16A8..0x82FD1868)
	// 82FD16A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD16AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD16B0: 9421FE80  stwu r1, -0x180(r1)
	ea = ctx.r[1].u32.wrapping_add(-384 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD16B4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FD16B8: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 82FD16BC: 409A002C  bne cr6, 0x82fd16e8
	if !ctx.cr[6].eq {
	pc = 0x82FD16E8; continue 'dispatch;
	}
	// 82FD16C0: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD16C4: 38C00051  li r6, 0x51
	ctx.r[6].s64 = 81;
	// 82FD16C8: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD16CC: 38A00323  li r5, 0x323
	ctx.r[5].s64 = 803;
	// 82FD16D0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD16D4: 4BFFF5F5  bl 0x82fd0cc8
	ctx.lr = 0x82FD16D8;
	sub_82FD0CC8(ctx, base);
	// 82FD16D8: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD16DC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD16E0: 388BC3FC  addi r4, r11, -0x3c04
	ctx.r[4].s64 = ctx.r[11].s64 + -15364;
	// 82FD16E4: 481DF545  bl 0x831b0c28
	ctx.lr = 0x82FD16E8;
	sub_831B0C28(ctx, base);
	// 82FD16E8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82FD16EC: 409A0014  bne cr6, 0x82fd1700
	if !ctx.cr[6].eq {
	pc = 0x82FD1700; continue 'dispatch;
	}
	// 82FD16F0: 39600030  li r11, 0x30
	ctx.r[11].s64 = 48;
	// 82FD16F4: B1440002  sth r10, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[10].u16 ) };
	// 82FD16F8: B1640000  sth r11, 0(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82FD16FC: 4800015C  b 0x82fd1858
	pc = 0x82FD1858; continue 'dispatch;
	// 82FD1700: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD1704: 2B060002  cmplwi cr6, r6, 2
	ctx.cr[6].compare_u32(ctx.r[6].u32, 2 as u32, &mut ctx.xer);
	// 82FD1708: 409A0030  bne cr6, 0x82fd1738
	if !ctx.cr[6].eq {
	pc = 0x82FD1738; continue 'dispatch;
	}
	// 82FD170C: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 82FD1710: 554807FF  clrlwi. r8, r10, 0x1f
	ctx.r[8].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FD1714: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD1718: 39000031  li r8, 0x31
	ctx.r[8].s64 = 49;
	// 82FD171C: 40820008  bne 0x82fd1724
	if !ctx.cr[0].eq {
	pc = 0x82FD1724; continue 'dispatch;
	}
	// 82FD1720: 39000030  li r8, 0x30
	ctx.r[8].s64 = 48;
	// 82FD1724: B1090000  sth r8, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 82FD1728: 554AF87F  rlwinm. r10, r10, 0x1f, 1, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD172C: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD1730: 4082FFE0  bne 0x82fd1710
	if !ctx.cr[0].eq {
	pc = 0x82FD1710; continue 'dispatch;
	}
	// 82FD1734: 480000AC  b 0x82fd17e0
	pc = 0x82FD17E0; continue 'dispatch;
	// 82FD1738: 2B060010  cmplwi cr6, r6, 0x10
	ctx.cr[6].compare_u32(ctx.r[6].u32, 16 as u32, &mut ctx.xer);
	// 82FD173C: 409A0030  bne cr6, 0x82fd176c
	if !ctx.cr[6].eq {
	pc = 0x82FD176C; continue 'dispatch;
	}
	// 82FD1740: 3D008213  lis r8, -0x7ded
	ctx.r[8].s64 = -2112684032;
	// 82FD1744: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 82FD1748: 39086B48  addi r8, r8, 0x6b48
	ctx.r[8].s64 = ctx.r[8].s64 + 27464;
	// 82FD174C: 55460EFC  rlwinm r6, r10, 1, 0x1b, 0x1e
	ctx.r[6].u64 = ctx.r[10].u32 as u64 & 0x7FFFFFFFu64;
	// 82FD1750: 554AE13F  rlwinm. r10, r10, 0x1c, 4, 0x1f
	ctx.r[10].u64 = ctx.r[10].u32 as u64 & 0x0000000Fu64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD1754: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD1758: 7CC6422E  lhzx r6, r6, r8
	ctx.r[6].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 82FD175C: B0C90000  sth r6, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 82FD1760: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD1764: 4082FFE8  bne 0x82fd174c
	if !ctx.cr[0].eq {
	pc = 0x82FD174C; continue 'dispatch;
	}
	// 82FD1768: 48000078  b 0x82fd17e0
	pc = 0x82FD17E0; continue 'dispatch;
	// 82FD176C: 2B060008  cmplwi cr6, r6, 8
	ctx.cr[6].compare_u32(ctx.r[6].u32, 8 as u32, &mut ctx.xer);
	// 82FD1770: 419A0034  beq cr6, 0x82fd17a4
	if ctx.cr[6].eq {
	pc = 0x82FD17A4; continue 'dispatch;
	}
	// 82FD1774: 2B06000A  cmplwi cr6, r6, 0xa
	ctx.cr[6].compare_u32(ctx.r[6].u32, 10 as u32, &mut ctx.xer);
	// 82FD1778: 419A002C  beq cr6, 0x82fd17a4
	if ctx.cr[6].eq {
	pc = 0x82FD17A4; continue 'dispatch;
	}
	// 82FD177C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1780: 38C00052  li r6, 0x52
	ctx.r[6].s64 = 82;
	// 82FD1784: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD1788: 38A0035E  li r5, 0x35e
	ctx.r[5].s64 = 862;
	// 82FD178C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1790: 4BFFF8C9  bl 0x82fd1058
	ctx.lr = 0x82FD1794;
	sub_82FD1058(ctx, base);
	// 82FD1794: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD1798: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD179C: 388BC3EC  addi r4, r11, -0x3c14
	ctx.r[4].s64 = ctx.r[11].s64 + -15380;
	// 82FD17A0: 481DF489  bl 0x831b0c28
	ctx.lr = 0x82FD17A4;
	sub_831B0C28(ctx, base);
	// 82FD17A4: 3D008213  lis r8, -0x7ded
	ctx.r[8].s64 = -2112684032;
	// 82FD17A8: 39210070  addi r9, r1, 0x70
	ctx.r[9].s64 = ctx.r[1].s64 + 112;
	// 82FD17AC: 39086B48  addi r8, r8, 0x6b48
	ctx.r[8].s64 = ctx.r[8].s64 + 27464;
	// 82FD17B0: 7C6A3396  divwu r3, r10, r6
	ctx.r[3].u32 = ctx.r[10].u32 / ctx.r[6].u32;
	// 82FD17B4: 0CC60000  twi 6, r6, 0
	// 82FD17B8: 7C6331D6  mullw r3, r3, r6
	ctx.r[3].s64 = (ctx.r[3].s32 as i64) * (ctx.r[6].s32 as i64);
	// 82FD17BC: 7C635050  subf r3, r3, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[3].s64;
	// 82FD17C0: 7D4A3397  divwu. r10, r10, r6
	ctx.r[10].u32 = ctx.r[10].u32 / ctx.r[6].u32;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 82FD17C4: 5463083C  slwi r3, r3, 1
	ctx.r[3].u32 = ctx.r[3].u32.wrapping_shl(1);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 82FD17C8: 0CC60000  twi 6, r6, 0
	// 82FD17CC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD17D0: 7C63422E  lhzx r3, r3, r8
	ctx.r[3].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 82FD17D4: B0690000  sth r3, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[3].u16 ) };
	// 82FD17D8: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD17DC: 4082FFD4  bne 0x82fd17b0
	if !ctx.cr[0].eq {
	pc = 0x82FD17B0; continue 'dispatch;
	}
	// 82FD17E0: 7F0B2840  cmplw cr6, r11, r5
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[5].u32, &mut ctx.xer);
	// 82FD17E4: 4099002C  ble cr6, 0x82fd1810
	if !ctx.cr[6].gt {
	pc = 0x82FD1810; continue 'dispatch;
	}
	// 82FD17E8: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD17EC: 38C00053  li r6, 0x53
	ctx.r[6].s64 = 83;
	// 82FD17F0: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD17F4: 38A00364  li r5, 0x364
	ctx.r[5].s64 = 868;
	// 82FD17F8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD17FC: 4BFFF4CD  bl 0x82fd0cc8
	ctx.lr = 0x82FD1800;
	sub_82FD0CC8(ctx, base);
	// 82FD1800: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD1804: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1808: 388BC3FC  addi r4, r11, -0x3c04
	ctx.r[4].s64 = ctx.r[11].s64 + -15364;
	// 82FD180C: 481DF41D  bl 0x831b0c28
	ctx.lr = 0x82FD1810;
	sub_831B0C28(ctx, base);
	// 82FD1810: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FD1814: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD1818: 419A0034  beq cr6, 0x82fd184c
	if ctx.cr[6].eq {
	pc = 0x82FD184C; continue 'dispatch;
	}
	// 82FD181C: 39010070  addi r8, r1, 0x70
	ctx.r[8].s64 = ctx.r[1].s64 + 112;
	// 82FD1820: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1824: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 82FD1828: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 82FD182C: 7D685B78  mr r8, r11
	ctx.r[8].u64 = ctx.r[11].u64;
	// 82FD1830: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82FD1834: A0EA0000  lhz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1838: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD183C: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82FD1840: B0E90000  sth r7, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 82FD1844: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD1848: 4082FFEC  bne 0x82fd1834
	if !ctx.cr[0].eq {
	pc = 0x82FD1834; continue 'dispatch;
	}
	// 82FD184C: 550B083C  slwi r11, r8, 1
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1850: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1854: 7D4B232E  sthx r10, r11, r4
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32), ctx.r[10].u16) };
	// 82FD1858: 38210180  addi r1, r1, 0x180
	ctx.r[1].s64 = ctx.r[1].s64 + 384;
	// 82FD185C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1860: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD1864: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1868(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1868 size=4
    let mut pc: u32 = 0x82FD1868;
    'dispatch: loop {
        match pc {
            0x82FD1868 => {
    //   block [0x82FD1868..0x82FD186C)
	// 82FD1868: 4BFFFE40  b 0x82fd16a8
	sub_82FD16A8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1870 size=40
    let mut pc: u32 = 0x82FD1870;
    'dispatch: loop {
        match pc {
            0x82FD1870 => {
    //   block [0x82FD1870..0x82FD1898)
	// 82FD1870: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD1874: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 82FD1878: 40980014  bge cr6, 0x82fd188c
	if !ctx.cr[6].lt {
	pc = 0x82FD188C; continue 'dispatch;
	}
	// 82FD187C: 3940002D  li r10, 0x2d
	ctx.r[10].s64 = 45;
	// 82FD1880: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FD1884: 7C6300D0  neg r3, r3
	ctx.r[3].s64 = -ctx.r[3].s64;
	// 82FD1888: B1440000  sth r10, 0(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD188C: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1890: 7C8B2214  add r4, r11, r4
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 82FD1894: 4BFFFE14  b 0x82fd16a8
	sub_82FD16A8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1898(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1898 size=32
    let mut pc: u32 = 0x82FD1898;
    'dispatch: loop {
        match pc {
            0x82FD1898 => {
    //   block [0x82FD1898..0x82FD18B8)
	// 82FD1898: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 82FD189C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD18A0: 419A0034  beq cr6, 0x82fd18d4
	if ctx.cr[6].eq {
		sub_82FD18D4(ctx, base);
		return;
	}
	// 82FD18A4: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD18A8: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD18AC: 41820028  beq 0x82fd18d4
	if ctx.cr[0].eq {
		sub_82FD18D4(ctx, base);
		return;
	}
	// 82FD18B0: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD18B4: 48000008  b 0x82fd18bc
	sub_82FD18B8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD18B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD18B8 size=28
    let mut pc: u32 = 0x82FD18B8;
    'dispatch: loop {
        match pc {
            0x82FD18B8 => {
    //   block [0x82FD18B8..0x82FD18D4)
	// 82FD18B8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD18BC: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD18C0: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD18C4: 4082FFF4  bne 0x82fd18b8
	if !ctx.cr[0].eq {
	pc = 0x82FD18B8; continue 'dispatch;
	}
	// 82FD18C8: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD18CC: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD18D0: 48000008  b 0x82fd18d8
	sub_82FD18D4(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD18D4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD18D4 size=68
    let mut pc: u32 = 0x82FD18D4;
    'dispatch: loop {
        match pc {
            0x82FD18D4 => {
    //   block [0x82FD18D4..0x82FD1918)
	// 82FD18D4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD18D8: A1280000  lhz r9, 0(r8)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD18DC: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD18E0: 41820028  beq 0x82fd1908
	if ctx.cr[0].eq {
	pc = 0x82FD1908; continue 'dispatch;
	}
	// 82FD18E4: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD18E8: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82FD18EC: 39080002  addi r8, r8, 2
	ctx.r[8].s64 = ctx.r[8].s64 + 2;
	// 82FD18F0: B12A0000  sth r9, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 82FD18F4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD18F8: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD18FC: A1280000  lhz r9, 0(r8)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1900: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1904: 4082FFE8  bne 0x82fd18ec
	if !ctx.cr[0].eq {
	pc = 0x82FD18EC; continue 'dispatch;
	}
	// 82FD1908: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD190C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1910: 7D4B1B2E  sthx r10, r11, r3
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u16) };
	// 82FD1914: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1918 size=36
    let mut pc: u32 = 0x82FD1918;
    'dispatch: loop {
        match pc {
            0x82FD1918 => {
    //   block [0x82FD1918..0x82FD193C)
	// 82FD1918: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD191C: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82FD1920: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD1924: 816BB7DC  lwz r11, -0x4824(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD1928: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD192C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1930: 816A0004  lwz r11, 4(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD1934: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD1938: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1940 size=88
    let mut pc: u32 = 0x82FD1940;
    'dispatch: loop {
        match pc {
            0x82FD1940 => {
    //   block [0x82FD1940..0x82FD1998)
	// 82FD1940: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1944: A1040000  lhz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1948: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD194C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1950: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82FD1954: 409A0034  bne cr6, 0x82fd1988
	if !ctx.cr[6].eq {
	pc = 0x82FD1988; continue 'dispatch;
	}
	// 82FD1958: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD195C: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1960: 41820038  beq 0x82fd1998
	if ctx.cr[0].eq {
		sub_82FD1998(ctx, base);
		return;
	}
	// 82FD1964: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD1968: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD196C: 38840002  addi r4, r4, 2
	ctx.r[4].s64 = ctx.r[4].s64 + 2;
	// 82FD1970: 7F0A2840  cmplw cr6, r10, r5
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[5].u32, &mut ctx.xer);
	// 82FD1974: 419A0024  beq cr6, 0x82fd1998
	if ctx.cr[6].eq {
		sub_82FD1998(ctx, base);
		return;
	}
	// 82FD1978: A1240000  lhz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD197C: A10B0000  lhz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1980: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82FD1984: 419AFFD4  beq cr6, 0x82fd1958
	if ctx.cr[6].eq {
	pc = 0x82FD1958; continue 'dispatch;
	}
	// 82FD1988: A1440000  lhz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD198C: A16B0000  lhz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1990: 7C6A5850  subf r3, r10, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82FD1994: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1998 size=8
    let mut pc: u32 = 0x82FD1998;
    'dispatch: loop {
        match pc {
            0x82FD1998 => {
    //   block [0x82FD1998..0x82FD19A0)
	// 82FD1998: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD199C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD19A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD19A0 size=40
    let mut pc: u32 = 0x82FD19A0;
    'dispatch: loop {
        match pc {
            0x82FD19A0 => {
    //   block [0x82FD19A0..0x82FD19C8)
	// 82FD19A0: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD19A4: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 82FD19A8: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 82FD19AC: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD19B0: 816BB7DC  lwz r11, -0x4824(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD19B4: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD19B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD19BC: 816A0008  lwz r11, 8(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD19C0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD19C4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD19C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD19C8 size=44
    let mut pc: u32 = 0x82FD19C8;
    'dispatch: loop {
        match pc {
            0x82FD19C8 => {
    //   block [0x82FD19C8..0x82FD19F4)
	// 82FD19C8: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FD19CC: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 82FD19D0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD19D4: 419A0020  beq cr6, 0x82fd19f4
	if ctx.cr[6].eq {
		sub_82FD19F4(ctx, base);
		return;
	}
	// 82FD19D8: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD19DC: 409A0078  bne cr6, 0x82fd1a54
	if !ctx.cr[6].eq {
		sub_82FD1A54(ctx, base);
		return;
	}
	// 82FD19E0: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD19E4: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD19E8: 418200A8  beq 0x82fd1a90
	if ctx.cr[0].eq {
		sub_82FD1A90(ctx, base);
		return;
	}
	// 82FD19EC: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD19F0: 4800004C  b 0x82fd1a3c
	sub_82FD1A38(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD19F4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD19F4 size=28
    let mut pc: u32 = 0x82FD19F4;
    'dispatch: loop {
        match pc {
            0x82FD19F4 => {
    //   block [0x82FD19F4..0x82FD1A10)
	// 82FD19F4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD19F8: 419A0034  beq cr6, 0x82fd1a2c
	if ctx.cr[6].eq {
		sub_82FD1A2C(ctx, base);
		return;
	}
	// 82FD19FC: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A00: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1A04: 41820028  beq 0x82fd1a2c
	if ctx.cr[0].eq {
		sub_82FD1A2C(ctx, base);
		return;
	}
	// 82FD1A08: 39640002  addi r11, r4, 2
	ctx.r[11].s64 = ctx.r[4].s64 + 2;
	// 82FD1A0C: 48000008  b 0x82fd1a14
	sub_82FD1A10(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A10 size=28
    let mut pc: u32 = 0x82FD1A10;
    'dispatch: loop {
        match pc {
            0x82FD1A10 => {
    //   block [0x82FD1A10..0x82FD1A2C)
	// 82FD1A10: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1A14: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A18: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1A1C: 4082FFF4  bne 0x82fd1a10
	if !ctx.cr[0].eq {
	pc = 0x82FD1A10; continue 'dispatch;
	}
	// 82FD1A20: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 82FD1A24: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1A28: 48000008  b 0x82fd1a30
	sub_82FD1A2C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A2C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A2C size=12
    let mut pc: u32 = 0x82FD1A2C;
    'dispatch: loop {
        match pc {
            0x82FD1A2C => {
    //   block [0x82FD1A2C..0x82FD1A38)
	// 82FD1A2C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD1A30: 7C6B00D0  neg r3, r11
	ctx.r[3].s64 = -ctx.r[11].s64;
	// 82FD1A34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A38 size=28
    let mut pc: u32 = 0x82FD1A38;
    'dispatch: loop {
        match pc {
            0x82FD1A38 => {
    //   block [0x82FD1A38..0x82FD1A54)
	// 82FD1A38: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1A3C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A40: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1A44: 4082FFF4  bne 0x82fd1a38
	if !ctx.cr[0].eq {
	pc = 0x82FD1A38; continue 'dispatch;
	}
	// 82FD1A48: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD1A4C: 7D630E70  srawi r3, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[3].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1A50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A54(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A54 size=12
    let mut pc: u32 = 0x82FD1A54;
    'dispatch: loop {
        match pc {
            0x82FD1A54 => {
    //   block [0x82FD1A54..0x82FD1A60)
	// 82FD1A54: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A58: A1040000  lhz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A5C: 4800001C  b 0x82fd1a78
	sub_82FD1A60(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A60 size=48
    let mut pc: u32 = 0x82FD1A60;
    'dispatch: loop {
        match pc {
            0x82FD1A60 => {
    //   block [0x82FD1A60..0x82FD1A90)
	// 82FD1A60: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD1A64: 419A002C  beq cr6, 0x82fd1a90
	if ctx.cr[6].eq {
		sub_82FD1A90(ctx, base);
		return;
	}
	// 82FD1A68: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD1A6C: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD1A70: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A74: A1090000  lhz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A78: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82FD1A7C: 419AFFE4  beq cr6, 0x82fd1a60
	if ctx.cr[6].eq {
	pc = 0x82FD1A60; continue 'dispatch;
	}
	// 82FD1A80: A1690000  lhz r11, 0(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A84: A14A0000  lhz r10, 0(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1A88: 7C6B5050  subf r3, r11, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 82FD1A8C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1A90 size=8
    let mut pc: u32 = 0x82FD1A90;
    'dispatch: loop {
        match pc {
            0x82FD1A90 => {
    //   block [0x82FD1A90..0x82FD1A98)
	// 82FD1A90: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1A94: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1A98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1A98 size=92
    let mut pc: u32 = 0x82FD1A98;
    'dispatch: loop {
        match pc {
            0x82FD1A98 => {
    //   block [0x82FD1A98..0x82FD1AF4)
	// 82FD1A98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1A9C: 481D66C9  bl 0x831a8164
	ctx.lr = 0x82FD1AA0;
	sub_831A8130(ctx, base);
	// 82FD1AA0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1AA4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD1AA8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD1AAC: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82FD1AB0: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 82FD1AB4: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 82FD1AB8: 4BFFF159  bl 0x82fd0c10
	ctx.lr = 0x82FD1ABC;
	sub_82FD0C10(ctx, base);
	// 82FD1ABC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1AC0: 4082000C  bne 0x82fd1acc
	if !ctx.cr[0].eq {
	pc = 0x82FD1ACC; continue 'dispatch;
	}
	// 82FD1AC4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1AC8: 48000024  b 0x82fd1aec
	pc = 0x82FD1AEC; continue 'dispatch;
	// 82FD1ACC: 578A083C  slwi r10, r28, 1
	ctx.r[10].u32 = ctx.r[28].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1AD0: 57CB083C  slwi r11, r30, 1
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1AD4: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 82FD1AD8: 7C8AEA14  add r4, r10, r29
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 82FD1ADC: 7C6BFA14  add r3, r11, r31
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FD1AE0: 4BFFFE61  bl 0x82fd1940
	ctx.lr = 0x82FD1AE4;
	sub_82FD1940(ctx, base);
	// 82FD1AE4: 7C6B0034  cntlzw r11, r3
	ctx.r[11].u64 = if ctx.r[3].u32 == 0 { 32 } else { ctx.r[3].u32.leading_zeros() as u64 };
	// 82FD1AE8: 5563DFFE  rlwinm r3, r11, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82FD1AEC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FD1AF0: 481D66C4  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1AF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1AF8 size=112
    let mut pc: u32 = 0x82FD1AF8;
    'dispatch: loop {
        match pc {
            0x82FD1AF8 => {
    //   block [0x82FD1AF8..0x82FD1B68)
	// 82FD1AF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1AFC: 481D6669  bl 0x831a8164
	ctx.lr = 0x82FD1B00;
	sub_831A8130(ctx, base);
	// 82FD1B00: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1B04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD1B08: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD1B0C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 82FD1B10: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 82FD1B14: 7CFB3B78  mr r27, r7
	ctx.r[27].u64 = ctx.r[7].u64;
	// 82FD1B18: 4BFFF0F9  bl 0x82fd0c10
	ctx.lr = 0x82FD1B1C;
	sub_82FD0C10(ctx, base);
	// 82FD1B1C: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1B20: 4082000C  bne 0x82fd1b2c
	if !ctx.cr[0].eq {
	pc = 0x82FD1B2C; continue 'dispatch;
	}
	// 82FD1B24: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1B28: 48000038  b 0x82fd1b60
	pc = 0x82FD1B60; continue 'dispatch;
	// 82FD1B2C: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD1B30: 578A083C  slwi r10, r28, 1
	ctx.r[10].u32 = ctx.r[28].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1B34: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 82FD1B38: 7CAAEA14  add r5, r10, r29
	ctx.r[5].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 82FD1B3C: 806BB7DC  lwz r3, -0x4824(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD1B40: 57CB083C  slwi r11, r30, 1
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1B44: 7C8BFA14  add r4, r11, r31
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 82FD1B48: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1B4C: 81690008  lwz r11, 8(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD1B50: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD1B54: 4E800421  bctrl
	ctx.lr = 0x82FD1B58;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD1B58: 7C6B0034  cntlzw r11, r3
	ctx.r[11].u64 = if ctx.r[3].u32 == 0 { 32 } else { ctx.r[3].u32.leading_zeros() as u64 };
	// 82FD1B5C: 5563DFFE  rlwinm r3, r11, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82FD1B60: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FD1B64: 481D6650  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1B68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1B68 size=60
    let mut pc: u32 = 0x82FD1B68;
    'dispatch: loop {
        match pc {
            0x82FD1B68 => {
    //   block [0x82FD1B68..0x82FD1BA4)
	// 82FD1B68: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1B6C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD1B70: 419A0028  beq cr6, 0x82fd1b98
	if ctx.cr[6].eq {
	pc = 0x82FD1B98; continue 'dispatch;
	}
	// 82FD1B74: A1440000  lhz r10, 0(r4)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1B78: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1B7C: 4182001C  beq 0x82fd1b98
	if ctx.cr[0].eq {
	pc = 0x82FD1B98; continue 'dispatch;
	}
	// 82FD1B80: 7D2B2050  subf r9, r11, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[11].s64;
	// 82FD1B84: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD1B88: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1B8C: 7D495A2E  lhzx r10, r9, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD1B90: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1B94: 4082FFF0  bne 0x82fd1b84
	if !ctx.cr[0].eq {
	pc = 0x82FD1B84; continue 'dispatch;
	}
	// 82FD1B98: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1B9C: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD1BA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1BA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1BA8 size=20
    let mut pc: u32 = 0x82FD1BA8;
    'dispatch: loop {
        match pc {
            0x82FD1BA8 => {
    //   block [0x82FD1BA8..0x82FD1BBC)
	// 82FD1BA8: 54AA083C  slwi r10, r5, 1
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1BAC: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1BB0: 7D4A1A14  add r10, r10, r3
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[3].u64;
	// 82FD1BB4: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82FD1BB8: 4800001C  b 0x82fd1bd4
	sub_82FD1BBC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1BBC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1BBC size=64
    let mut pc: u32 = 0x82FD1BBC;
    'dispatch: loop {
        match pc {
            0x82FD1BBC => {
    //   block [0x82FD1BBC..0x82FD1BFC)
	// 82FD1BBC: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82FD1BC0: 41990020  bgt cr6, 0x82fd1be0
	if ctx.cr[6].gt {
	pc = 0x82FD1BE0; continue 'dispatch;
	}
	// 82FD1BC4: A1240000  lhz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1BC8: 38840002  addi r4, r4, 2
	ctx.r[4].s64 = ctx.r[4].s64 + 2;
	// 82FD1BCC: B12B0000  sth r9, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 82FD1BD0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1BD4: A1240000  lhz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1BD8: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1BDC: 4082FFE0  bne 0x82fd1bbc
	if !ctx.cr[0].eq {
	pc = 0x82FD1BBC; continue 'dispatch;
	}
	// 82FD1BE0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1BE4: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD1BE8: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1BEC: 7D6B0034  cntlzw r11, r11
	ctx.r[11].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 82FD1BF0: 556BDFFE  rlwinm r11, r11, 0x1b, 0x1f, 0x1f
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000001Fu64;
	// 82FD1BF4: 5563063E  clrlwi r3, r11, 0x18
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	// 82FD1BF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1C00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1C00 size=148
    let mut pc: u32 = 0x82FD1C00;
    'dispatch: loop {
        match pc {
            0x82FD1C00 => {
    //   block [0x82FD1C00..0x82FD1C94)
	// 82FD1C00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1C04: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD1C08: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1C0C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FD1C10: 7CA72B78  mr r7, r5
	ctx.r[7].u64 = ctx.r[5].u64;
	// 82FD1C14: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD1C18: 409A002C  bne cr6, 0x82fd1c44
	if !ctx.cr[6].eq {
	pc = 0x82FD1C44; continue 'dispatch;
	}
	// 82FD1C1C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1C20: 38C00044  li r6, 0x44
	ctx.r[6].s64 = 68;
	// 82FD1C24: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD1C28: 38A0045D  li r5, 0x45d
	ctx.r[5].s64 = 1117;
	// 82FD1C2C: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1C30: 4BFFF099  bl 0x82fd0cc8
	ctx.lr = 0x82FD1C34;
	sub_82FD0CC8(ctx, base);
	// 82FD1C34: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD1C38: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1C3C: 388BC3FC  addi r4, r11, -0x3c04
	ctx.r[4].s64 = ctx.r[11].s64 + -15364;
	// 82FD1C40: 481DEFE9  bl 0x831b0c28
	ctx.lr = 0x82FD1C44;
	sub_831B0C28(ctx, base);
	// 82FD1C44: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FD1C48: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82FD1C4C: 419A0028  beq cr6, 0x82fd1c74
	if ctx.cr[6].eq {
	pc = 0x82FD1C74; continue 'dispatch;
	}
	// 82FD1C50: 48000018  b 0x82fd1c68
	pc = 0x82FD1C68; continue 'dispatch;
	// 82FD1C54: 1D090026  mulli r8, r9, 0x26
	ctx.r[8].s64 = ctx.r[9].s64 * 38;
	// 82FD1C58: 5529463E  srwi r9, r9, 0x18
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(24);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 82FD1C5C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD1C60: 7D284A14  add r9, r8, r9
	ctx.r[9].u64 = ctx.r[8].u64 + ctx.r[9].u64;
	// 82FD1C64: 7D295A14  add r9, r9, r11
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[11].u64;
	// 82FD1C68: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1C6C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1C70: 4082FFE4  bne 0x82fd1c54
	if !ctx.cr[0].eq {
	pc = 0x82FD1C54; continue 'dispatch;
	}
	// 82FD1C74: 7D692396  divwu r11, r9, r4
	ctx.r[11].u32 = ctx.r[9].u32 / ctx.r[4].u32;
	// 82FD1C78: 0CC40000  twi 6, r4, 0
	// 82FD1C7C: 7D6B21D6  mullw r11, r11, r4
	ctx.r[11].s64 = (ctx.r[11].s32 as i64) * (ctx.r[4].s32 as i64);
	// 82FD1C80: 7C6B4850  subf r3, r11, r9
	ctx.r[3].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	// 82FD1C84: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD1C88: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1C8C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD1C90: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1C98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1C98 size=48
    let mut pc: u32 = 0x82FD1C98;
    'dispatch: loop {
        match pc {
            0x82FD1C98 => {
    //   block [0x82FD1C98..0x82FD1CC8)
	// 82FD1C98: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1C9C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1CA0: 41820044  beq 0x82fd1ce4
	if ctx.cr[0].eq {
		sub_82FD1CC8(ctx, base);
		return;
	}
	// 82FD1CA4: A1240000  lhz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1CA8: 7C8A2378  mr r10, r4
	ctx.r[10].u64 = ctx.r[4].u64;
	// 82FD1CAC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 82FD1CB0: 419A0024  beq cr6, 0x82fd1cd4
	if ctx.cr[6].eq {
		sub_82FD1CC8(ctx, base);
		return;
	}
	// 82FD1CB4: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 82FD1CB8: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1CBC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD1CC0: 7F0B4040  cmplw cr6, r11, r8
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82FD1CC4: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1CC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1CC8 size=36
    let mut pc: u32 = 0x82FD1CC8;
    'dispatch: loop {
        match pc {
            0x82FD1CC8 => {
    //   block [0x82FD1CC8..0x82FD1CEC)
	// 82FD1CC8: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1CCC: 28080000  cmplwi r8, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1CD0: 4082FFE8  bne 0x82fd1cb8
	if !ctx.cr[0].eq {
		sub_82FD1C98(ctx, base);
		return;
	}
	// 82FD1CD4: 38630002  addi r3, r3, 2
	ctx.r[3].s64 = ctx.r[3].s64 + 2;
	// 82FD1CD8: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1CDC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1CE0: 4082FFC8  bne 0x82fd1ca8
	if !ctx.cr[0].eq {
		sub_82FD1C98(ctx, base);
		return;
	}
	// 82FD1CE4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD1CE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1CF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1CF0 size=48
    let mut pc: u32 = 0x82FD1CF0;
    'dispatch: loop {
        match pc {
            0x82FD1CF0 => {
    //   block [0x82FD1CF0..0x82FD1D20)
	// 82FD1CF0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD1CF4: 419A00A0  beq cr6, 0x82fd1d94
	if ctx.cr[6].eq {
		sub_82FD1D7C(ctx, base);
		return;
	}
	// 82FD1CF8: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1CFC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1D00: 41820094  beq 0x82fd1d94
	if ctx.cr[0].eq {
		sub_82FD1D7C(ctx, base);
		return;
	}
	// 82FD1D04: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD1D08: 419A0034  beq cr6, 0x82fd1d3c
	if ctx.cr[6].eq {
		sub_82FD1D3C(ctx, base);
		return;
	}
	// 82FD1D0C: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1D10: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1D14: 41820028  beq 0x82fd1d3c
	if ctx.cr[0].eq {
		sub_82FD1D3C(ctx, base);
		return;
	}
	// 82FD1D18: 39640002  addi r11, r4, 2
	ctx.r[11].s64 = ctx.r[4].s64 + 2;
	// 82FD1D1C: 48000008  b 0x82fd1d24
	sub_82FD1D20(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1D20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1D20 size=28
    let mut pc: u32 = 0x82FD1D20;
    'dispatch: loop {
        match pc {
            0x82FD1D20 => {
    //   block [0x82FD1D20..0x82FD1D3C)
	// 82FD1D20: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1D24: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1D28: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1D2C: 4082FFF4  bne 0x82fd1d20
	if !ctx.cr[0].eq {
	pc = 0x82FD1D20; continue 'dispatch;
	}
	// 82FD1D30: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 82FD1D34: 7D680E70  srawi r8, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1D38: 48000008  b 0x82fd1d40
	sub_82FD1D3C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1D3C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1D3C size=64
    let mut pc: u32 = 0x82FD1D3C;
    'dispatch: loop {
        match pc {
            0x82FD1D3C => {
    //   block [0x82FD1D3C..0x82FD1D7C)
	// 82FD1D3C: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FD1D40: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 82FD1D44: 419A0050  beq cr6, 0x82fd1d94
	if ctx.cr[6].eq {
		sub_82FD1D7C(ctx, base);
		return;
	}
	// 82FD1D48: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1D4C: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FD1D50: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1D54: 5547083C  slwi r7, r10, 1
	ctx.r[7].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 82FD1D58: A0CB0000  lhz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1D5C: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1D60: 7CE7222E  lhzx r7, r7, r4
	ctx.r[7].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[4].u32)) } as u64;
	// 82FD1D64: 7F063840  cmplw cr6, r6, r7
	ctx.cr[6].compare_u32(ctx.r[6].u32, ctx.r[7].u32, &mut ctx.xer);
	// 82FD1D68: 419A0014  beq cr6, 0x82fd1d7c
	if ctx.cr[6].eq {
		sub_82FD1D7C(ctx, base);
		return;
	}
	// 82FD1D6C: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD1D70: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD1D74: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 82FD1D78: 48000010  b 0x82fd1d88
	sub_82FD1D7C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1D7C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1D7C size=32
    let mut pc: u32 = 0x82FD1D7C;
    'dispatch: loop {
        match pc {
            0x82FD1D7C => {
    //   block [0x82FD1D7C..0x82FD1D9C)
	// 82FD1D7C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD1D80: 7F0A4000  cmpw cr6, r10, r8
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FD1D84: 419A0018  beq cr6, 0x82fd1d9c
	if ctx.cr[6].eq {
		sub_82FD1D9C(ctx, base);
		return;
	}
	// 82FD1D88: A0EB0000  lhz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1D8C: 28070000  cmplwi r7, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1D90: 4082FFC4  bne 0x82fd1d54
	if !ctx.cr[0].eq {
		sub_82FD1D3C(ctx, base);
		return;
	}
	// 82FD1D94: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FD1D98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1D9C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1D9C size=20
    let mut pc: u32 = 0x82FD1D9C;
    'dispatch: loop {
        match pc {
            0x82FD1D9C => {
    //   block [0x82FD1D9C..0x82FD1DB0)
	// 82FD1D9C: 550A083C  slwi r10, r8, 1
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1DA0: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82FD1DA4: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD1DA8: 7D630E70  srawi r3, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[3].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1DAC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1DB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1DB0 size=60
    let mut pc: u32 = 0x82FD1DB0;
    'dispatch: loop {
        match pc {
            0x82FD1DB0 => {
    //   block [0x82FD1DB0..0x82FD1DEC)
	// 82FD1DB0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD1DB4: 419A0030  beq cr6, 0x82fd1de4
	if ctx.cr[6].eq {
	pc = 0x82FD1DE4; continue 'dispatch;
	}
	// 82FD1DB8: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1DBC: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FD1DC0: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1DC4: 41820020  beq 0x82fd1de4
	if ctx.cr[0].eq {
	pc = 0x82FD1DE4; continue 'dispatch;
	}
	// 82FD1DC8: 5489043E  clrlwi r9, r4, 0x10
	ctx.r[9].u64 = ctx.r[4].u32 as u64 & 0x0000FFFFu64;
	// 82FD1DCC: 7F095840  cmplw cr6, r9, r11
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD1DD0: 419A001C  beq cr6, 0x82fd1dec
	if ctx.cr[6].eq {
		sub_82FD1DEC(ctx, base);
		return;
	}
	// 82FD1DD4: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD1DD8: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1DDC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1DE0: 4082FFEC  bne 0x82fd1dcc
	if !ctx.cr[0].eq {
	pc = 0x82FD1DCC; continue 'dispatch;
	}
	// 82FD1DE4: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FD1DE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1DEC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1DEC size=12
    let mut pc: u32 = 0x82FD1DEC;
    'dispatch: loop {
        match pc {
            0x82FD1DEC => {
    //   block [0x82FD1DEC..0x82FD1DF8)
	// 82FD1DEC: 7D635050  subf r11, r3, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[3].s64;
	// 82FD1DF0: 7D630E70  srawi r3, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[3].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1DF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1DF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1DF8 size=204
    let mut pc: u32 = 0x82FD1DF8;
    'dispatch: loop {
        match pc {
            0x82FD1DF8 => {
    //   block [0x82FD1DF8..0x82FD1EC4)
	// 82FD1DF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1DFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD1E00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1E04: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD1E08: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 82FD1E0C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD1E10: 419A0034  beq cr6, 0x82fd1e44
	if ctx.cr[6].eq {
	pc = 0x82FD1E44; continue 'dispatch;
	}
	// 82FD1E14: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1E18: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1E1C: 41820028  beq 0x82fd1e44
	if ctx.cr[0].eq {
	pc = 0x82FD1E44; continue 'dispatch;
	}
	// 82FD1E20: 394B0002  addi r10, r11, 2
	ctx.r[10].s64 = ctx.r[11].s64 + 2;
	// 82FD1E24: 48000008  b 0x82fd1e2c
	pc = 0x82FD1E2C; continue 'dispatch;
	// 82FD1E28: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD1E2C: A12A0000  lhz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1E30: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1E34: 4082FFF4  bne 0x82fd1e28
	if !ctx.cr[0].eq {
	pc = 0x82FD1E28; continue 'dispatch;
	}
	// 82FD1E38: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 82FD1E3C: 7D480E70  srawi r8, r10, 1
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[10].s32 >> 1) as i64;
	// 82FD1E40: 48000008  b 0x82fd1e48
	pc = 0x82FD1E48; continue 'dispatch;
	// 82FD1E44: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FD1E48: 3948FFFF  addi r10, r8, -1
	ctx.r[10].s64 = ctx.r[8].s64 + -1;
	// 82FD1E4C: 7F055000  cmpw cr6, r5, r10
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[10].s32, &mut ctx.xer);
	// 82FD1E50: 4099002C  ble cr6, 0x82fd1e7c
	if !ctx.cr[6].gt {
	pc = 0x82FD1E7C; continue 'dispatch;
	}
	// 82FD1E54: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD1E58: 38C00054  li r6, 0x54
	ctx.r[6].s64 = 84;
	// 82FD1E5C: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD1E60: 38A004EA  li r5, 0x4ea
	ctx.r[5].s64 = 1258;
	// 82FD1E64: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1E68: 4BFFEAF1  bl 0x82fd0958
	ctx.lr = 0x82FD1E6C;
	sub_82FD0958(ctx, base);
	// 82FD1E6C: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD1E70: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD1E74: 388BC49C  addi r4, r11, -0x3b64
	ctx.r[4].s64 = ctx.r[11].s64 + -15204;
	// 82FD1E78: 481DEDB1  bl 0x831b0c28
	ctx.lr = 0x82FD1E7C;
	sub_831B0C28(ctx, base);
	// 82FD1E7C: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 82FD1E80: 7F054000  cmpw cr6, r5, r8
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FD1E84: 4098002C  bge cr6, 0x82fd1eb0
	if !ctx.cr[6].lt {
	pc = 0x82FD1EB0; continue 'dispatch;
	}
	// 82FD1E88: 54AA083C  slwi r10, r5, 1
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1E8C: 5489043E  clrlwi r9, r4, 0x10
	ctx.r[9].u64 = ctx.r[4].u32 as u64 & 0x0000FFFFu64;
	// 82FD1E90: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 82FD1E94: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1E98: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82FD1E9C: 419A0018  beq cr6, 0x82fd1eb4
	if ctx.cr[6].eq {
	pc = 0x82FD1EB4; continue 'dispatch;
	}
	// 82FD1EA0: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 82FD1EA4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1EA8: 7F034000  cmpw cr6, r3, r8
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[8].s32, &mut ctx.xer);
	// 82FD1EAC: 4198FFE8  blt cr6, 0x82fd1e94
	if ctx.cr[6].lt {
	pc = 0x82FD1E94; continue 'dispatch;
	}
	// 82FD1EB0: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FD1EB4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD1EB8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD1EBC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD1EC0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1EC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1EC8 size=52
    let mut pc: u32 = 0x82FD1EC8;
    'dispatch: loop {
        match pc {
            0x82FD1EC8 => {
    //   block [0x82FD1EC8..0x82FD1EFC)
	// 82FD1EC8: 3565FFFF  addic. r11, r5, -1
	ctx.xer.ca = (ctx.r[5].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[5].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1ECC: 41800028  blt 0x82fd1ef4
	if ctx.cr[0].lt {
	pc = 0x82FD1EF4; continue 'dispatch;
	}
	// 82FD1ED0: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD1ED4: 5469043E  clrlwi r9, r3, 0x10
	ctx.r[9].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 82FD1ED8: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 82FD1EDC: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1EE0: 7F084840  cmplw cr6, r8, r9
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82FD1EE4: 419A0018  beq cr6, 0x82fd1efc
	if ctx.cr[6].eq {
		sub_82FD1EFC(ctx, base);
		return;
	}
	// 82FD1EE8: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1EEC: 394AFFFE  addi r10, r10, -2
	ctx.r[10].s64 = ctx.r[10].s64 + -2;
	// 82FD1EF0: 4080FFEC  bge 0x82fd1edc
	if !ctx.cr[0].lt {
	pc = 0x82FD1EDC; continue 'dispatch;
	}
	// 82FD1EF4: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 82FD1EF8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1EFC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD1EFC size=8
    let mut pc: u32 = 0x82FD1EFC;
    'dispatch: loop {
        match pc {
            0x82FD1EFC => {
    //   block [0x82FD1EFC..0x82FD1F04)
	// 82FD1EFC: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD1F00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD1F08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD1F08 size=316
    let mut pc: u32 = 0x82FD1F08;
    'dispatch: loop {
        match pc {
            0x82FD1F08 => {
    //   block [0x82FD1F08..0x82FD2044)
	// 82FD1F08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD1F0C: 481D6251  bl 0x831a815c
	ctx.lr = 0x82FD1F10;
	sub_831A8130(ctx, base);
	// 82FD1F10: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD1F14: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 82FD1F18: 3B200000  li r25, 0
	ctx.r[25].s64 = 0;
	// 82FD1F1C: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 82FD1F20: 419A0034  beq cr6, 0x82fd1f54
	if ctx.cr[6].eq {
	pc = 0x82FD1F54; continue 'dispatch;
	}
	// 82FD1F24: A17C0000  lhz r11, 0(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1F28: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1F2C: 41820028  beq 0x82fd1f54
	if ctx.cr[0].eq {
	pc = 0x82FD1F54; continue 'dispatch;
	}
	// 82FD1F30: 397C0002  addi r11, r28, 2
	ctx.r[11].s64 = ctx.r[28].s64 + 2;
	// 82FD1F34: 48000008  b 0x82fd1f3c
	pc = 0x82FD1F3C; continue 'dispatch;
	// 82FD1F38: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD1F3C: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1F40: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD1F44: 4082FFF4  bne 0x82fd1f38
	if !ctx.cr[0].eq {
	pc = 0x82FD1F38; continue 'dispatch;
	}
	// 82FD1F48: 7D7C5850  subf r11, r28, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[28].s64;
	// 82FD1F4C: 7D7D0E70  srawi r29, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[29].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD1F50: 48000008  b 0x82fd1f58
	pc = 0x82FD1F58; continue 'dispatch;
	// 82FD1F54: 7F3DCB78  mr r29, r25
	ctx.r[29].u64 = ctx.r[25].u64;
	// 82FD1F58: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 82FD1F5C: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 82FD1F60: 3F408339  lis r26, -0x7cc7
	ctx.r[26].s64 = -2093416448;
	// 82FD1F64: 419A0038  beq cr6, 0x82fd1f9c
	if ctx.cr[6].eq {
	pc = 0x82FD1F9C; continue 'dispatch;
	}
	// 82FD1F68: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 82FD1F6C: 807AB7DC  lwz r3, -0x4824(r26)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD1F70: A09E0000  lhz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1F74: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1F78: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD1F7C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD1F80: 4E800421  bctrl
	ctx.lr = 0x82FD1F84;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD1F84: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1F88: 41820014  beq 0x82fd1f9c
	if ctx.cr[0].eq {
	pc = 0x82FD1F9C; continue 'dispatch;
	}
	// 82FD1F8C: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FD1F90: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	// 82FD1F94: 7F1FE840  cmplw cr6, r31, r29
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[29].u32, &mut ctx.xer);
	// 82FD1F98: 4198FFD4  blt cr6, 0x82fd1f6c
	if ctx.cr[6].lt {
	pc = 0x82FD1F6C; continue 'dispatch;
	}
	// 82FD1F9C: 7FBBEB78  mr r27, r29
	ctx.r[27].u64 = ctx.r[29].u64;
	// 82FD1FA0: 7F1DF840  cmplw cr6, r29, r31
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[31].u32, &mut ctx.xer);
	// 82FD1FA4: 40990050  ble cr6, 0x82fd1ff4
	if !ctx.cr[6].gt {
	pc = 0x82FD1FF4; continue 'dispatch;
	}
	// 82FD1FA8: 57AB083C  slwi r11, r29, 1
	ctx.r[11].u32 = ctx.r[29].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1FAC: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 82FD1FB0: 3BCBFFFE  addi r30, r11, -2
	ctx.r[30].s64 = ctx.r[11].s64 + -2;
	// 82FD1FB4: 807AB7DC  lwz r3, -0x4824(r26)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD1FB8: A09E0000  lhz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1FBC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD1FC0: 816B0010  lwz r11, 0x10(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD1FC4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD1FC8: 4E800421  bctrl
	ctx.lr = 0x82FD1FCC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD1FCC: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD1FD0: 41820014  beq 0x82fd1fe4
	if ctx.cr[0].eq {
	pc = 0x82FD1FE4; continue 'dispatch;
	}
	// 82FD1FD4: 3B7BFFFF  addi r27, r27, -1
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	// 82FD1FD8: 3BDEFFFE  addi r30, r30, -2
	ctx.r[30].s64 = ctx.r[30].s64 + -2;
	// 82FD1FDC: 7F1BF840  cmplw cr6, r27, r31
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[31].u32, &mut ctx.xer);
	// 82FD1FE0: 4199FFD4  bgt cr6, 0x82fd1fb4
	if ctx.cr[6].gt {
	pc = 0x82FD1FB4; continue 'dispatch;
	}
	// 82FD1FE4: 7F1BE840  cmplw cr6, r27, r29
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[29].u32, &mut ctx.xer);
	// 82FD1FE8: 419A000C  beq cr6, 0x82fd1ff4
	if ctx.cr[6].eq {
	pc = 0x82FD1FF4; continue 'dispatch;
	}
	// 82FD1FEC: 576B083C  slwi r11, r27, 1
	ctx.r[11].u32 = ctx.r[27].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD1FF0: 7F2BE32E  sthx r25, r11, r28
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32), ctx.r[25].u16) };
	// 82FD1FF4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82FD1FF8: 419A0044  beq cr6, 0x82fd203c
	if ctx.cr[6].eq {
	pc = 0x82FD203C; continue 'dispatch;
	}
	// 82FD1FFC: 57EB083C  slwi r11, r31, 1
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2000: 7F29CB78  mr r9, r25
	ctx.r[9].u64 = ctx.r[25].u64;
	// 82FD2004: 7D6BE22E  lhzx r11, r11, r28
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32)) } as u64;
	// 82FD2008: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD200C: 41820028  beq 0x82fd2034
	if ctx.cr[0].eq {
	pc = 0x82FD2034; continue 'dispatch;
	}
	// 82FD2010: 7F8AE378  mr r10, r28
	ctx.r[10].u64 = ctx.r[28].u64;
	// 82FD2014: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 82FD2018: B16A0000  sth r11, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82FD201C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FD2020: 57EB083C  slwi r11, r31, 1
	ctx.r[11].u32 = ctx.r[31].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2024: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD2028: 7D6BE22E  lhzx r11, r11, r28
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32)) } as u64;
	// 82FD202C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2030: 4082FFE4  bne 0x82fd2014
	if !ctx.cr[0].eq {
	pc = 0x82FD2014; continue 'dispatch;
	}
	// 82FD2034: 552B083C  slwi r11, r9, 1
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2038: 7F2BE32E  sthx r25, r11, r28
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[28].u32), ctx.r[25].u16) };
	// 82FD203C: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82FD2040: 481D616C  b 0x831a81ac
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2048(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2048 size=32
    let mut pc: u32 = 0x82FD2048;
    'dispatch: loop {
        match pc {
            0x82FD2048 => {
    //   block [0x82FD2048..0x82FD2068)
	// 82FD2048: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD204C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD2050: 816BB7DC  lwz r11, -0x4824(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD2054: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD2058: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD205C: 816A001C  lwz r11, 0x1c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(28 as u32) ) } as u64;
	// 82FD2060: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD2064: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2068(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2068 size=32
    let mut pc: u32 = 0x82FD2068;
    'dispatch: loop {
        match pc {
            0x82FD2068 => {
    //   block [0x82FD2068..0x82FD2088)
	// 82FD2068: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD206C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 82FD2070: 816BB7DC  lwz r11, -0x4824(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-18468 as u32) ) } as u64;
	// 82FD2074: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 82FD2078: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD207C: 816A0020  lwz r11, 0x20(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32 as u32) ) } as u64;
	// 82FD2080: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD2084: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2088(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2088 size=264
    let mut pc: u32 = 0x82FD2088;
    'dispatch: loop {
        match pc {
            0x82FD2088 => {
    //   block [0x82FD2088..0x82FD2190)
	// 82FD2088: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD208C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD2090: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD2094: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD2098: 409A002C  bne cr6, 0x82fd20c4
	if !ctx.cr[6].eq {
	pc = 0x82FD20C4; continue 'dispatch;
	}
	// 82FD209C: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD20A0: 38C00051  li r6, 0x51
	ctx.r[6].s64 = 81;
	// 82FD20A4: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD20A8: 38A005B9  li r5, 0x5b9
	ctx.r[5].s64 = 1465;
	// 82FD20AC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD20B0: 4BFFEC19  bl 0x82fd0cc8
	ctx.lr = 0x82FD20B4;
	sub_82FD0CC8(ctx, base);
	// 82FD20B4: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD20B8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD20BC: 388BC3FC  addi r4, r11, -0x3c04
	ctx.r[4].s64 = ctx.r[11].s64 + -15364;
	// 82FD20C0: 481DEB69  bl 0x831b0c28
	ctx.lr = 0x82FD20C4;
	sub_831B0C28(ctx, base);
	// 82FD20C4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 82FD20C8: 419A0034  beq cr6, 0x82fd20fc
	if ctx.cr[6].eq {
	pc = 0x82FD20FC; continue 'dispatch;
	}
	// 82FD20CC: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD20D0: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD20D4: 41820028  beq 0x82fd20fc
	if ctx.cr[0].eq {
	pc = 0x82FD20FC; continue 'dispatch;
	}
	// 82FD20D8: 39640002  addi r11, r4, 2
	ctx.r[11].s64 = ctx.r[4].s64 + 2;
	// 82FD20DC: 48000008  b 0x82fd20e4
	pc = 0x82FD20E4; continue 'dispatch;
	// 82FD20E0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD20E4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD20E8: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD20EC: 4082FFF4  bne 0x82fd20e0
	if !ctx.cr[0].eq {
	pc = 0x82FD20E0; continue 'dispatch;
	}
	// 82FD20F0: 7D645850  subf r11, r4, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[4].s64;
	// 82FD20F4: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD20F8: 48000008  b 0x82fd2100
	pc = 0x82FD2100; continue 'dispatch;
	// 82FD20FC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD2100: 7D053050  subf r8, r5, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[5].s64;
	// 82FD2104: 2F050000  cmpwi cr6, r5, 0
	ctx.cr[6].compare_i32(ctx.r[5].s32, 0, &mut ctx.xer);
	// 82FD2108: 41980060  blt cr6, 0x82fd2168
	if ctx.cr[6].lt {
	pc = 0x82FD2168; continue 'dispatch;
	}
	// 82FD210C: 7F053000  cmpw cr6, r5, r6
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FD2110: 41990058  bgt cr6, 0x82fd2168
	if ctx.cr[6].gt {
	pc = 0x82FD2168; continue 'dispatch;
	}
	// 82FD2114: 7F065800  cmpw cr6, r6, r11
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[11].s32, &mut ctx.xer);
	// 82FD2118: 41990050  bgt cr6, 0x82fd2168
	if ctx.cr[6].gt {
	pc = 0x82FD2168; continue 'dispatch;
	}
	// 82FD211C: 7F053000  cmpw cr6, r5, r6
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[6].s32, &mut ctx.xer);
	// 82FD2120: 4098002C  bge cr6, 0x82fd214c
	if !ctx.cr[6].lt {
	pc = 0x82FD214C; continue 'dispatch;
	}
	// 82FD2124: 54AB083C  slwi r11, r5, 1
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2128: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 82FD212C: 7D4B2214  add r10, r11, r4
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 82FD2130: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 82FD2134: A0EA0000  lhz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2138: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD213C: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD2140: B0E90000  sth r7, 0(r9)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 82FD2144: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD2148: 4082FFEC  bne 0x82fd2134
	if !ctx.cr[0].eq {
	pc = 0x82FD2134; continue 'dispatch;
	}
	// 82FD214C: 550B083C  slwi r11, r8, 1
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2150: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD2154: 7D4B1B2E  sthx r10, r11, r3
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[3].u32), ctx.r[10].u16) };
	// 82FD2158: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD215C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD2160: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD2164: 4E800020  blr
	return;
	// 82FD2168: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD216C: 38C00054  li r6, 0x54
	ctx.r[6].s64 = 84;
	// 82FD2170: 388B6B18  addi r4, r11, 0x6b18
	ctx.r[4].s64 = ctx.r[11].s64 + 27416;
	// 82FD2174: 38A005C0  li r5, 0x5c0
	ctx.r[5].s64 = 1472;
	// 82FD2178: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD217C: 4BFFE7DD  bl 0x82fd0958
	ctx.lr = 0x82FD2180;
	sub_82FD0958(ctx, base);
	// 82FD2180: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD2184: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD2188: 388BC49C  addi r4, r11, -0x3b64
	ctx.r[4].s64 = ctx.r[11].s64 + -15204;
	// 82FD218C: 481DEA9D  bl 0x831b0c28
	ctx.lr = 0x82FD2190;
	sub_831B0C28(ctx, base);
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2190(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2190 size=28
    let mut pc: u32 = 0x82FD2190;
    'dispatch: loop {
        match pc {
            0x82FD2190 => {
    //   block [0x82FD2190..0x82FD21AC)
	// 82FD2190: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD2194: 419A0034  beq cr6, 0x82fd21c8
	if ctx.cr[6].eq {
		sub_82FD21C8(ctx, base);
		return;
	}
	// 82FD2198: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD219C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD21A0: 41820028  beq 0x82fd21c8
	if ctx.cr[0].eq {
		sub_82FD21C8(ctx, base);
		return;
	}
	// 82FD21A4: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 82FD21A8: 48000008  b 0x82fd21b0
	sub_82FD21AC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD21AC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD21AC size=28
    let mut pc: u32 = 0x82FD21AC;
    'dispatch: loop {
        match pc {
            0x82FD21AC => {
    //   block [0x82FD21AC..0x82FD21C8)
	// 82FD21AC: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD21B0: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD21B4: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD21B8: 4082FFF4  bne 0x82fd21ac
	if !ctx.cr[0].eq {
	pc = 0x82FD21AC; continue 'dispatch;
	}
	// 82FD21BC: 7D635850  subf r11, r3, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 82FD21C0: 7D680E70  srawi r8, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD21C4: 48000090  b 0x82fd2254
	sub_82FD222C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD21C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD21C8 size=8
    let mut pc: u32 = 0x82FD21C8;
    'dispatch: loop {
        match pc {
            0x82FD21C8 => {
    //   block [0x82FD21C8..0x82FD21D0)
	// 82FD21C8: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 82FD21CC: 48000088  b 0x82fd2254
	sub_82FD222C(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD21D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD21D0 size=92
    let mut pc: u32 = 0x82FD21D0;
    'dispatch: loop {
        match pc {
            0x82FD21D0 => {
    //   block [0x82FD21D0..0x82FD222C)
	// 82FD21D0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD21D4: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 82FD21D8: 419A002C  beq cr6, 0x82fd2204
	if ctx.cr[6].eq {
	pc = 0x82FD2204; continue 'dispatch;
	}
	// 82FD21DC: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 82FD21E0: 7D232050  subf r9, r3, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[3].s64;
	// 82FD21E4: 7CE95A2E  lhzx r7, r9, r11
	ctx.r[7].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD21E8: A0CB0000  lhz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD21EC: 7F073040  cmplw cr6, r7, r6
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[6].u32, &mut ctx.xer);
	// 82FD21F0: 409A0014  bne cr6, 0x82fd2204
	if !ctx.cr[6].eq {
	pc = 0x82FD2204; continue 'dispatch;
	}
	// 82FD21F4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD21F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD21FC: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82FD2200: 4198FFE4  blt cr6, 0x82fd21e4
	if ctx.cr[6].lt {
	pc = 0x82FD21E4; continue 'dispatch;
	}
	// 82FD2204: 7F0A4040  cmplw cr6, r10, r8
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[8].u32, &mut ctx.xer);
	// 82FD2208: 409A0030  bne cr6, 0x82fd2238
	if !ctx.cr[6].eq {
		sub_82FD222C(ctx, base);
		return;
	}
	// 82FD220C: 554B083C  slwi r11, r10, 1
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2210: 7D6B222E  lhzx r11, r11, r4
	ctx.r[11].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[4].u32)) } as u64;
	// 82FD2214: 2B0B0020  cmplwi cr6, r11, 0x20
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32 as u32, &mut ctx.xer);
	// 82FD2218: 419A000C  beq cr6, 0x82fd2224
	if ctx.cr[6].eq {
	pc = 0x82FD2224; continue 'dispatch;
	}
	// 82FD221C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD2220: 409A0018  bne cr6, 0x82fd2238
	if !ctx.cr[6].eq {
		sub_82FD222C(ctx, base);
		return;
	}
	// 82FD2224: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD2228: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD222C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD222C size=60
    let mut pc: u32 = 0x82FD222C;
    'dispatch: loop {
        match pc {
            0x82FD222C => {
    //   block [0x82FD222C..0x82FD2268)
	// 82FD222C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD2230: 419A0014  beq cr6, 0x82fd2244
	if ctx.cr[6].eq {
	pc = 0x82FD2244; continue 'dispatch;
	}
	// 82FD2234: 38840002  addi r4, r4, 2
	ctx.r[4].s64 = ctx.r[4].s64 + 2;
	// 82FD2238: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD223C: 2B0B0020  cmplwi cr6, r11, 0x20
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32 as u32, &mut ctx.xer);
	// 82FD2240: 409AFFEC  bne cr6, 0x82fd222c
	if !ctx.cr[6].eq {
	pc = 0x82FD222C; continue 'dispatch;
	}
	// 82FD2244: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2248: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD224C: 41820014  beq 0x82fd2260
	if ctx.cr[0].eq {
	pc = 0x82FD2260; continue 'dispatch;
	}
	// 82FD2250: 38840002  addi r4, r4, 2
	ctx.r[4].s64 = ctx.r[4].s64 + 2;
	// 82FD2254: A1640000  lhz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2258: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD225C: 4082FF74  bne 0x82fd21d0
	if !ctx.cr[0].eq {
		sub_82FD21D0(ctx, base);
		return;
	}
	// 82FD2260: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD2264: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2268(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2268 size=16
    let mut pc: u32 = 0x82FD2268;
    'dispatch: loop {
        match pc {
            0x82FD2268 => {
    //   block [0x82FD2268..0x82FD2278)
	// 82FD2268: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD226C: 409A0028  bne cr6, 0x82fd2294
	if !ctx.cr[6].eq {
		sub_82FD2278(ctx, base);
		return;
	}
	// 82FD2270: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD2274: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2278(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2278 size=44
    let mut pc: u32 = 0x82FD2278;
    'dispatch: loop {
        match pc {
            0x82FD2278 => {
    //   block [0x82FD2278..0x82FD22A4)
	// 82FD2278: 2B0B000D  cmplwi cr6, r11, 0xd
	ctx.cr[6].compare_u32(ctx.r[11].u32, 13 as u32, &mut ctx.xer);
	// 82FD227C: 419A0028  beq cr6, 0x82fd22a4
	if ctx.cr[6].eq {
		sub_82FD22A4(ctx, base);
		return;
	}
	// 82FD2280: 2B0B000A  cmplwi cr6, r11, 0xa
	ctx.cr[6].compare_u32(ctx.r[11].u32, 10 as u32, &mut ctx.xer);
	// 82FD2284: 419A0020  beq cr6, 0x82fd22a4
	if ctx.cr[6].eq {
		sub_82FD22A4(ctx, base);
		return;
	}
	// 82FD2288: 2B0B0009  cmplwi cr6, r11, 9
	ctx.cr[6].compare_u32(ctx.r[11].u32, 9 as u32, &mut ctx.xer);
	// 82FD228C: 419A0018  beq cr6, 0x82fd22a4
	if ctx.cr[6].eq {
		sub_82FD22A4(ctx, base);
		return;
	}
	// 82FD2290: 38630002  addi r3, r3, 2
	ctx.r[3].s64 = ctx.r[3].s64 + 2;
	// 82FD2294: A1630000  lhz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2298: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD229C: 4082FFDC  bne 0x82fd2278
	if !ctx.cr[0].eq {
	pc = 0x82FD2278; continue 'dispatch;
	}
	// 82FD22A0: 4BFFFFD0  b 0x82fd2270
	sub_82FD2268(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD22A4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD22A4 size=8
    let mut pc: u32 = 0x82FD22A4;
    'dispatch: loop {
        match pc {
            0x82FD22A4 => {
    //   block [0x82FD22A4..0x82FD22AC)
	// 82FD22A4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD22A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD22B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD22B0 size=188
    let mut pc: u32 = 0x82FD22B0;
    'dispatch: loop {
        match pc {
            0x82FD22B0 => {
    //   block [0x82FD22B0..0x82FD236C)
	// 82FD22B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD22B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD22B8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD22BC: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 82FD22C0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 82FD22C4: 419A0094  beq cr6, 0x82fd2358
	if ctx.cr[6].eq {
	pc = 0x82FD2358; continue 'dispatch;
	}
	// 82FD22C8: A10A0000  lhz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD22CC: 7D094379  or. r9, r8, r8
	ctx.r[9].u64 = ctx.r[8].u64 | ctx.r[8].u64;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 82FD22D0: 41820088  beq 0x82fd2358
	if ctx.cr[0].eq {
	pc = 0x82FD2358; continue 'dispatch;
	}
	// 82FD22D4: 4BFFFF95  bl 0x82fd2268
	ctx.lr = 0x82FD22D8;
	sub_82FD2268(ctx, base);
	// 82FD22D8: 546B063F  clrlwi. r11, r3, 0x18
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD22DC: 4082000C  bne 0x82fd22e8
	if !ctx.cr[0].eq {
	pc = 0x82FD22E8; continue 'dispatch;
	}
	// 82FD22E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 82FD22E4: 48000078  b 0x82fd235c
	pc = 0x82FD235C; continue 'dispatch;
	// 82FD22E8: 2B090020  cmplwi cr6, r9, 0x20
	ctx.cr[6].compare_u32(ctx.r[9].u32, 32 as u32, &mut ctx.xer);
	// 82FD22EC: 419AFFF4  beq cr6, 0x82fd22e0
	if ctx.cr[6].eq {
	pc = 0x82FD22E0; continue 'dispatch;
	}
	// 82FD22F0: 396A0002  addi r11, r10, 2
	ctx.r[11].s64 = ctx.r[10].s64 + 2;
	// 82FD22F4: 48000008  b 0x82fd22fc
	pc = 0x82FD22FC; continue 'dispatch;
	// 82FD22F8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD22FC: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2300: 28090000  cmplwi r9, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2304: 4082FFF4  bne 0x82fd22f8
	if !ctx.cr[0].eq {
	pc = 0x82FD22F8; continue 'dispatch;
	}
	// 82FD2308: 7D6A5850  subf r11, r10, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 82FD230C: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD2310: 556B083C  slwi r11, r11, 1
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2314: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FD2318: A16BFFFE  lhz r11, -2(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(-2 as u32) ) } as u64;
	// 82FD231C: 2B0B0020  cmplwi cr6, r11, 0x20
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32 as u32, &mut ctx.xer);
	// 82FD2320: 419AFFC0  beq cr6, 0x82fd22e0
	if ctx.cr[6].eq {
	pc = 0x82FD22E0; continue 'dispatch;
	}
	// 82FD2324: 550B043F  clrlwi. r11, r8, 0x10
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x0000FFFFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD2328: 41820030  beq 0x82fd2358
	if ctx.cr[0].eq {
	pc = 0x82FD2358; continue 'dispatch;
	}
	// 82FD232C: 2B0B0020  cmplwi cr6, r11, 0x20
	ctx.cr[6].compare_u32(ctx.r[11].u32, 32 as u32, &mut ctx.xer);
	// 82FD2330: 409A0014  bne cr6, 0x82fd2344
	if !ctx.cr[6].eq {
	pc = 0x82FD2344; continue 'dispatch;
	}
	// 82FD2334: 552B063F  clrlwi. r11, r9, 0x18
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD2338: 4082FFA8  bne 0x82fd22e0
	if !ctx.cr[0].eq {
	pc = 0x82FD22E0; continue 'dispatch;
	}
	// 82FD233C: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 82FD2340: 48000008  b 0x82fd2348
	pc = 0x82FD2348; continue 'dispatch;
	// 82FD2344: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FD2348: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD234C: A16A0000  lhz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2350: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2354: 4082FFD8  bne 0x82fd232c
	if !ctx.cr[0].eq {
	pc = 0x82FD232C; continue 'dispatch;
	}
	// 82FD2358: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 82FD235C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD2360: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD2364: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD2368: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2370(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2370 size=308
    let mut pc: u32 = 0x82FD2370;
    'dispatch: loop {
        match pc {
            0x82FD2370 => {
    //   block [0x82FD2370..0x82FD24A4)
	// 82FD2370: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD2374: 481D5DF9  bl 0x831a816c
	ctx.lr = 0x82FD2378;
	sub_831A8130(ctx, base);
	// 82FD2378: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD237C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD2380: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FD2384: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 82FD2388: 419A0114  beq cr6, 0x82fd249c
	if ctx.cr[6].eq {
	pc = 0x82FD249C; continue 'dispatch;
	}
	// 82FD238C: A17E0000  lhz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2390: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2394: 41820108  beq 0x82fd249c
	if ctx.cr[0].eq {
	pc = 0x82FD249C; continue 'dispatch;
	}
	// 82FD2398: 397E0002  addi r11, r30, 2
	ctx.r[11].s64 = ctx.r[30].s64 + 2;
	// 82FD239C: 48000008  b 0x82fd23a4
	pc = 0x82FD23A4; continue 'dispatch;
	// 82FD23A0: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD23A4: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD23A8: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD23AC: 4082FFF4  bne 0x82fd23a0
	if !ctx.cr[0].eq {
	pc = 0x82FD23A0; continue 'dispatch;
	}
	// 82FD23B0: 7D7E5850  subf r11, r30, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 82FD23B4: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD23B8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FD23BC: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD23C0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD23C4: 814A0004  lwz r10, 4(r10)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD23C8: 5564083C  slwi r4, r11, 1
	ctx.r[4].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 82FD23CC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 82FD23D0: 4E800421  bctrl
	ctx.lr = 0x82FD23D4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD23D4: A17E0000  lhz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD23D8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD23DC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD23E0: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 82FD23E4: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 82FD23E8: 41820044  beq 0x82fd242c
	if ctx.cr[0].eq {
	pc = 0x82FD242C; continue 'dispatch;
	}
	// 82FD23EC: A1090000  lhz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD23F0: 7D0A4378  mr r10, r8
	ctx.r[10].u64 = ctx.r[8].u64;
	// 82FD23F4: 2B0A000D  cmplwi cr6, r10, 0xd
	ctx.cr[6].compare_u32(ctx.r[10].u32, 13 as u32, &mut ctx.xer);
	// 82FD23F8: 419A0024  beq cr6, 0x82fd241c
	if ctx.cr[6].eq {
	pc = 0x82FD241C; continue 'dispatch;
	}
	// 82FD23FC: 2B0A000A  cmplwi cr6, r10, 0xa
	ctx.cr[6].compare_u32(ctx.r[10].u32, 10 as u32, &mut ctx.xer);
	// 82FD2400: 419A001C  beq cr6, 0x82fd241c
	if ctx.cr[6].eq {
	pc = 0x82FD241C; continue 'dispatch;
	}
	// 82FD2404: 2B0A0009  cmplwi cr6, r10, 9
	ctx.cr[6].compare_u32(ctx.r[10].u32, 9 as u32, &mut ctx.xer);
	// 82FD2408: 419A0014  beq cr6, 0x82fd241c
	if ctx.cr[6].eq {
	pc = 0x82FD241C; continue 'dispatch;
	}
	// 82FD240C: 2B0A0020  cmplwi cr6, r10, 0x20
	ctx.cr[6].compare_u32(ctx.r[10].u32, 32 as u32, &mut ctx.xer);
	// 82FD2410: 419A000C  beq cr6, 0x82fd241c
	if ctx.cr[6].eq {
	pc = 0x82FD241C; continue 'dispatch;
	}
	// 82FD2414: B10B0000  sth r8, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u16 ) };
	// 82FD2418: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD241C: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD2420: A1490000  lhz r10, 0(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2424: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2428: 4082FFC4  bne 0x82fd23ec
	if !ctx.cr[0].eq {
	pc = 0x82FD23EC; continue 'dispatch;
	}
	// 82FD242C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD2430: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 82FD2434: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD2438: 419A0034  beq cr6, 0x82fd246c
	if ctx.cr[6].eq {
	pc = 0x82FD246C; continue 'dispatch;
	}
	// 82FD243C: A17F0000  lhz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2440: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2444: 41820028  beq 0x82fd246c
	if ctx.cr[0].eq {
	pc = 0x82FD246C; continue 'dispatch;
	}
	// 82FD2448: 397F0002  addi r11, r31, 2
	ctx.r[11].s64 = ctx.r[31].s64 + 2;
	// 82FD244C: 48000008  b 0x82fd2454
	pc = 0x82FD2454; continue 'dispatch;
	// 82FD2450: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD2454: A14B0000  lhz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2458: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD245C: 4082FFF4  bne 0x82fd2450
	if !ctx.cr[0].eq {
	pc = 0x82FD2450; continue 'dispatch;
	}
	// 82FD2460: 7D7F5850  subf r11, r31, r11
	ctx.r[11].s64 = ctx.r[11].s64 - ctx.r[31].s64;
	// 82FD2464: 7D6B0E70  srawi r11, r11, 1
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[11].s32 >> 1) as i64;
	// 82FD2468: 48000008  b 0x82fd2470
	pc = 0x82FD2470; continue 'dispatch;
	// 82FD246C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD2470: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 82FD2474: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD2478: 5565083C  slwi r5, r11, 1
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 82FD247C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 82FD2480: 481D6091  bl 0x831a8510
	ctx.lr = 0x82FD2484;
	sub_831A8510(ctx, base);
	// 82FD2484: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2488: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 82FD248C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 82FD2490: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2494: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD2498: 4E800421  bctrl
	ctx.lr = 0x82FD249C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD249C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD24A0: 481D5D1C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD24A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD24A8 size=92
    let mut pc: u32 = 0x82FD24A8;
    'dispatch: loop {
        match pc {
            0x82FD24A8 => {
    //   block [0x82FD24A8..0x82FD2504)
	// 82FD24A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD24AC: 481D5CC1  bl 0x831a816c
	ctx.lr = 0x82FD24B0;
	sub_831A8130(ctx, base);
	// 82FD24B0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD24B4: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 82FD24B8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD24BC: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FD24C0: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 82FD24C4: 815F0018  lwz r10, 0x18(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 82FD24C8: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 82FD24CC: B16A0000  sth r11, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82FD24D0: A0830000  lhz r4, 0(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD24D4: 48000020  b 0x82fd24f4
	pc = 0x82FD24F4; continue 'dispatch;
	// 82FD24D8: A15D0000  lhz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD24DC: 3BDE0002  addi r30, r30, 2
	ctx.r[30].s64 = ctx.r[30].s64 + 2;
	// 82FD24E0: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 82FD24E4: 419A000C  beq cr6, 0x82fd24f0
	if ctx.cr[6].eq {
	pc = 0x82FD24F0; continue 'dispatch;
	}
	// 82FD24E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 82FD24EC: 4BFFE62D  bl 0x82fd0b18
	ctx.lr = 0x82FD24F0;
	sub_82FD0B18(ctx, base);
	// 82FD24F0: A09E0000  lhz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD24F4: 7C8B2379  or. r11, r4, r4
	ctx.r[11].u64 = ctx.r[4].u64 | ctx.r[4].u64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD24F8: 4082FFE0  bne 0x82fd24d8
	if !ctx.cr[0].eq {
	pc = 0x82FD24D8; continue 'dispatch;
	}
	// 82FD24FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 82FD2500: 481D5CBC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2508(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2508 size=484
    let mut pc: u32 = 0x82FD2508;
    'dispatch: loop {
        match pc {
            0x82FD2508 => {
    //   block [0x82FD2508..0x82FD26EC)
	// 82FD2508: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD250C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD2510: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD2514: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD2518: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 82FD251C: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 82FD2520: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 82FD2524: 419A01B4  beq cr6, 0x82fd26d8
	if ctx.cr[6].eq {
	pc = 0x82FD26D8; continue 'dispatch;
	}
	// 82FD2528: A0C70000  lhz r6, 0(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD252C: 28060000  cmplwi r6, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2530: 418201A8  beq 0x82fd26d8
	if ctx.cr[0].eq {
	pc = 0x82FD26D8; continue 'dispatch;
	}
	// 82FD2534: 3880003A  li r4, 0x3a
	ctx.r[4].s64 = 58;
	// 82FD2538: 4BFFF879  bl 0x82fd1db0
	ctx.lr = 0x82FD253C;
	sub_82FD1DB0(ctx, base);
	// 82FD253C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 82FD2540: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 82FD2544: 409A0090  bne cr6, 0x82fd25d4
	if !ctx.cr[6].eq {
	pc = 0x82FD25D4; continue 'dispatch;
	}
	// 82FD2548: 3880002F  li r4, 0x2f
	ctx.r[4].s64 = 47;
	// 82FD254C: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 82FD2550: 4BFFF861  bl 0x82fd1db0
	ctx.lr = 0x82FD2554;
	sub_82FD1DB0(ctx, base);
	// 82FD2554: 2C030000  cmpwi r3, 0
	ctx.cr[0].compare_i32(ctx.r[0].s32, 0, &mut ctx.xer);
	// 82FD2558: 4082015C  bne 0x82fd26b4
	if !ctx.cr[0].eq {
	pc = 0x82FD26B4; continue 'dispatch;
	}
	// 82FD255C: 39400066  li r10, 0x66
	ctx.r[10].s64 = 102;
	// 82FD2560: 39200069  li r9, 0x69
	ctx.r[9].s64 = 105;
	// 82FD2564: 38C0006C  li r6, 0x6c
	ctx.r[6].s64 = 108;
	// 82FD2568: 38A00065  li r5, 0x65
	ctx.r[5].s64 = 101;
	// 82FD256C: 3880003A  li r4, 0x3a
	ctx.r[4].s64 = 58;
	// 82FD2570: 3960002F  li r11, 0x2f
	ctx.r[11].s64 = 47;
	// 82FD2574: B1480000  sth r10, 0(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD2578: B1280002  sth r9, 2(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(2 as u32), ctx.r[9].u16 ) };
	// 82FD257C: 7CE93B78  mr r9, r7
	ctx.r[9].u64 = ctx.r[7].u64;
	// 82FD2580: B0C80004  sth r6, 4(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[6].u16 ) };
	// 82FD2584: 38C00007  li r6, 7
	ctx.r[6].s64 = 7;
	// 82FD2588: B0A80006  sth r5, 6(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(6 as u32), ctx.r[5].u16 ) };
	// 82FD258C: B0880008  sth r4, 8(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[4].u16 ) };
	// 82FD2590: B168000A  sth r11, 0xa(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(10 as u32), ctx.r[11].u16 ) };
	// 82FD2594: B168000C  sth r11, 0xc(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), ctx.r[11].u16 ) };
	// 82FD2598: A1470000  lhz r10, 0(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD259C: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD25A0: 41820024  beq 0x82fd25c4
	if ctx.cr[0].eq {
	pc = 0x82FD25C4; continue 'dispatch;
	}
	// 82FD25A4: 3968000E  addi r11, r8, 0xe
	ctx.r[11].s64 = ctx.r[8].s64 + 14;
	// 82FD25A8: 39290002  addi r9, r9, 2
	ctx.r[9].s64 = ctx.r[9].s64 + 2;
	// 82FD25AC: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD25B0: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 82FD25B4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD25B8: A1490000  lhz r10, 0(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD25BC: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD25C0: 4082FFE8  bne 0x82fd25a8
	if !ctx.cr[0].eq {
	pc = 0x82FD25A8; continue 'dispatch;
	}
	// 82FD25C4: 54CB083C  slwi r11, r6, 1
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD25C8: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 82FD25CC: 7D4B432E  sthx r10, r11, r8
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), ctx.r[10].u16) };
	// 82FD25D0: 48000108  b 0x82fd26d8
	pc = 0x82FD26D8; continue 'dispatch;
	// 82FD25D4: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 82FD25D8: 409A00DC  bne cr6, 0x82fd26b4
	if !ctx.cr[6].eq {
	pc = 0x82FD26B4; continue 'dispatch;
	}
	// 82FD25DC: 54CB043E  clrlwi r11, r6, 0x10
	ctx.r[11].u64 = ctx.r[6].u32 as u64 & 0x0000FFFFu64;
	// 82FD25E0: 2B0B0061  cmplwi cr6, r11, 0x61
	ctx.cr[6].compare_u32(ctx.r[11].u32, 97 as u32, &mut ctx.xer);
	// 82FD25E4: 4198000C  blt cr6, 0x82fd25f0
	if ctx.cr[6].lt {
	pc = 0x82FD25F0; continue 'dispatch;
	}
	// 82FD25E8: 2B0B007A  cmplwi cr6, r11, 0x7a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 122 as u32, &mut ctx.xer);
	// 82FD25EC: 40990014  ble cr6, 0x82fd2600
	if !ctx.cr[6].gt {
	pc = 0x82FD2600; continue 'dispatch;
	}
	// 82FD25F0: 2B0B0041  cmplwi cr6, r11, 0x41
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65 as u32, &mut ctx.xer);
	// 82FD25F4: 41980014  blt cr6, 0x82fd2608
	if ctx.cr[6].lt {
	pc = 0x82FD2608; continue 'dispatch;
	}
	// 82FD25F8: 2B0B005A  cmplwi cr6, r11, 0x5a
	ctx.cr[6].compare_u32(ctx.r[11].u32, 90 as u32, &mut ctx.xer);
	// 82FD25FC: 4199000C  bgt cr6, 0x82fd2608
	if ctx.cr[6].gt {
	pc = 0x82FD2608; continue 'dispatch;
	}
	// 82FD2600: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 82FD2604: 48000008  b 0x82fd260c
	pc = 0x82FD260C; continue 'dispatch;
	// 82FD2608: 7FEBFB78  mr r11, r31
	ctx.r[11].u64 = ctx.r[31].u64;
	// 82FD260C: 556B063F  clrlwi. r11, r11, 0x18
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x000000FFu64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 82FD2610: 418200A4  beq 0x82fd26b4
	if ctx.cr[0].eq {
	pc = 0x82FD26B4; continue 'dispatch;
	}
	// 82FD2614: 39400066  li r10, 0x66
	ctx.r[10].s64 = 102;
	// 82FD2618: 39200069  li r9, 0x69
	ctx.r[9].s64 = 105;
	// 82FD261C: 38C0006C  li r6, 0x6c
	ctx.r[6].s64 = 108;
	// 82FD2620: 38A00065  li r5, 0x65
	ctx.r[5].s64 = 101;
	// 82FD2624: 3880003A  li r4, 0x3a
	ctx.r[4].s64 = 58;
	// 82FD2628: 3960002F  li r11, 0x2f
	ctx.r[11].s64 = 47;
	// 82FD262C: B1480000  sth r10, 0(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD2630: B1280002  sth r9, 2(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(2 as u32), ctx.r[9].u16 ) };
	// 82FD2634: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 82FD2638: B0C80004  sth r6, 4(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[6].u16 ) };
	// 82FD263C: B0A80006  sth r5, 6(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(6 as u32), ctx.r[5].u16 ) };
	// 82FD2640: 7CE53B78  mr r5, r7
	ctx.r[5].u64 = ctx.r[7].u64;
	// 82FD2644: B0880008  sth r4, 8(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[4].u16 ) };
	// 82FD2648: B168000A  sth r11, 0xa(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(10 as u32), ctx.r[11].u16 ) };
	// 82FD264C: B168000C  sth r11, 0xc(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(12 as u32), ctx.r[11].u16 ) };
	// 82FD2650: B168000E  sth r11, 0xe(r8)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[8].u32.wrapping_add(14 as u32), ctx.r[11].u16 ) };
	// 82FD2654: A1470000  lhz r10, 0(r7)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2658: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD265C: 4182004C  beq 0x82fd26a8
	if ctx.cr[0].eq {
	pc = 0x82FD26A8; continue 'dispatch;
	}
	// 82FD2660: 39480010  addi r10, r8, 0x10
	ctx.r[10].s64 = ctx.r[8].s64 + 16;
	// 82FD2664: A0C50000  lhz r6, 0(r5)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2668: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 82FD266C: 2B0700A5  cmplwi cr6, r7, 0xa5
	ctx.cr[6].compare_u32(ctx.r[7].u32, 165 as u32, &mut ctx.xer);
	// 82FD2670: 419A001C  beq cr6, 0x82fd268c
	if ctx.cr[6].eq {
	pc = 0x82FD268C; continue 'dispatch;
	}
	// 82FD2674: 2B0720A9  cmplwi cr6, r7, 0x20a9
	ctx.cr[6].compare_u32(ctx.r[7].u32, 8361 as u32, &mut ctx.xer);
	// 82FD2678: 419A0014  beq cr6, 0x82fd268c
	if ctx.cr[6].eq {
	pc = 0x82FD268C; continue 'dispatch;
	}
	// 82FD267C: 2B07005C  cmplwi cr6, r7, 0x5c
	ctx.cr[6].compare_u32(ctx.r[7].u32, 92 as u32, &mut ctx.xer);
	// 82FD2680: 419A000C  beq cr6, 0x82fd268c
	if ctx.cr[6].eq {
	pc = 0x82FD268C; continue 'dispatch;
	}
	// 82FD2684: B0CA0000  sth r6, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[6].u16 ) };
	// 82FD2688: 48000008  b 0x82fd2690
	pc = 0x82FD2690; continue 'dispatch;
	// 82FD268C: B16A0000  sth r11, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u16 ) };
	// 82FD2690: 38A50002  addi r5, r5, 2
	ctx.r[5].s64 = ctx.r[5].s64 + 2;
	// 82FD2694: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 82FD2698: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 82FD269C: A0E50000  lhz r7, 0(r5)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[5].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD26A0: 28070000  cmplwi r7, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD26A4: 4082FFC0  bne 0x82fd2664
	if !ctx.cr[0].eq {
	pc = 0x82FD2664; continue 'dispatch;
	}
	// 82FD26A8: 552B083C  slwi r11, r9, 1
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD26AC: 7FEB432E  sthx r31, r11, r8
	unsafe { crate::rt::store_u16(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32), ctx.r[31].u16) };
	// 82FD26B0: 48000028  b 0x82fd26d8
	pc = 0x82FD26D8; continue 'dispatch;
	// 82FD26B4: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 82FD26B8: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 82FD26BC: 7D283850  subf r9, r8, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[8].s64;
	// 82FD26C0: B14B0000  sth r10, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u16 ) };
	// 82FD26C4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 82FD26C8: 7D495A2E  lhzx r10, r9, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD26CC: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD26D0: 4082FFF0  bne 0x82fd26c0
	if !ctx.cr[0].eq {
	pc = 0x82FD26C0; continue 'dispatch;
	}
	// 82FD26D4: B3EB0000  sth r31, 0(r11)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[31].u16 ) };
	// 82FD26D8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD26DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD26E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD26E4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD26E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD26F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD26F0 size=56
    let mut pc: u32 = 0x82FD26F0;
    'dispatch: loop {
        match pc {
            0x82FD26F0 => {
    //   block [0x82FD26F0..0x82FD2728)
	// 82FD26F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD26F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD26F8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD26FC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD2700: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD2704: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2708: 4B2EDB61  bl 0x822c0268
	ctx.lr = 0x82FD270C;
	sub_822C0268(ctx, base);
	// 82FD270C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD2710: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD2714: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD2718: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD271C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD2720: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD2724: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2728(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2728 size=20
    let mut pc: u32 = 0x82FD2728;
    'dispatch: loop {
        match pc {
            0x82FD2728 => {
    //   block [0x82FD2728..0x82FD273C)
	// 82FD2728: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD272C: 906BB7C0  stw r3, -0x4840(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-18496 as u32), ctx.r[3].u32 ) };
	// 82FD2730: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 82FD2734: 908BB7C4  stw r4, -0x483c(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-18492 as u32), ctx.r[4].u32 ) };
	// 82FD2738: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2740(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2740 size=88
    let mut pc: u32 = 0x82FD2740;
    'dispatch: loop {
        match pc {
            0x82FD2740 => {
    //   block [0x82FD2740..0x82FD2798)
	// 82FD2740: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD2744: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD2748: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD274C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD2750: 3FE08339  lis r31, -0x7cc7
	ctx.r[31].s64 = -2093416448;
	// 82FD2754: 807FB7C0  lwz r3, -0x4840(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-18496 as u32) ) } as u64;
	// 82FD2758: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 82FD275C: 419A0018  beq cr6, 0x82fd2774
	if ctx.cr[6].eq {
	pc = 0x82FD2774; continue 'dispatch;
	}
	// 82FD2760: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD2764: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 82FD2768: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 82FD276C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 82FD2770: 4E800421  bctrl
	ctx.lr = 0x82FD2774;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 82FD2774: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 82FD2778: 3D408339  lis r10, -0x7cc7
	ctx.r[10].s64 = -2093416448;
	// 82FD277C: 917FB7C0  stw r11, -0x4840(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-18496 as u32), ctx.r[11].u32 ) };
	// 82FD2780: 916AB7C4  stw r11, -0x483c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-18492 as u32), ctx.r[11].u32 ) };
	// 82FD2784: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 82FD2788: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD278C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD2790: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD2794: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2798(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2798 size=16
    let mut pc: u32 = 0x82FD2798;
    'dispatch: loop {
        match pc {
            0x82FD2798 => {
    //   block [0x82FD2798..0x82FD27A8)
	// 82FD2798: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD279C: 396B6B68  addi r11, r11, 0x6b68
	ctx.r[11].s64 = ctx.r[11].s64 + 27496;
	// 82FD27A0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 82FD27A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD27A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD27A8 size=128
    let mut pc: u32 = 0x82FD27A8;
    'dispatch: loop {
        match pc {
            0x82FD27A8 => {
    //   block [0x82FD27A8..0x82FD2828)
	// 82FD27A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD27AC: 481D59C1  bl 0x831a816c
	ctx.lr = 0x82FD27B0;
	sub_831A8130(ctx, base);
	// 82FD27B0: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD27B4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD27B8: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 82FD27BC: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 82FD27C0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD27C4: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD27C8: 41980030  blt cr6, 0x82fd27f8
	if ctx.cr[6].lt {
	pc = 0x82FD27F8; continue 'dispatch;
	}
	// 82FD27CC: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD27D0: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD27D4: 38C00074  li r6, 0x74
	ctx.r[6].s64 = 116;
	// 82FD27D8: 388B6B80  addi r4, r11, 0x6b80
	ctx.r[4].s64 = ctx.r[11].s64 + 27520;
	// 82FD27DC: 38A00043  li r5, 0x43
	ctx.r[5].s64 = 67;
	// 82FD27E0: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD27E4: 4BFFE175  bl 0x82fd0958
	ctx.lr = 0x82FD27E8;
	sub_82FD0958(ctx, base);
	// 82FD27E8: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD27EC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD27F0: 388BC49C  addi r4, r11, -0x3b64
	ctx.r[4].s64 = ctx.r[11].s64 + -15204;
	// 82FD27F4: 481DE435  bl 0x831b0c28
	ctx.lr = 0x82FD27F8;
	sub_831B0C28(ctx, base);
	// 82FD27F8: 897F0004  lbz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD27FC: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2800: 41820014  beq 0x82fd2814
	if ctx.cr[0].eq {
	pc = 0x82FD2814; continue 'dispatch;
	}
	// 82FD2804: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2808: 57CA103A  slwi r10, r30, 2
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD280C: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD2810: 4B2EDA59  bl 0x822c0268
	ctx.lr = 0x82FD2814;
	sub_822C0268(ctx, base);
	// 82FD2814: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2818: 57CA103A  slwi r10, r30, 2
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD281C: 7FAA592E  stwx r29, r10, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32), ctx.r[29].u32) };
	// 82FD2820: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 82FD2824: 481D5998  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2828(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2828 size=104
    let mut pc: u32 = 0x82FD2828;
    'dispatch: loop {
        match pc {
            0x82FD2828 => {
    //   block [0x82FD2828..0x82FD2890)
	// 82FD2828: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD282C: 481D593D  bl 0x831a8168
	ctx.lr = 0x82FD2830;
	sub_831A8130(ctx, base);
	// 82FD2830: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD2834: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD2838: 3B800000  li r28, 0
	ctx.r[28].s64 = 0;
	// 82FD283C: 7F9DE378  mr r29, r28
	ctx.r[29].u64 = ctx.r[28].u64;
	// 82FD2840: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2844: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 82FD2848: 4099003C  ble cr6, 0x82fd2884
	if !ctx.cr[6].gt {
	pc = 0x82FD2884; continue 'dispatch;
	}
	// 82FD284C: 7F9EE378  mr r30, r28
	ctx.r[30].u64 = ctx.r[28].u64;
	// 82FD2850: 897F0004  lbz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD2854: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD2858: 41820010  beq 0x82fd2868
	if ctx.cr[0].eq {
	pc = 0x82FD2868; continue 'dispatch;
	}
	// 82FD285C: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2860: 7C6BF02E  lwzx r3, r11, r30
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 82FD2864: 4B2EDA05  bl 0x822c0268
	ctx.lr = 0x82FD2868;
	sub_822C0268(ctx, base);
	// 82FD2868: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD286C: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 82FD2870: 7F8BF12E  stwx r28, r11, r30
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[11].u32.wrapping_add(ctx.r[30].u32), ctx.r[28].u32) };
	// 82FD2874: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 82FD2878: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD287C: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD2880: 4198FFD0  blt cr6, 0x82fd2850
	if ctx.cr[6].lt {
	pc = 0x82FD2850; continue 'dispatch;
	}
	// 82FD2884: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 82FD2888: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FD288C: 481D592C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2890(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x82FD2890 size=264
    let mut pc: u32 = 0x82FD2890;
    'dispatch: loop {
        match pc {
            0x82FD2890 => {
    //   block [0x82FD2890..0x82FD2998)
	// 82FD2890: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 82FD2894: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 82FD2898: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 82FD289C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 82FD28A0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 82FD28A4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 82FD28A8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 82FD28AC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD28B0: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD28B4: 41980030  blt cr6, 0x82fd28e4
	if ctx.cr[6].lt {
	pc = 0x82FD28E4; continue 'dispatch;
	}
	// 82FD28B8: 3D608213  lis r11, -0x7ded
	ctx.r[11].s64 = -2112684032;
	// 82FD28BC: 80FF0014  lwz r7, 0x14(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 82FD28C0: 38C00074  li r6, 0x74
	ctx.r[6].s64 = 116;
	// 82FD28C4: 388B6B80  addi r4, r11, 0x6b80
	ctx.r[4].s64 = ctx.r[11].s64 + 27520;
	// 82FD28C8: 38A00090  li r5, 0x90
	ctx.r[5].s64 = 144;
	// 82FD28CC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD28D0: 4BFFE089  bl 0x82fd0958
	ctx.lr = 0x82FD28D4;
	sub_82FD0958(ctx, base);
	// 82FD28D4: 3D608225  lis r11, -0x7ddb
	ctx.r[11].s64 = -2111504384;
	// 82FD28D8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 82FD28DC: 388BC49C  addi r4, r11, -0x3b64
	ctx.r[4].s64 = ctx.r[11].s64 + -15204;
	// 82FD28E0: 481DE349  bl 0x831b0c28
	ctx.lr = 0x82FD28E4;
	sub_831B0C28(ctx, base);
	// 82FD28E4: 897F0004  lbz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD28E8: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD28EC: 41820014  beq 0x82fd2900
	if ctx.cr[0].eq {
	pc = 0x82FD2900; continue 'dispatch;
	}
	// 82FD28F0: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD28F4: 57CA103A  slwi r10, r30, 2
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD28F8: 7C6A582E  lwzx r3, r10, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 82FD28FC: 4B2ED96D  bl 0x822c0268
	ctx.lr = 0x82FD2900;
	sub_822C0268(ctx, base);
	// 82FD2900: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2904: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FD2908: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD290C: 409A0018  bne cr6, 0x82fd2924
	if !ctx.cr[6].eq {
	pc = 0x82FD2924; continue 'dispatch;
	}
	// 82FD2910: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2914: 57CA103A  slwi r10, r30, 2
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD2918: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FD291C: 7D2A592E  stwx r9, r10, r11
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32), ctx.r[9].u32) };
	// 82FD2920: 48000054  b 0x82fd2974
	pc = 0x82FD2974; continue 'dispatch;
	// 82FD2924: 7FCAF378  mr r10, r30
	ctx.r[10].u64 = ctx.r[30].u64;
	// 82FD2928: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 82FD292C: 40980030  bge cr6, 0x82fd295c
	if !ctx.cr[6].lt {
	pc = 0x82FD295C; continue 'dispatch;
	}
	// 82FD2930: 57CB103A  slwi r11, r30, 2
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD2934: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2938: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 82FD293C: 7D2B4A14  add r9, r11, r9
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 82FD2940: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 82FD2944: 81090004  lwz r8, 4(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD2948: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 82FD294C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2950: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 82FD2954: 7F0A4840  cmplw cr6, r10, r9
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[9].u32, &mut ctx.xer);
	// 82FD2958: 4198FFDC  blt cr6, 0x82fd2934
	if ctx.cr[6].lt {
	pc = 0x82FD2934; continue 'dispatch;
	}
	// 82FD295C: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2960: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 82FD2964: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD2968: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 82FD296C: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 82FD2970: 912BFFFC  stw r9, -4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), ctx.r[9].u32 ) };
	// 82FD2974: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD2978: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FD297C: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FD2980: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 82FD2984: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 82FD2988: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 82FD298C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 82FD2990: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 82FD2994: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD2998(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD2998 size=12
    let mut pc: u32 = 0x82FD2998;
    'dispatch: loop {
        match pc {
            0x82FD2998 => {
    //   block [0x82FD2998..0x82FD29A4)
	// 82FD2998: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 82FD299C: 280B0000  cmplwi r11, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD29A0: 4D820020  beqlr
	if ctx.cr[0].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD29A4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD29A4 size=20
    let mut pc: u32 = 0x82FD29A4;
    'dispatch: loop {
        match pc {
            0x82FD29A4 => {
    //   block [0x82FD29A4..0x82FD29B8)
	// 82FD29A4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 82FD29A8: 89430004  lbz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 82FD29AC: 280A0000  cmplwi r10, 0
	ctx.cr[0].compare_u32(ctx.r[0].u32, 0 as u32, &mut ctx.xer);
	// 82FD29B0: 91630008  stw r11, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 82FD29B4: 4D820020  beqlr
	if ctx.cr[0].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD29B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD29B8 size=16
    let mut pc: u32 = 0x82FD29B8;
    'dispatch: loop {
        match pc {
            0x82FD29B8 => {
    //   block [0x82FD29B8..0x82FD29C8)
	// 82FD29B8: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 82FD29BC: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 82FD29C0: 7C6B502E  lwzx r3, r11, r10
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 82FD29C4: 4B2ED8A4  b 0x822c0268
	sub_822C0268(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_82FD29C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x82FD29C8 size=4
    let mut pc: u32 = 0x82FD29C8;
    'dispatch: loop {
        match pc {
            0x82FD29C8 => {
    //   block [0x82FD29C8..0x82FD29CC)
	// 82FD29C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}



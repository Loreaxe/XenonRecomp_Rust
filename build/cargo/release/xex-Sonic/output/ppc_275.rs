pub fn sub_83155A10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155A10 size=168
    let mut pc: u32 = 0x83155A10;
    'dispatch: loop {
        match pc {
            0x83155A10 => {
    //   block [0x83155A10..0x83155AB8)
	// 83155A10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155A14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155A18: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83155A1C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155A20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155A24: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83155A28: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155A2C: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 83155A30: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 83155A34: 38CB56C8  addi r6, r11, 0x56c8
	ctx.r[6].s64 = ctx.r[11].s64 + 22216;
	// 83155A38: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 83155A3C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83155A40: 386000BC  li r3, 0xbc
	ctx.r[3].s64 = 188;
	// 83155A44: 4800A1D5  bl 0x8315fc18
	ctx.lr = 0x83155A48;
	sub_8315FC18(ctx, base);
	// 83155A48: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155A4C: 419A0050  beq cr6, 0x83155a9c
	if ctx.cr[6].eq {
	pc = 0x83155A9C; continue 'dispatch;
	}
	// 83155A50: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 83155A54: 93E30004  stw r31, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[31].u32 ) };
	// 83155A58: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83155A5C: 392A5644  addi r9, r10, 0x5644
	ctx.r[9].s64 = ctx.r[10].s64 + 22084;
	// 83155A60: 91630028  stw r11, 0x28(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 83155A64: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155A68: 9163002C  stw r11, 0x2c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 83155A6C: 99630030  stb r11, 0x30(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), ctx.r[11].u8 ) };
	// 83155A70: 99630031  stb r11, 0x31(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(49 as u32), ctx.r[11].u8 ) };
	// 83155A74: 99630032  stb r11, 0x32(r3)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[3].u32.wrapping_add(50 as u32), ctx.r[11].u8 ) };
	// 83155A78: 91630034  stw r11, 0x34(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[11].u32 ) };
	// 83155A7C: 91630038  stw r11, 0x38(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), ctx.r[11].u32 ) };
	// 83155A80: 93C3003C  stw r30, 0x3c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(60 as u32), ctx.r[30].u32 ) };
	// 83155A84: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83155A88: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155A8C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155A90: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83155A94: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155A98: 4E800020  blr
	return;
	// 83155A9C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155AA0: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 83155AA4: 388B56BC  addi r4, r11, 0x56bc
	ctx.r[4].s64 = ctx.r[11].s64 + 22204;
	// 83155AA8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155AAC: 4800A095  bl 0x8315fb40
	ctx.lr = 0x83155AB0;
	sub_8315FB40(ctx, base);
	// 83155AB0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155AB4: 4BFFFFD0  b 0x83155a84
	pc = 0x83155A84; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155AB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155AB8 size=76
    let mut pc: u32 = 0x83155AB8;
    'dispatch: loop {
        match pc {
            0x83155AB8 => {
    //   block [0x83155AB8..0x83155B04)
	// 83155AB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155ABC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155AC0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155AC4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155AC8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155ACC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155AD0: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83155AD4: 392B562C  addi r9, r11, 0x562c
	ctx.r[9].s64 = ctx.r[11].s64 + 22060;
	// 83155AD8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83155ADC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155AE0: 419A0010  beq cr6, 0x83155af0
	if ctx.cr[6].eq {
	pc = 0x83155AF0; continue 'dispatch;
	}
	// 83155AE4: 388000BC  li r4, 0xbc
	ctx.r[4].s64 = 188;
	// 83155AE8: 4800A199  bl 0x8315fc80
	ctx.lr = 0x83155AEC;
	sub_8315FC80(ctx, base);
	// 83155AEC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155AF0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155AF4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155AF8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155AFC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155B00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155B08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155B08 size=236
    let mut pc: u32 = 0x83155B08;
    'dispatch: loop {
        match pc {
            0x83155B08 => {
    //   block [0x83155B08..0x83155BF4)
	// 83155B08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155B0C: 4805265D  bl 0x831a8168
	ctx.lr = 0x83155B10;
	sub_831A8130(ctx, base);
	// 83155B10: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155B14: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 83155B18: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155B1C: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 83155B20: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 83155B24: 38CB570C  addi r6, r11, 0x570c
	ctx.r[6].s64 = ctx.r[11].s64 + 22284;
	// 83155B28: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 83155B2C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83155B30: 386001C8  li r3, 0x1c8
	ctx.r[3].s64 = 456;
	// 83155B34: 4800A0E5  bl 0x8315fc18
	ctx.lr = 0x83155B38;
	sub_8315FC18(ctx, base);
	// 83155B38: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155B3C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83155B40: 419A007C  beq cr6, 0x83155bbc
	if ctx.cr[6].eq {
	pc = 0x83155BBC; continue 'dispatch;
	}
	// 83155B44: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155B48: 939F0004  stw r28, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[28].u32 ) };
	// 83155B4C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83155B50: 394B565C  addi r10, r11, 0x565c
	ctx.r[10].s64 = ctx.r[11].s64 + 22108;
	// 83155B54: 93DF0028  stw r30, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 83155B58: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 83155B5C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 83155B60: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83155B64: 93DF002C  stw r30, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[30].u32 ) };
	// 83155B68: 9BDF0030  stb r30, 0x30(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[30].u8 ) };
	// 83155B6C: 9BDF0031  stb r30, 0x31(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(49 as u32), ctx.r[30].u8 ) };
	// 83155B70: 9BDF0032  stb r30, 0x32(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(50 as u32), ctx.r[30].u8 ) };
	// 83155B74: 93DF0034  stw r30, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[30].u32 ) };
	// 83155B78: 93DF0038  stw r30, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[30].u32 ) };
	// 83155B7C: 93BF003C  stw r29, 0x3c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), ctx.r[29].u32 ) };
	// 83155B80: 48013E71  bl 0x831699f0
	ctx.lr = 0x83155B84;
	sub_831699F0(ctx, base);
	// 83155B84: 907F00B4  stw r3, 0xb4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(180 as u32), ctx.r[3].u32 ) };
	// 83155B88: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155B8C: 409A0050  bne cr6, 0x83155bdc
	if !ctx.cr[6].eq {
	pc = 0x83155BDC; continue 'dispatch;
	}
	// 83155B90: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155B94: 388B56E0  addi r4, r11, 0x56e0
	ctx.r[4].s64 = ctx.r[11].s64 + 22240;
	// 83155B98: 48009F81  bl 0x8315fb18
	ctx.lr = 0x83155B9C;
	sub_8315FB18(ctx, base);
	// 83155B9C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155BA0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155BA4: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155BA8: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83155BAC: 4E800421  bctrl
	ctx.lr = 0x83155BB0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83155BB0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155BB4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83155BB8: 48052600  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83155BBC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155BC0: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 83155BC4: 388B56D4  addi r4, r11, 0x56d4
	ctx.r[4].s64 = ctx.r[11].s64 + 22228;
	// 83155BC8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155BCC: 48009F75  bl 0x8315fb40
	ctx.lr = 0x83155BD0;
	sub_8315FB40(ctx, base);
	// 83155BD0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155BD4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83155BD8: 480525E0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83155BDC: FBDF00B8  std r30, 0xb8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(184 as u32), ctx.r[30].u64 ) };
	// 83155BE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155BE4: 9BDF00C4  stb r30, 0xc4(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(196 as u32), ctx.r[30].u8 ) };
	// 83155BE8: 93DF01C4  stw r30, 0x1c4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(452 as u32), ctx.r[30].u32 ) };
	// 83155BEC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83155BF0: 480525C8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155BF8 size=76
    let mut pc: u32 = 0x83155BF8;
    'dispatch: loop {
        match pc {
            0x83155BF8 => {
    //   block [0x83155BF8..0x83155C44)
	// 83155BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155BFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155C00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155C04: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155C08: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155C0C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155C10: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83155C14: 392B562C  addi r9, r11, 0x562c
	ctx.r[9].s64 = ctx.r[11].s64 + 22060;
	// 83155C18: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83155C1C: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155C20: 419A0010  beq cr6, 0x83155c30
	if ctx.cr[6].eq {
	pc = 0x83155C30; continue 'dispatch;
	}
	// 83155C24: 388001C8  li r4, 0x1c8
	ctx.r[4].s64 = 456;
	// 83155C28: 4800A059  bl 0x8315fc80
	ctx.lr = 0x83155C2C;
	sub_8315FC80(ctx, base);
	// 83155C2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155C30: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155C34: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155C38: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155C3C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155C40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155C48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155C48 size=84
    let mut pc: u32 = 0x83155C48;
    'dispatch: loop {
        match pc {
            0x83155C48 => {
    //   block [0x83155C48..0x83155C9C)
	// 83155C48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155C4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155C50: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155C54: 81630014  lwz r11, 0x14(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 83155C58: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83155C5C: 419A002C  beq cr6, 0x83155c88
	if ctx.cr[6].eq {
	pc = 0x83155C88; continue 'dispatch;
	}
	// 83155C60: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 83155C64: 419A0024  beq cr6, 0x83155c88
	if ctx.cr[6].eq {
	pc = 0x83155C88; continue 'dispatch;
	}
	// 83155C68: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 83155C6C: 419A001C  beq cr6, 0x83155c88
	if ctx.cr[6].eq {
	pc = 0x83155C88; continue 'dispatch;
	}
	// 83155C70: 4BFFFAF1  bl 0x83155760
	ctx.lr = 0x83155C74;
	sub_83155760(ctx, base);
	// 83155C74: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155C78: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155C7C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155C80: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155C84: 4E800020  blr
	return;
	// 83155C88: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83155C8C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155C90: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155C94: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155C98: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155CA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155CA0 size=76
    let mut pc: u32 = 0x83155CA0;
    'dispatch: loop {
        match pc {
            0x83155CA0 => {
    //   block [0x83155CA0..0x83155CEC)
	// 83155CA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155CA4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155CA8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155CAC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155CB0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155CB4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155CB8: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83155CBC: 392B5674  addi r9, r11, 0x5674
	ctx.r[9].s64 = ctx.r[11].s64 + 22132;
	// 83155CC0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83155CC4: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155CC8: 419A0010  beq cr6, 0x83155cd8
	if ctx.cr[6].eq {
	pc = 0x83155CD8; continue 'dispatch;
	}
	// 83155CCC: 38800030  li r4, 0x30
	ctx.r[4].s64 = 48;
	// 83155CD0: 48009FB1  bl 0x8315fc80
	ctx.lr = 0x83155CD4;
	sub_8315FC80(ctx, base);
	// 83155CD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155CD8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155CDC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155CE0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155CE4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155CE8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155CF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83155CF0 size=252
    let mut pc: u32 = 0x83155CF0;
    'dispatch: loop {
        match pc {
            0x83155CF0 => {
    //   block [0x83155CF0..0x83155DEC)
	// 83155CF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155CF4: 4805246D  bl 0x831a8160
	ctx.lr = 0x83155CF8;
	sub_831A8130(ctx, base);
	// 83155CF8: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155CFC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83155D00: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 83155D04: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 83155D08: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155D0C: 91210054  stw r9, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[9].u32 ) };
	// 83155D10: 7C9A2378  mr r26, r4
	ctx.r[26].u64 = ctx.r[4].u64;
	// 83155D14: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 83155D18: 38A00006  li r5, 6
	ctx.r[5].s64 = 6;
	// 83155D1C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83155D20: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155D24: 806A0004  lwz r3, 4(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155D28: 4800BC21  bl 0x83161948
	ctx.lr = 0x83155D2C;
	sub_83161948(ctx, base);
	// 83155D2C: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 83155D30: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155D34: 409A0024  bne cr6, 0x83155d58
	if !ctx.cr[6].eq {
	pc = 0x83155D58; continue 'dispatch;
	}
	// 83155D38: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155D3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155D40: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83155D44: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83155D48: 4E800421  bctrl
	ctx.lr = 0x83155D4C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83155D4C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155D50: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 83155D54: 4805245C  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 83155D58: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155D5C: 83DF002C  lwz r30, 0x2c(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) } as u64;
	// 83155D60: 83BF000C  lwz r29, 0xc(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83155D64: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 83155D68: 837A0010  lwz r27, 0x10(r26)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(16 as u32) ) } as u64;
	// 83155D6C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83155D70: 838B001C  lwz r28, 0x1c(r11)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 83155D74: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 83155D78: 4BFF6B39  bl 0x8314c8b0
	ctx.lr = 0x83155D7C;
	sub_8314C8B0(ctx, base);
	// 83155D7C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155D80: 409A001C  bne cr6, 0x83155d9c
	if !ctx.cr[6].eq {
	pc = 0x83155D9C; continue 'dispatch;
	}
	// 83155D84: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 83155D88: 80FF0008  lwz r7, 8(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 83155D8C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 83155D90: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 83155D94: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 83155D98: 4BFF6CB1  bl 0x8314ca48
	ctx.lr = 0x83155D9C;
	sub_8314CA48(ctx, base);
	// 83155D9C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155DA0: 907F0020  stw r3, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 83155DA4: 419AFF94  beq cr6, 0x83155d38
	if ctx.cr[6].eq {
	pc = 0x83155D38; continue 'dispatch;
	}
	// 83155DA8: C03F0010  lfs f1, 0x10(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 83155DAC: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83155DB0: 4BFF60F1  bl 0x8314bea0
	ctx.lr = 0x83155DB4;
	sub_8314BEA0(ctx, base);
	// 83155DB4: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83155DB8: 93EB0030  stw r31, 0x30(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(48 as u32), ctx.r[31].u32 ) };
	// 83155DBC: 809F002C  lwz r4, 0x2c(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) } as u64;
	// 83155DC0: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83155DC4: 4BFF61C5  bl 0x8314bf88
	ctx.lr = 0x83155DC8;
	sub_8314BF88(ctx, base);
	// 83155DC8: 809F0008  lwz r4, 8(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 83155DCC: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83155DD0: 4BE8BF01  bl 0x82fe1cd0
	ctx.lr = 0x83155DD4;
	sub_82FE1CD0(ctx, base);
	// 83155DD4: 809A0018  lwz r4, 0x18(r26)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(24 as u32) ) } as u64;
	// 83155DD8: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83155DDC: 4BFF61DD  bl 0x8314bfb8
	ctx.lr = 0x83155DE0;
	sub_8314BFB8(ctx, base);
	// 83155DE0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83155DE4: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 83155DE8: 480523C8  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155DF0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155DF0 size=100
    let mut pc: u32 = 0x83155DF0;
    'dispatch: loop {
        match pc {
            0x83155DF0 => {
    //   block [0x83155DF0..0x83155E54)
	// 83155DF0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155DF4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155DF8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83155DFC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155E00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155E04: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155E08: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83155E0C: 809F0020  lwz r4, 0x20(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83155E10: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 83155E14: 419A0014  beq cr6, 0x83155e28
	if ctx.cr[6].eq {
	pc = 0x83155E28; continue 'dispatch;
	}
	// 83155E18: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155E1C: 806B001C  lwz r3, 0x1c(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 83155E20: 4BFF6B69  bl 0x8314c988
	ctx.lr = 0x83155E24;
	sub_8314C988(ctx, base);
	// 83155E24: 93DF0020  stw r30, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[30].u32 ) };
	// 83155E28: 807F0018  lwz r3, 0x18(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 83155E2C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155E30: 419A000C  beq cr6, 0x83155e3c
	if ctx.cr[6].eq {
	pc = 0x83155E3C; continue 'dispatch;
	}
	// 83155E34: 4800BD15  bl 0x83161b48
	ctx.lr = 0x83155E38;
	sub_83161B48(ctx, base);
	// 83155E38: 93DF0018  stw r30, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 83155E3C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83155E40: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155E44: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155E48: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83155E4C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155E50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155E58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155E58 size=76
    let mut pc: u32 = 0x83155E58;
    'dispatch: loop {
        match pc {
            0x83155E58 => {
    //   block [0x83155E58..0x83155EA4)
	// 83155E58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155E5C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155E60: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155E64: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155E68: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155E6C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155E70: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83155E74: 392B5674  addi r9, r11, 0x5674
	ctx.r[9].s64 = ctx.r[11].s64 + 22132;
	// 83155E78: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83155E7C: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155E80: 419A0010  beq cr6, 0x83155e90
	if ctx.cr[6].eq {
	pc = 0x83155E90; continue 'dispatch;
	}
	// 83155E84: 38800038  li r4, 0x38
	ctx.r[4].s64 = 56;
	// 83155E88: 48009DF9  bl 0x8315fc80
	ctx.lr = 0x83155E8C;
	sub_8315FC80(ctx, base);
	// 83155E8C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155E90: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155E94: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155E98: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155E9C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155EA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155EA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155EA8 size=100
    let mut pc: u32 = 0x83155EA8;
    'dispatch: loop {
        match pc {
            0x83155EA8 => {
    //   block [0x83155EA8..0x83155F0C)
	// 83155EA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155EAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155EB0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155EB4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155EB8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155EBC: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155EC0: 809F0018  lwz r4, 0x18(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 83155EC4: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155EC8: 4BFFFB49  bl 0x83155a10
	ctx.lr = 0x83155ECC;
	sub_83155A10(ctx, base);
	// 83155ECC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83155ED0: 409A0018  bne cr6, 0x83155ee8
	if !ctx.cr[6].eq {
	pc = 0x83155EE8; continue 'dispatch;
	}
	// 83155ED4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155ED8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155EDC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155EE0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155EE4: 4E800020  blr
	return;
	// 83155EE8: 817F0034  lwz r11, 0x34(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) } as u64;
	// 83155EEC: 815F0030  lwz r10, 0x30(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 83155EF0: 91630044  stw r11, 0x44(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 83155EF4: 91430040  stw r10, 0x40(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(64 as u32), ctx.r[10].u32 ) };
	// 83155EF8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155EFC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155F00: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155F04: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155F08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155F10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83155F10 size=76
    let mut pc: u32 = 0x83155F10;
    'dispatch: loop {
        match pc {
            0x83155F10 => {
    //   block [0x83155F10..0x83155F5C)
	// 83155F10: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155F14: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155F18: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155F1C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155F20: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155F24: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155F28: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83155F2C: 392B5674  addi r9, r11, 0x5674
	ctx.r[9].s64 = ctx.r[11].s64 + 22132;
	// 83155F30: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83155F34: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83155F38: 419A0010  beq cr6, 0x83155f48
	if ctx.cr[6].eq {
	pc = 0x83155F48; continue 'dispatch;
	}
	// 83155F3C: 38800040  li r4, 0x40
	ctx.r[4].s64 = 64;
	// 83155F40: 48009D41  bl 0x8315fc80
	ctx.lr = 0x83155F44;
	sub_8315FC80(ctx, base);
	// 83155F44: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83155F48: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83155F4C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83155F50: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83155F54: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83155F58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83155F60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83155F60 size=324
    let mut pc: u32 = 0x83155F60;
    'dispatch: loop {
        match pc {
            0x83155F60 => {
    //   block [0x83155F60..0x831560A4)
	// 83155F60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83155F64: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83155F68: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83155F6C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83155F70: 9421FE90  stwu r1, -0x170(r1)
	ea = ctx.r[1].u32.wrapping_add(-368 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83155F74: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83155F78: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155F7C: 809F0018  lwz r4, 0x18(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 83155F80: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83155F84: 4BFFFB85  bl 0x83155b08
	ctx.lr = 0x83155F88;
	sub_83155B08(ctx, base);
	// 83155F88: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83155F8C: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 83155F90: 419A007C  beq cr6, 0x8315600c
	if ctx.cr[6].eq {
	pc = 0x8315600C; continue 'dispatch;
	}
	// 83155F94: 817F0034  lwz r11, 0x34(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) } as u64;
	// 83155F98: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 83155F9C: 892A0000  lbz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155FA0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 83155FA4: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 83155FA8: 409AFFF4  bne cr6, 0x83155f9c
	if !ctx.cr[6].eq {
	pc = 0x83155F9C; continue 'dispatch;
	}
	// 83155FAC: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 83155FB0: 813F0038  lwz r9, 0x38(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 83155FB4: 390AFFFF  addi r8, r10, -1
	ctx.r[8].s64 = ctx.r[10].s64 + -1;
	// 83155FB8: 7D2A4B78  mr r10, r9
	ctx.r[10].u64 = ctx.r[9].u64;
	// 83155FBC: 5508003E  slwi r8, r8, 0
	ctx.r[8].u32 = ctx.r[8].u32.wrapping_shl(0);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 83155FC0: 88EA0000  lbz r7, 0(r10)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155FC4: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 83155FC8: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 83155FCC: 409AFFF4  bne cr6, 0x83155fc0
	if !ctx.cr[6].eq {
	pc = 0x83155FC0; continue 'dispatch;
	}
	// 83155FD0: 7D495050  subf r10, r9, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[9].s64;
	// 83155FD4: 394AFFFF  addi r10, r10, -1
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	// 83155FD8: 554A003E  slwi r10, r10, 0
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83155FDC: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 83155FE0: 2F0800FF  cmpwi cr6, r8, 0xff
	ctx.cr[6].compare_i32(ctx.r[8].s32, 255, &mut ctx.xer);
	// 83155FE4: 40990030  ble cr6, 0x83156014
	if !ctx.cr[6].gt {
	pc = 0x83156014; continue 'dispatch;
	}
	// 83155FE8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83155FEC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83155FF0: 388B571C  addi r4, r11, 0x571c
	ctx.r[4].s64 = ctx.r[11].s64 + 22300;
	// 83155FF4: 48009B25  bl 0x8315fb18
	ctx.lr = 0x83155FF8;
	sub_8315FB18(ctx, base);
	// 83155FF8: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83155FFC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156000: 812A0000  lwz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156004: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156008: 4E800421  bctrl
	ctx.lr = 0x8315600C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315600C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156010: 4800007C  b 0x8315608c
	pc = 0x8315608C; continue 'dispatch;
	// 83156014: 39410050  addi r10, r1, 0x50
	ctx.r[10].s64 = ctx.r[1].s64 + 80;
	// 83156018: 7D4B5050  subf r10, r11, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 8315601C: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156020: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 83156024: 7D0A59AE  stbx r8, r10, r11
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32), ctx.r[8].u8) };
	// 83156028: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315602C: 409AFFF0  bne cr6, 0x8315601c
	if !ctx.cr[6].eq {
	pc = 0x8315601C; continue 'dispatch;
	}
	// 83156030: 39610050  addi r11, r1, 0x50
	ctx.r[11].s64 = ctx.r[1].s64 + 80;
	// 83156034: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156038: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315603C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83156040: 409AFFF4  bne cr6, 0x83156034
	if !ctx.cr[6].eq {
	pc = 0x83156034; continue 'dispatch;
	}
	// 83156044: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 83156048: 89490000  lbz r10, 0(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315604C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 83156050: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83156054: 994B0000  stb r10, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 83156058: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315605C: 409AFFEC  bne cr6, 0x83156048
	if !ctx.cr[6].eq {
	pc = 0x83156048; continue 'dispatch;
	}
	// 83156060: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 83156064: 809F0030  lwz r4, 0x30(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 83156068: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315606C: 4BFFF015  bl 0x83155080
	ctx.lr = 0x83156070;
	sub_83155080(ctx, base);
	// 83156070: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156074: C03F003C  lfs f1, 0x3c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 83156078: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315607C: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156080: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156084: 4E800421  bctrl
	ctx.lr = 0x83156088;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156088: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315608C: 38210170  addi r1, r1, 0x170
	ctx.r[1].s64 = ctx.r[1].s64 + 368;
	// 83156090: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156094: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156098: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315609C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831560A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831560A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831560A8 size=292
    let mut pc: u32 = 0x831560A8;
    'dispatch: loop {
        match pc {
            0x831560A8 => {
    //   block [0x831560A8..0x831561CC)
	// 831560A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831560AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831560B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831560B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831560B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831560BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831560C0: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 831560C4: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831560C8: 38CA575C  addi r6, r10, 0x575c
	ctx.r[6].s64 = ctx.r[10].s64 + 22364;
	// 831560CC: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831560D0: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831560D4: 38600038  li r3, 0x38
	ctx.r[3].s64 = 56;
	// 831560D8: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831560DC: 48009B3D  bl 0x8315fc18
	ctx.lr = 0x831560E0;
	sub_8315FC18(ctx, base);
	// 831560E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831560E4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831560E8: 419A00AC  beq cr6, 0x83156194
	if ctx.cr[6].eq {
	pc = 0x83156194; continue 'dispatch;
	}
	// 831560EC: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 831560F0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831560F4: 392A5674  addi r9, r10, 0x5674
	ctx.r[9].s64 = ctx.r[10].s64 + 22132;
	// 831560F8: 3D008219  lis r8, -0x7de7
	ctx.r[8].s64 = -2112290816;
	// 831560FC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156100: 80FE0000  lwz r7, 0(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156104: 38C8568C  addi r6, r8, 0x568c
	ctx.r[6].s64 = ctx.r[8].s64 + 22156;
	// 83156108: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 8315610C: 80BE0004  lwz r5, 4(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156110: 90BF0008  stw r5, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 83156114: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156118: 909F000C  stw r4, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 8315611C: C01E000C  lfs f0, 0xc(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156120: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 83156124: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 83156128: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8315612C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83156130: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 83156134: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 83156138: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8315613C: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 83156140: 807E0014  lwz r3, 0x14(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 83156144: 907F002C  stw r3, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[3].u32 ) };
	// 83156148: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315614C: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 83156150: 817E001C  lwz r11, 0x1c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) } as u64;
	// 83156154: 917F0030  stw r11, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[11].u32 ) };
	// 83156158: 815E0020  lwz r10, 0x20(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315615C: 915F0034  stw r10, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[10].u32 ) };
	// 83156160: 4BFFFB91  bl 0x83155cf0
	ctx.lr = 0x83156164;
	sub_83155CF0(ctx, base);
	// 83156164: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83156168: 419A0048  beq cr6, 0x831561b0
	if ctx.cr[6].eq {
	pc = 0x831561B0; continue 'dispatch;
	}
	// 8315616C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 83156170: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 83156174: 4BFF5E25  bl 0x8314bf98
	ctx.lr = 0x83156178;
	sub_8314BF98(ctx, base);
	// 83156178: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315617C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83156180: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156184: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156188: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315618C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83156190: 4E800020  blr
	return;
	// 83156194: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83156198: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 8315619C: 388B5750  addi r4, r11, 0x5750
	ctx.r[4].s64 = ctx.r[11].s64 + 22352;
	// 831561A0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831561A4: 4800999D  bl 0x8315fb40
	ctx.lr = 0x831561A8;
	sub_8315FB40(ctx, base);
	// 831561A8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831561AC: 4BFFFFD0  b 0x8315617c
	pc = 0x8315617C; continue 'dispatch;
	// 831561B0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831561B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831561B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831561BC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831561C0: 4E800421  bctrl
	ctx.lr = 0x831561C4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831561C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831561C8: 4BFFFFB4  b 0x8315617c
	pc = 0x8315617C; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831561D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831561D0 size=308
    let mut pc: u32 = 0x831561D0;
    'dispatch: loop {
        match pc {
            0x831561D0 => {
    //   block [0x831561D0..0x83156304)
	// 831561D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831561D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831561D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831561DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831561E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831561E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831561E8: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 831561EC: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 831561F0: 38CA5774  addi r6, r10, 0x5774
	ctx.r[6].s64 = ctx.r[10].s64 + 22388;
	// 831561F4: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 831561F8: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831561FC: 38600040  li r3, 0x40
	ctx.r[3].s64 = 64;
	// 83156200: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156204: 48009A15  bl 0x8315fc18
	ctx.lr = 0x83156208;
	sub_8315FC18(ctx, base);
	// 83156208: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315620C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83156210: 419A00BC  beq cr6, 0x831562cc
	if ctx.cr[6].eq {
	pc = 0x831562CC; continue 'dispatch;
	}
	// 83156214: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 83156218: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315621C: 392A5674  addi r9, r10, 0x5674
	ctx.r[9].s64 = ctx.r[10].s64 + 22132;
	// 83156220: 3D008219  lis r8, -0x7de7
	ctx.r[8].s64 = -2112290816;
	// 83156224: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156228: 80FE0000  lwz r7, 0(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315622C: 38C856A4  addi r6, r8, 0x56a4
	ctx.r[6].s64 = ctx.r[8].s64 + 22180;
	// 83156230: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 83156234: 80BE0004  lwz r5, 4(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156238: 90BF0008  stw r5, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 8315623C: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156240: 909F000C  stw r4, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 83156244: C01E000C  lfs f0, 0xc(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156248: D01F0010  stfs f0, 0x10(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8315624C: 917F0014  stw r11, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 83156250: 917F0018  stw r11, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 83156254: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83156258: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8315625C: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 83156260: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 83156264: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 83156268: 807E0014  lwz r3, 0x14(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315626C: 907F002C  stw r3, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[3].u32 ) };
	// 83156270: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156274: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 83156278: 817E0020  lwz r11, 0x20(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315627C: 917F0030  stw r11, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[11].u32 ) };
	// 83156280: 815E0024  lwz r10, 0x24(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(36 as u32) ) } as u64;
	// 83156284: 915F0034  stw r10, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[10].u32 ) };
	// 83156288: 813E0028  lwz r9, 0x28(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315628C: 913F0038  stw r9, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[9].u32 ) };
	// 83156290: C1BE001C  lfs f13, 0x1c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(28 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156294: D1BF003C  stfs f13, 0x3c(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), tmp.u32 ) };
	// 83156298: 4BFFFA59  bl 0x83155cf0
	ctx.lr = 0x8315629C;
	sub_83155CF0(ctx, base);
	// 8315629C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831562A0: 419A0048  beq cr6, 0x831562e8
	if ctx.cr[6].eq {
	pc = 0x831562E8; continue 'dispatch;
	}
	// 831562A4: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831562A8: 807F0020  lwz r3, 0x20(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 831562AC: 4BFF5CED  bl 0x8314bf98
	ctx.lr = 0x831562B0;
	sub_8314BF98(ctx, base);
	// 831562B0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831562B4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831562B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831562BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831562C0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831562C4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831562C8: 4E800020  blr
	return;
	// 831562CC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831562D0: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 831562D4: 388B5768  addi r4, r11, 0x5768
	ctx.r[4].s64 = ctx.r[11].s64 + 22376;
	// 831562D8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831562DC: 48009865  bl 0x8315fb40
	ctx.lr = 0x831562E0;
	sub_8315FB40(ctx, base);
	// 831562E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831562E4: 4BFFFFD0  b 0x831562b4
	pc = 0x831562B4; continue 'dispatch;
	// 831562E8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831562EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831562F0: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831562F4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831562F8: 4E800421  bctrl
	ctx.lr = 0x831562FC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831562FC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156300: 4BFFFFB4  b 0x831562b4
	pc = 0x831562B4; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156308(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156308 size=4
    let mut pc: u32 = 0x83156308;
    'dispatch: loop {
        match pc {
            0x83156308 => {
    //   block [0x83156308..0x8315630C)
	// 83156308: 480559C0  b 0x831abcc8
	sub_831ABCC8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156310(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156310 size=20
    let mut pc: u32 = 0x83156310;
    'dispatch: loop {
        match pc {
            0x83156310 => {
    //   block [0x83156310..0x83156324)
	// 83156310: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 83156314: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 83156318: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315631C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83156320: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156324(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156324 size=12
    let mut pc: u32 = 0x83156324;
    'dispatch: loop {
        match pc {
            0x83156324 => {
    //   block [0x83156324..0x83156330)
	// 83156324: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156328: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315632C: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156330(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156330 size=4
    let mut pc: u32 = 0x83156330;
    'dispatch: loop {
        match pc {
            0x83156330 => {
    //   block [0x83156330..0x83156334)
	// 83156330: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156338(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83156338 size=136
    let mut pc: u32 = 0x83156338;
    'dispatch: loop {
        match pc {
            0x83156338 => {
    //   block [0x83156338..0x831563C0)
	// 83156338: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315633C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83156340: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83156344: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156348: 3D008339  lis r8, -0x7cc7
	ctx.r[8].s64 = -2093416448;
	// 8315634C: 81687F58  lwz r11, 0x7f58(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(32600 as u32) ) } as u64;
	// 83156350: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 83156354: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83156358: 409A004C  bne cr6, 0x831563a4
	if !ctx.cr[6].eq {
	pc = 0x831563A4; continue 'dispatch;
	}
	// 8315635C: 3CE08339  lis r7, -0x7cc7
	ctx.r[7].s64 = -2093416448;
	// 83156360: 3D408315  lis r10, -0x7ceb
	ctx.r[10].s64 = -2095775744;
	// 83156364: 3BE77F50  addi r31, r7, 0x7f50
	ctx.r[31].s64 = ctx.r[7].s64 + 32592;
	// 83156368: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 8315636C: 394A6308  addi r10, r10, 0x6308
	ctx.r[10].s64 = ctx.r[10].s64 + 25352;
	// 83156370: 39207FFF  li r9, 0x7fff
	ctx.r[9].s64 = 32767;
	// 83156374: 91687F58  stw r11, 0x7f58(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(32600 as u32), ctx.r[11].u32 ) };
	// 83156378: 91477F50  stw r10, 0x7f50(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(32592 as u32), ctx.r[10].u32 ) };
	// 8315637C: 3CC08324  lis r6, -0x7cdc
	ctx.r[6].s64 = -2094792704;
	// 83156380: 913F0004  stw r9, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 83156384: 38662538  addi r3, r6, 0x2538
	ctx.r[3].s64 = ctx.r[6].s64 + 9528;
	// 83156388: 48052151  bl 0x831a84d8
	ctx.lr = 0x8315638C;
	sub_831A84D8(ctx, base);
	// 8315638C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156390: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83156394: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156398: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315639C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831563A0: 4E800020  blr
	return;
	// 831563A4: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 831563A8: 386B7F50  addi r3, r11, 0x7f50
	ctx.r[3].s64 = ctx.r[11].s64 + 32592;
	// 831563AC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831563B0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831563B4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831563B8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831563BC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831563C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831563C0 size=128
    let mut pc: u32 = 0x831563C0;
    'dispatch: loop {
        match pc {
            0x831563C0 => {
    //   block [0x831563C0..0x83156440)
	// 831563C0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831563C4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831563C8: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831563CC: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831563D0: 3D208339  lis r9, -0x7cc7
	ctx.r[9].s64 = -2093416448;
	// 831563D4: 81697F64  lwz r11, 0x7f64(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(32612 as u32) ) } as u64;
	// 831563D8: 556A07FE  clrlwi r10, r11, 0x1f
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0x00000001u64;
	// 831563DC: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831563E0: 409A0044  bne cr6, 0x83156424
	if !ctx.cr[6].eq {
	pc = 0x83156424; continue 'dispatch;
	}
	// 831563E4: 3D008339  lis r8, -0x7cc7
	ctx.r[8].s64 = -2093416448;
	// 831563E8: 616B0001  ori r11, r11, 1
	ctx.r[11].u64 = ctx.r[11].u64 | 1;
	// 831563EC: 3BE87F5C  addi r31, r8, 0x7f5c
	ctx.r[31].s64 = ctx.r[8].s64 + 32604;
	// 831563F0: 91697F64  stw r11, 0x7f64(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(32612 as u32), ctx.r[11].u32 ) };
	// 831563F4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831563F8: 3CE08324  lis r7, -0x7cdc
	ctx.r[7].s64 = -2094792704;
	// 831563FC: 91487F5C  stw r10, 0x7f5c(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(32604 as u32), ctx.r[10].u32 ) };
	// 83156400: 38672540  addi r3, r7, 0x2540
	ctx.r[3].s64 = ctx.r[7].s64 + 9536;
	// 83156404: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 83156408: 480520D1  bl 0x831a84d8
	ctx.lr = 0x8315640C;
	sub_831A84D8(ctx, base);
	// 8315640C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156410: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83156414: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156418: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315641C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83156420: 4E800020  blr
	return;
	// 83156424: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 83156428: 386B7F5C  addi r3, r11, 0x7f5c
	ctx.r[3].s64 = ctx.r[11].s64 + 32604;
	// 8315642C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83156430: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156434: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156438: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315643C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156440(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83156440 size=100
    let mut pc: u32 = 0x83156440;
    'dispatch: loop {
        match pc {
            0x83156440 => {
    //   block [0x83156440..0x831564A4)
	// 83156440: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156444: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83156448: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315644C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83156450: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156454: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156458: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315645C: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83156460: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156464: 4E800421  bctrl
	ctx.lr = 0x83156468;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156468: 807F001C  lwz r3, 0x1c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315646C: 4BFF67F5  bl 0x8314cc60
	ctx.lr = 0x83156470;
	sub_8314CC60(ctx, base);
	// 83156470: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156474: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83156478: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315647C: 81090010  lwz r8, 0x10(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) } as u64;
	// 83156480: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 83156484: 4E800421  bctrl
	ctx.lr = 0x83156488;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156488: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315648C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83156490: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156494: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156498: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315649C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831564A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831564A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831564A8 size=108
    let mut pc: u32 = 0x831564A8;
    'dispatch: loop {
        match pc {
            0x831564A8 => {
    //   block [0x831564A8..0x83156514)
	// 831564A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831564AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831564B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831564B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831564B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831564BC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831564C0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831564C4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831564C8: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 831564CC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831564D0: 4E800421  bctrl
	ctx.lr = 0x831564D4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831564D4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831564D8: 807F001C  lwz r3, 0x1c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 831564DC: 4BFF6855  bl 0x8314cd30
	ctx.lr = 0x831564E0;
	sub_8314CD30(ctx, base);
	// 831564E0: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831564E4: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 831564E8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831564EC: 81090010  lwz r8, 0x10(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(16 as u32) ) } as u64;
	// 831564F0: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 831564F4: 4E800421  bctrl
	ctx.lr = 0x831564F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831564F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831564FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83156500: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156504: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156508: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315650C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83156510: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156518(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83156518 size=80
    let mut pc: u32 = 0x83156518;
    'dispatch: loop {
        match pc {
            0x83156518 => {
    //   block [0x83156518..0x83156568)
	// 83156518: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315651C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83156520: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83156524: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156528: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315652C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156530: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156534: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156538: 4E800421  bctrl
	ctx.lr = 0x8315653C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315653C: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156540: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83156544: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156548: 8109002C  lwz r8, 0x2c(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(44 as u32) ) } as u64;
	// 8315654C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 83156550: 4E800421  bctrl
	ctx.lr = 0x83156554;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156554: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83156558: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315655C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156560: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83156564: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156568(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83156568 size=964
    let mut pc: u32 = 0x83156568;
    'dispatch: loop {
        match pc {
            0x83156568 => {
    //   block [0x83156568..0x8315692C)
	// 83156568: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315656C: 48051BFD  bl 0x831a8168
	ctx.lr = 0x83156570;
	sub_831A8130(ctx, base);
	// 83156570: 9421FE00  stwu r1, -0x200(r1)
	ea = ctx.r[1].u32.wrapping_add(-512 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156574: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 83156578: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 8315657C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156580: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 83156584: 395F0408  addi r10, r31, 0x408
	ctx.r[10].s64 = ctx.r[31].s64 + 1032;
	// 83156588: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315658C: C00808A8  lfs f0, 0x8a8(r8)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156590: C1AB0018  lfs f13, 0x18(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156594: D1BF03F8  stfs f13, 0x3f8(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1016 as u32), tmp.u32 ) };
	// 83156598: D01F03FC  stfs f0, 0x3fc(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1020 as u32), tmp.u32 ) };
	// 8315659C: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831565A0: C187001C  lfs f12, 0x1c(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(28 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831565A4: D19F0400  stfs f12, 0x400(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1024 as u32), tmp.u32 ) };
	// 831565A8: D01F0404  stfs f0, 0x404(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1028 as u32), tmp.u32 ) };
	// 831565AC: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831565B0: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 831565B4: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831565B8: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831565BC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831565C0: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831565C4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831565C8: 4200FFF0  bdnz 0x831565b8
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831565B8; continue 'dispatch;
	}
	// 831565CC: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831565D0: 395F047C  addi r10, r31, 0x47c
	ctx.r[10].s64 = ctx.r[31].s64 + 1148;
	// 831565D4: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 831565D8: 810B00D0  lwz r8, 0xd0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(208 as u32) ) } as u64;
	// 831565DC: 911F06BC  stw r8, 0x6bc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1724 as u32), ctx.r[8].u32 ) };
	// 831565E0: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831565E4: 80C700D4  lwz r6, 0xd4(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(212 as u32) ) } as u64;
	// 831565E8: 90DF06C0  stw r6, 0x6c0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1728 as u32), ctx.r[6].u32 ) };
	// 831565EC: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831565F0: 396B0090  addi r11, r11, 0x90
	ctx.r[11].s64 = ctx.r[11].s64 + 144;
	// 831565F4: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831565F8: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831565FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156600: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156604: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156608: 4200FFF0  bdnz 0x831565f8
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831565F8; continue 'dispatch;
	}
	// 8315660C: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156610: 395F049C  addi r10, r31, 0x49c
	ctx.r[10].s64 = ctx.r[31].s64 + 1180;
	// 83156614: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 83156618: 396B00B0  addi r11, r11, 0xb0
	ctx.r[11].s64 = ctx.r[11].s64 + 176;
	// 8315661C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156620: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156624: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156628: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8315662C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156630: 4200FFF0  bdnz 0x83156620
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156620; continue 'dispatch;
	}
	// 83156634: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156638: 395F06C4  addi r10, r31, 0x6c4
	ctx.r[10].s64 = ctx.r[31].s64 + 1732;
	// 8315663C: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 83156640: 810B0118  lwz r8, 0x118(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(280 as u32) ) } as u64;
	// 83156644: 911F0704  stw r8, 0x704(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1796 as u32), ctx.r[8].u32 ) };
	// 83156648: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315664C: 396B00D8  addi r11, r11, 0xd8
	ctx.r[11].s64 = ctx.r[11].s64 + 216;
	// 83156650: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156654: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156658: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315665C: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156660: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156664: 4200FFF0  bdnz 0x83156654
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156654; continue 'dispatch;
	}
	// 83156668: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315666C: 395F06E4  addi r10, r31, 0x6e4
	ctx.r[10].s64 = ctx.r[31].s64 + 1764;
	// 83156670: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 83156674: 396B00F8  addi r11, r11, 0xf8
	ctx.r[11].s64 = ctx.r[11].s64 + 248;
	// 83156678: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315667C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156680: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156684: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156688: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315668C: 4200FFF0  bdnz 0x8315667c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315667C; continue 'dispatch;
	}
	// 83156690: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156694: 395F0420  addi r10, r31, 0x420
	ctx.r[10].s64 = ctx.r[31].s64 + 1056;
	// 83156698: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 8315669C: 810B011C  lwz r8, 0x11c(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(284 as u32) ) } as u64;
	// 831566A0: 911F0708  stw r8, 0x708(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1800 as u32), ctx.r[8].u32 ) };
	// 831566A4: 80FE0008  lwz r7, 8(r30)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566A8: 80C70120  lwz r6, 0x120(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(288 as u32) ) } as u64;
	// 831566AC: 90DF070C  stw r6, 0x70c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1804 as u32), ctx.r[6].u32 ) };
	// 831566B0: 80BE0008  lwz r5, 8(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566B4: 80850124  lwz r4, 0x124(r5)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(292 as u32) ) } as u64;
	// 831566B8: 909F0710  stw r4, 0x710(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1808 as u32), ctx.r[4].u32 ) };
	// 831566BC: 807E0008  lwz r3, 8(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566C0: 81630128  lwz r11, 0x128(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(296 as u32) ) } as u64;
	// 831566C4: 917F0714  stw r11, 0x714(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1812 as u32), ctx.r[11].u32 ) };
	// 831566C8: 811E0008  lwz r8, 8(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566CC: 80E8012C  lwz r7, 0x12c(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(300 as u32) ) } as u64;
	// 831566D0: 90FF0718  stw r7, 0x718(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1816 as u32), ctx.r[7].u32 ) };
	// 831566D4: 80DE0008  lwz r6, 8(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566D8: 80A60130  lwz r5, 0x130(r6)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(304 as u32) ) } as u64;
	// 831566DC: 90BF071C  stw r5, 0x71c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1820 as u32), ctx.r[5].u32 ) };
	// 831566E0: 809E0008  lwz r4, 8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566E4: 80640134  lwz r3, 0x134(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(308 as u32) ) } as u64;
	// 831566E8: 907F0720  stw r3, 0x720(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1824 as u32), ctx.r[3].u32 ) };
	// 831566EC: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566F0: 810B0138  lwz r8, 0x138(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(312 as u32) ) } as u64;
	// 831566F4: 911F0724  stw r8, 0x724(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1828 as u32), ctx.r[8].u32 ) };
	// 831566F8: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831566FC: 396B0038  addi r11, r11, 0x38
	ctx.r[11].s64 = ctx.r[11].s64 + 56;
	// 83156700: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156704: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156708: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315670C: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156710: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156714: 4200FFF0  bdnz 0x83156704
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156704; continue 'dispatch;
	}
	// 83156718: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315671C: 395F0440  addi r10, r31, 0x440
	ctx.r[10].s64 = ctx.r[31].s64 + 1088;
	// 83156720: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 83156724: 396B0058  addi r11, r11, 0x58
	ctx.r[11].s64 = ctx.r[11].s64 + 88;
	// 83156728: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315672C: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156730: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156734: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156738: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315673C: 4200FFF0  bdnz 0x8315672c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315672C; continue 'dispatch;
	}
	// 83156740: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156744: 395F0460  addi r10, r31, 0x460
	ctx.r[10].s64 = ctx.r[31].s64 + 1120;
	// 83156748: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8315674C: 396B0078  addi r11, r11, 0x78
	ctx.r[11].s64 = ctx.r[11].s64 + 120;
	// 83156750: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156754: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156758: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315675C: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156760: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156764: 4200FFF0  bdnz 0x83156754
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156754; continue 'dispatch;
	}
	// 83156768: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315676C: 807E0004  lwz r3, 4(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156770: 808B007C  lwz r4, 0x7c(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(124 as u32) ) } as u64;
	// 83156774: 4BFED4CD  bl 0x83143c40
	ctx.lr = 0x83156778;
	sub_83143C40(ctx, base);
	// 83156778: 907F0474  stw r3, 0x474(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1140 as u32), ctx.r[3].u32 ) };
	// 8315677C: 395F0728  addi r10, r31, 0x728
	ctx.r[10].s64 = ctx.r[31].s64 + 1832;
	// 83156780: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156784: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 83156788: 396B013C  addi r11, r11, 0x13c
	ctx.r[11].s64 = ctx.r[11].s64 + 316;
	// 8315678C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156790: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156794: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156798: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8315679C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831567A0: 4200FFF0  bdnz 0x83156790
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156790; continue 'dispatch;
	}
	// 831567A4: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 831567A8: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 831567AC: 4BFF8F0D  bl 0x8314f6b8
	ctx.lr = 0x831567B0;
	sub_8314F6B8(ctx, base);
	// 831567B0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831567B4: 907F0764  stw r3, 0x764(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1892 as u32), ctx.r[3].u32 ) };
	// 831567B8: 409A0034  bne cr6, 0x831567ec
	if !ctx.cr[6].eq {
	pc = 0x831567EC; continue 'dispatch;
	}
	// 831567BC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831567C0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831567C4: 388B585C  addi r4, r11, 0x585c
	ctx.r[4].s64 = ctx.r[11].s64 + 22620;
	// 831567C8: 48009351  bl 0x8315fb18
	ctx.lr = 0x831567CC;
	sub_8315FB18(ctx, base);
	// 831567CC: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831567D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831567D4: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 831567D8: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831567DC: 4E800421  bctrl
	ctx.lr = 0x831567E0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831567E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831567E4: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 831567E8: 480519D0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831567EC: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 831567F0: 806B0010  lwz r3, 0x10(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831567F4: 4BFF7BB5  bl 0x8314e3a8
	ctx.lr = 0x831567F8;
	sub_8314E3A8(ctx, base);
	// 831567F8: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 831567FC: 2B1C0008  cmplwi cr6, r28, 8
	ctx.cr[6].compare_u32(ctx.r[28].u32, 8 as u32, &mut ctx.xer);
	// 83156800: 4099003C  ble cr6, 0x8315683c
	if !ctx.cr[6].gt {
	pc = 0x8315683C; continue 'dispatch;
	}
	// 83156804: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83156808: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8315680C: 388B5820  addi r4, r11, 0x5820
	ctx.r[4].s64 = ctx.r[11].s64 + 22560;
	// 83156810: 38A00008  li r5, 8
	ctx.r[5].s64 = 8;
	// 83156814: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156818: 48009321  bl 0x8315fb38
	ctx.lr = 0x8315681C;
	sub_8315FB38(ctx, base);
	// 8315681C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156820: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156824: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156828: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315682C: 4E800421  bctrl
	ctx.lr = 0x83156830;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156830: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156834: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 83156838: 48051980  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315683C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 83156840: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 83156844: 419A006C  beq cr6, 0x831568b0
	if ctx.cr[6].eq {
	pc = 0x831568B0; continue 'dispatch;
	}
	// 83156848: 817E0008  lwz r11, 8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315684C: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 83156850: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156854: 806B0010  lwz r3, 0x10(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 83156858: 4BFF7BD9  bl 0x8314e430
	ctx.lr = 0x8315685C;
	sub_8314E430(ctx, base);
	// 8315685C: 38A100D0  addi r5, r1, 0xd0
	ctx.r[5].s64 = ctx.r[1].s64 + 208;
	// 83156860: 38810150  addi r4, r1, 0x150
	ctx.r[4].s64 = ctx.r[1].s64 + 336;
	// 83156864: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 83156868: 4BFF7A79  bl 0x8314e2e0
	ctx.lr = 0x8315686C;
	sub_8314E2E0(ctx, base);
	// 8315686C: 388100D0  addi r4, r1, 0xd0
	ctx.r[4].s64 = ctx.r[1].s64 + 208;
	// 83156870: 807E0004  lwz r3, 4(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156874: 4BFED32D  bl 0x83143ba0
	ctx.lr = 0x83156878;
	sub_83143BA0(ctx, base);
	// 83156878: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8315687C: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 83156880: 419A0044  beq cr6, 0x831568c4
	if ctx.cr[6].eq {
	pc = 0x831568C4; continue 'dispatch;
	}
	// 83156884: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83156888: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315688C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156890: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156894: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156898: 4E800421  bctrl
	ctx.lr = 0x8315689C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315689C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831568A0: 419A0058  beq cr6, 0x831568f8
	if ctx.cr[6].eq {
	pc = 0x831568F8; continue 'dispatch;
	}
	// 831568A4: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831568A8: 7F1DE040  cmplw cr6, r29, r28
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[28].u32, &mut ctx.xer);
	// 831568AC: 4198FF9C  blt cr6, 0x83156848
	if ctx.cr[6].lt {
	pc = 0x83156848; continue 'dispatch;
	}
	// 831568B0: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 831568B4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831568B8: 917F0768  stw r11, 0x768(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1896 as u32), ctx.r[11].u32 ) };
	// 831568BC: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 831568C0: 480518F8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831568C4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831568C8: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 831568CC: 388B5800  addi r4, r11, 0x5800
	ctx.r[4].s64 = ctx.r[11].s64 + 22528;
	// 831568D0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831568D4: 48009255  bl 0x8315fb28
	ctx.lr = 0x831568D8;
	sub_8315FB28(ctx, base);
	// 831568D8: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831568DC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831568E0: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 831568E4: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831568E8: 4E800421  bctrl
	ctx.lr = 0x831568EC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831568EC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831568F0: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 831568F4: 480518C4  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 831568F8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831568FC: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 83156900: 388B57D4  addi r4, r11, 0x57d4
	ctx.r[4].s64 = ctx.r[11].s64 + 22484;
	// 83156904: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156908: 48009221  bl 0x8315fb28
	ctx.lr = 0x8315690C;
	sub_8315FB28(ctx, base);
	// 8315690C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156910: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156914: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156918: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315691C: 4E800421  bctrl
	ctx.lr = 0x83156920;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156920: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156924: 38210200  addi r1, r1, 0x200
	ctx.r[1].s64 = ctx.r[1].s64 + 512;
	// 83156928: 48051890  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156930(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83156930 size=192
    let mut pc: u32 = 0x83156930;
    'dispatch: loop {
        match pc {
            0x83156930 => {
    //   block [0x83156930..0x831569F0)
	// 83156930: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156934: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83156938: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315693C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83156940: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156944: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156948: 38A003A8  li r5, 0x3a8
	ctx.r[5].s64 = 936;
	// 8315694C: 3BDF0028  addi r30, r31, 0x28
	ctx.r[30].s64 = ctx.r[31].s64 + 40;
	// 83156950: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156954: 48051BBD  bl 0x831a8510
	ctx.lr = 0x83156958;
	sub_831A8510(ctx, base);
	// 83156958: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 8315695C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83156960: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156964: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 83156968: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315696C: 4E800421  bctrl
	ctx.lr = 0x83156970;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156970: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156974: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156978: 81090038  lwz r8, 0x38(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(56 as u32) ) } as u64;
	// 8315697C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 83156980: 4E800421  bctrl
	ctx.lr = 0x83156984;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156984: 80FF00D0  lwz r7, 0xd0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 83156988: 2F070001  cmpwi cr6, r7, 1
	ctx.cr[6].compare_i32(ctx.r[7].s32, 1, &mut ctx.xer);
	// 8315698C: 409A0048  bne cr6, 0x831569d4
	if !ctx.cr[6].eq {
	pc = 0x831569D4; continue 'dispatch;
	}
	// 83156990: 807F03B0  lwz r3, 0x3b0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(944 as u32) ) } as u64;
	// 83156994: 38810050  addi r4, r1, 0x50
	ctx.r[4].s64 = ctx.r[1].s64 + 80;
	// 83156998: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315699C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831569A0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831569A4: 4E800421  bctrl
	ctx.lr = 0x831569A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831569A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831569AC: 409A000C  bne cr6, 0x831569b8
	if !ctx.cr[6].eq {
	pc = 0x831569B8; continue 'dispatch;
	}
	// 831569B0: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 831569B4: 48000024  b 0x831569d8
	pc = 0x831569D8; continue 'dispatch;
	// 831569B8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 831569BC: C1BF039C  lfs f13, 0x39c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831569C0: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831569C4: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 831569C8: 419AFFE8  beq cr6, 0x831569b0
	if ctx.cr[6].eq {
	pc = 0x831569B0; continue 'dispatch;
	}
	// 831569CC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831569D0: 48000008  b 0x831569d8
	pc = 0x831569D8; continue 'dispatch;
	// 831569D4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831569D8: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831569DC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831569E0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831569E4: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 831569E8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831569EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831569F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831569F0 size=76
    let mut pc: u32 = 0x831569F0;
    'dispatch: loop {
        match pc {
            0x831569F0 => {
    //   block [0x831569F0..0x83156A3C)
	// 831569F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831569F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831569F8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831569FC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83156A00: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156A04: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 83156A08: 83C30760  lwz r30, 0x760(r3)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156A0C: 817F0388  lwz r11, 0x388(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(904 as u32) ) } as u64;
	// 83156A10: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 83156A14: 4BFE95AD  bl 0x8313ffc0
	ctx.lr = 0x83156A18;
	sub_8313FFC0(ctx, base);
	// 83156A18: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 83156A1C: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 83156A20: 4BFF93C1  bl 0x8314fde0
	ctx.lr = 0x83156A24;
	sub_8314FDE0(ctx, base);
	// 83156A24: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83156A28: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83156A2C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83156A30: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83156A34: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83156A38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156A40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156A40 size=20
    let mut pc: u32 = 0x83156A40;
    'dispatch: loop {
        match pc {
            0x83156A40 => {
    //   block [0x83156A40..0x83156A54)
	// 83156A40: 80630764  lwz r3, 0x764(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83156A44: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156A48: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 83156A4C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156A50: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156A58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156A58 size=20
    let mut pc: u32 = 0x83156A58;
    'dispatch: loop {
        match pc {
            0x83156A58 => {
    //   block [0x83156A58..0x83156A6C)
	// 83156A58: 80630764  lwz r3, 0x764(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83156A5C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156A60: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 83156A64: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156A68: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156A70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83156A70 size=20
    let mut pc: u32 = 0x83156A70;
    'dispatch: loop {
        match pc {
            0x83156A70 => {
    //   block [0x83156A70..0x83156A84)
	// 83156A70: 80630764  lwz r3, 0x764(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83156A74: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156A78: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 83156A7C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156A80: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156A88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83156A88 size=152
    let mut pc: u32 = 0x83156A88;
    'dispatch: loop {
        match pc {
            0x83156A88 => {
    //   block [0x83156A88..0x83156B20)
	// 83156A88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156A8C: 480516E1  bl 0x831a816c
	ctx.lr = 0x83156A90;
	sub_831A8130(ctx, base);
	// 83156A90: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156A94: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83156A98: 83BE03B0  lwz r29, 0x3b0(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(944 as u32) ) } as u64;
	// 83156A9C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83156AA0: 4BFE9511  bl 0x8313ffb0
	ctx.lr = 0x83156AA4;
	sub_8313FFB0(ctx, base);
	// 83156AA4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156AA8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83156AAC: 4BFE950D  bl 0x8313ffb8
	ctx.lr = 0x83156AB0;
	sub_8313FFB8(ctx, base);
	// 83156AB0: 817E076C  lwz r11, 0x76c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1900 as u32) ) } as u64;
	// 83156AB4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83156AB8: 419A004C  beq cr6, 0x83156b04
	if ctx.cr[6].eq {
	pc = 0x83156B04; continue 'dispatch;
	}
	// 83156ABC: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 83156AC0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83156AC4: 419A0040  beq cr6, 0x83156b04
	if ctx.cr[6].eq {
	pc = 0x83156B04; continue 'dispatch;
	}
	// 83156AC8: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 83156ACC: 7F0AF840  cmplw cr6, r10, r31
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[31].u32, &mut ctx.xer);
	// 83156AD0: 409A0010  bne cr6, 0x83156ae0
	if !ctx.cr[6].eq {
	pc = 0x83156AE0; continue 'dispatch;
	}
	// 83156AD4: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 83156AD8: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 83156ADC: 419A001C  beq cr6, 0x83156af8
	if ctx.cr[6].eq {
	pc = 0x83156AF8; continue 'dispatch;
	}
	// 83156AE0: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156AE4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83156AE8: 419A001C  beq cr6, 0x83156b04
	if ctx.cr[6].eq {
	pc = 0x83156B04; continue 'dispatch;
	}
	// 83156AEC: 356BFFFC  addic. r11, r11, -4
	ctx.xer.ca = (ctx.r[11].u32 > (!(-4 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83156AF0: 4082FFD8  bne 0x83156ac8
	if !ctx.cr[0].eq {
	pc = 0x83156AC8; continue 'dispatch;
	}
	// 83156AF4: 48000010  b 0x83156b04
	pc = 0x83156B04; continue 'dispatch;
	// 83156AF8: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 83156AFC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 83156B00: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 83156B04: 817E0768  lwz r11, 0x768(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1896 as u32) ) } as u64;
	// 83156B08: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83156B0C: 419A000C  beq cr6, 0x83156b18
	if ctx.cr[6].eq {
	pc = 0x83156B18; continue 'dispatch;
	}
	// 83156B10: 7D7E5B78  mr r30, r11
	ctx.r[30].u64 = ctx.r[11].u64;
	// 83156B14: 4BFFFF84  b 0x83156a98
	pc = 0x83156A98; continue 'dispatch;
	// 83156B18: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83156B1C: 480516A0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156B20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83156B20 size=620
    let mut pc: u32 = 0x83156B20;
    'dispatch: loop {
        match pc {
            0x83156B20 => {
    //   block [0x83156B20..0x83156CBC)
	// 83156B20: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156B24: 48051649  bl 0x831a816c
	ctx.lr = 0x83156B28;
	sub_831A8130(ctx, base);
	// 83156B28: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156B2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156B30: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 83156B34: 4BFFFA35  bl 0x83156568
	ctx.lr = 0x83156B38;
	sub_83156568(ctx, base);
	// 83156B38: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83156B3C: 409A0024  bne cr6, 0x83156b60
	if !ctx.cr[6].eq {
	pc = 0x83156B60; continue 'dispatch;
	}
	// 83156B40: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156B44: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156B48: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156B4C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83156B50: 4E800421  bctrl
	ctx.lr = 0x83156B54;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156B54: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156B58: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156B5C: 48051660  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83156B60: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156B64: 3D408200  lis r10, -0x7e00
	ctx.r[10].s64 = -2113929216;
	// 83156B68: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83156B6C: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 83156B70: C1AB0014  lfs f13, 0x14(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156B74: 93DF001C  stw r30, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[30].u32 ) };
	// 83156B78: C00A08A8  lfs f0, 0x8a8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156B7C: 93C10060  stw r30, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u32 ) };
	// 83156B80: D1BF03F0  stfs f13, 0x3f0(r31)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1008 as u32), tmp.u32 ) };
	// 83156B84: 93C10064  stw r30, 0x64(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(100 as u32), ctx.r[30].u32 ) };
	// 83156B88: D01F03F4  stfs f0, 0x3f4(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1012 as u32), tmp.u32 ) };
	// 83156B8C: 93C10068  stw r30, 0x68(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[30].u32 ) };
	// 83156B90: 93C10070  stw r30, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[30].u32 ) };
	// 83156B94: 9BC10074  stb r30, 0x74(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(116 as u32), ctx.r[30].u8 ) };
	// 83156B98: 9BC10075  stb r30, 0x75(r1)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[1].u32.wrapping_add(117 as u32), ctx.r[30].u8 ) };
	// 83156B9C: 93C10078  stw r30, 0x78(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[30].u32 ) };
	// 83156BA0: 813D0008  lwz r9, 8(r29)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156BA4: 807D0004  lwz r3, 4(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(4 as u32) ) } as u64;
	// 83156BA8: 8089000C  lwz r4, 0xc(r9)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 83156BAC: 4BFECDDD  bl 0x83143988
	ctx.lr = 0x83156BB0;
	sub_83143988(ctx, base);
	// 83156BB0: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83156BB4: 409A0018  bne cr6, 0x83156bcc
	if !ctx.cr[6].eq {
	pc = 0x83156BCC; continue 'dispatch;
	}
	// 83156BB8: 817D0008  lwz r11, 8(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156BBC: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 83156BC0: 388A5944  addi r4, r10, 0x5944
	ctx.r[4].s64 = ctx.r[10].s64 + 22852;
	// 83156BC4: 80AB000C  lwz r5, 0xc(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83156BC8: 4800019C  b 0x83156d64
	pc = 0x83156D64; continue 'dispatch;
	// 83156BCC: 8121006C  lwz r9, 0x6c(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 83156BD0: 80A10070  lwz r5, 0x70(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) } as u64;
	// 83156BD4: 2F090004  cmpwi cr6, r9, 4
	ctx.cr[6].compare_i32(ctx.r[9].s32, 4, &mut ctx.xer);
	// 83156BD8: 419A003C  beq cr6, 0x83156c14
	if ctx.cr[6].eq {
	pc = 0x83156C14; continue 'dispatch;
	}
	// 83156BDC: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 83156BE0: 409A0034  bne cr6, 0x83156c14
	if !ctx.cr[6].eq {
	pc = 0x83156C14; continue 'dispatch;
	}
	// 83156BE4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83156BE8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156BEC: 388B5908  addi r4, r11, 0x5908
	ctx.r[4].s64 = ctx.r[11].s64 + 22792;
	// 83156BF0: 48008F39  bl 0x8315fb28
	ctx.lr = 0x83156BF4;
	sub_8315FB28(ctx, base);
	// 83156BF4: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156BF8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156BFC: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156C00: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156C04: 4E800421  bctrl
	ctx.lr = 0x83156C08;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156C08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156C0C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156C10: 480515AC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83156C14: 89410074  lbz r10, 0x74(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(116 as u32) ) } as u64;
	// 83156C18: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 83156C1C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83156C20: 419A0138  beq cr6, 0x83156d58
	if ctx.cr[6].eq {
	pc = 0x83156D58; continue 'dispatch;
	}
	// 83156C24: 2B0B0008  cmplwi cr6, r11, 8
	ctx.cr[6].compare_u32(ctx.r[11].u32, 8 as u32, &mut ctx.xer);
	// 83156C28: 41990130  bgt cr6, 0x83156d58
	if ctx.cr[6].gt {
	pc = 0x83156D58; continue 'dispatch;
	}
	// 83156C2C: 88E10075  lbz r7, 0x75(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(117 as u32) ) } as u64;
	// 83156C30: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 83156C34: 2B070001  cmplwi cr6, r7, 1
	ctx.cr[6].compare_u32(ctx.r[7].u32, 1 as u32, &mut ctx.xer);
	// 83156C38: 409A0018  bne cr6, 0x83156c50
	if !ctx.cr[6].eq {
	pc = 0x83156C50; continue 'dispatch;
	}
	// 83156C3C: 917F03D0  stw r11, 0x3d0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(976 as u32), ctx.r[11].u32 ) };
	// 83156C40: 811D0008  lwz r8, 8(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(8 as u32) ) } as u64;
	// 83156C44: 80E8000C  lwz r7, 0xc(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 83156C48: 90FF03E4  stw r7, 0x3e4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(996 as u32), ctx.r[7].u32 ) };
	// 83156C4C: 4800001C  b 0x83156c68
	pc = 0x83156C68; continue 'dispatch;
	// 83156C50: 81010064  lwz r8, 0x64(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 83156C54: 80E10068  lwz r7, 0x68(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 83156C58: 93DF03D0  stw r30, 0x3d0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(976 as u32), ctx.r[30].u32 ) };
	// 83156C5C: FBDF03D8  std r30, 0x3d8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(984 as u32), ctx.r[30].u64 ) };
	// 83156C60: 911F03E4  stw r8, 0x3e4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(996 as u32), ctx.r[8].u32 ) };
	// 83156C64: 90FF03E0  stw r7, 0x3e0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(992 as u32), ctx.r[7].u32 ) };
	// 83156C68: 78A80020  clrldi r8, r5, 0x20
	ctx.r[8].u64 = ctx.r[5].u64 & 0x00000000FFFFFFFFu64;
	// 83156C6C: 995F03E8  stb r10, 0x3e8(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(1000 as u32), ctx.r[10].u8 ) };
	// 83156C70: 2B090005  cmplwi cr6, r9, 5
	ctx.cr[6].compare_u32(ctx.r[9].u32, 5 as u32, &mut ctx.xer);
	// 83156C74: F9010050  std r8, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u64 ) };
	// 83156C78: C8010050  lfd f0, 0x50(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 83156C7C: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 83156C80: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 83156C84: D19F03EC  stfs f12, 0x3ec(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1004 as u32), tmp.u32 ) };
	// 83156C88: 419900A0  bgt cr6, 0x83156d28
	if ctx.cr[6].gt {
	pc = 0x83156D28; continue 'dispatch;
	}
	// 83156C8C: 3D808315  lis r12, -0x7ceb
	ctx.r[12].s64 = -2095775744;
	// 83156C90: 398C6CA4  addi r12, r12, 0x6ca4
	ctx.r[12].s64 = ctx.r[12].s64 + 27812;
	// 83156C94: 5520103A  slwi r0, r9, 2
	ctx.r[0].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 83156C98: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 83156C9C: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 83156CA0: 4E800420  bctr
	match ctx.r[9].u64 {
		0 => {
	pc = 0x83156CBC; continue 'dispatch;
		},
		1 => {
	pc = 0x83156CBC; continue 'dispatch;
		},
		2 => {
	pc = 0x83156D10; continue 'dispatch;
		},
		3 => {
	pc = 0x83156CF0; continue 'dispatch;
		},
		4 => {
	pc = 0x83156D0C; continue 'dispatch;
		},
		5 => {
	pc = 0x83156CD4; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 83156CA4: 83156CBC  lwz r24, 0x6cbc(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27836 as u32) ) } as u64;
	// 83156CA8: 83156CBC  lwz r24, 0x6cbc(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27836 as u32) ) } as u64;
	// 83156CAC: 83156D10  lwz r24, 0x6d10(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27920 as u32) ) } as u64;
	// 83156CB0: 83156CF0  lwz r24, 0x6cf0(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27888 as u32) ) } as u64;
	// 83156CB4: 83156D0C  lwz r24, 0x6d0c(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27916 as u32) ) } as u64;
	// 83156CB8: 83156CD4  lwz r24, 0x6cd4(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(27860 as u32) ) } as u64;
            }
            0x83156CBC => {
    //   block [0x83156CBC..0x83156CD4)
	// 83156CBC: 81610078  lwz r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83156CC0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83156CC4: 93DF03D4  stw r30, 0x3d4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(980 as u32), ctx.r[30].u32 ) };
	// 83156CC8: 917F0778  stw r11, 0x778(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 83156CCC: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156CD0: 480514EC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            0x83156CD4 => {
    //   block [0x83156CD4..0x83156CF0)
	// 83156CD4: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 83156CD8: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83156CDC: 917F03D4  stw r11, 0x3d4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(980 as u32), ctx.r[11].u32 ) };
	// 83156CE0: 81610078  lwz r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83156CE4: 917F0778  stw r11, 0x778(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 83156CE8: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156CEC: 480514D0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            0x83156CF0 => {
    //   block [0x83156CF0..0x83156D0C)
	// 83156CF0: 39600003  li r11, 3
	ctx.r[11].s64 = 3;
	// 83156CF4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83156CF8: 917F03D4  stw r11, 0x3d4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(980 as u32), ctx.r[11].u32 ) };
	// 83156CFC: 81610078  lwz r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83156D00: 917F0778  stw r11, 0x778(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 83156D04: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156D08: 480514B4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            0x83156D0C => {
    //   block [0x83156D0C..0x83156D10)
	// 83156D0C: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	pc = 0x83156D10; continue 'dispatch;
            }
            0x83156D10 => {
    //   block [0x83156D10..0x83156D8C)
	// 83156D10: 917F03D4  stw r11, 0x3d4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(980 as u32), ctx.r[11].u32 ) };
	// 83156D14: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83156D18: 81610078  lwz r11, 0x78(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83156D1C: 917F0778  stw r11, 0x778(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 83156D20: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156D24: 48051498  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83156D28: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83156D2C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156D30: 388B58C8  addi r4, r11, 0x58c8
	ctx.r[4].s64 = ctx.r[11].s64 + 22728;
	// 83156D34: 48008DE5  bl 0x8315fb18
	ctx.lr = 0x83156D38;
	sub_8315FB18(ctx, base);
	// 83156D38: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156D3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156D40: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156D44: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156D48: 4E800421  bctrl
	ctx.lr = 0x83156D4C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156D4C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156D50: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156D54: 48051468  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83156D58: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 83156D5C: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 83156D60: 388A5888  addi r4, r10, 0x5888
	ctx.r[4].s64 = ctx.r[10].s64 + 22664;
	// 83156D64: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156D68: 48008DC1  bl 0x8315fb28
	ctx.lr = 0x83156D6C;
	sub_8315FB28(ctx, base);
	// 83156D6C: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156D70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156D74: 81090034  lwz r8, 0x34(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(52 as u32) ) } as u64;
	// 83156D78: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 83156D7C: 4E800421  bctrl
	ctx.lr = 0x83156D80;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83156D80: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156D84: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 83156D88: 48051434  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156D90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83156D90 size=268
    let mut pc: u32 = 0x83156D90;
    'dispatch: loop {
        match pc {
            0x83156D90 => {
    //   block [0x83156D90..0x83156E9C)
	// 83156D90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156D94: 480513D5  bl 0x831a8168
	ctx.lr = 0x83156D98;
	sub_831A8130(ctx, base);
	// 83156D98: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156D9C: 83C40388  lwz r30, 0x388(r4)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(904 as u32) ) } as u64;
	// 83156DA0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83156DA4: 4BFFFB8D  bl 0x83156930
	ctx.lr = 0x83156DA8;
	sub_83156930(ctx, base);
	// 83156DA8: 2B030001  cmplwi cr6, r3, 1
	ctx.cr[6].compare_u32(ctx.r[3].u32, 1 as u32, &mut ctx.xer);
	// 83156DAC: 419800C8  blt cr6, 0x83156e74
	if ctx.cr[6].lt {
	pc = 0x83156E74; continue 'dispatch;
	}
	// 83156DB0: 419A004C  beq cr6, 0x83156dfc
	if ctx.cr[6].eq {
	pc = 0x83156DFC; continue 'dispatch;
	}
	// 83156DB4: 2B030003  cmplwi cr6, r3, 3
	ctx.cr[6].compare_u32(ctx.r[3].u32, 3 as u32, &mut ctx.xer);
	// 83156DB8: 409800D8  bge cr6, 0x83156e90
	if !ctx.cr[6].lt {
	pc = 0x83156E90; continue 'dispatch;
	}
	// 83156DBC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156DC0: 839F0760  lwz r28, 0x760(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156DC4: 3BBF0028  addi r29, r31, 0x28
	ctx.r[29].s64 = ctx.r[31].s64 + 40;
	// 83156DC8: 4BFE91F9  bl 0x8313ffc0
	ctx.lr = 0x83156DCC;
	sub_8313FFC0(ctx, base);
	// 83156DCC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156DD0: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 83156DD4: 4BFF8F75  bl 0x8314fd48
	ctx.lr = 0x83156DD8;
	sub_8314FD48(ctx, base);
	// 83156DD8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156DDC: 83FF0760  lwz r31, 0x760(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156DE0: 4BFE91E1  bl 0x8313ffc0
	ctx.lr = 0x83156DE4;
	sub_8313FFC0(ctx, base);
	// 83156DE4: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156DE8: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 83156DEC: 4BFF90FD  bl 0x8314fee8
	ctx.lr = 0x83156DF0;
	sub_8314FEE8(ctx, base);
	// 83156DF0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156DF4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83156DF8: 480513C0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83156DFC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156E00: 839F0760  lwz r28, 0x760(r31)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156E04: 3BBF0028  addi r29, r31, 0x28
	ctx.r[29].s64 = ctx.r[31].s64 + 40;
	// 83156E08: 4BFE91B9  bl 0x8313ffc0
	ctx.lr = 0x83156E0C;
	sub_8313FFC0(ctx, base);
	// 83156E0C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156E10: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 83156E14: 4BFF91DD  bl 0x8314fff0
	ctx.lr = 0x83156E18;
	sub_8314FFF0(ctx, base);
	// 83156E18: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83156E1C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156E20: 419A0024  beq cr6, 0x83156e44
	if ctx.cr[6].eq {
	pc = 0x83156E44; continue 'dispatch;
	}
	// 83156E24: 83FF0760  lwz r31, 0x760(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156E28: 4BFE9199  bl 0x8313ffc0
	ctx.lr = 0x83156E2C;
	sub_8313FFC0(ctx, base);
	// 83156E2C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156E30: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 83156E34: 4BFF8F15  bl 0x8314fd48
	ctx.lr = 0x83156E38;
	sub_8314FD48(ctx, base);
	// 83156E38: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156E3C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83156E40: 48051378  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83156E44: 83DF0760  lwz r30, 0x760(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156E48: 4BFE9179  bl 0x8313ffc0
	ctx.lr = 0x83156E4C;
	sub_8313FFC0(ctx, base);
	// 83156E4C: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 83156E50: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 83156E54: 4BFF9825  bl 0x83150678
	ctx.lr = 0x83156E58;
	sub_83150678(ctx, base);
	// 83156E58: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83156E5C: 419A0034  beq cr6, 0x83156e90
	if ctx.cr[6].eq {
	pc = 0x83156E90; continue 'dispatch;
	}
	// 83156E60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83156E64: 4BFFFC25  bl 0x83156a88
	ctx.lr = 0x83156E68;
	sub_83156A88(ctx, base);
	// 83156E68: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156E6C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83156E70: 48051348  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83156E74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83156E78: 83DF0760  lwz r30, 0x760(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83156E7C: 3BFF0028  addi r31, r31, 0x28
	ctx.r[31].s64 = ctx.r[31].s64 + 40;
	// 83156E80: 4BFE9141  bl 0x8313ffc0
	ctx.lr = 0x83156E84;
	sub_8313FFC0(ctx, base);
	// 83156E84: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 83156E88: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 83156E8C: 4BFF8EBD  bl 0x8314fd48
	ctx.lr = 0x83156E90;
	sub_8314FD48(ctx, base);
	// 83156E90: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83156E94: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83156E98: 48051320  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83156EA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83156EA0 size=1156
    let mut pc: u32 = 0x83156EA0;
    'dispatch: loop {
        match pc {
            0x83156EA0 => {
    //   block [0x83156EA0..0x83157324)
	// 83156EA0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83156EA4: 480512C9  bl 0x831a816c
	ctx.lr = 0x83156EA8;
	sub_831A8130(ctx, base);
	// 83156EA8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83156EAC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83156EB0: 3CE08000  lis r7, -0x8000
	ctx.r[7].s64 = -2147483648;
	// 83156EB4: 3BFE0028  addi r31, r30, 0x28
	ctx.r[31].s64 = ctx.r[30].s64 + 40;
	// 83156EB8: C01E03F4  lfs f0, 0x3f4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1012 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156EBC: C1BE03F0  lfs f13, 0x3f0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1008 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156EC0: C19E004C  lfs f12, 0x4c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(76 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83156EC4: C17E0048  lfs f11, 0x48(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(72 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83156EC8: ED4C0032  fmuls f10, f12, f0
	ctx.f[10].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 83156ECC: ED2D5B3A  fmadds f9, f13, f12, f11
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[11].f64) as f32) as f64);
	// 83156ED0: D13E0048  stfs f9, 0x48(r30)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 83156ED4: D15E004C  stfs f10, 0x4c(r30)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 83156ED8: C11E03F8  lfs f8, 0x3f8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1016 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83156EDC: C0FE0050  lfs f7, 0x50(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(80 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 83156EE0: C0DE03FC  lfs f6, 0x3fc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1020 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 83156EE4: C0BE0054  lfs f5, 0x54(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(84 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 83156EE8: EC8501B2  fmuls f4, f5, f6
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[6].f64) as f32) as f64);
	// 83156EEC: EC68397A  fmadds f3, f8, f5, f7
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[5].f64 + ctx.f[7].f64) as f32) as f64);
	// 83156EF0: D07E0050  stfs f3, 0x50(r30)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 83156EF4: D09E0054  stfs f4, 0x54(r30)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 83156EF8: C05E0400  lfs f2, 0x400(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1024 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 83156EFC: C03E0058  lfs f1, 0x58(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 83156F00: C01E0404  lfs f0, 0x404(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1028 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156F04: C1BE005C  lfs f13, 0x5c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(92 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156F08: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83156F0C: ED620B7A  fmadds f11, f2, f13, f1
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 83156F10: D17E0058  stfs f11, 0x58(r30)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 83156F14: D19E005C  stfs f12, 0x5c(r30)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 83156F18: 817E03B8  lwz r11, 0x3b8(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(952 as u32) ) } as u64;
	// 83156F1C: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83156F20: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 83156F24: 409A0030  bne cr6, 0x83156f54
	if !ctx.cr[6].eq {
	pc = 0x83156F54; continue 'dispatch;
	}
	// 83156F28: E95E03D0  ld r10, 0x3d0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(976 as u32) ) };
	// 83156F2C: 7D693B78  or r9, r11, r7
	ctx.r[9].u64 = ctx.r[11].u64 | ctx.r[7].u64;
	// 83156F30: 391E03D0  addi r8, r30, 0x3d0
	ctx.r[8].s64 = ctx.r[30].s64 + 976;
	// 83156F34: F95F0000  std r10, 0(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 83156F38: E8DE03D8  ld r6, 0x3d8(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(984 as u32) ) };
	// 83156F3C: F8DF0008  std r6, 8(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[6].u64 ) };
	// 83156F40: E8BE03E0  ld r5, 0x3e0(r30)
	ctx.r[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(992 as u32) ) };
	// 83156F44: F8BF0010  std r5, 0x10(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[5].u64 ) };
	// 83156F48: E89E03E8  ld r4, 0x3e8(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[30].u32.wrapping_add(1000 as u32) ) };
	// 83156F4C: F89F0018  std r4, 0x18(r31)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[4].u64 ) };
	// 83156F50: 913F0390  stw r9, 0x390(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(912 as u32), ctx.r[9].u32 ) };
	// 83156F54: 811F0390  lwz r8, 0x390(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(912 as u32) ) } as u64;
	// 83156F58: 550B0042  rlwinm r11, r8, 0, 1, 1
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 83156F5C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83156F60: 409A0030  bne cr6, 0x83156f90
	if !ctx.cr[6].eq {
	pc = 0x83156F90; continue 'dispatch;
	}
	// 83156F64: 397E0408  addi r11, r30, 0x408
	ctx.r[11].s64 = ctx.r[30].s64 + 1032;
	// 83156F68: 395F0038  addi r10, r31, 0x38
	ctx.r[10].s64 = ctx.r[31].s64 + 56;
	// 83156F6C: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 83156F70: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83156F74: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83156F78: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83156F7C: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83156F80: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83156F84: 4200FFF0  bdnz 0x83156f74
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83156F74; continue 'dispatch;
	}
	// 83156F88: 650B4000  oris r11, r8, 0x4000
	ctx.r[11].u64 = ctx.r[8].u64 | 1073741824;
	// 83156F8C: 917F0390  stw r11, 0x390(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(912 as u32), ctx.r[11].u32 ) };
	// 83156F90: C01F0078  lfs f0, 0x78(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(120 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156F94: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 83156F98: C17E00A0  lfs f11, 0xa0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(160 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83156F9C: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 83156FA0: C1BE0444  lfs f13, 0x444(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1092 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83156FA4: ED2002F2  fmuls f9, f0, f11
	ctx.f[9].f64 = (((ctx.f[0].f64 * ctx.f[11].f64) as f32) as f64);
	// 83156FA8: C19F0074  lfs f12, 0x74(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(116 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83156FAC: D13F0078  stfs f9, 0x78(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(120 as u32), tmp.u32 ) };
	// 83156FB0: ED4D603A  fmadds f10, f13, f0, f12
	ctx.f[10].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 + ctx.f[12].f64) as f32) as f64);
	// 83156FB4: D15F0074  stfs f10, 0x74(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(116 as u32), tmp.u32 ) };
	// 83156FB8: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83156FBC: C0DF007C  lfs f6, 0x7c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(124 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 83156FC0: C11E00A8  lfs f8, 0xa8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(168 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83156FC4: C07F0080  lfs f3, 0x80(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(128 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 83156FC8: C0FE044C  lfs f7, 0x44c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1100 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 83156FCC: ECA03828  fsubs f5, f0, f7
	ctx.f[5].f64 = (((ctx.f[0].f64 - ctx.f[7].f64) as f32) as f64);
	// 83156FD0: EC803028  fsubs f4, f0, f6
	ctx.f[4].f64 = (((ctx.f[0].f64 - ctx.f[6].f64) as f32) as f64);
	// 83156FD4: EC230232  fmuls f1, f3, f8
	ctx.f[1].f64 = (((ctx.f[3].f64 * ctx.f[8].f64) as f32) as f64);
	// 83156FD8: D03F0080  stfs f1, 0x80(r31)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 83156FDC: EC4520FA  fmadds f2, f5, f3, f4
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[3].f64 + ctx.f[4].f64) as f32) as f64);
	// 83156FE0: EC001028  fsubs f0, f0, f2
	ctx.f[0].f64 = (((ctx.f[0].f64 - ctx.f[2].f64) as f32) as f64);
	// 83156FE4: D01F007C  stfs f0, 0x7c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 83156FE8: 815F0394  lwz r10, 0x394(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(916 as u32) ) } as u64;
	// 83156FEC: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 83156FF0: 409A0010  bne cr6, 0x83157000
	if !ctx.cr[6].eq {
	pc = 0x83157000; continue 'dispatch;
	}
	// 83156FF4: 817E0460  lwz r11, 0x460(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1120 as u32) ) } as u64;
	// 83156FF8: 93BF0394  stw r29, 0x394(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(916 as u32), ctx.r[29].u32 ) };
	// 83156FFC: 917F0090  stw r11, 0x90(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 83157000: 817F039C  lwz r11, 0x39c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) } as u64;
	// 83157004: 556A0000  rlwinm r10, r11, 0, 0, 0
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83157008: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315700C: 409A0014  bne cr6, 0x83157020
	if !ctx.cr[6].eq {
	pc = 0x83157020; continue 'dispatch;
	}
	// 83157010: 7D6B3B78  or r11, r11, r7
	ctx.r[11].u64 = ctx.r[11].u64 | ctx.r[7].u64;
	// 83157014: C01E046C  lfs f0, 0x46c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1132 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83157018: D01F009C  stfs f0, 0x9c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(156 as u32), tmp.u32 ) };
	// 8315701C: 917F039C  stw r11, 0x39c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(924 as u32), ctx.r[11].u32 ) };
	// 83157020: 817F039C  lwz r11, 0x39c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) } as u64;
	// 83157024: 556A0042  rlwinm r10, r11, 0, 1, 1
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83157028: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315702C: 409A0014  bne cr6, 0x83157040
	if !ctx.cr[6].eq {
	pc = 0x83157040; continue 'dispatch;
	}
	// 83157030: 895E0470  lbz r10, 0x470(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1136 as u32) ) } as u64;
	// 83157034: 65694000  oris r9, r11, 0x4000
	ctx.r[9].u64 = ctx.r[11].u64 | 1073741824;
	// 83157038: 913F039C  stw r9, 0x39c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(924 as u32), ctx.r[9].u32 ) };
	// 8315703C: 995F00A0  stb r10, 0xa0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(160 as u32), ctx.r[10].u8 ) };
	// 83157040: 817F0390  lwz r11, 0x390(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(912 as u32) ) } as u64;
	// 83157044: 556A0084  rlwinm r10, r11, 0, 2, 2
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83157048: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315704C: 409A0014  bne cr6, 0x83157060
	if !ctx.cr[6].eq {
	pc = 0x83157060; continue 'dispatch;
	}
	// 83157050: 815E0478  lwz r10, 0x478(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1144 as u32) ) } as u64;
	// 83157054: 65692000  oris r9, r11, 0x2000
	ctx.r[9].u64 = ctx.r[11].u64 | 536870912;
	// 83157058: 913F0390  stw r9, 0x390(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(912 as u32), ctx.r[9].u32 ) };
	// 8315705C: 915F00A8  stw r10, 0xa8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(168 as u32), ctx.r[10].u32 ) };
	// 83157060: 38BE049C  addi r5, r30, 0x49c
	ctx.r[5].s64 = ctx.r[30].s64 + 1180;
	// 83157064: 389E047C  addi r4, r30, 0x47c
	ctx.r[4].s64 = ctx.r[30].s64 + 1148;
	// 83157068: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315706C: 4BFF6F05  bl 0x8314df70
	ctx.lr = 0x83157070;
	sub_8314DF70(ctx, base);
	// 83157070: 817F039C  lwz r11, 0x39c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) } as u64;
	// 83157074: 556A0108  rlwinm r10, r11, 0, 4, 4
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83157078: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315707C: 409A0014  bne cr6, 0x83157090
	if !ctx.cr[6].eq {
	pc = 0x83157090; continue 'dispatch;
	}
	// 83157080: 815E06BC  lwz r10, 0x6bc(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1724 as u32) ) } as u64;
	// 83157084: 65690800  oris r9, r11, 0x800
	ctx.r[9].u64 = ctx.r[11].u64 | 134217728;
	// 83157088: 913F039C  stw r9, 0x39c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(924 as u32), ctx.r[9].u32 ) };
	// 8315708C: 915F02EC  stw r10, 0x2ec(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(748 as u32), ctx.r[10].u32 ) };
	// 83157090: 817F039C  lwz r11, 0x39c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) } as u64;
	// 83157094: 556A014A  rlwinm r10, r11, 0, 5, 5
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 83157098: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315709C: 409A0014  bne cr6, 0x831570b0
	if !ctx.cr[6].eq {
	pc = 0x831570B0; continue 'dispatch;
	}
	// 831570A0: 815E06C0  lwz r10, 0x6c0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1728 as u32) ) } as u64;
	// 831570A4: 65690400  oris r9, r11, 0x400
	ctx.r[9].u64 = ctx.r[11].u64 | 67108864;
	// 831570A8: 913F039C  stw r9, 0x39c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(924 as u32), ctx.r[9].u32 ) };
	// 831570AC: 915F02F0  stw r10, 0x2f0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(752 as u32), ctx.r[10].u32 ) };
	// 831570B0: 817F039C  lwz r11, 0x39c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) } as u64;
	// 831570B4: 556A018C  rlwinm r10, r11, 0, 6, 6
	ctx.r[10].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 831570B8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 831570BC: 409A0014  bne cr6, 0x831570d0
	if !ctx.cr[6].eq {
	pc = 0x831570D0; continue 'dispatch;
	}
	// 831570C0: 815E0704  lwz r10, 0x704(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1796 as u32) ) } as u64;
	// 831570C4: 65690200  oris r9, r11, 0x200
	ctx.r[9].u64 = ctx.r[11].u64 | 33554432;
	// 831570C8: 913F039C  stw r9, 0x39c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(924 as u32), ctx.r[9].u32 ) };
	// 831570CC: 915F0334  stw r10, 0x334(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(820 as u32), ctx.r[10].u32 ) };
	// 831570D0: C01E06E4  lfs f0, 0x6e4(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1764 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831570D4: C1BF0314  lfs f13, 0x314(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(788 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831570D8: C19E06C4  lfs f12, 0x6c4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1732 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831570DC: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831570E0: C15F02F4  lfs f10, 0x2f4(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(756 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831570E4: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 831570E8: D13F02F4  stfs f9, 0x2f4(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(756 as u32), tmp.u32 ) };
	// 831570EC: D17F0314  stfs f11, 0x314(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(788 as u32), tmp.u32 ) };
	// 831570F0: 897F03A0  lbz r11, 0x3a0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(928 as u32) ) } as u64;
	// 831570F4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831570F8: 409A0010  bne cr6, 0x83157108
	if !ctx.cr[6].eq {
	pc = 0x83157108; continue 'dispatch;
	}
	// 831570FC: 817E0708  lwz r11, 0x708(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1800 as u32) ) } as u64;
	// 83157100: 917F0338  stw r11, 0x338(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(824 as u32), ctx.r[11].u32 ) };
	// 83157104: 9BBF03A0  stb r29, 0x3a0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(928 as u32), ctx.r[29].u8 ) };
	// 83157108: C01E06E8  lfs f0, 0x6e8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1768 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315710C: C1BF0318  lfs f13, 0x318(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(792 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157110: C19E06C8  lfs f12, 0x6c8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1736 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83157114: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83157118: C15F02F8  lfs f10, 0x2f8(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(760 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315711C: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157120: D13F02F8  stfs f9, 0x2f8(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(760 as u32), tmp.u32 ) };
	// 83157124: D17F0318  stfs f11, 0x318(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(792 as u32), tmp.u32 ) };
	// 83157128: 897F03A1  lbz r11, 0x3a1(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(929 as u32) ) } as u64;
	// 8315712C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157130: 409A0010  bne cr6, 0x83157140
	if !ctx.cr[6].eq {
	pc = 0x83157140; continue 'dispatch;
	}
	// 83157134: 817E070C  lwz r11, 0x70c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1804 as u32) ) } as u64;
	// 83157138: 917F033C  stw r11, 0x33c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(828 as u32), ctx.r[11].u32 ) };
	// 8315713C: 9BBF03A1  stb r29, 0x3a1(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(929 as u32), ctx.r[29].u8 ) };
	// 83157140: C01F031C  lfs f0, 0x31c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(796 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83157144: C1BE06CC  lfs f13, 0x6cc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1740 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157148: C19E06EC  lfs f12, 0x6ec(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1772 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315714C: C17F02FC  lfs f11, 0x2fc(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(764 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83157150: ED400332  fmuls f10, f0, f12
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 83157154: ED2D583A  fmadds f9, f13, f0, f11
	ctx.f[9].f64 = (((ctx.f[13].f64 * ctx.f[0].f64 + ctx.f[11].f64) as f32) as f64);
	// 83157158: D13F02FC  stfs f9, 0x2fc(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(764 as u32), tmp.u32 ) };
	// 8315715C: D15F031C  stfs f10, 0x31c(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(796 as u32), tmp.u32 ) };
	// 83157160: 897F03A2  lbz r11, 0x3a2(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(930 as u32) ) } as u64;
	// 83157164: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157168: 409A0010  bne cr6, 0x83157178
	if !ctx.cr[6].eq {
	pc = 0x83157178; continue 'dispatch;
	}
	// 8315716C: 817E0710  lwz r11, 0x710(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1808 as u32) ) } as u64;
	// 83157170: 917F0340  stw r11, 0x340(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(832 as u32), ctx.r[11].u32 ) };
	// 83157174: 9BBF03A2  stb r29, 0x3a2(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(930 as u32), ctx.r[29].u8 ) };
	// 83157178: C01E06F0  lfs f0, 0x6f0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1776 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315717C: C1BF0320  lfs f13, 0x320(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(800 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157180: C19E06D0  lfs f12, 0x6d0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1744 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83157184: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83157188: C15F0300  lfs f10, 0x300(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(768 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315718C: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157190: D13F0300  stfs f9, 0x300(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(768 as u32), tmp.u32 ) };
	// 83157194: D17F0320  stfs f11, 0x320(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(800 as u32), tmp.u32 ) };
	// 83157198: 897F03A3  lbz r11, 0x3a3(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(931 as u32) ) } as u64;
	// 8315719C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831571A0: 409A0010  bne cr6, 0x831571b0
	if !ctx.cr[6].eq {
	pc = 0x831571B0; continue 'dispatch;
	}
	// 831571A4: 817E0714  lwz r11, 0x714(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1812 as u32) ) } as u64;
	// 831571A8: 917F0344  stw r11, 0x344(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(836 as u32), ctx.r[11].u32 ) };
	// 831571AC: 9BBF03A3  stb r29, 0x3a3(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(931 as u32), ctx.r[29].u8 ) };
	// 831571B0: C01E06F4  lfs f0, 0x6f4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1780 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831571B4: C1BF0324  lfs f13, 0x324(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(804 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831571B8: C19E06D4  lfs f12, 0x6d4(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1748 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831571BC: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831571C0: C15F0304  lfs f10, 0x304(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(772 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831571C4: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 831571C8: D13F0304  stfs f9, 0x304(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(772 as u32), tmp.u32 ) };
	// 831571CC: D17F0324  stfs f11, 0x324(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(804 as u32), tmp.u32 ) };
	// 831571D0: 897F03A4  lbz r11, 0x3a4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(932 as u32) ) } as u64;
	// 831571D4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831571D8: 409A0010  bne cr6, 0x831571e8
	if !ctx.cr[6].eq {
	pc = 0x831571E8; continue 'dispatch;
	}
	// 831571DC: 817E0718  lwz r11, 0x718(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1816 as u32) ) } as u64;
	// 831571E0: 917F0348  stw r11, 0x348(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(840 as u32), ctx.r[11].u32 ) };
	// 831571E4: 9BBF03A4  stb r29, 0x3a4(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(932 as u32), ctx.r[29].u8 ) };
	// 831571E8: C01E06F8  lfs f0, 0x6f8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1784 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831571EC: C1BF0328  lfs f13, 0x328(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(808 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831571F0: C19E06D8  lfs f12, 0x6d8(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1752 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831571F4: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831571F8: C15F0308  lfs f10, 0x308(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(776 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831571FC: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157200: D13F0308  stfs f9, 0x308(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(776 as u32), tmp.u32 ) };
	// 83157204: D17F0328  stfs f11, 0x328(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(808 as u32), tmp.u32 ) };
	// 83157208: 897F03A5  lbz r11, 0x3a5(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(933 as u32) ) } as u64;
	// 8315720C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157210: 409A0010  bne cr6, 0x83157220
	if !ctx.cr[6].eq {
	pc = 0x83157220; continue 'dispatch;
	}
	// 83157214: 817E071C  lwz r11, 0x71c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1820 as u32) ) } as u64;
	// 83157218: 917F034C  stw r11, 0x34c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(844 as u32), ctx.r[11].u32 ) };
	// 8315721C: 9BBF03A5  stb r29, 0x3a5(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(933 as u32), ctx.r[29].u8 ) };
	// 83157220: C01E06FC  lfs f0, 0x6fc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1788 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83157224: C1BF032C  lfs f13, 0x32c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(812 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157228: C19E06DC  lfs f12, 0x6dc(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1756 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315722C: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83157230: C15F030C  lfs f10, 0x30c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(780 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 83157234: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157238: D13F030C  stfs f9, 0x30c(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(780 as u32), tmp.u32 ) };
	// 8315723C: D17F032C  stfs f11, 0x32c(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(812 as u32), tmp.u32 ) };
	// 83157240: 897F03A6  lbz r11, 0x3a6(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(934 as u32) ) } as u64;
	// 83157244: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157248: 409A0010  bne cr6, 0x83157258
	if !ctx.cr[6].eq {
	pc = 0x83157258; continue 'dispatch;
	}
	// 8315724C: 817E0720  lwz r11, 0x720(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1824 as u32) ) } as u64;
	// 83157250: 917F0350  stw r11, 0x350(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(848 as u32), ctx.r[11].u32 ) };
	// 83157254: 9BBF03A6  stb r29, 0x3a6(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(934 as u32), ctx.r[29].u8 ) };
	// 83157258: C01E0700  lfs f0, 0x700(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1792 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315725C: C1BF0330  lfs f13, 0x330(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(816 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157260: C19E06E0  lfs f12, 0x6e0(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1760 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83157264: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83157268: C15F0310  lfs f10, 0x310(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(784 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315726C: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157270: D13F0310  stfs f9, 0x310(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(784 as u32), tmp.u32 ) };
	// 83157274: D17F0330  stfs f11, 0x330(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(816 as u32), tmp.u32 ) };
	// 83157278: 897F03A7  lbz r11, 0x3a7(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(935 as u32) ) } as u64;
	// 8315727C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157280: 409A0010  bne cr6, 0x83157290
	if !ctx.cr[6].eq {
	pc = 0x83157290; continue 'dispatch;
	}
	// 83157284: 817E0724  lwz r11, 0x724(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1828 as u32) ) } as u64;
	// 83157288: 917F0354  stw r11, 0x354(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(852 as u32), ctx.r[11].u32 ) };
	// 8315728C: 9BBF03A7  stb r29, 0x3a7(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(935 as u32), ctx.r[29].u8 ) };
	// 83157290: C01F0364  lfs f0, 0x364(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(868 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83157294: C1BF0360  lfs f13, 0x360(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(864 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157298: C19E0734  lfs f12, 0x734(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1844 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315729C: C17E0730  lfs f11, 0x730(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1840 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831572A0: ED400332  fmuls f10, f0, f12
	ctx.f[10].f64 = (((ctx.f[0].f64 * ctx.f[12].f64) as f32) as f64);
	// 831572A4: ED2B683A  fmadds f9, f11, f0, f13
	ctx.f[9].f64 = (((ctx.f[11].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 831572A8: D13F0360  stfs f9, 0x360(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(864 as u32), tmp.u32 ) };
	// 831572AC: D15F0364  stfs f10, 0x364(r31)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(868 as u32), tmp.u32 ) };
	// 831572B0: C0FF0368  lfs f7, 0x368(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(872 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831572B4: C0DE0738  lfs f6, 0x738(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1848 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831572B8: C11F036C  lfs f8, 0x36c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(876 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831572BC: C0BE073C  lfs f5, 0x73c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1852 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831572C0: EC863A3A  fmadds f4, f6, f8, f7
	ctx.f[4].f64 = (((ctx.f[6].f64 * ctx.f[8].f64 + ctx.f[7].f64) as f32) as f64);
	// 831572C4: EC680172  fmuls f3, f8, f5
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[5].f64) as f32) as f64);
	// 831572C8: D09F0368  stfs f4, 0x368(r31)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(872 as u32), tmp.u32 ) };
	// 831572CC: D07F036C  stfs f3, 0x36c(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(876 as u32), tmp.u32 ) };
	// 831572D0: C05F0358  lfs f2, 0x358(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(856 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831572D4: C03E0728  lfs f1, 0x728(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1832 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831572D8: C1BF035C  lfs f13, 0x35c(r31)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(860 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831572DC: ED61137A  fmadds f11, f1, f13, f2
	ctx.f[11].f64 = (((ctx.f[1].f64 * ctx.f[13].f64 + ctx.f[2].f64) as f32) as f64);
	// 831572E0: C01E072C  lfs f0, 0x72c(r30)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1836 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831572E4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831572E8: D17F0358  stfs f11, 0x358(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(856 as u32), tmp.u32 ) };
	// 831572EC: D19F035C  stfs f12, 0x35c(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(860 as u32), tmp.u32 ) };
	// 831572F0: 817F0098  lwz r11, 0x98(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(152 as u32) ) } as u64;
	// 831572F4: 815E0468  lwz r10, 0x468(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1128 as u32) ) } as u64;
	// 831572F8: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 831572FC: 917F0098  stw r11, 0x98(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(152 as u32), ctx.r[11].u32 ) };
	// 83157300: 815E0464  lwz r10, 0x464(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1124 as u32) ) } as u64;
	// 83157304: 915F0094  stw r10, 0x94(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(148 as u32), ctx.r[10].u32 ) };
	// 83157308: 93BF0398  stw r29, 0x398(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(920 as u32), ctx.r[29].u32 ) };
	// 8315730C: 811E0474  lwz r8, 0x474(r30)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1140 as u32) ) } as u64;
	// 83157310: 813E0018  lwz r9, 0x18(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(24 as u32) ) } as u64;
	// 83157314: 913E03A8  stw r9, 0x3a8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(936 as u32), ctx.r[9].u32 ) };
	// 83157318: 911E00CC  stw r8, 0xcc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(204 as u32), ctx.r[8].u32 ) };
	// 8315731C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157320: 48050E9C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157328(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83157328 size=12
    let mut pc: u32 = 0x83157328;
    'dispatch: loop {
        match pc {
            0x83157328 => {
    //   block [0x83157328..0x83157334)
	// 83157328: 81630760  lwz r11, 0x760(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1888 as u32) ) } as u64;
	// 8315732C: 7F0B2040  cmplw cr6, r11, r4
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[4].u32, &mut ctx.xer);
	// 83157330: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157334(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83157334 size=8
    let mut pc: u32 = 0x83157334;
    'dispatch: loop {
        match pc {
            0x83157334 => {
    //   block [0x83157334..0x8315733C)
	// 83157334: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157338: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157340(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157340 size=240
    let mut pc: u32 = 0x83157340;
    'dispatch: loop {
        match pc {
            0x83157340 => {
    //   block [0x83157340..0x83157430)
	// 83157340: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157344: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157348: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315734C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157350: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157354: 81630778  lwz r11, 0x778(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1912 as u32) ) } as u64;
	// 83157358: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315735C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83157360: 41980074  blt cr6, 0x831573d4
	if ctx.cr[6].lt {
	pc = 0x831573D4; continue 'dispatch;
	}
	// 83157364: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 83157368: 409800B0  bge cr6, 0x83157418
	if !ctx.cr[6].lt {
	pc = 0x83157418; continue 'dispatch;
	}
	// 8315736C: 81630780  lwz r11, 0x780(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83157370: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157374: 396BFFF8  addi r11, r11, -8
	ctx.r[11].s64 = ctx.r[11].s64 + -8;
	// 83157378: 409A0008  bne cr6, 0x83157380
	if !ctx.cr[6].eq {
	pc = 0x83157380; continue 'dispatch;
	}
	// 8315737C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83157380: A1430788  lhz r10, 0x788(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83157384: 7D490734  extsh r9, r10
	ctx.r[9].s64 = ctx.r[10].s16 as i64;
	// 83157388: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315738C: 4099002C  ble cr6, 0x831573b8
	if !ctx.cr[6].gt {
	pc = 0x831573B8; continue 'dispatch;
	}
	// 83157390: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83157394: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157398: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315739C: 396BFFF8  addi r11, r11, -8
	ctx.r[11].s64 = ctx.r[11].s64 + -8;
	// 831573A0: 409A0008  bne cr6, 0x831573a8
	if !ctx.cr[6].eq {
	pc = 0x831573A8; continue 'dispatch;
	}
	// 831573A4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831573A8: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831573AC: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 831573B0: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 831573B4: 4198FFE0  blt cr6, 0x83157394
	if ctx.cr[6].lt {
	pc = 0x83157394; continue 'dispatch;
	}
	// 831573B8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831573BC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831573C0: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 831573C4: 812A0014  lwz r9, 0x14(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) } as u64;
	// 831573C8: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 831573CC: 4E800421  bctrl
	ctx.lr = 0x831573D0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831573D0: 48000048  b 0x83157418
	pc = 0x83157418; continue 'dispatch;
	// 831573D4: 81630780  lwz r11, 0x780(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1920 as u32) ) } as u64;
	// 831573D8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831573DC: 419A003C  beq cr6, 0x83157418
	if ctx.cr[6].eq {
	pc = 0x83157418; continue 'dispatch;
	}
	// 831573E0: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 831573E4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831573E8: 419A0030  beq cr6, 0x83157418
	if ctx.cr[6].eq {
	pc = 0x83157418; continue 'dispatch;
	}
	// 831573EC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831573F0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831573F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831573F8: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 831573FC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157400: 4E800421  bctrl
	ctx.lr = 0x83157404;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157404: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157408: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315740C: 419A000C  beq cr6, 0x83157418
	if ctx.cr[6].eq {
	pc = 0x83157418; continue 'dispatch;
	}
	// 83157410: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 83157414: 4082FFD8  bne 0x831573ec
	if !ctx.cr[0].eq {
	pc = 0x831573EC; continue 'dispatch;
	}
	// 83157418: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315741C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157420: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157424: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83157428: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315742C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157430(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157430 size=136
    let mut pc: u32 = 0x83157430;
    'dispatch: loop {
        match pc {
            0x83157430 => {
    //   block [0x83157430..0x831574B8)
	// 83157430: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157434: 48050D39  bl 0x831a816c
	ctx.lr = 0x83157438;
	sub_831A8130(ctx, base);
	// 83157438: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315743C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157440: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 83157444: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83157448: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315744C: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 83157450: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157454: 4E800421  bctrl
	ctx.lr = 0x83157458;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157458: 817F0780  lwz r11, 0x780(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1920 as u32) ) } as u64;
	// 8315745C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83157460: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157464: 419A0048  beq cr6, 0x831574ac
	if ctx.cr[6].eq {
	pc = 0x831574AC; continue 'dispatch;
	}
	// 83157468: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 8315746C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157470: 419A003C  beq cr6, 0x831574ac
	if ctx.cr[6].eq {
	pc = 0x831574AC; continue 'dispatch;
	}
	// 83157474: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157478: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315747C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157480: 814B000C  lwz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157484: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157488: 4E800421  bctrl
	ctx.lr = 0x8315748C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315748C: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 83157490: 409A0008  bne cr6, 0x83157498
	if !ctx.cr[6].eq {
	pc = 0x83157498; continue 'dispatch;
	}
	// 83157494: 3BC00001  li r30, 1
	ctx.r[30].s64 = 1;
	// 83157498: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315749C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831574A0: 419A000C  beq cr6, 0x831574ac
	if ctx.cr[6].eq {
	pc = 0x831574AC; continue 'dispatch;
	}
	// 831574A4: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831574A8: 4082FFCC  bne 0x83157474
	if !ctx.cr[0].eq {
	pc = 0x83157474; continue 'dispatch;
	}
	// 831574AC: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 831574B0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831574B4: 48050D08  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831574B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831574B8 size=160
    let mut pc: u32 = 0x831574B8;
    'dispatch: loop {
        match pc {
            0x831574B8 => {
    //   block [0x831574B8..0x83157558)
	// 831574B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831574BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831574C0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831574C4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831574C8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831574CC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831574D0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831574D4: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 831574D8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 831574DC: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 831574E0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831574E4: 4E800421  bctrl
	ctx.lr = 0x831574E8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831574E8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831574EC: 409A0054  bne cr6, 0x83157540
	if !ctx.cr[6].eq {
	pc = 0x83157540; continue 'dispatch;
	}
	// 831574F0: 817F0780  lwz r11, 0x780(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1920 as u32) ) } as u64;
	// 831574F4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831574F8: 419A0044  beq cr6, 0x8315753c
	if ctx.cr[6].eq {
	pc = 0x8315753C; continue 'dispatch;
	}
	// 831574FC: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157500: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157504: 419A0038  beq cr6, 0x8315753c
	if ctx.cr[6].eq {
	pc = 0x8315753C; continue 'dispatch;
	}
	// 83157508: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315750C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83157510: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157514: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 83157518: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315751C: 4E800421  bctrl
	ctx.lr = 0x83157520;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157520: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157524: 409A001C  bne cr6, 0x83157540
	if !ctx.cr[6].eq {
	pc = 0x83157540; continue 'dispatch;
	}
	// 83157528: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315752C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157530: 419A000C  beq cr6, 0x8315753c
	if ctx.cr[6].eq {
	pc = 0x8315753C; continue 'dispatch;
	}
	// 83157534: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 83157538: 4082FFD0  bne 0x83157508
	if !ctx.cr[0].eq {
	pc = 0x83157508; continue 'dispatch;
	}
	// 8315753C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157540: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157544: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157548: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315754C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83157550: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157554: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157558(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83157558 size=200
    let mut pc: u32 = 0x83157558;
    'dispatch: loop {
        match pc {
            0x83157558 => {
    //   block [0x83157558..0x83157620)
	// 83157558: C00303F4  lfs f0, 0x3f4(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1012 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315755C: 39630028  addi r11, r3, 0x28
	ctx.r[11].s64 = ctx.r[3].s64 + 40;
	// 83157560: C1A3004C  lfs f13, 0x4c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(76 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83157564: C18303F0  lfs f12, 0x3f0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1008 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83157568: ED6D0032  fmuls f11, f13, f0
	ctx.f[11].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315756C: C1430048  lfs f10, 0x48(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(72 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 83157570: ED2C537A  fmadds f9, f12, f13, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[13].f64 + ctx.f[10].f64) as f32) as f64);
	// 83157574: D163004C  stfs f11, 0x4c(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 83157578: D1230048  stfs f9, 0x48(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), tmp.u32 ) };
	// 8315757C: C10303F8  lfs f8, 0x3f8(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1016 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83157580: C0E30050  lfs f7, 0x50(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(80 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 83157584: C0C303FC  lfs f6, 0x3fc(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1020 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 83157588: C0A30054  lfs f5, 0x54(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(84 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315758C: EC8501B2  fmuls f4, f5, f6
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[6].f64) as f32) as f64);
	// 83157590: EC68397A  fmadds f3, f8, f5, f7
	ctx.f[3].f64 = (((ctx.f[8].f64 * ctx.f[5].f64 + ctx.f[7].f64) as f32) as f64);
	// 83157594: D0630050  stfs f3, 0x50(r3)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(80 as u32), tmp.u32 ) };
	// 83157598: D0830054  stfs f4, 0x54(r3)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(84 as u32), tmp.u32 ) };
	// 8315759C: C0430400  lfs f2, 0x400(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1024 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831575A0: C0230058  lfs f1, 0x58(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(88 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831575A4: C0030404  lfs f0, 0x404(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1028 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831575A8: C1A3005C  lfs f13, 0x5c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(92 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831575AC: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831575B0: ED620B7A  fmadds f11, f2, f13, f1
	ctx.f[11].f64 = (((ctx.f[2].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 831575B4: D1630058  stfs f11, 0x58(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(88 as u32), tmp.u32 ) };
	// 831575B8: D183005C  stfs f12, 0x5c(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(92 as u32), tmp.u32 ) };
	// 831575BC: C1430730  lfs f10, 0x730(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1840 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831575C0: C1230388  lfs f9, 0x388(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(904 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831575C4: C1030734  lfs f8, 0x734(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1844 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831575C8: C0E3038C  lfs f7, 0x38c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(908 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 831575CC: ECC70232  fmuls f6, f7, f8
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[8].f64) as f32) as f64);
	// 831575D0: ECAA49FA  fmadds f5, f10, f7, f9
	ctx.f[5].f64 = (((ctx.f[10].f64 * ctx.f[7].f64 + ctx.f[9].f64) as f32) as f64);
	// 831575D4: D0A30388  stfs f5, 0x388(r3)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(904 as u32), tmp.u32 ) };
	// 831575D8: D0C3038C  stfs f6, 0x38c(r3)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(908 as u32), tmp.u32 ) };
	// 831575DC: C0830738  lfs f4, 0x738(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1848 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831575E0: C0630390  lfs f3, 0x390(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(912 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 831575E4: C043073C  lfs f2, 0x73c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1852 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 831575E8: C0230394  lfs f1, 0x394(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(916 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831575EC: EC0100B2  fmuls f0, f1, f2
	ctx.f[0].f64 = (((ctx.f[1].f64 * ctx.f[2].f64) as f32) as f64);
	// 831575F0: EDA4187A  fmadds f13, f4, f1, f3
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[1].f64 + ctx.f[3].f64) as f32) as f64);
	// 831575F4: D1A30390  stfs f13, 0x390(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(912 as u32), tmp.u32 ) };
	// 831575F8: D0030394  stfs f0, 0x394(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(916 as u32), tmp.u32 ) };
	// 831575FC: C1830728  lfs f12, 0x728(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1832 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83157600: C1630380  lfs f11, 0x380(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(896 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83157604: C143072C  lfs f10, 0x72c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1836 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 83157608: C1230384  lfs f9, 0x384(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(900 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315760C: ED0902B2  fmuls f8, f9, f10
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[10].f64) as f32) as f64);
	// 83157610: ECEC5A7A  fmadds f7, f12, f9, f11
	ctx.f[7].f64 = (((ctx.f[12].f64 * ctx.f[9].f64 + ctx.f[11].f64) as f32) as f64);
	// 83157614: D0E30380  stfs f7, 0x380(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(896 as u32), tmp.u32 ) };
	// 83157618: D1030384  stfs f8, 0x384(r3)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(900 as u32), tmp.u32 ) };
	// 8315761C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157620(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83157620 size=12
    let mut pc: u32 = 0x83157620;
    'dispatch: loop {
        match pc {
            0x83157620 => {
    //   block [0x83157620..0x8315762C)
	// 83157620: 3960FFFF  li r11, -1
	ctx.r[11].s64 = -1;
	// 83157624: B1630788  sth r11, 0x788(r3)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[3].u32.wrapping_add(1928 as u32), ctx.r[11].u16 ) };
	// 83157628: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157630 size=200
    let mut pc: u32 = 0x83157630;
    'dispatch: loop {
        match pc {
            0x83157630 => {
    //   block [0x83157630..0x831576F8)
	// 83157630: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157634: 48050B31  bl 0x831a8164
	ctx.lr = 0x83157638;
	sub_831A8130(ctx, base);
	// 83157638: DBE1FFC8  stfd f31, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[31].u64 ) };
	// 8315763C: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157640: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157644: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 83157648: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315764C: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 83157650: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 83157654: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83157658: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 8315765C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157660: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 83157664: 409A0008  bne cr6, 0x8315766c
	if !ctx.cr[6].eq {
	pc = 0x8315766C; continue 'dispatch;
	}
	// 83157668: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315766C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157670: 4E800421  bctrl
	ctx.lr = 0x83157674;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157674: 817F0780  lwz r11, 0x780(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83157678: FFE00890  fmr f31, f1
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ctx.f[1].f64;
	// 8315767C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157680: 419A0068  beq cr6, 0x831576e8
	if ctx.cr[6].eq {
	pc = 0x831576E8; continue 'dispatch;
	}
	// 83157684: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157688: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315768C: 419A005C  beq cr6, 0x831576e8
	if ctx.cr[6].eq {
	pc = 0x831576E8; continue 'dispatch;
	}
	// 83157690: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157694: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 83157698: 7F87E378  mr r7, r28
	ctx.r[7].u64 = ctx.r[28].u64;
	// 8315769C: 7FA6EB78  mr r6, r29
	ctx.r[6].u64 = ctx.r[29].u64;
	// 831576A0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831576A4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831576A8: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 831576AC: 419A0018  beq cr6, 0x831576c4
	if ctx.cr[6].eq {
	pc = 0x831576C4; continue 'dispatch;
	}
	// 831576B0: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 831576B4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831576B8: 4E800421  bctrl
	ctx.lr = 0x831576BC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831576BC: EFE1F82A  fadds f31, f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = ((ctx.f[1].f64 + ctx.f[31].f64) as f32) as f64;
	// 831576C0: 48000014  b 0x831576d4
	pc = 0x831576D4; continue 'dispatch;
	// 831576C4: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 831576C8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831576CC: 4E800421  bctrl
	ctx.lr = 0x831576D0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831576D0: EFE107F2  fmuls f31, f1, f31
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].f64 = (((ctx.f[1].f64 * ctx.f[31].f64) as f32) as f64);
	// 831576D4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831576D8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831576DC: 419A000C  beq cr6, 0x831576e8
	if ctx.cr[6].eq {
	pc = 0x831576E8; continue 'dispatch;
	}
	// 831576E0: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 831576E4: 4082FFAC  bne 0x83157690
	if !ctx.cr[0].eq {
	pc = 0x83157690; continue 'dispatch;
	}
	// 831576E8: FC20F890  fmr f1, f31
	ctx.f[1].f64 = ctx.f[31].f64;
	// 831576EC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 831576F0: CBE1FFC8  lfd f31, -0x38(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 831576F4: 48050AC0  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831576F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831576F8 size=188
    let mut pc: u32 = 0x831576F8;
    'dispatch: loop {
        match pc {
            0x831576F8 => {
    //   block [0x831576F8..0x831577B4)
	// 831576F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831576FC: 48050A71  bl 0x831a816c
	ctx.lr = 0x83157700;
	sub_831A8130(ctx, base);
	// 83157700: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157704: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 83157708: 817D0780  lwz r11, 0x780(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(1920 as u32) ) } as u64;
	// 8315770C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157710: 419A0010  beq cr6, 0x83157720
	if ctx.cr[6].eq {
	pc = 0x83157720; continue 'dispatch;
	}
	// 83157714: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157718: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315771C: 409A0010  bne cr6, 0x8315772c
	if !ctx.cr[6].eq {
	pc = 0x8315772C; continue 'dispatch;
	}
	// 83157720: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157724: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157728: 48050A94  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315772C: 817D0778  lwz r11, 0x778(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(1912 as u32) ) } as u64;
	// 83157730: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157734: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83157738: 41980070  blt cr6, 0x831577a8
	if ctx.cr[6].lt {
	pc = 0x831577A8; continue 'dispatch;
	}
	// 8315773C: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 83157740: 4098006C  bge cr6, 0x831577ac
	if !ctx.cr[6].lt {
	pc = 0x831577AC; continue 'dispatch;
	}
	// 83157744: A17D0788  lhz r11, 0x788(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83157748: 2B0BFFFF  cmplwi cr6, r11, 0xffff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 65535 as u32, &mut ctx.xer);
	// 8315774C: 419AFFD4  beq cr6, 0x83157720
	if ctx.cr[6].eq {
	pc = 0x83157720; continue 'dispatch;
	}
	// 83157750: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83157754: A15D0788  lhz r10, 0x788(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[29].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83157758: 7D7E0734  extsh r30, r11
	ctx.r[30].s64 = ctx.r[11].s16 as i64;
	// 8315775C: 7D490734  extsh r9, r10
	ctx.r[9].s64 = ctx.r[10].s16 as i64;
	// 83157760: 7F1E4800  cmpw cr6, r30, r9
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[9].s32, &mut ctx.xer);
	// 83157764: 409A0018  bne cr6, 0x8315777c
	if !ctx.cr[6].eq {
	pc = 0x8315777C; continue 'dispatch;
	}
	// 83157768: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315776C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157770: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 83157774: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157778: 4E800421  bctrl
	ctx.lr = 0x8315777C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315777C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157780: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157784: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157788: 409A0008  bne cr6, 0x83157790
	if !ctx.cr[6].eq {
	pc = 0x83157790; continue 'dispatch;
	}
	// 8315778C: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 83157790: 397E0001  addi r11, r30, 1
	ctx.r[11].s64 = ctx.r[30].s64 + 1;
	// 83157794: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157798: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8315779C: 409AFFB8  bne cr6, 0x83157754
	if !ctx.cr[6].eq {
	pc = 0x83157754; continue 'dispatch;
	}
	// 831577A0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831577A4: 48050A18  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831577A8: 807D078C  lwz r3, 0x78c(r29)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(1932 as u32) ) } as u64;
	// 831577AC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831577B0: 48050A0C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831577B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831577B8 size=140
    let mut pc: u32 = 0x831577B8;
    'dispatch: loop {
        match pc {
            0x831577B8 => {
    //   block [0x831577B8..0x83157844)
	// 831577B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831577BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831577C0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831577C4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831577C8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831577CC: 81630760  lwz r11, 0x760(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1888 as u32) ) } as u64;
	// 831577D0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 831577D4: 7F0BF040  cmplw cr6, r11, r30
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[30].u32, &mut ctx.xer);
	// 831577D8: 419A0054  beq cr6, 0x8315782c
	if ctx.cr[6].eq {
	pc = 0x8315782C; continue 'dispatch;
	}
	// 831577DC: 81630780  lwz r11, 0x780(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1920 as u32) ) } as u64;
	// 831577E0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831577E4: 419A0044  beq cr6, 0x83157828
	if ctx.cr[6].eq {
	pc = 0x83157828; continue 'dispatch;
	}
	// 831577E8: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 831577EC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831577F0: 419A0038  beq cr6, 0x83157828
	if ctx.cr[6].eq {
	pc = 0x83157828; continue 'dispatch;
	}
	// 831577F4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831577F8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831577FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157800: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 83157804: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157808: 4E800421  bctrl
	ctx.lr = 0x8315780C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315780C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157810: 409A001C  bne cr6, 0x8315782c
	if !ctx.cr[6].eq {
	pc = 0x8315782C; continue 'dispatch;
	}
	// 83157814: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157818: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315781C: 419A000C  beq cr6, 0x83157828
	if ctx.cr[6].eq {
	pc = 0x83157828; continue 'dispatch;
	}
	// 83157820: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 83157824: 4082FFD0  bne 0x831577f4
	if !ctx.cr[0].eq {
	pc = 0x831577F4; continue 'dispatch;
	}
	// 83157828: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315782C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157830: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157834: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157838: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315783C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157840: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157848(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157848 size=144
    let mut pc: u32 = 0x83157848;
    'dispatch: loop {
        match pc {
            0x83157848 => {
    //   block [0x83157848..0x831578D8)
	// 83157848: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315784C: 48050921  bl 0x831a816c
	ctx.lr = 0x83157850;
	sub_831A8130(ctx, base);
	// 83157850: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157854: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83157858: 83BE03B0  lwz r29, 0x3b0(r30)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(944 as u32) ) } as u64;
	// 8315785C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157860: 4BFE8751  bl 0x8313ffb0
	ctx.lr = 0x83157864;
	sub_8313FFB0(ctx, base);
	// 83157864: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157868: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315786C: 4BFE874D  bl 0x8313ffb8
	ctx.lr = 0x83157870;
	sub_8313FFB8(ctx, base);
	// 83157870: 817E076C  lwz r11, 0x76c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1900 as u32) ) } as u64;
	// 83157874: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157878: 419A0048  beq cr6, 0x831578c0
	if ctx.cr[6].eq {
	pc = 0x831578C0; continue 'dispatch;
	}
	// 8315787C: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 83157880: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157884: 419A003C  beq cr6, 0x831578c0
	if ctx.cr[6].eq {
	pc = 0x831578C0; continue 'dispatch;
	}
	// 83157888: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315788C: 7F0AF840  cmplw cr6, r10, r31
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[31].u32, &mut ctx.xer);
	// 83157890: 409A001C  bne cr6, 0x831578ac
	if !ctx.cr[6].eq {
	pc = 0x831578AC; continue 'dispatch;
	}
	// 83157894: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 83157898: 7F0A1840  cmplw cr6, r10, r3
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[3].u32, &mut ctx.xer);
	// 8315789C: 409A0010  bne cr6, 0x831578ac
	if !ctx.cr[6].eq {
	pc = 0x831578AC; continue 'dispatch;
	}
	// 831578A0: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831578A4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831578A8: 41990024  bgt cr6, 0x831578cc
	if ctx.cr[6].gt {
	pc = 0x831578CC; continue 'dispatch;
	}
	// 831578AC: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 831578B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831578B4: 419A000C  beq cr6, 0x831578c0
	if ctx.cr[6].eq {
	pc = 0x831578C0; continue 'dispatch;
	}
	// 831578B8: 356BFFFC  addic. r11, r11, -4
	ctx.xer.ca = (ctx.r[11].u32 > (!(-4 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831578BC: 4082FFCC  bne 0x83157888
	if !ctx.cr[0].eq {
	pc = 0x83157888; continue 'dispatch;
	}
	// 831578C0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831578C4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831578C8: 480508F4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 831578CC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831578D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 831578D4: 480508E8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831578D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831578D8 size=156
    let mut pc: u32 = 0x831578D8;
    'dispatch: loop {
        match pc {
            0x831578D8 => {
    //   block [0x831578D8..0x83157974)
	// 831578D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831578DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831578E0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 831578E4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 831578E8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831578EC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831578F0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 831578F4: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 831578F8: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 831578FC: 38CB5980  addi r6, r11, 0x5980
	ctx.r[6].s64 = ctx.r[11].s64 + 22912;
	// 83157900: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 83157904: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 83157908: 3860001C  li r3, 0x1c
	ctx.r[3].s64 = 28;
	// 8315790C: 4800830D  bl 0x8315fc18
	ctx.lr = 0x83157910;
	sub_8315FC18(ctx, base);
	// 83157910: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157914: 419A0030  beq cr6, 0x83157944
	if ctx.cr[6].eq {
	pc = 0x83157944; continue 'dispatch;
	}
	// 83157918: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 8315791C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83157920: 392A5794  addi r9, r10, 0x5794
	ctx.r[9].s64 = ctx.r[10].s64 + 22420;
	// 83157924: 91630004  stw r11, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 83157928: 91630008  stw r11, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8315792C: 9163000C  stw r11, 0xc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 83157930: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157934: 91630010  stw r11, 0x10(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 83157938: 93E30014  stw r31, 0x14(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(20 as u32), ctx.r[31].u32 ) };
	// 8315793C: 93C30018  stw r30, 0x18(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(24 as u32), ctx.r[30].u32 ) };
	// 83157940: 4800001C  b 0x8315795c
	pc = 0x8315795C; continue 'dispatch;
	// 83157944: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157948: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 8315794C: 388B5970  addi r4, r11, 0x5970
	ctx.r[4].s64 = ctx.r[11].s64 + 22896;
	// 83157950: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157954: 480081ED  bl 0x8315fb40
	ctx.lr = 0x83157958;
	sub_8315FB40(ctx, base);
	// 83157958: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315795C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157960: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157964: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157968: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315796C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157970: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157978 size=76
    let mut pc: u32 = 0x83157978;
    'dispatch: loop {
        match pc {
            0x83157978 => {
    //   block [0x83157978..0x831579C4)
	// 83157978: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315797C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157980: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157984: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157988: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315798C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157990: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83157994: 392B5794  addi r9, r11, 0x5794
	ctx.r[9].s64 = ctx.r[11].s64 + 22420;
	// 83157998: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315799C: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831579A0: 419A0010  beq cr6, 0x831579b0
	if ctx.cr[6].eq {
	pc = 0x831579B0; continue 'dispatch;
	}
	// 831579A4: 3880001C  li r4, 0x1c
	ctx.r[4].s64 = 28;
	// 831579A8: 480082D9  bl 0x8315fc80
	ctx.lr = 0x831579AC;
	sub_8315FC80(ctx, base);
	// 831579AC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831579B0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831579B4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831579B8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831579BC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831579C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831579C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831579C8 size=164
    let mut pc: u32 = 0x831579C8;
    'dispatch: loop {
        match pc {
            0x831579C8 => {
    //   block [0x831579C8..0x83157A6C)
	// 831579C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831579CC: 480507A1  bl 0x831a816c
	ctx.lr = 0x831579D0;
	sub_831A8130(ctx, base);
	// 831579D0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831579D4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831579D8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831579DC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 831579E0: 394B5798  addi r10, r11, 0x5798
	ctx.r[10].s64 = ctx.r[11].s64 + 22424;
	// 831579E4: 3BBF0028  addi r29, r31, 0x28
	ctx.r[29].s64 = ctx.r[31].s64 + 40;
	// 831579E8: 93DF0008  stw r30, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[30].u32 ) };
	// 831579EC: 93DF000C  stw r30, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[30].u32 ) };
	// 831579F0: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831579F4: 93DF0010  stw r30, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 831579F8: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 831579FC: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157A00: 913F0014  stw r9, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[9].u32 ) };
	// 83157A04: 81040008  lwz r8, 8(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157A08: 80E80000  lwz r7, 0(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157A0C: 90FF0018  stw r7, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[7].u32 ) };
	// 83157A10: 93DF0020  stw r30, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[30].u32 ) };
	// 83157A14: 4BFE880D  bl 0x83140220
	ctx.lr = 0x83157A18;
	sub_83140220(ctx, base);
	// 83157A18: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157A1C: 4BFE75AD  bl 0x8313efc8
	ctx.lr = 0x83157A20;
	sub_8313EFC8(ctx, base);
	// 83157A20: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157A24: 4BFE75A5  bl 0x8313efc8
	ctx.lr = 0x83157A28;
	sub_8313EFC8(ctx, base);
	// 83157A28: 387F03D0  addi r3, r31, 0x3d0
	ctx.r[3].s64 = ctx.r[31].s64 + 976;
	// 83157A2C: 4BFE87F5  bl 0x83140220
	ctx.lr = 0x83157A30;
	sub_83140220(ctx, base);
	// 83157A30: 3D408339  lis r10, -0x7cc7
	ctx.r[10].s64 = -2093416448;
	// 83157A34: 816A7F68  lwz r11, 0x7f68(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32616 as u32) ) } as u64;
	// 83157A38: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 83157A3C: 916A7F68  stw r11, 0x7f68(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32616 as u32), ctx.r[11].u32 ) };
	// 83157A40: 2F0BFFFF  cmpwi cr6, r11, -1
	ctx.cr[6].compare_i32(ctx.r[11].s32, -1, &mut ctx.xer);
	// 83157A44: 409A000C  bne cr6, 0x83157a50
	if !ctx.cr[6].eq {
	pc = 0x83157A50; continue 'dispatch;
	}
	// 83157A48: 7FCBF378  mr r11, r30
	ctx.r[11].u64 = ctx.r[30].u64;
	// 83157A4C: 916A7F68  stw r11, 0x7f68(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32616 as u32), ctx.r[11].u32 ) };
	// 83157A50: 917F0760  stw r11, 0x760(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1888 as u32), ctx.r[11].u32 ) };
	// 83157A54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157A58: 93DF0764  stw r30, 0x764(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1892 as u32), ctx.r[30].u32 ) };
	// 83157A5C: 93DF076C  stw r30, 0x76c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1900 as u32), ctx.r[30].u32 ) };
	// 83157A60: 93DF0770  stw r30, 0x770(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1904 as u32), ctx.r[30].u32 ) };
	// 83157A64: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157A68: 48050754  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157A70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157A70 size=76
    let mut pc: u32 = 0x83157A70;
    'dispatch: loop {
        match pc {
            0x83157A70 => {
    //   block [0x83157A70..0x83157ABC)
	// 83157A70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157A74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157A78: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157A7C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157A80: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157A84: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157A88: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83157A8C: 392B5798  addi r9, r11, 0x5798
	ctx.r[9].s64 = ctx.r[11].s64 + 22424;
	// 83157A90: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157A94: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157A98: 419A0010  beq cr6, 0x83157aa8
	if ctx.cr[6].eq {
	pc = 0x83157AA8; continue 'dispatch;
	}
	// 83157A9C: 38800778  li r4, 0x778
	ctx.r[4].s64 = 1912;
	// 83157AA0: 480081E1  bl 0x8315fc80
	ctx.lr = 0x83157AA4;
	sub_8315FC80(ctx, base);
	// 83157AA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157AA8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83157AAC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157AB0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157AB4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157AB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157AC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157AC0 size=256
    let mut pc: u32 = 0x83157AC0;
    'dispatch: loop {
        match pc {
            0x83157AC0 => {
    //   block [0x83157AC0..0x83157BC0)
	// 83157AC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157AC4: 480506A5  bl 0x831a8168
	ctx.lr = 0x83157AC8;
	sub_831A8130(ctx, base);
	// 83157AC8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157ACC: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 83157AD0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 83157AD4: 3BDC076C  addi r30, r28, 0x76c
	ctx.r[30].s64 = ctx.r[28].s64 + 1900;
	// 83157AD8: 817C076C  lwz r11, 0x76c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1900 as u32) ) } as u64;
	// 83157ADC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157AE0: 419A00A4  beq cr6, 0x83157b84
	if ctx.cr[6].eq {
	pc = 0x83157B84; continue 'dispatch;
	}
	// 83157AE4: 386BFFFC  addi r3, r11, -4
	ctx.r[3].s64 = ctx.r[11].s64 + -4;
	// 83157AE8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157AEC: 419A0098  beq cr6, 0x83157b84
	if ctx.cr[6].eq {
	pc = 0x83157B84; continue 'dispatch;
	}
	// 83157AF0: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157AF4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157AF8: 3BEBFFFC  addi r31, r11, -4
	ctx.r[31].s64 = ctx.r[11].s64 + -4;
	// 83157AFC: 409A0008  bne cr6, 0x83157b04
	if !ctx.cr[6].eq {
	pc = 0x83157B04; continue 'dispatch;
	}
	// 83157B00: 7FBFEB78  mr r31, r29
	ctx.r[31].u64 = ctx.r[29].u64;
	// 83157B04: 35630004  addic. r11, r3, 4
	ctx.xer.ca = (ctx.r[3].u32 > (!(4 as u32)));
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83157B08: 418200A4  beq 0x83157bac
	if ctx.cr[0].eq {
	pc = 0x83157BAC; continue 'dispatch;
	}
	// 83157B0C: 815E0000  lwz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B10: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83157B14: 409A000C  bne cr6, 0x83157b20
	if !ctx.cr[6].eq {
	pc = 0x83157B20; continue 'dispatch;
	}
	// 83157B18: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157B1C: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 83157B20: 815E0004  lwz r10, 4(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157B24: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83157B28: 409A000C  bne cr6, 0x83157b34
	if !ctx.cr[6].eq {
	pc = 0x83157B34; continue 'dispatch;
	}
	// 83157B2C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B30: 915E0004  stw r10, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 83157B34: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B38: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157B3C: 419A000C  beq cr6, 0x83157b48
	if ctx.cr[6].eq {
	pc = 0x83157B48; continue 'dispatch;
	}
	// 83157B40: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157B44: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 83157B48: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157B4C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157B50: 419A000C  beq cr6, 0x83157b5c
	if ctx.cr[6].eq {
	pc = 0x83157B5C; continue 'dispatch;
	}
	// 83157B54: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B58: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157B5C: 93AB0004  stw r29, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 83157B60: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83157B64: 93AB0000  stw r29, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[29].u32 ) };
	// 83157B68: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B6C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B70: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157B74: 4E800421  bctrl
	ctx.lr = 0x83157B78;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157B78: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157B7C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157B80: 409AFF70  bne cr6, 0x83157af0
	if !ctx.cr[6].eq {
	pc = 0x83157AF0; continue 'dispatch;
	}
	// 83157B84: 807C0764  lwz r3, 0x764(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83157B88: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157B8C: 419A0018  beq cr6, 0x83157ba4
	if ctx.cr[6].eq {
	pc = 0x83157BA4; continue 'dispatch;
	}
	// 83157B90: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B94: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157B98: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157B9C: 4E800421  bctrl
	ctx.lr = 0x83157BA0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157BA0: 93BC0764  stw r29, 0x764(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(1892 as u32), ctx.r[29].u32 ) };
	// 83157BA4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83157BA8: 48050610  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 83157BAC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157BB0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157BB4: 388B37A8  addi r4, r11, 0x37a8
	ctx.r[4].s64 = ctx.r[11].s64 + 14248;
	// 83157BB8: 48007F61  bl 0x8315fb18
	ctx.lr = 0x83157BBC;
	sub_8315FB18(ctx, base);
	// 83157BBC: 48000000  b 0x83157bbc
	pc = 0x83157BBC; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157BC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157BC0 size=164
    let mut pc: u32 = 0x83157BC0;
    'dispatch: loop {
        match pc {
            0x83157BC0 => {
    //   block [0x83157BC0..0x83157C64)
	// 83157BC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157BC4: 480505A9  bl 0x831a816c
	ctx.lr = 0x83157BC8;
	sub_831A8130(ctx, base);
	// 83157BC8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157BCC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157BD0: 83BF03B0  lwz r29, 0x3b0(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(944 as u32) ) } as u64;
	// 83157BD4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157BD8: 4BFE83D9  bl 0x8313ffb0
	ctx.lr = 0x83157BDC;
	sub_8313FFB0(ctx, base);
	// 83157BDC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83157BE0: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157BE4: 4BFE83D5  bl 0x8313ffb8
	ctx.lr = 0x83157BE8;
	sub_8313FFB8(ctx, base);
	// 83157BE8: 817F076C  lwz r11, 0x76c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1900 as u32) ) } as u64;
	// 83157BEC: 3BBF076C  addi r29, r31, 0x76c
	ctx.r[29].s64 = ctx.r[31].s64 + 1900;
	// 83157BF0: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 83157BF4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157BF8: 419A0030  beq cr6, 0x83157c28
	if ctx.cr[6].eq {
	pc = 0x83157C28; continue 'dispatch;
	}
	// 83157BFC: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 83157C00: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157C04: 419A0024  beq cr6, 0x83157c28
	if ctx.cr[6].eq {
	pc = 0x83157C28; continue 'dispatch;
	}
	// 83157C08: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 83157C0C: 7F0AF040  cmplw cr6, r10, r30
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[30].u32, &mut ctx.xer);
	// 83157C10: 419A0040  beq cr6, 0x83157c50
	if ctx.cr[6].eq {
	pc = 0x83157C50; continue 'dispatch;
	}
	// 83157C14: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157C18: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157C1C: 419A000C  beq cr6, 0x83157c28
	if ctx.cr[6].eq {
	pc = 0x83157C28; continue 'dispatch;
	}
	// 83157C20: 356BFFFC  addic. r11, r11, -4
	ctx.xer.ca = (ctx.r[11].u32 > (!(-4 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83157C24: 4082FFE4  bne 0x83157c08
	if !ctx.cr[0].eq {
	pc = 0x83157C08; continue 'dispatch;
	}
	// 83157C28: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83157C2C: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 83157C30: 4BFFFCA9  bl 0x831578d8
	ctx.lr = 0x83157C34;
	sub_831578D8(ctx, base);
	// 83157C34: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83157C38: 419A0010  beq cr6, 0x83157c48
	if ctx.cr[6].eq {
	pc = 0x83157C48; continue 'dispatch;
	}
	// 83157C3C: 38830004  addi r4, r3, 4
	ctx.r[4].s64 = ctx.r[3].s64 + 4;
	// 83157C40: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157C44: 4BFE84A5  bl 0x831400e8
	ctx.lr = 0x83157C48;
	sub_831400E8(ctx, base);
	// 83157C48: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157C4C: 48050570  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157C50: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83157C54: 90AB0018  stw r5, 0x18(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(24 as u32), ctx.r[5].u32 ) };
	// 83157C58: 914B0010  stw r10, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 83157C5C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157C60: 4805055C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157C68(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83157C68 size=8
    let mut pc: u32 = 0x83157C68;
    'dispatch: loop {
        match pc {
            0x83157C68 => {
    //   block [0x83157C68..0x83157C70)
	// 83157C68: 80630778  lwz r3, 0x778(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(1912 as u32) ) } as u64;
	// 83157C6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157C70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157C70 size=76
    let mut pc: u32 = 0x83157C70;
    'dispatch: loop {
        match pc {
            0x83157C70 => {
    //   block [0x83157C70..0x83157CBC)
	// 83157C70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157C74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157C78: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157C7C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157C80: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157C84: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157C88: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83157C8C: 392B5798  addi r9, r11, 0x5798
	ctx.r[9].s64 = ctx.r[11].s64 + 22424;
	// 83157C90: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157C94: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157C98: 419A0010  beq cr6, 0x83157ca8
	if ctx.cr[6].eq {
	pc = 0x83157CA8; continue 'dispatch;
	}
	// 83157C9C: 38800780  li r4, 0x780
	ctx.r[4].s64 = 1920;
	// 83157CA0: 48007FE1  bl 0x8315fc80
	ctx.lr = 0x83157CA4;
	sub_8315FC80(ctx, base);
	// 83157CA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157CA8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83157CAC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157CB0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157CB4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157CB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157CC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83157CC0 size=4
    let mut pc: u32 = 0x83157CC0;
    'dispatch: loop {
        match pc {
            0x83157CC0 => {
    //   block [0x83157CC0..0x83157CC4)
	// 83157CC0: 4BFFFE00  b 0x83157ac0
	sub_83157AC0(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157CC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157CC8 size=76
    let mut pc: u32 = 0x83157CC8;
    'dispatch: loop {
        match pc {
            0x83157CC8 => {
    //   block [0x83157CC8..0x83157D14)
	// 83157CC8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157CCC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157CD0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157CD4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157CD8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157CDC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157CE0: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83157CE4: 392B5798  addi r9, r11, 0x5798
	ctx.r[9].s64 = ctx.r[11].s64 + 22424;
	// 83157CE8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157CEC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157CF0: 419A0010  beq cr6, 0x83157d00
	if ctx.cr[6].eq {
	pc = 0x83157D00; continue 'dispatch;
	}
	// 83157CF4: 38800790  li r4, 0x790
	ctx.r[4].s64 = 1936;
	// 83157CF8: 48007F89  bl 0x8315fc80
	ctx.lr = 0x83157CFC;
	sub_8315FC80(ctx, base);
	// 83157CFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157D00: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83157D04: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83157D08: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83157D0C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83157D10: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157D18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157D18 size=196
    let mut pc: u32 = 0x83157D18;
    'dispatch: loop {
        match pc {
            0x83157D18 => {
    //   block [0x83157D18..0x83157DDC)
	// 83157D18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157D1C: 48050451  bl 0x831a816c
	ctx.lr = 0x83157D20;
	sub_831A8130(ctx, base);
	// 83157D20: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157D24: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 83157D28: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83157D2C: 3BFD0780  addi r31, r29, 0x780
	ctx.r[31].s64 = ctx.r[29].s64 + 1920;
	// 83157D30: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157D34: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157D38: 419A0080  beq cr6, 0x83157db8
	if ctx.cr[6].eq {
	pc = 0x83157DB8; continue 'dispatch;
	}
	// 83157D3C: 346BFFF8  addic. r3, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[3].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83157D40: 41820078  beq 0x83157db8
	if ctx.cr[0].eq {
	pc = 0x83157DB8; continue 'dispatch;
	}
	// 83157D44: 35630008  addic. r11, r3, 8
	ctx.xer.ca = (ctx.r[3].u32 > (!(8 as u32)));
	ctx.r[11].s64 = ctx.r[3].s64 + 8;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83157D48: 41820080  beq 0x83157dc8
	if ctx.cr[0].eq {
	pc = 0x83157DC8; continue 'dispatch;
	}
	// 83157D4C: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157D50: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83157D54: 409A000C  bne cr6, 0x83157d60
	if !ctx.cr[6].eq {
	pc = 0x83157D60; continue 'dispatch;
	}
	// 83157D58: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157D5C: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 83157D60: 815F0004  lwz r10, 4(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157D64: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83157D68: 409A000C  bne cr6, 0x83157d74
	if !ctx.cr[6].eq {
	pc = 0x83157D74; continue 'dispatch;
	}
	// 83157D6C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157D70: 915F0004  stw r10, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 83157D74: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157D78: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157D7C: 419A000C  beq cr6, 0x83157d88
	if ctx.cr[6].eq {
	pc = 0x83157D88; continue 'dispatch;
	}
	// 83157D80: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157D84: 912A0004  stw r9, 4(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), ctx.r[9].u32 ) };
	// 83157D88: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157D8C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83157D90: 419A000C  beq cr6, 0x83157d9c
	if ctx.cr[6].eq {
	pc = 0x83157D9C; continue 'dispatch;
	}
	// 83157D94: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157D98: 912A0000  stw r9, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83157D9C: 93CB0004  stw r30, 4(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 83157DA0: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 83157DA4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157DA8: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157DAC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157DB0: 4E800421  bctrl
	ctx.lr = 0x83157DB4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157DB4: 4BFFFF7C  b 0x83157d30
	pc = 0x83157D30; continue 'dispatch;
	// 83157DB8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157DBC: 4BFFFD05  bl 0x83157ac0
	ctx.lr = 0x83157DC0;
	sub_83157AC0(ctx, base);
	// 83157DC0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157DC4: 480503F8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157DC8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83157DCC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157DD0: 388B37A8  addi r4, r11, 0x37a8
	ctx.r[4].s64 = ctx.r[11].s64 + 14248;
	// 83157DD4: 48007D45  bl 0x8315fb18
	ctx.lr = 0x83157DD8;
	sub_8315FB18(ctx, base);
	// 83157DD8: 48000000  b 0x83157dd8
	pc = 0x83157DD8; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157DE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83157DE0 size=432
    let mut pc: u32 = 0x83157DE0;
    'dispatch: loop {
        match pc {
            0x83157DE0 => {
    //   block [0x83157DE0..0x83157F90)
	// 83157DE0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157DE4: 48050389  bl 0x831a816c
	ctx.lr = 0x83157DE8;
	sub_831A8130(ctx, base);
	// 83157DE8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157DEC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83157DF0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 83157DF4: 4BFFEB3D  bl 0x83156930
	ctx.lr = 0x83157DF8;
	sub_83156930(ctx, base);
	// 83157DF8: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 83157DFC: 2B1D0001  cmplwi cr6, r29, 1
	ctx.cr[6].compare_u32(ctx.r[29].u32, 1 as u32, &mut ctx.xer);
	// 83157E00: 4198013C  blt cr6, 0x83157f3c
	if ctx.cr[6].lt {
	pc = 0x83157F3C; continue 'dispatch;
	}
	// 83157E04: 419A0030  beq cr6, 0x83157e34
	if ctx.cr[6].eq {
	pc = 0x83157E34; continue 'dispatch;
	}
	// 83157E08: 2B1D0003  cmplwi cr6, r29, 3
	ctx.cr[6].compare_u32(ctx.r[29].u32, 3 as u32, &mut ctx.xer);
	// 83157E0C: 40980178  bge cr6, 0x83157f84
	if !ctx.cr[6].lt {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157E10: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157E14: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 83157E18: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83157E1C: 814B0014  lwz r10, 0x14(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 83157E20: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157E24: 4E800421  bctrl
	ctx.lr = 0x83157E28;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157E28: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157E2C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157E30: 4805038C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157E34: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83157E38: 4BFFFA11  bl 0x83157848
	ctx.lr = 0x83157E3C;
	sub_83157848(ctx, base);
	// 83157E3C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83157E40: 419A00D8  beq cr6, 0x83157f18
	if ctx.cr[6].eq {
	pc = 0x83157F18; continue 'dispatch;
	}
	// 83157E44: 817E0778  lwz r11, 0x778(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1912 as u32) ) } as u64;
	// 83157E48: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83157E4C: 41980078  blt cr6, 0x83157ec4
	if ctx.cr[6].lt {
	pc = 0x83157EC4; continue 'dispatch;
	}
	// 83157E50: 2B0B0004  cmplwi cr6, r11, 4
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4 as u32, &mut ctx.xer);
	// 83157E54: 40980130  bge cr6, 0x83157f84
	if !ctx.cr[6].lt {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157E58: 817E0780  lwz r11, 0x780(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83157E5C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157E60: 386BFFF8  addi r3, r11, -8
	ctx.r[3].s64 = ctx.r[11].s64 + -8;
	// 83157E64: 409A0008  bne cr6, 0x83157e6c
	if !ctx.cr[6].eq {
	pc = 0x83157E6C; continue 'dispatch;
	}
	// 83157E68: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157E6C: A17E0788  lhz r11, 0x788(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[30].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83157E70: 7D690734  extsh r9, r11
	ctx.r[9].s64 = ctx.r[11].s16 as i64;
	// 83157E74: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 83157E78: 4099002C  ble cr6, 0x83157ea4
	if !ctx.cr[6].gt {
	pc = 0x83157EA4; continue 'dispatch;
	}
	// 83157E7C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83157E80: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157E84: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157E88: 386BFFF8  addi r3, r11, -8
	ctx.r[3].s64 = ctx.r[11].s64 + -8;
	// 83157E8C: 409A0008  bne cr6, 0x83157e94
	if !ctx.cr[6].eq {
	pc = 0x83157E94; continue 'dispatch;
	}
	// 83157E90: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83157E94: 396A0001  addi r11, r10, 1
	ctx.r[11].s64 = ctx.r[10].s64 + 1;
	// 83157E98: 7D6A0734  extsh r10, r11
	ctx.r[10].s64 = ctx.r[11].s16 as i64;
	// 83157E9C: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 83157EA0: 4198FFE0  blt cr6, 0x83157e80
	if ctx.cr[6].lt {
	pc = 0x83157E80; continue 'dispatch;
	}
	// 83157EA4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157EA8: 389E0028  addi r4, r30, 0x28
	ctx.r[4].s64 = ctx.r[30].s64 + 40;
	// 83157EAC: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157EB0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157EB4: 4E800421  bctrl
	ctx.lr = 0x83157EB8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157EB8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157EBC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157EC0: 480502FC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157EC4: 817E0780  lwz r11, 0x780(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83157EC8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157ECC: 419A00B8  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157ED0: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157ED4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157ED8: 419A00AC  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157EDC: 3BDE0028  addi r30, r30, 0x28
	ctx.r[30].s64 = ctx.r[30].s64 + 40;
	// 83157EE0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157EE4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83157EE8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157EEC: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157EF0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157EF4: 4E800421  bctrl
	ctx.lr = 0x83157EF8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157EF8: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157EFC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157F00: 419A0084  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157F04: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 83157F08: 4082FFD8  bne 0x83157ee0
	if !ctx.cr[0].eq {
	pc = 0x83157EE0; continue 'dispatch;
	}
	// 83157F0C: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157F10: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157F14: 480502A8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157F18: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157F1C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 83157F20: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83157F24: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83157F28: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157F2C: 4E800421  bctrl
	ctx.lr = 0x83157F30;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157F30: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157F34: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157F38: 48050284  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83157F3C: 817E0780  lwz r11, 0x780(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83157F40: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157F44: 419A0040  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157F48: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83157F4C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83157F50: 419A0034  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157F54: 3BDE0028  addi r30, r30, 0x28
	ctx.r[30].s64 = ctx.r[30].s64 + 40;
	// 83157F58: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157F5C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83157F60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157F64: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83157F68: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157F6C: 4E800421  bctrl
	ctx.lr = 0x83157F70;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157F70: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83157F74: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83157F78: 419A000C  beq cr6, 0x83157f84
	if ctx.cr[6].eq {
	pc = 0x83157F84; continue 'dispatch;
	}
	// 83157F7C: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 83157F80: 4082FFD8  bne 0x83157f58
	if !ctx.cr[0].eq {
	pc = 0x83157F58; continue 'dispatch;
	}
	// 83157F84: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83157F88: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83157F8C: 48050230  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83157F90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83157F90 size=172
    let mut pc: u32 = 0x83157F90;
    'dispatch: loop {
        match pc {
            0x83157F90 => {
    //   block [0x83157F90..0x8315803C)
	// 83157F90: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83157F94: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83157F98: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83157F9C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83157FA0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83157FA4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83157FA8: 38A003A8  li r5, 0x3a8
	ctx.r[5].s64 = 936;
	// 83157FAC: 3BDF0028  addi r30, r31, 0x28
	ctx.r[30].s64 = ctx.r[31].s64 + 40;
	// 83157FB0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 83157FB4: 4805055D  bl 0x831a8510
	ctx.lr = 0x83157FB8;
	sub_831A8510(ctx, base);
	// 83157FB8: 807F0764  lwz r3, 0x764(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1892 as u32) ) } as u64;
	// 83157FBC: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83157FC0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157FC4: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 83157FC8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83157FCC: 4E800421  bctrl
	ctx.lr = 0x83157FD0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157FD0: 813F0000  lwz r9, 0(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83157FD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157FD8: 81090038  lwz r8, 0x38(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(56 as u32) ) } as u64;
	// 83157FDC: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 83157FE0: 4E800421  bctrl
	ctx.lr = 0x83157FE4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83157FE4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83157FE8: 4BFFFBD9  bl 0x83157bc0
	ctx.lr = 0x83157FEC;
	sub_83157BC0(ctx, base);
	// 83157FEC: 80FF00D0  lwz r7, 0xd0(r31)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(208 as u32) ) } as u64;
	// 83157FF0: 2F070001  cmpwi cr6, r7, 1
	ctx.cr[6].compare_i32(ctx.r[7].s32, 1, &mut ctx.xer);
	// 83157FF4: 409A0024  bne cr6, 0x83158018
	if !ctx.cr[6].eq {
	pc = 0x83158018; continue 'dispatch;
	}
	// 83157FF8: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 83157FFC: C1BF039C  lfs f13, 0x39c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(924 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158000: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158004: FF0D0000  fcmpu cr6, f13, f0
	ctx.cr[6].compare_f64(ctx.f[13].f64, ctx.f[0].f64);
	// 83158008: 409A0010  bne cr6, 0x83158018
	if !ctx.cr[6].eq {
	pc = 0x83158018; continue 'dispatch;
	}
	// 8315800C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83158010: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158014: 4800000C  b 0x83158020
	pc = 0x83158020; continue 'dispatch;
	// 83158018: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315801C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83158020: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 83158024: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83158028: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315802C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83158030: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83158034: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158038: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158040(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83158040 size=212
    let mut pc: u32 = 0x83158040;
    'dispatch: loop {
        match pc {
            0x83158040 => {
    //   block [0x83158040..0x83158114)
	// 83158040: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83158044: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83158048: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315804C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83158050: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158054: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83158058: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315805C: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 83158060: 38CB5A20  addi r6, r11, 0x5a20
	ctx.r[6].s64 = ctx.r[11].s64 + 23072;
	// 83158064: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 83158068: 38600780  li r3, 0x780
	ctx.r[3].s64 = 1920;
	// 8315806C: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158070: 48007BA9  bl 0x8315fc18
	ctx.lr = 0x83158074;
	sub_8315FC18(ctx, base);
	// 83158074: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83158078: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315807C: 419A0060  beq cr6, 0x831580dc
	if ctx.cr[6].eq {
	pc = 0x831580DC; continue 'dispatch;
	}
	// 83158080: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 83158084: 4BFFF945  bl 0x831579c8
	ctx.lr = 0x83158088;
	sub_831579C8(ctx, base);
	// 83158088: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315808C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83158090: 392B599C  addi r9, r11, 0x599c
	ctx.r[9].s64 = ctx.r[11].s64 + 22940;
	// 83158094: 915F0778  stw r10, 0x778(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1912 as u32), ctx.r[10].u32 ) };
	// 83158098: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315809C: 552B003E  slwi r11, r9, 0
	ctx.r[11].u32 = ctx.r[9].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831580A0: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831580A4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831580A8: 814B0030  lwz r10, 0x30(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 831580AC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831580B0: 4E800421  bctrl
	ctx.lr = 0x831580B4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831580B4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831580B8: 409A0040  bne cr6, 0x831580f8
	if !ctx.cr[6].eq {
	pc = 0x831580F8; continue 'dispatch;
	}
	// 831580BC: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831580C0: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 831580C4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831580C8: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 831580CC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831580D0: 4E800421  bctrl
	ctx.lr = 0x831580D4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831580D4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831580D8: 48000024  b 0x831580fc
	pc = 0x831580FC; continue 'dispatch;
	// 831580DC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831580E0: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 831580E4: 388B5A14  addi r4, r11, 0x5a14
	ctx.r[4].s64 = ctx.r[11].s64 + 23060;
	// 831580E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831580EC: 48007A55  bl 0x8315fb40
	ctx.lr = 0x831580F0;
	sub_8315FB40(ctx, base);
	// 831580F0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831580F4: 48000008  b 0x831580fc
	pc = 0x831580FC; continue 'dispatch;
	// 831580F8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831580FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83158100: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83158104: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83158108: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315810C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158110: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158118(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83158118 size=88
    let mut pc: u32 = 0x83158118;
    'dispatch: loop {
        match pc {
            0x83158118 => {
    //   block [0x83158118..0x83158170)
	// 83158118: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315811C: 48050051  bl 0x831a816c
	ctx.lr = 0x83158120;
	sub_831A8130(ctx, base);
	// 83158120: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158124: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83158128: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315812C: 4BFFFE65  bl 0x83157f90
	ctx.lr = 0x83158130;
	sub_83157F90(ctx, base);
	// 83158130: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83158134: 419A0030  beq cr6, 0x83158164
	if ctx.cr[6].eq {
	pc = 0x83158164; continue 'dispatch;
	}
	// 83158138: 807E0388  lwz r3, 0x388(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(904 as u32) ) } as u64;
	// 8315813C: 3BDF0028  addi r30, r31, 0x28
	ctx.r[30].s64 = ctx.r[31].s64 + 40;
	// 83158140: 83BF0760  lwz r29, 0x760(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(1888 as u32) ) } as u64;
	// 83158144: 4BFE7E7D  bl 0x8313ffc0
	ctx.lr = 0x83158148;
	sub_8313FFC0(ctx, base);
	// 83158148: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315814C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 83158150: 4BFF8529  bl 0x83150678
	ctx.lr = 0x83158154;
	sub_83150678(ctx, base);
	// 83158154: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83158158: 419A000C  beq cr6, 0x83158164
	if ctx.cr[6].eq {
	pc = 0x83158164; continue 'dispatch;
	}
	// 8315815C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83158160: 4BFFE929  bl 0x83156a88
	ctx.lr = 0x83158164;
	sub_83156A88(ctx, base);
	// 83158164: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83158168: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315816C: 48050050  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158170(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83158170 size=232
    let mut pc: u32 = 0x83158170;
    'dispatch: loop {
        match pc {
            0x83158170 => {
    //   block [0x83158170..0x83158258)
	// 83158170: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83158174: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83158178: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315817C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83158180: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158184: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 83158188: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315818C: 38E00004  li r7, 4
	ctx.r[7].s64 = 4;
	// 83158190: 38CB5A38  addi r6, r11, 0x5a38
	ctx.r[6].s64 = ctx.r[11].s64 + 23096;
	// 83158194: 38A00002  li r5, 2
	ctx.r[5].s64 = 2;
	// 83158198: 38600790  li r3, 0x790
	ctx.r[3].s64 = 1936;
	// 8315819C: 809E0000  lwz r4, 0(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 831581A0: 48007A79  bl 0x8315fc18
	ctx.lr = 0x831581A4;
	sub_8315FC18(ctx, base);
	// 831581A4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831581A8: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831581AC: 419A0074  beq cr6, 0x83158220
	if ctx.cr[6].eq {
	pc = 0x83158220; continue 'dispatch;
	}
	// 831581B0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831581B4: 4BFFF815  bl 0x831579c8
	ctx.lr = 0x831581B8;
	sub_831579C8(ctx, base);
	// 831581B8: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 831581BC: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831581C0: 392A59D8  addi r9, r10, 0x59d8
	ctx.r[9].s64 = ctx.r[10].s64 + 23000;
	// 831581C4: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 831581C8: 917F077C  stw r11, 0x77c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1916 as u32), ctx.r[11].u32 ) };
	// 831581CC: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831581D0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 831581D4: 917F0780  stw r11, 0x780(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1920 as u32), ctx.r[11].u32 ) };
	// 831581D8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831581DC: 917F0784  stw r11, 0x784(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1924 as u32), ctx.r[11].u32 ) };
	// 831581E0: B11F0788  sth r8, 0x788(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(1928 as u32), ctx.r[8].u16 ) };
	// 831581E4: 917F078C  stw r11, 0x78c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(1932 as u32), ctx.r[11].u32 ) };
	// 831581E8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831581EC: 814B0030  lwz r10, 0x30(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(48 as u32) ) } as u64;
	// 831581F0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831581F4: 4E800421  bctrl
	ctx.lr = 0x831581F8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831581F8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831581FC: 409A0040  bne cr6, 0x8315823c
	if !ctx.cr[6].eq {
	pc = 0x8315823C; continue 'dispatch;
	}
	// 83158200: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158204: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83158208: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315820C: 814B002C  lwz r10, 0x2c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(44 as u32) ) } as u64;
	// 83158210: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158214: 4E800421  bctrl
	ctx.lr = 0x83158218;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158218: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315821C: 48000024  b 0x83158240
	pc = 0x83158240; continue 'dispatch;
	// 83158220: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158224: 38A0FFFD  li r5, -3
	ctx.r[5].s64 = -3;
	// 83158228: 388B5A2C  addi r4, r11, 0x5a2c
	ctx.r[4].s64 = ctx.r[11].s64 + 23084;
	// 8315822C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158230: 48007911  bl 0x8315fb40
	ctx.lr = 0x83158234;
	sub_8315FB40(ctx, base);
	// 83158234: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158238: 48000008  b 0x83158240
	pc = 0x83158240; continue 'dispatch;
	// 8315823C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83158240: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83158244: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83158248: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315824C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83158250: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158254: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158258(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83158258 size=836
    let mut pc: u32 = 0x83158258;
    'dispatch: loop {
        match pc {
            0x83158258 => {
    //   block [0x83158258..0x831582C0)
	// 83158258: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315825C: 4804FF09  bl 0x831a8164
	ctx.lr = 0x83158260;
	sub_831A8130(ctx, base);
	// 83158260: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158264: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 83158268: 4BFFFD29  bl 0x83157f90
	ctx.lr = 0x8315826C;
	sub_83157F90(ctx, base);
	// 8315826C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83158270: 419A0320  beq cr6, 0x83158590
	if ctx.cr[6].eq {
	pc = 0x83158590; continue 'dispatch;
	}
	// 83158274: 817C0780  lwz r11, 0x780(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1920 as u32) ) } as u64;
	// 83158278: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315827C: 419A0314  beq cr6, 0x83158590
	if ctx.cr[6].eq {
	pc = 0x83158590; continue 'dispatch;
	}
	// 83158280: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83158284: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83158288: 419A0308  beq cr6, 0x83158590
	if ctx.cr[6].eq {
	pc = 0x83158590; continue 'dispatch;
	}
	// 8315828C: 817C0778  lwz r11, 0x778(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1912 as u32) ) } as u64;
	// 83158290: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 83158294: 419902F0  bgt cr6, 0x83158584
	if ctx.cr[6].gt {
	pc = 0x83158584; continue 'dispatch;
	}
	// 83158298: 3D808316  lis r12, -0x7cea
	ctx.r[12].s64 = -2095710208;
	// 8315829C: 398C82B0  addi r12, r12, -0x7d50
	ctx.r[12].s64 = ctx.r[12].s64 + -32080;
	// 831582A0: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 831582A4: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 831582A8: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 831582AC: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x831582C0; continue 'dispatch;
		},
		1 => {
	pc = 0x83158364; continue 'dispatch;
		},
		2 => {
	pc = 0x831583DC; continue 'dispatch;
		},
		3 => {
	pc = 0x83158474; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 831582B0: 831582C0  lwz r24, -0x7d40(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-32064 as u32) ) } as u64;
	// 831582B4: 83158364  lwz r24, -0x7c9c(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-31900 as u32) ) } as u64;
	// 831582B8: 831583DC  lwz r24, -0x7c24(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-31780 as u32) ) } as u64;
	// 831582BC: 83158474  lwz r24, -0x7b8c(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-31628 as u32) ) } as u64;
            }
            0x831582C0 => {
    //   block [0x831582C0..0x83158364)
	// 831582C0: 807C03B0  lwz r3, 0x3b0(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(944 as u32) ) } as u64;
	// 831582C4: 4BFE7C05  bl 0x8313fec8
	ctx.lr = 0x831582C8;
	sub_8313FEC8(ctx, base);
	// 831582C8: 817C03AC  lwz r11, 0x3ac(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(940 as u32) ) } as u64;
	// 831582CC: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 831582D0: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 831582D4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831582D8: 409A0028  bne cr6, 0x83158300
	if !ctx.cr[6].eq {
	pc = 0x83158300; continue 'dispatch;
	}
	// 831582DC: 4BFFE165  bl 0x83156440
	ctx.lr = 0x831582E0;
	sub_83156440(ctx, base);
	// 831582E0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 831582E4: 409A0014  bne cr6, 0x831582f8
	if !ctx.cr[6].eq {
	pc = 0x831582F8; continue 'dispatch;
	}
	// 831582E8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831582EC: 388B5A70  addi r4, r11, 0x5a70
	ctx.r[4].s64 = ctx.r[11].s64 + 23152;
	// 831582F0: 48007829  bl 0x8315fb18
	ctx.lr = 0x831582F4;
	sub_8315FB18(ctx, base);
	// 831582F4: 4800000C  b 0x83158300
	pc = 0x83158300; continue 'dispatch;
	// 831582F8: 907C03AC  stw r3, 0x3ac(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(940 as u32), ctx.r[3].u32 ) };
	// 831582FC: 3BA00001  li r29, 1
	ctx.r[29].s64 = 1;
	// 83158300: 3BDC0028  addi r30, r28, 0x28
	ctx.r[30].s64 = ctx.r[28].s64 + 40;
	// 83158304: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158308: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315830C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83158310: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158314: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158318: 4E800421  bctrl
	ctx.lr = 0x8315831C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315831C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158320: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158324: 419A000C  beq cr6, 0x83158330
	if ctx.cr[6].eq {
	pc = 0x83158330; continue 'dispatch;
	}
	// 83158328: 37EBFFF8  addic. r31, r11, -8
	ctx.xer.ca = (ctx.r[11].u32 > (!(-8 as u32)));
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8315832C: 4082FFD8  bne 0x83158304
	if !ctx.cr[0].eq {
	pc = 0x83158304; continue 'dispatch;
	}
	// 83158330: 2F1D0001  cmpwi cr6, r29, 1
	ctx.cr[6].compare_i32(ctx.r[29].s32, 1, &mut ctx.xer);
	// 83158334: 409A0250  bne cr6, 0x83158584
	if !ctx.cr[6].eq {
	pc = 0x83158584; continue 'dispatch;
	}
	// 83158338: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8315833C: 809C03AC  lwz r4, 0x3ac(r28)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(940 as u32) ) } as u64;
	// 83158340: 4BFFE169  bl 0x831564a8
	ctx.lr = 0x83158344;
	sub_831564A8(ctx, base);
	// 83158344: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 83158348: 409A023C  bne cr6, 0x83158584
	if !ctx.cr[6].eq {
	pc = 0x83158584; continue 'dispatch;
	}
	// 8315834C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158350: 388B5A48  addi r4, r11, 0x5a48
	ctx.r[4].s64 = ctx.r[11].s64 + 23112;
	// 83158354: 480077C5  bl 0x8315fb18
	ctx.lr = 0x83158358;
	sub_8315FB18(ctx, base);
	// 83158358: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315835C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83158360: 4804FE54  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            0x83158364 => {
    //   block [0x83158364..0x831583DC)
	// 83158364: 4BFFDFD5  bl 0x83156338
	ctx.lr = 0x83158368;
	sub_83156338(ctx, base);
	// 83158368: 815C077C  lwz r10, 0x77c(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 8315836C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 83158370: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83158374: 409A000C  bne cr6, 0x83158380
	if !ctx.cr[6].eq {
	pc = 0x83158380; continue 'dispatch;
	}
	// 83158378: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315837C: 48000024  b 0x831583a0
	pc = 0x831583A0; continue 'dispatch;
	// 83158380: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158384: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158388: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315838C: 4E800421  bctrl
	ctx.lr = 0x83158390;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158390: 815C077C  lwz r10, 0x77c(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 83158394: 7D235396  divwu r9, r3, r10
	ctx.r[9].u32 = ctx.r[3].u32 / ctx.r[10].u32;
	// 83158398: 7D0951D6  mullw r8, r9, r10
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 8315839C: 7FC81850  subf r30, r8, r3
	ctx.r[30].s64 = ctx.r[3].s64 - ctx.r[8].s64;
	// 831583A0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831583A4: 7F0AF040  cmplw cr6, r10, r30
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[30].u32, &mut ctx.xer);
	// 831583A8: 419A01C0  beq cr6, 0x83158568
	if ctx.cr[6].eq {
	pc = 0x83158568; continue 'dispatch;
	}
	// 831583AC: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 831583B0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 831583B4: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 831583B8: 409A0008  bne cr6, 0x831583c0
	if !ctx.cr[6].eq {
	pc = 0x831583C0; continue 'dispatch;
	}
	// 831583BC: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 831583C0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831583C4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831583C8: 409AFFDC  bne cr6, 0x831583a4
	if !ctx.cr[6].eq {
	pc = 0x831583A4; continue 'dispatch;
	}
	// 831583CC: B3DC0788  sth r30, 0x788(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(1928 as u32), ctx.r[30].u16 ) };
	// 831583D0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831583D4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831583D8: 4804FDDC  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            0x831583DC => {
    //   block [0x831583DC..0x83158474)
	// 831583DC: A15C0788  lhz r10, 0x788(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(1928 as u32) ) } as u64;
	// 831583E0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 831583E4: 813C077C  lwz r9, 0x77c(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 831583E8: 38EA0001  addi r7, r10, 1
	ctx.r[7].s64 = ctx.r[10].s64 + 1;
	// 831583EC: 7D260734  extsh r6, r9
	ctx.r[6].s64 = ctx.r[9].s16 as i64;
	// 831583F0: 7CE50734  extsh r5, r7
	ctx.r[5].s64 = ctx.r[7].s16 as i64;
	// 831583F4: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 831583F8: B0BC0788  sth r5, 0x788(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(1928 as u32), ctx.r[5].u16 ) };
	// 831583FC: 7F043000  cmpw cr6, r4, r6
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[6].s32, &mut ctx.xer);
	// 83158400: 4198000C  blt cr6, 0x8315840c
	if ctx.cr[6].lt {
	pc = 0x8315840C; continue 'dispatch;
	}
	// 83158404: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83158408: B15C0788  sth r10, 0x788(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(1928 as u32), ctx.r[10].u16 ) };
	// 8315840C: A15C0788  lhz r10, 0x788(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83158410: 7D490734  extsh r9, r10
	ctx.r[9].s64 = ctx.r[10].s16 as i64;
	// 83158414: 7D6A0734  extsh r10, r11
	ctx.r[10].s64 = ctx.r[11].s16 as i64;
	// 83158418: 7F0A4800  cmpw cr6, r10, r9
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[9].s32, &mut ctx.xer);
	// 8315841C: 419A0034  beq cr6, 0x83158450
	if ctx.cr[6].eq {
	pc = 0x83158450; continue 'dispatch;
	}
	// 83158420: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158424: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158428: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 8315842C: 409A0008  bne cr6, 0x83158434
	if !ctx.cr[6].eq {
	pc = 0x83158434; continue 'dispatch;
	}
	// 83158430: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 83158434: 396A0001  addi r11, r10, 1
	ctx.r[11].s64 = ctx.r[10].s64 + 1;
	// 83158438: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315843C: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 83158440: 409AFFD4  bne cr6, 0x83158414
	if !ctx.cr[6].eq {
	pc = 0x83158414; continue 'dispatch;
	}
	// 83158444: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83158448: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315844C: 4804FD68  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 83158450: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158454: 389C0028  addi r4, r28, 0x28
	ctx.r[4].s64 = ctx.r[28].s64 + 40;
	// 83158458: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315845C: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158460: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158464: 4E800421  bctrl
	ctx.lr = 0x83158468;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158468: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315846C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83158470: 4804FD44  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            0x83158474 => {
    //   block [0x83158474..0x8315859C)
	// 83158474: 4BFFDEC5  bl 0x83156338
	ctx.lr = 0x83158478;
	sub_83156338(ctx, base);
	// 83158478: 815C077C  lwz r10, 0x77c(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 8315847C: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 83158480: 2B0A0002  cmplwi cr6, r10, 2
	ctx.cr[6].compare_u32(ctx.r[10].u32, 2 as u32, &mut ctx.xer);
	// 83158484: A15C0788  lhz r10, 0x788(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83158488: 409A0044  bne cr6, 0x831584cc
	if !ctx.cr[6].eq {
	pc = 0x831584CC; continue 'dispatch;
	}
	// 8315848C: 2B0A8000  cmplwi cr6, r10, 0x8000
	ctx.cr[6].compare_u32(ctx.r[10].u32, 32768 as u32, &mut ctx.xer);
	// 83158490: 41980028  blt cr6, 0x831584b8
	if ctx.cr[6].lt {
	pc = 0x831584B8; continue 'dispatch;
	}
	// 83158494: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158498: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315849C: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831584A0: 4E800421  bctrl
	ctx.lr = 0x831584A4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831584A4: 815C077C  lwz r10, 0x77c(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 831584A8: 7D235396  divwu r9, r3, r10
	ctx.r[9].u32 = ctx.r[3].u32 / ctx.r[10].u32;
	// 831584AC: 7D0951D6  mullw r8, r9, r10
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831584B0: 7FC81850  subf r30, r8, r3
	ctx.r[30].s64 = ctx.r[3].s64 - ctx.r[8].s64;
	// 831584B4: 48000078  b 0x8315852c
	pc = 0x8315852C; continue 'dispatch;
	// 831584B8: A17C0788  lhz r11, 0x788(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(1928 as u32) ) } as u64;
	// 831584BC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 831584C0: 394BFFFF  addi r10, r11, -1
	ctx.r[10].s64 = ctx.r[11].s64 + -1;
	// 831584C4: 555E07FE  clrlwi r30, r10, 0x1f
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0x00000001u64;
	// 831584C8: 48000064  b 0x8315852c
	pc = 0x8315852C; continue 'dispatch;
	// 831584CC: 806B0004  lwz r3, 4(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831584D0: 2B0A8000  cmplwi cr6, r10, 0x8000
	ctx.cr[6].compare_u32(ctx.r[10].u32, 32768 as u32, &mut ctx.xer);
	// 831584D4: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831584D8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 831584DC: 4198001C  blt cr6, 0x831584f8
	if ctx.cr[6].lt {
	pc = 0x831584F8; continue 'dispatch;
	}
	// 831584E0: 4E800421  bctrl
	ctx.lr = 0x831584E4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831584E4: 815C077C  lwz r10, 0x77c(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 831584E8: 7D235396  divwu r9, r3, r10
	ctx.r[9].u32 = ctx.r[3].u32 / ctx.r[10].u32;
	// 831584EC: 7D0951D6  mullw r8, r9, r10
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[10].s32 as i64);
	// 831584F0: 7FC81850  subf r30, r8, r3
	ctx.r[30].s64 = ctx.r[3].s64 - ctx.r[8].s64;
	// 831584F4: 48000038  b 0x8315852c
	pc = 0x8315852C; continue 'dispatch;
	// 831584F8: 4E800421  bctrl
	ctx.lr = 0x831584FC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831584FC: 817C077C  lwz r11, 0x77c(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1916 as u32) ) } as u64;
	// 83158500: A15C0788  lhz r10, 0x788(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[28].u32.wrapping_add(1928 as u32) ) } as u64;
	// 83158504: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 83158508: 7D4A0734  extsh r10, r10
	ctx.r[10].s64 = ctx.r[10].s16 as i64;
	// 8315850C: 7D034B96  divwu r8, r3, r9
	ctx.r[8].u32 = ctx.r[3].u32 / ctx.r[9].u32;
	// 83158510: 7CE849D6  mullw r7, r8, r9
	ctx.r[7].s64 = (ctx.r[8].s32 as i64) * (ctx.r[9].s32 as i64);
	// 83158514: 7D271850  subf r9, r7, r3
	ctx.r[9].s64 = ctx.r[3].s64 - ctx.r[7].s64;
	// 83158518: 7D495214  add r10, r9, r10
	ctx.r[10].u64 = ctx.r[9].u64 + ctx.r[10].u64;
	// 8315851C: 38CA0001  addi r6, r10, 1
	ctx.r[6].s64 = ctx.r[10].s64 + 1;
	// 83158520: 7CA65B96  divwu r5, r6, r11
	ctx.r[5].u32 = ctx.r[6].u32 / ctx.r[11].u32;
	// 83158524: 7C8559D6  mullw r4, r5, r11
	ctx.r[4].s64 = (ctx.r[5].s32 as i64) * (ctx.r[11].s32 as i64);
	// 83158528: 7FC43050  subf r30, r4, r6
	ctx.r[30].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 8315852C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83158530: 7F0AF040  cmplw cr6, r10, r30
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[30].u32, &mut ctx.xer);
	// 83158534: 419A0034  beq cr6, 0x83158568
	if ctx.cr[6].eq {
	pc = 0x83158568; continue 'dispatch;
	}
	// 83158538: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315853C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158540: 3BEBFFF8  addi r31, r11, -8
	ctx.r[31].s64 = ctx.r[11].s64 + -8;
	// 83158544: 409A0008  bne cr6, 0x8315854c
	if !ctx.cr[6].eq {
	pc = 0x8315854C; continue 'dispatch;
	}
	// 83158548: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8315854C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 83158550: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83158554: 409AFFDC  bne cr6, 0x83158530
	if !ctx.cr[6].eq {
	pc = 0x83158530; continue 'dispatch;
	}
	// 83158558: B3DC0788  sth r30, 0x788(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(1928 as u32), ctx.r[30].u16 ) };
	// 8315855C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83158560: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83158564: 4804FC50  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 83158568: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315856C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83158570: 389C0028  addi r4, r28, 0x28
	ctx.r[4].s64 = ctx.r[28].s64 + 40;
	// 83158574: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158578: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315857C: 4E800421  bctrl
	ctx.lr = 0x83158580;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158580: B3DC0788  sth r30, 0x788(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(1928 as u32), ctx.r[30].u16 ) };
	// 83158584: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83158588: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315858C: 4804FC28  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 83158590: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158594: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83158598: 4804FC1C  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831585A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x831585A0 size=108
    let mut pc: u32 = 0x831585A0;
    'dispatch: loop {
        match pc {
            0x831585A0 => {
    //   block [0x831585A0..0x8315860C)
	// 831585A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831585A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831585A8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831585AC: 81630008  lwz r11, 8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 831585B0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 831585B4: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831585B8: 41980040  blt cr6, 0x831585f8
	if ctx.cr[6].lt {
	pc = 0x831585F8; continue 'dispatch;
	}
	// 831585BC: 419A0028  beq cr6, 0x831585e4
	if ctx.cr[6].eq {
	pc = 0x831585E4; continue 'dispatch;
	}
	// 831585C0: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831585C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831585C8: 388B5AB4  addi r4, r11, 0x5ab4
	ctx.r[4].s64 = ctx.r[11].s64 + 23220;
	// 831585CC: 4800754D  bl 0x8315fb18
	ctx.lr = 0x831585D0;
	sub_8315FB18(ctx, base);
	// 831585D0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831585D4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831585D8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831585DC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831585E0: 4E800020  blr
	return;
	// 831585E4: 4BFFFB8D  bl 0x83158170
	ctx.lr = 0x831585E8;
	sub_83158170(ctx, base);
	// 831585E8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831585EC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831585F0: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831585F4: 4E800020  blr
	return;
	// 831585F8: 4BFFFA49  bl 0x83158040
	ctx.lr = 0x831585FC;
	sub_83158040(ctx, base);
	// 831585FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83158600: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83158604: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83158608: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158610(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83158610 size=772
    let mut pc: u32 = 0x83158610;
    'dispatch: loop {
        match pc {
            0x83158610 => {
    //   block [0x83158610..0x8315889C)
	// 83158610: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83158614: 4804FB45  bl 0x831a8158
	ctx.lr = 0x83158618;
	sub_831A8130(ctx, base);
	// 83158618: 9421FD70  stwu r1, -0x290(r1)
	ea = ctx.r[1].u32.wrapping_add(-656 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315861C: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 83158620: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 83158624: 4BFFDF45  bl 0x83156568
	ctx.lr = 0x83158628;
	sub_83156568(ctx, base);
	// 83158628: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315862C: 409A0024  bne cr6, 0x83158650
	if !ctx.cr[6].eq {
	pc = 0x83158650; continue 'dispatch;
	}
	// 83158630: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158634: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 83158638: 814B0034  lwz r10, 0x34(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(52 as u32) ) } as u64;
	// 8315863C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158640: 4E800421  bctrl
	ctx.lr = 0x83158644;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158644: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158648: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 8315864C: 4804FB5C  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
	// 83158650: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 83158654: 3B000001  li r24, 1
	ctx.r[24].s64 = 1;
	// 83158658: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315865C: 7FD9F378  mr r25, r30
	ctx.r[25].u64 = ctx.r[30].u64;
	// 83158660: C00B08A4  lfs f0, 0x8a4(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158664: 7FDAF378  mr r26, r30
	ctx.r[26].u64 = ctx.r[30].u64;
	// 83158668: D01D03F0  stfs f0, 0x3f0(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1008 as u32), tmp.u32 ) };
	// 8315866C: 815C0008  lwz r10, 8(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158670: C00A0014  lfs f0, 0x14(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(20 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158674: 931D001C  stw r24, 0x1c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), ctx.r[24].u32 ) };
	// 83158678: D01D03F4  stfs f0, 0x3f4(r29)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1012 as u32), tmp.u32 ) };
	// 8315867C: 813C0008  lwz r9, 8(r28)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158680: 8149000C  lwz r10, 0xc(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158684: 890A0000  lbz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158688: 7D0B0774  extsb r11, r8
	ctx.r[11].s64 = ctx.r[8].s8 as i64;
	// 8315868C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83158690: 419A0024  beq cr6, 0x831586b4
	if ctx.cr[6].eq {
	pc = 0x831586B4; continue 'dispatch;
	}
	// 83158694: 2F0B000A  cmpwi cr6, r11, 0xa
	ctx.cr[6].compare_i32(ctx.r[11].s32, 10, &mut ctx.xer);
	// 83158698: 409A0008  bne cr6, 0x831586a0
	if !ctx.cr[6].eq {
	pc = 0x831586A0; continue 'dispatch;
	}
	// 8315869C: 3B5A0001  addi r26, r26, 1
	ctx.r[26].s64 = ctx.r[26].s64 + 1;
	// 831586A0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831586A4: 896A0000  lbz r11, 0(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 831586A8: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 831586AC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831586B0: 409AFFE4  bne cr6, 0x83158694
	if !ctx.cr[6].eq {
	pc = 0x83158694; continue 'dispatch;
	}
	// 831586B4: 817D0014  lwz r11, 0x14(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(20 as u32) ) } as u64;
	// 831586B8: 7FDBF378  mr r27, r30
	ctx.r[27].u64 = ctx.r[30].u64;
	// 831586BC: 815C0004  lwz r10, 4(r28)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 831586C0: 2B1A0000  cmplwi cr6, r26, 0
	ctx.cr[6].compare_u32(ctx.r[26].u32, 0 as u32, &mut ctx.xer);
	// 831586C4: 93A1005C  stw r29, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[29].u32 ) };
	// 831586C8: 91610050  stw r11, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 831586CC: 91410054  stw r10, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[10].u32 ) };
	// 831586D0: 419A0158  beq cr6, 0x83158828
	if ctx.cr[6].eq {
	pc = 0x83158828; continue 'dispatch;
	}
	// 831586D4: 93C10060  stw r30, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[30].u32 ) };
	// 831586D8: 396100F0  addi r11, r1, 0xf0
	ctx.r[11].s64 = ctx.r[1].s64 + 240;
	// 831586DC: 93C1006C  stw r30, 0x6c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(108 as u32), ctx.r[30].u32 ) };
	// 831586E0: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 831586E4: 93C10070  stw r30, 0x70(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[30].u32 ) };
	// 831586E8: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 831586EC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831586F0: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 831586F4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831586F8: 4200FFF8  bdnz 0x831586f0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x831586F0; continue 'dispatch;
	}
	// 831586FC: 39610110  addi r11, r1, 0x110
	ctx.r[11].s64 = ctx.r[1].s64 + 272;
	// 83158700: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 83158704: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 83158708: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315870C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83158710: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83158714: 4200FFF8  bdnz 0x8315870c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315870C; continue 'dispatch;
	}
	// 83158718: 93C10130  stw r30, 0x130(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(304 as u32), ctx.r[30].u32 ) };
	// 8315871C: 39610138  addi r11, r1, 0x138
	ctx.r[11].s64 = ctx.r[1].s64 + 312;
	// 83158720: 93C10134  stw r30, 0x134(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(308 as u32), ctx.r[30].u32 ) };
	// 83158724: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 83158728: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 8315872C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158730: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83158734: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83158738: 4200FFF8  bdnz 0x83158730
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83158730; continue 'dispatch;
	}
	// 8315873C: 39610158  addi r11, r1, 0x158
	ctx.r[11].s64 = ctx.r[1].s64 + 344;
	// 83158740: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 83158744: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 83158748: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315874C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83158750: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83158754: 4200FFF8  bdnz 0x8315874c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315874C; continue 'dispatch;
	}
	// 83158758: 3961017C  addi r11, r1, 0x17c
	ctx.r[11].s64 = ctx.r[1].s64 + 380;
	// 8315875C: 93C10178  stw r30, 0x178(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(376 as u32), ctx.r[30].u32 ) };
	// 83158760: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 83158764: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 83158768: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315876C: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83158770: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83158774: 4200FFF8  bdnz 0x8315876c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315876C; continue 'dispatch;
	}
	// 83158778: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315877C: 38A101C0  addi r5, r1, 0x1c0
	ctx.r[5].s64 = ctx.r[1].s64 + 448;
	// 83158780: 7F64DB78  mr r4, r27
	ctx.r[4].u64 = ctx.r[27].u64;
	// 83158784: 806B000C  lwz r3, 0xc(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158788: 4BFEA9C9  bl 0x83143150
	ctx.lr = 0x8315878C;
	sub_83143150(ctx, base);
	// 8315878C: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 83158790: 807C0004  lwz r3, 4(r28)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(4 as u32) ) } as u64;
	// 83158794: 388101C0  addi r4, r1, 0x1c0
	ctx.r[4].s64 = ctx.r[1].s64 + 448;
	// 83158798: 4BFECE29  bl 0x831455c0
	ctx.lr = 0x8315879C;
	sub_831455C0(ctx, base);
	// 8315879C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 831587A0: 419A00E4  beq cr6, 0x83158884
	if ctx.cr[6].eq {
	pc = 0x83158884; continue 'dispatch;
	}
	// 831587A4: 81610064  lwz r11, 0x64(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 831587A8: 39410060  addi r10, r1, 0x60
	ctx.r[10].s64 = ctx.r[1].s64 + 96;
	// 831587AC: 91410058  stw r10, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[10].u32 ) };
	// 831587B0: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 831587B4: 41980014  blt cr6, 0x831587c8
	if ctx.cr[6].lt {
	pc = 0x831587C8; continue 'dispatch;
	}
	// 831587B8: 409A00B0  bne cr6, 0x83158868
	if !ctx.cr[6].eq {
	pc = 0x83158868; continue 'dispatch;
	}
	// 831587BC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831587C0: 4BFFF9B1  bl 0x83158170
	ctx.lr = 0x831587C4;
	sub_83158170(ctx, base);
	// 831587C4: 4800000C  b 0x831587d0
	pc = 0x831587D0; continue 'dispatch;
	// 831587C8: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 831587CC: 4BFFF875  bl 0x83158040
	ctx.lr = 0x831587D0;
	sub_83158040(ctx, base);
	// 831587D0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 831587D4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 831587D8: 419A00A0  beq cr6, 0x83158878
	if ctx.cr[6].eq {
	pc = 0x83158878; continue 'dispatch;
	}
	// 831587DC: 389F0008  addi r4, r31, 8
	ctx.r[4].s64 = ctx.r[31].s64 + 8;
	// 831587E0: 387D0780  addi r3, r29, 0x780
	ctx.r[3].s64 = ctx.r[29].s64 + 1920;
	// 831587E4: 4BFF2C7D  bl 0x8314b460
	ctx.lr = 0x831587E8;
	sub_8314B460(ctx, base);
	// 831587E8: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 831587EC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831587F0: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 831587F4: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 831587F8: 4E800421  bctrl
	ctx.lr = 0x831587FC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 831587FC: 7F191840  cmplw cr6, r25, r3
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[3].u32, &mut ctx.xer);
	// 83158800: 4199001C  bgt cr6, 0x8315881c
	if ctx.cr[6].gt {
	pc = 0x8315881C; continue 'dispatch;
	}
	// 83158804: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158808: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315880C: 814B0028  lwz r10, 0x28(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 83158810: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158814: 4E800421  bctrl
	ctx.lr = 0x83158818;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158818: 7C791B78  mr r25, r3
	ctx.r[25].u64 = ctx.r[3].u64;
	// 8315881C: 3B7B0001  addi r27, r27, 1
	ctx.r[27].s64 = ctx.r[27].s64 + 1;
	// 83158820: 7F1BD040  cmplw cr6, r27, r26
	ctx.cr[6].compare_u32(ctx.r[27].u32, ctx.r[26].u32, &mut ctx.xer);
	// 83158824: 4198FEB0  blt cr6, 0x831586d4
	if ctx.cr[6].lt {
	pc = 0x831586D4; continue 'dispatch;
	}
	// 83158828: 933D078C  stw r25, 0x78c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1932 as u32), ctx.r[25].u32 ) };
	// 8315882C: 935D077C  stw r26, 0x77c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1916 as u32), ctx.r[26].u32 ) };
	// 83158830: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158834: 816B0008  lwz r11, 8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158838: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 8315883C: 419900A8  bgt cr6, 0x831588e4
	if ctx.cr[6].gt {
	pc = 0x831588E4; continue 'dispatch;
	}
	// 83158840: 3D808316  lis r12, -0x7cea
	ctx.r[12].s64 = -2095710208;
	// 83158844: 398C8858  addi r12, r12, -0x77a8
	ctx.r[12].s64 = ctx.r[12].s64 + -30632;
	// 83158848: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8315884C: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 83158850: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 83158854: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8315889C; continue 'dispatch;
		},
		1 => {
	pc = 0x831588AC; continue 'dispatch;
		},
		2 => {
	pc = 0x831588BC; continue 'dispatch;
		},
		3 => {
	pc = 0x831588D0; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 83158858: 8315889C  lwz r24, -0x7764(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-30564 as u32) ) } as u64;
	// 8315885C: 831588AC  lwz r24, -0x7754(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-30548 as u32) ) } as u64;
	// 83158860: 831588BC  lwz r24, -0x7744(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-30532 as u32) ) } as u64;
	// 83158864: 831588D0  lwz r24, -0x7730(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-30512 as u32) ) } as u64;
	// 83158868: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315886C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158870: 388B5AB4  addi r4, r11, 0x5ab4
	ctx.r[4].s64 = ctx.r[11].s64 + 23220;
	// 83158874: 480072A5  bl 0x8315fb18
	ctx.lr = 0x83158878;
	sub_8315FB18(ctx, base);
	// 83158878: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315887C: 388B5B34  addi r4, r11, 0x5b34
	ctx.r[4].s64 = ctx.r[11].s64 + 23348;
	// 83158880: 4800006C  b 0x831588ec
	pc = 0x831588EC; continue 'dispatch;
	// 83158884: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158888: 38A101C0  addi r5, r1, 0x1c0
	ctx.r[5].s64 = ctx.r[1].s64 + 448;
	// 8315888C: 388B5B08  addi r4, r11, 0x5b08
	ctx.r[4].s64 = ctx.r[11].s64 + 23304;
	// 83158890: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158894: 48007295  bl 0x8315fb28
	ctx.lr = 0x83158898;
	sub_8315FB28(ctx, base);
	// 83158898: 4800005C  b 0x831588f4
	pc = 0x831588F4; continue 'dispatch;
            }
            0x8315889C => {
    //   block [0x8315889C..0x831588AC)
	// 8315889C: 93DD0778  stw r30, 0x778(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1912 as u32), ctx.r[30].u32 ) };
	// 831588A0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831588A4: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 831588A8: 4804F900  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            0x831588AC => {
    //   block [0x831588AC..0x831588BC)
	// 831588AC: 931D0778  stw r24, 0x778(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1912 as u32), ctx.r[24].u32 ) };
	// 831588B0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831588B4: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 831588B8: 4804F8F0  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            0x831588BC => {
    //   block [0x831588BC..0x831588D0)
	// 831588BC: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 831588C0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831588C4: 917D0778  stw r11, 0x778(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 831588C8: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 831588CC: 4804F8DC  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            0x831588D0 => {
    //   block [0x831588D0..0x83158914)
	// 831588D0: 39600003  li r11, 3
	ctx.r[11].s64 = 3;
	// 831588D4: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 831588D8: 917D0778  stw r11, 0x778(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(1912 as u32), ctx.r[11].u32 ) };
	// 831588DC: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 831588E0: 4804F8C8  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
	// 831588E4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 831588E8: 388B5AE0  addi r4, r11, 0x5ae0
	ctx.r[4].s64 = ctx.r[11].s64 + 23264;
	// 831588EC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 831588F0: 48007229  bl 0x8315fb18
	ctx.lr = 0x831588F4;
	sub_8315FB18(ctx, base);
	// 831588F4: 815D0000  lwz r10, 0(r29)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 831588F8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 831588FC: 812A0034  lwz r9, 0x34(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(52 as u32) ) } as u64;
	// 83158900: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 83158904: 4E800421  bctrl
	ctx.lr = 0x83158908;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158908: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315890C: 38210290  addi r1, r1, 0x290
	ctx.r[1].s64 = ctx.r[1].s64 + 656;
	// 83158910: 4804F898  b 0x831a81a8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158918(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83158918 size=20
    let mut pc: u32 = 0x83158918;
    'dispatch: loop {
        match pc {
            0x83158918 => {
    //   block [0x83158918..0x8315892C)
	// 83158918: 8163012C  lwz r11, 0x12c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(300 as u32) ) } as u64;
	// 8315891C: 3863012C  addi r3, r3, 0x12c
	ctx.r[3].s64 = ctx.r[3].s64 + 300;
	// 83158920: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158924: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158928: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158930(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83158930 size=160
    let mut pc: u32 = 0x83158930;
    'dispatch: loop {
        match pc {
            0x83158930 => {
    //   block [0x83158930..0x831589D0)
	// 83158930: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83158934: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83158938: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315893C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158940: 81640048  lwz r11, 0x48(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(72 as u32) ) } as u64;
	// 83158944: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83158948: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 8315894C: C004004C  lfs f0, 0x4c(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(76 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158950: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 83158954: D01F004C  stfs f0, 0x4c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), tmp.u32 ) };
	// 83158958: 915F0040  stw r10, 0x40(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[10].u32 ) };
	// 8315895C: 913F0044  stw r9, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[9].u32 ) };
	// 83158960: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 83158964: 81040040  lwz r8, 0x40(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(64 as u32) ) } as u64;
	// 83158968: 2B080008  cmplwi cr6, r8, 8
	ctx.cr[6].compare_u32(ctx.r[8].u32, 8 as u32, &mut ctx.xer);
	// 8315896C: 419A0018  beq cr6, 0x83158984
	if ctx.cr[6].eq {
	pc = 0x83158984; continue 'dispatch;
	}
	// 83158970: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158974: 38A0FFFF  li r5, -1
	ctx.r[5].s64 = -1;
	// 83158978: 388B5B80  addi r4, r11, 0x5b80
	ctx.r[4].s64 = ctx.r[11].s64 + 23424;
	// 8315897C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83158980: 480071C1  bl 0x8315fb40
	ctx.lr = 0x83158984;
	sub_8315FB40(ctx, base);
	// 83158984: 817F0040  lwz r11, 0x40(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 83158988: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8315898C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158990: 40990028  ble cr6, 0x831589b8
	if !ctx.cr[6].gt {
	pc = 0x831589B8; continue 'dispatch;
	}
	// 83158994: 7FEAFB78  mr r10, r31
	ctx.r[10].u64 = ctx.r[31].u64;
	// 83158998: 397F0060  addi r11, r31, 0x60
	ctx.r[11].s64 = ctx.r[31].s64 + 96;
	// 8315899C: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 831589A0: 916A0000  stw r11, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 831589A4: 811F0040  lwz r8, 0x40(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(64 as u32) ) } as u64;
	// 831589A8: 396B0204  addi r11, r11, 0x204
	ctx.r[11].s64 = ctx.r[11].s64 + 516;
	// 831589AC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831589B0: 7F094040  cmplw cr6, r9, r8
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831589B4: 4198FFE8  blt cr6, 0x8315899c
	if ctx.cr[6].lt {
	pc = 0x8315899C; continue 'dispatch;
	}
	// 831589B8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 831589BC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 831589C0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 831589C4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 831589C8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 831589CC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831589D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831589D0 size=28
    let mut pc: u32 = 0x831589D0;
    'dispatch: loop {
        match pc {
            0x831589D0 => {
    //   block [0x831589D0..0x831589EC)
	// 831589D0: D0230100  stfs f1, 0x100(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 831589D4: 908300EC  stw r4, 0xec(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(236 as u32), ctx.r[4].u32 ) };
	// 831589D8: 90A300F0  stw r5, 0xf0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(240 as u32), ctx.r[5].u32 ) };
	// 831589DC: 90C300F4  stw r6, 0xf4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(244 as u32), ctx.r[6].u32 ) };
	// 831589E0: 90E300F8  stw r7, 0xf8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(248 as u32), ctx.r[7].u32 ) };
	// 831589E4: 910300FC  stw r8, 0xfc(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(252 as u32), ctx.r[8].u32 ) };
	// 831589E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831589F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x831589F0 size=16
    let mut pc: u32 = 0x831589F0;
    'dispatch: loop {
        match pc {
            0x831589F0 => {
    //   block [0x831589F0..0x83158A00)
	// 831589F0: C0030104  lfs f0, 0x104(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(260 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831589F4: D0030108  stfs f0, 0x108(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 831589F8: D0230104  stfs f1, 0x104(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 831589FC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158A00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158A00 size=12
    let mut pc: u32 = 0x83158A00;
    'dispatch: loop {
        match pc {
            0x83158A00 => {
    //   block [0x83158A00..0x83158A0C)
	// 83158A00: D0230104  stfs f1, 0x104(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(260 as u32), tmp.u32 ) };
	// 83158A04: D0230108  stfs f1, 0x108(r3)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 83158A08: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158A10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83158A10 size=8
    let mut pc: u32 = 0x83158A10;
    'dispatch: loop {
        match pc {
            0x83158A10 => {
    //   block [0x83158A10..0x83158A18)
	// 83158A10: 8063010C  lwz r3, 0x10c(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(268 as u32) ) } as u64;
	// 83158A14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158A18 size=112
    let mut pc: u32 = 0x83158A18;
    'dispatch: loop {
        match pc {
            0x83158A18 => {
    //   block [0x83158A18..0x83158A88)
	// 83158A18: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83158A1C: 3CE08219  lis r7, -0x7de7
	ctx.r[7].s64 = -2112290816;
	// 83158A20: 91630030  stw r11, 0x30(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(48 as u32), ctx.r[11].u32 ) };
	// 83158A24: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 83158A28: 810300EC  lwz r8, 0xec(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(236 as u32) ) } as u64;
	// 83158A2C: 5506003E  slwi r6, r8, 0
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 83158A30: C0075B74  lfs f0, 0x5b74(r7)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(23412 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158A34: 91030034  stw r8, 0x34(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(52 as u32), ctx.r[8].u32 ) };
	// 83158A38: 91230038  stw r9, 0x38(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(56 as u32), ctx.r[9].u32 ) };
	// 83158A3C: D0030028  stfs f0, 0x28(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 83158A40: D003002C  stfs f0, 0x2c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(44 as u32), tmp.u32 ) };
	// 83158A44: 90C30044  stw r6, 0x44(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(68 as u32), ctx.r[6].u32 ) };
	// 83158A48: 810300F0  lwz r8, 0xf0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(240 as u32) ) } as u64;
	// 83158A4C: 39430028  addi r10, r3, 0x28
	ctx.r[10].s64 = ctx.r[3].s64 + 40;
	// 83158A50: 80C30034  lwz r6, 0x34(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(52 as u32) ) } as u64;
	// 83158A54: 7CA83214  add r5, r8, r6
	ctx.r[5].u64 = ctx.r[8].u64 + ctx.r[6].u64;
	// 83158A58: 90A30048  stw r5, 0x48(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(72 as u32), ctx.r[5].u32 ) };
	// 83158A5C: 3963003C  addi r11, r3, 0x3c
	ctx.r[11].s64 = ctx.r[3].s64 + 60;
	// 83158A60: 810300F0  lwz r8, 0xf0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(240 as u32) ) } as u64;
	// 83158A64: 39430050  addi r10, r3, 0x50
	ctx.r[10].s64 = ctx.r[3].s64 + 80;
	// 83158A68: 39230064  addi r9, r3, 0x64
	ctx.r[9].s64 = ctx.r[3].s64 + 100;
	// 83158A6C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 83158A70: 409A0018  bne cr6, 0x83158a88
	if !ctx.cr[6].eq {
		sub_83158A88(ctx, base);
		return;
	}
	// 83158A74: 3D008219  lis r8, -0x7de7
	ctx.r[8].s64 = -2112290816;
	// 83158A78: 39085B70  addi r8, r8, 0x5b70
	ctx.r[8].s64 = ctx.r[8].s64 + 23408;
	// 83158A7C: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158A80: D00B0000  stfs f0, 0(r11)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158A84: 4800002C  b 0x83158ab0
	sub_83158A88(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158A88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158A88 size=192
    let mut pc: u32 = 0x83158A88;
    'dispatch: loop {
        match pc {
            0x83158A88 => {
    //   block [0x83158A88..0x83158B48)
	// 83158A88: 79060020  clrldi r6, r8, 0x20
	ctx.r[6].u64 = ctx.r[8].u64 & 0x00000000FFFFFFFFu64;
	// 83158A8C: 3D008219  lis r8, -0x7de7
	ctx.r[8].s64 = -2112290816;
	// 83158A90: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 83158A94: C801FFF0  lfd f0, -0x10(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158A98: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 83158A9C: 39085B70  addi r8, r8, 0x5b70
	ctx.r[8].s64 = ctx.r[8].s64 + 23408;
	// 83158AA0: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 83158AA4: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158AA8: ED606024  fdivs f11, f0, f12
	ctx.f[11].f64 = ((ctx.f[0].f64 / ctx.f[12].f64) as f32) as f64;
	// 83158AAC: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158AB0: 80CB0008  lwz r6, 8(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158AB4: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83158AB8: 80AB000C  lwz r5, 0xc(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158ABC: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 83158AC0: C0075B74  lfs f0, 0x5b74(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(23412 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158AC4: 908B0010  stw r4, 0x10(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), ctx.r[4].u32 ) };
	// 83158AC8: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 83158ACC: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158AD0: F8C1FFF0  std r6, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[6].u64 ) };
	// 83158AD4: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158AD8: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 83158ADC: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 83158AE0: ED090332  fmuls f8, f9, f12
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[12].f64) as f32) as f64);
	// 83158AE4: FCE04050  fneg f7, f8
	ctx.f[7].u64 = ctx.f[8].u64 ^ 0x8000_0000_0000_0000u64;
	// 83158AE8: D0EB0004  stfs f7, 4(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 83158AEC: 90AA0008  stw r5, 8(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 83158AF0: 80C300F4  lwz r6, 0xf4(r3)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(244 as u32) ) } as u64;
	// 83158AF4: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158AF8: D00A0000  stfs f0, 0(r10)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158AFC: 7D665A14  add r11, r6, r11
	ctx.r[11].u64 = ctx.r[6].u64 + ctx.r[11].u64;
	// 83158B00: D1AA0004  stfs f13, 4(r10)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 83158B04: 908A0010  stw r4, 0x10(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(16 as u32), ctx.r[4].u32 ) };
	// 83158B08: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158B0C: 5566003E  slwi r6, r11, 0
	ctx.r[6].u32 = ctx.r[11].u32.wrapping_shl(0);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 83158B10: 916A000C  stw r11, 0xc(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 83158B14: 90C90008  stw r6, 8(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(8 as u32), ctx.r[6].u32 ) };
	// 83158B18: 816A000C  lwz r11, 0xc(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 83158B1C: 814300F8  lwz r10, 0xf8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(248 as u32) ) } as u64;
	// 83158B20: 7CAB5214  add r5, r11, r10
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 83158B24: 90A9000C  stw r5, 0xc(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 83158B28: C1A30100  lfs f13, 0x100(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(256 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158B2C: 816300F8  lwz r11, 0xf8(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(248 as u32) ) } as u64;
	// 83158B30: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158B34: 409A0014  bne cr6, 0x83158b48
	if !ctx.cr[6].eq {
		sub_83158B48(ctx, base);
		return;
	}
	// 83158B38: ED806828  fsubs f12, f0, f13
	ctx.f[12].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 83158B3C: FD606050  fneg f11, f12
	ctx.f[11].u64 = ctx.f[12].u64 ^ 0x8000_0000_0000_0000u64;
	// 83158B40: D1690000  stfs f11, 0(r9)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158B44: 48000028  b 0x83158b6c
	sub_83158B48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158B48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158B48 size=132
    let mut pc: u32 = 0x83158B48;
    'dispatch: loop {
        match pc {
            0x83158B48 => {
    //   block [0x83158B48..0x83158BCC)
	// 83158B48: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 83158B4C: ED206828  fsubs f9, f0, f13
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[9].f64 = (((ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 83158B50: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 83158B54: C981FFF0  lfd f12, -0x10(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158B58: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 83158B5C: FD405818  frsp f10, f11
	ctx.f[10].f64 = (ctx.f[11].f64 as f32) as f64;
	// 83158B60: ED095024  fdivs f8, f9, f10
	ctx.f[8].f64 = ((ctx.f[9].f64 / ctx.f[10].f64) as f32) as f64;
	// 83158B64: FCE04050  fneg f7, f8
	ctx.f[7].u64 = ctx.f[8].u64 ^ 0x8000_0000_0000_0000u64;
	// 83158B68: D0E90000  stfs f7, 0(r9)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158B6C: 81490008  lwz r10, 8(r9)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158B70: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158B74: C1890000  lfs f12, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83158B78: 39600004  li r11, 4
	ctx.r[11].s64 = 4;
	// 83158B7C: 7D485378  mr r8, r10
	ctx.r[8].u64 = ctx.r[10].u64;
	// 83158B80: C1A75B74  lfs f13, 0x5b74(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(23412 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158B84: 91690010  stw r11, 0x10(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 83158B88: F901FFF0  std r8, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[8].u64 ) };
	// 83158B8C: C961FFF0  lfd f11, -0x10(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158B90: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 83158B94: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 83158B98: ED09033C  fnmsubs f8, f9, f12, f0
	ctx.f[8].f64 = -(((ctx.f[9].f64 * ctx.f[12].f64 - ctx.f[0].f64) as f32) as f64);
	// 83158B9C: D1090004  stfs f8, 4(r9)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 83158BA0: FC006890  fmr f0, f13
	ctx.f[0].f64 = ctx.f[13].f64;
	// 83158BA4: 91630078  stw r11, 0x78(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(120 as u32), ctx.r[11].u32 ) };
	// 83158BA8: D1A3007C  stfs f13, 0x7c(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(124 as u32), tmp.u32 ) };
	// 83158BAC: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 83158BB0: C0E30100  lfs f7, 0x100(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(256 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 83158BB4: D0E30080  stfs f7, 0x80(r3)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 83158BB8: FF070000  fcmpu cr6, f7, f0
	ctx.cr[6].compare_f64(ctx.f[7].f64, ctx.f[0].f64);
	// 83158BBC: 419A0008  beq cr6, 0x83158bc4
	if ctx.cr[6].eq {
	pc = 0x83158BC4; continue 'dispatch;
	}
	// 83158BC0: 39600005  li r11, 5
	ctx.r[11].s64 = 5;
	// 83158BC4: 91630084  stw r11, 0x84(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(132 as u32), ctx.r[11].u32 ) };
	// 83158BC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158BD0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158BD0 size=44
    let mut pc: u32 = 0x83158BD0;
    'dispatch: loop {
        match pc {
            0x83158BD0 => {
    //   block [0x83158BD0..0x83158BFC)
	// 83158BD0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 83158BD4: 91630090  stw r11, 0x90(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(144 as u32), ctx.r[11].u32 ) };
	// 83158BD8: 814300FC  lwz r10, 0xfc(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(252 as u32) ) } as u64;
	// 83158BDC: 91430094  stw r10, 0x94(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(148 as u32), ctx.r[10].u32 ) };
	// 83158BE0: C003001C  lfs f0, 0x1c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158BE4: 816300FC  lwz r11, 0xfc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(252 as u32) ) } as u64;
	// 83158BE8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158BEC: 409A0010  bne cr6, 0x83158bfc
	if !ctx.cr[6].eq {
		sub_83158BFC(ctx, base);
		return;
	}
	// 83158BF0: FDA00050  fneg f13, f0
	ctx.f[13].u64 = ctx.f[0].u64 ^ 0x8000_0000_0000_0000u64;
	// 83158BF4: D1A30088  stfs f13, 0x88(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 83158BF8: 48000024  b 0x83158c1c
	sub_83158BFC(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158BFC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83158BFC size=88
    let mut pc: u32 = 0x83158BFC;
    'dispatch: loop {
        match pc {
            0x83158BFC => {
    //   block [0x83158BFC..0x83158C54)
	// 83158BFC: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 83158C00: F961FFF0  std r11, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[11].u64 ) };
	// 83158C04: C9A1FFF0  lfd f13, -0x10(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83158C08: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 83158C0C: FD606018  frsp f11, f12
	ctx.f[11].f64 = (ctx.f[12].f64 as f32) as f64;
	// 83158C10: ED405824  fdivs f10, f0, f11
	ctx.f[10].f64 = ((ctx.f[0].f64 / ctx.f[11].f64) as f32) as f64;
	// 83158C14: FD205050  fneg f9, f10
	ctx.f[9].u64 = ctx.f[10].u64 ^ 0x8000_0000_0000_0000u64;
	// 83158C18: D1230088  stfs f9, 0x88(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 83158C1C: 39400006  li r10, 6
	ctx.r[10].s64 = 6;
	// 83158C20: C003001C  lfs f0, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158C24: D003008C  stfs f0, 0x8c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 83158C28: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158C2C: 91430098  stw r10, 0x98(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(152 as u32), ctx.r[10].u32 ) };
	// 83158C30: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 83158C34: 39000008  li r8, 8
	ctx.r[8].s64 = 8;
	// 83158C38: 912300D8  stw r9, 0xd8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(216 as u32), ctx.r[9].u32 ) };
	// 83158C3C: 910300E4  stw r8, 0xe4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(228 as u32), ctx.r[8].u32 ) };
	// 83158C40: C00B5B74  lfs f0, 0x5b74(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(23412 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158C44: D00300E0  stfs f0, 0xe0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 83158C48: C1A3001C  lfs f13, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158C4C: D1A300DC  stfs f13, 0xdc(r3)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 83158C50: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83158C58(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83158C58 size=1240
    let mut pc: u32 = 0x83158C58;
    'dispatch: loop {
        match pc {
            0x83158C58 => {
    //   block [0x83158C58..0x83159130)
	// 83158C58: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83158C5C: 4804F4F1  bl 0x831a814c
	ctx.lr = 0x83158C60;
	sub_831A8130(ctx, base);
	// 83158C60: DBE1FF98  stfd f31, -0x68(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-104 as u32), ctx.f[31].u64 ) };
	// 83158C64: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 83158C68: E981E000  ld r12, -0x2000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-8192 as u32) ) };
	// 83158C6C: 9421DE10  stwu r1, -0x21f0(r1)
	ea = ctx.r[1].u32.wrapping_add(-8688 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83158C70: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 83158C74: FFE00890  fmr f31, f1
	ctx.f[31].f64 = ctx.f[1].f64;
	// 83158C78: 7C992378  mr r25, r4
	ctx.r[25].u64 = ctx.r[4].u64;
	// 83158C7C: C01C0104  lfs f0, 0x104(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(260 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158C80: C1BC0108  lfs f13, 0x108(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(264 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158C84: FF006800  fcmpu cr6, f0, f13
	ctx.cr[6].compare_f64(ctx.f[0].f64, ctx.f[13].f64);
	// 83158C88: 409A0248  bne cr6, 0x83158ed0
	if !ctx.cr[6].eq {
	pc = 0x83158ED0; continue 'dispatch;
	}
	// 83158C8C: EFE007F2  fmuls f31, f0, f31
	ctx.f[31].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158C90: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158C94: C00B5B70  lfs f0, 0x5b70(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(23408 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158C98: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 83158C9C: 409A0030  bne cr6, 0x83158ccc
	if !ctx.cr[6].eq {
	pc = 0x83158CCC; continue 'dispatch;
	}
	// 83158CA0: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158CA4: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CA8: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83158CAC: 419A0478  beq cr6, 0x83159124
	if ctx.cr[6].eq {
	pc = 0x83159124; continue 'dispatch;
	}
	// 83158CB0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CB4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CB8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158CBC: 4E800421  bctrl
	ctx.lr = 0x83158CC0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158CC0: 382121F0  addi r1, r1, 0x21f0
	ctx.r[1].s64 = ctx.r[1].s64 + 8688;
	// 83158CC4: CBE1FF98  lfd f31, -0x68(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-104 as u32) ) };
	// 83158CC8: 4804F4D4  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
	// 83158CCC: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83158CD0: C00B5B74  lfs f0, 0x5b74(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(23412 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158CD4: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 83158CD8: 409A0058  bne cr6, 0x83158d30
	if !ctx.cr[6].eq {
	pc = 0x83158D30; continue 'dispatch;
	}
	// 83158CDC: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158CE0: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CE4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83158CE8: 419A0018  beq cr6, 0x83158d00
	if ctx.cr[6].eq {
	pc = 0x83158D00; continue 'dispatch;
	}
	// 83158CEC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CF0: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 83158CF4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158CF8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158CFC: 4E800421  bctrl
	ctx.lr = 0x83158D00;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158D00: 81590044  lwz r10, 0x44(r25)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(68 as u32) ) } as u64;
	// 83158D04: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83158D08: 419A041C  beq cr6, 0x83159124
	if ctx.cr[6].eq {
	pc = 0x83159124; continue 'dispatch;
	}
	// 83158D0C: 39790050  addi r11, r25, 0x50
	ctx.r[11].s64 = ctx.r[25].s64 + 80;
	// 83158D10: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 83158D14: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158D18: 992B0000  stb r9, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 83158D1C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 83158D20: 4200FFF8  bdnz 0x83158d18
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83158D18; continue 'dispatch;
	}
	// 83158D24: 382121F0  addi r1, r1, 0x21f0
	ctx.r[1].s64 = ctx.r[1].s64 + 8688;
	// 83158D28: CBE1FF98  lfd f31, -0x68(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-104 as u32) ) };
	// 83158D2C: 4804F470  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
	// 83158D30: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 83158D34: 38611100  addi r3, r1, 0x1100
	ctx.r[3].s64 = ctx.r[1].s64 + 4352;
	// 83158D38: 4BFFFBF9  bl 0x83158930
	ctx.lr = 0x83158D3C;
	sub_83158930(ctx, base);
	// 83158D3C: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158D40: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158D44: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83158D48: 419A0018  beq cr6, 0x83158d60
	if ctx.cr[6].eq {
	pc = 0x83158D60; continue 'dispatch;
	}
	// 83158D4C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158D50: 38811100  addi r4, r1, 0x1100
	ctx.r[4].s64 = ctx.r[1].s64 + 4352;
	// 83158D54: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158D58: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158D5C: 4E800421  bctrl
	ctx.lr = 0x83158D60;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158D60: 81611144  lwz r11, 0x1144(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4420 as u32) ) } as u64;
	// 83158D64: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 83158D68: 7D7C5B78  mr r28, r11
	ctx.r[28].u64 = ctx.r[11].u64;
	// 83158D6C: 7F1EC378  mr r30, r24
	ctx.r[30].u64 = ctx.r[24].u64;
	// 83158D70: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158D74: 91790044  stw r11, 0x44(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 83158D78: 419A0120  beq cr6, 0x83158e98
	if ctx.cr[6].eq {
	pc = 0x83158E98; continue 'dispatch;
	}
	// 83158D7C: 39611100  addi r11, r1, 0x1100
	ctx.r[11].s64 = ctx.r[1].s64 + 4352;
	// 83158D80: 3BF90050  addi r31, r25, 0x50
	ctx.r[31].s64 = ctx.r[25].s64 + 80;
	// 83158D84: 7F23CB78  mr r3, r25
	ctx.r[3].u64 = ctx.r[25].u64;
	// 83158D88: 7FB95850  subf r29, r25, r11
	ctx.r[29].s64 = ctx.r[11].s64 - ctx.r[25].s64;
	// 83158D8C: 3AE00001  li r23, 1
	ctx.r[23].s64 = 1;
	// 83158D90: 81611140  lwz r11, 0x1140(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4416 as u32) ) } as u64;
	// 83158D94: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 83158D98: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83158D9C: 40980008  bge cr6, 0x83158da4
	if !ctx.cr[6].lt {
	pc = 0x83158DA4; continue 'dispatch;
	}
	// 83158DA0: 7C9D182E  lwzx r4, r29, r3
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[3].u32)) } as u64;
	// 83158DA4: 81790040  lwz r11, 0x40(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(64 as u32) ) } as u64;
	// 83158DA8: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83158DAC: 41980010  blt cr6, 0x83158dbc
	if ctx.cr[6].lt {
	pc = 0x83158DBC; continue 'dispatch;
	}
	// 83158DB0: 7F05C378  mr r5, r24
	ctx.r[5].u64 = ctx.r[24].u64;
	// 83158DB4: 7F08C378  mr r8, r24
	ctx.r[8].u64 = ctx.r[24].u64;
	// 83158DB8: 4800000C  b 0x83158dc4
	pc = 0x83158DC4; continue 'dispatch;
	// 83158DBC: 80B90048  lwz r5, 0x48(r25)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(72 as u32) ) } as u64;
	// 83158DC0: 81030000  lwz r8, 0(r3)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158DC4: 7D7DF8AE  lbzx r11, r29, r31
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 83158DC8: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83158DCC: 409A00B4  bne cr6, 0x83158e80
	if !ctx.cr[6].eq {
	pc = 0x83158E80; continue 'dispatch;
	}
	// 83158DD0: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 83158DD4: 419A00AC  beq cr6, 0x83158e80
	if ctx.cr[6].eq {
	pc = 0x83158E80; continue 'dispatch;
	}
	// 83158DD8: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 83158DDC: 419A00A4  beq cr6, 0x83158e80
	if ctx.cr[6].eq {
	pc = 0x83158E80; continue 'dispatch;
	}
	// 83158DE0: 7F07C378  mr r7, r24
	ctx.r[7].u64 = ctx.r[24].u64;
	// 83158DE4: 2F050004  cmpwi cr6, r5, 4
	ctx.cr[6].compare_i32(ctx.r[5].s32, 4, &mut ctx.xer);
	// 83158DE8: 41980060  blt cr6, 0x83158e48
	if ctx.cr[6].lt {
	pc = 0x83158E48; continue 'dispatch;
	}
	// 83158DEC: 3965FFFC  addi r11, r5, -4
	ctx.r[11].s64 = ctx.r[5].s64 + -4;
	// 83158DF0: 3944000C  addi r10, r4, 0xc
	ctx.r[10].s64 = ctx.r[4].s64 + 12;
	// 83158DF4: 5569F0BE  srwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 83158DF8: 39680004  addi r11, r8, 4
	ctx.r[11].s64 = ctx.r[8].s64 + 4;
	// 83158DFC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 83158E00: 7CC82050  subf r6, r8, r4
	ctx.r[6].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 83158E04: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 83158E08: C00AFFF4  lfs f0, -0xc(r10)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-12 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158E0C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 83158E10: EDA007F2  fmuls f13, f0, f31
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158E14: D1ABFFFC  stfs f13, -4(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 83158E18: 7D8B342E  lfsx f12, r11, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83158E1C: ED6C07F2  fmuls f11, f12, f31
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158E20: D16B0000  stfs f11, 0(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158E24: C14AFFFC  lfs f10, -4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 83158E28: ED2A07F2  fmuls f9, f10, f31
	ctx.f[9].f64 = (((ctx.f[10].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158E2C: D12B0004  stfs f9, 4(r11)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 83158E30: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83158E34: ECE807F2  fmuls f7, f8, f31
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158E38: D0EB0008  stfs f7, 8(r11)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 83158E3C: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 83158E40: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 83158E44: 4082FFC4  bne 0x83158e08
	if !ctx.cr[0].eq {
	pc = 0x83158E08; continue 'dispatch;
	}
	// 83158E48: 7F072840  cmplw cr6, r7, r5
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[5].u32, &mut ctx.xer);
	// 83158E4C: 4098002C  bge cr6, 0x83158e78
	if !ctx.cr[6].lt {
	pc = 0x83158E78; continue 'dispatch;
	}
	// 83158E50: 54EB103A  slwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83158E54: 7D282050  subf r9, r8, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[8].s64;
	// 83158E58: 7D6B4214  add r11, r11, r8
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 83158E5C: 7D472850  subf r10, r7, r5
	ctx.r[10].s64 = ctx.r[5].s64 - ctx.r[7].s64;
	// 83158E60: 7C0B4C2E  lfsx f0, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158E64: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 83158E68: EDA007F2  fmuls f13, f0, f31
	ctx.f[13].f64 = (((ctx.f[0].f64 * ctx.f[31].f64) as f32) as f64);
	// 83158E6C: D1AB0000  stfs f13, 0(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83158E70: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83158E74: 4082FFEC  bne 0x83158e60
	if !ctx.cr[0].eq {
	pc = 0x83158E60; continue 'dispatch;
	}
	// 83158E78: 9AFF0000  stb r23, 0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[23].u8 ) };
	// 83158E7C: 48000008  b 0x83158e84
	pc = 0x83158E84; continue 'dispatch;
	// 83158E80: 9B1F0000  stb r24, 0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[24].u8 ) };
	// 83158E84: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 83158E88: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 83158E8C: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 83158E90: 7F1EE040  cmplw cr6, r30, r28
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[28].u32, &mut ctx.xer);
	// 83158E94: 4198FEFC  blt cr6, 0x83158d90
	if ctx.cr[6].lt {
	pc = 0x83158D90; continue 'dispatch;
	}
	// 83158E98: 81411140  lwz r10, 0x1140(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4416 as u32) ) } as u64;
	// 83158E9C: 7F0BC378  mr r11, r24
	ctx.r[11].u64 = ctx.r[24].u64;
	// 83158EA0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83158EA4: 419A0280  beq cr6, 0x83159124
	if ctx.cr[6].eq {
	pc = 0x83159124; continue 'dispatch;
	}
	// 83158EA8: 39411100  addi r10, r1, 0x1100
	ctx.r[10].s64 = ctx.r[1].s64 + 4352;
	// 83158EAC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 83158EB0: 930A0000  stw r24, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 83158EB4: 81211140  lwz r9, 0x1140(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4416 as u32) ) } as u64;
	// 83158EB8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83158EBC: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 83158EC0: 4198FFEC  blt cr6, 0x83158eac
	if ctx.cr[6].lt {
	pc = 0x83158EAC; continue 'dispatch;
	}
	// 83158EC4: 382121F0  addi r1, r1, 0x21f0
	ctx.r[1].s64 = ctx.r[1].s64 + 8688;
	// 83158EC8: CBE1FF98  lfd f31, -0x68(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-104 as u32) ) };
	// 83158ECC: 4804F2D0  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
	// 83158ED0: 7F24CB78  mr r4, r25
	ctx.r[4].u64 = ctx.r[25].u64;
	// 83158ED4: 38610080  addi r3, r1, 0x80
	ctx.r[3].s64 = ctx.r[1].s64 + 128;
	// 83158ED8: 4BFFFA59  bl 0x83158930
	ctx.lr = 0x83158EDC;
	sub_83158930(ctx, base);
	// 83158EDC: 817C0008  lwz r11, 8(r28)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(8 as u32) ) } as u64;
	// 83158EE0: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158EE4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83158EE8: 419A0018  beq cr6, 0x83158f00
	if ctx.cr[6].eq {
	pc = 0x83158F00; continue 'dispatch;
	}
	// 83158EEC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158EF0: 38810080  addi r4, r1, 0x80
	ctx.r[4].s64 = ctx.r[1].s64 + 128;
	// 83158EF4: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158EF8: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83158EFC: 4E800421  bctrl
	ctx.lr = 0x83158F00;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83158F00: 812100C8  lwz r9, 0xc8(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) } as u64;
	// 83158F04: C1BC0104  lfs f13, 0x104(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(260 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83158F08: C01C0108  lfs f0, 0x108(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(264 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83158F0C: 816100C4  lwz r11, 0xc4(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(196 as u32) ) } as u64;
	// 83158F10: ED8D0028  fsubs f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 - ctx.f[0].f64) as f32) as f64);
	// 83158F14: 3B000000  li r24, 0
	ctx.r[24].s64 = 0;
	// 83158F18: 7D7A5B78  mr r26, r11
	ctx.r[26].u64 = ctx.r[11].u64;
	// 83158F1C: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 83158F20: F9210050  std r9, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u64 ) };
	// 83158F24: C9610050  lfd f11, 0x50(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 83158F28: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 83158F2C: 91790044  stw r11, 0x44(r25)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[25].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 83158F30: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 83158F34: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83158F38: EDAC4824  fdivs f13, f12, f9
	ctx.f[13].f64 = ((ctx.f[12].f64 / ctx.f[9].f64) as f32) as f64;
	// 83158F3C: 419A01B4  beq cr6, 0x831590f0
	if ctx.cr[6].eq {
	pc = 0x831590F0; continue 'dispatch;
	}
	// 83158F40: 39610080  addi r11, r1, 0x80
	ctx.r[11].s64 = ctx.r[1].s64 + 128;
	// 83158F44: 3BD90050  addi r30, r25, 0x50
	ctx.r[30].s64 = ctx.r[25].s64 + 80;
	// 83158F48: 7F3FCB78  mr r31, r25
	ctx.r[31].u64 = ctx.r[25].u64;
	// 83158F4C: 7F795850  subf r27, r25, r11
	ctx.r[27].s64 = ctx.r[11].s64 - ctx.r[25].s64;
	// 83158F50: 3AE00001  li r23, 1
	ctx.r[23].s64 = 1;
	// 83158F54: 816100C0  lwz r11, 0xc0(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 83158F58: 7F03C378  mr r3, r24
	ctx.r[3].u64 = ctx.r[24].u64;
	// 83158F5C: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83158F60: 40980008  bge cr6, 0x83158f68
	if !ctx.cr[6].lt {
	pc = 0x83158F68; continue 'dispatch;
	}
	// 83158F64: 7C7BF82E  lwzx r3, r27, r31
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 83158F68: 81790040  lwz r11, 0x40(r25)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(64 as u32) ) } as u64;
	// 83158F6C: 7F1D5840  cmplw cr6, r29, r11
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83158F70: 41980010  blt cr6, 0x83158f80
	if ctx.cr[6].lt {
	pc = 0x83158F80; continue 'dispatch;
	}
	// 83158F74: 7F04C378  mr r4, r24
	ctx.r[4].u64 = ctx.r[24].u64;
	// 83158F78: 7F05C378  mr r5, r24
	ctx.r[5].u64 = ctx.r[24].u64;
	// 83158F7C: 4800000C  b 0x83158f88
	pc = 0x83158F88; continue 'dispatch;
	// 83158F80: 80990048  lwz r4, 0x48(r25)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[25].u32.wrapping_add(72 as u32) ) } as u64;
	// 83158F84: 80BF0000  lwz r5, 0(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83158F88: 7D7BF0AE  lbzx r11, r27, r30
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 83158F8C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83158F90: 409A0148  bne cr6, 0x831590d8
	if !ctx.cr[6].eq {
	pc = 0x831590D8; continue 'dispatch;
	}
	// 83158F94: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83158F98: 419A0140  beq cr6, 0x831590d8
	if ctx.cr[6].eq {
	pc = 0x831590D8; continue 'dispatch;
	}
	// 83158F9C: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 83158FA0: 419A0138  beq cr6, 0x831590d8
	if ctx.cr[6].eq {
	pc = 0x831590D8; continue 'dispatch;
	}
	// 83158FA4: 7F0AC378  mr r10, r24
	ctx.r[10].u64 = ctx.r[24].u64;
	// 83158FA8: 2F040004  cmpwi cr6, r4, 4
	ctx.cr[6].compare_i32(ctx.r[4].s32, 4, &mut ctx.xer);
	// 83158FAC: 419800D8  blt cr6, 0x83159084
	if ctx.cr[6].lt {
	pc = 0x83159084; continue 'dispatch;
	}
	// 83158FB0: 38E4FFFD  addi r7, r4, -3
	ctx.r[7].s64 = ctx.r[4].s64 + -3;
	// 83158FB4: 39200002  li r9, 2
	ctx.r[9].s64 = 2;
	// 83158FB8: 3903000C  addi r8, r3, 0xc
	ctx.r[8].s64 = ctx.r[3].s64 + 12;
	// 83158FBC: 39650004  addi r11, r5, 4
	ctx.r[11].s64 = ctx.r[5].s64 + 4;
	// 83158FC0: 7CC51850  subf r6, r5, r3
	ctx.r[6].s64 = ctx.r[3].s64 - ctx.r[5].s64;
	// 83158FC4: 79550020  clrldi r21, r10, 0x20
	ctx.r[21].u64 = ctx.r[10].u64 & 0x00000000FFFFFFFFu64;
	// 83158FC8: C188FFF4  lfs f12, -0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83158FCC: 3AC90001  addi r22, r9, 1
	ctx.r[22].s64 = ctx.r[9].s64 + 1;
	// 83158FD0: FAA10068  std r21, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[21].u64 ) };
	// 83158FD4: 79350020  clrldi r21, r9, 0x20
	ctx.r[21].u64 = ctx.r[9].u64 & 0x00000000FFFFFFFFu64;
	// 83158FD8: 7AD60020  clrldi r22, r22, 0x20
	ctx.r[22].u64 = ctx.r[22].u64 & 0x00000000FFFFFFFFu64;
	// 83158FDC: C9010068  lfd f8, 0x68(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 83158FE0: FAA10058  std r21, 0x58(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[21].u64 ) };
	// 83158FE4: C8A10058  lfd f5, 0x58(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) };
	// 83158FE8: FAC10050  std r22, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[22].u64 ) };
	// 83158FEC: C9610050  lfd f11, 0x50(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 83158FF0: 3AC9FFFF  addi r22, r9, -1
	ctx.r[22].s64 = ctx.r[9].s64 + -1;
	// 83158FF4: FCC0469C  fcfid f6, f8
	ctx.f[6].f64 = (ctx.f[8].s64 as f64);
	// 83158FF8: 7AD60020  clrldi r22, r22, 0x20
	ctx.r[22].u64 = ctx.r[22].u64 & 0x00000000FFFFFFFFu64;
	// 83158FFC: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 83159000: FCE05E9C  fcfid f7, f11
	ctx.f[7].f64 = (ctx.f[11].s64 as f64);
	// 83159004: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83159008: FAC10070  std r22, 0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[22].u64 ) };
	// 8315900C: C9410070  lfd f10, 0x70(r1)
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 83159010: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 83159014: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 83159018: FC203018  frsp f1, f6
	ctx.f[1].f64 = (ctx.f[6].f64 as f32) as f64;
	// 8315901C: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 83159020: FC604818  frsp f3, f9
	ctx.f[3].f64 = (ctx.f[9].f64 as f32) as f64;
	// 83159024: FD602018  frsp f11, f4
	ctx.f[11].f64 = (ctx.f[4].f64 as f32) as f64;
	// 83159028: FC403818  frsp f2, f7
	ctx.f[2].f64 = (ctx.f[7].f64 as f32) as f64;
	// 8315902C: ED01037A  fmadds f8, f1, f13, f0
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 83159030: ED43037A  fmadds f10, f3, f13, f0
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 83159034: ECEB037A  fmadds f7, f11, f13, f0
	ctx.f[7].f64 = (((ctx.f[11].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 83159038: ED22037A  fmadds f9, f2, f13, f0
	ctx.f[9].f64 = (((ctx.f[2].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 8315903C: EC8807F2  fmuls f4, f8, f31
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[31].f64) as f32) as f64);
	// 83159040: ECCA07F2  fmuls f6, f10, f31
	ctx.f[6].f64 = (((ctx.f[10].f64 * ctx.f[31].f64) as f32) as f64);
	// 83159044: EC6707F2  fmuls f3, f7, f31
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[31].f64) as f32) as f64);
	// 83159048: ECA907F2  fmuls f5, f9, f31
	ctx.f[5].f64 = (((ctx.f[9].f64 * ctx.f[31].f64) as f32) as f64);
	// 8315904C: EC440332  fmuls f2, f4, f12
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 83159050: D04BFFFC  stfs f2, -4(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 83159054: 7C265C2E  lfsx f1, r6, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 83159058: ED860072  fmuls f12, f6, f1
	ctx.f[12].f64 = (((ctx.f[6].f64 * ctx.f[1].f64) as f32) as f64);
	// 8315905C: D18B0000  stfs f12, 0(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83159060: C168FFFC  lfs f11, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83159064: ED4302F2  fmuls f10, f3, f11
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[11].f64) as f32) as f64);
	// 83159068: D14B0004  stfs f10, 4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8315906C: C1280000  lfs f9, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 83159070: ED050272  fmuls f8, f5, f9
	ctx.f[8].f64 = (((ctx.f[5].f64 * ctx.f[9].f64) as f32) as f64);
	// 83159074: D10B0008  stfs f8, 8(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 83159078: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 8315907C: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 83159080: 4198FF44  blt cr6, 0x83158fc4
	if ctx.cr[6].lt {
	pc = 0x83158FC4; continue 'dispatch;
	}
	// 83159084: 7F0A2040  cmplw cr6, r10, r4
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[4].u32, &mut ctx.xer);
	// 83159088: 40980048  bge cr6, 0x831590d0
	if !ctx.cr[6].lt {
	pc = 0x831590D0; continue 'dispatch;
	}
	// 8315908C: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83159090: 7D251850  subf r9, r5, r3
	ctx.r[9].s64 = ctx.r[3].s64 - ctx.r[5].s64;
	// 83159094: 7D6B2A14  add r11, r11, r5
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[5].u64;
	// 83159098: 79480020  clrldi r8, r10, 0x20
	ctx.r[8].u64 = ctx.r[10].u64 & 0x00000000FFFFFFFFu64;
	// 8315909C: 7D8B4C2E  lfsx f12, r11, r9
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 831590A0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831590A4: F9010060  std r8, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[8].u64 ) };
	// 831590A8: 7F0A2040  cmplw cr6, r10, r4
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[4].u32, &mut ctx.xer);
	// 831590AC: C9610060  lfd f11, 0x60(r1)
	ctx.f[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 831590B0: FD405E9C  fcfid f10, f11
	ctx.f[10].f64 = (ctx.f[11].s64 as f64);
	// 831590B4: FD205018  frsp f9, f10
	ctx.f[9].f64 = (ctx.f[10].f64 as f32) as f64;
	// 831590B8: ED09037A  fmadds f8, f9, f13, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 831590BC: ECE807F2  fmuls f7, f8, f31
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[31].f64) as f32) as f64);
	// 831590C0: ECC70332  fmuls f6, f7, f12
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831590C4: D0CB0000  stfs f6, 0(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831590C8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831590CC: 4198FFCC  blt cr6, 0x83159098
	if ctx.cr[6].lt {
	pc = 0x83159098; continue 'dispatch;
	}
	// 831590D0: 9AFE0000  stb r23, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[23].u8 ) };
	// 831590D4: 48000008  b 0x831590dc
	pc = 0x831590DC; continue 'dispatch;
	// 831590D8: 9B1E0000  stb r24, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[24].u8 ) };
	// 831590DC: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 831590E0: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 831590E4: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 831590E8: 7F1DD040  cmplw cr6, r29, r26
	ctx.cr[6].compare_u32(ctx.r[29].u32, ctx.r[26].u32, &mut ctx.xer);
	// 831590EC: 4198FE68  blt cr6, 0x83158f54
	if ctx.cr[6].lt {
	pc = 0x83158F54; continue 'dispatch;
	}
	// 831590F0: 814100C0  lwz r10, 0xc0(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 831590F4: C01C0104  lfs f0, 0x104(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(260 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831590F8: D01C0108  stfs f0, 0x108(r28)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 831590FC: 7F0BC378  mr r11, r24
	ctx.r[11].u64 = ctx.r[24].u64;
	// 83159100: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83159104: 419A0020  beq cr6, 0x83159124
	if ctx.cr[6].eq {
	pc = 0x83159124; continue 'dispatch;
	}
	// 83159108: 39410080  addi r10, r1, 0x80
	ctx.r[10].s64 = ctx.r[1].s64 + 128;
	// 8315910C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 83159110: 930A0000  stw r24, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[24].u32 ) };
	// 83159114: 812100C0  lwz r9, 0xc0(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) } as u64;
	// 83159118: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315911C: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 83159120: 4198FFEC  blt cr6, 0x8315910c
	if ctx.cr[6].lt {
	pc = 0x8315910C; continue 'dispatch;
	}
	// 83159124: 382121F0  addi r1, r1, 0x21f0
	ctx.r[1].s64 = ctx.r[1].s64 + 8688;
	// 83159128: CBE1FF98  lfd f31, -0x68(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-104 as u32) ) };
	// 8315912C: 4804F070  b 0x831a819c
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159130(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83159130 size=2016
    let mut pc: u32 = 0x83159130;
    'dispatch: loop {
        match pc {
            0x83159130 => {
    //   block [0x83159130..0x83159910)
	// 83159130: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159134: 4804EFFD  bl 0x831a8130
	ctx.lr = 0x83159138;
	sub_831A8130(ctx, base);
	// 83159138: E981F000  ld r12, -0x1000(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-4096 as u32) ) };
	// 8315913C: 9421EDF0  stwu r1, -0x1210(r1)
	ea = ctx.r[1].u32.wrapping_add(-4624 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159140: 7C6F1B78  mr r15, r3
	ctx.r[15].u64 = ctx.r[3].u64;
	// 83159144: 386100F0  addi r3, r1, 0xf0
	ctx.r[3].s64 = ctx.r[1].s64 + 240;
	// 83159148: 91E11224  stw r15, 0x1224(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(4644 as u32), ctx.r[15].u32 ) };
	// 8315914C: 7C942378  mr r20, r4
	ctx.r[20].u64 = ctx.r[4].u64;
	// 83159150: 7CBB2B78  mr r27, r5
	ctx.r[27].u64 = ctx.r[5].u64;
	// 83159154: 7CD33378  mr r19, r6
	ctx.r[19].u64 = ctx.r[6].u64;
	// 83159158: 7CF23B78  mr r18, r7
	ctx.r[18].u64 = ctx.r[7].u64;
	// 8315915C: 4BFFF7D5  bl 0x83158930
	ctx.lr = 0x83159160;
	sub_83158930(ctx, base);
	// 83159160: 816F0008  lwz r11, 8(r15)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(8 as u32) ) } as u64;
	// 83159164: 806B0000  lwz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159168: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315916C: 419A0018  beq cr6, 0x83159184
	if ctx.cr[6].eq {
	pc = 0x83159184; continue 'dispatch;
	}
	// 83159170: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159174: 388100F0  addi r4, r1, 0xf0
	ctx.r[4].s64 = ctx.r[1].s64 + 240;
	// 83159178: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315917C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83159180: 4E800421  bctrl
	ctx.lr = 0x83159184;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83159184: 81410138  lwz r10, 0x138(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(312 as u32) ) } as u64;
	// 83159188: 3A200000  li r17, 0
	ctx.r[17].s64 = 0;
	// 8315918C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83159190: 409A0038  bne cr6, 0x831591c8
	if !ctx.cr[6].eq {
	pc = 0x831591C8; continue 'dispatch;
	}
	// 83159194: 81410130  lwz r10, 0x130(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 83159198: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 8315919C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831591A0: 419A0768  beq cr6, 0x83159908
	if ctx.cr[6].eq {
	pc = 0x83159908; continue 'dispatch;
	}
	// 831591A4: 394100F0  addi r10, r1, 0xf0
	ctx.r[10].s64 = ctx.r[1].s64 + 240;
	// 831591A8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831591AC: 922A0000  stw r17, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[17].u32 ) };
	// 831591B0: 81210130  lwz r9, 0x130(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 831591B4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831591B8: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831591BC: 4198FFEC  blt cr6, 0x831591a8
	if ctx.cr[6].lt {
	pc = 0x831591A8; continue 'dispatch;
	}
	// 831591C0: 38211210  addi r1, r1, 0x1210
	ctx.r[1].s64 = ctx.r[1].s64 + 4624;
	// 831591C4: 4804EFBC  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
	// 831591C8: 81610134  lwz r11, 0x134(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(308 as u32) ) } as u64;
	// 831591CC: 3A000001  li r16, 1
	ctx.r[16].s64 = 1;
	// 831591D0: 91740044  stw r11, 0x44(r20)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[20].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 831591D4: C16F0108  lfs f11, 0x108(r15)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(264 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831591D8: 83330000  lwz r25, 0(r19)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 831591DC: 83D20000  lwz r30, 0(r18)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 831591E0: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 831591E4: C12F0104  lfs f9, 0x104(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(260 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 831591E8: FF095800  fcmpu cr6, f9, f11
	ctx.cr[6].compare_f64(ctx.f[9].f64, ctx.f[11].f64);
	// 831591EC: 409A0008  bne cr6, 0x831591f4
	if !ctx.cr[6].eq {
	pc = 0x831591F4; continue 'dispatch;
	}
	// 831591F0: 7E308B78  mr r16, r17
	ctx.r[16].u64 = ctx.r[17].u64;
	// 831591F4: 794A0020  clrldi r10, r10, 0x20
	ctx.r[10].u64 = ctx.r[10].u64 & 0x00000000FFFFFFFFu64;
	// 831591F8: EC095828  fsubs f0, f9, f11
	ctx.f[0].f64 = (((ctx.f[9].f64 - ctx.f[11].f64) as f32) as f64);
	// 831591FC: 7E378B78  mr r23, r17
	ctx.r[23].u64 = ctx.r[17].u64;
	// 83159200: F9410050  std r10, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[10].u64 ) };
	// 83159204: C9A10050  lfd f13, 0x50(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 83159208: FD806E9C  fcfid f12, f13
	ctx.f[12].f64 = (ctx.f[13].s64 as f64);
	// 8315920C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83159210: FD406018  frsp f10, f12
	ctx.f[10].f64 = (ctx.f[12].f64 as f32) as f64;
	// 83159214: ED405024  fdivs f10, f0, f10
	ctx.f[10].f64 = ((ctx.f[0].f64 / ctx.f[10].f64) as f32) as f64;
	// 83159218: 419A06AC  beq cr6, 0x831598c4
	if ctx.cr[6].eq {
	pc = 0x831598C4; continue 'dispatch;
	}
	// 8315921C: 396100F0  addi r11, r1, 0xf0
	ctx.r[11].s64 = ctx.r[1].s64 + 240;
	// 83159220: 3AB40050  addi r21, r20, 0x50
	ctx.r[21].s64 = ctx.r[20].s64 + 80;
	// 83159224: 7D345850  subf r9, r20, r11
	ctx.r[9].s64 = ctx.r[11].s64 - ctx.r[20].s64;
	// 83159228: 7E96A378  mr r22, r20
	ctx.r[22].u64 = ctx.r[20].u64;
	// 8315922C: 91210050  stw r9, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[9].u32 ) };
	// 83159230: 83330000  lwz r25, 0(r19)
	ctx.r[25].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159234: 7E3F8B78  mr r31, r17
	ctx.r[31].u64 = ctx.r[17].u64;
	// 83159238: 81410130  lwz r10, 0x130(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 8315923C: 572B103A  slwi r11, r25, 2
	ctx.r[11].u32 = ctx.r[25].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83159240: 83D20000  lwz r30, 0(r18)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159244: 7F175040  cmplw cr6, r23, r10
	ctx.cr[6].compare_u32(ctx.r[23].u32, ctx.r[10].u32, &mut ctx.xer);
	// 83159248: 7D195A14  add r8, r25, r11
	ctx.r[8].u64 = ctx.r[25].u64 + ctx.r[11].u64;
	// 8315924C: 550B103A  slwi r11, r8, 2
	ctx.r[11].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83159250: 7F4BDA14  add r26, r11, r27
	ctx.r[26].u64 = ctx.r[11].u64 + ctx.r[27].u64;
	// 83159254: 40980008  bge cr6, 0x8315925c
	if !ctx.cr[6].lt {
	pc = 0x8315925C; continue 'dispatch;
	}
	// 83159258: 7FE9B02E  lwzx r31, r9, r22
	ctx.r[31].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[22].u32)) } as u64;
	// 8315925C: 81740040  lwz r11, 0x40(r20)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(64 as u32) ) } as u64;
	// 83159260: 7F175840  cmplw cr6, r23, r11
	ctx.cr[6].compare_u32(ctx.r[23].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83159264: 41980010  blt cr6, 0x83159274
	if ctx.cr[6].lt {
	pc = 0x83159274; continue 'dispatch;
	}
	// 83159268: 7E3C8B78  mr r28, r17
	ctx.r[28].u64 = ctx.r[17].u64;
	// 8315926C: 7E248B78  mr r4, r17
	ctx.r[4].u64 = ctx.r[17].u64;
	// 83159270: 4800000C  b 0x8315927c
	pc = 0x8315927C; continue 'dispatch;
	// 83159274: 83940048  lwz r28, 0x48(r20)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(72 as u32) ) } as u64;
	// 83159278: 80960000  lwz r4, 0(r22)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315927C: 7D69A8AE  lbzx r11, r9, r21
	ctx.r[11].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[21].u32)) } as u64;
	// 83159280: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 83159284: 409A05F0  bne cr6, 0x83159874
	if !ctx.cr[6].eq {
	pc = 0x83159874; continue 'dispatch;
	}
	// 83159288: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315928C: 419A05E8  beq cr6, 0x83159874
	if ctx.cr[6].eq {
	pc = 0x83159874; continue 'dispatch;
	}
	// 83159290: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 83159294: 419A05E0  beq cr6, 0x83159874
	if ctx.cr[6].eq {
	pc = 0x83159874; continue 'dispatch;
	}
	// 83159298: 7F98E378  mr r24, r28
	ctx.r[24].u64 = ctx.r[28].u64;
	// 8315929C: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 831592A0: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 831592A4: 419A05C4  beq cr6, 0x83159868
	if ctx.cr[6].eq {
	pc = 0x83159868; continue 'dispatch;
	}
	// 831592A8: 815A000C  lwz r10, 0xc(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 831592AC: 7F1E5040  cmplw cr6, r30, r10
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[10].u32, &mut ctx.xer);
	// 831592B0: 4198025C  blt cr6, 0x8315950c
	if ctx.cr[6].lt {
	pc = 0x8315950C; continue 'dispatch;
	}
	// 831592B4: 572A103A  slwi r10, r25, 2
	ctx.r[10].u32 = ctx.r[25].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831592B8: 813B0050  lwz r9, 0x50(r27)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(80 as u32) ) } as u64;
	// 831592BC: 7D595214  add r10, r25, r10
	ctx.r[10].u64 = ctx.r[25].u64 + ctx.r[10].u64;
	// 831592C0: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831592C4: 7D4ADA14  add r10, r10, r27
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[27].u64;
	// 831592C8: 3B390001  addi r25, r25, 1
	ctx.r[25].s64 = ctx.r[25].s64 + 1;
	// 831592CC: 394A0014  addi r10, r10, 0x14
	ctx.r[10].s64 = ctx.r[10].s64 + 20;
	// 831592D0: 7F194840  cmplw cr6, r25, r9
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[9].u32, &mut ctx.xer);
	// 831592D4: 40980018  bge cr6, 0x831592ec
	if !ctx.cr[6].lt {
	pc = 0x831592EC; continue 'dispatch;
	}
	// 831592D8: 810A000C  lwz r8, 0xc(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(12 as u32) ) } as u64;
	// 831592DC: 7D5A5378  mr r26, r10
	ctx.r[26].u64 = ctx.r[10].u64;
	// 831592E0: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831592E4: 4098FFE4  bge cr6, 0x831592c8
	if !ctx.cr[6].lt {
	pc = 0x831592C8; continue 'dispatch;
	}
	// 831592E8: 48000224  b 0x8315950c
	pc = 0x8315950C; continue 'dispatch;
	// 831592EC: 2F100001  cmpwi cr6, r16, 1
	ctx.cr[6].compare_i32(ctx.r[16].s32, 1, &mut ctx.xer);
	// 831592F0: 7D4BE050  subf r10, r11, r28
	ctx.r[10].s64 = ctx.r[28].s64 - ctx.r[11].s64;
	// 831592F4: 409A0158  bne cr6, 0x8315944c
	if !ctx.cr[6].eq {
	pc = 0x8315944C; continue 'dispatch;
	}
	// 831592F8: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 831592FC: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 83159300: 419800F8  blt cr6, 0x831593f8
	if ctx.cr[6].lt {
	pc = 0x831593F8; continue 'dispatch;
	}
	// 83159304: 394B0003  addi r10, r11, 3
	ctx.r[10].s64 = ctx.r[11].s64 + 3;
	// 83159308: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 8315930C: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83159310: 5505103A  slwi r5, r8, 2
	ctx.r[5].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 83159314: 7CEAFA14  add r7, r10, r31
	ctx.r[7].u64 = ctx.r[10].u64 + ctx.r[31].u64;
	// 83159318: 7D452214  add r10, r5, r4
	ctx.r[10].u64 = ctx.r[5].u64 + ctx.r[4].u64;
	// 8315931C: 38DCFFFD  addi r6, r28, -3
	ctx.r[6].s64 = ctx.r[28].s64 + -3;
	// 83159320: 390B0002  addi r8, r11, 2
	ctx.r[8].s64 = ctx.r[11].s64 + 2;
	// 83159324: 7CA4F850  subf r5, r4, r31
	ctx.r[5].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 83159328: 79230020  clrldi r3, r9, 0x20
	ctx.r[3].u64 = ctx.r[9].u64 & 0x00000000FFFFFFFFu64;
	// 8315932C: C01B0058  lfs f0, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159330: 3BA8FFFF  addi r29, r8, -1
	ctx.r[29].s64 = ctx.r[8].s64 + -1;
	// 83159334: C1A7FFF4  lfs f13, -0xc(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83159338: F86100B0  std r3, 0xb0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[3].u64 ) };
	// 8315933C: 79030020  clrldi r3, r8, 0x20
	ctx.r[3].u64 = ctx.r[8].u64 & 0x00000000FFFFFFFFu64;
	// 83159340: 7BBD0020  clrldi r29, r29, 0x20
	ctx.r[29].u64 = ctx.r[29].u64 & 0x00000000FFFFFFFFu64;
	// 83159344: C8C100B0  lfd f6, 0xb0(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 83159348: F86100A0  std r3, 0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[3].u64 ) };
	// 8315934C: C98100A0  lfd f12, 0xa0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 83159350: FBA10070  std r29, 0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[29].u64 ) };
	// 83159354: C9010070  lfd f8, 0x70(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 83159358: FC80369C  fcfid f4, f6
	ctx.f[4].f64 = (ctx.f[6].s64 as f64);
	// 8315935C: 38680001  addi r3, r8, 1
	ctx.r[3].s64 = ctx.r[8].s64 + 1;
	// 83159360: FCE0669C  fcfid f7, f12
	ctx.f[7].f64 = (ctx.f[12].s64 as f64);
	// 83159364: 78630020  clrldi r3, r3, 0x20
	ctx.r[3].u64 = ctx.r[3].u64 & 0x00000000FFFFFFFFu64;
	// 83159368: FCA0469C  fcfid f5, f8
	ctx.f[5].f64 = (ctx.f[8].s64 as f64);
	// 8315936C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 83159370: FD802018  frsp f12, f4
	ctx.f[12].f64 = (ctx.f[4].f64 as f32) as f64;
	// 83159374: F8610080  std r3, 0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[3].u64 ) };
	// 83159378: C8410080  lfd f2, 0x80(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8315937C: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 83159380: FD002818  frsp f8, f5
	ctx.f[8].f64 = (ctx.f[5].f64 as f32) as f64;
	// 83159384: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 83159388: ECAC5ABA  fmadds f5, f12, f10, f11
	ctx.f[5].f64 = (((ctx.f[12].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 8315938C: 7F093040  cmplw cr6, r9, r6
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[6].u32, &mut ctx.xer);
	// 83159390: FCC00818  frsp f6, f1
	ctx.f[6].f64 = (ctx.f[1].f64 as f32) as f64;
	// 83159394: FC603818  frsp f3, f7
	ctx.f[3].f64 = (ctx.f[7].f64 as f32) as f64;
	// 83159398: EC885ABA  fmadds f4, f8, f10, f11
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 8315939C: EC450032  fmuls f2, f5, f0
	ctx.f[2].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 831593A0: ECE35ABA  fmadds f7, f3, f10, f11
	ctx.f[7].f64 = (((ctx.f[3].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 831593A4: EC665ABA  fmadds f3, f6, f10, f11
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 831593A8: EC220372  fmuls f1, f2, f13
	ctx.f[1].f64 = (((ctx.f[2].f64 * ctx.f[13].f64) as f32) as f64);
	// 831593AC: D02AFFFC  stfs f1, -4(r10)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831593B0: 7C05542E  lfsx f0, r5, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831593B4: C1BB0058  lfs f13, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831593B8: ED840372  fmuls f12, f4, f13
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[13].f64) as f32) as f64);
	// 831593BC: ED0C0032  fmuls f8, f12, f0
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 831593C0: D10A0000  stfs f8, 0(r10)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831593C4: C0C7FFFC  lfs f6, -4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831593C8: C0BB0058  lfs f5, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 831593CC: EC870172  fmuls f4, f7, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[5].f64) as f32) as f64);
	// 831593D0: EC4401B2  fmuls f2, f4, f6
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[6].f64) as f32) as f64);
	// 831593D4: D04A0004  stfs f2, 4(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831593D8: C0270000  lfs f1, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831593DC: 38E70010  addi r7, r7, 0x10
	ctx.r[7].s64 = ctx.r[7].s64 + 16;
	// 831593E0: C01B0058  lfs f0, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831593E4: EDA30032  fmuls f13, f3, f0
	ctx.f[13].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 831593E8: ED8D0072  fmuls f12, f13, f1
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[1].f64) as f32) as f64);
	// 831593EC: D18A0008  stfs f12, 8(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831593F0: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 831593F4: 4198FF34  blt cr6, 0x83159328
	if ctx.cr[6].lt {
	pc = 0x83159328; continue 'dispatch;
	}
	// 831593F8: 7F09E040  cmplw cr6, r9, r28
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[28].u32, &mut ctx.xer);
	// 831593FC: 40980108  bge cr6, 0x83159504
	if !ctx.cr[6].lt {
	pc = 0x83159504; continue 'dispatch;
	}
	// 83159400: 552A103A  slwi r10, r9, 2
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83159404: 7D04F850  subf r8, r4, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 83159408: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 8315940C: 79270020  clrldi r7, r9, 0x20
	ctx.r[7].u64 = ctx.r[9].u64 & 0x00000000FFFFFFFFu64;
	// 83159410: C01B0058  lfs f0, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159414: 7DAA442E  lfsx f13, r10, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83159418: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8315941C: F8E100D0  std r7, 0xd0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[7].u64 ) };
	// 83159420: C98100D0  lfd f12, 0xd0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 83159424: FD00669C  fcfid f8, f12
	ctx.f[8].f64 = (ctx.f[12].s64 as f64);
	// 83159428: 7F09E040  cmplw cr6, r9, r28
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[28].u32, &mut ctx.xer);
	// 8315942C: FCE04018  frsp f7, f8
	ctx.f[7].f64 = (ctx.f[8].f64 as f32) as f64;
	// 83159430: ECC75ABA  fmadds f6, f7, f10, f11
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[10].f64 + ctx.f[11].f64) as f32) as f64);
	// 83159434: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 83159438: EC850372  fmuls f4, f5, f13
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315943C: D08A0000  stfs f4, 0(r10)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83159440: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83159444: 4198FFC8  blt cr6, 0x8315940c
	if ctx.cr[6].lt {
	pc = 0x8315940C; continue 'dispatch;
	}
	// 83159448: 480000BC  b 0x83159504
	pc = 0x83159504; continue 'dispatch;
	// 8315944C: C01B0058  lfs f0, 0x58(r27)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159450: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 83159454: EC000272  fmuls f0, f0, f9
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 83159458: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 8315945C: 41980078  blt cr6, 0x831594d4
	if ctx.cr[6].lt {
	pc = 0x831594D4; continue 'dispatch;
	}
	// 83159460: 7D4BE050  subf r10, r11, r28
	ctx.r[10].s64 = ctx.r[28].s64 - ctx.r[11].s64;
	// 83159464: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 83159468: 390AFFFC  addi r8, r10, -4
	ctx.r[8].s64 = ctx.r[10].s64 + -4;
	// 8315946C: 392B0003  addi r9, r11, 3
	ctx.r[9].s64 = ctx.r[11].s64 + 3;
	// 83159470: 550AF0BE  srwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83159474: 5529103A  slwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 83159478: 390A0001  addi r8, r10, 1
	ctx.r[8].s64 = ctx.r[10].s64 + 1;
	// 8315947C: 54EA103A  slwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83159480: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 83159484: 7D29FA14  add r9, r9, r31
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[31].u64;
	// 83159488: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 8315948C: 7CC4F850  subf r6, r4, r31
	ctx.r[6].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 83159490: 7CE75A14  add r7, r7, r11
	ctx.r[7].u64 = ctx.r[7].u64 + ctx.r[11].u64;
	// 83159494: C1A9FFF4  lfs f13, -0xc(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-12 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83159498: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315949C: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831594A0: D18AFFFC  stfs f12, -4(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831594A4: 7D0A342E  lfsx f8, r10, r6
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[6].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831594A8: ECE80032  fmuls f7, f8, f0
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[0].f64) as f32) as f64);
	// 831594AC: D0EA0000  stfs f7, 0(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831594B0: C0C9FFFC  lfs f6, -4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(-4 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 831594B4: ECA60032  fmuls f5, f6, f0
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64) as f32) as f64);
	// 831594B8: D0AA0004  stfs f5, 4(r10)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831594BC: C0890000  lfs f4, 0(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831594C0: EC640032  fmuls f3, f4, f0
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[0].f64) as f32) as f64);
	// 831594C4: D06A0008  stfs f3, 8(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831594C8: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 831594CC: 39290010  addi r9, r9, 0x10
	ctx.r[9].s64 = ctx.r[9].s64 + 16;
	// 831594D0: 4082FFC4  bne 0x83159494
	if !ctx.cr[0].eq {
	pc = 0x83159494; continue 'dispatch;
	}
	// 831594D4: 7F07E040  cmplw cr6, r7, r28
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[28].u32, &mut ctx.xer);
	// 831594D8: 4098002C  bge cr6, 0x83159504
	if !ctx.cr[6].lt {
	pc = 0x83159504; continue 'dispatch;
	}
	// 831594DC: 54EA103A  slwi r10, r7, 2
	ctx.r[10].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 831594E0: 7D04F850  subf r8, r4, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831594E4: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 831594E8: 7D27E050  subf r9, r7, r28
	ctx.r[9].s64 = ctx.r[28].s64 - ctx.r[7].s64;
	// 831594EC: 7DA8542E  lfsx f13, r8, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 831594F0: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 831594F4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 831594F8: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831594FC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 83159500: 4082FFEC  bne 0x831594ec
	if !ctx.cr[0].eq {
	pc = 0x831594EC; continue 'dispatch;
	}
	// 83159504: 7FD8F214  add r30, r24, r30
	ctx.r[30].u64 = ctx.r[24].u64 + ctx.r[30].u64;
	// 83159508: 7E388B78  mr r24, r17
	ctx.r[24].u64 = ctx.r[17].u64;
	// 8315950C: 815A000C  lwz r10, 0xc(r26)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 83159510: 7F1DC378  mr r29, r24
	ctx.r[29].u64 = ctx.r[24].u64;
	// 83159514: 7D5E5050  subf r10, r30, r10
	ctx.r[10].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 83159518: 7F185040  cmplw cr6, r24, r10
	ctx.cr[6].compare_u32(ctx.r[24].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8315951C: 40990008  ble cr6, 0x83159524
	if !ctx.cr[6].gt {
	pc = 0x83159524; continue 'dispatch;
	}
	// 83159520: 7D5D5378  mr r29, r10
	ctx.r[29].u64 = ctx.r[10].u64;
	// 83159524: 2B1D0000  cmplwi cr6, r29, 0
	ctx.cr[6].compare_u32(ctx.r[29].u32, 0 as u32, &mut ctx.xer);
	// 83159528: 419A0334  beq cr6, 0x8315985c
	if ctx.cr[6].eq {
	pc = 0x8315985C; continue 'dispatch;
	}
	// 8315952C: 7CDD5A14  add r6, r29, r11
	ctx.r[6].u64 = ctx.r[29].u64 + ctx.r[11].u64;
	// 83159530: 2F100001  cmpwi cr6, r16, 1
	ctx.cr[6].compare_i32(ctx.r[16].s32, 1, &mut ctx.xer);
	// 83159534: 409A01C8  bne cr6, 0x831596fc
	if !ctx.cr[6].eq {
	pc = 0x831596FC; continue 'dispatch;
	}
	// 83159538: 7BCA0020  clrldi r10, r30, 0x20
	ctx.r[10].u64 = ctx.r[30].u64 & 0x00000000FFFFFFFFu64;
	// 8315953C: C19A0000  lfs f12, 0(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83159540: C11A0004  lfs f8, 4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83159544: 7D2B3050  subf r9, r11, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 83159548: F9410090  std r10, 0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[10].u64 ) };
	// 8315954C: C8E10090  lfd f7, 0x90(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 83159550: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 83159554: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 83159558: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 8315955C: 2F090004  cmpwi cr6, r9, 4
	ctx.cr[6].compare_i32(ctx.r[9].s32, 4, &mut ctx.xer);
	// 83159560: EC0C02B2  fmuls f0, f12, f10
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[10].f64) as f32) as f64);
	// 83159564: EC85433A  fmadds f4, f5, f12, f8
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64 + ctx.f[8].f64) as f32) as f64);
	// 83159568: EC6402B2  fmuls f3, f4, f10
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[10].f64) as f32) as f64);
	// 8315956C: EDA402F2  fmuls f13, f4, f11
	ctx.f[13].f64 = (((ctx.f[4].f64 * ctx.f[11].f64) as f32) as f64);
	// 83159570: ED8C1AFA  fmadds f12, f12, f11, f3
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[11].f64 + ctx.f[3].f64) as f32) as f64);
	// 83159574: 41980128  blt cr6, 0x8315969c
	if ctx.cr[6].lt {
	pc = 0x8315969C; continue 'dispatch;
	}
	// 83159578: 38E6FFFD  addi r7, r6, -3
	ctx.r[7].s64 = ctx.r[6].s64 + -3;
	// 8315957C: 390B0001  addi r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 1;
	// 83159580: 7D2B3850  subf r9, r11, r7
	ctx.r[9].s64 = ctx.r[7].s64 - ctx.r[11].s64;
	// 83159584: 38AB0003  addi r5, r11, 3
	ctx.r[5].s64 = ctx.r[11].s64 + 3;
	// 83159588: 3929FFFF  addi r9, r9, -1
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	// 8315958C: 5503103A  slwi r3, r8, 2
	ctx.r[3].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 83159590: 5529F0BE  srwi r9, r9, 2
	ctx.r[9].u32 = ctx.r[9].u32.wrapping_shr(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 83159594: 54A8103A  slwi r8, r5, 2
	ctx.r[8].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 83159598: 38A90001  addi r5, r9, 1
	ctx.r[5].s64 = ctx.r[9].s64 + 1;
	// 8315959C: 392B0002  addi r9, r11, 2
	ctx.r[9].s64 = ctx.r[11].s64 + 2;
	// 831595A0: 54A5103A  slwi r5, r5, 2
	ctx.r[5].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 831595A4: 7D632214  add r11, r3, r4
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[4].u64;
	// 831595A8: 7D08FA14  add r8, r8, r31
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 831595AC: 7C64F850  subf r3, r4, r31
	ctx.r[3].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831595B0: 7FC5F214  add r30, r5, r30
	ctx.r[30].u64 = ctx.r[5].u64 + ctx.r[30].u64;
	// 831595B4: 38A9FFFF  addi r5, r9, -1
	ctx.r[5].s64 = ctx.r[9].s64 + -1;
	// 831595B8: F8C10078  std r6, 0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[6].u64 ) };
	// 831595BC: 38C90001  addi r6, r9, 1
	ctx.r[6].s64 = ctx.r[9].s64 + 1;
	// 831595C0: C108FFF4  lfs f8, -0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-12 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831595C4: 78A50020  clrldi r5, r5, 0x20
	ctx.r[5].u64 = ctx.r[5].u64 & 0x00000000FFFFFFFFu64;
	// 831595C8: 792E0020  clrldi r14, r9, 0x20
	ctx.r[14].u64 = ctx.r[9].u64 & 0x00000000FFFFFFFFu64;
	// 831595CC: F8A100C0  std r5, 0xc0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[5].u64 ) };
	// 831595D0: 78C50020  clrldi r5, r6, 0x20
	ctx.r[5].u64 = ctx.r[6].u64 & 0x00000000FFFFFFFFu64;
	// 831595D4: F9C10068  std r14, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[14].u64 ) };
	// 831595D8: 794E0020  clrldi r14, r10, 0x20
	ctx.r[14].u64 = ctx.r[10].u64 & 0x00000000FFFFFFFFu64;
	// 831595DC: F8A10060  std r5, 0x60(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[5].u64 ) };
	// 831595E0: C8C10060  lfd f6, 0x60(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) };
	// 831595E4: F9C100E0  std r14, 0xe0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[14].u64 ) };
	// 831595E8: C8A100E0  lfd f5, 0xe0(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 831595EC: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831595F0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831595F4: C8E100C0  lfd f7, 0xc0(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 831595F8: FCC0369C  fcfid f6, f6
	ctx.f[6].f64 = (ctx.f[6].s64 as f64);
	// 831595FC: C8410068  lfd f2, 0x68(r1)
	ctx.f[2].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 83159600: FC603E9C  fcfid f3, f7
	ctx.f[3].f64 = (ctx.f[7].s64 as f64);
	// 83159604: FC20169C  fcfid f1, f2
	ctx.f[1].f64 = (ctx.f[2].s64 as f64);
	// 83159608: E8C10078  ld r6, 0x78(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8315960C: FCE02018  frsp f7, f4
	ctx.f[7].f64 = (ctx.f[4].f64 as f32) as f64;
	// 83159610: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 83159614: 7F0A3840  cmplw cr6, r10, r7
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[7].u32, &mut ctx.xer);
	// 83159618: FCA01818  frsp f5, f3
	ctx.f[5].f64 = (ctx.f[3].f64 as f32) as f64;
	// 8315961C: FC800818  frsp f4, f1
	ctx.f[4].f64 = (ctx.f[1].f64 as f32) as f64;
	// 83159620: EC470332  fmuls f2, f7, f12
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 83159624: EC6701F2  fmuls f3, f7, f7
	ctx.f[3].f64 = (((ctx.f[7].f64 * ctx.f[7].f64) as f32) as f64);
	// 83159628: FC203018  frsp f1, f6
	ctx.f[1].f64 = (ctx.f[6].f64 as f32) as f64;
	// 8315962C: ECC50332  fmuls f6, f5, f12
	ctx.f[6].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 83159630: ECE50172  fmuls f7, f5, f5
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[5].f64) as f32) as f64);
	// 83159634: ECA40132  fmuls f5, f4, f4
	ctx.f[5].f64 = (((ctx.f[4].f64 * ctx.f[4].f64) as f32) as f64);
	// 83159638: EC840332  fmuls f4, f4, f12
	ctx.f[4].f64 = (((ctx.f[4].f64 * ctx.f[12].f64) as f32) as f64);
	// 8315963C: EC63103A  fmadds f3, f3, f0, f2
	ctx.f[3].f64 = (((ctx.f[3].f64 * ctx.f[0].f64 + ctx.f[2].f64) as f32) as f64);
	// 83159640: EC410072  fmuls f2, f1, f1
	ctx.f[2].f64 = (((ctx.f[1].f64 * ctx.f[1].f64) as f32) as f64);
	// 83159644: EC210332  fmuls f1, f1, f12
	ctx.f[1].f64 = (((ctx.f[1].f64 * ctx.f[12].f64) as f32) as f64);
	// 83159648: ECE7303A  fmadds f7, f7, f0, f6
	ctx.f[7].f64 = (((ctx.f[7].f64 * ctx.f[0].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315964C: ECC5203A  fmadds f6, f5, f0, f4
	ctx.f[6].f64 = (((ctx.f[5].f64 * ctx.f[0].f64 + ctx.f[4].f64) as f32) as f64);
	// 83159650: ECA3682A  fadds f5, f3, f13
	ctx.f[5].f64 = ((ctx.f[3].f64 + ctx.f[13].f64) as f32) as f64;
	// 83159654: EC82083A  fmadds f4, f2, f0, f1
	ctx.f[4].f64 = (((ctx.f[2].f64 * ctx.f[0].f64 + ctx.f[1].f64) as f32) as f64);
	// 83159658: EC67682A  fadds f3, f7, f13
	ctx.f[3].f64 = ((ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64;
	// 8315965C: EC46682A  fadds f2, f6, f13
	ctx.f[2].f64 = ((ctx.f[6].f64 + ctx.f[13].f64) as f32) as f64;
	// 83159660: EC250232  fmuls f1, f5, f8
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[8].f64) as f32) as f64);
	// 83159664: D02BFFFC  stfs f1, -4(r11)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 83159668: ECE4682A  fadds f7, f4, f13
	ctx.f[7].f64 = ((ctx.f[4].f64 + ctx.f[13].f64) as f32) as f64;
	// 8315966C: 7D035C2E  lfsx f8, r3, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 83159670: ECC30232  fmuls f6, f3, f8
	ctx.f[6].f64 = (((ctx.f[3].f64 * ctx.f[8].f64) as f32) as f64);
	// 83159674: D0CB0000  stfs f6, 0(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 83159678: C0A8FFFC  lfs f5, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315967C: EC820172  fmuls f4, f2, f5
	ctx.f[4].f64 = (((ctx.f[2].f64 * ctx.f[5].f64) as f32) as f64);
	// 83159680: D08B0004  stfs f4, 4(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 83159684: C0680000  lfs f3, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 83159688: EC4700F2  fmuls f2, f7, f3
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[3].f64) as f32) as f64);
	// 8315968C: D04B0008  stfs f2, 8(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 83159690: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 83159694: 396B0010  addi r11, r11, 0x10
	ctx.r[11].s64 = ctx.r[11].s64 + 16;
	// 83159698: 4198FF1C  blt cr6, 0x831595b4
	if ctx.cr[6].lt {
	pc = 0x831595B4; continue 'dispatch;
	}
	// 8315969C: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831596A0: 409801B4  bge cr6, 0x83159854
	if !ctx.cr[6].lt {
	pc = 0x83159854; continue 'dispatch;
	}
	// 831596A4: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 831596A8: 7D2A3050  subf r9, r10, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[10].s64;
	// 831596AC: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 831596B0: 7D04F850  subf r8, r4, r31
	ctx.r[8].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 831596B4: 7FC9F214  add r30, r9, r30
	ctx.r[30].u64 = ctx.r[9].u64 + ctx.r[30].u64;
	// 831596B8: 79490020  clrldi r9, r10, 0x20
	ctx.r[9].u64 = ctx.r[10].u64 & 0x00000000FFFFFFFFu64;
	// 831596BC: 7D0B442E  lfsx f8, r11, r8
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[8].u32)) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831596C0: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 831596C4: F9210088  std r9, 0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[9].u64 ) };
	// 831596C8: 7F0A3040  cmplw cr6, r10, r6
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[6].u32, &mut ctx.xer);
	// 831596CC: C8E10088  lfd f7, 0x88(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 831596D0: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 831596D4: FCA03018  frsp f5, f6
	ctx.f[5].f64 = (ctx.f[6].f64 as f32) as f64;
	// 831596D8: EC850172  fmuls f4, f5, f5
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[5].f64) as f32) as f64);
	// 831596DC: EC650332  fmuls f3, f5, f12
	ctx.f[3].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 831596E0: EC44183A  fmadds f2, f4, f0, f3
	ctx.f[2].f64 = (((ctx.f[4].f64 * ctx.f[0].f64 + ctx.f[3].f64) as f32) as f64);
	// 831596E4: EC22682A  fadds f1, f2, f13
	ctx.f[1].f64 = ((ctx.f[2].f64 + ctx.f[13].f64) as f32) as f64;
	// 831596E8: ED010232  fmuls f8, f1, f8
	ctx.f[8].f64 = (((ctx.f[1].f64 * ctx.f[8].f64) as f32) as f64);
	// 831596EC: D10B0000  stfs f8, 0(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831596F0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 831596F4: 4198FFC4  blt cr6, 0x831596b8
	if ctx.cr[6].lt {
	pc = 0x831596B8; continue 'dispatch;
	}
	// 831596F8: 4800015C  b 0x83159854
	pc = 0x83159854; continue 'dispatch;
	// 831596FC: 7D4B3050  subf r10, r11, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 83159700: C01A0000  lfs f0, 0(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159704: C1BA0004  lfs f13, 4(r26)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83159708: EC000272  fmuls f0, f0, f9
	ctx.f[0].f64 = (((ctx.f[0].f64 * ctx.f[9].f64) as f32) as f64);
	// 8315970C: EDAD0272  fmuls f13, f13, f9
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[9].f64) as f32) as f64);
	// 83159710: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 83159714: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 83159718: 419800F0  blt cr6, 0x83159808
	if ctx.cr[6].lt {
	pc = 0x83159808; continue 'dispatch;
	}
	// 8315971C: 7D4B3050  subf r10, r11, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 83159720: 38AB0001  addi r5, r11, 1
	ctx.r[5].s64 = ctx.r[11].s64 + 1;
	// 83159724: 390AFFFC  addi r8, r10, -4
	ctx.r[8].s64 = ctx.r[10].s64 + -4;
	// 83159728: 392B0003  addi r9, r11, 3
	ctx.r[9].s64 = ctx.r[11].s64 + 3;
	// 8315972C: 550AF0BE  srwi r10, r8, 2
	ctx.r[10].u32 = ctx.r[8].u32.wrapping_shr(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 83159730: 5528103A  slwi r8, r9, 2
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 83159734: 38EA0001  addi r7, r10, 1
	ctx.r[7].s64 = ctx.r[10].s64 + 1;
	// 83159738: 54AA103A  slwi r10, r5, 2
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315973C: 54E5103A  slwi r5, r7, 2
	ctx.r[5].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 83159740: 393E0002  addi r9, r30, 2
	ctx.r[9].s64 = ctx.r[30].s64 + 2;
	// 83159744: 7D08FA14  add r8, r8, r31
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[31].u64;
	// 83159748: 7D4A2214  add r10, r10, r4
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[4].u64;
	// 8315974C: 7C64F850  subf r3, r4, r31
	ctx.r[3].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 83159750: 7CA55A14  add r5, r5, r11
	ctx.r[5].u64 = ctx.r[5].u64 + ctx.r[11].u64;
	// 83159754: 792B0020  clrldi r11, r9, 0x20
	ctx.r[11].u64 = ctx.r[9].u64 & 0x00000000FFFFFFFFu64;
	// 83159758: C188FFF4  lfs f12, -0xc(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-12 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315975C: 39E9FFFF  addi r15, r9, -1
	ctx.r[15].s64 = ctx.r[9].s64 + -1;
	// 83159760: F9610098  std r11, 0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[11].u64 ) };
	// 83159764: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 83159768: 79EB0020  clrldi r11, r15, 0x20
	ctx.r[11].u64 = ctx.r[15].u64 & 0x00000000FFFFFFFFu64;
	// 8315976C: 7BCF0020  clrldi r15, r30, 0x20
	ctx.r[15].u64 = ctx.r[30].u64 & 0x00000000FFFFFFFFu64;
	// 83159770: F96100B8  std r11, 0xb8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u64 ) };
	// 83159774: 39690001  addi r11, r9, 1
	ctx.r[11].s64 = ctx.r[9].s64 + 1;
	// 83159778: F9E100A8  std r15, 0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[15].u64 ) };
	// 8315977C: C8E100A8  lfd f7, 0xa8(r1)
	ctx.f[7].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 83159780: FCC03E9C  fcfid f6, f7
	ctx.f[6].f64 = (ctx.f[7].s64 as f64);
	// 83159784: 796B0020  clrldi r11, r11, 0x20
	ctx.r[11].u64 = ctx.r[11].u64 & 0x00000000FFFFFFFFu64;
	// 83159788: FC403018  frsp f2, f6
	ctx.f[2].f64 = (ctx.f[6].f64 as f32) as f64;
	// 8315978C: F96100C8  std r11, 0xc8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[11].u64 ) };
	// 83159790: C8C100C8  lfd f6, 0xc8(r1)
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 83159794: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 83159798: C8A100B8  lfd f5, 0xb8(r1)
	ctx.f[5].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8315979C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 831597A0: FC802E9C  fcfid f4, f5
	ctx.f[4].f64 = (ctx.f[5].s64 as f64);
	// 831597A4: C9010098  lfd f8, 0x98(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 831597A8: FC60469C  fcfid f3, f8
	ctx.f[3].f64 = (ctx.f[8].s64 as f64);
	// 831597AC: ECE2683A  fmadds f7, f2, f0, f13
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 831597B0: FC202018  frsp f1, f4
	ctx.f[1].f64 = (ctx.f[4].f64 as f32) as f64;
	// 831597B4: FD001818  frsp f8, f3
	ctx.f[8].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831597B8: EC470332  fmuls f2, f7, f12
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[12].f64) as f32) as f64);
	// 831597BC: D04AFFFC  stfs f2, -4(r10)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 831597C0: ECA1683A  fmadds f5, f1, f0, f13
	ctx.f[5].f64 = (((ctx.f[1].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 831597C4: 7C23542E  lfsx f1, r3, r10
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[10].u32)) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 831597C8: EC88683A  fmadds f4, f8, f0, f13
	ctx.f[4].f64 = (((ctx.f[8].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 831597CC: ED850072  fmuls f12, f5, f1
	ctx.f[12].f64 = (((ctx.f[5].f64 * ctx.f[1].f64) as f32) as f64);
	// 831597D0: D18A0000  stfs f12, 0(r10)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 831597D4: FC60369C  fcfid f3, f6
	ctx.f[3].f64 = (ctx.f[6].s64 as f64);
	// 831597D8: C108FFFC  lfs f8, -4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(-4 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 831597DC: ECE40232  fmuls f7, f4, f8
	ctx.f[7].f64 = (((ctx.f[4].f64 * ctx.f[8].f64) as f32) as f64);
	// 831597E0: D0EA0004  stfs f7, 4(r10)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 831597E4: FCC01818  frsp f6, f3
	ctx.f[6].f64 = (ctx.f[3].f64 as f32) as f64;
	// 831597E8: C0880000  lfs f4, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 831597EC: 39080010  addi r8, r8, 0x10
	ctx.r[8].s64 = ctx.r[8].s64 + 16;
	// 831597F0: ECA6683A  fmadds f5, f6, f0, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 831597F4: EC650132  fmuls f3, f5, f4
	ctx.f[3].f64 = (((ctx.f[5].f64 * ctx.f[4].f64) as f32) as f64);
	// 831597F8: D06A0008  stfs f3, 8(r10)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 831597FC: 394A0010  addi r10, r10, 0x10
	ctx.r[10].s64 = ctx.r[10].s64 + 16;
	// 83159800: 4082FF54  bne 0x83159754
	if !ctx.cr[0].eq {
	pc = 0x83159754; continue 'dispatch;
	}
	// 83159804: 81E11224  lwz r15, 0x1224(r1)
	ctx.r[15].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(4644 as u32) ) } as u64;
	// 83159808: 7F053040  cmplw cr6, r5, r6
	ctx.cr[6].compare_u32(ctx.r[5].u32, ctx.r[6].u32, &mut ctx.xer);
	// 8315980C: 40980048  bge cr6, 0x83159854
	if !ctx.cr[6].lt {
	pc = 0x83159854; continue 'dispatch;
	}
	// 83159810: 54AB103A  slwi r11, r5, 2
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83159814: 7D24F850  subf r9, r4, r31
	ctx.r[9].s64 = ctx.r[31].s64 - ctx.r[4].s64;
	// 83159818: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 8315981C: 7D453050  subf r10, r5, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[5].s64;
	// 83159820: 7BC80020  clrldi r8, r30, 0x20
	ctx.r[8].u64 = ctx.r[30].u64 & 0x00000000FFFFFFFFu64;
	// 83159824: 7D895C2E  lfsx f12, r9, r11
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 83159828: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315982C: F90100D8  std r8, 0xd8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[8].u64 ) };
	// 83159830: C90100D8  lfd f8, 0xd8(r1)
	ctx.f[8].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 83159834: FCE0469C  fcfid f7, f8
	ctx.f[7].f64 = (ctx.f[8].s64 as f64);
	// 83159838: 3BDE0001  addi r30, r30, 1
	ctx.r[30].s64 = ctx.r[30].s64 + 1;
	// 8315983C: FCC03818  frsp f6, f7
	ctx.f[6].f64 = (ctx.f[7].f64 as f32) as f64;
	// 83159840: ECA6683A  fmadds f5, f6, f0, f13
	ctx.f[5].f64 = (((ctx.f[6].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 83159844: EC850332  fmuls f4, f5, f12
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[12].f64) as f32) as f64);
	// 83159848: D08B0000  stfs f4, 0(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315984C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83159850: 4082FFD0  bne 0x83159820
	if !ctx.cr[0].eq {
	pc = 0x83159820; continue 'dispatch;
	}
	// 83159854: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 83159858: 7F1DC050  subf r24, r29, r24
	ctx.r[24].s64 = ctx.r[24].s64 - ctx.r[29].s64;
	// 8315985C: 2B180000  cmplwi cr6, r24, 0
	ctx.cr[6].compare_u32(ctx.r[24].u32, 0 as u32, &mut ctx.xer);
	// 83159860: 409AFA48  bne cr6, 0x831592a8
	if !ctx.cr[6].eq {
	pc = 0x831592A8; continue 'dispatch;
	}
	// 83159864: 81210050  lwz r9, 0x50(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 83159868: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315986C: 99750000  stb r11, 0(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[11].u8 ) };
	// 83159870: 4800003C  b 0x831598ac
	pc = 0x831598AC; continue 'dispatch;
	// 83159874: 817A000C  lwz r11, 0xc(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 83159878: 7FDCF214  add r30, r28, r30
	ctx.r[30].u64 = ctx.r[28].u64 + ctx.r[30].u64;
	// 8315987C: 7F1E5840  cmplw cr6, r30, r11
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[11].u32, &mut ctx.xer);
	// 83159880: 41980028  blt cr6, 0x831598a8
	if ctx.cr[6].lt {
	pc = 0x831598A8; continue 'dispatch;
	}
	// 83159884: 815B0050  lwz r10, 0x50(r27)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[27].u32.wrapping_add(80 as u32) ) } as u64;
	// 83159888: 397A000C  addi r11, r26, 0xc
	ctx.r[11].s64 = ctx.r[26].s64 + 12;
	// 8315988C: 3B390001  addi r25, r25, 1
	ctx.r[25].s64 = ctx.r[25].s64 + 1;
	// 83159890: 396B0014  addi r11, r11, 0x14
	ctx.r[11].s64 = ctx.r[11].s64 + 20;
	// 83159894: 7F195040  cmplw cr6, r25, r10
	ctx.cr[6].compare_u32(ctx.r[25].u32, ctx.r[10].u32, &mut ctx.xer);
	// 83159898: 40980010  bge cr6, 0x831598a8
	if !ctx.cr[6].lt {
	pc = 0x831598A8; continue 'dispatch;
	}
	// 8315989C: 810B0000  lwz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 831598A0: 7F1E4040  cmplw cr6, r30, r8
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[8].u32, &mut ctx.xer);
	// 831598A4: 4098FFE8  bge cr6, 0x8315988c
	if !ctx.cr[6].lt {
	pc = 0x8315988C; continue 'dispatch;
	}
	// 831598A8: 9A350000  stb r17, 0(r21)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[21].u32.wrapping_add(0 as u32), ctx.r[17].u8 ) };
	// 831598AC: 81610058  lwz r11, 0x58(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 831598B0: 3AF70001  addi r23, r23, 1
	ctx.r[23].s64 = ctx.r[23].s64 + 1;
	// 831598B4: 3AD60004  addi r22, r22, 4
	ctx.r[22].s64 = ctx.r[22].s64 + 4;
	// 831598B8: 3AB50001  addi r21, r21, 1
	ctx.r[21].s64 = ctx.r[21].s64 + 1;
	// 831598BC: 7F175840  cmplw cr6, r23, r11
	ctx.cr[6].compare_u32(ctx.r[23].u32, ctx.r[11].u32, &mut ctx.xer);
	// 831598C0: 4198F970  blt cr6, 0x83159230
	if ctx.cr[6].lt {
	pc = 0x83159230; continue 'dispatch;
	}
	// 831598C4: 2F100001  cmpwi cr6, r16, 1
	ctx.cr[6].compare_i32(ctx.r[16].s32, 1, &mut ctx.xer);
	// 831598C8: 409A000C  bne cr6, 0x831598d4
	if !ctx.cr[6].eq {
	pc = 0x831598D4; continue 'dispatch;
	}
	// 831598CC: C00F0104  lfs f0, 0x104(r15)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[15].u32.wrapping_add(260 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831598D0: D00F0108  stfs f0, 0x108(r15)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[15].u32.wrapping_add(264 as u32), tmp.u32 ) };
	// 831598D4: 81410130  lwz r10, 0x130(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 831598D8: 7E2B8B78  mr r11, r17
	ctx.r[11].u64 = ctx.r[17].u64;
	// 831598DC: 93330000  stw r25, 0(r19)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[19].u32.wrapping_add(0 as u32), ctx.r[25].u32 ) };
	// 831598E0: 93D20000  stw r30, 0(r18)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 831598E4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 831598E8: 419A0020  beq cr6, 0x83159908
	if ctx.cr[6].eq {
	pc = 0x83159908; continue 'dispatch;
	}
	// 831598EC: 394100F0  addi r10, r1, 0xf0
	ctx.r[10].s64 = ctx.r[1].s64 + 240;
	// 831598F0: 922A0000  stw r17, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[17].u32 ) };
	// 831598F4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 831598F8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 831598FC: 81210130  lwz r9, 0x130(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(304 as u32) ) } as u64;
	// 83159900: 7F0B4840  cmplw cr6, r11, r9
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[9].u32, &mut ctx.xer);
	// 83159904: 4198FFEC  blt cr6, 0x831598f0
	if ctx.cr[6].lt {
	pc = 0x831598F0; continue 'dispatch;
	}
	// 83159908: 38211210  addi r1, r1, 0x1210
	ctx.r[1].s64 = ctx.r[1].s64 + 4624;
	// 8315990C: 4804E874  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159910(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83159910 size=184
    let mut pc: u32 = 0x83159910;
    'dispatch: loop {
        match pc {
            0x83159910 => {
    //   block [0x83159910..0x831599C8)
	// 83159910: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159914: 4804E859  bl 0x831a816c
	ctx.lr = 0x83159918;
	sub_831A8130(ctx, base);
	// 83159918: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315991C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159920: 83DF00E8  lwz r30, 0xe8(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(232 as u32) ) } as u64;
	// 83159924: 2B1E0000  cmplwi cr6, r30, 0
	ctx.cr[6].compare_u32(ctx.r[30].u32, 0 as u32, &mut ctx.xer);
	// 83159928: 409A0014  bne cr6, 0x8315993c
	if !ctx.cr[6].eq {
	pc = 0x8315993C; continue 'dispatch;
	}
	// 8315992C: C03F001C  lfs f1, 0x1c(r31)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 83159930: 4BFFF329  bl 0x83158c58
	ctx.lr = 0x83159934;
	sub_83158C58(ctx, base);
	// 83159934: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83159938: 4804E884  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315993C: 3BBF0020  addi r29, r31, 0x20
	ctx.r[29].s64 = ctx.r[31].s64 + 32;
	// 83159940: 38DF0024  addi r6, r31, 0x24
	ctx.r[6].s64 = ctx.r[31].s64 + 36;
	// 83159944: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 83159948: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 8315994C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159950: 4BFFF7E1  bl 0x83159130
	ctx.lr = 0x83159954;
	sub_83159130(ctx, base);
	// 83159954: 817F0024  lwz r11, 0x24(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 83159958: 815E0050  lwz r10, 0x50(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315995C: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 83159960: 41980024  blt cr6, 0x83159984
	if ctx.cr[6].lt {
	pc = 0x83159984; continue 'dispatch;
	}
	// 83159964: 817E005C  lwz r11, 0x5c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(92 as u32) ) } as u64;
	// 83159968: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315996C: 917F010C  stw r11, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 83159970: C01E0058  lfs f0, 0x58(r30)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(88 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159974: D01F001C  stfs f0, 0x1c(r31)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 83159978: 915F00E8  stw r10, 0xe8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(232 as u32), ctx.r[10].u32 ) };
	// 8315997C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 83159980: 4804E83C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83159984: 811D0000  lwz r8, 0(r29)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159988: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315998C: 7CEB5214  add r7, r11, r10
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 83159990: 54EB103A  slwi r11, r7, 2
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 83159994: F9010050  std r8, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[8].u64 ) };
	// 83159998: C8010050  lfd f0, 0x50(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) };
	// 8315999C: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 831599A0: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 831599A4: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 831599A8: 80CB0010  lwz r6, 0x10(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 831599AC: 90DF010C  stw r6, 0x10c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(268 as u32), ctx.r[6].u32 ) };
	// 831599B0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 831599B4: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 831599B8: ED2C52FA  fmadds f9, f12, f11, f10
	ctx.f[9].f64 = (((ctx.f[12].f64 * ctx.f[11].f64 + ctx.f[10].f64) as f32) as f64);
	// 831599BC: D13F001C  stfs f9, 0x1c(r31)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 831599C0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 831599C4: 4804E7F8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_831599C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x831599C8 size=80
    let mut pc: u32 = 0x831599C8;
    'dispatch: loop {
        match pc {
            0x831599C8 => {
    //   block [0x831599C8..0x83159A18)
	// 831599C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 831599CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 831599D0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 831599D4: 8163010C  lwz r11, 0x10c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(268 as u32) ) } as u64;
	// 831599D8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 831599DC: 409A002C  bne cr6, 0x83159a08
	if !ctx.cr[6].eq {
	pc = 0x83159A08; continue 'dispatch;
	}
	// 831599E0: 4BFFF039  bl 0x83158a18
	ctx.lr = 0x831599E4;
	sub_83158A18(ctx, base);
	// 831599E4: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 831599E8: 39630028  addi r11, r3, 0x28
	ctx.r[11].s64 = ctx.r[3].s64 + 40;
	// 831599EC: 91430020  stw r10, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[10].u32 ) };
	// 831599F0: 916300E8  stw r11, 0xe8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 831599F4: 91430024  stw r10, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 831599F8: C003007C  lfs f0, 0x7c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(124 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 831599FC: D003001C  stfs f0, 0x1c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 83159A00: 81630038  lwz r11, 0x38(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(56 as u32) ) } as u64;
	// 83159A04: 9163010C  stw r11, 0x10c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 83159A08: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159A0C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159A10: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159A14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159A18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83159A18 size=88
    let mut pc: u32 = 0x83159A18;
    'dispatch: loop {
        match pc {
            0x83159A18 => {
    //   block [0x83159A18..0x83159A70)
	// 83159A18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159A1C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159A20: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159A24: 8163010C  lwz r11, 0x10c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(268 as u32) ) } as u64;
	// 83159A28: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83159A2C: 40990034  ble cr6, 0x83159a60
	if !ctx.cr[6].gt {
	pc = 0x83159A60; continue 'dispatch;
	}
	// 83159A30: 2F0B0005  cmpwi cr6, r11, 5
	ctx.cr[6].compare_i32(ctx.r[11].s32, 5, &mut ctx.xer);
	// 83159A34: 4199002C  bgt cr6, 0x83159a60
	if ctx.cr[6].gt {
	pc = 0x83159A60; continue 'dispatch;
	}
	// 83159A38: 4BFFF199  bl 0x83158bd0
	ctx.lr = 0x83159A3C;
	sub_83158BD0(ctx, base);
	// 83159A3C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83159A40: 39630088  addi r11, r3, 0x88
	ctx.r[11].s64 = ctx.r[3].s64 + 136;
	// 83159A44: 91430020  stw r10, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[10].u32 ) };
	// 83159A48: 916300E8  stw r11, 0xe8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 83159A4C: 91430024  stw r10, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 83159A50: C00300DC  lfs f0, 0xdc(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(220 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159A54: D003001C  stfs f0, 0x1c(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 83159A58: 81630098  lwz r11, 0x98(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(152 as u32) ) } as u64;
	// 83159A5C: 9163010C  stw r11, 0x10c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(268 as u32), ctx.r[11].u32 ) };
	// 83159A60: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159A64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159A68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159A6C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159A70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83159A70 size=12
    let mut pc: u32 = 0x83159A70;
    'dispatch: loop {
        match pc {
            0x83159A70 => {
    //   block [0x83159A70..0x83159A7C)
	// 83159A70: 8163010C  lwz r11, 0x10c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(268 as u32) ) } as u64;
	// 83159A74: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83159A78: 4C990020  blelr cr6
	if !ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159A7C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83159A7C size=8
    let mut pc: u32 = 0x83159A7C;
    'dispatch: loop {
        match pc {
            0x83159A7C => {
    //   block [0x83159A7C..0x83159A84)
	// 83159A7C: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 83159A80: 4D990020  bgtlr cr6
	if ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159A84(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x83159A84 size=124
    let mut pc: u32 = 0x83159A84;
    'dispatch: loop {
        match pc {
            0x83159A84 => {
    //   block [0x83159A84..0x83159B00)
	// 83159A84: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159A88: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 83159A8C: 39200080  li r9, 0x80
	ctx.r[9].s64 = 128;
	// 83159A90: 91430090  stw r10, 0x90(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(144 as u32), ctx.r[10].u32 ) };
	// 83159A94: 39000007  li r8, 7
	ctx.r[8].s64 = 7;
	// 83159A98: 91230094  stw r9, 0x94(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(148 as u32), ctx.r[9].u32 ) };
	// 83159A9C: C1A3001C  lfs f13, 0x1c(r3)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 83159AA0: C00B5B8C  lfs f0, 0x5b8c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(23436 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159AA4: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 83159AA8: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 83159AAC: D1830088  stfs f12, 0x88(r3)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(136 as u32), tmp.u32 ) };
	// 83159AB0: C163001C  lfs f11, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 83159AB4: 91030098  stw r8, 0x98(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(152 as u32), ctx.r[8].u32 ) };
	// 83159AB8: D163008C  stfs f11, 0x8c(r3)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(140 as u32), tmp.u32 ) };
	// 83159ABC: 38C00008  li r6, 8
	ctx.r[6].s64 = 8;
	// 83159AC0: C143001C  lfs f10, 0x1c(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 83159AC4: 90E300D8  stw r7, 0xd8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(216 as u32), ctx.r[7].u32 ) };
	// 83159AC8: D14300DC  stfs f10, 0xdc(r3)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(220 as u32), tmp.u32 ) };
	// 83159ACC: 90C300E4  stw r6, 0xe4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(228 as u32), ctx.r[6].u32 ) };
	// 83159AD0: 3CA08219  lis r5, -0x7de7
	ctx.r[5].s64 = -2112290816;
	// 83159AD4: FD205090  fmr f9, f10
	ctx.f[9].f64 = ctx.f[10].f64;
	// 83159AD8: 39630088  addi r11, r3, 0x88
	ctx.r[11].s64 = ctx.r[3].s64 + 136;
	// 83159ADC: D123001C  stfs f9, 0x1c(r3)
	tmp.f32 = (ctx.f[9].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(28 as u32), tmp.u32 ) };
	// 83159AE0: 91430020  stw r10, 0x20(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32 as u32), ctx.r[10].u32 ) };
	// 83159AE4: 91430024  stw r10, 0x24(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(36 as u32), ctx.r[10].u32 ) };
	// 83159AE8: 916300E8  stw r11, 0xe8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(232 as u32), ctx.r[11].u32 ) };
	// 83159AEC: C0055B74  lfs f0, 0x5b74(r5)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(23412 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 83159AF0: D00300E0  stfs f0, 0xe0(r3)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(224 as u32), tmp.u32 ) };
	// 83159AF4: 80830098  lwz r4, 0x98(r3)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(152 as u32) ) } as u64;
	// 83159AF8: 9083010C  stw r4, 0x10c(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(268 as u32), ctx.r[4].u32 ) };
	// 83159AFC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159B00(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159B00 size=40
    let mut pc: u32 = 0x83159B00;
    'dispatch: loop {
        match pc {
            0x83159B00 => {
    //   block [0x83159B00..0x83159B28)
	// 83159B00: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159B04: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159B08: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159B0C: 38600004  li r3, 4
	ctx.r[3].s64 = 4;
	// 83159B10: 480061A9  bl 0x8315fcb8
	ctx.lr = 0x83159B14;
	sub_8315FCB8(ctx, base);
	// 83159B14: 38633080  addi r3, r3, 0x3080
	ctx.r[3].s64 = ctx.r[3].s64 + 12416;
	// 83159B18: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159B1C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159B20: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159B24: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159B28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159B28 size=208
    let mut pc: u32 = 0x83159B28;
    'dispatch: loop {
        match pc {
            0x83159B28 => {
    //   block [0x83159B28..0x83159BF8)
	// 83159B28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159B2C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159B30: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83159B34: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159B38: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159B3C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159B40: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83159B44: 397F0008  addi r11, r31, 8
	ctx.r[11].s64 = ctx.r[31].s64 + 8;
	// 83159B48: 7FC9F378  mr r9, r30
	ctx.r[9].u64 = ctx.r[30].u64;
	// 83159B4C: 39400008  li r10, 8
	ctx.r[10].s64 = 8;
	// 83159B50: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 83159B54: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83159B58: 912B0000  stw r9, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83159B5C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 83159B60: 4200FFF8  bdnz 0x83159b58
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x83159B58; continue 'dispatch;
	}
	// 83159B64: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159B68: 93DF0028  stw r30, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 83159B6C: 93DF002C  stw r30, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[30].u32 ) };
	// 83159B70: 38A03000  li r5, 0x3000
	ctx.r[5].s64 = 12288;
	// 83159B74: 93DF0030  stw r30, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[30].u32 ) };
	// 83159B78: 394B5B90  addi r10, r11, 0x5b90
	ctx.r[10].s64 = ctx.r[11].s64 + 23440;
	// 83159B7C: 93DF0034  stw r30, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[30].u32 ) };
	// 83159B80: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 83159B84: 387F0050  addi r3, r31, 0x50
	ctx.r[3].s64 = ctx.r[31].s64 + 80;
	// 83159B88: 915F0000  stw r10, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 83159B8C: 93DF0038  stw r30, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[30].u32 ) };
	// 83159B90: 93DF003C  stw r30, 0x3c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), ctx.r[30].u32 ) };
	// 83159B94: 9BDF0040  stb r30, 0x40(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(64 as u32), ctx.r[30].u8 ) };
	// 83159B98: 9BDF0041  stb r30, 0x41(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(65 as u32), ctx.r[30].u8 ) };
	// 83159B9C: 93DF0044  stw r30, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[30].u32 ) };
	// 83159BA0: 93DF0048  stw r30, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[30].u32 ) };
	// 83159BA4: 93DF004C  stw r30, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[30].u32 ) };
	// 83159BA8: 4804E639  bl 0x831a81e0
	ctx.lr = 0x83159BAC;
	sub_831A81E0(ctx, base);
	// 83159BAC: 93DF3050  stw r30, 0x3050(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12368 as u32), ctx.r[30].u32 ) };
	// 83159BB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159BB4: 93DF3054  stw r30, 0x3054(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12372 as u32), ctx.r[30].u32 ) };
	// 83159BB8: 93DF3058  stw r30, 0x3058(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12376 as u32), ctx.r[30].u32 ) };
	// 83159BBC: 93DF305C  stw r30, 0x305c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12380 as u32), ctx.r[30].u32 ) };
	// 83159BC0: 93DF3060  stw r30, 0x3060(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12384 as u32), ctx.r[30].u32 ) };
	// 83159BC4: 93DF3064  stw r30, 0x3064(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12388 as u32), ctx.r[30].u32 ) };
	// 83159BC8: 93DF3068  stw r30, 0x3068(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12392 as u32), ctx.r[30].u32 ) };
	// 83159BCC: 93DF306C  stw r30, 0x306c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12396 as u32), ctx.r[30].u32 ) };
	// 83159BD0: 93DF3070  stw r30, 0x3070(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12400 as u32), ctx.r[30].u32 ) };
	// 83159BD4: 93DF3074  stw r30, 0x3074(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12404 as u32), ctx.r[30].u32 ) };
	// 83159BD8: 93DF3078  stw r30, 0x3078(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12408 as u32), ctx.r[30].u32 ) };
	// 83159BDC: 93DF307C  stw r30, 0x307c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12412 as u32), ctx.r[30].u32 ) };
	// 83159BE0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83159BE4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159BE8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159BEC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83159BF0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159BF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159BF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159BF8 size=132
    let mut pc: u32 = 0x83159BF8;
    'dispatch: loop {
        match pc {
            0x83159BF8 => {
    //   block [0x83159BF8..0x83159C7C)
	// 83159BF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159BFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159C00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159C04: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159C08: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159C0C: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 83159C10: 38AB5BC8  addi r5, r11, 0x5bc8
	ctx.r[5].s64 = ctx.r[11].s64 + 23496;
	// 83159C14: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 83159C18: 38603080  li r3, 0x3080
	ctx.r[3].s64 = 12416;
	// 83159C1C: 480060DD  bl 0x8315fcf8
	ctx.lr = 0x83159C20;
	sub_8315FCF8(ctx, base);
	// 83159C20: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159C24: 419A0014  beq cr6, 0x83159c38
	if ctx.cr[6].eq {
	pc = 0x83159C38; continue 'dispatch;
	}
	// 83159C28: 4BFFFF01  bl 0x83159b28
	ctx.lr = 0x83159C2C;
	sub_83159B28(ctx, base);
	// 83159C2C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159C30: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83159C34: 409A002C  bne cr6, 0x83159c60
	if !ctx.cr[6].eq {
	pc = 0x83159C60; continue 'dispatch;
	}
	// 83159C38: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159C3C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159C40: 388B5B9C  addi r4, r11, 0x5b9c
	ctx.r[4].s64 = ctx.r[11].s64 + 23452;
	// 83159C44: 48005ED5  bl 0x8315fb18
	ctx.lr = 0x83159C48;
	sub_8315FB18(ctx, base);
	// 83159C48: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159C4C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159C50: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159C54: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159C58: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159C5C: 4E800020  blr
	return;
	// 83159C60: 48004709  bl 0x8315e368
	ctx.lr = 0x83159C64;
	sub_8315E368(ctx, base);
	// 83159C64: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159C68: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159C6C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159C70: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159C74: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159C78: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159C80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159C80 size=120
    let mut pc: u32 = 0x83159C80;
    'dispatch: loop {
        match pc {
            0x83159C80 => {
    //   block [0x83159C80..0x83159CF8)
	// 83159C80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159C84: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159C88: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83159C8C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159C90: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159C94: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159C98: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 83159C9C: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 83159CA0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159CA4: 419A0014  beq cr6, 0x83159cb8
	if ctx.cr[6].eq {
	pc = 0x83159CB8; continue 'dispatch;
	}
	// 83159CA8: 48004531  bl 0x8315e1d8
	ctx.lr = 0x83159CAC;
	sub_8315E1D8(ctx, base);
	// 83159CAC: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 83159CB0: 48004429  bl 0x8315e0d8
	ctx.lr = 0x83159CB4;
	sub_8315E0D8(ctx, base);
	// 83159CB4: 93DF004C  stw r30, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[30].u32 ) };
	// 83159CB8: 807F3054  lwz r3, 0x3054(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12372 as u32) ) } as u64;
	// 83159CBC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159CC0: 419A000C  beq cr6, 0x83159ccc
	if ctx.cr[6].eq {
	pc = 0x83159CCC; continue 'dispatch;
	}
	// 83159CC4: 480097B5  bl 0x83163478
	ctx.lr = 0x83159CC8;
	sub_83163478(ctx, base);
	// 83159CC8: 93DF3054  stw r30, 0x3054(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12372 as u32), ctx.r[30].u32 ) };
	// 83159CCC: 807F3050  lwz r3, 0x3050(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12368 as u32) ) } as u64;
	// 83159CD0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159CD4: 419A000C  beq cr6, 0x83159ce0
	if ctx.cr[6].eq {
	pc = 0x83159CE0; continue 'dispatch;
	}
	// 83159CD8: 480097A1  bl 0x83163478
	ctx.lr = 0x83159CDC;
	sub_83163478(ctx, base);
	// 83159CDC: 93DF3050  stw r30, 0x3050(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12368 as u32), ctx.r[30].u32 ) };
	// 83159CE0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83159CE4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159CE8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159CEC: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83159CF0: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159CF4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159CF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159CF8 size=76
    let mut pc: u32 = 0x83159CF8;
    'dispatch: loop {
        match pc {
            0x83159CF8 => {
    //   block [0x83159CF8..0x83159D44)
	// 83159CF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159CFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159D00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159D04: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159D08: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159D0C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159D10: 548A07FE  clrlwi r10, r4, 0x1f
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 83159D14: 392B5350  addi r9, r11, 0x5350
	ctx.r[9].s64 = ctx.r[11].s64 + 21328;
	// 83159D18: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 83159D1C: 913F0000  stw r9, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 83159D20: 419A0010  beq cr6, 0x83159d30
	if ctx.cr[6].eq {
	pc = 0x83159D30; continue 'dispatch;
	}
	// 83159D24: 38803080  li r4, 0x3080
	ctx.r[4].s64 = 12416;
	// 83159D28: 48005F59  bl 0x8315fc80
	ctx.lr = 0x83159D2C;
	sub_8315FC80(ctx, base);
	// 83159D2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159D30: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159D34: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159D38: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159D3C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159D40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159D48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159D48 size=80
    let mut pc: u32 = 0x83159D48;
    'dispatch: loop {
        match pc {
            0x83159D48 => {
    //   block [0x83159D48..0x83159D98)
	// 83159D48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159D4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159D50: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159D54: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159D58: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159D5C: 4BFFFF25  bl 0x83159c80
	ctx.lr = 0x83159D60;
	sub_83159C80(ctx, base);
	// 83159D60: 480041E9  bl 0x8315df48
	ctx.lr = 0x83159D64;
	sub_8315DF48(ctx, base);
	// 83159D64: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 83159D68: 419A001C  beq cr6, 0x83159d84
	if ctx.cr[6].eq {
	pc = 0x83159D84; continue 'dispatch;
	}
	// 83159D6C: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159D70: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83159D74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159D78: 814B0008  lwz r10, 8(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 83159D7C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 83159D80: 4E800421  bctrl
	ctx.lr = 0x83159D84;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 83159D84: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 83159D88: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159D8C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159D90: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159D94: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159D98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x83159D98 size=224
    let mut pc: u32 = 0x83159D98;
    'dispatch: loop {
        match pc {
            0x83159D98 => {
    //   block [0x83159D98..0x83159E78)
	// 83159D98: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159D9C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 83159DA0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 83159DA4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 83159DA8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159DAC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159DB0: 4BFFFED1  bl 0x83159c80
	ctx.lr = 0x83159DB4;
	sub_83159C80(ctx, base);
	// 83159DB4: 38800014  li r4, 0x14
	ctx.r[4].s64 = 20;
	// 83159DB8: 387F3058  addi r3, r31, 0x3058
	ctx.r[3].s64 = ctx.r[31].s64 + 12376;
	// 83159DBC: 4800961D  bl 0x831633d8
	ctx.lr = 0x83159DC0;
	sub_831633D8(ctx, base);
	// 83159DC0: 907F3050  stw r3, 0x3050(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12368 as u32), ctx.r[3].u32 ) };
	// 83159DC4: 38800014  li r4, 0x14
	ctx.r[4].s64 = 20;
	// 83159DC8: 387F306C  addi r3, r31, 0x306c
	ctx.r[3].s64 = ctx.r[31].s64 + 12396;
	// 83159DCC: 4800960D  bl 0x831633d8
	ctx.lr = 0x83159DD0;
	sub_831633D8(ctx, base);
	// 83159DD0: 817F3050  lwz r11, 0x3050(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12368 as u32) ) } as u64;
	// 83159DD4: 3BDF3054  addi r30, r31, 0x3054
	ctx.r[30].s64 = ctx.r[31].s64 + 12372;
	// 83159DD8: 907F3054  stw r3, 0x3054(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12372 as u32), ctx.r[3].u32 ) };
	// 83159DDC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 83159DE0: 419A006C  beq cr6, 0x83159e4c
	if ctx.cr[6].eq {
	pc = 0x83159E4C; continue 'dispatch;
	}
	// 83159DE4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159DE8: 419A0064  beq cr6, 0x83159e4c
	if ctx.cr[6].eq {
	pc = 0x83159E4C; continue 'dispatch;
	}
	// 83159DEC: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 83159DF0: 809F0004  lwz r4, 4(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83159DF4: 480096AD  bl 0x831634a0
	ctx.lr = 0x83159DF8;
	sub_831634A0(ctx, base);
	// 83159DF8: 809F0008  lwz r4, 8(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 83159DFC: 807E0000  lwz r3, 0(r30)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 83159E00: 480096A1  bl 0x831634a0
	ctx.lr = 0x83159E04;
	sub_831634A0(ctx, base);
	// 83159E04: 38E03000  li r7, 0x3000
	ctx.r[7].s64 = 12288;
	// 83159E08: 807F3050  lwz r3, 0x3050(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12368 as u32) ) } as u64;
	// 83159E0C: 38DF0050  addi r6, r31, 0x50
	ctx.r[6].s64 = ctx.r[31].s64 + 80;
	// 83159E10: 7FC5F378  mr r5, r30
	ctx.r[5].u64 = ctx.r[30].u64;
	// 83159E14: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83159E18: 48004171  bl 0x8315df88
	ctx.lr = 0x83159E1C;
	sub_8315DF88(ctx, base);
	// 83159E1C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159E20: 907F004C  stw r3, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[3].u32 ) };
	// 83159E24: 409A0010  bne cr6, 0x83159e34
	if !ctx.cr[6].eq {
	pc = 0x83159E34; continue 'dispatch;
	}
	// 83159E28: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159E2C: 388B5C04  addi r4, r11, 0x5c04
	ctx.r[4].s64 = ctx.r[11].s64 + 23556;
	// 83159E30: 48000024  b 0x83159e54
	pc = 0x83159E54; continue 'dispatch;
	// 83159E34: 38800020  li r4, 0x20
	ctx.r[4].s64 = 32;
	// 83159E38: 48002B81  bl 0x8315c9b8
	ctx.lr = 0x83159E3C;
	sub_8315C9B8(ctx, base);
	// 83159E3C: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 83159E40: 48004319  bl 0x8315e158
	ctx.lr = 0x83159E44;
	sub_8315E158(ctx, base);
	// 83159E44: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 83159E48: 48000018  b 0x83159e60
	pc = 0x83159E60; continue 'dispatch;
	// 83159E4C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159E50: 388B5BD8  addi r4, r11, 0x5bd8
	ctx.r[4].s64 = ctx.r[11].s64 + 23512;
	// 83159E54: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159E58: 48005CC1  bl 0x8315fb18
	ctx.lr = 0x83159E5C;
	sub_8315FB18(ctx, base);
	// 83159E5C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159E60: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 83159E64: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 83159E68: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 83159E6C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 83159E70: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 83159E74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83159E78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x83159E78 size=636
    let mut pc: u32 = 0x83159E78;
    'dispatch: loop {
        match pc {
            0x83159E78 => {
    //   block [0x83159E78..0x8315A0F4)
	// 83159E78: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 83159E7C: 4804E2F1  bl 0x831a816c
	ctx.lr = 0x83159E80;
	sub_831A8130(ctx, base);
	// 83159E80: 9421FF50  stwu r1, -0xb0(r1)
	ea = ctx.r[1].u32.wrapping_add(-176 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 83159E84: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 83159E88: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 83159E8C: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83159E90: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 83159E94: 419A0238  beq cr6, 0x8315a0cc
	if ctx.cr[6].eq {
	pc = 0x8315A0CC; continue 'dispatch;
	}
	// 83159E98: 817F003C  lwz r11, 0x3c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 83159E9C: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 83159EA0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83159EA4: 409A0008  bne cr6, 0x83159eac
	if !ctx.cr[6].eq {
	pc = 0x83159EAC; continue 'dispatch;
	}
	// 83159EA8: 93BF0038  stw r29, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[29].u32 ) };
	// 83159EAC: 817F0038  lwz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 83159EB0: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 83159EB4: 409A01FC  bne cr6, 0x8315a0b0
	if !ctx.cr[6].eq {
	pc = 0x8315A0B0; continue 'dispatch;
	}
	// 83159EB8: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 83159EBC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83159EC0: 409A0160  bne cr6, 0x8315a020
	if !ctx.cr[6].eq {
	pc = 0x8315A020; continue 'dispatch;
	}
	// 83159EC4: 3CA07FFF  lis r5, 0x7fff
	ctx.r[5].s64 = 2147418112;
	// 83159EC8: 38C10078  addi r6, r1, 0x78
	ctx.r[6].s64 = ctx.r[1].s64 + 120;
	// 83159ECC: 60A5FFFF  ori r5, r5, 0xffff
	ctx.r[5].u64 = ctx.r[5].u64 | 65535;
	// 83159ED0: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83159ED4: 48007CA5  bl 0x83161b78
	ctx.lr = 0x83159ED8;
	sub_83161B78(ctx, base);
	// 83159ED8: 38C10062  addi r6, r1, 0x62
	ctx.r[6].s64 = ctx.r[1].s64 + 98;
	// 83159EDC: 38A10060  addi r5, r1, 0x60
	ctx.r[5].s64 = ctx.r[1].s64 + 96;
	// 83159EE0: 8081007C  lwz r4, 0x7c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 83159EE4: 80610078  lwz r3, 0x78(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83159EE8: 48008E49  bl 0x83162d30
	ctx.lr = 0x83159EEC;
	sub_83162D30(ctx, base);
	// 83159EEC: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 83159EF0: 409A001C  bne cr6, 0x83159f0c
	if !ctx.cr[6].eq {
	pc = 0x83159F0C; continue 'dispatch;
	}
	// 83159EF4: 38A10078  addi r5, r1, 0x78
	ctx.r[5].s64 = ctx.r[1].s64 + 120;
	// 83159EF8: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83159EFC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83159F00: 48007C89  bl 0x83161b88
	ctx.lr = 0x83159F04;
	sub_83161B88(ctx, base);
	// 83159F04: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 83159F08: 4804E2B4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83159F0C: 89410060  lbz r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 83159F10: 2B0A0006  cmplwi cr6, r10, 6
	ctx.cr[6].compare_u32(ctx.r[10].u32, 6 as u32, &mut ctx.xer);
	// 83159F14: 419A0024  beq cr6, 0x83159f38
	if ctx.cr[6].eq {
	pc = 0x83159F38; continue 'dispatch;
	}
	// 83159F18: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159F1C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159F20: 388B5C80  addi r4, r11, 0x5c80
	ctx.r[4].s64 = ctx.r[11].s64 + 23680;
	// 83159F24: 48005BF5  bl 0x8315fb18
	ctx.lr = 0x83159F28;
	sub_8315FB18(ctx, base);
	// 83159F28: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 83159F2C: 915F0048  stw r10, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[10].u32 ) };
	// 83159F30: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 83159F34: 4804E288  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83159F38: 3901006C  addi r8, r1, 0x6c
	ctx.r[8].s64 = ctx.r[1].s64 + 108;
	// 83159F3C: 8081007C  lwz r4, 0x7c(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(124 as u32) ) } as u64;
	// 83159F40: 39610070  addi r11, r1, 0x70
	ctx.r[11].s64 = ctx.r[1].s64 + 112;
	// 83159F44: 80610078  lwz r3, 0x78(r1)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) } as u64;
	// 83159F48: 91010054  stw r8, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[8].u32 ) };
	// 83159F4C: 39410068  addi r10, r1, 0x68
	ctx.r[10].s64 = ctx.r[1].s64 + 104;
	// 83159F50: 39210061  addi r9, r1, 0x61
	ctx.r[9].s64 = ctx.r[1].s64 + 97;
	// 83159F54: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 83159F58: 39010063  addi r8, r1, 0x63
	ctx.r[8].s64 = ctx.r[1].s64 + 99;
	// 83159F5C: 38E10064  addi r7, r1, 0x64
	ctx.r[7].s64 = ctx.r[1].s64 + 100;
	// 83159F60: 38C10065  addi r6, r1, 0x65
	ctx.r[6].s64 = ctx.r[1].s64 + 101;
	// 83159F64: 38A10066  addi r5, r1, 0x66
	ctx.r[5].s64 = ctx.r[1].s64 + 102;
	// 83159F68: 48008E19  bl 0x83162d80
	ctx.lr = 0x83159F6C;
	sub_83162D80(ctx, base);
	// 83159F6C: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 83159F70: 419AFF84  beq cr6, 0x83159ef4
	if ctx.cr[6].eq {
	pc = 0x83159EF4; continue 'dispatch;
	}
	// 83159F74: 89610061  lbz r11, 0x61(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(97 as u32) ) } as u64;
	// 83159F78: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 83159F7C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 83159F80: 41980154  blt cr6, 0x8315a0d4
	if ctx.cr[6].lt {
	pc = 0x8315A0D4; continue 'dispatch;
	}
	// 83159F84: 81210068  lwz r9, 0x68(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 83159F88: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 83159F8C: 40990148  ble cr6, 0x8315a0d4
	if !ctx.cr[6].gt {
	pc = 0x8315A0D4; continue 'dispatch;
	}
	// 83159F90: 8141006C  lwz r10, 0x6c(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(108 as u32) ) } as u64;
	// 83159F94: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 83159F98: 4198013C  blt cr6, 0x8315a0d4
	if ctx.cr[6].lt {
	pc = 0x8315A0D4; continue 'dispatch;
	}
	// 83159F9C: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 83159FA0: 40990024  ble cr6, 0x83159fc4
	if !ctx.cr[6].gt {
	pc = 0x83159FC4; continue 'dispatch;
	}
	// 83159FA4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 83159FA8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 83159FAC: 388B5C4C  addi r4, r11, 0x5c4c
	ctx.r[4].s64 = ctx.r[11].s64 + 23628;
	// 83159FB0: 48005B69  bl 0x8315fb18
	ctx.lr = 0x83159FB4;
	sub_8315FB18(ctx, base);
	// 83159FB4: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 83159FB8: 915F0048  stw r10, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[10].u32 ) };
	// 83159FBC: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 83159FC0: 4804E1FC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 83159FC4: 7D2907B4  extsw r9, r9
	ctx.r[9].s64 = ctx.r[9].s32 as i64;
	// 83159FC8: 915F0030  stw r10, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[10].u32 ) };
	// 83159FCC: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 83159FD0: 38A10078  addi r5, r1, 0x78
	ctx.r[5].s64 = ctx.r[1].s64 + 120;
	// 83159FD4: F9210080  std r9, 0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[9].u64 ) };
	// 83159FD8: C8010080  lfd f0, 0x80(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 83159FDC: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 83159FE0: 93BF0044  stw r29, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[29].u32 ) };
	// 83159FE4: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 83159FE8: D19F0028  stfs f12, 0x28(r31)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), tmp.u32 ) };
	// 83159FEC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 83159FF0: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 83159FF4: 48007B95  bl 0x83161b88
	ctx.lr = 0x83159FF8;
	sub_83161B88(ctx, base);
	// 83159FF8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 83159FFC: 4BFFFD9D  bl 0x83159d98
	ctx.lr = 0x8315A000;
	sub_83159D98(ctx, base);
	// 8315A000: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315A004: 409A0014  bne cr6, 0x8315a018
	if !ctx.cr[6].eq {
	pc = 0x8315A018; continue 'dispatch;
	}
	// 8315A008: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 8315A00C: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 8315A010: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8315A014: 4804E1A8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315A018: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315A01C: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 8315A020: 817F0048  lwz r11, 0x48(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 8315A024: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8315A028: 409A0030  bne cr6, 0x8315a058
	if !ctx.cr[6].eq {
	pc = 0x8315A058; continue 'dispatch;
	}
	// 8315A02C: 39600060  li r11, 0x60
	ctx.r[11].s64 = 96;
	// 8315A030: 7D5E5B96  divwu r10, r30, r11
	ctx.r[10].u32 = ctx.r[30].u32 / ctx.r[11].u32;
	// 8315A034: 37CA0001  addic. r30, r10, 1
	ctx.xer.ca = (ctx.r[10].u32 > (!(1 as u32)));
	ctx.r[30].s64 = ctx.r[10].s64 + 1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8315A038: 40810014  ble 0x8315a04c
	if !ctx.cr[0].gt {
	pc = 0x8315A04C; continue 'dispatch;
	}
	// 8315A03C: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8315A040: 480046B9  bl 0x8315e6f8
	ctx.lr = 0x8315A044;
	sub_8315E6F8(ctx, base);
	// 8315A044: 37DEFFFF  addic. r30, r30, -1
	ctx.xer.ca = (ctx.r[30].u32 > (!(-1 as u32)));
	ctx.r[30].s64 = ctx.r[30].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8315A048: 4082FFF4  bne 0x8315a03c
	if !ctx.cr[0].eq {
	pc = 0x8315A03C; continue 'dispatch;
	}
	// 8315A04C: 807F004C  lwz r3, 0x4c(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8315A050: 4BEF9FF1  bl 0x83054040
	ctx.lr = 0x8315A054;
	sub_83054040(ctx, base);
	// 8315A054: 907F0044  stw r3, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[3].u32 ) };
	// 8315A058: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315A05C: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315A060: 48007B49  bl 0x83161ba8
	ctx.lr = 0x8315A064;
	sub_83161BA8(ctx, base);
	// 8315A064: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315A068: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315A06C: 807F0008  lwz r3, 8(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315A070: 48007B39  bl 0x83161ba8
	ctx.lr = 0x8315A074;
	sub_83161BA8(ctx, base);
	// 8315A074: 897F0041  lbz r11, 0x41(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(65 as u32) ) } as u64;
	// 8315A078: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8315A07C: 409A0034  bne cr6, 0x8315a0b0
	if !ctx.cr[6].eq {
	pc = 0x8315A0B0; continue 'dispatch;
	}
	// 8315A080: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8315A084: 409A002C  bne cr6, 0x8315a0b0
	if !ctx.cr[6].eq {
	pc = 0x8315A0B0; continue 'dispatch;
	}
	// 8315A088: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315A08C: 409A0024  bne cr6, 0x8315a0b0
	if !ctx.cr[6].eq {
	pc = 0x8315A0B0; continue 'dispatch;
	}
	// 8315A090: 817F0044  lwz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 8315A094: 815F0030  lwz r10, 0x30(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(48 as u32) ) } as u64;
	// 8315A098: 7F0B5040  cmplw cr6, r11, r10
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8315A09C: 41980014  blt cr6, 0x8315a0b0
	if ctx.cr[6].lt {
	pc = 0x8315A0B0; continue 'dispatch;
	}
	// 8315A0A0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315A0A4: 4BFFFBDD  bl 0x83159c80
	ctx.lr = 0x8315A0A8;
	sub_83159C80(ctx, base);
	// 8315A0A8: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 8315A0AC: 917F0038  stw r11, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[11].u32 ) };
	// 8315A0B0: 817F0038  lwz r11, 0x38(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 8315A0B4: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8315A0B8: 409A0014  bne cr6, 0x8315a0cc
	if !ctx.cr[6].eq {
	pc = 0x8315A0CC; continue 'dispatch;
	}
	// 8315A0BC: 817F003C  lwz r11, 0x3c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 8315A0C0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315A0C4: 409A0008  bne cr6, 0x8315a0cc
	if !ctx.cr[6].eq {
	pc = 0x8315A0CC; continue 'dispatch;
	}
	// 8315A0C8: 93BF0038  stw r29, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[29].u32 ) };
	// 8315A0CC: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8315A0D0: 4804E0EC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315A0D4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315A0D8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315A0DC: 388B5C2C  addi r4, r11, 0x5c2c
	ctx.r[4].s64 = ctx.r[11].s64 + 23596;
	// 8315A0E0: 48005A39  bl 0x8315fb18
	ctx.lr = 0x8315A0E4;
	sub_8315FB18(ctx, base);
	// 8315A0E4: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8315A0E8: 915F0048  stw r10, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[10].u32 ) };
	// 8315A0EC: 382100B0  addi r1, r1, 0xb0
	ctx.r[1].s64 = ctx.r[1].s64 + 176;
	// 8315A0F0: 4804E0CC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A0F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315A0F8 size=260
    let mut pc: u32 = 0x8315A0F8;
    'dispatch: loop {
        match pc {
            0x8315A0F8 => {
    //   block [0x8315A0F8..0x8315A1FC)
	// 8315A0F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A0FC: 4804E06D  bl 0x831a8168
	ctx.lr = 0x8315A100;
	sub_831A8130(ctx, base);
	// 8315A100: DBC1FFC8  stfd f30, -0x38(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-56 as u32), ctx.f[30].u64 ) };
	// 8315A104: DBE1FFD0  stfd f31, -0x30(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-48 as u32), ctx.f[31].u64 ) };
	// 8315A108: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315A10C: FFC00890  fmr f30, f1
	ctx.f[30].f64 = ctx.f[1].f64;
	// 8315A110: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8315A114: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8315A118: FFE01090  fmr f31, f2
	ctx.f[31].f64 = ctx.f[2].f64;
	// 8315A11C: C00B08A4  lfs f0, 0x8a4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A120: FF1E0000  fcmpu cr6, f30, f0
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[0].f64);
	// 8315A124: 409A000C  bne cr6, 0x8315a130
	if !ctx.cr[6].eq {
	pc = 0x8315A130; continue 'dispatch;
	}
	// 8315A128: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 8315A12C: 419A0068  beq cr6, 0x8315a194
	if ctx.cr[6].eq {
	pc = 0x8315A194; continue 'dispatch;
	}
	// 8315A130: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8315A134: C19C04BC  lfs f12, 0x4bc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1212 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315A138: 3D408208  lis r10, -0x7df8
	ctx.r[10].s64 = -2113404928;
	// 8315A13C: C00B9450  lfs f0, -0x6bb0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27568 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A140: C1AA89AC  lfs f13, -0x7654(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-30292 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315A144: EC0C6838  fmsubs f0, f12, f0, f13
	ctx.f[0].f64 = (((ctx.f[12].f64 * ctx.f[0].f64 - ctx.f[13].f64) as f32) as f64);
	// 8315A148: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 8315A14C: 40990008  ble cr6, 0x8315a154
	if !ctx.cr[6].gt {
	pc = 0x8315A154; continue 'dispatch;
	}
	// 8315A150: FFE00090  fmr f31, f0
	ctx.f[31].f64 = ctx.f[0].f64;
	// 8315A154: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8315A158: C00BA1C4  lfs f0, -0x5e3c(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-24124 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A15C: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 8315A160: 40980008  bge cr6, 0x8315a168
	if !ctx.cr[6].lt {
	pc = 0x8315A168; continue 'dispatch;
	}
	// 8315A164: FFE00090  fmr f31, f0
	ctx.f[31].f64 = ctx.f[0].f64;
	// 8315A168: 3D608201  lis r11, -0x7dff
	ctx.r[11].s64 = -2113863680;
	// 8315A16C: C00B9524  lfs f0, -0x6adc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27356 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A170: EC1F0028  fsubs f0, f31, f0
	ctx.f[0].f64 = (((ctx.f[31].f64 - ctx.f[0].f64) as f32) as f64);
	// 8315A174: FF1E0000  fcmpu cr6, f30, f0
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[0].f64);
	// 8315A178: 40990008  ble cr6, 0x8315a180
	if !ctx.cr[6].gt {
	pc = 0x8315A180; continue 'dispatch;
	}
	// 8315A17C: FFC00090  fmr f30, f0
	ctx.f[30].f64 = ctx.f[0].f64;
	// 8315A180: 3D608200  lis r11, -0x7e00
	ctx.r[11].s64 = -2113929216;
	// 8315A184: C00B08A8  lfs f0, 0x8a8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(2216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A188: FF1E0000  fcmpu cr6, f30, f0
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[0].f64);
	// 8315A18C: 40980008  bge cr6, 0x8315a194
	if !ctx.cr[6].lt {
	pc = 0x8315A194; continue 'dispatch;
	}
	// 8315A190: FFC00090  fmr f30, f0
	ctx.f[30].f64 = ctx.f[0].f64;
	// 8315A194: C01C04C0  lfs f0, 0x4c0(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1216 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A198: FF1E0000  fcmpu cr6, f30, f0
	ctx.cr[6].compare_f64(ctx.f[30].f64, ctx.f[0].f64);
	// 8315A19C: 409A0010  bne cr6, 0x8315a1ac
	if !ctx.cr[6].eq {
	pc = 0x8315A1AC; continue 'dispatch;
	}
	// 8315A1A0: C01C04C4  lfs f0, 0x4c4(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1220 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A1A4: FF1F0000  fcmpu cr6, f31, f0
	ctx.cr[6].compare_f64(ctx.f[31].f64, ctx.f[0].f64);
	// 8315A1A8: 419A0044  beq cr6, 0x8315a1ec
	if ctx.cr[6].eq {
	pc = 0x8315A1EC; continue 'dispatch;
	}
	// 8315A1AC: 3BBC001C  addi r29, r28, 0x1c
	ctx.r[29].s64 = ctx.r[28].s64 + 28;
	// 8315A1B0: C03C04BC  lfs f1, 0x4bc(r28)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(1212 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315A1B4: FC60F890  fmr f3, f31
	ctx.f[3].f64 = ctx.f[31].f64;
	// 8315A1B8: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315A1BC: FC40F090  fmr f2, f30
	ctx.f[2].f64 = ctx.f[30].f64;
	// 8315A1C0: 4BFE1851  bl 0x8313ba10
	ctx.lr = 0x8315A1C4;
	sub_8313BA10(ctx, base);
	// 8315A1C4: 3BDC00B0  addi r30, r28, 0xb0
	ctx.r[30].s64 = ctx.r[28].s64 + 176;
	// 8315A1C8: 3BE00007  li r31, 7
	ctx.r[31].s64 = 7;
	// 8315A1CC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315A1D0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315A1D4: 4BFF056D  bl 0x8314a740
	ctx.lr = 0x8315A1D8;
	sub_8314A740(ctx, base);
	// 8315A1D8: 37FFFFFF  addic. r31, r31, -1
	ctx.xer.ca = (ctx.r[31].u32 > (!(-1 as u32)));
	ctx.r[31].s64 = ctx.r[31].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8315A1DC: 3BDE0094  addi r30, r30, 0x94
	ctx.r[30].s64 = ctx.r[30].s64 + 148;
	// 8315A1E0: 4082FFEC  bne 0x8315a1cc
	if !ctx.cr[0].eq {
	pc = 0x8315A1CC; continue 'dispatch;
	}
	// 8315A1E4: D3DC04C0  stfs f30, 0x4c0(r28)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.f32 = (ctx.f[30].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(1216 as u32), tmp.u32 ) };
	// 8315A1E8: D3FC04C4  stfs f31, 0x4c4(r28)
	tmp.f32 = (ctx.f[31].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(1220 as u32), tmp.u32 ) };
	// 8315A1EC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8315A1F0: CBC1FFC8  lfd f30, -0x38(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-56 as u32) ) };
	// 8315A1F4: CBE1FFD0  lfd f31, -0x30(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-48 as u32) ) };
	// 8315A1F8: 4804DFC0  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A200(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A200 size=184
    let mut pc: u32 = 0x8315A200;
    'dispatch: loop {
        match pc {
            0x8315A200 => {
    //   block [0x8315A200..0x8315A2B8)
	// 8315A200: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A204: 39630001  addi r11, r3, 1
	ctx.r[11].s64 = ctx.r[3].s64 + 1;
	// 8315A208: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A20C: 99440000  stb r10, 0(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u8 ) };
	// 8315A210: 89230001  lbz r9, 1(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A214: 99240001  stb r9, 1(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(1 as u32), ctx.r[9].u8 ) };
	// 8315A218: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A21C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A220: 99040002  stb r8, 2(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[8].u8 ) };
	// 8315A224: 88EB0000  lbz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A228: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A22C: 98E40003  stb r7, 3(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(3 as u32), ctx.r[7].u8 ) };
	// 8315A230: 88CB0001  lbz r6, 1(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A234: 88AB0002  lbz r5, 2(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A238: 886B0003  lbz r3, 3(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A23C: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A240: 5549403E  rotlwi r9, r10, 8
	ctx.r[9].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A244: 7D283378  or r8, r9, r6
	ctx.r[8].u64 = ctx.r[9].u64 | ctx.r[6].u64;
	// 8315A248: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315A24C: 5507402E  slwi r7, r8, 8
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315A250: 7CE62B78  or r6, r7, r5
	ctx.r[6].u64 = ctx.r[7].u64 | ctx.r[5].u64;
	// 8315A254: 54C5402E  slwi r5, r6, 8
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(8);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8315A258: 7CA31B78  or r3, r5, r3
	ctx.r[3].u64 = ctx.r[5].u64 | ctx.r[3].u64;
	// 8315A25C: 90640004  stw r3, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 8315A260: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A264: 892B0002  lbz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A268: 890B0003  lbz r8, 3(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A26C: 88EB0000  lbz r7, 0(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A270: 54E6403E  rotlwi r6, r7, 8
	ctx.r[6].u64 = ((ctx.r[7].u32).rotate_left(8)) as u64;
	// 8315A274: 7CC55378  or r5, r6, r10
	ctx.r[5].u64 = ctx.r[6].u64 | ctx.r[10].u64;
	// 8315A278: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315A27C: 54A3402E  slwi r3, r5, 8
	ctx.r[3].u32 = ctx.r[5].u32.wrapping_shl(8);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 8315A280: 7C6A4B78  or r10, r3, r9
	ctx.r[10].u64 = ctx.r[3].u64 | ctx.r[9].u64;
	// 8315A284: 5549402E  slwi r9, r10, 8
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(8);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8315A288: 7D284378  or r8, r9, r8
	ctx.r[8].u64 = ctx.r[9].u64 | ctx.r[8].u64;
	// 8315A28C: 91040008  stw r8, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8315A290: 88EB0001  lbz r7, 1(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A294: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A298: 54C5403E  rotlwi r5, r6, 8
	ctx.r[5].u64 = ((ctx.r[6].u32).rotate_left(8)) as u64;
	// 8315A29C: 7CA33B78  or r3, r5, r7
	ctx.r[3].u64 = ctx.r[5].u64 | ctx.r[7].u64;
	// 8315A2A0: B064000C  sth r3, 0xc(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[3].u16 ) };
	// 8315A2A4: 892B0002  lbz r9, 2(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A2A8: 9924003C  stb r9, 0x3c(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(60 as u32), ctx.r[9].u8 ) };
	// 8315A2AC: 890B0003  lbz r8, 3(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A2B0: 9904003D  stb r8, 0x3d(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(61 as u32), ctx.r[8].u8 ) };
	// 8315A2B4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A2B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A2B8 size=236
    let mut pc: u32 = 0x8315A2B8;
    'dispatch: loop {
        match pc {
            0x8315A2B8 => {
    //   block [0x8315A2B8..0x8315A3A4)
	// 8315A2B8: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A2BC: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 8315A2C0: 89230001  lbz r9, 1(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A2C4: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A2C8: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8315A2CC: 7D074B78  or r7, r8, r9
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A2D0: B0E40000  sth r7, 0(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8315A2D4: 88A30003  lbz r5, 3(r3)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A2D8: 88630002  lbz r3, 2(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A2DC: 546A403E  rotlwi r10, r3, 8
	ctx.r[10].u64 = ((ctx.r[3].u32).rotate_left(8)) as u64;
	// 8315A2E0: 7D492B78  or r9, r10, r5
	ctx.r[9].u64 = ctx.r[10].u64 | ctx.r[5].u64;
	// 8315A2E4: B1240002  sth r9, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[9].u16 ) };
	// 8315A2E8: 88EB0001  lbz r7, 1(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A2EC: 88CB0002  lbz r6, 2(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A2F0: 88AB0003  lbz r5, 3(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A2F4: 886B0000  lbz r3, 0(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A2F8: 546A403E  rotlwi r10, r3, 8
	ctx.r[10].u64 = ((ctx.r[3].u32).rotate_left(8)) as u64;
	// 8315A2FC: 7D493B78  or r9, r10, r7
	ctx.r[9].u64 = ctx.r[10].u64 | ctx.r[7].u64;
	// 8315A300: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315A304: 5528402E  slwi r8, r9, 8
	ctx.r[8].u32 = ctx.r[9].u32.wrapping_shl(8);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315A308: 7D073378  or r7, r8, r6
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[6].u64;
	// 8315A30C: 54E6402E  slwi r6, r7, 8
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315A310: 7CC52B78  or r5, r6, r5
	ctx.r[5].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8315A314: 90A40004  stw r5, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[5].u32 ) };
	// 8315A318: 886B0001  lbz r3, 1(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A31C: 894B0002  lbz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A320: 892B0003  lbz r9, 3(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A324: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A328: 5507403E  rotlwi r7, r8, 8
	ctx.r[7].u64 = ((ctx.r[8].u32).rotate_left(8)) as u64;
	// 8315A32C: 7CE61B78  or r6, r7, r3
	ctx.r[6].u64 = ctx.r[7].u64 | ctx.r[3].u64;
	// 8315A330: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315A334: 54C5402E  slwi r5, r6, 8
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(8);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8315A338: 7CA35378  or r3, r5, r10
	ctx.r[3].u64 = ctx.r[5].u64 | ctx.r[10].u64;
	// 8315A33C: 546A402E  slwi r10, r3, 8
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(8);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315A340: 7D494B78  or r9, r10, r9
	ctx.r[9].u64 = ctx.r[10].u64 | ctx.r[9].u64;
	// 8315A344: 91240008  stw r9, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8315A348: 890B0001  lbz r8, 1(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A34C: 88EB0002  lbz r7, 2(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A350: 88CB0003  lbz r6, 3(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A354: 88AB0000  lbz r5, 0(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A358: 54A3403E  rotlwi r3, r5, 8
	ctx.r[3].u64 = ((ctx.r[5].u32).rotate_left(8)) as u64;
	// 8315A35C: 7C6A4378  or r10, r3, r8
	ctx.r[10].u64 = ctx.r[3].u64 | ctx.r[8].u64;
	// 8315A360: 5549402E  slwi r9, r10, 8
	ctx.r[9].u32 = ctx.r[10].u32.wrapping_shl(8);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8315A364: 7D283B78  or r8, r9, r7
	ctx.r[8].u64 = ctx.r[9].u64 | ctx.r[7].u64;
	// 8315A368: 5507402E  slwi r7, r8, 8
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315A36C: 7CE63378  or r6, r7, r6
	ctx.r[6].u64 = ctx.r[7].u64 | ctx.r[6].u64;
	// 8315A370: 90C4000C  stw r6, 0xc(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 8315A374: 88AB0005  lbz r5, 5(r11)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(5 as u32) ) } as u64;
	// 8315A378: 886B0006  lbz r3, 6(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(6 as u32) ) } as u64;
	// 8315A37C: 894B0007  lbz r10, 7(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(7 as u32) ) } as u64;
	// 8315A380: 892B0004  lbz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315A384: 5528403E  rotlwi r8, r9, 8
	ctx.r[8].u64 = ((ctx.r[9].u32).rotate_left(8)) as u64;
	// 8315A388: 7D072B78  or r7, r8, r5
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[5].u64;
	// 8315A38C: 54E6402E  slwi r6, r7, 8
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315A390: 7CC51B78  or r5, r6, r3
	ctx.r[5].u64 = ctx.r[6].u64 | ctx.r[3].u64;
	// 8315A394: 54A3402E  slwi r3, r5, 8
	ctx.r[3].u32 = ctx.r[5].u32.wrapping_shl(8);
	ctx.r[3].u64 = ctx.r[3].u32 as u64;
	// 8315A398: 7C6B5378  or r11, r3, r10
	ctx.r[11].u64 = ctx.r[3].u64 | ctx.r[10].u64;
	// 8315A39C: 91640010  stw r11, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315A3A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A3A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A3A8 size=200
    let mut pc: u32 = 0x8315A3A8;
    'dispatch: loop {
        match pc {
            0x8315A3A8 => {
    //   block [0x8315A3A8..0x8315A470)
	// 8315A3A8: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A3AC: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 8315A3B0: 89230001  lbz r9, 1(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A3B4: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A3B8: 7D074B78  or r7, r8, r9
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A3BC: 54E5043E  clrlwi r5, r7, 0x10
	ctx.r[5].u64 = ctx.r[7].u32 as u64 & 0x0000FFFFu64;
	// 8315A3C0: B0E40000  sth r7, 0(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[7].u16 ) };
	// 8315A3C4: 7CA30734  extsh r3, r5
	ctx.r[3].s64 = ctx.r[5].s16 as i64;
	// 8315A3C8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315A3CC: 40990018  ble cr6, 0x8315a3e4
	if !ctx.cr[6].gt {
	pc = 0x8315A3E4; continue 'dispatch;
	}
	// 8315A3D0: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A3D4: 892B0001  lbz r9, 1(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A3D8: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A3DC: 7D074B78  or r7, r8, r9
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A3E0: B0E40002  sth r7, 2(r4)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[4].u32.wrapping_add(2 as u32), ctx.r[7].u16 ) };
	// 8315A3E4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8315A3E8: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A3EC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A3F0: 5549063E  clrlwi r9, r10, 0x18
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8315A3F4: 7D280774  extsb r8, r9
	ctx.r[8].s64 = ctx.r[9].s8 as i64;
	// 8315A3F8: 99440004  stb r10, 4(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[10].u8 ) };
	// 8315A3FC: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315A400: 4099000C  ble cr6, 0x8315a40c
	if !ctx.cr[6].gt {
	pc = 0x8315A40C; continue 'dispatch;
	}
	// 8315A404: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A408: 99440005  stb r10, 5(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(5 as u32), ctx.r[10].u8 ) };
	// 8315A40C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A410: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A414: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A418: 5549063E  clrlwi r9, r10, 0x18
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8315A41C: 7D280774  extsb r8, r9
	ctx.r[8].s64 = ctx.r[9].s8 as i64;
	// 8315A420: 99440006  stb r10, 6(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(6 as u32), ctx.r[10].u8 ) };
	// 8315A424: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315A428: 4099000C  ble cr6, 0x8315a434
	if !ctx.cr[6].gt {
	pc = 0x8315A434; continue 'dispatch;
	}
	// 8315A42C: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A430: 99440007  stb r10, 7(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(7 as u32), ctx.r[10].u8 ) };
	// 8315A434: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A438: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A43C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315A440: 5549063E  clrlwi r9, r10, 0x18
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x000000FFu64;
	// 8315A444: 7D280774  extsb r8, r9
	ctx.r[8].s64 = ctx.r[9].s8 as i64;
	// 8315A448: 99440008  stb r10, 8(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[10].u8 ) };
	// 8315A44C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315A450: 4099000C  ble cr6, 0x8315a45c
	if !ctx.cr[6].gt {
	pc = 0x8315A45C; continue 'dispatch;
	}
	// 8315A454: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A458: 99440009  stb r10, 9(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(9 as u32), ctx.r[10].u8 ) };
	// 8315A45C: 894B0001  lbz r10, 1(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A460: 7D490774  extsb r9, r10
	ctx.r[9].s64 = ctx.r[10].s8 as i64;
	// 8315A464: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315A468: 9944000A  stb r10, 0xa(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(10 as u32), ctx.r[10].u8 ) };
	// 8315A46C: 4C990020  blelr cr6
	if !ctx.cr[6].gt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A470(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A470 size=12
    let mut pc: u32 = 0x8315A470;
    'dispatch: loop {
        match pc {
            0x8315A470 => {
    //   block [0x8315A470..0x8315A47C)
	// 8315A470: 896B0002  lbz r11, 2(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A474: 9964000B  stb r11, 0xb(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(11 as u32), ctx.r[11].u8 ) };
	// 8315A478: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A480(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315A480 size=428
    let mut pc: u32 = 0x8315A480;
    'dispatch: loop {
        match pc {
            0x8315A480 => {
    //   block [0x8315A480..0x8315A62C)
	// 8315A480: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A484: 4804DCE5  bl 0x831a8168
	ctx.lr = 0x8315A488;
	sub_831A8130(ctx, base);
	// 8315A488: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315A48C: 7CDF3378  mr r31, r6
	ctx.r[31].u64 = ctx.r[6].u64;
	// 8315A490: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8315A494: 419A000C  beq cr6, 0x8315a4a0
	if ctx.cr[6].eq {
	pc = 0x8315A4A0; continue 'dispatch;
	}
	// 8315A498: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315A49C: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315A4A0: 2F040004  cmpwi cr6, r4, 4
	ctx.cr[6].compare_i32(ctx.r[4].s32, 4, &mut ctx.xer);
	// 8315A4A4: 40980010  bge cr6, 0x8315a4b4
	if !ctx.cr[6].lt {
	pc = 0x8315A4B4; continue 'dispatch;
	}
	// 8315A4A8: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315A4AC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A4B0: 4804DD08  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315A4B4: 89430000  lbz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A4B8: 39630002  addi r11, r3, 2
	ctx.r[11].s64 = ctx.r[3].s64 + 2;
	// 8315A4BC: 89230001  lbz r9, 1(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[3].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A4C0: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A4C4: 7D074B78  or r7, r8, r9
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A4C8: 54E6043E  clrlwi r6, r7, 0x10
	ctx.r[6].u64 = ctx.r[7].u32 as u64 & 0x0000FFFFu64;
	// 8315A4CC: 2B068000  cmplwi cr6, r6, 0x8000
	ctx.cr[6].compare_u32(ctx.r[6].u32, 32768 as u32, &mut ctx.xer);
	// 8315A4D0: 419A0010  beq cr6, 0x8315a4e0
	if ctx.cr[6].eq {
	pc = 0x8315A4E0; continue 'dispatch;
	}
	// 8315A4D4: 3860FFFC  li r3, -4
	ctx.r[3].s64 = -4;
	// 8315A4D8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A4DC: 4804DCDC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315A4E0: 894B0000  lbz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A4E4: 3BAB0002  addi r29, r11, 2
	ctx.r[29].s64 = ctx.r[11].s64 + 2;
	// 8315A4E8: 892B0001  lbz r9, 1(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315A4EC: 2B050000  cmplwi cr6, r5, 0
	ctx.cr[6].compare_u32(ctx.r[5].u32, 0 as u32, &mut ctx.xer);
	// 8315A4F0: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A4F4: 7D0B4B78  or r11, r8, r9
	ctx.r[11].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A4F8: 419A0008  beq cr6, 0x8315a500
	if ctx.cr[6].eq {
	pc = 0x8315A500; continue 'dispatch;
	}
	// 8315A4FC: 91650000  stw r11, 0(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315A500: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315A504: 419A011C  beq cr6, 0x8315a620
	if ctx.cr[6].eq {
	pc = 0x8315A620; continue 'dispatch;
	}
	// 8315A508: 394B0004  addi r10, r11, 4
	ctx.r[10].s64 = ctx.r[11].s64 + 4;
	// 8315A50C: 7F045000  cmpw cr6, r4, r10
	ctx.cr[6].compare_i32(ctx.r[4].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315A510: 40980010  bge cr6, 0x8315a520
	if !ctx.cr[6].lt {
	pc = 0x8315A520; continue 'dispatch;
	}
	// 8315A514: 3860FFFE  li r3, -2
	ctx.r[3].s64 = -2;
	// 8315A518: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A51C: 4804DC9C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315A520: 3BCBFFFA  addi r30, r11, -6
	ctx.r[30].s64 = ctx.r[11].s64 + -6;
	// 8315A524: 2F1E0010  cmpwi cr6, r30, 0x10
	ctx.cr[6].compare_i32(ctx.r[30].s32, 16, &mut ctx.xer);
	// 8315A528: 4198FFEC  blt cr6, 0x8315a514
	if ctx.cr[6].lt {
	pc = 0x8315A514; continue 'dispatch;
	}
	// 8315A52C: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8315A530: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315A534: 4BFFFCCD  bl 0x8315a200
	ctx.lr = 0x8315A538;
	sub_8315A200(ctx, base);
	// 8315A538: 895F003C  lbz r10, 0x3c(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(60 as u32) ) } as u64;
	// 8315A53C: 397D0010  addi r11, r29, 0x10
	ctx.r[11].s64 = ctx.r[29].s64 + 16;
	// 8315A540: 3B9EFFF0  addi r28, r30, -0x10
	ctx.r[28].s64 = ctx.r[30].s64 + -16;
	// 8315A544: 2B0A0004  cmplwi cr6, r10, 4
	ctx.cr[6].compare_u32(ctx.r[10].u32, 4 as u32, &mut ctx.xer);
	// 8315A548: 409A000C  bne cr6, 0x8315a554
	if !ctx.cr[6].eq {
	pc = 0x8315A554; continue 'dispatch;
	}
	// 8315A54C: 396B000C  addi r11, r11, 0xc
	ctx.r[11].s64 = ctx.r[11].s64 + 12;
	// 8315A550: 3B9CFFF4  addi r28, r28, -0xc
	ctx.r[28].s64 = ctx.r[28].s64 + -12;
	// 8315A554: 2F1C0004  cmpwi cr6, r28, 4
	ctx.cr[6].compare_i32(ctx.r[28].s32, 4, &mut ctx.xer);
	// 8315A558: 419800C8  blt cr6, 0x8315a620
	if ctx.cr[6].lt {
	pc = 0x8315A620; continue 'dispatch;
	}
	// 8315A55C: 894B0002  lbz r10, 2(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315A560: 3BCB0004  addi r30, r11, 4
	ctx.r[30].s64 = ctx.r[11].s64 + 4;
	// 8315A564: 892B0003  lbz r9, 3(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A568: 5548403E  rotlwi r8, r10, 8
	ctx.r[8].u64 = ((ctx.r[10].u32).rotate_left(8)) as u64;
	// 8315A56C: 7D074B78  or r7, r8, r9
	ctx.r[7].u64 = ctx.r[8].u64 | ctx.r[9].u64;
	// 8315A570: 7CE60734  extsh r6, r7
	ctx.r[6].s64 = ctx.r[7].s16 as i64;
	// 8315A574: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 8315A578: B0DF000E  sth r6, 0xe(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(14 as u32), ctx.r[6].u16 ) };
	// 8315A57C: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315A580: 7CAB5214  add r5, r11, r10
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315A584: 54A4103A  slwi r4, r5, 2
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(2);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8315A588: 7F1C2000  cmpw cr6, r28, r4
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[4].s32, &mut ctx.xer);
	// 8315A58C: 41980094  blt cr6, 0x8315a620
	if ctx.cr[6].lt {
	pc = 0x8315A620; continue 'dispatch;
	}
	// 8315A590: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8315A594: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315A598: 40990028  ble cr6, 0x8315a5c0
	if !ctx.cr[6].gt {
	pc = 0x8315A5C0; continue 'dispatch;
	}
	// 8315A59C: 389F0010  addi r4, r31, 0x10
	ctx.r[4].s64 = ctx.r[31].s64 + 16;
	// 8315A5A0: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315A5A4: 4BFFFD15  bl 0x8315a2b8
	ctx.lr = 0x8315A5A8;
	sub_8315A2B8(ctx, base);
	// 8315A5A8: A17F000E  lhz r11, 0xe(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315A5AC: 3BBD0001  addi r29, r29, 1
	ctx.r[29].s64 = ctx.r[29].s64 + 1;
	// 8315A5B0: 7D6A0734  extsh r10, r11
	ctx.r[10].s64 = ctx.r[11].s16 as i64;
	// 8315A5B4: 38840014  addi r4, r4, 0x14
	ctx.r[4].s64 = ctx.r[4].s64 + 20;
	// 8315A5B8: 7F1D5000  cmpw cr6, r29, r10
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315A5BC: 4198FFE4  blt cr6, 0x8315a5a0
	if ctx.cr[6].lt {
	pc = 0x8315A5A0; continue 'dispatch;
	}
	// 8315A5C0: A17F000E  lhz r11, 0xe(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315A5C4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315A5C8: 895F0003  lbz r10, 3(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A5CC: 7D6B0734  extsh r11, r11
	ctx.r[11].s64 = ctx.r[11].s16 as i64;
	// 8315A5D0: 7D490774  extsb r9, r10
	ctx.r[9].s64 = ctx.r[10].s8 as i64;
	// 8315A5D4: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315A5D8: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315A5DC: 7D0B5214  add r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315A5E0: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315A5E4: 7FA7E050  subf r29, r7, r28
	ctx.r[29].s64 = ctx.r[28].s64 - ctx.r[7].s64;
	// 8315A5E8: 40990038  ble cr6, 0x8315a620
	if !ctx.cr[6].gt {
	pc = 0x8315A620; continue 'dispatch;
	}
	// 8315A5EC: 389F0024  addi r4, r31, 0x24
	ctx.r[4].s64 = ctx.r[31].s64 + 36;
	// 8315A5F0: 2F1D000C  cmpwi cr6, r29, 0xc
	ctx.cr[6].compare_i32(ctx.r[29].s32, 12, &mut ctx.xer);
	// 8315A5F4: 4198002C  blt cr6, 0x8315a620
	if ctx.cr[6].lt {
	pc = 0x8315A620; continue 'dispatch;
	}
	// 8315A5F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315A5FC: 4BFFFDAD  bl 0x8315a3a8
	ctx.lr = 0x8315A600;
	sub_8315A3A8(ctx, base);
	// 8315A600: 897F0003  lbz r11, 3(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315A604: 38C60001  addi r6, r6, 1
	ctx.r[6].s64 = ctx.r[6].s64 + 1;
	// 8315A608: 7D6A0774  extsb r10, r11
	ctx.r[10].s64 = ctx.r[11].s8 as i64;
	// 8315A60C: 3BDE000C  addi r30, r30, 0xc
	ctx.r[30].s64 = ctx.r[30].s64 + 12;
	// 8315A610: 3BBDFFF4  addi r29, r29, -0xc
	ctx.r[29].s64 = ctx.r[29].s64 + -12;
	// 8315A614: 3884000C  addi r4, r4, 0xc
	ctx.r[4].s64 = ctx.r[4].s64 + 12;
	// 8315A618: 7F065000  cmpw cr6, r6, r10
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315A61C: 4198FFD4  blt cr6, 0x8315a5f0
	if ctx.cr[6].lt {
	pc = 0x8315A5F0; continue 'dispatch;
	}
	// 8315A620: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315A624: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A628: 4804DB90  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A630(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315A630 size=180
    let mut pc: u32 = 0x8315A630;
    'dispatch: loop {
        match pc {
            0x8315A630 => {
    //   block [0x8315A630..0x8315A6E4)
	// 8315A630: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A634: 4804DB35  bl 0x831a8168
	ctx.lr = 0x8315A638;
	sub_831A8130(ctx, base);
	// 8315A638: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315A63C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315A640: 2F050034  cmpwi cr6, r5, 0x34
	ctx.cr[6].compare_i32(ctx.r[5].s32, 52, &mut ctx.xer);
	// 8315A644: 40980010  bge cr6, 0x8315a654
	if !ctx.cr[6].lt {
	pc = 0x8315A654; continue 'dispatch;
	}
	// 8315A648: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315A64C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A650: 4804DB68  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315A654: 39640007  addi r11, r4, 7
	ctx.r[11].s64 = ctx.r[4].s64 + 7;
	// 8315A658: 38A0002C  li r5, 0x2c
	ctx.r[5].s64 = 44;
	// 8315A65C: 557D0038  rlwinm r29, r11, 0, 0, 0x1c
	ctx.r[29].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8315A660: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315A664: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315A668: 4804DB79  bl 0x831a81e0
	ctx.lr = 0x8315A66C;
	sub_831A81E0(ctx, base);
	// 8315A66C: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315A670: 93FD0004  stw r31, 4(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(4 as u32), ctx.r[31].u32 ) };
	// 8315A674: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315A678: 93DD0010  stw r30, 0x10(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(16 as u32), ctx.r[30].u32 ) };
	// 8315A67C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315A680: 815F0000  lwz r10, 0(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A684: 812A0024  lwz r9, 0x24(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A688: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315A68C: 4E800421  bctrl
	ctx.lr = 0x8315A690;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315A690: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A694: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8315A698: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315A69C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315A6A0: 80E80024  lwz r7, 0x24(r8)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A6A4: 7CE903A6  mtctr r7
	ctx.ctr.u64 = ctx.r[7].u64;
	// 8315A6A8: 4E800421  bctrl
	ctx.lr = 0x8315A6AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315A6AC: 7CDC1A14  add r6, r28, r3
	ctx.r[6].u64 = ctx.r[28].u64 + ctx.r[3].u64;
	// 8315A6B0: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8315A6B4: 93DD0024  stw r30, 0x24(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(36 as u32), ctx.r[30].u32 ) };
	// 8315A6B8: 7CC41670  srawi r4, r6, 2
	ctx.xer.ca = (ctx.r[6].s32 < 0) && ((ctx.r[6].u32 & ((1u32 << 2) - 1)) != 0);
	ctx.r[4].s64 = (ctx.r[6].s32 >> 2) as i64;
	// 8315A6BC: 90DD0014  stw r6, 0x14(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(20 as u32), ctx.r[6].u32 ) };
	// 8315A6C0: 93DD001C  stw r30, 0x1c(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(28 as u32), ctx.r[30].u32 ) };
	// 8315A6C4: 7C640194  addze r3, r4
	tmp.s64 = ctx.r[4].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[4].u32);
	ctx.r[3].s64 = tmp.s64;
	// 8315A6C8: 93DD0020  stw r30, 0x20(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(32 as u32), ctx.r[30].u32 ) };
	// 8315A6CC: 93DD0028  stw r30, 0x28(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(40 as u32), ctx.r[30].u32 ) };
	// 8315A6D0: 907D0018  stw r3, 0x18(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 8315A6D4: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315A6D8: 90BD0000  stw r5, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 8315A6DC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A6E0: 4804DAD8  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A6E8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315A6E8 size=156
    let mut pc: u32 = 0x8315A6E8;
    'dispatch: loop {
        match pc {
            0x8315A6E8 => {
    //   block [0x8315A6E8..0x8315A784)
	// 8315A6E8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A6EC: 4804DA7D  bl 0x831a8168
	ctx.lr = 0x8315A6F0;
	sub_831A8130(ctx, base);
	// 8315A6F0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315A6F4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315A6F8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315A6FC: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315A700: 419A007C  beq cr6, 0x8315a77c
	if ctx.cr[6].eq {
	pc = 0x8315A77C; continue 'dispatch;
	}
	// 8315A704: 38A0002C  li r5, 0x2c
	ctx.r[5].s64 = 44;
	// 8315A708: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315A70C: 4804DAD5  bl 0x831a81e0
	ctx.lr = 0x8315A710;
	sub_831A81E0(ctx, base);
	// 8315A710: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8315A714: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8315A718: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315A71C: 93BF0010  stw r29, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[29].u32 ) };
	// 8315A720: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315A724: 817E0000  lwz r11, 0(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A728: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A72C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315A730: 4E800421  bctrl
	ctx.lr = 0x8315A734;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315A734: 813E0000  lwz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A738: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8315A73C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315A740: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315A744: 81090024  lwz r8, 0x24(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A748: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 8315A74C: 4E800421  bctrl
	ctx.lr = 0x8315A750;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315A750: 7CFC1A14  add r7, r28, r3
	ctx.r[7].u64 = ctx.r[28].u64 + ctx.r[3].u64;
	// 8315A754: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 8315A758: 93BF0024  stw r29, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[29].u32 ) };
	// 8315A75C: 7CE51670  srawi r5, r7, 2
	ctx.xer.ca = (ctx.r[7].s32 < 0) && ((ctx.r[7].u32 & ((1u32 << 2) - 1)) != 0);
	ctx.r[5].s64 = (ctx.r[7].s32 >> 2) as i64;
	// 8315A760: 90FF0014  stw r7, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[7].u32 ) };
	// 8315A764: 93BF001C  stw r29, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[29].u32 ) };
	// 8315A768: 7C850194  addze r4, r5
	tmp.s64 = ctx.r[5].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[5].u32);
	ctx.r[4].s64 = tmp.s64;
	// 8315A76C: 93BF0020  stw r29, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[29].u32 ) };
	// 8315A770: 93BF0028  stw r29, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[29].u32 ) };
	// 8315A774: 909F0018  stw r4, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[4].u32 ) };
	// 8315A778: 90DF0000  stw r6, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[6].u32 ) };
	// 8315A77C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315A780: 4804DA38  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A788(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315A788 size=104
    let mut pc: u32 = 0x8315A788;
    'dispatch: loop {
        match pc {
            0x8315A788 => {
    //   block [0x8315A788..0x8315A7F0)
	// 8315A788: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A78C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315A790: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315A794: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315A798: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315A79C: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315A7A0: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315A7A4: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A7A8: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A7AC: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315A7B0: 4E800421  bctrl
	ctx.lr = 0x8315A7B4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315A7B4: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315A7B8: 409A0020  bne cr6, 0x8315a7d8
	if !ctx.cr[6].eq {
	pc = 0x8315A7D8; continue 'dispatch;
	}
	// 8315A7BC: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315A7C0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315A7C4: 409A0014  bne cr6, 0x8315a7d8
	if !ctx.cr[6].eq {
	pc = 0x8315A7D8; continue 'dispatch;
	}
	// 8315A7C8: 817F0024  lwz r11, 0x24(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315A7CC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315A7D0: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315A7D4: 419A0008  beq cr6, 0x8315a7dc
	if ctx.cr[6].eq {
	pc = 0x8315A7DC; continue 'dispatch;
	}
	// 8315A7D8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315A7DC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315A7E0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315A7E4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315A7E8: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315A7EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A7F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A7F0 size=72
    let mut pc: u32 = 0x8315A7F0;
    'dispatch: loop {
        match pc {
            0x8315A7F0 => {
    //   block [0x8315A7F0..0x8315A838)
	// 8315A7F0: 81240000  lwz r9, 0(r4)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A7F4: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315A7F8: 409A001C  bne cr6, 0x8315a814
	if !ctx.cr[6].eq {
	pc = 0x8315A814; continue 'dispatch;
	}
	// 8315A7FC: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315A800: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 8315A804: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315A808: 419A0008  beq cr6, 0x8315a810
	if ctx.cr[6].eq {
	pc = 0x8315A810; continue 'dispatch;
	}
	// 8315A80C: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 8315A810: 91640004  stw r11, 4(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315A814: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315A818: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8315A81C: 409A001C  bne cr6, 0x8315a838
	if !ctx.cr[6].eq {
		sub_8315A838(ctx, base);
		return;
	}
	// 8315A820: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 8315A824: 3940001E  li r10, 0x1e
	ctx.r[10].s64 = 30;
	// 8315A828: 816B7F7C  lwz r11, 0x7f7c(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32636 as u32) ) } as u64;
	// 8315A82C: 91440010  stw r10, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8315A830: 91640018  stw r11, 0x18(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(24 as u32), ctx.r[11].u32 ) };
	// 8315A834: 4800000C  b 0x8315a840
	sub_8315A838(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A838 size=56
    let mut pc: u32 = 0x8315A838;
    'dispatch: loop {
        match pc {
            0x8315A838 => {
    //   block [0x8315A838..0x8315A870)
	// 8315A838: 39600020  li r11, 0x20
	ctx.r[11].s64 = 32;
	// 8315A83C: 91640010  stw r11, 0x10(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315A840: 8163001C  lwz r11, 0x1c(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315A844: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8315A848: 409A0028  bne cr6, 0x8315a870
	if !ctx.cr[6].eq {
		sub_8315A870(ctx, base);
		return;
	}
	// 8315A84C: 81430004  lwz r10, 4(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315A850: 3D008334  lis r8, -0x7ccc
	ctx.r[8].s64 = -2093744128;
	// 8315A854: 81630020  lwz r11, 0x20(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315A858: 554A103A  slwi r10, r10, 2
	ctx.r[10].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315A85C: 38E86188  addi r7, r8, 0x6188
	ctx.r[7].s64 = ctx.r[8].s64 + 24968;
	// 8315A860: 7CCA5A14  add r6, r10, r11
	ctx.r[6].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8315A864: 54C5103A  slwi r5, r6, 2
	ctx.r[5].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8315A868: 7D65382E  lwzx r11, r5, r7
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[5].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 8315A86C: 48000008  b 0x8315a874
	sub_8315A870(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A870(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A870 size=16
    let mut pc: u32 = 0x8315A870;
    'dispatch: loop {
        match pc {
            0x8315A870 => {
    //   block [0x8315A870..0x8315A880)
	// 8315A870: 81640010  lwz r11, 0x10(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315A874: 91640014  stw r11, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[11].u32 ) };
	// 8315A878: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315A87C: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A880(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315A880 size=40
    let mut pc: u32 = 0x8315A880;
    'dispatch: loop {
        match pc {
            0x8315A880 => {
    //   block [0x8315A880..0x8315A8A8)
	// 8315A880: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315A884: 3D208334  lis r9, -0x7ccc
	ctx.r[9].s64 = -2093744128;
	// 8315A888: 81430010  lwz r10, 0x10(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315A88C: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315A890: 39096000  addi r8, r9, 0x6000
	ctx.r[8].s64 = ctx.r[9].s64 + 24576;
	// 8315A894: 7CEB5214  add r7, r11, r10
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315A898: 54E6103A  slwi r6, r7, 2
	ctx.r[6].u32 = ctx.r[7].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315A89C: 7CA6402E  lwzx r5, r6, r8
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 8315A8A0: 90A40008  stw r5, 8(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 8315A8A4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315A8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315A8A8 size=1748
    let mut pc: u32 = 0x8315A8A8;
    'dispatch: loop {
        match pc {
            0x8315A8A8 => {
    //   block [0x8315A8A8..0x8315AF7C)
	// 8315A8A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315A8AC: 4804D8C1  bl 0x831a816c
	ctx.lr = 0x8315A8B0;
	sub_831A8130(ctx, base);
	// 8315A8B0: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 8315A8B4: 4804E1C1  bl 0x831a8a74
	ctx.lr = 0x8315A8B8;
	sub_831A8A40(ctx, base);
	// 8315A8B8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315A8BC: 7CA92B78  mr r9, r5
	ctx.r[9].u64 = ctx.r[5].u64;
	// 8315A8C0: 38E50080  addi r7, r5, 0x80
	ctx.r[7].s64 = ctx.r[5].s64 + 128;
	// 8315A8C4: 3BE50084  addi r31, r5, 0x84
	ctx.r[31].s64 = ctx.r[5].s64 + 132;
	// 8315A8C8: 3BC500FC  addi r30, r5, 0xfc
	ctx.r[30].s64 = ctx.r[5].s64 + 252;
	// 8315A8CC: 39000010  li r8, 0x10
	ctx.r[8].s64 = 16;
	// 8315A8D0: 39630004  addi r11, r3, 4
	ctx.r[11].s64 = ctx.r[3].s64 + 4;
	// 8315A8D4: C0040000  lfs f0, 0(r4)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A8D8: 39440004  addi r10, r4, 4
	ctx.r[10].s64 = ctx.r[4].s64 + 4;
	// 8315A8DC: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315A8E0: 38CB0004  addi r6, r11, 4
	ctx.r[6].s64 = ctx.r[11].s64 + 4;
	// 8315A8E4: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315A8E8: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315A8EC: C1440004  lfs f10, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315A8F0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A8F4: C12B0004  lfs f9, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315A8F8: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A8FC: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315A900: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A904: C0E60000  lfs f7, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315A908: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A90C: ECCB62BA  fmadds f6, f11, f10, f12
	ctx.f[6].f64 = (((ctx.f[11].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315A910: C0AA0000  lfs f5, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315A914: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A918: C0860000  lfs f4, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315A91C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A920: C06A0000  lfs f3, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315A924: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A928: C0460000  lfs f2, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315A92C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A930: EC29323A  fmadds f1, f9, f8, f6
	ctx.f[1].f64 = (((ctx.f[9].f64 * ctx.f[8].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315A934: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A938: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A93C: C1A60000  lfs f13, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315A940: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A944: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315A948: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A94C: C1660000  lfs f11, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315A950: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A954: ED47097A  fmadds f10, f7, f5, f1
	ctx.f[10].f64 = (((ctx.f[7].f64 * ctx.f[5].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315A958: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315A95C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A960: C1060000  lfs f8, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315A964: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A968: C0EA0000  lfs f7, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315A96C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A970: C0C60000  lfs f6, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315A974: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A978: ECA450FA  fmadds f5, f4, f3, f10
	ctx.f[5].f64 = (((ctx.f[4].f64 * ctx.f[3].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315A97C: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315A980: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A984: C0660000  lfs f3, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315A988: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A98C: C02A0000  lfs f1, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315A990: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A994: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315A998: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A99C: ECA2283A  fmadds f5, f2, f0, f5
	ctx.f[5].f64 = (((ctx.f[2].f64 * ctx.f[0].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315A9A0: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315A9A4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A9A8: C0060000  lfs f0, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315A9AC: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A9B0: C3EA0000  lfs f31, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315A9B4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A9B8: C3C60000  lfs f30, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315A9BC: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A9C0: EDAD2B3A  fmadds f13, f13, f12, f5
	ctx.f[13].f64 = (((ctx.f[13].f64 * ctx.f[12].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315A9C4: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315A9C8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A9CC: C0A60000  lfs f5, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315A9D0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A9D4: C3AA0000  lfs f29, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315A9D8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A9DC: C3860000  lfs f28, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315A9E0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315A9E4: EDAB6A7A  fmadds f13, f11, f9, f13
	ctx.f[13].f64 = (((ctx.f[11].f64 * ctx.f[9].f64 + ctx.f[13].f64) as f32) as f64);
	// 8315A9E8: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315A9EC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315A9F0: C1260000  lfs f9, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315A9F4: ED0869FA  fmadds f8, f8, f7, f13
	ctx.f[8].f64 = (((ctx.f[8].f64 * ctx.f[7].f64 + ctx.f[13].f64) as f32) as f64);
	// 8315A9F8: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315A9FC: ECE6413A  fmadds f7, f6, f4, f8
	ctx.f[7].f64 = (((ctx.f[6].f64 * ctx.f[4].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315AA00: ECC3387A  fmadds f6, f3, f1, f7
	ctx.f[6].f64 = (((ctx.f[3].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315AA04: EC8A30BA  fmadds f4, f10, f2, f6
	ctx.f[4].f64 = (((ctx.f[10].f64 * ctx.f[2].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315AA08: EC6027FA  fmadds f3, f0, f31, f4
	ctx.f[3].f64 = (((ctx.f[0].f64 * ctx.f[31].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315AA0C: EC5E1B3A  fmadds f2, f30, f12, f3
	ctx.f[2].f64 = (((ctx.f[30].f64 * ctx.f[12].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315AA10: EC25177A  fmadds f1, f5, f29, f2
	ctx.f[1].f64 = (((ctx.f[5].f64 * ctx.f[29].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315AA14: EC1C0AFA  fmadds f0, f28, f11, f1
	ctx.f[0].f64 = (((ctx.f[28].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315AA18: ED89037A  fmadds f12, f9, f13, f0
	ctx.f[12].f64 = (((ctx.f[9].f64 * ctx.f[13].f64 + ctx.f[0].f64) as f32) as f64);
	// 8315AA1C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA20: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA24: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315AA28: C1660000  lfs f11, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AA2C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA30: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AA34: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA38: ED0B62BA  fmadds f8, f11, f10, f12
	ctx.f[8].f64 = (((ctx.f[11].f64 * ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315AA3C: C1260000  lfs f9, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AA40: C0EA0000  lfs f7, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AA44: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA48: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA4C: C0C60000  lfs f6, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AA50: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA54: C0AA0000  lfs f5, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AA58: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA5C: EC6941FA  fmadds f3, f9, f7, f8
	ctx.f[3].f64 = (((ctx.f[9].f64 * ctx.f[7].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315AA60: C0860000  lfs f4, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AA64: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA68: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315AA6C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA70: C0260000  lfs f1, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AA74: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA78: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AA7C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA80: ED86197A  fmadds f12, f6, f5, f3
	ctx.f[12].f64 = (((ctx.f[6].f64 * ctx.f[5].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315AA84: C1A60000  lfs f13, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AA88: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA8C: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AA90: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AA94: C1460000  lfs f10, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AA98: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AA9C: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AAA0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AAA4: ECE460BA  fmadds f7, f4, f2, f12
	ctx.f[7].f64 = (((ctx.f[4].f64 * ctx.f[2].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315AAA8: C1060000  lfs f8, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AAAC: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AAB0: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AAB4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AAB8: C0A60000  lfs f5, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AABC: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AAC0: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AAC4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AAC8: EC41383A  fmadds f2, f1, f0, f7
	ctx.f[2].f64 = (((ctx.f[1].f64 * ctx.f[0].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315AACC: C0660000  lfs f3, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AAD0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AAD4: C02A0000  lfs f1, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AAD8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AADC: C0060000  lfs f0, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AAE0: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AAE4: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AAE8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AAEC: 388A0004  addi r4, r10, 4
	ctx.r[4].s64 = ctx.r[10].s64 + 4;
	// 8315AAF0: EC4D12FA  fmadds f2, f13, f11, f2
	ctx.f[2].f64 = (((ctx.f[13].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315AAF4: C0E60000  lfs f7, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AAF8: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AAFC: 39460004  addi r10, r6, 4
	ctx.r[10].s64 = ctx.r[6].s64 + 4;
	// 8315AB00: 38C40004  addi r6, r4, 4
	ctx.r[6].s64 = ctx.r[4].s64 + 4;
	// 8315AB04: C1640000  lfs f11, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AB08: C3E40004  lfs f31, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315AB0C: 38C60004  addi r6, r6, 4
	ctx.r[6].s64 = ctx.r[6].s64 + 4;
	// 8315AB10: C3CA0000  lfs f30, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315AB14: 38860004  addi r4, r6, 4
	ctx.r[4].s64 = ctx.r[6].s64 + 4;
	// 8315AB18: C3AA0004  lfs f29, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315AB1C: C38A0008  lfs f28, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315AB20: ED4A127A  fmadds f10, f10, f9, f2
	ctx.f[10].f64 = (((ctx.f[10].f64 * ctx.f[9].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315AB24: C3660000  lfs f27, 0(r6)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315AB28: ED2851BA  fmadds f9, f8, f6, f10
	ctx.f[9].f64 = (((ctx.f[8].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315AB2C: ED05493A  fmadds f8, f5, f4, f9
	ctx.f[8].f64 = (((ctx.f[5].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315AB30: ECC3407A  fmadds f6, f3, f1, f8
	ctx.f[6].f64 = (((ctx.f[3].f64 * ctx.f[1].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315AB34: ECA0333A  fmadds f5, f0, f12, f6
	ctx.f[5].f64 = (((ctx.f[0].f64 * ctx.f[12].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315AB38: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315AB3C: EC7E22FA  fmadds f3, f30, f11, f4
	ctx.f[3].f64 = (((ctx.f[30].f64 * ctx.f[11].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315AB40: EC5D1FFA  fmadds f2, f29, f31, f3
	ctx.f[2].f64 = (((ctx.f[29].f64 * ctx.f[31].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315AB44: EC3C16FA  fmadds f1, f28, f27, f2
	ctx.f[1].f64 = (((ctx.f[28].f64 * ctx.f[27].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315AB48: D0290000  stfs f1, 0(r9)
	tmp.f32 = (ctx.f[1].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315AB4C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8315AB50: FC000850  fneg f0, f1
	ctx.f[0].u64 = ctx.f[1].u64 ^ 0x8000_0000_0000_0000u64;
	// 8315AB54: D0070000  stfs f0, 0(r7)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315AB58: 38E7FFFC  addi r7, r7, -4
	ctx.r[7].s64 = ctx.r[7].s64 + -4;
	// 8315AB5C: 4082FD78  bne 0x8315a8d4
	if !ctx.cr[0].eq {
	pc = 0x8315A8D4; continue 'dispatch;
	}
	// 8315AB60: 3D008200  lis r8, -0x7e00
	ctx.r[8].s64 = -2113929216;
	// 8315AB64: 3920000F  li r9, 0xf
	ctx.r[9].s64 = 15;
	// 8315AB68: 395D1080  addi r10, r29, 0x1080
	ctx.r[10].s64 = ctx.r[29].s64 + 4224;
	// 8315AB6C: C00808A4  lfs f0, 0x8a4(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(2212 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AB70: D0050040  stfs f0, 0x40(r5)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(64 as u32), tmp.u32 ) };
	// 8315AB74: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AB78: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AB7C: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AB80: 390B0004  addi r8, r11, 4
	ctx.r[8].s64 = ctx.r[11].s64 + 4;
	// 8315AB84: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315AB88: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AB8C: C14B0004  lfs f10, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AB90: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AB94: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AB98: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AB9C: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315ABA0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ABA4: C0EA0000  lfs f7, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315ABA8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ABAC: ECCB627A  fmadds f6, f11, f9, f12
	ctx.f[6].f64 = (((ctx.f[11].f64 * ctx.f[9].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315ABB0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315ABB4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ABB8: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315ABBC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ABC0: C0680000  lfs f3, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315ABC4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ABC8: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315ABCC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ABD0: EC2A31FA  fmadds f1, f10, f7, f6
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[7].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315ABD4: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315ABD8: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ABDC: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315ABE0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ABE4: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315ABE8: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ABEC: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315ABF0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ABF4: ED48093A  fmadds f10, f8, f4, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[4].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315ABF8: C1280000  lfs f9, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315ABFC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC00: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AC04: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC08: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AC0C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC10: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AC14: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC18: ECA550BA  fmadds f5, f5, f2, f10
	ctx.f[5].f64 = (((ctx.f[5].f64 * ctx.f[2].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315AC1C: C0880000  lfs f4, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AC20: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC24: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315AC28: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC2C: C0280000  lfs f1, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AC30: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC34: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AC38: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC3C: ECA32B7A  fmadds f5, f3, f13, f5
	ctx.f[5].f64 = (((ctx.f[3].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315AC40: C0680000  lfs f3, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AC44: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC48: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AC4C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC50: C3E80000  lfs f31, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315AC54: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC58: C3CA0000  lfs f30, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315AC5C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC60: ED602AFA  fmadds f11, f0, f11, f5
	ctx.f[11].f64 = (((ctx.f[0].f64 * ctx.f[11].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315AC64: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AC68: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC6C: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AC70: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC74: C3A80000  lfs f29, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315AC78: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AC7C: C38A0000  lfs f28, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315AC80: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC84: ED8C5A3A  fmadds f12, f12, f8, f11
	ctx.f[12].f64 = (((ctx.f[12].f64 * ctx.f[8].f64 + ctx.f[11].f64) as f32) as f64);
	// 8315AC88: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AC8C: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AC90: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AC94: ECC961BA  fmadds f6, f9, f6, f12
	ctx.f[6].f64 = (((ctx.f[9].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315AC98: EC4730BA  fmadds f2, f7, f2, f6
	ctx.f[2].f64 = (((ctx.f[7].f64 * ctx.f[2].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315AC9C: ED8412BA  fmadds f12, f4, f10, f2
	ctx.f[12].f64 = (((ctx.f[4].f64 * ctx.f[10].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315ACA0: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315ACA4: ED41637A  fmadds f10, f1, f13, f12
	ctx.f[10].f64 = (((ctx.f[1].f64 * ctx.f[13].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315ACA8: ED2357BA  fmadds f9, f3, f30, f10
	ctx.f[9].f64 = (((ctx.f[3].f64 * ctx.f[30].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315ACAC: ECFF483A  fmadds f7, f31, f0, f9
	ctx.f[7].f64 = (((ctx.f[31].f64 * ctx.f[0].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315ACB0: ECC53F3A  fmadds f6, f5, f28, f7
	ctx.f[6].f64 = (((ctx.f[5].f64 * ctx.f[28].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315ACB4: ECBD323A  fmadds f5, f29, f8, f6
	ctx.f[5].f64 = (((ctx.f[29].f64 * ctx.f[8].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315ACB8: EC6B293A  fmadds f3, f11, f4, f5
	ctx.f[3].f64 = (((ctx.f[11].f64 * ctx.f[4].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315ACBC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ACC0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ACC4: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315ACC8: C04A0000  lfs f2, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315ACCC: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ACD0: C0280000  lfs f1, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315ACD4: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ACD8: EDA118BA  fmadds f13, f1, f2, f3
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[2].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315ACDC: C00A0000  lfs f0, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315ACE0: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315ACE4: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ACE8: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ACEC: C16A0000  lfs f11, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315ACF0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315ACF4: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315ACF8: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ACFC: ED0C683A  fmadds f8, f12, f0, f13
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64);
	// 8315AD00: C12A0000  lfs f9, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AD04: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD08: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AD0C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD10: C0CA0000  lfs f6, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AD14: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD18: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AD1C: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD20: EC6A42FA  fmadds f3, f10, f11, f8
	ctx.f[3].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315AD24: C08A0000  lfs f4, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AD28: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD2C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315AD30: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD34: C02A0000  lfs f1, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AD38: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD3C: C0080000  lfs f0, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AD40: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD44: ED871A7A  fmadds f12, f7, f9, f3
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[9].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315AD48: C1AA0000  lfs f13, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AD4C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD50: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AD54: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD58: C14A0000  lfs f10, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AD5C: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD60: C1280000  lfs f9, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AD64: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD68: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315AD6C: C10A0000  lfs f8, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AD70: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD74: C0C80000  lfs f6, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AD78: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD7C: C0AA0000  lfs f5, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AD80: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AD84: C0680000  lfs f3, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AD88: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315AD8C: 38EA0004  addi r7, r10, 4
	ctx.r[7].s64 = ctx.r[10].s64 + 4;
	// 8315AD90: ECE2393A  fmadds f7, f2, f4, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[4].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315AD94: C18A0000  lfs f12, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AD98: 39480004  addi r10, r8, 4
	ctx.r[10].s64 = ctx.r[8].s64 + 4;
	// 8315AD9C: C0880000  lfs f4, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315ADA0: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315ADA4: C0470000  lfs f2, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315ADA8: C3E70004  lfs f31, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315ADAC: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315ADB0: C3CA0000  lfs f30, 0(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315ADB4: C3AA0004  lfs f29, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315ADB8: C38A0008  lfs f28, 8(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(8 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315ADBC: 39480004  addi r10, r8, 4
	ctx.r[10].s64 = ctx.r[8].s64 + 4;
	// 8315ADC0: C3680000  lfs f27, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315ADC4: EC20387A  fmadds f1, f0, f1, f7
	ctx.f[1].f64 = (((ctx.f[0].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315ADC8: EC0B0B7A  fmadds f0, f11, f13, f1
	ctx.f[0].f64 = (((ctx.f[11].f64 * ctx.f[13].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315ADCC: EDA902BA  fmadds f13, f9, f10, f0
	ctx.f[13].f64 = (((ctx.f[9].f64 * ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64);
	// 8315ADD0: ED666A3A  fmadds f11, f6, f8, f13
	ctx.f[11].f64 = (((ctx.f[6].f64 * ctx.f[8].f64 + ctx.f[13].f64) as f32) as f64);
	// 8315ADD4: ED43597A  fmadds f10, f3, f5, f11
	ctx.f[10].f64 = (((ctx.f[3].f64 * ctx.f[5].f64 + ctx.f[11].f64) as f32) as f64);
	// 8315ADD8: ED24533A  fmadds f9, f4, f12, f10
	ctx.f[9].f64 = (((ctx.f[4].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315ADDC: ED1E48BA  fmadds f8, f30, f2, f9
	ctx.f[8].f64 = (((ctx.f[30].f64 * ctx.f[2].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315ADE0: ECFD47FA  fmadds f7, f29, f31, f8
	ctx.f[7].f64 = (((ctx.f[29].f64 * ctx.f[31].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315ADE4: ECDC3EFA  fmadds f6, f28, f27, f7
	ctx.f[6].f64 = (((ctx.f[28].f64 * ctx.f[27].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315ADE8: D0DF0000  stfs f6, 0(r31)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315ADEC: D0DE0000  stfs f6, 0(r30)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315ADF0: 3BFF0004  addi r31, r31, 4
	ctx.r[31].s64 = ctx.r[31].s64 + 4;
	// 8315ADF4: 3BDEFFFC  addi r30, r30, -4
	ctx.r[30].s64 = ctx.r[30].s64 + -4;
	// 8315ADF8: 4082FD7C  bne 0x8315ab74
	if !ctx.cr[0].eq {
	pc = 0x8315AB74; continue 'dispatch;
	}
	// 8315ADFC: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AE00: 394B0004  addi r10, r11, 4
	ctx.r[10].s64 = ctx.r[11].s64 + 4;
	// 8315AE04: C1A30000  lfs f13, 0(r3)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AE08: ED80682A  fadds f12, f0, f13
	ctx.f[12].f64 = ((ctx.f[0].f64 + ctx.f[13].f64) as f32) as f64;
	// 8315AE0C: C16B0004  lfs f11, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AE10: 396A0004  addi r11, r10, 4
	ctx.r[11].s64 = ctx.r[10].s64 + 4;
	// 8315AE14: C14A0004  lfs f10, 4(r10)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(4 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AE18: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE1C: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AE20: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE24: ED0B602A  fadds f8, f11, f12
	ctx.f[8].f64 = ((ctx.f[11].f64 + ctx.f[12].f64) as f32) as f64;
	// 8315AE28: C0EB0000  lfs f7, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AE2C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE30: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AE34: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE38: ECAA402A  fadds f5, f10, f8
	ctx.f[5].f64 = ((ctx.f[10].f64 + ctx.f[8].f64) as f32) as f64;
	// 8315AE3C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AE40: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE44: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AE48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE4C: EC49282A  fadds f2, f9, f5
	ctx.f[2].f64 = ((ctx.f[9].f64 + ctx.f[5].f64) as f32) as f64;
	// 8315AE50: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AE54: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE58: C00B0000  lfs f0, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AE5C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE60: EDA7102A  fadds f13, f7, f2
	ctx.f[13].f64 = ((ctx.f[7].f64 + ctx.f[2].f64) as f32) as f64;
	// 8315AE64: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AE68: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE6C: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AE70: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE74: ED46682A  fadds f10, f6, f13
	ctx.f[10].f64 = ((ctx.f[6].f64 + ctx.f[13].f64) as f32) as f64;
	// 8315AE78: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AE7C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE80: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AE84: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE88: ECE4502A  fadds f7, f4, f10
	ctx.f[7].f64 = ((ctx.f[4].f64 + ctx.f[10].f64) as f32) as f64;
	// 8315AE8C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AE90: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE94: C0AB0000  lfs f5, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AE98: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AE9C: EC83382A  fadds f4, f3, f7
	ctx.f[4].f64 = ((ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64;
	// 8315AEA0: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AEA4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEA8: C04B0000  lfs f2, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315AEAC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEB0: EC21202A  fadds f1, f1, f4
	ctx.f[1].f64 = ((ctx.f[1].f64 + ctx.f[4].f64) as f32) as f64;
	// 8315AEB4: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AEB8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEBC: C14B0000  lfs f10, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315AEC0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEC4: ECE0082A  fadds f7, f0, f1
	ctx.f[7].f64 = ((ctx.f[0].f64 + ctx.f[1].f64) as f32) as f64;
	// 8315AEC8: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AECC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AED0: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AED4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AED8: EC0C382A  fadds f0, f12, f7
	ctx.f[0].f64 = ((ctx.f[12].f64 + ctx.f[7].f64) as f32) as f64;
	// 8315AEDC: C18B0000  lfs f12, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AEE0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEE4: C0EB0000  lfs f7, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AEE8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEEC: EC0B002A  fadds f0, f11, f0
	ctx.f[0].f64 = ((ctx.f[11].f64 + ctx.f[0].f64) as f32) as f64;
	// 8315AEF0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AEF4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AEF8: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315AEFC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AF00: ED29002A  fadds f9, f9, f0
	ctx.f[9].f64 = ((ctx.f[9].f64 + ctx.f[0].f64) as f32) as f64;
	// 8315AF04: ED08482A  fadds f8, f8, f9
	ctx.f[8].f64 = ((ctx.f[8].f64 + ctx.f[9].f64) as f32) as f64;
	// 8315AF08: ECC6402A  fadds f6, f6, f8
	ctx.f[6].f64 = ((ctx.f[6].f64 + ctx.f[8].f64) as f32) as f64;
	// 8315AF0C: ECA5302A  fadds f5, f5, f6
	ctx.f[5].f64 = ((ctx.f[5].f64 + ctx.f[6].f64) as f32) as f64;
	// 8315AF10: EC63282A  fadds f3, f3, f5
	ctx.f[3].f64 = ((ctx.f[3].f64 + ctx.f[5].f64) as f32) as f64;
	// 8315AF14: EC42182A  fadds f2, f2, f3
	ctx.f[2].f64 = ((ctx.f[2].f64 + ctx.f[3].f64) as f32) as f64;
	// 8315AF18: EC0D102A  fadds f0, f13, f2
	ctx.f[0].f64 = ((ctx.f[13].f64 + ctx.f[2].f64) as f32) as f64;
	// 8315AF1C: EDAA002A  fadds f13, f10, f0
	ctx.f[13].f64 = ((ctx.f[10].f64 + ctx.f[0].f64) as f32) as f64;
	// 8315AF20: ED44682A  fadds f10, f4, f13
	ctx.f[10].f64 = ((ctx.f[4].f64 + ctx.f[13].f64) as f32) as f64;
	// 8315AF24: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315AF28: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AF2C: ED21502A  fadds f9, f1, f10
	ctx.f[9].f64 = ((ctx.f[1].f64 + ctx.f[10].f64) as f32) as f64;
	// 8315AF30: ED0C482A  fadds f8, f12, f9
	ctx.f[8].f64 = ((ctx.f[12].f64 + ctx.f[9].f64) as f32) as f64;
	// 8315AF34: ECE7402A  fadds f7, f7, f8
	ctx.f[7].f64 = ((ctx.f[7].f64 + ctx.f[8].f64) as f32) as f64;
	// 8315AF38: ECCB382A  fadds f6, f11, f7
	ctx.f[6].f64 = ((ctx.f[11].f64 + ctx.f[7].f64) as f32) as f64;
	// 8315AF3C: ECBF302A  fadds f5, f31, f6
	ctx.f[5].f64 = ((ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64;
	// 8315AF40: EC64282A  fadds f3, f4, f5
	ctx.f[3].f64 = ((ctx.f[4].f64 + ctx.f[5].f64) as f32) as f64;
	// 8315AF44: C04B0000  lfs f2, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315AF48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AF4C: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315AF50: C1AB0004  lfs f13, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AF54: C18B0008  lfs f12, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AF58: EC02182A  fadds f0, f2, f3
	ctx.f[0].f64 = ((ctx.f[2].f64 + ctx.f[3].f64) as f32) as f64;
	// 8315AF5C: ED61002A  fadds f11, f1, f0
	ctx.f[11].f64 = ((ctx.f[1].f64 + ctx.f[0].f64) as f32) as f64;
	// 8315AF60: ED4D582A  fadds f10, f13, f11
	ctx.f[10].f64 = ((ctx.f[13].f64 + ctx.f[11].f64) as f32) as f64;
	// 8315AF64: ED2A602A  fadds f9, f10, f12
	ctx.f[9].f64 = ((ctx.f[10].f64 + ctx.f[12].f64) as f32) as f64;
	// 8315AF68: FD004850  fneg f8, f9
	ctx.f[8].u64 = ctx.f[9].u64 ^ 0x8000_0000_0000_0000u64;
	// 8315AF6C: D10500C0  stfs f8, 0xc0(r5)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(192 as u32), tmp.u32 ) };
	// 8315AF70: 3981FFE0  addi r12, r1, -0x20
	ctx.r[12].s64 = ctx.r[1].s64 + -32;
	// 8315AF74: 4804DB4D  bl 0x831a8ac0
	ctx.lr = 0x8315AF78;
	sub_831A8A8C(ctx, base);
	// 8315AF78: 4804D244  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315AF80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315AF80 size=388
    let mut pc: u32 = 0x8315AF80;
    'dispatch: loop {
        match pc {
            0x8315AF80 => {
    //   block [0x8315AF80..0x8315B104)
	// 8315AF80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315AF84: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315AF88: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315AF8C: 4804DAE1  bl 0x831a8a6c
	ctx.lr = 0x8315AF90;
	sub_831A8A40(ctx, base);
	// 8315AF90: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315AF94: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315AF98: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315AF9C: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315AFA0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315AFA4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315AFA8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315AFAC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315AFB0: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315AFB4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AFB8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315AFBC: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315AFC0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315AFC4: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315AFC8: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315AFCC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315AFD0: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315AFD4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AFD8: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315AFDC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315AFE0: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315AFE4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AFE8: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315AFEC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315AFF0: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315AFF4: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315AFF8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315AFFC: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B000: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B004: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B008: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B00C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B010: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B014: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B018: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B01C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B020: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B024: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B028: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B02C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B030: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B034: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B038: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B03C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B040: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B044: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B048: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B04C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B050: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B054: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B058: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B05C: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B060: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B064: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B068: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B06C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B070: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B074: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B078: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B07C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B080: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B084: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B088: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B08C: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B090: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B094: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B098: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B09C: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B0A0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B0A4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B0A8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B0AC: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B0B0: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B0B4: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B0B8: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B0BC: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B0C0: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B0C4: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B0C8: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B0CC: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B0D0: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B0D4: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B0D8: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B0DC: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B0E0: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B0E4: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B0E8: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B0EC: 4082FEB4  bne 0x8315afa0
	if !ctx.cr[0].eq {
	pc = 0x8315AFA0; continue 'dispatch;
	}
	// 8315B0F0: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B0F4: 4804D9C5  bl 0x831a8ab8
	ctx.lr = 0x8315B0F8;
	sub_831A8A8C(ctx, base);
	// 8315B0F8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B0FC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B100: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B108(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B108 size=388
    let mut pc: u32 = 0x8315B108;
    'dispatch: loop {
        match pc {
            0x8315B108 => {
    //   block [0x8315B108..0x8315B28C)
	// 8315B108: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B10C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B110: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B114: 4804D959  bl 0x831a8a6c
	ctx.lr = 0x8315B118;
	sub_831A8A40(ctx, base);
	// 8315B118: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B11C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B120: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B124: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B128: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B12C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B130: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B134: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B138: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B13C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B140: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B144: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B148: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B14C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B150: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B154: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B158: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B15C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B160: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B164: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B168: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B16C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B170: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B174: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B178: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B17C: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B180: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B184: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B188: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B18C: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B190: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B194: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B198: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B19C: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B1A0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B1A4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B1A8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B1AC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B1B0: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B1B4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B1B8: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B1BC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B1C0: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B1C4: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B1C8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B1CC: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B1D0: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B1D4: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B1D8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B1DC: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B1E0: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B1E4: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B1E8: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B1EC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B1F0: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B1F4: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B1F8: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B1FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B200: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B204: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B208: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B20C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B210: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B214: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B218: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B21C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B220: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B224: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B228: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B22C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B230: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B234: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B238: C32BF200  lfs f25, -0xe00(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3584 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B23C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B240: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B244: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B248: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B24C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B250: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B254: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B258: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B25C: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B260: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B264: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B268: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B26C: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B270: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B274: 4082FEB4  bne 0x8315b128
	if !ctx.cr[0].eq {
	pc = 0x8315B128; continue 'dispatch;
	}
	// 8315B278: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B27C: 4804D83D  bl 0x831a8ab8
	ctx.lr = 0x8315B280;
	sub_831A8A8C(ctx, base);
	// 8315B280: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B284: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B288: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B290(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B290 size=388
    let mut pc: u32 = 0x8315B290;
    'dispatch: loop {
        match pc {
            0x8315B290 => {
    //   block [0x8315B290..0x8315B414)
	// 8315B290: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B294: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B298: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B29C: 4804D7D1  bl 0x831a8a6c
	ctx.lr = 0x8315B2A0;
	sub_831A8A40(ctx, base);
	// 8315B2A0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B2A4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B2A8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B2AC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B2B0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B2B4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B2B8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B2BC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B2C0: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B2C4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B2C8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B2CC: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B2D0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B2D4: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B2D8: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B2DC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B2E0: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B2E4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B2E8: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B2EC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B2F0: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B2F4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B2F8: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B2FC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B300: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B304: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B308: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B30C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B310: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B314: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B318: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B31C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B320: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B324: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B328: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B32C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B330: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B334: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B338: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B33C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B340: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B344: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B348: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B34C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B350: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B354: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B358: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B35C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B360: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B364: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B368: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B36C: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B370: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B374: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B378: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B37C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B380: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B384: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B388: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B38C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B390: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B394: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B398: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B39C: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B3A0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B3A4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B3A8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B3AC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B3B0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B3B4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B3B8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B3BC: C34BF080  lfs f26, -0xf80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3968 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B3C0: C32BF200  lfs f25, -0xe00(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-3584 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B3C4: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B3C8: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B3CC: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B3D0: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B3D4: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B3D8: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B3DC: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B3E0: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B3E4: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B3E8: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B3EC: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B3F0: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B3F4: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B3F8: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B3FC: 4082FEB4  bne 0x8315b2b0
	if !ctx.cr[0].eq {
	pc = 0x8315B2B0; continue 'dispatch;
	}
	// 8315B400: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B404: 4804D6B5  bl 0x831a8ab8
	ctx.lr = 0x8315B408;
	sub_831A8A8C(ctx, base);
	// 8315B408: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B40C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B410: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B418(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B418 size=388
    let mut pc: u32 = 0x8315B418;
    'dispatch: loop {
        match pc {
            0x8315B418 => {
    //   block [0x8315B418..0x8315B59C)
	// 8315B418: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B41C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B420: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B424: 4804D649  bl 0x831a8a6c
	ctx.lr = 0x8315B428;
	sub_831A8A40(ctx, base);
	// 8315B428: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B42C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B430: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B434: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B438: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B43C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B440: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B444: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B448: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B44C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B450: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B454: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B458: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B45C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B460: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B464: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B468: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B46C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B470: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B474: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B478: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B47C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B480: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B484: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B488: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B48C: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B490: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B494: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B498: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B49C: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B4A0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B4A4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B4A8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B4AC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B4B0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B4B4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B4B8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B4BC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B4C0: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B4C4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B4C8: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B4CC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B4D0: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B4D4: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B4D8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B4DC: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B4E0: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B4E4: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B4E8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B4EC: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B4F0: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B4F4: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B4F8: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B4FC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B500: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B504: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B508: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B50C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B510: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B514: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B518: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B51C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B520: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B524: 3968F180  addi r11, r8, -0xe80
	ctx.r[11].s64 = ctx.r[8].s64 + -3712;
	// 8315B528: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B52C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B530: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B534: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B538: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B53C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B540: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B544: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B548: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B54C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B550: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B554: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B558: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B55C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B560: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B564: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B568: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B56C: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B570: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B574: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B578: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B57C: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B580: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B584: 4082FEB4  bne 0x8315b438
	if !ctx.cr[0].eq {
	pc = 0x8315B438; continue 'dispatch;
	}
	// 8315B588: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B58C: 4804D52D  bl 0x831a8ab8
	ctx.lr = 0x8315B590;
	sub_831A8A8C(ctx, base);
	// 8315B590: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B594: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B598: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B5A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B5A0 size=388
    let mut pc: u32 = 0x8315B5A0;
    'dispatch: loop {
        match pc {
            0x8315B5A0 => {
    //   block [0x8315B5A0..0x8315B724)
	// 8315B5A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B5A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B5A8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B5AC: 4804D4C1  bl 0x831a8a6c
	ctx.lr = 0x8315B5B0;
	sub_831A8A40(ctx, base);
	// 8315B5B0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B5B4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B5B8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B5BC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B5C0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B5C4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B5C8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B5CC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B5D0: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B5D4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B5D8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B5DC: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B5E0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B5E4: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B5E8: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B5EC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B5F0: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B5F4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B5F8: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B5FC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B600: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B604: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B608: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B60C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B610: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B614: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B618: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B61C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B620: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B624: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B628: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B62C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B630: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B634: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B638: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B63C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B640: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B644: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B648: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B64C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B650: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B654: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B658: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B65C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B660: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B664: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B668: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B66C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B670: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B674: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B678: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B67C: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B680: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B684: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B688: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B68C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B690: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B694: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B698: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B69C: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315B6A0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B6A4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B6A8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B6AC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B6B0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B6B4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B6B8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B6BC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B6C0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B6C4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B6C8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B6CC: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B6D0: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B6D4: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B6D8: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B6DC: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B6E0: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B6E4: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B6E8: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B6EC: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B6F0: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B6F4: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B6F8: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B6FC: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B700: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B704: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B708: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B70C: 4082FEB4  bne 0x8315b5c0
	if !ctx.cr[0].eq {
	pc = 0x8315B5C0; continue 'dispatch;
	}
	// 8315B710: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B714: 4804D3A5  bl 0x831a8ab8
	ctx.lr = 0x8315B718;
	sub_831A8A8C(ctx, base);
	// 8315B718: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B71C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B720: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B728(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B728 size=388
    let mut pc: u32 = 0x8315B728;
    'dispatch: loop {
        match pc {
            0x8315B728 => {
    //   block [0x8315B728..0x8315B8AC)
	// 8315B728: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B72C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B730: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B734: 4804D339  bl 0x831a8a6c
	ctx.lr = 0x8315B738;
	sub_831A8A40(ctx, base);
	// 8315B738: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B73C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B740: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B744: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B748: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B74C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B750: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B754: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B758: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B75C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B760: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B764: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B768: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B76C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B770: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B774: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B778: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B77C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B780: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B784: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B788: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B78C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B790: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B794: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B798: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B79C: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B7A0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7A4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B7A8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B7AC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B7B0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7B4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B7B8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B7BC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B7C0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B7C4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7C8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B7CC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B7D0: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B7D4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7D8: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B7DC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B7E0: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B7E4: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B7E8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7EC: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B7F0: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B7F4: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B7F8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B7FC: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B800: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B804: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B808: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B80C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B810: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B814: 3908F180  addi r8, r8, -0xe80
	ctx.r[8].s64 = ctx.r[8].s64 + -3712;
	// 8315B818: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B81C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B820: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B824: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B828: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B82C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B830: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B834: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B838: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B83C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B840: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B844: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B848: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B84C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B850: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B854: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B858: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B85C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B860: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B864: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B868: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B86C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B870: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B874: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315B878: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315B87C: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B880: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315B884: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315B888: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315B88C: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315B890: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315B894: 4082FEB4  bne 0x8315b748
	if !ctx.cr[0].eq {
	pc = 0x8315B748; continue 'dispatch;
	}
	// 8315B898: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B89C: 4804D21D  bl 0x831a8ab8
	ctx.lr = 0x8315B8A0;
	sub_831A8A8C(ctx, base);
	// 8315B8A0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315B8A4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315B8A8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315B8B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315B8B0 size=388
    let mut pc: u32 = 0x8315B8B0;
    'dispatch: loop {
        match pc {
            0x8315B8B0 => {
    //   block [0x8315B8B0..0x8315BA34)
	// 8315B8B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315B8B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315B8B8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315B8BC: 4804D1B1  bl 0x831a8a6c
	ctx.lr = 0x8315B8C0;
	sub_831A8A40(ctx, base);
	// 8315B8C0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315B8C4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315B8C8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315B8CC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315B8D0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315B8D4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B8D8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B8DC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315B8E0: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315B8E4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B8E8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B8EC: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B8F0: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315B8F4: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315B8F8: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B8FC: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315B900: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B904: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B908: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B90C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B910: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B914: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B918: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B91C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B920: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B924: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B928: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B92C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B930: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B934: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315B938: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B93C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B940: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B944: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315B948: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B94C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B950: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315B954: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B958: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315B95C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B960: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315B964: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B968: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315B96C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315B970: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B974: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315B978: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B97C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315B980: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B984: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315B988: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315B98C: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B990: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315B994: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B998: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315B99C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315B9A0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315B9A4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315B9A8: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315B9AC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315B9B0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315B9B4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315B9B8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315B9BC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315B9C0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315B9C4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315B9C8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315B9CC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315B9D0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315B9D4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315B9D8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315B9DC: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315B9E0: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315B9E4: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B9E8: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315B9EC: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315B9F0: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315B9F4: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315B9F8: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315B9FC: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315BA00: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315BA04: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BA08: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315BA0C: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315BA10: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315BA14: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315BA18: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315BA1C: 4082FEB4  bne 0x8315b8d0
	if !ctx.cr[0].eq {
	pc = 0x8315B8D0; continue 'dispatch;
	}
	// 8315BA20: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BA24: 4804D095  bl 0x831a8ab8
	ctx.lr = 0x8315BA28;
	sub_831A8A8C(ctx, base);
	// 8315BA28: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315BA2C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315BA30: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315BA38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315BA38 size=388
    let mut pc: u32 = 0x8315BA38;
    'dispatch: loop {
        match pc {
            0x8315BA38 => {
    //   block [0x8315BA38..0x8315BBBC)
	// 8315BA38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315BA3C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315BA40: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BA44: 4804D029  bl 0x831a8a6c
	ctx.lr = 0x8315BA48;
	sub_831A8A40(ctx, base);
	// 8315BA48: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315BA4C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315BA50: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315BA54: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315BA58: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315BA5C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BA60: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BA64: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315BA68: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315BA6C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BA70: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BA74: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BA78: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315BA7C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315BA80: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BA84: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315BA88: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BA8C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BA90: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BA94: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BA98: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BA9C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAA0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BAA4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BAA8: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BAAC: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BAB0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAB4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BAB8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BABC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315BAC0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAC4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BAC8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BACC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BAD0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BAD4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAD8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315BADC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BAE0: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BAE4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAE8: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BAEC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BAF0: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315BAF4: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BAF8: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BAFC: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BB00: 3908F180  addi r8, r8, -0xe80
	ctx.r[8].s64 = ctx.r[8].s64 + -3712;
	// 8315BB04: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315BB08: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BB0C: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BB10: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BB14: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BB18: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BB1C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BB20: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BB24: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BB28: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315BB2C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BB30: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315BB34: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BB38: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315BB3C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BB40: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BB44: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315BB48: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BB4C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315BB50: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315BB54: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315BB58: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315BB5C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315BB60: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315BB64: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315BB68: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315BB6C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BB70: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BB74: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BB78: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BB7C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315BB80: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315BB84: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315BB88: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315BB8C: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BB90: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315BB94: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315BB98: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315BB9C: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315BBA0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315BBA4: 4082FEB4  bne 0x8315ba58
	if !ctx.cr[0].eq {
	pc = 0x8315BA58; continue 'dispatch;
	}
	// 8315BBA8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BBAC: 4804CF0D  bl 0x831a8ab8
	ctx.lr = 0x8315BBB0;
	sub_831A8A8C(ctx, base);
	// 8315BBB0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315BBB4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315BBB8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315BBC0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315BBC0 size=388
    let mut pc: u32 = 0x8315BBC0;
    'dispatch: loop {
        match pc {
            0x8315BBC0 => {
    //   block [0x8315BBC0..0x8315BD44)
	// 8315BBC0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315BBC4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315BBC8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BBCC: 4804CEA1  bl 0x831a8a6c
	ctx.lr = 0x8315BBD0;
	sub_831A8A40(ctx, base);
	// 8315BBD0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315BBD4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315BBD8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315BBDC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315BBE0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315BBE4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BBE8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BBEC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315BBF0: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315BBF4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BBF8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BBFC: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BC00: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315BC04: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315BC08: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BC0C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315BC10: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BC14: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC18: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BC1C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BC20: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BC24: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC28: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BC2C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BC30: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BC34: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BC38: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC3C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BC40: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BC44: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315BC48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC4C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BC50: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BC54: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BC58: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BC5C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC60: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315BC64: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BC68: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BC6C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC70: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BC74: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315BC78: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315BC7C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BC80: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC84: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BC88: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BC8C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315BC90: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BC94: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BC98: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BC9C: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BCA0: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BCA4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BCA8: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BCAC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BCB0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315BCB4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BCB8: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315BCBC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BCC0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315BCC4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BCC8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BCCC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315BCD0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BCD4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315BCD8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315BCDC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315BCE0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315BCE4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315BCE8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315BCEC: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315BCF0: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315BCF4: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BCF8: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BCFC: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BD00: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BD04: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315BD08: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315BD0C: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315BD10: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315BD14: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BD18: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315BD1C: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315BD20: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315BD24: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315BD28: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315BD2C: 4082FEB4  bne 0x8315bbe0
	if !ctx.cr[0].eq {
	pc = 0x8315BBE0; continue 'dispatch;
	}
	// 8315BD30: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BD34: 4804CD85  bl 0x831a8ab8
	ctx.lr = 0x8315BD38;
	sub_831A8A8C(ctx, base);
	// 8315BD38: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315BD3C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315BD40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315BD48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315BD48 size=388
    let mut pc: u32 = 0x8315BD48;
    'dispatch: loop {
        match pc {
            0x8315BD48 => {
    //   block [0x8315BD48..0x8315BECC)
	// 8315BD48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315BD4C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315BD50: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BD54: 4804CD19  bl 0x831a8a6c
	ctx.lr = 0x8315BD58;
	sub_831A8A40(ctx, base);
	// 8315BD58: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315BD5C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315BD60: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315BD64: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315BD68: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315BD6C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BD70: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BD74: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315BD78: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315BD7C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BD80: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BD84: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BD88: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315BD8C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315BD90: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BD94: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315BD98: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BD9C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDA0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BDA4: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BDA8: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BDAC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDB0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BDB4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BDB8: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BDBC: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BDC0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDC4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BDC8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BDCC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315BDD0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDD4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BDD8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BDDC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BDE0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BDE4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDE8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315BDEC: 3908F180  addi r8, r8, -0xe80
	ctx.r[8].s64 = ctx.r[8].s64 + -3712;
	// 8315BDF0: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BDF4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BDF8: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BDFC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BE00: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315BE04: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BE08: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BE0C: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BE10: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BE14: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315BE18: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BE1C: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BE20: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BE24: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BE28: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BE2C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BE30: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BE34: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BE38: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315BE3C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BE40: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315BE44: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BE48: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315BE4C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BE50: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BE54: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315BE58: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BE5C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315BE60: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315BE64: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315BE68: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315BE6C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315BE70: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315BE74: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315BE78: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315BE7C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BE80: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BE84: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315BE88: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BE8C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315BE90: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315BE94: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315BE98: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315BE9C: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BEA0: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315BEA4: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315BEA8: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315BEAC: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315BEB0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315BEB4: 4082FEB4  bne 0x8315bd68
	if !ctx.cr[0].eq {
	pc = 0x8315BD68; continue 'dispatch;
	}
	// 8315BEB8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BEBC: 4804CBFD  bl 0x831a8ab8
	ctx.lr = 0x8315BEC0;
	sub_831A8A8C(ctx, base);
	// 8315BEC0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315BEC4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315BEC8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315BED0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315BED0 size=388
    let mut pc: u32 = 0x8315BED0;
    'dispatch: loop {
        match pc {
            0x8315BED0 => {
    //   block [0x8315BED0..0x8315C054)
	// 8315BED0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315BED4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315BED8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315BEDC: 4804CB91  bl 0x831a8a6c
	ctx.lr = 0x8315BEE0;
	sub_831A8A40(ctx, base);
	// 8315BEE0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315BEE4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315BEE8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315BEEC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315BEF0: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315BEF4: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BEF8: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BEFC: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315BF00: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315BF04: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF08: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BF0C: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BF10: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315BF14: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315BF18: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BF1C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315BF20: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BF24: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF28: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BF2C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BF30: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BF34: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF38: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BF3C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BF40: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315BF44: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BF48: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF4C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BF50: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BF54: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315BF58: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF5C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BF60: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315BF64: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315BF68: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315BF6C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF70: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315BF74: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BF78: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315BF7C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF80: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315BF84: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BF88: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315BF8C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315BF90: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BF94: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315BF98: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BF9C: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315BFA0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BFA4: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315BFA8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BFAC: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BFB0: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315BFB4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BFB8: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315BFBC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315BFC0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315BFC4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315BFC8: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315BFCC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315BFD0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315BFD4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315BFD8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315BFDC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315BFE0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315BFE4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315BFE8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315BFEC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315BFF0: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315BFF4: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315BFF8: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315BFFC: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C000: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C004: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C008: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C00C: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C010: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C014: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C018: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C01C: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C020: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C024: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C028: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C02C: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C030: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C034: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C038: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C03C: 4082FEB4  bne 0x8315bef0
	if !ctx.cr[0].eq {
	pc = 0x8315BEF0; continue 'dispatch;
	}
	// 8315C040: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C044: 4804CA75  bl 0x831a8ab8
	ctx.lr = 0x8315C048;
	sub_831A8A8C(ctx, base);
	// 8315C048: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C04C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C050: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C058(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C058 size=388
    let mut pc: u32 = 0x8315C058;
    'dispatch: loop {
        match pc {
            0x8315C058 => {
    //   block [0x8315C058..0x8315C1DC)
	// 8315C058: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C05C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315C060: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C064: 4804CA09  bl 0x831a8a6c
	ctx.lr = 0x8315C068;
	sub_831A8A40(ctx, base);
	// 8315C068: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315C06C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315C070: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315C074: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C078: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315C07C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C080: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C084: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315C088: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315C08C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C090: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C094: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C098: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315C09C: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315C0A0: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C0A4: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315C0A8: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C0AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C0B0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C0B4: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C0B8: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C0BC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C0C0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C0C4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C0C8: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C0CC: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C0D0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C0D4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C0D8: 3908F180  addi r8, r8, -0xe80
	ctx.r[8].s64 = ctx.r[8].s64 + -3712;
	// 8315C0DC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C0E0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C0E4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C0E8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C0EC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C0F0: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C0F4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C0F8: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315C0FC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C100: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C104: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C108: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C10C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C110: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315C114: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C118: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C11C: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C120: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C124: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315C128: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C12C: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C130: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C134: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C138: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C13C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C140: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C144: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C148: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315C14C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C150: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315C154: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C158: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315C15C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C160: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C164: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315C168: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C16C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315C170: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315C174: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315C178: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315C17C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315C180: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315C184: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C188: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C18C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C190: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C194: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C198: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C19C: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C1A0: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C1A4: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C1A8: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C1AC: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C1B0: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C1B4: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C1B8: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C1BC: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C1C0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C1C4: 4082FEB4  bne 0x8315c078
	if !ctx.cr[0].eq {
	pc = 0x8315C078; continue 'dispatch;
	}
	// 8315C1C8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C1CC: 4804C8ED  bl 0x831a8ab8
	ctx.lr = 0x8315C1D0;
	sub_831A8A8C(ctx, base);
	// 8315C1D0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C1D4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C1D8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C1E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C1E0 size=388
    let mut pc: u32 = 0x8315C1E0;
    'dispatch: loop {
        match pc {
            0x8315C1E0 => {
    //   block [0x8315C1E0..0x8315C364)
	// 8315C1E0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C1E4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315C1E8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C1EC: 4804C881  bl 0x831a8a6c
	ctx.lr = 0x8315C1F0;
	sub_831A8A40(ctx, base);
	// 8315C1F0: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315C1F4: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315C1F8: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315C1FC: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C200: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315C204: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C208: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C20C: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315C210: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315C214: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C218: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C21C: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C220: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315C224: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315C228: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C22C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315C230: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C234: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C238: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C23C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C240: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C244: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C248: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C24C: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315C250: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C254: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C258: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C25C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C260: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C264: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C268: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C26C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C270: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C274: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C278: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C27C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C280: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315C284: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C288: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C28C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C290: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C294: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C298: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315C29C: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C2A0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C2A4: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C2A8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C2AC: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315C2B0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C2B4: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C2B8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C2BC: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C2C0: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C2C4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C2C8: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C2CC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C2D0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315C2D4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C2D8: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315C2DC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C2E0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315C2E4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C2E8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C2EC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315C2F0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C2F4: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315C2F8: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315C2FC: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315C300: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315C304: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315C308: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315C30C: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C310: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C314: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C318: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C31C: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C320: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C324: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C328: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C32C: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C330: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C334: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C338: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C33C: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C340: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C344: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C348: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C34C: 4082FEB4  bne 0x8315c200
	if !ctx.cr[0].eq {
	pc = 0x8315C200; continue 'dispatch;
	}
	// 8315C350: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C354: 4804C765  bl 0x831a8ab8
	ctx.lr = 0x8315C358;
	sub_831A8A8C(ctx, base);
	// 8315C358: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C35C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C360: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C368(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C368 size=388
    let mut pc: u32 = 0x8315C368;
    'dispatch: loop {
        match pc {
            0x8315C368 => {
    //   block [0x8315C368..0x8315C4EC)
	// 8315C368: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C36C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315C370: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C374: 4804C6F9  bl 0x831a8a6c
	ctx.lr = 0x8315C378;
	sub_831A8A40(ctx, base);
	// 8315C378: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315C37C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315C380: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315C384: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C388: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315C38C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C390: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C394: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315C398: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315C39C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C3A0: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C3A4: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C3A8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315C3AC: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315C3B0: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C3B4: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315C3B8: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C3BC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C3C0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C3C4: 3908F180  addi r8, r8, -0xe80
	ctx.r[8].s64 = ctx.r[8].s64 + -3712;
	// 8315C3C8: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C3CC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C3D0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C3D4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C3D8: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C3DC: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C3E0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C3E4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C3E8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C3EC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C3F0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C3F4: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C3F8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C3FC: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C400: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C404: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C408: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315C40C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C410: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C414: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C418: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C41C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C420: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315C424: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C428: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C42C: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C430: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C434: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315C438: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C43C: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C440: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C444: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C448: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C44C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C450: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C454: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C458: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315C45C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C460: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315C464: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C468: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315C46C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C470: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C474: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315C478: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C47C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315C480: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315C484: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315C488: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315C48C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315C490: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315C494: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C498: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C49C: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C4A0: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C4A4: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C4A8: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C4AC: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C4B0: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C4B4: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C4B8: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C4BC: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C4C0: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C4C4: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C4C8: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C4CC: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C4D0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C4D4: 4082FEB4  bne 0x8315c388
	if !ctx.cr[0].eq {
	pc = 0x8315C388; continue 'dispatch;
	}
	// 8315C4D8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C4DC: 4804C5DD  bl 0x831a8ab8
	ctx.lr = 0x8315C4E0;
	sub_831A8A8C(ctx, base);
	// 8315C4E0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C4E4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C4E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C4F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C4F0 size=388
    let mut pc: u32 = 0x8315C4F0;
    'dispatch: loop {
        match pc {
            0x8315C4F0 => {
    //   block [0x8315C4F0..0x8315C674)
	// 8315C4F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C4F4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315C4F8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C4FC: 4804C571  bl 0x831a8a6c
	ctx.lr = 0x8315C500;
	sub_831A8A40(ctx, base);
	// 8315C500: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315C504: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315C508: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315C50C: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C510: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315C514: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C518: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C51C: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315C520: 39070180  addi r8, r7, 0x180
	ctx.r[8].s64 = ctx.r[7].s64 + 384;
	// 8315C524: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C528: 3908F080  addi r8, r8, -0xf80
	ctx.r[8].s64 = ctx.r[8].s64 + -3968;
	// 8315C52C: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C530: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315C534: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315C538: C1270180  lfs f9, 0x180(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(384 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C53C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315C540: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C544: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C548: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C54C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C550: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C554: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C558: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C55C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C560: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C564: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C568: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C56C: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C570: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C574: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C578: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C57C: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C580: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C584: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C588: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C58C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C590: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315C594: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C598: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C59C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C5A0: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C5A4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C5A8: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315C5AC: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C5B0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C5B4: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C5B8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C5BC: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315C5C0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C5C4: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C5C8: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C5CC: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C5D0: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C5D4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C5D8: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C5DC: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C5E0: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315C5E4: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C5E8: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315C5EC: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C5F0: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315C5F4: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C5F8: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C5FC: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315C600: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C604: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315C608: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315C60C: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315C610: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315C614: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315C618: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315C61C: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C620: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C624: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C628: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C62C: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C630: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C634: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C638: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C63C: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C640: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C644: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C648: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C64C: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C650: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C654: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C658: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C65C: 4082FEB4  bne 0x8315c510
	if !ctx.cr[0].eq {
	pc = 0x8315C510; continue 'dispatch;
	}
	// 8315C660: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C664: 4804C455  bl 0x831a8ab8
	ctx.lr = 0x8315C668;
	sub_831A8A8C(ctx, base);
	// 8315C668: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C66C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C670: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C678(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C678 size=388
    let mut pc: u32 = 0x8315C678;
    'dispatch: loop {
        match pc {
            0x8315C678 => {
    //   block [0x8315C678..0x8315C7FC)
	// 8315C678: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C67C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315C680: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C684: 4804C3E9  bl 0x831a8a6c
	ctx.lr = 0x8315C688;
	sub_831A8A40(ctx, base);
	// 8315C688: 3D608212  lis r11, -0x7dee
	ctx.r[11].s64 = -2112749568;
	// 8315C68C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315C690: 39200020  li r9, 0x20
	ctx.r[9].s64 = 32;
	// 8315C694: C00BDFB4  lfs f0, -0x204c(r11)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8268 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C698: 7D475378  mr r7, r10
	ctx.r[7].u64 = ctx.r[10].u64;
	// 8315C69C: C1A40000  lfs f13, 0(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C6A0: C1840004  lfs f12, 4(r4)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C6A4: 39640004  addi r11, r4, 4
	ctx.r[11].s64 = ctx.r[4].s64 + 4;
	// 8315C6A8: 3907F180  addi r8, r7, -0xe80
	ctx.r[8].s64 = ctx.r[7].s64 + -3712;
	// 8315C6AC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C6B0: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C6B4: C1670000  lfs f11, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C6B8: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315C6BC: ED4B0372  fmuls f10, f11, f13
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[13].f64) as f32) as f64);
	// 8315C6C0: C127F180  lfs f9, -0xe80(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(-3712 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C6C4: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315C6C8: C10B0000  lfs f8, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C6CC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C6D0: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C6D4: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C6D8: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C6DC: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C6E0: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C6E4: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C6E8: EC89533A  fmadds f4, f9, f12, f10
	ctx.f[4].f64 = (((ctx.f[9].f64 * ctx.f[12].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C6EC: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C6F0: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C6F4: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C6F8: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C6FC: C02B0000  lfs f1, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C700: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C704: C1A80000  lfs f13, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C708: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C70C: ED87223A  fmadds f12, f7, f8, f4
	ctx.f[12].f64 = (((ctx.f[7].f64 * ctx.f[8].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C710: C16B0000  lfs f11, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C714: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C718: C1480000  lfs f10, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[10].f64 = (tmp.f32 as f64);
	// 8315C71C: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C720: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C724: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C728: C1080000  lfs f8, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[8].f64 = (tmp.f32 as f64);
	// 8315C72C: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C730: ECE561BA  fmadds f7, f5, f6, f12
	ctx.f[7].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[12].f64) as f32) as f64);
	// 8315C734: C0CB0000  lfs f6, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[6].f64 = (tmp.f32 as f64);
	// 8315C738: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C73C: C0A80000  lfs f5, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C740: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C744: C08B0000  lfs f4, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[4].f64 = (tmp.f32 as f64);
	// 8315C748: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C74C: C1880000  lfs f12, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C750: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C754: ECE238FA  fmadds f7, f2, f3, f7
	ctx.f[7].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C758: C06B0000  lfs f3, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C75C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C760: C0480000  lfs f2, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[2].f64 = (tmp.f32 as f64);
	// 8315C764: 39080180  addi r8, r8, 0x180
	ctx.r[8].s64 = ctx.r[8].s64 + 384;
	// 8315C768: C3EB0000  lfs f31, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[31].f64 = (tmp.f32 as f64);
	// 8315C76C: 396B0004  addi r11, r11, 4
	ctx.r[11].s64 = ctx.r[11].s64 + 4;
	// 8315C770: C3C80000  lfs f30, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[30].f64 = (tmp.f32 as f64);
	// 8315C774: 39080080  addi r8, r8, 0x80
	ctx.r[8].s64 = ctx.r[8].s64 + 128;
	// 8315C778: 38EB0004  addi r7, r11, 4
	ctx.r[7].s64 = ctx.r[11].s64 + 4;
	// 8315C77C: EC2D387A  fmadds f1, f13, f1, f7
	ctx.f[1].f64 = (((ctx.f[13].f64 * ctx.f[1].f64 + ctx.f[7].f64) as f32) as f64);
	// 8315C780: C1AB0000  lfs f13, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C784: 39680180  addi r11, r8, 0x180
	ctx.r[11].s64 = ctx.r[8].s64 + 384;
	// 8315C788: C0E80000  lfs f7, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C78C: 39070004  addi r8, r7, 4
	ctx.r[8].s64 = ctx.r[7].s64 + 4;
	// 8315C790: C3A70000  lfs f29, 0(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315C794: C3870004  lfs f28, 4(r7)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) };
	ctx.f[28].f64 = (tmp.f32 as f64);
	// 8315C798: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315C79C: C36B0000  lfs f27, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[27].f64 = (tmp.f32 as f64);
	// 8315C7A0: 38880004  addi r4, r8, 4
	ctx.r[4].s64 = ctx.r[8].s64 + 4;
	// 8315C7A4: C34B0080  lfs f26, 0x80(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(128 as u32) ) };
	ctx.f[26].f64 = (tmp.f32 as f64);
	// 8315C7A8: C32B0200  lfs f25, 0x200(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(512 as u32) ) };
	ctx.f[25].f64 = (tmp.f32 as f64);
	// 8315C7AC: EC2A0AFA  fmadds f1, f10, f11, f1
	ctx.f[1].f64 = (((ctx.f[10].f64 * ctx.f[11].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C7B0: C1680000  lfs f11, 0(r8)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C7B4: ED480A7A  fmadds f10, f8, f9, f1
	ctx.f[10].f64 = (((ctx.f[8].f64 * ctx.f[9].f64 + ctx.f[1].f64) as f32) as f64);
	// 8315C7B8: ED2551BA  fmadds f9, f5, f6, f10
	ctx.f[9].f64 = (((ctx.f[5].f64 * ctx.f[6].f64 + ctx.f[10].f64) as f32) as f64);
	// 8315C7BC: ED0C493A  fmadds f8, f12, f4, f9
	ctx.f[8].f64 = (((ctx.f[12].f64 * ctx.f[4].f64 + ctx.f[9].f64) as f32) as f64);
	// 8315C7C0: ECC240FA  fmadds f6, f2, f3, f8
	ctx.f[6].f64 = (((ctx.f[2].f64 * ctx.f[3].f64 + ctx.f[8].f64) as f32) as f64);
	// 8315C7C4: ECBE37FA  fmadds f5, f30, f31, f6
	ctx.f[5].f64 = (((ctx.f[30].f64 * ctx.f[31].f64 + ctx.f[6].f64) as f32) as f64);
	// 8315C7C8: EC872B7A  fmadds f4, f7, f13, f5
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[13].f64 + ctx.f[5].f64) as f32) as f64);
	// 8315C7CC: EC7B277A  fmadds f3, f27, f29, f4
	ctx.f[3].f64 = (((ctx.f[27].f64 * ctx.f[29].f64 + ctx.f[4].f64) as f32) as f64);
	// 8315C7D0: EC5A1F3A  fmadds f2, f26, f28, f3
	ctx.f[2].f64 = (((ctx.f[26].f64 * ctx.f[28].f64 + ctx.f[3].f64) as f32) as f64);
	// 8315C7D4: EC3912FA  fmadds f1, f25, f11, f2
	ctx.f[1].f64 = (((ctx.f[25].f64 * ctx.f[11].f64 + ctx.f[2].f64) as f32) as f64);
	// 8315C7D8: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C7DC: D1A50000  stfs f13, 0(r5)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C7E0: 38A50004  addi r5, r5, 4
	ctx.r[5].s64 = ctx.r[5].s64 + 4;
	// 8315C7E4: 4082FEB4  bne 0x8315c698
	if !ctx.cr[0].eq {
	pc = 0x8315C698; continue 'dispatch;
	}
	// 8315C7E8: 3981FFF8  addi r12, r1, -8
	ctx.r[12].s64 = ctx.r[1].s64 + -8;
	// 8315C7EC: 4804C2CD  bl 0x831a8ab8
	ctx.lr = 0x8315C7F0;
	sub_831A8A8C(ctx, base);
	// 8315C7F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315C7F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315C7F8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C800(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315C800 size=16
    let mut pc: u32 = 0x8315C800;
    'dispatch: loop {
        match pc {
            0x8315C800 => {
    //   block [0x8315C800..0x8315C810)
	// 8315C800: 3CC08339  lis r6, -0x7cc7
	ctx.r[6].s64 = -2093416448;
	// 8315C804: 81667F94  lwz r11, 0x7f94(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(32660 as u32) ) } as u64;
	// 8315C808: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315C80C: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C810(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315C810 size=252
    let mut pc: u32 = 0x8315C810;
    'dispatch: loop {
        match pc {
            0x8315C810 => {
    //   block [0x8315C810..0x8315C90C)
	// 8315C810: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 8315C814: 3CE08339  lis r7, -0x7cc7
	ctx.r[7].s64 = -2093416448;
	// 8315C818: 39400800  li r10, 0x800
	ctx.r[10].s64 = 2048;
	// 8315C81C: 810B7F70  lwz r8, 0x7f70(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32624 as u32) ) } as u64;
	// 8315C820: 3928001F  addi r9, r8, 0x1f
	ctx.r[9].s64 = ctx.r[8].s64 + 31;
	// 8315C824: 55290034  rlwinm r9, r9, 0, 0, 0x1a
	ctx.r[9].u64 = ctx.r[9].u32 as u64 & 0xFFFFFFFFu64;
	// 8315C828: 91277F8C  stw r9, 0x7f8c(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(32652 as u32), ctx.r[9].u32 ) };
	// 8315C82C: 39690800  addi r11, r9, 0x800
	ctx.r[11].s64 = ctx.r[9].s64 + 2048;
	// 8315C830: 7D294050  subf r9, r9, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 8315C834: 7D0958AE  lbzx r8, r9, r11
	ctx.r[8].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8315C838: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315C83C: 990B0000  stb r8, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8315C840: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315C844: 4080FFF0  bge 0x8315c834
	if !ctx.cr[0].lt {
	pc = 0x8315C834; continue 'dispatch;
	}
	// 8315C848: 3D208219  lis r9, -0x7de7
	ctx.r[9].s64 = -2112290816;
	// 8315C84C: 81677F8C  lwz r11, 0x7f8c(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(32652 as u32) ) } as u64;
	// 8315C850: 39400040  li r10, 0x40
	ctx.r[10].s64 = 64;
	// 8315C854: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8315C858: C0095D80  lfs f0, 0x5d80(r9)
	ctx.fpscr.disable_flush_mode_unconditional();
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(23936 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315C85C: C1ABFFF8  lfs f13, -8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-8 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315C860: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315C864: ED8D0032  fmuls f12, f13, f0
	ctx.f[12].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C868: D18BFFF8  stfs f12, -8(r11)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-8 as u32), tmp.u32 ) };
	// 8315C86C: C16BFFFC  lfs f11, -4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-4 as u32) ) };
	ctx.f[11].f64 = (tmp.f32 as f64);
	// 8315C870: ED4B0032  fmuls f10, f11, f0
	ctx.f[10].f64 = (((ctx.f[11].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C874: D14BFFFC  stfs f10, -4(r11)
	tmp.f32 = (ctx.f[10].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-4 as u32), tmp.u32 ) };
	// 8315C878: C12B0000  lfs f9, 0(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) };
	ctx.f[9].f64 = (tmp.f32 as f64);
	// 8315C87C: ED090032  fmuls f8, f9, f0
	ctx.f[8].f64 = (((ctx.f[9].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C880: D10B0000  stfs f8, 0(r11)
	tmp.f32 = (ctx.f[8].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315C884: C0EB0004  lfs f7, 4(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) };
	ctx.f[7].f64 = (tmp.f32 as f64);
	// 8315C888: ECC70032  fmuls f6, f7, f0
	ctx.f[6].f64 = (((ctx.f[7].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C88C: D0CB0004  stfs f6, 4(r11)
	tmp.f32 = (ctx.f[6].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(4 as u32), tmp.u32 ) };
	// 8315C890: C0AB0008  lfs f5, 8(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) };
	ctx.f[5].f64 = (tmp.f32 as f64);
	// 8315C894: EC850032  fmuls f4, f5, f0
	ctx.f[4].f64 = (((ctx.f[5].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C898: D08B0008  stfs f4, 8(r11)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(8 as u32), tmp.u32 ) };
	// 8315C89C: C06B000C  lfs f3, 0xc(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) };
	ctx.f[3].f64 = (tmp.f32 as f64);
	// 8315C8A0: EC430032  fmuls f2, f3, f0
	ctx.f[2].f64 = (((ctx.f[3].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C8A4: D04B000C  stfs f2, 0xc(r11)
	tmp.f32 = (ctx.f[2].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(12 as u32), tmp.u32 ) };
	// 8315C8A8: C02B0010  lfs f1, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[1].f64 = (tmp.f32 as f64);
	// 8315C8AC: EDA10032  fmuls f13, f1, f0
	ctx.f[13].f64 = (((ctx.f[1].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C8B0: D1AB0010  stfs f13, 0x10(r11)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(16 as u32), tmp.u32 ) };
	// 8315C8B4: C18B0014  lfs f12, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315C8B8: ED6C0032  fmuls f11, f12, f0
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315C8BC: D16B0014  stfs f11, 0x14(r11)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(20 as u32), tmp.u32 ) };
	// 8315C8C0: 396B0020  addi r11, r11, 0x20
	ctx.r[11].s64 = ctx.r[11].s64 + 32;
	// 8315C8C4: 4082FF98  bne 0x8315c85c
	if !ctx.cr[0].eq {
	pc = 0x8315C85C; continue 'dispatch;
	}
	// 8315C8C8: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 8315C8CC: 3CE08339  lis r7, -0x7cc7
	ctx.r[7].s64 = -2093416448;
	// 8315C8D0: 39402000  li r10, 0x2000
	ctx.r[10].s64 = 8192;
	// 8315C8D4: 810B7F74  lwz r8, 0x7f74(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32628 as u32) ) } as u64;
	// 8315C8D8: 38A8001F  addi r5, r8, 0x1f
	ctx.r[5].s64 = ctx.r[8].s64 + 31;
	// 8315C8DC: 54A90034  rlwinm r9, r5, 0, 0, 0x1a
	ctx.r[9].u64 = ctx.r[5].u32 as u64 & 0xFFFFFFFFu64;
	// 8315C8E0: 91277F88  stw r9, 0x7f88(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(32648 as u32), ctx.r[9].u32 ) };
	// 8315C8E4: 39692000  addi r11, r9, 0x2000
	ctx.r[11].s64 = ctx.r[9].s64 + 8192;
	// 8315C8E8: 7D294050  subf r9, r9, r8
	ctx.r[9].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 8315C8EC: 7D0B48AE  lbzx r8, r11, r9
	ctx.r[8].u64 = unsafe { crate::rt::load_u8(base as *const u8, ctx.r[11].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8315C8F0: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315C8F4: 990B0000  stb r8, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8315C8F8: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315C8FC: 4080FFF0  bge 0x8315c8ec
	if !ctx.cr[0].lt {
	pc = 0x8315C8EC; continue 'dispatch;
	}
	// 8315C900: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315C904: 91667F94  stw r11, 0x7f94(r6)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[6].u32.wrapping_add(32660 as u32), ctx.r[11].u32 ) };
	// 8315C908: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C910(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315C910 size=168
    let mut pc: u32 = 0x8315C910;
    'dispatch: loop {
        match pc {
            0x8315C910 => {
    //   block [0x8315C910..0x8315C9B8)
	// 8315C910: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C914: 4804B855  bl 0x831a8168
	ctx.lr = 0x8315C918;
	sub_831A8130(ctx, base);
	// 8315C918: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315C91C: 39650001  addi r11, r5, 1
	ctx.r[11].s64 = ctx.r[5].s64 + 1;
	// 8315C920: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315C924: 557D103A  slwi r29, r11, 2
	ctx.r[29].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[29].u64 = ctx.r[29].u32 as u64;
	// 8315C928: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315C92C: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 8315C930: 546A06FE  clrlwi r10, r3, 0x1b
	ctx.r[10].u64 = ctx.r[3].u32 as u64 & 0x0000001Fu64;
	// 8315C934: 7D7DF82E  lwzx r11, r29, r31
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 8315C938: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315C93C: 392BFFC0  addi r9, r11, -0x40
	ctx.r[9].s64 = ctx.r[11].s64 + -64;
	// 8315C940: 552B05BE  clrlwi r11, r9, 0x16
	ctx.r[11].u64 = ctx.r[9].u32 as u64 & 0x000003FFu64;
	// 8315C944: 7D7DF92E  stwx r11, r29, r31
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32), ctx.r[11].u32) };
	// 8315C948: 809F000C  lwz r4, 0xc(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315C94C: 409A0068  bne cr6, 0x8315c9b4
	if !ctx.cr[6].eq {
	pc = 0x8315C9B4; continue 'dispatch;
	}
	// 8315C950: 548A06FE  clrlwi r10, r4, 0x1b
	ctx.r[10].u64 = ctx.r[4].u32 as u64 & 0x0000001Fu64;
	// 8315C954: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315C958: 409A005C  bne cr6, 0x8315c9b4
	if !ctx.cr[6].eq {
	pc = 0x8315C9B4; continue 'dispatch;
	}
	// 8315C95C: 54BE502A  slwi r30, r5, 0xa
	ctx.r[30].u32 = ctx.r[5].u32.wrapping_shl(10);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8315C960: 7D7E5A14  add r11, r30, r11
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8315C964: 396B0005  addi r11, r11, 5
	ctx.r[11].s64 = ctx.r[11].s64 + 5;
	// 8315C968: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315C96C: 7CABFA14  add r5, r11, r31
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 8315C970: 4BFFDF39  bl 0x8315a8a8
	ctx.lr = 0x8315C974;
	sub_8315A8A8(ctx, base);
	// 8315C974: 7D7DF82E  lwzx r11, r29, r31
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[29].u32.wrapping_add(ctx.r[31].u32)) } as u64;
	// 8315C978: 3D408334  lis r10, -0x7ccc
	ctx.r[10].s64 = -2093744128;
	// 8315C97C: 809F0010  lwz r4, 0x10(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315C980: 7D693670  srawi r9, r11, 6
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 6) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[11].s32 >> 6) as i64;
	// 8315C984: 7D7E5A14  add r11, r30, r11
	ctx.r[11].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8315C988: 390A61B8  addi r8, r10, 0x61b8
	ctx.r[8].s64 = ctx.r[10].s64 + 25016;
	// 8315C98C: 38CB0005  addi r6, r11, 5
	ctx.r[6].s64 = ctx.r[11].s64 + 5;
	// 8315C990: 5527103A  slwi r7, r9, 2
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315C994: 54CB103A  slwi r11, r6, 2
	ctx.r[11].u32 = ctx.r[6].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315C998: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8315C99C: 7C6BFA14  add r3, r11, r31
	ctx.r[3].u64 = ctx.r[11].u64 + ctx.r[31].u64;
	// 8315C9A0: 7D67402E  lwzx r11, r7, r8
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[7].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 8315C9A4: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315C9A8: 4E800421  bctrl
	ctx.lr = 0x8315C9AC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315C9AC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315C9B0: 4804B808  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315C9B4: 48000000  b 0x8315c9b4
	pc = 0x8315C9B4; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C9B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315C9B8 size=12
    let mut pc: u32 = 0x8315C9B8;
    'dispatch: loop {
        match pc {
            0x8315C9B8 => {
    //   block [0x8315C9B8..0x8315C9C4)
	// 8315C9B8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315C9BC: 988B034B  stb r4, 0x34b(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(843 as u32), ctx.r[4].u8 ) };
	// 8315C9C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315C9C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315C9C8 size=612
    let mut pc: u32 = 0x8315C9C8;
    'dispatch: loop {
        match pc {
            0x8315C9C8 => {
    //   block [0x8315C9C8..0x8315CC2C)
	// 8315C9C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315C9CC: 4804B7A1  bl 0x831a816c
	ctx.lr = 0x8315C9D0;
	sub_831A8130(ctx, base);
	// 8315C9D0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315C9D4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315C9D8: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315C9DC: 815F0024  lwz r10, 0x24(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315C9E0: 212B0020  subfic r9, r11, 0x20
	ctx.xer.ca = ctx.r[11].u32 <= 32 as u32;
	ctx.r[9].s64 = (32 as i64) - ctx.r[11].s64;
	// 8315C9E4: 2F0A0004  cmpwi cr6, r10, 4
	ctx.cr[6].compare_i32(ctx.r[10].s32, 4, &mut ctx.xer);
	// 8315C9E8: 7D281E70  srawi r8, r9, 3
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[9].s32 >> 3) as i64;
	// 8315C9EC: 7FA80194  addze r29, r8
	tmp.s64 = ctx.r[8].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[8].u32);
	ctx.r[29].s64 = tmp.s64;
	// 8315C9F0: 409800BC  bge cr6, 0x8315caac
	if !ctx.cr[6].lt {
	pc = 0x8315CAAC; continue 'dispatch;
	}
	// 8315C9F4: E97F001C  ld r11, 0x1c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) };
	// 8315C9F8: 3BDF001C  addi r30, r31, 0x1c
	ctx.r[30].s64 = ctx.r[31].s64 + 28;
	// 8315C9FC: F9610050  std r11, 0x50(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[11].u64 ) };
	// 8315CA00: 81610054  lwz r11, 0x54(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8315CA04: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315CA08: 419A0074  beq cr6, 0x8315ca7c
	if ctx.cr[6].eq {
	pc = 0x8315CA7C; continue 'dispatch;
	}
	// 8315CA0C: 7D4A5850  subf r10, r10, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[10].s64;
	// 8315CA10: 7D695B78  mr r9, r11
	ctx.r[9].u64 = ctx.r[11].u64;
	// 8315CA14: 7F0B5000  cmpw cr6, r11, r10
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315CA18: 4099000C  ble cr6, 0x8315ca24
	if !ctx.cr[6].gt {
	pc = 0x8315CA24; continue 'dispatch;
	}
	// 8315CA1C: 7D4B5378  mr r11, r10
	ctx.r[11].u64 = ctx.r[10].u64;
	// 8315CA20: 91610054  stw r11, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[11].u32 ) };
	// 8315CA24: 7D4B4851  subf. r10, r11, r9
	ctx.r[10].s64 = ctx.r[9].s64 - ctx.r[11].s64;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315CA28: 9141005C  stw r10, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[10].u32 ) };
	// 8315CA2C: 4082000C  bne 0x8315ca38
	if !ctx.cr[0].eq {
	pc = 0x8315CA38; continue 'dispatch;
	}
	// 8315CA30: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315CA34: 4800000C  b 0x8315ca40
	pc = 0x8315CA40; continue 'dispatch;
	// 8315CA38: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315CA3C: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8315CA40: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315CA44: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315CA48: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8315CA4C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CA50: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CA54: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315CA58: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315CA5C: 4E800421  bctrl
	ctx.lr = 0x8315CA60;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315CA60: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315CA64: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8315CA68: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315CA6C: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CA70: 8109001C  lwz r8, 0x1c(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315CA74: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 8315CA78: 4E800421  bctrl
	ctx.lr = 0x8315CA7C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315CA7C: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315CA80: 7FC6F378  mr r6, r30
	ctx.r[6].u64 = ctx.r[30].u64;
	// 8315CA84: 80BF0018  lwz r5, 0x18(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315CA88: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315CA8C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CA90: 814B0018  lwz r10, 0x18(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315CA94: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315CA98: 4E800421  bctrl
	ctx.lr = 0x8315CA9C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315CA9C: 813E0000  lwz r9, 0(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CAA0: 811F0020  lwz r8, 0x20(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315CAA4: 913F0028  stw r9, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[9].u32 ) };
	// 8315CAA8: 911F0024  stw r8, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[8].u32 ) };
	// 8315CAAC: 817F0024  lwz r11, 0x24(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315CAB0: 7F1D5800  cmpw cr6, r29, r11
	ctx.cr[6].compare_i32(ctx.r[29].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315CAB4: 41980008  blt cr6, 0x8315cabc
	if ctx.cr[6].lt {
	pc = 0x8315CABC; continue 'dispatch;
	}
	// 8315CAB8: 7D7D5B78  mr r29, r11
	ctx.r[29].u64 = ctx.r[11].u64;
	// 8315CABC: 2F1D0003  cmpwi cr6, r29, 3
	ctx.cr[6].compare_i32(ctx.r[29].s32, 3, &mut ctx.xer);
	// 8315CAC0: 409A0060  bne cr6, 0x8315cb20
	if !ctx.cr[6].eq {
	pc = 0x8315CB20; continue 'dispatch;
	}
	// 8315CAC4: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CAC8: 392BFFFD  addi r9, r11, -3
	ctx.r[9].s64 = ctx.r[11].s64 + -3;
	// 8315CACC: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CAD0: 38EA0018  addi r7, r10, 0x18
	ctx.r[7].s64 = ctx.r[10].s64 + 24;
	// 8315CAD4: 815F0028  lwz r10, 0x28(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315CAD8: 5506402E  slwi r6, r8, 8
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315CADC: 396A0001  addi r11, r10, 1
	ctx.r[11].s64 = ctx.r[10].s64 + 1;
	// 8315CAE0: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315CAE4: 88AA0000  lbz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CAE8: 888A0001  lbz r4, 1(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315CAEC: 386B0001  addi r3, r11, 1
	ctx.r[3].s64 = ctx.r[11].s64 + 1;
	// 8315CAF0: 7CCA2B78  or r10, r6, r5
	ctx.r[10].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8315CAF4: 5548402E  slwi r8, r10, 8
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(8);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315CAF8: 88CB0000  lbz r6, 0(r11)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CAFC: 907F0028  stw r3, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[3].u32 ) };
	// 8315CB00: 7D052378  or r5, r8, r4
	ctx.r[5].u64 = ctx.r[8].u64 | ctx.r[4].u64;
	// 8315CB04: 913F0024  stw r9, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 8315CB08: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 8315CB0C: 54A4402E  slwi r4, r5, 8
	ctx.r[4].u32 = ctx.r[5].u32.wrapping_shl(8);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8315CB10: 7C833378  or r3, r4, r6
	ctx.r[3].u64 = ctx.r[4].u64 | ctx.r[6].u64;
	// 8315CB14: 907F0008  stw r3, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 8315CB18: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CB1C: 4804B6A0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315CB20: 2F1D0002  cmpwi cr6, r29, 2
	ctx.cr[6].compare_i32(ctx.r[29].s32, 2, &mut ctx.xer);
	// 8315CB24: 409A0050  bne cr6, 0x8315cb74
	if !ctx.cr[6].eq {
	pc = 0x8315CB74; continue 'dispatch;
	}
	// 8315CB28: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CB2C: 392BFFFE  addi r9, r11, -2
	ctx.r[9].s64 = ctx.r[11].s64 + -2;
	// 8315CB30: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CB34: 38EA0010  addi r7, r10, 0x10
	ctx.r[7].s64 = ctx.r[10].s64 + 16;
	// 8315CB38: 815F0028  lwz r10, 0x28(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315CB3C: 5506402E  slwi r6, r8, 8
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315CB40: 396A0001  addi r11, r10, 1
	ctx.r[11].s64 = ctx.r[10].s64 + 1;
	// 8315CB44: 38AB0001  addi r5, r11, 1
	ctx.r[5].s64 = ctx.r[11].s64 + 1;
	// 8315CB48: 888A0000  lbz r4, 0(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CB4C: 886A0001  lbz r3, 1(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315CB50: 7CCB2378  or r11, r6, r4
	ctx.r[11].u64 = ctx.r[6].u64 | ctx.r[4].u64;
	// 8315CB54: 913F0024  stw r9, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 8315CB58: 90BF0028  stw r5, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[5].u32 ) };
	// 8315CB5C: 556A402E  slwi r10, r11, 8
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(8);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315CB60: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 8315CB64: 7D491B78  or r9, r10, r3
	ctx.r[9].u64 = ctx.r[10].u64 | ctx.r[3].u64;
	// 8315CB68: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8315CB6C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CB70: 4804B64C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315CB74: 2F1D0001  cmpwi cr6, r29, 1
	ctx.cr[6].compare_i32(ctx.r[29].s32, 1, &mut ctx.xer);
	// 8315CB78: 409A0040  bne cr6, 0x8315cbb8
	if !ctx.cr[6].eq {
	pc = 0x8315CBB8; continue 'dispatch;
	}
	// 8315CB7C: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 8315CB80: 817F0028  lwz r11, 0x28(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315CB84: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CB88: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CB8C: 38EB0001  addi r7, r11, 1
	ctx.r[7].s64 = ctx.r[11].s64 + 1;
	// 8315CB90: 5506402E  slwi r6, r8, 8
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315CB94: 38AA0008  addi r5, r10, 8
	ctx.r[5].s64 = ctx.r[10].s64 + 8;
	// 8315CB98: 888B0000  lbz r4, 0(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CB9C: 90FF0028  stw r7, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[7].u32 ) };
	// 8315CBA0: 7CC32378  or r3, r6, r4
	ctx.r[3].u64 = ctx.r[6].u64 | ctx.r[4].u64;
	// 8315CBA4: 90BF000C  stw r5, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 8315CBA8: 913F0024  stw r9, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 8315CBAC: 907F0008  stw r3, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 8315CBB0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CBB4: 4804B608  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315CBB8: 2F1D0004  cmpwi cr6, r29, 4
	ctx.cr[6].compare_i32(ctx.r[29].s32, 4, &mut ctx.xer);
	// 8315CBBC: 409A0068  bne cr6, 0x8315cc24
	if !ctx.cr[6].eq {
	pc = 0x8315CC24; continue 'dispatch;
	}
	// 8315CBC0: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CBC4: 392BFFFC  addi r9, r11, -4
	ctx.r[9].s64 = ctx.r[11].s64 + -4;
	// 8315CBC8: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CBCC: 38EA0020  addi r7, r10, 0x20
	ctx.r[7].s64 = ctx.r[10].s64 + 32;
	// 8315CBD0: 815F0028  lwz r10, 0x28(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315CBD4: 5506402E  slwi r6, r8, 8
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(8);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315CBD8: 396A0001  addi r11, r10, 1
	ctx.r[11].s64 = ctx.r[10].s64 + 1;
	// 8315CBDC: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315CBE0: 88AA0000  lbz r5, 0(r10)
	ctx.r[5].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CBE4: 888A0001  lbz r4, 1(r10)
	ctx.r[4].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315CBE8: 7CC32B78  or r3, r6, r5
	ctx.r[3].u64 = ctx.r[6].u64 | ctx.r[5].u64;
	// 8315CBEC: 546A402E  slwi r10, r3, 8
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(8);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315CBF0: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CBF4: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315CBF8: 7D462378  or r6, r10, r4
	ctx.r[6].u64 = ctx.r[10].u64 | ctx.r[4].u64;
	// 8315CBFC: 38AB0001  addi r5, r11, 1
	ctx.r[5].s64 = ctx.r[11].s64 + 1;
	// 8315CC00: 54C4402E  slwi r4, r6, 8
	ctx.r[4].u32 = ctx.r[6].u32.wrapping_shl(8);
	ctx.r[4].u64 = ctx.r[4].u32 as u64;
	// 8315CC04: 7C834378  or r3, r4, r8
	ctx.r[3].u64 = ctx.r[4].u64 | ctx.r[8].u64;
	// 8315CC08: 896B0000  lbz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CC0C: 913F0024  stw r9, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[9].u32 ) };
	// 8315CC10: 546A402E  slwi r10, r3, 8
	ctx.r[10].u32 = ctx.r[3].u32.wrapping_shl(8);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315CC14: 90BF0028  stw r5, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[5].u32 ) };
	// 8315CC18: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 8315CC1C: 7D495B78  or r9, r10, r11
	ctx.r[9].u64 = ctx.r[10].u64 | ctx.r[11].u64;
	// 8315CC20: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8315CC24: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CC28: 4804B594  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CC30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315CC30 size=88
    let mut pc: u32 = 0x8315CC30;
    'dispatch: loop {
        match pc {
            0x8315CC30 => {
    //   block [0x8315CC30..0x8315CC88)
	// 8315CC30: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CC34: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315CC38: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315CC3C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315CC40: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CC44: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CC48: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315CC4C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CC50: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315CC54: 40980008  bge cr6, 0x8315cc5c
	if !ctx.cr[6].lt {
	pc = 0x8315CC5C; continue 'dispatch;
	}
	// 8315CC58: 4BFFFD71  bl 0x8315c9c8
	ctx.lr = 0x8315CC5C;
	sub_8315C9C8(ctx, base);
	// 8315CC5C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CC60: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315CC64: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315CC68: 41990008  bgt cr6, 0x8315cc70
	if ctx.cr[6].gt {
	pc = 0x8315CC70; continue 'dispatch;
	}
	// 8315CC6C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315CC70: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315CC74: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315CC78: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315CC7C: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315CC80: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315CC84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CC88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315CC88 size=156
    let mut pc: u32 = 0x8315CC88;
    'dispatch: loop {
        match pc {
            0x8315CC88 => {
    //   block [0x8315CC88..0x8315CD24)
	// 8315CC88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CC8C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315CC90: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315CC94: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315CC98: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CC9C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CCA0: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315CCA4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CCA8: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315CCAC: 40980008  bge cr6, 0x8315ccb4
	if !ctx.cr[6].lt {
	pc = 0x8315CCB4; continue 'dispatch;
	}
	// 8315CCB0: 4BFFFD19  bl 0x8315c9c8
	ctx.lr = 0x8315CCB4;
	sub_8315C9C8(ctx, base);
	// 8315CCB4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CCB8: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315CCBC: 40990020  ble cr6, 0x8315ccdc
	if !ctx.cr[6].gt {
	pc = 0x8315CCDC; continue 'dispatch;
	}
	// 8315CCC0: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315CCC4: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8315CCC8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315CCCC: 7D0A5A14  add r8, r10, r11
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8315CCD0: 913F000C  stw r9, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[9].u32 ) };
	// 8315CCD4: 911F0010  stw r8, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[8].u32 ) };
	// 8315CCD8: 48000034  b 0x8315cd0c
	pc = 0x8315CD0C; continue 'dispatch;
	// 8315CCDC: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 8315CCE0: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CCE4: 57C8103A  slwi r8, r30, 2
	ctx.r[8].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315CCE8: 38EA5CF8  addi r7, r10, 0x5cf8
	ctx.r[7].s64 = ctx.r[10].s64 + 23800;
	// 8315CCEC: 7CDE5850  subf r6, r30, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 8315CCF0: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315CCF4: 7D253630  sraw r5, r9, r6
	tmp.u32 = ctx.r[6].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[5].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8315CCF8: 7C88382E  lwzx r4, r8, r7
	ctx.r[4].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[8].u32.wrapping_add(ctx.r[7].u32)) } as u64;
	// 8315CCFC: 7D6BF214  add r11, r11, r30
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8315CD00: 90DF000C  stw r6, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[6].u32 ) };
	// 8315CD04: 7CA32038  and r3, r5, r4
	ctx.r[3].u64 = ctx.r[5].u64 & ctx.r[4].u64;
	// 8315CD08: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315CD0C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315CD10: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315CD14: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315CD18: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315CD1C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315CD20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CD28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315CD28 size=280
    let mut pc: u32 = 0x8315CD28;
    'dispatch: loop {
        match pc {
            0x8315CD28 => {
    //   block [0x8315CD28..0x8315CE40)
	// 8315CD28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CD2C: 4804B43D  bl 0x831a8168
	ctx.lr = 0x8315CD30;
	sub_831A8130(ctx, base);
	// 8315CD30: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CD34: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CD38: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315CD3C: 556B077E  clrlwi r11, r11, 0x1d
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x00000007u64;
	// 8315CD40: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315CD44: 419A000C  beq cr6, 0x8315cd50
	if ctx.cr[6].eq {
	pc = 0x8315CD50; continue 'dispatch;
	}
	// 8315CD48: 208B0008  subfic r4, r11, 8
	ctx.xer.ca = ctx.r[11].u32 <= 8 as u32;
	ctx.r[4].s64 = (8 as i64) - ctx.r[11].s64;
	// 8315CD4C: 4BFFFF3D  bl 0x8315cc88
	ctx.lr = 0x8315CD50;
	sub_8315CC88(ctx, base);
	// 8315CD50: 3880000C  li r4, 0xc
	ctx.r[4].s64 = 12;
	// 8315CD54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315CD58: 4BFFFF31  bl 0x8315cc88
	ctx.lr = 0x8315CD5C;
	sub_8315CC88(ctx, base);
	// 8315CD5C: 3D608001  lis r11, -0x7fff
	ctx.r[11].s64 = -2147418112;
	// 8315CD60: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315CD64: 3BA00000  li r29, 0
	ctx.r[29].s64 = 0;
	// 8315CD68: 617C000C  ori r28, r11, 0xc
	ctx.r[28].u64 = ctx.r[11].u64 | 12;
	// 8315CD6C: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315CD70: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315CD74: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CD78: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315CD7C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315CD80: 4E800421  bctrl
	ctx.lr = 0x8315CD84;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315CD84: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315CD88: 409A001C  bne cr6, 0x8315cda4
	if !ctx.cr[6].eq {
	pc = 0x8315CDA4; continue 'dispatch;
	}
	// 8315CD8C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CD90: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315CD94: 409A0010  bne cr6, 0x8315cda4
	if !ctx.cr[6].eq {
	pc = 0x8315CDA4; continue 'dispatch;
	}
	// 8315CD98: 817F0024  lwz r11, 0x24(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315CD9C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315CDA0: 419A0094  beq cr6, 0x8315ce34
	if ctx.cr[6].eq {
	pc = 0x8315CE34; continue 'dispatch;
	}
	// 8315CDA4: 57CB053E  clrlwi r11, r30, 0x14
	ctx.r[11].u64 = ctx.r[30].u32 as u64 & 0x00000FFFu64;
	// 8315CDA8: 2B0B0FFF  cmplwi cr6, r11, 0xfff
	ctx.cr[6].compare_u32(ctx.r[11].u32, 4095 as u32, &mut ctx.xer);
	// 8315CDAC: 419A0070  beq cr6, 0x8315ce1c
	if ctx.cr[6].eq {
	pc = 0x8315CE1C; continue 'dispatch;
	}
	// 8315CDB0: 7F1EE040  cmplw cr6, r30, r28
	ctx.cr[6].compare_u32(ctx.r[30].u32, ctx.r[28].u32, &mut ctx.xer);
	// 8315CDB4: 419A0074  beq cr6, 0x8315ce28
	if ctx.cr[6].eq {
	pc = 0x8315CE28; continue 'dispatch;
	}
	// 8315CDB8: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CDBC: 57DE2036  slwi r30, r30, 4
	ctx.r[30].u32 = ctx.r[30].u32.wrapping_shl(4);
	ctx.r[30].u64 = ctx.r[30].u32 as u64;
	// 8315CDC0: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 8315CDC4: 4098000C  bge cr6, 0x8315cdd0
	if !ctx.cr[6].lt {
	pc = 0x8315CDD0; continue 'dispatch;
	}
	// 8315CDC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315CDCC: 4BFFFBFD  bl 0x8315c9c8
	ctx.lr = 0x8315CDD0;
	sub_8315C9C8(ctx, base);
	// 8315CDD0: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315CDD4: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315CDD8: 2F0B0004  cmpwi cr6, r11, 4
	ctx.cr[6].compare_i32(ctx.r[11].s32, 4, &mut ctx.xer);
	// 8315CDDC: 4098001C  bge cr6, 0x8315cdf8
	if !ctx.cr[6].lt {
	pc = 0x8315CDF8; continue 'dispatch;
	}
	// 8315CDE0: 7FAAEB78  mr r10, r29
	ctx.r[10].u64 = ctx.r[29].u64;
	// 8315CDE4: 93BF000C  stw r29, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[29].u32 ) };
	// 8315CDE8: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315CDEC: 7D5EF378  or r30, r10, r30
	ctx.r[30].u64 = ctx.r[10].u64 | ctx.r[30].u64;
	// 8315CDF0: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315CDF4: 4BFFFF78  b 0x8315cd6c
	pc = 0x8315CD6C; continue 'dispatch;
	// 8315CDF8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315CDFC: 396BFFFC  addi r11, r11, -4
	ctx.r[11].s64 = ctx.r[11].s64 + -4;
	// 8315CE00: 38E90004  addi r7, r9, 4
	ctx.r[7].s64 = ctx.r[9].s64 + 4;
	// 8315CE04: 7D485E30  sraw r8, r10, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[10].s32 >> tmp.u32) as i64;
	// 8315CE08: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315CE0C: 550A073E  clrlwi r10, r8, 0x1c
	ctx.r[10].u64 = ctx.r[8].u32 as u64 & 0x0000000Fu64;
	// 8315CE10: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315CE14: 7D5EF378  or r30, r10, r30
	ctx.r[30].u64 = ctx.r[10].u64 | ctx.r[30].u64;
	// 8315CE18: 4BFFFF54  b 0x8315cd6c
	pc = 0x8315CD6C; continue 'dispatch;
	// 8315CE1C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315CE20: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CE24: 4804B394  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315CE28: 38600002  li r3, 2
	ctx.r[3].s64 = 2;
	// 8315CE2C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CE30: 4804B388  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315CE34: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315CE38: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315CE3C: 4804B37C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CE40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315CE40 size=200
    let mut pc: u32 = 0x8315CE40;
    'dispatch: loop {
        match pc {
            0x8315CE40 => {
    //   block [0x8315CE40..0x8315CF08)
	// 8315CE40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CE44: 4804B329  bl 0x831a816c
	ctx.lr = 0x8315CE48;
	sub_831A8130(ctx, base);
	// 8315CE48: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CE4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CE50: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315CE54: 397F0007  addi r11, r31, 7
	ctx.r[11].s64 = ctx.r[31].s64 + 7;
	// 8315CE58: 38A00BCC  li r5, 0xbcc
	ctx.r[5].s64 = 3020;
	// 8315CE5C: 557E0038  rlwinm r30, r11, 0, 0, 0x1c
	ctx.r[30].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8315CE60: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CE64: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315CE68: 4804B379  bl 0x831a81e0
	ctx.lr = 0x8315CE6C;
	sub_831A81E0(ctx, base);
	// 8315CE6C: 395E0BD3  addi r10, r30, 0xbd3
	ctx.r[10].s64 = ctx.r[30].s64 + 3027;
	// 8315CE70: 555E0038  rlwinm r30, r10, 0, 0, 0x1c
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 8315CE74: 393E101C  addi r9, r30, 0x101c
	ctx.r[9].s64 = ctx.r[30].s64 + 4124;
	// 8315CE78: 7F09E840  cmplw cr6, r9, r29
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8315CE7C: 40980010  bge cr6, 0x8315ce8c
	if !ctx.cr[6].lt {
	pc = 0x8315CE8C; continue 'dispatch;
	}
	// 8315CE80: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315CE84: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315CE88: 4804B334  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315CE8C: 38A0101C  li r5, 0x101c
	ctx.r[5].s64 = 4124;
	// 8315CE90: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CE94: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315CE98: 4804B349  bl 0x831a81e0
	ctx.lr = 0x8315CE9C;
	sub_831A81E0(ctx, base);
	// 8315CE9C: 3D008339  lis r8, -0x7cc7
	ctx.r[8].s64 = -2093416448;
	// 8315CEA0: 39600040  li r11, 0x40
	ctx.r[11].s64 = 64;
	// 8315CEA4: 3CE08339  lis r7, -0x7cc7
	ctx.r[7].s64 = -2093416448;
	// 8315CEA8: 38DF0023  addi r6, r31, 0x23
	ctx.r[6].s64 = ctx.r[31].s64 + 35;
	// 8315CEAC: 917E0008  stw r11, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8315CEB0: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315CEB4: 39200001  li r9, 1
	ctx.r[9].s64 = 1;
	// 8315CEB8: 54C50034  rlwinm r5, r6, 0, 0, 0x1a
	ctx.r[5].u64 = ctx.r[6].u32 as u64 & 0xFFFFFFFFu64;
	// 8315CEBC: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315CEC0: 3C808339  lis r4, -0x7cc7
	ctx.r[4].s64 = -2093416448;
	// 8315CEC4: 38C00010  li r6, 0x10
	ctx.r[6].s64 = 16;
	// 8315CEC8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315CECC: 81687F8C  lwz r11, 0x7f8c(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(32652 as u32) ) } as u64;
	// 8315CED0: 917E0010  stw r11, 0x10(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315CED4: 81677F88  lwz r11, 0x7f88(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(32648 as u32) ) } as u64;
	// 8315CED8: 993E0000  stb r9, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 8315CEDC: 917E000C  stw r11, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315CEE0: 93DF0354  stw r30, 0x354(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(852 as u32), ctx.r[30].u32 ) };
	// 8315CEE4: 90BF0000  stw r5, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[5].u32 ) };
	// 8315CEE8: 915F0388  stw r10, 0x388(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(904 as u32), ctx.r[10].u32 ) };
	// 8315CEEC: 915F038C  stw r10, 0x38c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(908 as u32), ctx.r[10].u32 ) };
	// 8315CEF0: 81647F80  lwz r11, 0x7f80(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(32640 as u32) ) } as u64;
	// 8315CEF4: 98DF034B  stb r6, 0x34b(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(843 as u32), ctx.r[6].u8 ) };
	// 8315CEF8: 993F0348  stb r9, 0x348(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(840 as u32), ctx.r[9].u8 ) };
	// 8315CEFC: 917F0344  stw r11, 0x344(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(836 as u32), ctx.r[11].u32 ) };
	// 8315CF00: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315CF04: 4804B2B8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CF08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315CF08 size=88
    let mut pc: u32 = 0x8315CF08;
    'dispatch: loop {
        match pc {
            0x8315CF08 => {
    //   block [0x8315CF08..0x8315CF60)
	// 8315CF08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CF0C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315CF10: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315CF14: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CF18: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CF1C: 807F0354  lwz r3, 0x354(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(852 as u32) ) } as u64;
	// 8315CF20: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315CF24: 419A0018  beq cr6, 0x8315cf3c
	if ctx.cr[6].eq {
	pc = 0x8315CF3C; continue 'dispatch;
	}
	// 8315CF28: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315CF2C: 38A01014  li r5, 0x1014
	ctx.r[5].s64 = 4116;
	// 8315CF30: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CF34: 917F0354  stw r11, 0x354(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(852 as u32), ctx.r[11].u32 ) };
	// 8315CF38: 4804B2A9  bl 0x831a81e0
	ctx.lr = 0x8315CF3C;
	sub_831A81E0(ctx, base);
	// 8315CF3C: 38A00BCC  li r5, 0xbcc
	ctx.r[5].s64 = 3020;
	// 8315CF40: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CF44: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315CF48: 4804B299  bl 0x831a81e0
	ctx.lr = 0x8315CF4C;
	sub_831A81E0(ctx, base);
	// 8315CF4C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315CF50: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315CF54: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315CF58: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315CF5C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315CF60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315CF60 size=268
    let mut pc: u32 = 0x8315CF60;
    'dispatch: loop {
        match pc {
            0x8315CF60 => {
    //   block [0x8315CF60..0x8315D06C)
	// 8315CF60: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315CF64: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315CF68: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315CF6C: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315CF70: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315CF74: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315CF78: 38A00030  li r5, 0x30
	ctx.r[5].s64 = 48;
	// 8315CF7C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CF80: 387F0358  addi r3, r31, 0x358
	ctx.r[3].s64 = ctx.r[31].s64 + 856;
	// 8315CF84: 83DF0354  lwz r30, 0x354(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(852 as u32) ) } as u64;
	// 8315CF88: 4804B259  bl 0x831a81e0
	ctx.lr = 0x8315CF8C;
	sub_831A81E0(ctx, base);
	// 8315CF8C: 38A0003C  li r5, 0x3c
	ctx.r[5].s64 = 60;
	// 8315CF90: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CF94: 387F0388  addi r3, r31, 0x388
	ctx.r[3].s64 = ctx.r[31].s64 + 904;
	// 8315CF98: 4804B249  bl 0x831a81e0
	ctx.lr = 0x8315CF9C;
	sub_831A81E0(ctx, base);
	// 8315CF9C: 38A00100  li r5, 0x100
	ctx.r[5].s64 = 256;
	// 8315CFA0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CFA4: 387F03C4  addi r3, r31, 0x3c4
	ctx.r[3].s64 = ctx.r[31].s64 + 964;
	// 8315CFA8: 4804B239  bl 0x831a81e0
	ctx.lr = 0x8315CFAC;
	sub_831A81E0(ctx, base);
	// 8315CFAC: 38A00100  li r5, 0x100
	ctx.r[5].s64 = 256;
	// 8315CFB0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CFB4: 387F04C4  addi r3, r31, 0x4c4
	ctx.r[3].s64 = ctx.r[31].s64 + 1220;
	// 8315CFB8: 4804B229  bl 0x831a81e0
	ctx.lr = 0x8315CFBC;
	sub_831A81E0(ctx, base);
	// 8315CFBC: 38A00300  li r5, 0x300
	ctx.r[5].s64 = 768;
	// 8315CFC0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CFC4: 387F05C4  addi r3, r31, 0x5c4
	ctx.r[3].s64 = ctx.r[31].s64 + 1476;
	// 8315CFC8: 4804B219  bl 0x831a81e0
	ctx.lr = 0x8315CFCC;
	sub_831A81E0(ctx, base);
	// 8315CFCC: 38A00300  li r5, 0x300
	ctx.r[5].s64 = 768;
	// 8315CFD0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CFD4: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315CFD8: 4804B209  bl 0x831a81e0
	ctx.lr = 0x8315CFDC;
	sub_831A81E0(ctx, base);
	// 8315CFDC: 38A00300  li r5, 0x300
	ctx.r[5].s64 = 768;
	// 8315CFE0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315CFE4: 387F08C4  addi r3, r31, 0x8c4
	ctx.r[3].s64 = ctx.r[31].s64 + 2244;
	// 8315CFE8: 4804B1F9  bl 0x831a81e0
	ctx.lr = 0x8315CFEC;
	sub_831A81E0(ctx, base);
	// 8315CFEC: 807F0354  lwz r3, 0x354(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(852 as u32) ) } as u64;
	// 8315CFF0: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315CFF4: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315CFF8: 997F0349  stb r11, 0x349(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(841 as u32), ctx.r[11].u8 ) };
	// 8315CFFC: 917F034C  stw r11, 0x34c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(844 as u32), ctx.r[11].u32 ) };
	// 8315D000: 419A0054  beq cr6, 0x8315d054
	if ctx.cr[6].eq {
	pc = 0x8315D054; continue 'dispatch;
	}
	// 8315D004: 38A01014  li r5, 0x1014
	ctx.r[5].s64 = 4116;
	// 8315D008: 917F0354  stw r11, 0x354(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(852 as u32), ctx.r[11].u32 ) };
	// 8315D00C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315D010: 4804B1D1  bl 0x831a81e0
	ctx.lr = 0x8315D014;
	sub_831A81E0(ctx, base);
	// 8315D014: 38A0101C  li r5, 0x101c
	ctx.r[5].s64 = 4124;
	// 8315D018: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315D01C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D020: 4804B1C1  bl 0x831a81e0
	ctx.lr = 0x8315D024;
	sub_831A81E0(ctx, base);
	// 8315D024: 3D408339  lis r10, -0x7cc7
	ctx.r[10].s64 = -2093416448;
	// 8315D028: 39600040  li r11, 0x40
	ctx.r[11].s64 = 64;
	// 8315D02C: 3D208339  lis r9, -0x7cc7
	ctx.r[9].s64 = -2093416448;
	// 8315D030: 917E0008  stw r11, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8315D034: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 8315D038: 917E0004  stw r11, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315D03C: 816A7F8C  lwz r11, 0x7f8c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32652 as u32) ) } as u64;
	// 8315D040: 917E0010  stw r11, 0x10(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D044: 81697F88  lwz r11, 0x7f88(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(32648 as u32) ) } as u64;
	// 8315D048: 991E0000  stb r8, 0(r30)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8315D04C: 917E000C  stw r11, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D050: 93DF0354  stw r30, 0x354(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(852 as u32), ctx.r[30].u32 ) };
	// 8315D054: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315D058: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315D05C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315D060: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315D064: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315D068: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315D070(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315D070 size=348
    let mut pc: u32 = 0x8315D070;
    'dispatch: loop {
        match pc {
            0x8315D070 => {
    //   block [0x8315D070..0x8315D1CC)
	// 8315D070: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315D074: 4804B0ED  bl 0x831a8160
	ctx.lr = 0x8315D078;
	sub_831A8130(ctx, base);
	// 8315D078: 9421FF20  stwu r1, -0xe0(r1)
	ea = ctx.r[1].u32.wrapping_add(-224 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315D07C: 83830350  lwz r28, 0x350(r3)
	ctx.r[28].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315D080: 3B630388  addi r27, r3, 0x388
	ctx.r[27].s64 = ctx.r[3].s64 + 904;
	// 8315D084: 2B1C0000  cmplwi cr6, r28, 0
	ctx.cr[6].compare_u32(ctx.r[28].u32, 0 as u32, &mut ctx.xer);
	// 8315D088: 419A013C  beq cr6, 0x8315d1c4
	if ctx.cr[6].eq {
	pc = 0x8315D1C4; continue 'dispatch;
	}
	// 8315D08C: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8315D090: 39610060  addi r11, r1, 0x60
	ctx.r[11].s64 = ctx.r[1].s64 + 96;
	// 8315D094: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D098: 39200008  li r9, 8
	ctx.r[9].s64 = 8;
	// 8315D09C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315D0A0: F94B0000  std r10, 0(r11)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[10].u64 ) };
	// 8315D0A4: 396B0008  addi r11, r11, 8
	ctx.r[11].s64 = ctx.r[11].s64 + 8;
	// 8315D0A8: 4200FFF8  bdnz 0x8315d0a0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315D0A0; continue 'dispatch;
	}
	// 8315D0AC: 3D608339  lis r11, -0x7cc7
	ctx.r[11].s64 = -2093416448;
	// 8315D0B0: 3BCB7FA0  addi r30, r11, 0x7fa0
	ctx.r[30].s64 = ctx.r[11].s64 + 32672;
	// 8315D0B4: 7FDFF378  mr r31, r30
	ctx.r[31].u64 = ctx.r[30].u64;
	// 8315D0B8: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 8315D0BC: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315D0C0: 4BFFFBC9  bl 0x8315cc88
	ctx.lr = 0x8315D0C4;
	sub_8315CC88(ctx, base);
	// 8315D0C4: 987F0000  stb r3, 0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[3].u8 ) };
	// 8315D0C8: 395E0004  addi r10, r30, 4
	ctx.r[10].s64 = ctx.r[30].s64 + 4;
	// 8315D0CC: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 8315D0D0: 7F1F5040  cmplw cr6, r31, r10
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8315D0D4: 409AFFE4  bne cr6, 0x8315d0b8
	if !ctx.cr[6].eq {
	pc = 0x8315D0B8; continue 'dispatch;
	}
	// 8315D0D8: 895E0000  lbz r10, 0(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D0DC: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 8315D0E0: 893E0001  lbz r9, 1(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(1 as u32) ) } as u64;
	// 8315D0E4: 5149442E  rlwimi r9, r10, 8, 0x10, 0x17
	ctx.r[9].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[9].u64 & 0xFFFFFFFFFFFF00FF);
	// 8315D0E8: 552A043E  clrlwi r10, r9, 0x10
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x0000FFFFu64;
	// 8315D0EC: 2B0A8000  cmplwi cr6, r10, 0x8000
	ctx.cr[6].compare_u32(ctx.r[10].u32, 32768 as u32, &mut ctx.xer);
	// 8315D0F0: 409A0014  bne cr6, 0x8315d104
	if !ctx.cr[6].eq {
	pc = 0x8315D104; continue 'dispatch;
	}
	// 8315D0F4: 897E0003  lbz r11, 3(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(3 as u32) ) } as u64;
	// 8315D0F8: 895E0002  lbz r10, 2(r30)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[30].u32.wrapping_add(2 as u32) ) } as u64;
	// 8315D0FC: 514B442E  rlwimi r11, r10, 8, 0x10, 0x17
	ctx.r[11].u64 = (((ctx.r[10].u32).rotate_left(8) as u64) & 0x000000000000FF00) | (ctx.r[11].u64 & 0xFFFFFFFFFFFF00FF);
	// 8315D100: 556B043E  clrlwi r11, r11, 0x10
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8315D104: 395E0004  addi r10, r30, 4
	ctx.r[10].s64 = ctx.r[30].s64 + 4;
	// 8315D108: 7FAB5214  add r29, r11, r10
	ctx.r[29].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315D10C: 7F1FE840  cmplw cr6, r31, r29
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8315D110: 419A0020  beq cr6, 0x8315d130
	if ctx.cr[6].eq {
	pc = 0x8315D130; continue 'dispatch;
	}
	// 8315D114: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 8315D118: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315D11C: 4BFFFB6D  bl 0x8315cc88
	ctx.lr = 0x8315D120;
	sub_8315CC88(ctx, base);
	// 8315D120: 987F0000  stb r3, 0(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[3].u8 ) };
	// 8315D124: 3BFF0001  addi r31, r31, 1
	ctx.r[31].s64 = ctx.r[31].s64 + 1;
	// 8315D128: 7F1FE840  cmplw cr6, r31, r29
	ctx.cr[6].compare_u32(ctx.r[31].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8315D12C: 409AFFE8  bne cr6, 0x8315d114
	if !ctx.cr[6].eq {
	pc = 0x8315D114; continue 'dispatch;
	}
	// 8315D130: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D134: 38C10060  addi r6, r1, 0x60
	ctx.r[6].s64 = ctx.r[1].s64 + 96;
	// 8315D138: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315D13C: 38800200  li r4, 0x200
	ctx.r[4].s64 = 512;
	// 8315D140: 4BFFD341  bl 0x8315a480
	ctx.lr = 0x8315D144;
	sub_8315A480(ctx, base);
	// 8315D144: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315D148: 4198007C  blt cr6, 0x8315d1c4
	if ctx.cr[6].lt {
	pc = 0x8315D1C4; continue 'dispatch;
	}
	// 8315D14C: 89410063  lbz r10, 0x63(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[1].u32.wrapping_add(99 as u32) ) } as u64;
	// 8315D150: 393B001C  addi r9, r27, 0x1c
	ctx.r[9].s64 = ctx.r[27].s64 + 28;
	// 8315D154: 81010064  lwz r8, 0x64(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(100 as u32) ) } as u64;
	// 8315D158: 39610084  addi r11, r1, 0x84
	ctx.r[11].s64 = ctx.r[1].s64 + 132;
	// 8315D15C: 80E10068  lwz r7, 0x68(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) } as u64;
	// 8315D160: 7D460774  extsb r6, r10
	ctx.r[6].s64 = ctx.r[10].s8 as i64;
	// 8315D164: 7D2A4B78  mr r10, r9
	ctx.r[10].u64 = ctx.r[9].u64;
	// 8315D168: 90DB0004  stw r6, 4(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 8315D16C: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8315D170: 911B0008  stw r8, 8(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8315D174: 90FB000C  stw r7, 0xc(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 8315D178: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315D17C: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D180: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8315D184: B12A0000  sth r9, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8315D188: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8315D18C: 4200FFF0  bdnz 0x8315d17c
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315D17C; continue 'dispatch;
	}
	// 8315D190: 395B0028  addi r10, r27, 0x28
	ctx.r[10].s64 = ctx.r[27].s64 + 40;
	// 8315D194: 39610090  addi r11, r1, 0x90
	ctx.r[11].s64 = ctx.r[1].s64 + 144;
	// 8315D198: 39200006  li r9, 6
	ctx.r[9].s64 = 6;
	// 8315D19C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315D1A0: A12B0000  lhz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D1A4: 396B0002  addi r11, r11, 2
	ctx.r[11].s64 = ctx.r[11].s64 + 2;
	// 8315D1A8: B12A0000  sth r9, 0(r10)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[9].u16 ) };
	// 8315D1AC: 394A0002  addi r10, r10, 2
	ctx.r[10].s64 = ctx.r[10].s64 + 2;
	// 8315D1B0: 4200FFF0  bdnz 0x8315d1a0
	ctx.ctr.u64 = ctx.ctr.u64.wrapping_sub(1);
	if ctx.ctr.u32 != 0 {
			pc = 0x8315D1A0; continue 'dispatch;
	}
	// 8315D1B4: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315D1B8: 917B0000  stw r11, 0(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D1BC: 935B0034  stw r26, 0x34(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(52 as u32), ctx.r[26].u32 ) };
	// 8315D1C0: 935B0038  stw r26, 0x38(r27)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[27].u32.wrapping_add(56 as u32), ctx.r[26].u32 ) };
	// 8315D1C4: 382100E0  addi r1, r1, 0xe0
	ctx.r[1].s64 = ctx.r[1].s64 + 224;
	// 8315D1C8: 4804AFE8  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315D1D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315D1D0 size=284
    let mut pc: u32 = 0x8315D1D0;
    'dispatch: loop {
        match pc {
            0x8315D1D0 => {
    //   block [0x8315D1D0..0x8315D2EC)
	// 8315D1D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315D1D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315D1D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315D1DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315D1E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315D1E4: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8315D1E8: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D1EC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315D1F0: 4BFFFA99  bl 0x8315cc88
	ctx.lr = 0x8315D1F4;
	sub_8315CC88(ctx, base);
	// 8315D1F4: 907F0000  stw r3, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 8315D1F8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D1FC: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D200: 4BFFFA89  bl 0x8315cc88
	ctx.lr = 0x8315D204;
	sub_8315CC88(ctx, base);
	// 8315D204: 21630004  subfic r11, r3, 4
	ctx.xer.ca = ctx.r[3].u32 <= 4 as u32;
	ctx.r[11].s64 = (4 as i64) - ctx.r[3].s64;
	// 8315D208: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D20C: 917F0004  stw r11, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315D210: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D214: 4BFFFA75  bl 0x8315cc88
	ctx.lr = 0x8315D218;
	sub_8315CC88(ctx, base);
	// 8315D218: 7C6A0034  cntlzw r10, r3
	ctx.r[10].u64 = if ctx.r[3].u32 == 0 { 32 } else { ctx.r[3].u32.leading_zeros() as u64 };
	// 8315D21C: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D220: 5549DFFE  rlwinm r9, r10, 0x1b, 0x1f, 0x1f
	ctx.r[9].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 8315D224: 38800004  li r4, 4
	ctx.r[4].s64 = 4;
	// 8315D228: 913F0008  stw r9, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8315D22C: 4BFFFA5D  bl 0x8315cc88
	ctx.lr = 0x8315D230;
	sub_8315CC88(ctx, base);
	// 8315D230: 907F000C  stw r3, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[3].u32 ) };
	// 8315D234: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D238: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D23C: 4BFFFA4D  bl 0x8315cc88
	ctx.lr = 0x8315D240;
	sub_8315CC88(ctx, base);
	// 8315D240: 907F0010  stw r3, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[3].u32 ) };
	// 8315D244: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D248: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D24C: 4BFFFA3D  bl 0x8315cc88
	ctx.lr = 0x8315D250;
	sub_8315CC88(ctx, base);
	// 8315D250: 907F0014  stw r3, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[3].u32 ) };
	// 8315D254: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D258: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D25C: 4BFFFA2D  bl 0x8315cc88
	ctx.lr = 0x8315D260;
	sub_8315CC88(ctx, base);
	// 8315D260: 907F0018  stw r3, 0x18(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(24 as u32), ctx.r[3].u32 ) };
	// 8315D264: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D268: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D26C: 4BFFFA1D  bl 0x8315cc88
	ctx.lr = 0x8315D270;
	sub_8315CC88(ctx, base);
	// 8315D270: 907F001C  stw r3, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[3].u32 ) };
	// 8315D274: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D278: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D27C: 4BFFFA0D  bl 0x8315cc88
	ctx.lr = 0x8315D280;
	sub_8315CC88(ctx, base);
	// 8315D280: 907F0020  stw r3, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[3].u32 ) };
	// 8315D284: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D288: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D28C: 4BFFF9FD  bl 0x8315cc88
	ctx.lr = 0x8315D290;
	sub_8315CC88(ctx, base);
	// 8315D290: 907F0024  stw r3, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[3].u32 ) };
	// 8315D294: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D298: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315D29C: 4BFFF9ED  bl 0x8315cc88
	ctx.lr = 0x8315D2A0;
	sub_8315CC88(ctx, base);
	// 8315D2A0: 907F0028  stw r3, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[3].u32 ) };
	// 8315D2A4: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D2A8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315D2AC: 4BFFF9DD  bl 0x8315cc88
	ctx.lr = 0x8315D2B0;
	sub_8315CC88(ctx, base);
	// 8315D2B0: 811F001C  lwz r8, 0x1c(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315D2B4: 907F002C  stw r3, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[3].u32 ) };
	// 8315D2B8: 2F080003  cmpwi cr6, r8, 3
	ctx.cr[6].compare_i32(ctx.r[8].s32, 3, &mut ctx.xer);
	// 8315D2BC: 409A0014  bne cr6, 0x8315d2d0
	if !ctx.cr[6].eq {
	pc = 0x8315D2D0; continue 'dispatch;
	}
	// 8315D2C0: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315D2C4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315D2C8: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315D2CC: 419A0008  beq cr6, 0x8315d2d4
	if ctx.cr[6].eq {
	pc = 0x8315D2D4; continue 'dispatch;
	}
	// 8315D2D0: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315D2D4: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315D2D8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315D2DC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315D2E0: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315D2E4: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315D2E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315D2F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315D2F0 size=452
    let mut pc: u32 = 0x8315D2F0;
    'dispatch: loop {
        match pc {
            0x8315D2F0 => {
    //   block [0x8315D2F0..0x8315D4B4)
	// 8315D2F0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315D2F4: 4804AE4D  bl 0x831a8140
	ctx.lr = 0x8315D2F8;
	sub_831A8130(ctx, base);
	// 8315D2F8: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315D2FC: 83640014  lwz r27, 0x14(r4)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315D300: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315D304: 82640010  lwz r19, 0x10(r4)
	ctx.r[19].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D308: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315D30C: 82440004  lwz r18, 4(r4)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315D310: 7CB42B78  mr r20, r5
	ctx.r[20].u64 = ctx.r[5].u64;
	// 8315D314: 82C40018  lwz r22, 0x18(r4)
	ctx.r[22].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315D318: 3AA00000  li r21, 0
	ctx.r[21].s64 = 0;
	// 8315D31C: 2F1B0000  cmpwi cr6, r27, 0
	ctx.cr[6].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 8315D320: 3AEB5CF8  addi r23, r11, 0x5cf8
	ctx.r[23].s64 = ctx.r[11].s64 + 23800;
	// 8315D324: 409900A4  ble cr6, 0x8315d3c8
	if !ctx.cr[6].gt {
	pc = 0x8315D3C8; continue 'dispatch;
	}
	// 8315D328: 7E99A378  mr r25, r20
	ctx.r[25].u64 = ctx.r[20].u64;
	// 8315D32C: 3B560004  addi r26, r22, 4
	ctx.r[26].s64 = ctx.r[22].s64 + 4;
	// 8315D330: 7F78DB78  mr r24, r27
	ctx.r[24].u64 = ctx.r[27].u64;
	// 8315D334: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8315D338: 40990080  ble cr6, 0x8315d3b8
	if !ctx.cr[6].gt {
	pc = 0x8315D3B8; continue 'dispatch;
	}
	// 8315D33C: 7F3CCB78  mr r28, r25
	ctx.r[28].u64 = ctx.r[25].u64;
	// 8315D340: 7E5D9378  mr r29, r18
	ctx.r[29].u64 = ctx.r[18].u64;
	// 8315D344: 83DA0000  lwz r30, 0(r26)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D348: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D34C: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315D350: 4098000C  bge cr6, 0x8315d35c
	if !ctx.cr[6].lt {
	pc = 0x8315D35C; continue 'dispatch;
	}
	// 8315D354: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D358: 4BFFF671  bl 0x8315c9c8
	ctx.lr = 0x8315D35C;
	sub_8315C9C8(ctx, base);
	// 8315D35C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D360: 7F1E5800  cmpw cr6, r30, r11
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315D364: 4099001C  ble cr6, 0x8315d380
	if !ctx.cr[6].gt {
	pc = 0x8315D380; continue 'dispatch;
	}
	// 8315D368: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D36C: 7EAAAB78  mr r10, r21
	ctx.r[10].u64 = ctx.r[21].u64;
	// 8315D370: 92BF000C  stw r21, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[21].u32 ) };
	// 8315D374: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D378: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D37C: 4800002C  b 0x8315d3a8
	pc = 0x8315D3A8; continue 'dispatch;
	// 8315D380: 57CA103A  slwi r10, r30, 2
	ctx.r[10].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315D384: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D388: 7D1E5850  subf r8, r30, r11
	ctx.r[8].s64 = ctx.r[11].s64 - ctx.r[30].s64;
	// 8315D38C: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D390: 7D274630  sraw r7, r9, r8
	tmp.u32 = ctx.r[8].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8315D394: 7CCAB82E  lwzx r6, r10, r23
	ctx.r[6].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[23].u32)) } as u64;
	// 8315D398: 7CBE5A14  add r5, r30, r11
	ctx.r[5].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8315D39C: 911F000C  stw r8, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 8315D3A0: 7CEA3038  and r10, r7, r6
	ctx.r[10].u64 = ctx.r[7].u64 & ctx.r[6].u64;
	// 8315D3A4: 90BF0010  stw r5, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[5].u32 ) };
	// 8315D3A8: 915C0000  stw r10, 0(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315D3AC: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8315D3B0: 3B9C0080  addi r28, r28, 0x80
	ctx.r[28].s64 = ctx.r[28].s64 + 128;
	// 8315D3B4: 4082FF90  bne 0x8315d344
	if !ctx.cr[0].eq {
	pc = 0x8315D344; continue 'dispatch;
	}
	// 8315D3B8: 3718FFFF  addic. r24, r24, -1
	ctx.xer.ca = (ctx.r[24].u32 > (!(-1 as u32)));
	ctx.r[24].s64 = ctx.r[24].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[24].s32, 0, &mut ctx.xer);
	// 8315D3BC: 3B5A0180  addi r26, r26, 0x180
	ctx.r[26].s64 = ctx.r[26].s64 + 384;
	// 8315D3C0: 3B390004  addi r25, r25, 4
	ctx.r[25].s64 = ctx.r[25].s64 + 4;
	// 8315D3C4: 4082FF70  bne 0x8315d334
	if !ctx.cr[0].eq {
	pc = 0x8315D334; continue 'dispatch;
	}
	// 8315D3C8: 7F1B9800  cmpw cr6, r27, r19
	ctx.cr[6].compare_i32(ctx.r[27].s32, ctx.r[19].s32, &mut ctx.xer);
	// 8315D3CC: 409800A0  bge cr6, 0x8315d46c
	if !ctx.cr[6].lt {
	pc = 0x8315D46C; continue 'dispatch;
	}
	// 8315D3D0: 576B083C  slwi r11, r27, 1
	ctx.r[11].u32 = ctx.r[27].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D3D4: 576A103A  slwi r10, r27, 2
	ctx.r[10].u32 = ctx.r[27].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315D3D8: 7D7B5A14  add r11, r27, r11
	ctx.r[11].u64 = ctx.r[27].u64 + ctx.r[11].u64;
	// 8315D3DC: 7FAAA214  add r29, r10, r20
	ctx.r[29].u64 = ctx.r[10].u64 + ctx.r[20].u64;
	// 8315D3E0: 556B3830  slwi r11, r11, 7
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(7);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D3E4: 7F7B9850  subf r27, r27, r19
	ctx.r[27].s64 = ctx.r[19].s64 - ctx.r[27].s64;
	// 8315D3E8: 7D6BB214  add r11, r11, r22
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 8315D3EC: 3B8B0004  addi r28, r11, 4
	ctx.r[28].s64 = ctx.r[11].s64 + 4;
	// 8315D3F0: 83DC0000  lwz r30, 0(r28)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[28].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D3F4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D3F8: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315D3FC: 4098000C  bge cr6, 0x8315d408
	if !ctx.cr[6].lt {
	pc = 0x8315D408; continue 'dispatch;
	}
	// 8315D400: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D404: 4BFFF5C5  bl 0x8315c9c8
	ctx.lr = 0x8315D408;
	sub_8315C9C8(ctx, base);
	// 8315D408: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D40C: 7F1E5000  cmpw cr6, r30, r10
	ctx.cr[6].compare_i32(ctx.r[30].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315D410: 4099001C  ble cr6, 0x8315d42c
	if !ctx.cr[6].gt {
	pc = 0x8315D42C; continue 'dispatch;
	}
	// 8315D414: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D418: 7EABAB78  mr r11, r21
	ctx.r[11].u64 = ctx.r[21].u64;
	// 8315D41C: 92BF000C  stw r21, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[21].u32 ) };
	// 8315D420: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8315D424: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8315D428: 4800002C  b 0x8315d454
	pc = 0x8315D454; continue 'dispatch;
	// 8315D42C: 57C9103A  slwi r9, r30, 2
	ctx.r[9].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8315D430: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D434: 811F0008  lwz r8, 8(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D438: 7CFE5050  subf r7, r30, r10
	ctx.r[7].s64 = ctx.r[10].s64 - ctx.r[30].s64;
	// 8315D43C: 7C9E5A14  add r4, r30, r11
	ctx.r[4].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8315D440: 7D063E30  sraw r6, r8, r7
	tmp.u32 = ctx.r[7].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[6].s64 = (ctx.r[8].s32 >> tmp.u32) as i64;
	// 8315D444: 7CA9B82E  lwzx r5, r9, r23
	ctx.r[5].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[23].u32)) } as u64;
	// 8315D448: 90FF000C  stw r7, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[7].u32 ) };
	// 8315D44C: 7CCB2838  and r11, r6, r5
	ctx.r[11].u64 = ctx.r[6].u64 & ctx.r[5].u64;
	// 8315D450: 909F0010  stw r4, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[4].u32 ) };
	// 8315D454: 917D0080  stw r11, 0x80(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8315D458: 377BFFFF  addic. r27, r27, -1
	ctx.xer.ca = (ctx.r[27].u32 > (!(-1 as u32)));
	ctx.r[27].s64 = ctx.r[27].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[27].s32, 0, &mut ctx.xer);
	// 8315D45C: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D460: 3B9C0180  addi r28, r28, 0x180
	ctx.r[28].s64 = ctx.r[28].s64 + 384;
	// 8315D464: 3BBD0004  addi r29, r29, 4
	ctx.r[29].s64 = ctx.r[29].s64 + 4;
	// 8315D468: 4082FF88  bne 0x8315d3f0
	if !ctx.cr[0].eq {
	pc = 0x8315D3F0; continue 'dispatch;
	}
	// 8315D46C: 2F130020  cmpwi cr6, r19, 0x20
	ctx.cr[6].compare_i32(ctx.r[19].s32, 32, &mut ctx.xer);
	// 8315D470: 4098003C  bge cr6, 0x8315d4ac
	if !ctx.cr[6].lt {
	pc = 0x8315D4AC; continue 'dispatch;
	}
	// 8315D474: 566B103A  slwi r11, r19, 2
	ctx.r[11].u32 = ctx.r[19].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D478: 21130020  subfic r8, r19, 0x20
	ctx.xer.ca = ctx.r[19].u32 <= 32 as u32;
	ctx.r[8].s64 = (32 as i64) - ctx.r[19].s64;
	// 8315D47C: 7D2BA214  add r9, r11, r20
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[20].u64;
	// 8315D480: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8315D484: 4099001C  ble cr6, 0x8315d4a0
	if !ctx.cr[6].gt {
	pc = 0x8315D4A0; continue 'dispatch;
	}
	// 8315D488: 7D2A4B78  mr r10, r9
	ctx.r[10].u64 = ctx.r[9].u64;
	// 8315D48C: 7E4B9378  mr r11, r18
	ctx.r[11].u64 = ctx.r[18].u64;
	// 8315D490: 92AA0000  stw r21, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[21].u32 ) };
	// 8315D494: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315D498: 394A0080  addi r10, r10, 0x80
	ctx.r[10].s64 = ctx.r[10].s64 + 128;
	// 8315D49C: 4082FFF4  bne 0x8315d490
	if !ctx.cr[0].eq {
	pc = 0x8315D490; continue 'dispatch;
	}
	// 8315D4A0: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315D4A4: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8315D4A8: 4082FFD8  bne 0x8315d480
	if !ctx.cr[0].eq {
	pc = 0x8315D480; continue 'dispatch;
	}
	// 8315D4AC: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 8315D4B0: 4804ACE0  b 0x831a8190
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315D4B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315D4B8 size=1220
    let mut pc: u32 = 0x8315D4B8;
    'dispatch: loop {
        match pc {
            0x8315D4B8 => {
    //   block [0x8315D4B8..0x8315D610)
	// 8315D4B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315D4BC: 4804AC81  bl 0x831a813c
	ctx.lr = 0x8315D4C0;
	sub_831A8130(ctx, base);
	// 8315D4C0: 9421FF30  stwu r1, -0xd0(r1)
	ea = ctx.r[1].u32.wrapping_add(-208 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315D4C4: 7CB32B78  mr r19, r5
	ctx.r[19].u64 = ctx.r[5].u64;
	// 8315D4C8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315D4CC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315D4D0: 7CD63378  mr r22, r6
	ctx.r[22].u64 = ctx.r[6].u64;
	// 8315D4D4: 7CF13B78  mr r17, r7
	ctx.r[17].u64 = ctx.r[7].u64;
	// 8315D4D8: 81730000  lwz r11, 0(r19)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[19].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D4DC: 3B400000  li r26, 0
	ctx.r[26].s64 = 0;
	// 8315D4E0: 829E0010  lwz r20, 0x10(r30)
	ctx.r[20].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D4E4: 825E0004  lwz r18, 4(r30)
	ctx.r[18].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315D4E8: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315D4EC: 419A0014  beq cr6, 0x8315d500
	if ctx.cr[6].eq {
	pc = 0x8315D500; continue 'dispatch;
	}
	// 8315D4F0: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D4F4: 4BFFF795  bl 0x8315cc88
	ctx.lr = 0x8315D4F8;
	sub_8315CC88(ctx, base);
	// 8315D4F8: 90760000  stw r3, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 8315D4FC: 48000008  b 0x8315d504
	pc = 0x8315D504; continue 'dispatch;
	// 8315D500: 93560000  stw r26, 0(r22)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[22].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 8315D504: 81760000  lwz r11, 0(r22)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D508: 2F140001  cmpwi cr6, r20, 1
	ctx.cr[6].compare_i32(ctx.r[20].s32, 1, &mut ctx.xer);
	// 8315D50C: 396B001A  addi r11, r11, 0x1a
	ctx.r[11].s64 = ctx.r[11].s64 + 26;
	// 8315D510: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315D514: 7F8AF22E  lhzx r28, r10, r30
	ctx.r[28].u64 = unsafe { crate::rt::load_u16(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 8315D518: 40990048  ble cr6, 0x8315d560
	if !ctx.cr[6].gt {
	pc = 0x8315D560; continue 'dispatch;
	}
	// 8315D51C: 3BD60004  addi r30, r22, 4
	ctx.r[30].s64 = ctx.r[22].s64 + 4;
	// 8315D520: 7F769850  subf r27, r22, r19
	ctx.r[27].s64 = ctx.r[19].s64 - ctx.r[22].s64;
	// 8315D524: 3BB4FFFF  addi r29, r20, -1
	ctx.r[29].s64 = ctx.r[20].s64 + -1;
	// 8315D528: 7D7BF02E  lwzx r11, r27, r30
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[27].u32.wrapping_add(ctx.r[30].u32)) } as u64;
	// 8315D52C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315D530: 419A001C  beq cr6, 0x8315d54c
	if ctx.cr[6].eq {
	pc = 0x8315D54C; continue 'dispatch;
	}
	// 8315D534: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315D538: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D53C: 4BFFF74D  bl 0x8315cc88
	ctx.lr = 0x8315D540;
	sub_8315CC88(ctx, base);
	// 8315D540: 578B07BE  clrlwi r11, r28, 0x1e
	ctx.r[11].u64 = ctx.r[28].u32 as u64 & 0x00000003u64;
	// 8315D544: 7C6A5A78  xor r10, r3, r11
	ctx.r[10].u64 = ctx.r[3].u64 ^ ctx.r[11].u64;
	// 8315D548: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315D54C: 7F8B0734  extsh r11, r28
	ctx.r[11].s64 = ctx.r[28].s16 as i64;
	// 8315D550: 3BDE0004  addi r30, r30, 4
	ctx.r[30].s64 = ctx.r[30].s64 + 4;
	// 8315D554: 7D7C1670  srawi r28, r11, 2
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 2) - 1)) != 0);
	ctx.r[28].s64 = (ctx.r[11].s32 >> 2) as i64;
	// 8315D558: 37BDFFFF  addic. r29, r29, -1
	ctx.xer.ca = (ctx.r[29].u32 > (!(-1 as u32)));
	ctx.r[29].s64 = ctx.r[29].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[29].s32, 0, &mut ctx.xer);
	// 8315D55C: 4082FFCC  bne 0x8315d528
	if !ctx.cr[0].eq {
	pc = 0x8315D528; continue 'dispatch;
	}
	// 8315D560: 2F140020  cmpwi cr6, r20, 0x20
	ctx.cr[6].compare_i32(ctx.r[20].s32, 32, &mut ctx.xer);
	// 8315D564: 4098003C  bge cr6, 0x8315d5a0
	if !ctx.cr[6].lt {
	pc = 0x8315D5A0; continue 'dispatch;
	}
	// 8315D568: 568B103A  slwi r11, r20, 2
	ctx.r[11].u32 = ctx.r[20].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D56C: 21140020  subfic r8, r20, 0x20
	ctx.xer.ca = ctx.r[20].u32 <= 32 as u32;
	ctx.r[8].s64 = (32 as i64) - ctx.r[20].s64;
	// 8315D570: 7D2BB214  add r9, r11, r22
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[22].u64;
	// 8315D574: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8315D578: 4099001C  ble cr6, 0x8315d594
	if !ctx.cr[6].gt {
	pc = 0x8315D594; continue 'dispatch;
	}
	// 8315D57C: 7D2A4B78  mr r10, r9
	ctx.r[10].u64 = ctx.r[9].u64;
	// 8315D580: 7E4B9378  mr r11, r18
	ctx.r[11].u64 = ctx.r[18].u64;
	// 8315D584: 934A0000  stw r26, 0(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(0 as u32), ctx.r[26].u32 ) };
	// 8315D588: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315D58C: 394A0080  addi r10, r10, 0x80
	ctx.r[10].s64 = ctx.r[10].s64 + 128;
	// 8315D590: 4082FFF4  bne 0x8315d584
	if !ctx.cr[0].eq {
	pc = 0x8315D584; continue 'dispatch;
	}
	// 8315D594: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315D598: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8315D59C: 4082FFD8  bne 0x8315d574
	if !ctx.cr[0].eq {
	pc = 0x8315D574; continue 'dispatch;
	}
	// 8315D5A0: 3AE0003F  li r23, 0x3f
	ctx.r[23].s64 = 63;
	// 8315D5A4: 2F140000  cmpwi cr6, r20, 0
	ctx.cr[6].compare_i32(ctx.r[20].s32, 0, &mut ctx.xer);
	// 8315D5A8: 40990380  ble cr6, 0x8315d928
	if !ctx.cr[6].gt {
	pc = 0x8315D928; continue 'dispatch;
	}
	// 8315D5AC: 7EDBB378  mr r27, r22
	ctx.r[27].u64 = ctx.r[22].u64;
	// 8315D5B0: 3B310080  addi r25, r17, 0x80
	ctx.r[25].s64 = ctx.r[17].s64 + 128;
	// 8315D5B4: 7E95A378  mr r21, r20
	ctx.r[21].u64 = ctx.r[20].u64;
	// 8315D5B8: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8315D5BC: 4099035C  ble cr6, 0x8315d918
	if !ctx.cr[6].gt {
	pc = 0x8315D918; continue 'dispatch;
	}
	// 8315D5C0: 7F7DDB78  mr r29, r27
	ctx.r[29].u64 = ctx.r[27].u64;
	// 8315D5C4: 7F3ECB78  mr r30, r25
	ctx.r[30].u64 = ctx.r[25].u64;
	// 8315D5C8: 7F169850  subf r24, r22, r19
	ctx.r[24].s64 = ctx.r[19].s64 - ctx.r[22].s64;
	// 8315D5CC: 7E5C9378  mr r28, r18
	ctx.r[28].u64 = ctx.r[18].u64;
	// 8315D5D0: 7D78E82E  lwzx r11, r24, r29
	ctx.r[11].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[24].u32.wrapping_add(ctx.r[29].u32)) } as u64;
	// 8315D5D4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315D5D8: 419A0324  beq cr6, 0x8315d8fc
	if ctx.cr[6].eq {
	pc = 0x8315D8FC; continue 'dispatch;
	}
	// 8315D5DC: 817D0000  lwz r11, 0(r29)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[29].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315D5E0: 2B0B0003  cmplwi cr6, r11, 3
	ctx.cr[6].compare_u32(ctx.r[11].u32, 3 as u32, &mut ctx.xer);
	// 8315D5E4: 41990324  bgt cr6, 0x8315d908
	if ctx.cr[6].gt {
	pc = 0x8315D908; continue 'dispatch;
	}
	// 8315D5E8: 3D808316  lis r12, -0x7cea
	ctx.r[12].s64 = -2095710208;
	// 8315D5EC: 398CD600  addi r12, r12, -0x2a00
	ctx.r[12].s64 = ctx.r[12].s64 + -10752;
	// 8315D5F0: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8315D5F4: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8315D5F8: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8315D5FC: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
	pc = 0x8315D610; continue 'dispatch;
		},
		1 => {
	pc = 0x8315D724; continue 'dispatch;
		},
		2 => {
	pc = 0x8315D888; continue 'dispatch;
		},
		3 => {
	pc = 0x8315D7C0; continue 'dispatch;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
	// 8315D600: 8315D610  lwz r24, -0x29f0(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-10736 as u32) ) } as u64;
	// 8315D604: 8315D724  lwz r24, -0x28dc(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-10460 as u32) ) } as u64;
	// 8315D608: 8315D888  lwz r24, -0x2778(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-10104 as u32) ) } as u64;
	// 8315D60C: 8315D7C0  lwz r24, -0x2840(r21)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[21].u32.wrapping_add(-10304 as u32) ) } as u64;
            }
            0x8315D610 => {
    //   block [0x8315D610..0x8315D724)
	// 8315D610: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D614: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D618: 4098000C  bge cr6, 0x8315d624
	if !ctx.cr[6].lt {
	pc = 0x8315D624; continue 'dispatch;
	}
	// 8315D61C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D620: 4BFFF3A9  bl 0x8315c9c8
	ctx.lr = 0x8315D624;
	sub_8315C9C8(ctx, base);
	// 8315D624: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D628: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D62C: 4098001C  bge cr6, 0x8315d648
	if !ctx.cr[6].lt {
	pc = 0x8315D648; continue 'dispatch;
	}
	// 8315D630: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D634: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D638: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D63C: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D640: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D644: 48000024  b 0x8315d668
	pc = 0x8315D668; continue 'dispatch;
	// 8315D648: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D64C: 396BFFFA  addi r11, r11, -6
	ctx.r[11].s64 = ctx.r[11].s64 + -6;
	// 8315D650: 7D495E30  sraw r9, r10, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[10].s32 >> tmp.u32) as i64;
	// 8315D654: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D658: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D65C: 552A06BE  clrlwi r10, r9, 0x1a
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x0000003Fu64;
	// 8315D660: 390B0006  addi r8, r11, 6
	ctx.r[8].s64 = ctx.r[11].s64 + 6;
	// 8315D664: 911F0010  stw r8, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[8].u32 ) };
	// 8315D668: 915EFF80  stw r10, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[10].u32 ) };
	// 8315D66C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D670: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D674: 4098000C  bge cr6, 0x8315d680
	if !ctx.cr[6].lt {
	pc = 0x8315D680; continue 'dispatch;
	}
	// 8315D678: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D67C: 4BFFF34D  bl 0x8315c9c8
	ctx.lr = 0x8315D680;
	sub_8315C9C8(ctx, base);
	// 8315D680: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D684: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D688: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D68C: 40980018  bge cr6, 0x8315d6a4
	if !ctx.cr[6].lt {
	pc = 0x8315D6A4; continue 'dispatch;
	}
	// 8315D690: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D694: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D698: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D69C: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D6A0: 48000020  b 0x8315d6c0
	pc = 0x8315D6C0; continue 'dispatch;
	// 8315D6A4: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D6A8: 396BFFFA  addi r11, r11, -6
	ctx.r[11].s64 = ctx.r[11].s64 + -6;
	// 8315D6AC: 38E90006  addi r7, r9, 6
	ctx.r[7].s64 = ctx.r[9].s64 + 6;
	// 8315D6B0: 7D485E30  sraw r8, r10, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[10].s32 >> tmp.u32) as i64;
	// 8315D6B4: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D6B8: 550A06BE  clrlwi r10, r8, 0x1a
	ctx.r[10].u64 = ctx.r[8].u32 as u64 & 0x0000003Fu64;
	// 8315D6BC: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315D6C0: 915E0000  stw r10, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315D6C4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D6C8: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D6CC: 4098000C  bge cr6, 0x8315d6d8
	if !ctx.cr[6].lt {
	pc = 0x8315D6D8; continue 'dispatch;
	}
	// 8315D6D0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D6D4: 4BFFF2F5  bl 0x8315c9c8
	ctx.lr = 0x8315D6D8;
	sub_8315C9C8(ctx, base);
	// 8315D6D8: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D6DC: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D6E0: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D6E4: 4098001C  bge cr6, 0x8315d700
	if !ctx.cr[6].lt {
	pc = 0x8315D700; continue 'dispatch;
	}
	// 8315D6E8: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D6EC: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D6F0: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D6F4: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D6F8: 915E0080  stw r10, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[10].u32 ) };
	// 8315D6FC: 4800020C  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
	// 8315D700: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D704: 396BFFFA  addi r11, r11, -6
	ctx.r[11].s64 = ctx.r[11].s64 + -6;
	// 8315D708: 38E90006  addi r7, r9, 6
	ctx.r[7].s64 = ctx.r[9].s64 + 6;
	// 8315D70C: 7D485E30  sraw r8, r10, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[10].s32 >> tmp.u32) as i64;
	// 8315D710: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D714: 550A06BE  clrlwi r10, r8, 0x1a
	ctx.r[10].u64 = ctx.r[8].u32 as u64 & 0x0000003Fu64;
	// 8315D718: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315D71C: 915E0080  stw r10, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[10].u32 ) };
	// 8315D720: 480001E8  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
            }
            0x8315D724 => {
    //   block [0x8315D724..0x8315D7C0)
	// 8315D724: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D728: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D72C: 4098000C  bge cr6, 0x8315d738
	if !ctx.cr[6].lt {
	pc = 0x8315D738; continue 'dispatch;
	}
	// 8315D730: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D734: 4BFFF295  bl 0x8315c9c8
	ctx.lr = 0x8315D738;
	sub_8315C9C8(ctx, base);
	// 8315D738: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D73C: 2F0A0006  cmpwi cr6, r10, 6
	ctx.cr[6].compare_i32(ctx.r[10].s32, 6, &mut ctx.xer);
	// 8315D740: 4098001C  bge cr6, 0x8315d75c
	if !ctx.cr[6].lt {
	pc = 0x8315D75C; continue 'dispatch;
	}
	// 8315D744: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D748: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 8315D74C: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D750: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8315D754: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8315D758: 48000024  b 0x8315d77c
	pc = 0x8315D77C; continue 'dispatch;
	// 8315D75C: 396AFFFA  addi r11, r10, -6
	ctx.r[11].s64 = ctx.r[10].s64 + -6;
	// 8315D760: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D764: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D768: 38EA0006  addi r7, r10, 6
	ctx.r[7].s64 = ctx.r[10].s64 + 6;
	// 8315D76C: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D770: 7D285E30  sraw r8, r9, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8315D774: 550B06BE  clrlwi r11, r8, 0x1a
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x0000003Fu64;
	// 8315D778: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315D77C: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D780: 917EFF80  stw r11, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[11].u32 ) };
	// 8315D784: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D788: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D78C: 4098000C  bge cr6, 0x8315d798
	if !ctx.cr[6].lt {
	pc = 0x8315D798; continue 'dispatch;
	}
	// 8315D790: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D794: 4BFFF235  bl 0x8315c9c8
	ctx.lr = 0x8315D798;
	sub_8315C9C8(ctx, base);
	// 8315D798: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D79C: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D7A0: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D7A4: 4098FF5C  bge cr6, 0x8315d700
	if !ctx.cr[6].lt {
	pc = 0x8315D700; continue 'dispatch;
	}
	// 8315D7A8: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D7AC: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D7B0: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D7B4: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D7B8: 915E0080  stw r10, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[10].u32 ) };
	// 8315D7BC: 4800014C  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
            }
            0x8315D7C0 => {
    //   block [0x8315D7C0..0x8315D888)
	// 8315D7C0: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D7C4: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D7C8: 4098000C  bge cr6, 0x8315d7d4
	if !ctx.cr[6].lt {
	pc = 0x8315D7D4; continue 'dispatch;
	}
	// 8315D7CC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D7D0: 4BFFF1F9  bl 0x8315c9c8
	ctx.lr = 0x8315D7D4;
	sub_8315C9C8(ctx, base);
	// 8315D7D4: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D7D8: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D7DC: 4098001C  bge cr6, 0x8315d7f8
	if !ctx.cr[6].lt {
	pc = 0x8315D7F8; continue 'dispatch;
	}
	// 8315D7E0: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D7E4: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315D7E8: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D7EC: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315D7F0: 917F0010  stw r11, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[11].u32 ) };
	// 8315D7F4: 48000024  b 0x8315d818
	pc = 0x8315D818; continue 'dispatch;
	// 8315D7F8: 815F0008  lwz r10, 8(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D7FC: 396BFFFA  addi r11, r11, -6
	ctx.r[11].s64 = ctx.r[11].s64 + -6;
	// 8315D800: 7D495E30  sraw r9, r10, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[10].s32 >> tmp.u32) as i64;
	// 8315D804: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D808: 817F0010  lwz r11, 0x10(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D80C: 552A06BE  clrlwi r10, r9, 0x1a
	ctx.r[10].u64 = ctx.r[9].u32 as u64 & 0x0000003Fu64;
	// 8315D810: 390B0006  addi r8, r11, 6
	ctx.r[8].s64 = ctx.r[11].s64 + 6;
	// 8315D814: 911F0010  stw r8, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[8].u32 ) };
	// 8315D818: 915EFF80  stw r10, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[10].u32 ) };
	// 8315D81C: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D820: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D824: 4098000C  bge cr6, 0x8315d830
	if !ctx.cr[6].lt {
	pc = 0x8315D830; continue 'dispatch;
	}
	// 8315D828: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D82C: 4BFFF19D  bl 0x8315c9c8
	ctx.lr = 0x8315D830;
	sub_8315C9C8(ctx, base);
	// 8315D830: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D834: 2F0A0006  cmpwi cr6, r10, 6
	ctx.cr[6].compare_i32(ctx.r[10].s32, 6, &mut ctx.xer);
	// 8315D838: 40980024  bge cr6, 0x8315d85c
	if !ctx.cr[6].lt {
	pc = 0x8315D85C; continue 'dispatch;
	}
	// 8315D83C: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D840: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 8315D844: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D848: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8315D84C: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8315D850: 917E0080  stw r11, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8315D854: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D858: 480000B0  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
	// 8315D85C: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D860: 396AFFFA  addi r11, r10, -6
	ctx.r[11].s64 = ctx.r[10].s64 + -6;
	// 8315D864: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D868: 7D285E30  sraw r8, r9, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8315D86C: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D870: 38EA0006  addi r7, r10, 6
	ctx.r[7].s64 = ctx.r[10].s64 + 6;
	// 8315D874: 550B06BE  clrlwi r11, r8, 0x1a
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x0000003Fu64;
	// 8315D878: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315D87C: 917E0080  stw r11, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8315D880: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D884: 48000084  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
            }
            0x8315D888 => {
    //   block [0x8315D888..0x8315D97C)
	// 8315D888: 817F000C  lwz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D88C: 2F0B0006  cmpwi cr6, r11, 6
	ctx.cr[6].compare_i32(ctx.r[11].s32, 6, &mut ctx.xer);
	// 8315D890: 4098000C  bge cr6, 0x8315d89c
	if !ctx.cr[6].lt {
	pc = 0x8315D89C; continue 'dispatch;
	}
	// 8315D894: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315D898: 4BFFF131  bl 0x8315c9c8
	ctx.lr = 0x8315D89C;
	sub_8315C9C8(ctx, base);
	// 8315D89C: 815F000C  lwz r10, 0xc(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315D8A0: 2F0A0006  cmpwi cr6, r10, 6
	ctx.cr[6].compare_i32(ctx.r[10].s32, 6, &mut ctx.xer);
	// 8315D8A4: 40980028  bge cr6, 0x8315d8cc
	if !ctx.cr[6].lt {
	pc = 0x8315D8CC; continue 'dispatch;
	}
	// 8315D8A8: 813F0010  lwz r9, 0x10(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D8AC: 7F4BD378  mr r11, r26
	ctx.r[11].u64 = ctx.r[26].u64;
	// 8315D8B0: 935F000C  stw r26, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[26].u32 ) };
	// 8315D8B4: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8315D8B8: 915F0010  stw r10, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[10].u32 ) };
	// 8315D8BC: 917E0080  stw r11, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8315D8C0: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D8C4: 917EFF80  stw r11, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[11].u32 ) };
	// 8315D8C8: 48000040  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
	// 8315D8CC: 813F0008  lwz r9, 8(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315D8D0: 396AFFFA  addi r11, r10, -6
	ctx.r[11].s64 = ctx.r[10].s64 + -6;
	// 8315D8D4: 815F0010  lwz r10, 0x10(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D8D8: 7D285E30  sraw r8, r9, r11
	tmp.u32 = ctx.r[11].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[8].s64 = (ctx.r[9].s32 >> tmp.u32) as i64;
	// 8315D8DC: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315D8E0: 38EA0006  addi r7, r10, 6
	ctx.r[7].s64 = ctx.r[10].s64 + 6;
	// 8315D8E4: 550B06BE  clrlwi r11, r8, 0x1a
	ctx.r[11].u64 = ctx.r[8].u32 as u64 & 0x0000003Fu64;
	// 8315D8E8: 90FF0010  stw r7, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[7].u32 ) };
	// 8315D8EC: 917E0080  stw r11, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[11].u32 ) };
	// 8315D8F0: 917E0000  stw r11, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315D8F4: 917EFF80  stw r11, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[11].u32 ) };
	// 8315D8F8: 48000010  b 0x8315d908
	pc = 0x8315D908; continue 'dispatch;
	// 8315D8FC: 92FE0080  stw r23, 0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(128 as u32), ctx.r[23].u32 ) };
	// 8315D900: 92FE0000  stw r23, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 8315D904: 92FEFF80  stw r23, -0x80(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(-128 as u32), ctx.r[23].u32 ) };
	// 8315D908: 379CFFFF  addic. r28, r28, -1
	ctx.xer.ca = (ctx.r[28].u32 > (!(-1 as u32)));
	ctx.r[28].s64 = ctx.r[28].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 8315D90C: 3BBD0080  addi r29, r29, 0x80
	ctx.r[29].s64 = ctx.r[29].s64 + 128;
	// 8315D910: 3BDE0180  addi r30, r30, 0x180
	ctx.r[30].s64 = ctx.r[30].s64 + 384;
	// 8315D914: 4082FCBC  bne 0x8315d5d0
	if !ctx.cr[0].eq {
	pc = 0x8315D5D0; continue 'dispatch;
	}
	// 8315D918: 36B5FFFF  addic. r21, r21, -1
	ctx.xer.ca = (ctx.r[21].u32 > (!(-1 as u32)));
	ctx.r[21].s64 = ctx.r[21].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[21].s32, 0, &mut ctx.xer);
	// 8315D91C: 3B7B0004  addi r27, r27, 4
	ctx.r[27].s64 = ctx.r[27].s64 + 4;
	// 8315D920: 3B390004  addi r25, r25, 4
	ctx.r[25].s64 = ctx.r[25].s64 + 4;
	// 8315D924: 4082FC94  bne 0x8315d5b8
	if !ctx.cr[0].eq {
	pc = 0x8315D5B8; continue 'dispatch;
	}
	// 8315D928: 2F140020  cmpwi cr6, r20, 0x20
	ctx.cr[6].compare_i32(ctx.r[20].s32, 32, &mut ctx.xer);
	// 8315D92C: 40980048  bge cr6, 0x8315d974
	if !ctx.cr[6].lt {
	pc = 0x8315D974; continue 'dispatch;
	}
	// 8315D930: 39740020  addi r11, r20, 0x20
	ctx.r[11].s64 = ctx.r[20].s64 + 32;
	// 8315D934: 21140020  subfic r8, r20, 0x20
	ctx.xer.ca = ctx.r[20].u32 <= 32 as u32;
	ctx.r[8].s64 = (32 as i64) - ctx.r[20].s64;
	// 8315D938: 556B103A  slwi r11, r11, 2
	ctx.r[11].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D93C: 7D2B8A14  add r9, r11, r17
	ctx.r[9].u64 = ctx.r[11].u64 + ctx.r[17].u64;
	// 8315D940: 2F120000  cmpwi cr6, r18, 0
	ctx.cr[6].compare_i32(ctx.r[18].s32, 0, &mut ctx.xer);
	// 8315D944: 40990024  ble cr6, 0x8315d968
	if !ctx.cr[6].gt {
	pc = 0x8315D968; continue 'dispatch;
	}
	// 8315D948: 7D2B4B78  mr r11, r9
	ctx.r[11].u64 = ctx.r[9].u64;
	// 8315D94C: 7E4A9378  mr r10, r18
	ctx.r[10].u64 = ctx.r[18].u64;
	// 8315D950: 92EB0080  stw r23, 0x80(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(128 as u32), ctx.r[23].u32 ) };
	// 8315D954: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315D958: 92EB0000  stw r23, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[23].u32 ) };
	// 8315D95C: 92EBFF80  stw r23, -0x80(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-128 as u32), ctx.r[23].u32 ) };
	// 8315D960: 396B0180  addi r11, r11, 0x180
	ctx.r[11].s64 = ctx.r[11].s64 + 384;
	// 8315D964: 4082FFEC  bne 0x8315d950
	if !ctx.cr[0].eq {
	pc = 0x8315D950; continue 'dispatch;
	}
	// 8315D968: 3508FFFF  addic. r8, r8, -1
	ctx.xer.ca = (ctx.r[8].u32 > (!(-1 as u32)));
	ctx.r[8].s64 = ctx.r[8].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315D96C: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8315D970: 4082FFD0  bne 0x8315d940
	if !ctx.cr[0].eq {
	pc = 0x8315D940; continue 'dispatch;
	}
	// 8315D974: 382100D0  addi r1, r1, 0xd0
	ctx.r[1].s64 = ctx.r[1].s64 + 208;
	// 8315D978: 4804A814  b 0x831a818c
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315D980(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315D980 size=1476
    let mut pc: u32 = 0x8315D980;
    'dispatch: loop {
        match pc {
            0x8315D980 => {
    //   block [0x8315D980..0x8315DF44)
	// 8315D980: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315D984: 4804A7AD  bl 0x831a8130
	ctx.lr = 0x8315D988;
	sub_831A8130(ctx, base);
	// 8315D988: DBA1FF50  stfd f29, -0xb0(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-176 as u32), ctx.f[29].u64 ) };
	// 8315D98C: DBC1FF58  stfd f30, -0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-168 as u32), ctx.f[30].u64 ) };
	// 8315D990: DBE1FF60  stfd f31, -0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-160 as u32), ctx.f[31].u64 ) };
	// 8315D994: 9421FE50  stwu r1, -0x1b0(r1)
	ea = ctx.r[1].u32.wrapping_add(-432 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315D998: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315D99C: 912101F4  stw r9, 0x1f4(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(500 as u32), ctx.r[9].u32 ) };
	// 8315D9A0: 7C731B78  mr r19, r3
	ctx.r[19].u64 = ctx.r[3].u64;
	// 8315D9A4: 910101EC  stw r8, 0x1ec(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(492 as u32), ctx.r[8].u32 ) };
	// 8315D9A8: 3D208200  lis r9, -0x7e00
	ctx.r[9].s64 = -2113929216;
	// 8315D9AC: 3AC00003  li r22, 3
	ctx.r[22].s64 = 3;
	// 8315D9B0: 3A000000  li r16, 0
	ctx.r[16].s64 = 0;
	// 8315D9B4: 814B0010  lwz r10, 0x10(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315D9B8: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315D9BC: 806B0014  lwz r3, 0x14(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315D9C0: C3A908A4  lfs f29, 0x8a4(r9)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(2212 as u32) ) };
	ctx.f[29].f64 = (tmp.f32 as f64);
	// 8315D9C4: 816B0018  lwz r11, 0x18(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315D9C8: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315D9CC: 91410060  stw r10, 0x60(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(96 as u32), ctx.r[10].u32 ) };
	// 8315D9D0: 90810058  stw r4, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[4].u32 ) };
	// 8315D9D4: 90610050  stw r3, 0x50(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(80 as u32), ctx.r[3].u32 ) };
	// 8315D9D8: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8315D9DC: 40990508  ble cr6, 0x8315dee4
	if !ctx.cr[6].gt {
	pc = 0x8315DEE4; continue 'dispatch;
	}
	// 8315D9E0: 54EB3830  slwi r11, r7, 7
	ctx.r[11].u32 = ctx.r[7].u32.wrapping_shl(7);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315D9E4: 3A480100  addi r18, r8, 0x100
	ctx.r[18].s64 = ctx.r[8].s64 + 256;
	// 8315D9E8: 7DCB3214  add r14, r11, r6
	ctx.r[14].u64 = ctx.r[11].u64 + ctx.r[6].u64;
	// 8315D9EC: 3D608334  lis r11, -0x7ccc
	ctx.r[11].s64 = -2093744128;
	// 8315D9F0: 3D205555  lis r9, 0x5555
	ctx.r[9].s64 = 1431633920;
	// 8315D9F4: 3D006666  lis r8, 0x6666
	ctx.r[8].s64 = 1717960704;
	// 8315D9F8: 3CE038E3  lis r7, 0x38e3
	ctx.r[7].s64 = 954400768;
	// 8315D9FC: 38CB61F8  addi r6, r11, 0x61f8
	ctx.r[6].s64 = ctx.r[11].s64 + 25080;
	// 8315DA00: 3A200000  li r17, 0
	ctx.r[17].s64 = 0;
	// 8315DA04: 7CAF2B78  mr r15, r5
	ctx.r[15].u64 = ctx.r[5].u64;
	// 8315DA08: 90C10054  stw r6, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[6].u32 ) };
	// 8315DA0C: 613B5556  ori r27, r9, 0x5556
	ctx.r[27].u64 = ctx.r[9].u64 | 21846;
	// 8315DA10: 3B200005  li r25, 5
	ctx.r[25].s64 = 5;
	// 8315DA14: 611C6667  ori r28, r8, 0x6667
	ctx.r[28].u64 = ctx.r[8].u64 | 26215;
	// 8315DA18: 3B400009  li r26, 9
	ctx.r[26].s64 = 9;
	// 8315DA1C: 60FD8E39  ori r29, r7, 0x8e39
	ctx.r[29].u64 = ctx.r[7].u64 | 36409;
	// 8315DA20: 3AA00000  li r21, 0
	ctx.r[21].s64 = 0;
	// 8315DA24: 7DF47B78  mr r20, r15
	ctx.r[20].u64 = ctx.r[15].u64;
	// 8315DA28: 7E5F9378  mr r31, r18
	ctx.r[31].u64 = ctx.r[18].u64;
	// 8315DA2C: 7E579378  mr r23, r18
	ctx.r[23].u64 = ctx.r[18].u64;
	// 8315DA30: 7DD87378  mr r24, r14
	ctx.r[24].u64 = ctx.r[14].u64;
	// 8315DA34: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315DA38: 7F105800  cmpw cr6, r16, r11
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315DA3C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315DA40: 41980008  blt cr6, 0x8315da48
	if ctx.cr[6].lt {
	pc = 0x8315DA48; continue 'dispatch;
	}
	// 8315DA44: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315DA48: 7F155800  cmpw cr6, r21, r11
	ctx.cr[6].compare_i32(ctx.r[21].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315DA4C: 40980478  bge cr6, 0x8315dec4
	if !ctx.cr[6].lt {
	pc = 0x8315DEC4; continue 'dispatch;
	}
	// 8315DA50: 81740000  lwz r11, 0(r20)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[20].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315DA54: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315DA58: 419A0414  beq cr6, 0x8315de6c
	if ctx.cr[6].eq {
	pc = 0x8315DE6C; continue 'dispatch;
	}
	// 8315DA5C: 7D715A14  add r11, r17, r11
	ctx.r[11].u64 = ctx.r[17].u64 + ctx.r[11].u64;
	// 8315DA60: 8121005C  lwz r9, 0x5c(r1)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(92 as u32) ) } as u64;
	// 8315DA64: 81180000  lwz r8, 0(r24)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[24].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315DA68: 7E639B78  mr r3, r19
	ctx.r[3].u64 = ctx.r[19].u64;
	// 8315DA6C: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DA70: 80E101F4  lwz r7, 0x1f4(r1)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(500 as u32) ) } as u64;
	// 8315DA74: 5506103A  slwi r6, r8, 2
	ctx.r[6].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[6].u64 = ctx.r[6].u32 as u64;
	// 8315DA78: 7CAB5214  add r5, r11, r10
	ctx.r[5].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DA7C: 54AB1838  slwi r11, r5, 3
	ctx.r[11].u32 = ctx.r[5].u32.wrapping_shl(3);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315DA80: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315DA84: 7C063C2E  lfsx f0, r6, r7
	tmp.u32 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[6].u32.wrapping_add(ctx.r[7].u32)) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315DA88: 808B0008  lwz r4, 8(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315DA8C: C1AB0010  lfs f13, 0x10(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(16 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315DA90: C18B0014  lfs f12, 0x14(r11)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(20 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315DA94: EFED0032  fmuls f31, f13, f0
	ctx.f[31].f64 = (((ctx.f[13].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315DA98: EFCC0032  fmuls f30, f12, f0
	ctx.f[30].f64 = (((ctx.f[12].f64 * ctx.f[0].f64) as f32) as f64);
	// 8315DA9C: 2F040003  cmpwi cr6, r4, 3
	ctx.cr[6].compare_i32(ctx.r[4].s32, 3, &mut ctx.xer);
	// 8315DAA0: 409A0108  bne cr6, 0x8315dba8
	if !ctx.cr[6].eq {
	pc = 0x8315DBA8; continue 'dispatch;
	}
	// 8315DAA4: 83CB0004  lwz r30, 4(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315DAA8: 2F1E0008  cmpwi cr6, r30, 8
	ctx.cr[6].compare_i32(ctx.r[30].s32, 8, &mut ctx.xer);
	// 8315DAAC: 41990084  bgt cr6, 0x8315db30
	if ctx.cr[6].gt {
	pc = 0x8315DB30; continue 'dispatch;
	}
	// 8315DAB0: 57CB083C  slwi r11, r30, 1
	ctx.r[11].u32 = ctx.r[30].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315DAB4: 7C9E5A14  add r4, r30, r11
	ctx.r[4].u64 = ctx.r[30].u64 + ctx.r[11].u64;
	// 8315DAB8: 4BFFF1D1  bl 0x8315cc88
	ctx.lr = 0x8315DABC;
	sub_8315CC88(ctx, base);
	// 8315DABC: 81410054  lwz r10, 0x54(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8315DAC0: 57C9103A  slwi r9, r30, 2
	ctx.r[9].u32 = ctx.r[30].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8315DAC4: 7C6BF630  sraw r11, r3, r30
	tmp.u32 = ctx.r[30].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[3].s32 < 0) && ((ctx.r[3].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[3].s32 >> tmp.u32) as i64;
	// 8315DAC8: 7D09502E  lwzx r8, r9, r10
	ctx.r[8].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[9].u32.wrapping_add(ctx.r[10].u32)) } as u64;
	// 8315DACC: 7D67F630  sraw r7, r11, r30
	tmp.u32 = ctx.r[30].u32 & 0x3F;
	if tmp.u32 > 0x1F { tmp.u32 = 0x1F; }
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << tmp.u32) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[11].s32 >> tmp.u32) as i64;
	// 8315DAD0: 7D055838  and r5, r8, r11
	ctx.r[5].u64 = ctx.r[8].u64 & ctx.r[11].u64;
	// 8315DAD4: 7D061838  and r6, r8, r3
	ctx.r[6].u64 = ctx.r[8].u64 & ctx.r[3].u64;
	// 8315DAD8: 7CA307B4  extsw r3, r5
	ctx.r[3].s64 = ctx.r[5].s32 as i64;
	// 8315DADC: 7CEB07B4  extsw r11, r7
	ctx.r[11].s64 = ctx.r[7].s32 as i64;
	// 8315DAE0: F8610078  std r3, 0x78(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(120 as u32), ctx.r[3].u64 ) };
	// 8315DAE4: C9A10078  lfd f13, 0x78(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(120 as u32) ) };
	// 8315DAE8: F96100B8  std r11, 0xb8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(184 as u32), ctx.r[11].u64 ) };
	// 8315DAEC: C98100B8  lfd f12, 0xb8(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(184 as u32) ) };
	// 8315DAF0: 7CC407B4  extsw r4, r6
	ctx.r[4].s64 = ctx.r[6].s32 as i64;
	// 8315DAF4: F88100C8  std r4, 0xc8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(200 as u32), ctx.r[4].u64 ) };
	// 8315DAF8: C80100C8  lfd f0, 0xc8(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(200 as u32) ) };
	// 8315DAFC: FD20069C  fcfid f9, f0
	ctx.f[9].f64 = (ctx.f[0].s64 as f64);
	// 8315DB00: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 8315DB04: FD406E9C  fcfid f10, f13
	ctx.f[10].f64 = (ctx.f[13].s64 as f64);
	// 8315DB08: FCC04818  frsp f6, f9
	ctx.f[6].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DB0C: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8315DB10: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8315DB14: EC66F7FA  fmadds f3, f6, f31, f30
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DB18: D07F0000  stfs f3, 0(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DB1C: ECA8F7FA  fmadds f5, f8, f31, f30
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DB20: D0BFFF00  stfs f5, -0x100(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DB24: EC87F7FA  fmadds f4, f7, f31, f30
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DB28: D09FFF80  stfs f4, -0x80(r31)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DB2C: 4800034C  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DB30: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315DB34: 4BFFF155  bl 0x8315cc88
	ctx.lr = 0x8315DB38;
	sub_8315CC88(ctx, base);
	// 8315DB38: 7C6B07B4  extsw r11, r3
	ctx.r[11].s64 = ctx.r[3].s32 as i64;
	// 8315DB3C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315DB40: F9610088  std r11, 0x88(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(136 as u32), ctx.r[11].u64 ) };
	// 8315DB44: C8010088  lfd f0, 0x88(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(136 as u32) ) };
	// 8315DB48: FDA0069C  fcfid f13, f0
	ctx.f[13].f64 = (ctx.f[0].s64 as f64);
	// 8315DB4C: 7E639B78  mr r3, r19
	ctx.r[3].u64 = ctx.r[19].u64;
	// 8315DB50: FD806818  frsp f12, f13
	ctx.f[12].f64 = (ctx.f[13].f64 as f32) as f64;
	// 8315DB54: ED6CF7FA  fmadds f11, f12, f31, f30
	ctx.f[11].f64 = (((ctx.f[12].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DB58: D17FFF00  stfs f11, -0x100(r31)
	tmp.f32 = (ctx.f[11].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DB5C: 4BFFF12D  bl 0x8315cc88
	ctx.lr = 0x8315DB60;
	sub_8315CC88(ctx, base);
	// 8315DB60: 7C6A07B4  extsw r10, r3
	ctx.r[10].s64 = ctx.r[3].s32 as i64;
	// 8315DB64: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315DB68: F94100D8  std r10, 0xd8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(216 as u32), ctx.r[10].u64 ) };
	// 8315DB6C: C94100D8  lfd f10, 0xd8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[10].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(216 as u32) ) };
	// 8315DB70: FD20569C  fcfid f9, f10
	ctx.f[9].f64 = (ctx.f[10].s64 as f64);
	// 8315DB74: 7E639B78  mr r3, r19
	ctx.r[3].u64 = ctx.r[19].u64;
	// 8315DB78: FD004818  frsp f8, f9
	ctx.f[8].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DB7C: ECE8F7FA  fmadds f7, f8, f31, f30
	ctx.f[7].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DB80: D0FFFF80  stfs f7, -0x80(r31)
	tmp.f32 = (ctx.f[7].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DB84: 4BFFF105  bl 0x8315cc88
	ctx.lr = 0x8315DB88;
	sub_8315CC88(ctx, base);
	// 8315DB88: 7C6907B4  extsw r9, r3
	ctx.r[9].s64 = ctx.r[3].s32 as i64;
	// 8315DB8C: F9210098  std r9, 0x98(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(152 as u32), ctx.r[9].u64 ) };
	// 8315DB90: C8C10098  lfd f6, 0x98(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[6].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(152 as u32) ) };
	// 8315DB94: FCA0369C  fcfid f5, f6
	ctx.f[5].f64 = (ctx.f[6].s64 as f64);
	// 8315DB98: FC802818  frsp f4, f5
	ctx.f[4].f64 = (ctx.f[5].f64 as f32) as f64;
	// 8315DB9C: EC64F7FA  fmadds f3, f4, f31, f30
	ctx.f[3].f64 = (((ctx.f[4].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DBA0: D07F0000  stfs f3, 0(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DBA4: 480002D4  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DBA8: 83CB0000  lwz r30, 0(r11)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315DBAC: 808B0004  lwz r4, 4(r11)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315DBB0: 4BFFF0D9  bl 0x8315cc88
	ctx.lr = 0x8315DBB4;
	sub_8315CC88(ctx, base);
	// 8315DBB4: 2F1E0003  cmpwi cr6, r30, 3
	ctx.cr[6].compare_i32(ctx.r[30].s32, 3, &mut ctx.xer);
	// 8315DBB8: 409A00B0  bne cr6, 0x8315dc68
	if !ctx.cr[6].eq {
	pc = 0x8315DC68; continue 'dispatch;
	}
	// 8315DBBC: 7D63B3D6  divw r11, r3, r22
	ctx.r[11].s32 = ctx.r[3].s32 / ctx.r[22].s32;
	// 8315DBC0: 7D23D896  mulhw r9, r3, r27
	ctx.r[9].s64 = ((ctx.r[3].s32 as i64 * ctx.r[27].s32 as i64) >> 32);
	// 8315DBC4: 7CCBB3D6  divw r6, r11, r22
	ctx.r[6].s32 = ctx.r[11].s32 / ctx.r[22].s32;
	// 8315DBC8: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 8315DBCC: 7D46D896  mulhw r10, r6, r27
	ctx.r[10].s64 = ((ctx.r[6].s32 as i64 * ctx.r[27].s32 as i64) >> 32);
	// 8315DBD0: 55480FFE  srwi r8, r10, 0x1f
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shr(31);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315DBD4: 7D65D896  mulhw r11, r5, r27
	ctx.r[11].s64 = ((ctx.r[5].s32 as i64 * ctx.r[27].s32 as i64) >> 32);
	// 8315DBD8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8315DBDC: 55270FFE  srwi r7, r9, 0x1f
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shr(31);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DBE0: 5548083C  slwi r8, r10, 1
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(1);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315DBE4: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315DBE8: 7C8A4214  add r4, r10, r8
	ctx.r[4].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8315DBEC: 556A0FFE  srwi r10, r11, 0x1f
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shr(31);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DBF0: 5527083C  slwi r7, r9, 1
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(1);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DBF4: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DBF8: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315DBFC: 556A083C  slwi r10, r11, 1
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(1);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DC00: 7CE91850  subf r7, r9, r3
	ctx.r[7].s64 = ctx.r[3].s64 - ctx.r[9].s64;
	// 8315DC04: 7D0B5214  add r8, r11, r10
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DC08: 7D443050  subf r10, r4, r6
	ctx.r[10].s64 = ctx.r[6].s64 - ctx.r[4].s64;
	// 8315DC0C: 7CA82850  subf r5, r8, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[8].s64;
	// 8315DC10: 7D4907B4  extsw r9, r10
	ctx.r[9].s64 = ctx.r[10].s32 as i64;
	// 8315DC14: 7CAB07B4  extsw r11, r5
	ctx.r[11].s64 = ctx.r[5].s32 as i64;
	// 8315DC18: F92100E8  std r9, 0xe8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(232 as u32), ctx.r[9].u64 ) };
	// 8315DC1C: C98100E8  lfd f12, 0xe8(r1)
	ctx.fpscr.disable_flush_mode_unconditional();
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(232 as u32) ) };
	// 8315DC20: F96100A8  std r11, 0xa8(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(168 as u32), ctx.r[11].u64 ) };
	// 8315DC24: C9A100A8  lfd f13, 0xa8(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(168 as u32) ) };
	// 8315DC28: 7CE307B4  extsw r3, r7
	ctx.r[3].s64 = ctx.r[7].s32 as i64;
	// 8315DC2C: F8610068  std r3, 0x68(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(104 as u32), ctx.r[3].u64 ) };
	// 8315DC30: C8010068  lfd f0, 0x68(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(104 as u32) ) };
	// 8315DC34: FD20069C  fcfid f9, f0
	ctx.f[9].f64 = (ctx.f[0].s64 as f64);
	// 8315DC38: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 8315DC3C: FD406E9C  fcfid f10, f13
	ctx.f[10].f64 = (ctx.f[13].s64 as f64);
	// 8315DC40: FCC04818  frsp f6, f9
	ctx.f[6].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DC44: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8315DC48: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8315DC4C: EC66F7FA  fmadds f3, f6, f31, f30
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DC50: D07FFF00  stfs f3, -0x100(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DC54: ECA8F7FA  fmadds f5, f8, f31, f30
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DC58: D0BF0000  stfs f5, 0(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DC5C: EC87F7FA  fmadds f4, f7, f31, f30
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DC60: D09FFF80  stfs f4, -0x80(r31)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DC64: 48000214  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DC68: 2F1E0005  cmpwi cr6, r30, 5
	ctx.cr[6].compare_i32(ctx.r[30].s32, 5, &mut ctx.xer);
	// 8315DC6C: 409A00BC  bne cr6, 0x8315dd28
	if !ctx.cr[6].eq {
	pc = 0x8315DD28; continue 'dispatch;
	}
	// 8315DC70: 7D63CBD6  divw r11, r3, r25
	ctx.r[11].s32 = ctx.r[3].s32 / ctx.r[25].s32;
	// 8315DC74: 7C83E096  mulhw r4, r3, r28
	ctx.r[4].s64 = ((ctx.r[3].s32 as i64 * ctx.r[28].s32 as i64) >> 32);
	// 8315DC78: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 8315DC7C: 7CABCBD6  divw r5, r11, r25
	ctx.r[5].s32 = ctx.r[11].s32 / ctx.r[25].s32;
	// 8315DC80: 7D46E096  mulhw r10, r6, r28
	ctx.r[10].s64 = ((ctx.r[6].s32 as i64 * ctx.r[28].s32 as i64) >> 32);
	// 8315DC84: 7D25E096  mulhw r9, r5, r28
	ctx.r[9].s64 = ((ctx.r[5].s32 as i64 * ctx.r[28].s32 as i64) >> 32);
	// 8315DC88: 7C8B0E70  srawi r11, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 8315DC8C: 7D4A0E70  srawi r10, r10, 1
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[10].s64 = (ctx.r[10].s32 >> 1) as i64;
	// 8315DC90: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8315DC94: 55680FFE  srwi r8, r11, 0x1f
	ctx.r[8].u32 = ctx.r[11].u32.wrapping_shr(31);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315DC98: 55270FFE  srwi r7, r9, 0x1f
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shr(31);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DC9C: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8315DCA0: 7D693A14  add r11, r9, r7
	ctx.r[11].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315DCA4: 5507103A  slwi r7, r8, 2
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(2);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DCA8: 5569103A  slwi r9, r11, 2
	ctx.r[9].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[9].u64 = ctx.r[9].u32 as u64;
	// 8315DCAC: 7D083A14  add r8, r8, r7
	ctx.r[8].u64 = ctx.r[8].u64 + ctx.r[7].u64;
	// 8315DCB0: 7CEB4A14  add r7, r11, r9
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315DCB4: 554B0FFE  srwi r11, r10, 0x1f
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shr(31);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315DCB8: 7CA72850  subf r5, r7, r5
	ctx.r[5].s64 = ctx.r[5].s64 - ctx.r[7].s64;
	// 8315DCBC: 7D6A5A14  add r11, r10, r11
	ctx.r[11].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8315DCC0: 7CA407B4  extsw r4, r5
	ctx.r[4].s64 = ctx.r[5].s32 as i64;
	// 8315DCC4: 556A103A  slwi r10, r11, 2
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DCC8: F8810070  std r4, 0x70(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(112 as u32), ctx.r[4].u64 ) };
	// 8315DCCC: C8010070  lfd f0, 0x70(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(112 as u32) ) };
	// 8315DCD0: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DCD4: FD20069C  fcfid f9, f0
	ctx.f[9].f64 = (ctx.f[0].s64 as f64);
	// 8315DCD8: 7D2B3050  subf r9, r11, r6
	ctx.r[9].s64 = ctx.r[6].s64 - ctx.r[11].s64;
	// 8315DCDC: FCC04818  frsp f6, f9
	ctx.f[6].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DCE0: 7D481850  subf r10, r8, r3
	ctx.r[10].s64 = ctx.r[3].s64 - ctx.r[8].s64;
	// 8315DCE4: 7D2707B4  extsw r7, r9
	ctx.r[7].s64 = ctx.r[9].s32 as i64;
	// 8315DCE8: 7D4807B4  extsw r8, r10
	ctx.r[8].s64 = ctx.r[10].s32 as i64;
	// 8315DCEC: F8E10090  std r7, 0x90(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(144 as u32), ctx.r[7].u64 ) };
	// 8315DCF0: C9810090  lfd f12, 0x90(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(144 as u32) ) };
	// 8315DCF4: F9010080  std r8, 0x80(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(128 as u32), ctx.r[8].u64 ) };
	// 8315DCF8: C9A10080  lfd f13, 0x80(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(128 as u32) ) };
	// 8315DCFC: FD606E9C  fcfid f11, f13
	ctx.f[11].f64 = (ctx.f[13].s64 as f64);
	// 8315DD00: FD40669C  fcfid f10, f12
	ctx.f[10].f64 = (ctx.f[12].s64 as f64);
	// 8315DD04: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8315DD08: EC66F7FA  fmadds f3, f6, f31, f30
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DD0C: D07F0000  stfs f3, 0(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DD10: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8315DD14: ECA8F7FA  fmadds f5, f8, f31, f30
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DD18: D0BFFF00  stfs f5, -0x100(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DD1C: EC87F7FA  fmadds f4, f7, f31, f30
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DD20: D09FFF80  stfs f4, -0x80(r31)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DD24: 48000154  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DD28: 2F1E0009  cmpwi cr6, r30, 9
	ctx.cr[6].compare_i32(ctx.r[30].s32, 9, &mut ctx.xer);
	// 8315DD2C: 409A00BC  bne cr6, 0x8315dde8
	if !ctx.cr[6].eq {
	pc = 0x8315DDE8; continue 'dispatch;
	}
	// 8315DD30: 7D63D3D6  divw r11, r3, r26
	ctx.r[11].s32 = ctx.r[3].s32 / ctx.r[26].s32;
	// 8315DD34: 7CA3E896  mulhw r5, r3, r29
	ctx.r[5].s64 = ((ctx.r[3].s32 as i64 * ctx.r[29].s32 as i64) >> 32);
	// 8315DD38: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 8315DD3C: 7FCBD3D6  divw r30, r11, r26
	ctx.r[30].s32 = ctx.r[11].s32 / ctx.r[26].s32;
	// 8315DD40: 7C86E896  mulhw r4, r6, r29
	ctx.r[4].s64 = ((ctx.r[6].s32 as i64 * ctx.r[29].s32 as i64) >> 32);
	// 8315DD44: 7CAB0E70  srawi r11, r5, 1
	ctx.xer.ca = (ctx.r[5].s32 < 0) && ((ctx.r[5].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[11].s64 = (ctx.r[5].s32 >> 1) as i64;
	// 8315DD48: 7C8A0E70  srawi r10, r4, 1
	ctx.xer.ca = (ctx.r[4].s32 < 0) && ((ctx.r[4].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[10].s64 = (ctx.r[4].s32 >> 1) as i64;
	// 8315DD4C: 7D3EE896  mulhw r9, r30, r29
	ctx.r[9].s64 = ((ctx.r[30].s32 as i64 * ctx.r[29].s32 as i64) >> 32);
	// 8315DD50: 55480FFE  srwi r8, r10, 0x1f
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shr(31);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315DD54: 7D290E70  srawi r9, r9, 1
	ctx.xer.ca = (ctx.r[9].s32 < 0) && ((ctx.r[9].u32 & ((1u32 << 1) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[9].s32 >> 1) as i64;
	// 8315DD58: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8315DD5C: 55270FFE  srwi r7, r9, 0x1f
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shr(31);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DD60: 55481838  slwi r8, r10, 3
	ctx.r[8].u32 = ctx.r[10].u32.wrapping_shl(3);
	ctx.r[8].u64 = ctx.r[8].u32 as u64;
	// 8315DD64: 7D293A14  add r9, r9, r7
	ctx.r[9].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315DD68: 7D0A4214  add r8, r10, r8
	ctx.r[8].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8315DD6C: 556A0FFE  srwi r10, r11, 0x1f
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shr(31);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DD70: 55271838  slwi r7, r9, 3
	ctx.r[7].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315DD74: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DD78: 7CE93A14  add r7, r9, r7
	ctx.r[7].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315DD7C: 556A1838  slwi r10, r11, 3
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315DD80: 7D083050  subf r8, r8, r6
	ctx.r[8].s64 = ctx.r[6].s64 - ctx.r[8].s64;
	// 8315DD84: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315DD88: 7CA7F050  subf r5, r7, r30
	ctx.r[5].s64 = ctx.r[30].s64 - ctx.r[7].s64;
	// 8315DD8C: 7D441850  subf r10, r4, r3
	ctx.r[10].s64 = ctx.r[3].s64 - ctx.r[4].s64;
	// 8315DD90: 7D0707B4  extsw r7, r8
	ctx.r[7].s64 = ctx.r[8].s32 as i64;
	// 8315DD94: 7D4907B4  extsw r9, r10
	ctx.r[9].s64 = ctx.r[10].s32 as i64;
	// 8315DD98: F8E100C0  std r7, 0xc0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(192 as u32), ctx.r[7].u64 ) };
	// 8315DD9C: C98100C0  lfd f12, 0xc0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(192 as u32) ) };
	// 8315DDA0: F92100B0  std r9, 0xb0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(176 as u32), ctx.r[9].u64 ) };
	// 8315DDA4: C9A100B0  lfd f13, 0xb0(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(176 as u32) ) };
	// 8315DDA8: 7CAB07B4  extsw r11, r5
	ctx.r[11].s64 = ctx.r[5].s32 as i64;
	// 8315DDAC: F96100A0  std r11, 0xa0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(160 as u32), ctx.r[11].u64 ) };
	// 8315DDB0: C80100A0  lfd f0, 0xa0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(160 as u32) ) };
	// 8315DDB4: FD20069C  fcfid f9, f0
	ctx.f[9].f64 = (ctx.f[0].s64 as f64);
	// 8315DDB8: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 8315DDBC: FD406E9C  fcfid f10, f13
	ctx.f[10].f64 = (ctx.f[13].s64 as f64);
	// 8315DDC0: FCC04818  frsp f6, f9
	ctx.f[6].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DDC4: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8315DDC8: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8315DDCC: EC66F7FA  fmadds f3, f6, f31, f30
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DDD0: D07F0000  stfs f3, 0(r31)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DDD4: ECA8F7FA  fmadds f5, f8, f31, f30
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DDD8: D0BFFF80  stfs f5, -0x80(r31)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DDDC: EC87F7FA  fmadds f4, f7, f31, f30
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DDE0: D09FFF00  stfs f4, -0x100(r31)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DDE4: 48000094  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DDE8: 7D63F3D6  divw r11, r3, r30
	ctx.r[11].s32 = ctx.r[3].s32 / ctx.r[30].s32;
	// 8315DDEC: 7D43F3D6  divw r10, r3, r30
	ctx.r[10].s32 = ctx.r[3].s32 / ctx.r[30].s32;
	// 8315DDF0: 7D2BF3D6  divw r9, r11, r30
	ctx.r[9].s32 = ctx.r[11].s32 / ctx.r[30].s32;
	// 8315DDF4: 7D0AF1D6  mullw r8, r10, r30
	ctx.r[8].s64 = (ctx.r[10].s32 as i64) * (ctx.r[30].s32 as i64);
	// 8315DDF8: 7CE9F1D6  mullw r7, r9, r30
	ctx.r[7].s64 = (ctx.r[9].s32 as i64) * (ctx.r[30].s32 as i64);
	// 8315DDFC: 7CC75850  subf r6, r7, r11
	ctx.r[6].s64 = ctx.r[11].s64 - ctx.r[7].s64;
	// 8315DE00: 7D6BF3D6  divw r11, r11, r30
	ctx.r[11].s32 = ctx.r[11].s32 / ctx.r[30].s32;
	// 8315DE04: 7CA81850  subf r5, r8, r3
	ctx.r[5].s64 = ctx.r[3].s64 - ctx.r[8].s64;
	// 8315DE08: 7D4BF3D6  divw r10, r11, r30
	ctx.r[10].s32 = ctx.r[11].s32 / ctx.r[30].s32;
	// 8315DE0C: 7CA307B4  extsw r3, r5
	ctx.r[3].s64 = ctx.r[5].s32 as i64;
	// 8315DE10: 7D2AF1D6  mullw r9, r10, r30
	ctx.r[9].s64 = (ctx.r[10].s32 as i64) * (ctx.r[30].s32 as i64);
	// 8315DE14: F86100E0  std r3, 0xe0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(224 as u32), ctx.r[3].u64 ) };
	// 8315DE18: C9A100E0  lfd f13, 0xe0(r1)
	ctx.f[13].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(224 as u32) ) };
	// 8315DE1C: 7D095850  subf r8, r9, r11
	ctx.r[8].s64 = ctx.r[11].s64 - ctx.r[9].s64;
	// 8315DE20: 7CC407B4  extsw r4, r6
	ctx.r[4].s64 = ctx.r[6].s32 as i64;
	// 8315DE24: 7D0707B4  extsw r7, r8
	ctx.r[7].s64 = ctx.r[8].s32 as i64;
	// 8315DE28: F88100D0  std r4, 0xd0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(208 as u32), ctx.r[4].u64 ) };
	// 8315DE2C: C80100D0  lfd f0, 0xd0(r1)
	ctx.f[0].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(208 as u32) ) };
	// 8315DE30: F8E100F0  std r7, 0xf0(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(240 as u32), ctx.r[7].u64 ) };
	// 8315DE34: C98100F0  lfd f12, 0xf0(r1)
	ctx.f[12].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(240 as u32) ) };
	// 8315DE38: FD20069C  fcfid f9, f0
	ctx.f[9].f64 = (ctx.f[0].s64 as f64);
	// 8315DE3C: FD60669C  fcfid f11, f12
	ctx.f[11].f64 = (ctx.f[12].s64 as f64);
	// 8315DE40: FD406E9C  fcfid f10, f13
	ctx.f[10].f64 = (ctx.f[13].s64 as f64);
	// 8315DE44: FCC04818  frsp f6, f9
	ctx.f[6].f64 = (ctx.f[9].f64 as f32) as f64;
	// 8315DE48: FD005818  frsp f8, f11
	ctx.f[8].f64 = (ctx.f[11].f64 as f32) as f64;
	// 8315DE4C: FCE05018  frsp f7, f10
	ctx.f[7].f64 = (ctx.f[10].f64 as f32) as f64;
	// 8315DE50: EC66F7FA  fmadds f3, f6, f31, f30
	ctx.f[3].f64 = (((ctx.f[6].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DE54: D077FF80  stfs f3, -0x80(r23)
	tmp.f32 = (ctx.f[3].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DE58: ECA8F7FA  fmadds f5, f8, f31, f30
	ctx.f[5].f64 = (((ctx.f[8].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DE5C: D0B70000  stfs f5, 0(r23)
	tmp.f32 = (ctx.f[5].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DE60: EC87F7FA  fmadds f4, f7, f31, f30
	ctx.f[4].f64 = (((ctx.f[7].f64 * ctx.f[31].f64 + ctx.f[30].f64) as f32) as f64);
	// 8315DE64: D097FF00  stfs f4, -0x100(r23)
	tmp.f32 = (ctx.f[4].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[23].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DE68: 48000010  b 0x8315de78
	pc = 0x8315DE78; continue 'dispatch;
	// 8315DE6C: D3BFFF00  stfs f29, -0x100(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-256 as u32), tmp.u32 ) };
	// 8315DE70: D3BFFF80  stfs f29, -0x80(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-128 as u32), tmp.u32 ) };
	// 8315DE74: D3BF0000  stfs f29, 0(r31)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DE78: 80810058  lwz r4, 0x58(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(88 as u32) ) } as u64;
	// 8315DE7C: 2F040002  cmpwi cr6, r4, 2
	ctx.cr[6].compare_i32(ctx.r[4].s32, 2, &mut ctx.xer);
	// 8315DE80: 409A0028  bne cr6, 0x8315dea8
	if !ctx.cr[6].eq {
	pc = 0x8315DEA8; continue 'dispatch;
	}
	// 8315DE84: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315DE88: 7F105800  cmpw cr6, r16, r11
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315DE8C: 4198001C  blt cr6, 0x8315dea8
	if ctx.cr[6].lt {
	pc = 0x8315DEA8; continue 'dispatch;
	}
	// 8315DE90: C012FF00  lfs f0, -0x100(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(-256 as u32) ) };
	ctx.f[0].f64 = (tmp.f32 as f64);
	// 8315DE94: C1B2FF80  lfs f13, -0x80(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(-128 as u32) ) };
	ctx.f[13].f64 = (tmp.f32 as f64);
	// 8315DE98: C1920000  lfs f12, 0(r18)
	tmp.u32 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[18].u32.wrapping_add(0 as u32) ) };
	ctx.f[12].f64 = (tmp.f32 as f64);
	// 8315DE9C: D0120080  stfs f0, 0x80(r18)
	tmp.f32 = (ctx.f[0].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(128 as u32), tmp.u32 ) };
	// 8315DEA0: D1B20100  stfs f13, 0x100(r18)
	tmp.f32 = (ctx.f[13].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(256 as u32), tmp.u32 ) };
	// 8315DEA4: D1920180  stfs f12, 0x180(r18)
	tmp.f32 = (ctx.f[12].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[18].u32.wrapping_add(384 as u32), tmp.u32 ) };
	// 8315DEA8: 81410060  lwz r10, 0x60(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(96 as u32) ) } as u64;
	// 8315DEAC: 3AB50001  addi r21, r21, 1
	ctx.r[21].s64 = ctx.r[21].s64 + 1;
	// 8315DEB0: 3A940080  addi r20, r20, 0x80
	ctx.r[20].s64 = ctx.r[20].s64 + 128;
	// 8315DEB4: 3B180180  addi r24, r24, 0x180
	ctx.r[24].s64 = ctx.r[24].s64 + 384;
	// 8315DEB8: 3AF70180  addi r23, r23, 0x180
	ctx.r[23].s64 = ctx.r[23].s64 + 384;
	// 8315DEBC: 3BFF0180  addi r31, r31, 0x180
	ctx.r[31].s64 = ctx.r[31].s64 + 384;
	// 8315DEC0: 4BFFFB74  b 0x8315da34
	pc = 0x8315DA34; continue 'dispatch;
	// 8315DEC4: 3A100001  addi r16, r16, 1
	ctx.r[16].s64 = ctx.r[16].s64 + 1;
	// 8315DEC8: 3A310010  addi r17, r17, 0x10
	ctx.r[17].s64 = ctx.r[17].s64 + 16;
	// 8315DECC: 39EF0004  addi r15, r15, 4
	ctx.r[15].s64 = ctx.r[15].s64 + 4;
	// 8315DED0: 39CE0004  addi r14, r14, 4
	ctx.r[14].s64 = ctx.r[14].s64 + 4;
	// 8315DED4: 3A520004  addi r18, r18, 4
	ctx.r[18].s64 = ctx.r[18].s64 + 4;
	// 8315DED8: 7F105000  cmpw cr6, r16, r10
	ctx.cr[6].compare_i32(ctx.r[16].s32, ctx.r[10].s32, &mut ctx.xer);
	// 8315DEDC: 4198FB44  blt cr6, 0x8315da20
	if ctx.cr[6].lt {
	pc = 0x8315DA20; continue 'dispatch;
	}
	// 8315DEE0: 810101EC  lwz r8, 0x1ec(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(492 as u32) ) } as u64;
	// 8315DEE4: 2F0A0020  cmpwi cr6, r10, 0x20
	ctx.cr[6].compare_i32(ctx.r[10].s32, 32, &mut ctx.xer);
	// 8315DEE8: 40980048  bge cr6, 0x8315df30
	if !ctx.cr[6].lt {
	pc = 0x8315DF30; continue 'dispatch;
	}
	// 8315DEEC: 554B103A  slwi r11, r10, 2
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(2);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315DEF0: 20EA0020  subfic r7, r10, 0x20
	ctx.xer.ca = ctx.r[10].u32 <= 32 as u32;
	ctx.r[7].s64 = (32 as i64) - ctx.r[10].s64;
	// 8315DEF4: 7D0B4214  add r8, r11, r8
	ctx.r[8].u64 = ctx.r[11].u64 + ctx.r[8].u64;
	// 8315DEF8: 2F040000  cmpwi cr6, r4, 0
	ctx.cr[6].compare_i32(ctx.r[4].s32, 0, &mut ctx.xer);
	// 8315DEFC: 40990028  ble cr6, 0x8315df24
	if !ctx.cr[6].gt {
	pc = 0x8315DF24; continue 'dispatch;
	}
	// 8315DF00: 7D0B4378  mr r11, r8
	ctx.r[11].u64 = ctx.r[8].u64;
	// 8315DF04: 7C892378  mr r9, r4
	ctx.r[9].u64 = ctx.r[4].u64;
	// 8315DF08: 7ECAB378  mr r10, r22
	ctx.r[10].u64 = ctx.r[22].u64;
	// 8315DF0C: D3AB0000  stfs f29, 0(r11)
	tmp.f32 = (ctx.f[29].f64 as f32);
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), tmp.u32 ) };
	// 8315DF10: 354AFFFF  addic. r10, r10, -1
	ctx.xer.ca = (ctx.r[10].u32 > (!(-1 as u32)));
	ctx.r[10].s64 = ctx.r[10].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315DF14: 396B0080  addi r11, r11, 0x80
	ctx.r[11].s64 = ctx.r[11].s64 + 128;
	// 8315DF18: 4082FFF4  bne 0x8315df0c
	if !ctx.cr[0].eq {
	pc = 0x8315DF0C; continue 'dispatch;
	}
	// 8315DF1C: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315DF20: 4082FFE8  bne 0x8315df08
	if !ctx.cr[0].eq {
	pc = 0x8315DF08; continue 'dispatch;
	}
	// 8315DF24: 34E7FFFF  addic. r7, r7, -1
	ctx.xer.ca = (ctx.r[7].u32 > (!(-1 as u32)));
	ctx.r[7].s64 = ctx.r[7].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8315DF28: 39080004  addi r8, r8, 4
	ctx.r[8].s64 = ctx.r[8].s64 + 4;
	// 8315DF2C: 4082FFCC  bne 0x8315def8
	if !ctx.cr[0].eq {
	pc = 0x8315DEF8; continue 'dispatch;
	}
	// 8315DF30: 382101B0  addi r1, r1, 0x1b0
	ctx.r[1].s64 = ctx.r[1].s64 + 432;
	// 8315DF34: CBA1FF50  lfd f29, -0xb0(r1)
	ctx.f[29].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-176 as u32) ) };
	// 8315DF38: CBC1FF58  lfd f30, -0xa8(r1)
	ctx.f[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-168 as u32) ) };
	// 8315DF3C: CBE1FF60  lfd f31, -0xa0(r1)
	ctx.f[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-160 as u32) ) };
	// 8315DF40: 4804A240  b 0x831a8180
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315DF48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315DF48 size=24
    let mut pc: u32 = 0x8315DF48;
    'dispatch: loop {
        match pc {
            0x8315DF48 => {
    //   block [0x8315DF48..0x8315DF60)
	// 8315DF48: 3D408339  lis r10, -0x7cc7
	ctx.r[10].s64 = -2093416448;
	// 8315DF4C: 816A7F98  lwz r11, 0x7f98(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(32664 as u32) ) } as u64;
	// 8315DF50: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8315DF54: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315DF58: 916A7F98  stw r11, 0x7f98(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32664 as u32), ctx.r[11].u32 ) };
	// 8315DF5C: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315DF60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315DF60 size=20
    let mut pc: u32 = 0x8315DF60;
    'dispatch: loop {
        match pc {
            0x8315DF60 => {
    //   block [0x8315DF60..0x8315DF74)
	// 8315DF60: 3D008339  lis r8, -0x7cc7
	ctx.r[8].s64 = -2093416448;
	// 8315DF64: 81287F84  lwz r9, 0x7f84(r8)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(32644 as u32) ) } as u64;
	// 8315DF68: 3529FFFF  addic. r9, r9, -1
	ctx.xer.ca = (ctx.r[9].u32 > (!(-1 as u32)));
	ctx.r[9].s64 = ctx.r[9].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315DF6C: 91287F84  stw r9, 0x7f84(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(32644 as u32), ctx.r[9].u32 ) };
	// 8315DF70: 4C820020  bnelr
	if !ctx.cr[0].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315DF74(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315DF74 size=20
    let mut pc: u32 = 0x8315DF74;
    'dispatch: loop {
        match pc {
            0x8315DF74 => {
    //   block [0x8315DF74..0x8315DF88)
	// 8315DF74: 3D208339  lis r9, -0x7cc7
	ctx.r[9].s64 = -2093416448;
	// 8315DF78: 81697F90  lwz r11, 0x7f90(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(32656 as u32) ) } as u64;
	// 8315DF7C: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315DF80: 91697F90  stw r11, 0x7f90(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(32656 as u32), ctx.r[11].u32 ) };
	// 8315DF84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315DF88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315DF88 size=332
    let mut pc: u32 = 0x8315DF88;
    'dispatch: loop {
        match pc {
            0x8315DF88 => {
    //   block [0x8315DF88..0x8315E0D4)
	// 8315DF88: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315DF8C: 4804A1D5  bl 0x831a8160
	ctx.lr = 0x8315DF90;
	sub_831A8130(ctx, base);
	// 8315DF90: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315DF94: 39660007  addi r11, r6, 7
	ctx.r[11].s64 = ctx.r[6].s64 + 7;
	// 8315DF98: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8315DF9C: 557F0038  rlwinm r31, r11, 0, 0, 0x1c
	ctx.r[31].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8315DFA0: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8315DFA4: 7CBA2B78  mr r26, r5
	ctx.r[26].u64 = ctx.r[5].u64;
	// 8315DFA8: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 8315DFAC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315DFB0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315DFB4: 7FA63A14  add r29, r6, r7
	ctx.r[29].u64 = ctx.r[6].u64 + ctx.r[7].u64;
	// 8315DFB8: 4804A229  bl 0x831a81e0
	ctx.lr = 0x8315DFBC;
	sub_831A81E0(ctx, base);
	// 8315DFBC: 395F005B  addi r10, r31, 0x5b
	ctx.r[10].s64 = ctx.r[31].s64 + 91;
	// 8315DFC0: 555E0038  rlwinm r30, r10, 0, 0, 0x1c
	ctx.r[30].u64 = ctx.r[10].u32 as u64 & 0xFFFFFFFFu64;
	// 8315DFC4: 393E0034  addi r9, r30, 0x34
	ctx.r[9].s64 = ctx.r[30].s64 + 52;
	// 8315DFC8: 7F09E840  cmplw cr6, r9, r29
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8315DFCC: 41990064  bgt cr6, 0x8315e030
	if ctx.cr[6].gt {
	pc = 0x8315E030; continue 'dispatch;
	}
	// 8315DFD0: 38A00034  li r5, 0x34
	ctx.r[5].s64 = 52;
	// 8315DFD4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315DFD8: 7F63DB78  mr r3, r27
	ctx.r[3].u64 = ctx.r[27].u64;
	// 8315DFDC: 4BFFC655  bl 0x8315a630
	ctx.lr = 0x8315DFE0;
	sub_8315A630(ctx, base);
	// 8315DFE0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315DFE4: 907F0004  stw r3, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[3].u32 ) };
	// 8315DFE8: 419A0048  beq cr6, 0x8315e030
	if ctx.cr[6].eq {
	pc = 0x8315E030; continue 'dispatch;
	}
	// 8315DFEC: 397E003B  addi r11, r30, 0x3b
	ctx.r[11].s64 = ctx.r[30].s64 + 59;
	// 8315DFF0: 556B0038  rlwinm r11, r11, 0, 0, 0x1c
	ctx.r[11].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8315DFF4: 394B1BF0  addi r10, r11, 0x1bf0
	ctx.r[10].s64 = ctx.r[11].s64 + 7152;
	// 8315DFF8: 7F0AE840  cmplw cr6, r10, r29
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[29].u32, &mut ctx.xer);
	// 8315DFFC: 41990028  bgt cr6, 0x8315e024
	if ctx.cr[6].gt {
	pc = 0x8315E024; continue 'dispatch;
	}
	// 8315E000: 38801BF0  li r4, 0x1bf0
	ctx.r[4].s64 = 7152;
	// 8315E004: 7D635B78  mr r3, r11
	ctx.r[3].u64 = ctx.r[11].u64;
	// 8315E008: 4BFFEE39  bl 0x8315ce40
	ctx.lr = 0x8315E00C;
	sub_8315CE40(ctx, base);
	// 8315E00C: 907F0000  stw r3, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[3].u32 ) };
	// 8315E010: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E014: 409A0028  bne cr6, 0x8315e03c
	if !ctx.cr[6].eq {
	pc = 0x8315E03C; continue 'dispatch;
	}
	// 8315E018: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E01C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E020: 419A0010  beq cr6, 0x8315e030
	if ctx.cr[6].eq {
	pc = 0x8315E030; continue 'dispatch;
	}
	// 8315E024: 38A0002C  li r5, 0x2c
	ctx.r[5].s64 = 44;
	// 8315E028: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E02C: 4804A1B5  bl 0x831a81e0
	ctx.lr = 0x8315E030;
	sub_831A81E0(ctx, base);
	// 8315E030: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315E034: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8315E038: 4804A178  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
	// 8315E03C: 937F0010  stw r27, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[27].u32 ) };
	// 8315E040: 2F1C0000  cmpwi cr6, r28, 0
	ctx.cr[6].compare_i32(ctx.r[28].s32, 0, &mut ctx.xer);
	// 8315E044: 9B9F000A  stb r28, 0xa(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(10 as u32), ctx.r[28].u8 ) };
	// 8315E048: 40990028  ble cr6, 0x8315e070
	if !ctx.cr[6].gt {
	pc = 0x8315E070; continue 'dispatch;
	}
	// 8315E04C: 7F4AD378  mr r10, r26
	ctx.r[10].u64 = ctx.r[26].u64;
	// 8315E050: 393F0014  addi r9, r31, 0x14
	ctx.r[9].s64 = ctx.r[31].s64 + 20;
	// 8315E054: 7F8BE378  mr r11, r28
	ctx.r[11].u64 = ctx.r[28].u64;
	// 8315E058: 810A0000  lwz r8, 0(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E05C: 356BFFFF  addic. r11, r11, -1
	ctx.xer.ca = (ctx.r[11].u32 > (!(-1 as u32)));
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315E060: 394A0004  addi r10, r10, 4
	ctx.r[10].s64 = ctx.r[10].s64 + 4;
	// 8315E064: 91090000  stw r8, 0(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8315E068: 39290004  addi r9, r9, 4
	ctx.r[9].s64 = ctx.r[9].s64 + 4;
	// 8315E06C: 4082FFEC  bne 0x8315e058
	if !ctx.cr[0].eq {
	pc = 0x8315E058; continue 'dispatch;
	}
	// 8315E070: 3D407FFF  lis r10, 0x7fff
	ctx.r[10].s64 = 2147418112;
	// 8315E074: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315E078: 6149FFFF  ori r9, r10, 0xffff
	ctx.r[9].u64 = ctx.r[10].u64 | 65535;
	// 8315E07C: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8315E080: 997F0009  stb r11, 9(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(9 as u32), ctx.r[11].u8 ) };
	// 8315E084: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8315E088: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315E08C: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8315E090: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315E094: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 8315E098: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8315E09C: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 8315E0A0: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 8315E0A4: 913F0030  stw r9, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[9].u32 ) };
	// 8315E0A8: 911F0034  stw r8, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[8].u32 ) };
	// 8315E0AC: 917F0038  stw r11, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[11].u32 ) };
	// 8315E0B0: 917F003C  stw r11, 0x3c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), ctx.r[11].u32 ) };
	// 8315E0B4: 997F000B  stb r11, 0xb(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(11 as u32), ctx.r[11].u8 ) };
	// 8315E0B8: 917F0044  stw r11, 0x44(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(68 as u32), ctx.r[11].u32 ) };
	// 8315E0BC: 917F0048  stw r11, 0x48(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(72 as u32), ctx.r[11].u32 ) };
	// 8315E0C0: 917F004C  stw r11, 0x4c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(76 as u32), ctx.r[11].u32 ) };
	// 8315E0C4: 917F0050  stw r11, 0x50(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(80 as u32), ctx.r[11].u32 ) };
	// 8315E0C8: 98FF0008  stb r7, 8(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[7].u8 ) };
	// 8315E0CC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8315E0D0: 4804A0E0  b 0x831a81b0
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E0D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E0D8 size=124
    let mut pc: u32 = 0x8315E0D8;
    'dispatch: loop {
        match pc {
            0x8315E0D8 => {
    //   block [0x8315E0D8..0x8315E154)
	// 8315E0D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E0DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E0E0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315E0E4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315E0E8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E0EC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E0F0: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315E0F4: 419A0048  beq cr6, 0x8315e13c
	if ctx.cr[6].eq {
	pc = 0x8315E13C; continue 'dispatch;
	}
	// 8315E0F8: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E0FC: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315E100: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E104: 419A0014  beq cr6, 0x8315e118
	if ctx.cr[6].eq {
	pc = 0x8315E118; continue 'dispatch;
	}
	// 8315E108: 38A0002C  li r5, 0x2c
	ctx.r[5].s64 = 44;
	// 8315E10C: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8315E110: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E114: 4804A0CD  bl 0x831a81e0
	ctx.lr = 0x8315E118;
	sub_831A81E0(ctx, base);
	// 8315E118: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E11C: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E120: 419A000C  beq cr6, 0x8315e12c
	if ctx.cr[6].eq {
	pc = 0x8315E12C; continue 'dispatch;
	}
	// 8315E124: 93DF0000  stw r30, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8315E128: 4BFFEDE1  bl 0x8315cf08
	ctx.lr = 0x8315E12C;
	sub_8315CF08(ctx, base);
	// 8315E12C: 38A00054  li r5, 0x54
	ctx.r[5].s64 = 84;
	// 8315E130: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E134: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315E138: 4804A0A9  bl 0x831a81e0
	ctx.lr = 0x8315E13C;
	sub_831A81E0(ctx, base);
	// 8315E13C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E140: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E144: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E148: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315E14C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E150: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E158(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E158 size=124
    let mut pc: u32 = 0x8315E158;
    'dispatch: loop {
        match pc {
            0x8315E158 => {
    //   block [0x8315E158..0x8315E1D4)
	// 8315E158: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E15C: 4804A011  bl 0x831a816c
	ctx.lr = 0x8315E160;
	sub_831A8130(ctx, base);
	// 8315E160: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E164: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E168: 3D407FFF  lis r10, 0x7fff
	ctx.r[10].s64 = 2147418112;
	// 8315E16C: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315E170: 6149FFFF  ori r9, r10, 0xffff
	ctx.r[9].u64 = ctx.r[10].u64 | 65535;
	// 8315E174: 3900FFFF  li r8, -1
	ctx.r[8].s64 = -1;
	// 8315E178: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315E17C: 917F001C  stw r11, 0x1c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(28 as u32), ctx.r[11].u32 ) };
	// 8315E180: 917F0020  stw r11, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[11].u32 ) };
	// 8315E184: 917F0024  stw r11, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[11].u32 ) };
	// 8315E188: 917F0028  stw r11, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[11].u32 ) };
	// 8315E18C: 917F002C  stw r11, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[11].u32 ) };
	// 8315E190: 913F0030  stw r9, 0x30(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(48 as u32), ctx.r[9].u32 ) };
	// 8315E194: 911F0034  stw r8, 0x34(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(52 as u32), ctx.r[8].u32 ) };
	// 8315E198: 917F0038  stw r11, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[11].u32 ) };
	// 8315E19C: 917F003C  stw r11, 0x3c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(60 as u32), ctx.r[11].u32 ) };
	// 8315E1A0: 997F000B  stb r11, 0xb(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(11 as u32), ctx.r[11].u8 ) };
	// 8315E1A4: 809F0010  lwz r4, 0x10(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315E1A8: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E1AC: 4BFFC53D  bl 0x8315a6e8
	ctx.lr = 0x8315E1B0;
	sub_8315A6E8(ctx, base);
	// 8315E1B0: 83DF0000  lwz r30, 0(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E1B4: 83BF0004  lwz r29, 4(r31)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E1B8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315E1BC: 4BFFEDA5  bl 0x8315cf60
	ctx.lr = 0x8315E1C0;
	sub_8315CF60(ctx, base);
	// 8315E1C0: 38E00001  li r7, 1
	ctx.r[7].s64 = 1;
	// 8315E1C4: 93BE0350  stw r29, 0x350(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(848 as u32), ctx.r[29].u32 ) };
	// 8315E1C8: 98FF0009  stb r7, 9(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(9 as u32), ctx.r[7].u8 ) };
	// 8315E1CC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E1D0: 48049FEC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E1D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E1D8 size=56
    let mut pc: u32 = 0x8315E1D8;
    'dispatch: loop {
        match pc {
            0x8315E1D8 => {
    //   block [0x8315E1D8..0x8315E210)
	// 8315E1D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E1DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E1E0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315E1E4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E1E8: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E1EC: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E1F0: 4BFFED71  bl 0x8315cf60
	ctx.lr = 0x8315E1F4;
	sub_8315CF60(ctx, base);
	// 8315E1F4: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315E1F8: 997F0009  stb r11, 9(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(9 as u32), ctx.r[11].u8 ) };
	// 8315E1FC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E200: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E204: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E208: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E20C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E210(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E210 size=200
    let mut pc: u32 = 0x8315E210;
    'dispatch: loop {
        match pc {
            0x8315E210 => {
    //   block [0x8315E210..0x8315E2D8)
	// 8315E210: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E214: 48049F59  bl 0x831a816c
	ctx.lr = 0x8315E218;
	sub_831A8130(ctx, base);
	// 8315E218: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E21C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E220: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E224: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E228: 409A0010  bne cr6, 0x8315e238
	if !ctx.cr[6].eq {
	pc = 0x8315E238; continue 'dispatch;
	}
	// 8315E22C: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315E230: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E234: 48049F88  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315E238: 4BFFEAF1  bl 0x8315cd28
	ctx.lr = 0x8315E23C;
	sub_8315CD28(ctx, base);
	// 8315E23C: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 8315E240: 419AFFEC  beq cr6, 0x8315e22c
	if ctx.cr[6].eq {
	pc = 0x8315E22C; continue 'dispatch;
	}
	// 8315E244: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315E248: 419A0010  beq cr6, 0x8315e258
	if ctx.cr[6].eq {
	pc = 0x8315E258; continue 'dispatch;
	}
	// 8315E24C: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315E250: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E254: 48049F68  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315E258: 38800014  li r4, 0x14
	ctx.r[4].s64 = 20;
	// 8315E25C: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E260: 4BFFE9D1  bl 0x8315cc30
	ctx.lr = 0x8315E264;
	sub_8315CC30(ctx, base);
	// 8315E264: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315E268: 419AFFC4  beq cr6, 0x8315e22c
	if ctx.cr[6].eq {
	pc = 0x8315E22C; continue 'dispatch;
	}
	// 8315E26C: 3BBF0358  addi r29, r31, 0x358
	ctx.r[29].s64 = ctx.r[31].s64 + 856;
	// 8315E270: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E274: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315E278: 4BFFEF59  bl 0x8315d1d0
	ctx.lr = 0x8315E27C;
	sub_8315D1D0(ctx, base);
	// 8315E27C: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315E280: 4198FFAC  blt cr6, 0x8315e22c
	if ctx.cr[6].lt {
	pc = 0x8315E22C; continue 'dispatch;
	}
	// 8315E284: 3BDF0388  addi r30, r31, 0x388
	ctx.r[30].s64 = ctx.r[31].s64 + 904;
	// 8315E288: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315E28C: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315E290: 4BFFC561  bl 0x8315a7f0
	ctx.lr = 0x8315E294;
	sub_8315A7F0(ctx, base);
	// 8315E294: 3BBF03C4  addi r29, r31, 0x3c4
	ctx.r[29].s64 = ctx.r[31].s64 + 964;
	// 8315E298: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315E29C: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E2A0: 4BFFF051  bl 0x8315d2f0
	ctx.lr = 0x8315E2A4;
	sub_8315D2F0(ctx, base);
	// 8315E2A4: 38FF05C4  addi r7, r31, 0x5c4
	ctx.r[7].s64 = ctx.r[31].s64 + 1476;
	// 8315E2A8: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E2AC: 38DF04C4  addi r6, r31, 0x4c4
	ctx.r[6].s64 = ctx.r[31].s64 + 1220;
	// 8315E2B0: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315E2B4: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315E2B8: 4BFFF201  bl 0x8315d4b8
	ctx.lr = 0x8315E2BC;
	sub_8315D4B8(ctx, base);
	// 8315E2BC: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315E2C0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315E2C4: 997F0349  stb r11, 0x349(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(841 as u32), ctx.r[11].u8 ) };
	// 8315E2C8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315E2CC: 915F034C  stw r10, 0x34c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(844 as u32), ctx.r[10].u32 ) };
	// 8315E2D0: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E2D4: 48049EE8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E2D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E2D8 size=140
    let mut pc: u32 = 0x8315E2D8;
    'dispatch: loop {
        match pc {
            0x8315E2D8 => {
    //   block [0x8315E2D8..0x8315E364)
	// 8315E2D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E2DC: 48049E91  bl 0x831a816c
	ctx.lr = 0x8315E2E0;
	sub_831A8130(ctx, base);
	// 8315E2E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E2E4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E2E8: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315E2EC: 817F034C  lwz r11, 0x34c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(844 as u32) ) } as u64;
	// 8315E2F0: 2F0B000C  cmpwi cr6, r11, 0xc
	ctx.cr[6].compare_i32(ctx.r[11].s32, 12, &mut ctx.xer);
	// 8315E2F4: 409A0010  bne cr6, 0x8315e304
	if !ctx.cr[6].eq {
	pc = 0x8315E304; continue 'dispatch;
	}
	// 8315E2F8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315E2FC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E300: 48049EBC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315E304: 7D671670  srawi r7, r11, 2
	ctx.xer.ca = (ctx.r[11].s32 < 0) && ((ctx.r[11].u32 & ((1u32 << 2) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[11].s32 >> 2) as i64;
	// 8315E308: 813F0344  lwz r9, 0x344(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(836 as u32) ) } as u64;
	// 8315E30C: 38DF05C4  addi r6, r31, 0x5c4
	ctx.r[6].s64 = ctx.r[31].s64 + 1476;
	// 8315E310: 811F0000  lwz r8, 0(r31)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E314: 38BF03C4  addi r5, r31, 0x3c4
	ctx.r[5].s64 = ctx.r[31].s64 + 964;
	// 8315E318: 807F0350  lwz r3, 0x350(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(848 as u32) ) } as u64;
	// 8315E31C: 389F0388  addi r4, r31, 0x388
	ctx.r[4].s64 = ctx.r[31].s64 + 904;
	// 8315E320: 4BFFF661  bl 0x8315d980
	ctx.lr = 0x8315E324;
	sub_8315D980(ctx, base);
	// 8315E324: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315E328: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E32C: 7CDEEA14  add r6, r30, r29
	ctx.r[6].u64 = ctx.r[30].u64 + ctx.r[29].u64;
	// 8315E330: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315E334: 807F0354  lwz r3, 0x354(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(852 as u32) ) } as u64;
	// 8315E338: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8315E33C: 4BFFE5D5  bl 0x8315c910
	ctx.lr = 0x8315E340;
	sub_8315C910(ctx, base);
	// 8315E340: 3BDE0080  addi r30, r30, 0x80
	ctx.r[30].s64 = ctx.r[30].s64 + 128;
	// 8315E344: 2F1E0180  cmpwi cr6, r30, 0x180
	ctx.cr[6].compare_i32(ctx.r[30].s32, 384, &mut ctx.xer);
	// 8315E348: 4198FFE0  blt cr6, 0x8315e328
	if ctx.cr[6].lt {
	pc = 0x8315E328; continue 'dispatch;
	}
	// 8315E34C: 817F034C  lwz r11, 0x34c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(844 as u32) ) } as u64;
	// 8315E350: 38600060  li r3, 0x60
	ctx.r[3].s64 = 96;
	// 8315E354: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315E358: 917F034C  stw r11, 0x34c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(844 as u32), ctx.r[11].u32 ) };
	// 8315E35C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E360: 48049E5C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E368(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E368 size=260
    let mut pc: u32 = 0x8315E368;
    'dispatch: loop {
        match pc {
            0x8315E368 => {
    //   block [0x8315E368..0x8315E46C)
	// 8315E368: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E36C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E370: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315E374: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E378: 3FE08339  lis r31, -0x7cc7
	ctx.r[31].s64 = -2093416448;
	// 8315E37C: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 8315E380: 817F7F98  lwz r11, 0x7f98(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32664 as u32) ) } as u64;
	// 8315E384: 812A5D7C  lwz r9, 0x5d7c(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(23932 as u32) ) } as u64;
	// 8315E388: 810A5D7C  lwz r8, 0x5d7c(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(23932 as u32) ) } as u64;
	// 8315E38C: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315E390: 409A00C0  bne cr6, 0x8315e450
	if !ctx.cr[6].eq {
	pc = 0x8315E450; continue 'dispatch;
	}
	// 8315E394: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 8315E398: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8315E39C: 480003F5  bl 0x8315e790
	ctx.lr = 0x8315E3A0;
	sub_8315E790(ctx, base);
	// 8315E3A0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E3A4: 3D408339  lis r10, -0x7cc7
	ctx.r[10].s64 = -2093416448;
	// 8315E3A8: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 8315E3AC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8315E3B0: 916A7F7C  stw r11, 0x7f7c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(32636 as u32), ctx.r[11].u32 ) };
	// 8315E3B4: 4800040D  bl 0x8315e7c0
	ctx.lr = 0x8315E3B8;
	sub_8315E7C0(ctx, base);
	// 8315E3B8: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E3BC: 3D208339  lis r9, -0x7cc7
	ctx.r[9].s64 = -2093416448;
	// 8315E3C0: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 8315E3C4: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8315E3C8: 91697F80  stw r11, 0x7f80(r9)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[9].u32.wrapping_add(32640 as u32), ctx.r[11].u32 ) };
	// 8315E3CC: 48000425  bl 0x8315e7f0
	ctx.lr = 0x8315E3D0;
	sub_8315E7F0(ctx, base);
	// 8315E3D0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E3D4: 3D008339  lis r8, -0x7cc7
	ctx.r[8].s64 = -2093416448;
	// 8315E3D8: 38810054  addi r4, r1, 0x54
	ctx.r[4].s64 = ctx.r[1].s64 + 84;
	// 8315E3DC: 38610050  addi r3, r1, 0x50
	ctx.r[3].s64 = ctx.r[1].s64 + 80;
	// 8315E3E0: 91687F74  stw r11, 0x7f74(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(32628 as u32), ctx.r[11].u32 ) };
	// 8315E3E4: 4800043D  bl 0x8315e820
	ctx.lr = 0x8315E3E8;
	sub_8315E820(ctx, base);
	// 8315E3E8: 3C808339  lis r4, -0x7cc7
	ctx.r[4].s64 = -2093416448;
	// 8315E3EC: 81410050  lwz r10, 0x50(r1)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E3F0: 3CE08339  lis r7, -0x7cc7
	ctx.r[7].s64 = -2093416448;
	// 8315E3F4: 81647F84  lwz r11, 0x7f84(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(32644 as u32) ) } as u64;
	// 8315E3F8: 91477F70  stw r10, 0x7f70(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(32624 as u32), ctx.r[10].u32 ) };
	// 8315E3FC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315E400: 409A0028  bne cr6, 0x8315e428
	if !ctx.cr[6].eq {
	pc = 0x8315E428; continue 'dispatch;
	}
	// 8315E404: 3C608339  lis r3, -0x7cc7
	ctx.r[3].s64 = -2093416448;
	// 8315E408: 81437F90  lwz r10, 0x7f90(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32656 as u32) ) } as u64;
	// 8315E40C: 2F0A0000  cmpwi cr6, r10, 0
	ctx.cr[6].compare_i32(ctx.r[10].s32, 0, &mut ctx.xer);
	// 8315E410: 409A0010  bne cr6, 0x8315e420
	if !ctx.cr[6].eq {
	pc = 0x8315E420; continue 'dispatch;
	}
	// 8315E414: 4BFFE3ED  bl 0x8315c800
	ctx.lr = 0x8315E418;
	sub_8315C800(ctx, base);
	// 8315E418: 81647F84  lwz r11, 0x7f84(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(32644 as u32) ) } as u64;
	// 8315E41C: 81437F90  lwz r10, 0x7f90(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(32656 as u32) ) } as u64;
	// 8315E420: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8315E424: 91437F90  stw r10, 0x7f90(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(32656 as u32), ctx.r[10].u32 ) };
	// 8315E428: 815F7F98  lwz r10, 0x7f98(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32664 as u32) ) } as u64;
	// 8315E42C: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315E430: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8315E434: 91647F84  stw r11, 0x7f84(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(32644 as u32), ctx.r[11].u32 ) };
	// 8315E438: 915F7F98  stw r10, 0x7f98(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32664 as u32), ctx.r[10].u32 ) };
	// 8315E43C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E440: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E444: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E448: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E44C: 4E800020  blr
	return;
	// 8315E450: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315E454: 917F7F98  stw r11, 0x7f98(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32664 as u32), ctx.r[11].u32 ) };
	// 8315E458: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315E45C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E460: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E464: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E468: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E470(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    let mut ea: u32 = 0;
    // ---- function 0x8315E470 size=644
    let mut pc: u32 = 0x8315E470;
    'dispatch: loop {
        match pc {
            0x8315E470 => {
    //   block [0x8315E470..0x8315E6F4)
	// 8315E470: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E474: 48049CF1  bl 0x831a8164
	ctx.lr = 0x8315E478;
	sub_831A8130(ctx, base);
	// 8315E478: 9421FF70  stwu r1, -0x90(r1)
	ea = ctx.r[1].u32.wrapping_add(-144 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E47C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E480: 897F000B  lbz r11, 0xb(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(11 as u32) ) } as u64;
	// 8315E484: 83DF0000  lwz r30, 0(r31)
	ctx.r[30].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E488: 807F0010  lwz r3, 0x10(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315E48C: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8315E490: 409A0030  bne cr6, 0x8315e4c0
	if !ctx.cr[6].eq {
	pc = 0x8315E4C0; continue 'dispatch;
	}
	// 8315E494: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E498: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315E49C: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315E4A0: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315E4A4: 4E800421  bctrl
	ctx.lr = 0x8315E4A8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E4A8: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315E4AC: 409A0014  bne cr6, 0x8315e4c0
	if !ctx.cr[6].eq {
	pc = 0x8315E4C0; continue 'dispatch;
	}
	// 8315E4B0: 807F0004  lwz r3, 4(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E4B4: 4BFFC2D5  bl 0x8315a788
	ctx.lr = 0x8315E4B8;
	sub_8315A788(ctx, base);
	// 8315E4B8: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315E4BC: 419A0228  beq cr6, 0x8315e6e4
	if ctx.cr[6].eq {
	pc = 0x8315E6E4; continue 'dispatch;
	}
	// 8315E4C0: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E4C4: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E4C8: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315E4CC: 894B034B  lbz r10, 0x34b(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(843 as u32) ) } as u64;
	// 8315E4D0: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E4D4: 7D480774  extsb r8, r10
	ctx.r[8].s64 = ctx.r[10].s8 as i64;
	// 8315E4D8: 7D071E70  srawi r7, r8, 3
	ctx.xer.ca = (ctx.r[8].s32 < 0) && ((ctx.r[8].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[7].s64 = (ctx.r[8].s32 >> 3) as i64;
	// 8315E4DC: 80C90024  lwz r6, 0x24(r9)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315E4E0: 7F870194  addze r28, r7
	tmp.s64 = ctx.r[7].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[7].u32);
	ctx.r[28].s64 = tmp.s64;
	// 8315E4E4: 7CC903A6  mtctr r6
	ctx.ctr.u64 = ctx.r[6].u64;
	// 8315E4E8: 4E800421  bctrl
	ctx.lr = 0x8315E4EC;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E4EC: 7CA3E3D6  divw r5, r3, r28
	ctx.r[5].s32 = ctx.r[3].s32 / ctx.r[28].s32;
	// 8315E4F0: 2F050060  cmpwi cr6, r5, 0x60
	ctx.cr[6].compare_i32(ctx.r[5].s32, 96, &mut ctx.xer);
	// 8315E4F4: 419801F8  blt cr6, 0x8315e6ec
	if ctx.cr[6].lt {
	pc = 0x8315E6EC; continue 'dispatch;
	}
	// 8315E4F8: 817E034C  lwz r11, 0x34c(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(844 as u32) ) } as u64;
	// 8315E4FC: 2F0B000C  cmpwi cr6, r11, 0xc
	ctx.cr[6].compare_i32(ctx.r[11].s32, 12, &mut ctx.xer);
	// 8315E500: 409A001C  bne cr6, 0x8315e51c
	if !ctx.cr[6].eq {
	pc = 0x8315E51C; continue 'dispatch;
	}
	// 8315E504: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315E508: 4BFFFD09  bl 0x8315e210
	ctx.lr = 0x8315E50C;
	sub_8315E210(ctx, base);
	// 8315E50C: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315E510: 419A01D4  beq cr6, 0x8315e6e4
	if ctx.cr[6].eq {
	pc = 0x8315E6E4; continue 'dispatch;
	}
	// 8315E514: 2F03FFFF  cmpwi cr6, r3, -1
	ctx.cr[6].compare_i32(ctx.r[3].s32, -1, &mut ctx.xer);
	// 8315E518: 419A01D4  beq cr6, 0x8315e6ec
	if ctx.cr[6].eq {
	pc = 0x8315E6EC; continue 'dispatch;
	}
	// 8315E51C: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315E520: 578B083C  slwi r11, r28, 1
	ctx.r[11].u32 = ctx.r[28].u32.wrapping_shl(1);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315E524: 38C10050  addi r6, r1, 0x50
	ctx.r[6].s64 = ctx.r[1].s64 + 80;
	// 8315E528: 7D7C5A14  add r11, r28, r11
	ctx.r[11].u64 = ctx.r[28].u64 + ctx.r[11].u64;
	// 8315E52C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E530: 55652834  slwi r5, r11, 5
	ctx.r[5].u32 = ctx.r[11].u32.wrapping_shl(5);
	ctx.r[5].u64 = ctx.r[5].u32 as u64;
	// 8315E534: 81430000  lwz r10, 0(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E538: 812A0018  lwz r9, 0x18(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315E53C: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315E540: 4E800421  bctrl
	ctx.lr = 0x8315E544;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E544: 81010054  lwz r8, 0x54(r1)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8315E548: 7CE8E3D6  divw r7, r8, r28
	ctx.r[7].s32 = ctx.r[8].s32 / ctx.r[28].s32;
	// 8315E54C: 2F070060  cmpwi cr6, r7, 0x60
	ctx.cr[6].compare_i32(ctx.r[7].s32, 96, &mut ctx.xer);
	// 8315E550: 419A0028  beq cr6, 0x8315e578
	if ctx.cr[6].eq {
	pc = 0x8315E578; continue 'dispatch;
	}
	// 8315E554: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315E558: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315E55C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E560: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E564: 814B001C  lwz r10, 0x1c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315E568: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315E56C: 4E800421  bctrl
	ctx.lr = 0x8315E570;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E570: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8315E574: 48049C40  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 8315E578: 38C00060  li r6, 0x60
	ctx.r[6].s64 = 96;
	// 8315E57C: 80810050  lwz r4, 0x50(r1)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E580: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315E584: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315E588: 4BFFFD51  bl 0x8315e2d8
	ctx.lr = 0x8315E58C;
	sub_8315E2D8(ctx, base);
	// 8315E58C: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315E590: 7C7D1B78  mr r29, r3
	ctx.r[29].u64 = ctx.r[3].u64;
	// 8315E594: 2F0B01E0  cmpwi cr6, r11, 0x1e0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 480, &mut ctx.xer);
	// 8315E598: 3BC00000  li r30, 0
	ctx.r[30].s64 = 0;
	// 8315E59C: 41980008  blt cr6, 0x8315e5a4
	if ctx.cr[6].lt {
	pc = 0x8315E5A4; continue 'dispatch;
	}
	// 8315E5A0: 7FBEEB78  mr r30, r29
	ctx.r[30].u64 = ctx.r[29].u64;
	// 8315E5A4: 817F0000  lwz r11, 0(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E5A8: 3B600000  li r27, 0
	ctx.r[27].s64 = 0;
	// 8315E5AC: 894B0349  lbz r10, 0x349(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(841 as u32) ) } as u64;
	// 8315E5B0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315E5B4: 419A0008  beq cr6, 0x8315e5bc
	if ctx.cr[6].eq {
	pc = 0x8315E5BC; continue 'dispatch;
	}
	// 8315E5B8: 836B0394  lwz r27, 0x394(r11)
	ctx.r[27].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(916 as u32) ) } as u64;
	// 8315E5BC: 817F0028  lwz r11, 0x28(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315E5C0: 7D4BF214  add r10, r11, r30
	ctx.r[10].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8315E5C4: 7F0AD800  cmpw cr6, r10, r27
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[27].s32, &mut ctx.xer);
	// 8315E5C8: 40990008  ble cr6, 0x8315e5d0
	if !ctx.cr[6].gt {
	pc = 0x8315E5D0; continue 'dispatch;
	}
	// 8315E5CC: 7FCBD850  subf r30, r11, r27
	ctx.r[30].s64 = ctx.r[27].s64 - ctx.r[11].s64;
	// 8315E5D0: 80C10054  lwz r6, 0x54(r1)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(84 as u32) ) } as u64;
	// 8315E5D4: 7D7EE1D6  mullw r11, r30, r28
	ctx.r[11].s64 = (ctx.r[30].s32 as i64) * (ctx.r[28].s32 as i64);
	// 8315E5D8: 7CCA3378  mr r10, r6
	ctx.r[10].u64 = ctx.r[6].u64;
	// 8315E5DC: 7F065800  cmpw cr6, r6, r11
	ctx.cr[6].compare_i32(ctx.r[6].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315E5E0: 4099000C  ble cr6, 0x8315e5ec
	if !ctx.cr[6].gt {
	pc = 0x8315E5EC; continue 'dispatch;
	}
	// 8315E5E4: 7D665B78  mr r6, r11
	ctx.r[6].u64 = ctx.r[11].u64;
	// 8315E5E8: 90C10054  stw r6, 0x54(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(84 as u32), ctx.r[6].u32 ) };
	// 8315E5EC: 7D665051  subf. r11, r6, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[6].s64;
	ctx.cr[0].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315E5F0: 80A10050  lwz r5, 0x50(r1)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E5F4: 9161005C  stw r11, 0x5c(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(92 as u32), ctx.r[11].u32 ) };
	// 8315E5F8: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315E5FC: 41820008  beq 0x8315e604
	if ctx.cr[0].eq {
	pc = 0x8315E604; continue 'dispatch;
	}
	// 8315E600: 7D653214  add r11, r5, r6
	ctx.r[11].u64 = ctx.r[5].u64 + ctx.r[6].u64;
	// 8315E604: 91610058  stw r11, 0x58(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(88 as u32), ctx.r[11].u32 ) };
	// 8315E608: 817F004C  lwz r11, 0x4c(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(76 as u32) ) } as u64;
	// 8315E60C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315E610: 419A001C  beq cr6, 0x8315e62c
	if ctx.cr[6].eq {
	pc = 0x8315E62C; continue 'dispatch;
	}
	// 8315E614: 2F1E0000  cmpwi cr6, r30, 0
	ctx.cr[6].compare_i32(ctx.r[30].s32, 0, &mut ctx.xer);
	// 8315E618: 40990014  ble cr6, 0x8315e62c
	if !ctx.cr[6].gt {
	pc = 0x8315E62C; continue 'dispatch;
	}
	// 8315E61C: 807F0050  lwz r3, 0x50(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315E620: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E624: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315E628: 4E800421  bctrl
	ctx.lr = 0x8315E62C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E62C: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315E630: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315E634: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315E638: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E63C: 814B0020  lwz r10, 0x20(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315E640: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315E644: 4E800421  bctrl
	ctx.lr = 0x8315E648;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E648: 807F0014  lwz r3, 0x14(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315E64C: 38A10058  addi r5, r1, 0x58
	ctx.r[5].s64 = ctx.r[1].s64 + 88;
	// 8315E650: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315E654: 81230000  lwz r9, 0(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E658: 8109001C  lwz r8, 0x1c(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(28 as u32) ) } as u64;
	// 8315E65C: 7D0903A6  mtctr r8
	ctx.ctr.u64 = ctx.r[8].u64;
	// 8315E660: 4E800421  bctrl
	ctx.lr = 0x8315E664;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E664: 817F0020  lwz r11, 0x20(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315E668: 80BF0004  lwz r5, 4(r31)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E66C: 813F002C  lwz r9, 0x2c(r31)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(44 as u32) ) } as u64;
	// 8315E670: 7CEBEA14  add r7, r11, r29
	ctx.r[7].u64 = ctx.r[11].u64 + ctx.r[29].u64;
	// 8315E674: 815F0038  lwz r10, 0x38(r31)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(56 as u32) ) } as u64;
	// 8315E678: 7CC9EA14  add r6, r9, r29
	ctx.r[6].u64 = ctx.r[9].u64 + ctx.r[29].u64;
	// 8315E67C: 90FF0020  stw r7, 0x20(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(32 as u32), ctx.r[7].u32 ) };
	// 8315E680: 7D4AEA14  add r10, r10, r29
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[29].u64;
	// 8315E684: 81250010  lwz r9, 0x10(r5)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315E688: 38690007  addi r3, r9, 7
	ctx.r[3].s64 = ctx.r[9].s64 + 7;
	// 8315E68C: 817F0028  lwz r11, 0x28(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315E690: 7C691E70  srawi r9, r3, 3
	ctx.xer.ca = (ctx.r[3].s32 < 0) && ((ctx.r[3].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[3].s32 >> 3) as i64;
	// 8315E694: 90DF002C  stw r6, 0x2c(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(44 as u32), ctx.r[6].u32 ) };
	// 8315E698: 7C8BF214  add r4, r11, r30
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[30].u64;
	// 8315E69C: 817F0034  lwz r11, 0x34(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(52 as u32) ) } as u64;
	// 8315E6A0: 7D090194  addze r8, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8315E6A4: 915F0038  stw r10, 0x38(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(56 as u32), ctx.r[10].u32 ) };
	// 8315E6A8: 909F0028  stw r4, 0x28(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(40 as u32), ctx.r[4].u32 ) };
	// 8315E6AC: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315E6B0: 911F0024  stw r8, 0x24(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(36 as u32), ctx.r[8].u32 ) };
	// 8315E6B4: 41980024  blt cr6, 0x8315e6d8
	if ctx.cr[6].lt {
	pc = 0x8315E6D8; continue 'dispatch;
	}
	// 8315E6B8: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315E6BC: 4198001C  blt cr6, 0x8315e6d8
	if ctx.cr[6].lt {
	pc = 0x8315E6D8; continue 'dispatch;
	}
	// 8315E6C0: 817F0044  lwz r11, 0x44(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(68 as u32) ) } as u64;
	// 8315E6C4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315E6C8: 419A0010  beq cr6, 0x8315e6d8
	if ctx.cr[6].eq {
	pc = 0x8315E6D8; continue 'dispatch;
	}
	// 8315E6CC: 807F0048  lwz r3, 0x48(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(72 as u32) ) } as u64;
	// 8315E6D0: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315E6D4: 4E800421  bctrl
	ctx.lr = 0x8315E6D8;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E6D8: 817F0028  lwz r11, 0x28(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315E6DC: 7F0BD800  cmpw cr6, r11, r27
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[27].s32, &mut ctx.xer);
	// 8315E6E0: 4198000C  blt cr6, 0x8315e6ec
	if ctx.cr[6].lt {
	pc = 0x8315E6EC; continue 'dispatch;
	}
	// 8315E6E4: 39600003  li r11, 3
	ctx.r[11].s64 = 3;
	// 8315E6E8: 997F0009  stb r11, 9(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(9 as u32), ctx.r[11].u8 ) };
	// 8315E6EC: 38210090  addi r1, r1, 0x90
	ctx.r[1].s64 = ctx.r[1].s64 + 144;
	// 8315E6F0: 48049AC4  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E6F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E6F8 size=152
    let mut pc: u32 = 0x8315E6F8;
    'dispatch: loop {
        match pc {
            0x8315E6F8 => {
    //   block [0x8315E6F8..0x8315E790)
	// 8315E6F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E6FC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E700: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315E704: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E708: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E70C: 897F0009  lbz r11, 9(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(9 as u32) ) } as u64;
	// 8315E710: 7D6B0774  extsb r11, r11
	ctx.r[11].s64 = ctx.r[11].s8 as i64;
	// 8315E714: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8315E718: 409A001C  bne cr6, 0x8315e734
	if !ctx.cr[6].eq {
	pc = 0x8315E734; continue 'dispatch;
	}
	// 8315E71C: 4BFFFD55  bl 0x8315e470
	ctx.lr = 0x8315E720;
	sub_8315E470(ctx, base);
	// 8315E720: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E724: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E728: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E72C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E730: 4E800020  blr
	return;
	// 8315E734: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8315E738: 409A0044  bne cr6, 0x8315e77c
	if !ctx.cr[6].eq {
	pc = 0x8315E77C; continue 'dispatch;
	}
	// 8315E73C: 807F0010  lwz r3, 0x10(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315E740: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315E744: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E748: 814B0024  lwz r10, 0x24(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315E74C: 7D4903A6  mtctr r10
	ctx.ctr.u64 = ctx.r[10].u64;
	// 8315E750: 4E800421  bctrl
	ctx.lr = 0x8315E754;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315E754: 2F030024  cmpwi cr6, r3, 0x24
	ctx.cr[6].compare_i32(ctx.r[3].s32, 36, &mut ctx.xer);
	// 8315E758: 41980024  blt cr6, 0x8315e77c
	if ctx.cr[6].lt {
	pc = 0x8315E77C; continue 'dispatch;
	}
	// 8315E75C: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E760: 4BFFE911  bl 0x8315d070
	ctx.lr = 0x8315E764;
	sub_8315D070(ctx, base);
	// 8315E764: 807F0000  lwz r3, 0(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315E768: 4BFFFAA9  bl 0x8315e210
	ctx.lr = 0x8315E76C;
	sub_8315E210(ctx, base);
	// 8315E76C: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315E770: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8315E774: 997F000B  stb r11, 0xb(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(11 as u32), ctx.r[11].u8 ) };
	// 8315E778: 995F0009  stb r10, 9(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(9 as u32), ctx.r[10].u8 ) };
	// 8315E77C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E780: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E784: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E788: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E78C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E790(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E790 size=28
    let mut pc: u32 = 0x8315E790;
    'dispatch: loop {
        match pc {
            0x8315E790 => {
    //   block [0x8315E790..0x8315E7AC)
	// 8315E790: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E794: 419A0010  beq cr6, 0x8315e7a4
	if ctx.cr[6].eq {
	pc = 0x8315E7A4; continue 'dispatch;
	}
	// 8315E798: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E79C: 816B9320  lwz r11, -0x6ce0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27872 as u32) ) } as u64;
	// 8315E7A0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315E7A4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315E7A8: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E7AC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E7AC size=16
    let mut pc: u32 = 0x8315E7AC;
    'dispatch: loop {
        match pc {
            0x8315E7AC => {
    //   block [0x8315E7AC..0x8315E7BC)
	// 8315E7AC: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E7B0: 814B9324  lwz r10, -0x6cdc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27868 as u32) ) } as u64;
	// 8315E7B4: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315E7B8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E7C0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E7C0 size=28
    let mut pc: u32 = 0x8315E7C0;
    'dispatch: loop {
        match pc {
            0x8315E7C0 => {
    //   block [0x8315E7C0..0x8315E7DC)
	// 8315E7C0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E7C4: 419A0010  beq cr6, 0x8315e7d4
	if ctx.cr[6].eq {
	pc = 0x8315E7D4; continue 'dispatch;
	}
	// 8315E7C8: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E7CC: 816B9328  lwz r11, -0x6cd8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27864 as u32) ) } as u64;
	// 8315E7D0: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315E7D4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315E7D8: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E7DC(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E7DC size=16
    let mut pc: u32 = 0x8315E7DC;
    'dispatch: loop {
        match pc {
            0x8315E7DC => {
    //   block [0x8315E7DC..0x8315E7EC)
	// 8315E7DC: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E7E0: 814B932C  lwz r10, -0x6cd4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-27860 as u32) ) } as u64;
	// 8315E7E4: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315E7E8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E7F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E7F0 size=28
    let mut pc: u32 = 0x8315E7F0;
    'dispatch: loop {
        match pc {
            0x8315E7F0 => {
    //   block [0x8315E7F0..0x8315E80C)
	// 8315E7F0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E7F4: 419A0010  beq cr6, 0x8315e804
	if ctx.cr[6].eq {
	pc = 0x8315E804; continue 'dispatch;
	}
	// 8315E7F8: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E7FC: 816BB3B0  lwz r11, -0x4c50(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-19536 as u32) ) } as u64;
	// 8315E800: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315E804: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315E808: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E80C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E80C size=16
    let mut pc: u32 = 0x8315E80C;
    'dispatch: loop {
        match pc {
            0x8315E80C => {
    //   block [0x8315E80C..0x8315E81C)
	// 8315E80C: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E810: 814BB3B4  lwz r10, -0x4c4c(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-19532 as u32) ) } as u64;
	// 8315E814: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315E818: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E820(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E820 size=28
    let mut pc: u32 = 0x8315E820;
    'dispatch: loop {
        match pc {
            0x8315E820 => {
    //   block [0x8315E820..0x8315E83C)
	// 8315E820: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E824: 419A0010  beq cr6, 0x8315e834
	if ctx.cr[6].eq {
	pc = 0x8315E834; continue 'dispatch;
	}
	// 8315E828: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E82C: 816BBC38  lwz r11, -0x43c8(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17352 as u32) ) } as u64;
	// 8315E830: 91630000  stw r11, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315E834: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315E838: 4D9A0020  beqlr cr6
	if ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E83C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E83C size=16
    let mut pc: u32 = 0x8315E83C;
    'dispatch: loop {
        match pc {
            0x8315E83C => {
    //   block [0x8315E83C..0x8315E84C)
	// 8315E83C: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315E840: 814BBC3C  lwz r10, -0x43c4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-17348 as u32) ) } as u64;
	// 8315E844: 91440000  stw r10, 0(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315E848: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E850(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E850 size=64
    let mut pc: u32 = 0x8315E850;
    'dispatch: loop {
        match pc {
            0x8315E850 => {
    //   block [0x8315E850..0x8315E890)
	// 8315E850: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E854: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E858: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315E85C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E860: 3FE0833A  lis r31, -0x7cc6
	ctx.r[31].s64 = -2093350912;
	// 8315E864: 807F81A8  lwz r3, -0x7e58(r31)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(-32344 as u32) ) } as u64;
	// 8315E868: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315E86C: 419A0010  beq cr6, 0x8315e87c
	if ctx.cr[6].eq {
	pc = 0x8315E87C; continue 'dispatch;
	}
	// 8315E870: 48001541  bl 0x8315fdb0
	ctx.lr = 0x8315E874;
	sub_8315FDB0(ctx, base);
	// 8315E874: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315E878: 917F81A8  stw r11, -0x7e58(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(-32344 as u32), ctx.r[11].u32 ) };
	// 8315E87C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E880: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E884: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E888: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315E88C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E890(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E890 size=12
    let mut pc: u32 = 0x8315E890;
    'dispatch: loop {
        match pc {
            0x8315E890 => {
    //   block [0x8315E890..0x8315E89C)
	// 8315E890: 39630007  addi r11, r3, 7
	ctx.r[11].s64 = ctx.r[3].s64 + 7;
	// 8315E894: 55630038  rlwinm r3, r11, 0, 0, 0x1c
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0xFFFFFFFFu64;
	// 8315E898: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E8A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E8A0 size=16
    let mut pc: u32 = 0x8315E8A0;
    'dispatch: loop {
        match pc {
            0x8315E8A0 => {
    //   block [0x8315E8A0..0x8315E8B0)
	// 8315E8A0: A163000E  lhz r11, 0xe(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315E8A4: 396B001C  addi r11, r11, 0x1c
	ctx.r[11].s64 = ctx.r[11].s64 + 28;
	// 8315E8A8: 5563043E  clrlwi r3, r11, 0x10
	ctx.r[3].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8315E8AC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E8B0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E8B0 size=48
    let mut pc: u32 = 0x8315E8B0;
    'dispatch: loop {
        match pc {
            0x8315E8B0 => {
    //   block [0x8315E8B0..0x8315E8E0)
	// 8315E8B0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E8B4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E8B8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E8BC: A163000E  lhz r11, 0xe(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315E8C0: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8315E8C4: 386B0018  addi r3, r11, 0x18
	ctx.r[3].s64 = ctx.r[11].s64 + 24;
	// 8315E8C8: 4BFFFFC9  bl 0x8315e890
	ctx.lr = 0x8315E8CC;
	sub_8315E890(ctx, base);
	// 8315E8CC: 3863FFFC  addi r3, r3, -4
	ctx.r[3].s64 = ctx.r[3].s64 + -4;
	// 8315E8D0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E8D4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E8D8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E8DC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E8E0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E8E0 size=16
    let mut pc: u32 = 0x8315E8E0;
    'dispatch: loop {
        match pc {
            0x8315E8E0 => {
    //   block [0x8315E8E0..0x8315E8F0)
	// 8315E8E0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315E8E4: 7D6A0034  cntlzw r10, r11
	ctx.r[10].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8315E8E8: 5543DFFE  rlwinm r3, r10, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 8315E8EC: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E8F0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut tmp: PPCRegister = Default::default();
    // ---- function 0x8315E8F0 size=68
    let mut pc: u32 = 0x8315E8F0;
    'dispatch: loop {
        match pc {
            0x8315E8F0 => {
    //   block [0x8315E8F0..0x8315E934)
	// 8315E8F0: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315E8F4: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 8315E8F8: 41990008  bgt cr6, 0x8315e900
	if ctx.cr[6].gt {
	pc = 0x8315E900; continue 'dispatch;
	}
	// 8315E8FC: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 8315E900: 7D6A5B78  mr r10, r11
	ctx.r[10].u64 = ctx.r[11].u64;
	// 8315E904: 7D491E70  srawi r9, r10, 3
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[10].s32 >> 3) as i64;
	// 8315E908: 7D090194  addze r8, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[8].s64 = tmp.s64;
	// 8315E90C: 55071838  slwi r7, r8, 3
	ctx.r[7].u32 = ctx.r[8].u32.wrapping_shl(3);
	ctx.r[7].u64 = ctx.r[7].u32 as u64;
	// 8315E910: 7CC75051  subf. r6, r7, r10
	ctx.r[6].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	ctx.cr[0].compare_i32(ctx.r[6].s32, 0, &mut ctx.xer);
	// 8315E914: 41820020  beq 0x8315e934
	if ctx.cr[0].eq {
		sub_8315E934(ctx, base);
		return;
	}
	// 8315E918: 396BFFF8  addi r11, r11, -8
	ctx.r[11].s64 = ctx.r[11].s64 + -8;
	// 8315E91C: 556A1838  slwi r10, r11, 3
	ctx.r[10].u32 = ctx.r[11].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315E920: 7D491E70  srawi r9, r10, 3
	ctx.xer.ca = (ctx.r[10].s32 < 0) && ((ctx.r[10].u32 & ((1u32 << 3) - 1)) != 0);
	ctx.r[9].s64 = (ctx.r[10].s32 >> 3) as i64;
	// 8315E924: 7D690194  addze r11, r9
	tmp.s64 = ctx.r[9].s64 + ctx.xer.ca as i64;
	ctx.xer.ca = (tmp.u32 < ctx.r[9].u32);
	ctx.r[11].s64 = tmp.s64;
	// 8315E928: 7D035B96  divwu r8, r3, r11
	ctx.r[8].u32 = ctx.r[3].u32 / ctx.r[11].u32;
	// 8315E92C: 7C6859D6  mullw r3, r8, r11
	ctx.r[3].s64 = (ctx.r[8].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8315E930: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E934(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E934 size=12
    let mut pc: u32 = 0x8315E934;
    'dispatch: loop {
        match pc {
            0x8315E934 => {
    //   block [0x8315E934..0x8315E940)
	// 8315E934: 7D435B96  divwu r10, r3, r11
	ctx.r[10].u32 = ctx.r[3].u32 / ctx.r[11].u32;
	// 8315E938: 7C6A59D6  mullw r3, r10, r11
	ctx.r[3].s64 = (ctx.r[10].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8315E93C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E940 size=48
    let mut pc: u32 = 0x8315E940;
    'dispatch: loop {
        match pc {
            0x8315E940 => {
    //   block [0x8315E940..0x8315E970)
	// 8315E940: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E944: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E948: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E94C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315E950: 4BFFFF61  bl 0x8315e8b0
	ctx.lr = 0x8315E954;
	sub_8315E8B0(ctx, base);
	// 8315E954: A16A000E  lhz r11, 0xe(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[10].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315E958: 392B001C  addi r9, r11, 0x1c
	ctx.r[9].s64 = ctx.r[11].s64 + 28;
	// 8315E95C: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8315E960: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E964: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E968: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E96C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E970(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E970 size=8
    let mut pc: u32 = 0x8315E970;
    'dispatch: loop {
        match pc {
            0x8315E970 => {
    //   block [0x8315E970..0x8315E978)
	// 8315E970: 8063FFFC  lwz r3, -4(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(-4 as u32) ) } as u64;
	// 8315E974: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E978(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E978 size=40
    let mut pc: u32 = 0x8315E978;
    'dispatch: loop {
        match pc {
            0x8315E978 => {
    //   block [0x8315E978..0x8315E9A0)
	// 8315E978: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E97C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315E980: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E984: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315E988: 4BFFFFE9  bl 0x8315e970
	ctx.lr = 0x8315E98C;
	sub_8315E970(ctx, base);
	// 8315E98C: 7C635050  subf r3, r3, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[3].s64;
	// 8315E990: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315E994: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315E998: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315E99C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E9A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E9A0 size=36
    let mut pc: u32 = 0x8315E9A0;
    'dispatch: loop {
        match pc {
            0x8315E9A0 => {
    //   block [0x8315E9A0..0x8315E9C4)
	// 8315E9A0: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315E9A4: 3943001C  addi r10, r3, 0x1c
	ctx.r[10].s64 = ctx.r[3].s64 + 28;
	// 8315E9A8: 2F0B0008  cmpwi cr6, r11, 8
	ctx.cr[6].compare_i32(ctx.r[11].s32, 8, &mut ctx.xer);
	// 8315E9AC: 40980008  bge cr6, 0x8315e9b4
	if !ctx.cr[6].lt {
	pc = 0x8315E9B4; continue 'dispatch;
	}
	// 8315E9B0: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 8315E9B4: 7D2A5B96  divwu r9, r10, r11
	ctx.r[9].u32 = ctx.r[10].u32 / ctx.r[11].u32;
	// 8315E9B8: 7D0959D6  mullw r8, r9, r11
	ctx.r[8].s64 = (ctx.r[9].s32 as i64) * (ctx.r[11].s32 as i64);
	// 8315E9BC: 7C685051  subf. r3, r8, r10
	ctx.r[3].s64 = ctx.r[10].s64 - ctx.r[8].s64;
	ctx.cr[0].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315E9C0: 4D820020  beqlr
	if ctx.cr[0].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E9C4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315E9C4 size=8
    let mut pc: u32 = 0x8315E9C4;
    'dispatch: loop {
        match pc {
            0x8315E9C4 => {
    //   block [0x8315E9C4..0x8315E9CC)
	// 8315E9C4: 7C635850  subf r3, r3, r11
	ctx.r[3].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 8315E9C8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315E9D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315E9D0 size=156
    let mut pc: u32 = 0x8315E9D0;
    'dispatch: loop {
        match pc {
            0x8315E9D0 => {
    //   block [0x8315E9D0..0x8315EA6C)
	// 8315E9D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315E9D4: 48049795  bl 0x831a8168
	ctx.lr = 0x8315E9D8;
	sub_831A8130(ctx, base);
	// 8315E9D8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315E9DC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315E9E0: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315E9E4: 395F0018  addi r10, r31, 0x18
	ctx.r[10].s64 = ctx.r[31].s64 + 24;
	// 8315E9E8: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 8315E9EC: 93BF0004  stw r29, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[29].u32 ) };
	// 8315E9F0: 4BFFFEA1  bl 0x8315e890
	ctx.lr = 0x8315E9F4;
	sub_8315E890(ctx, base);
	// 8315E9F4: 7C7C1B78  mr r28, r3
	ctx.r[28].u64 = ctx.r[3].u64;
	// 8315E9F8: 38A00018  li r5, 0x18
	ctx.r[5].s64 = 24;
	// 8315E9FC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315EA00: 7FCAE050  subf r30, r10, r28
	ctx.r[30].s64 = ctx.r[28].s64 - ctx.r[10].s64;
	// 8315EA04: 480497DD  bl 0x831a81e0
	ctx.lr = 0x8315EA08;
	sub_831A81E0(ctx, base);
	// 8315EA08: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315EA0C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315EA10: 4BFFFF91  bl 0x8315e9a0
	ctx.lr = 0x8315EA14;
	sub_8315E9A0(ctx, base);
	// 8315EA14: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315EA18: B07C000E  sth r3, 0xe(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(14 as u32), ctx.r[3].u16 ) };
	// 8315EA1C: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315EA20: 915C0004  stw r10, 4(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8315EA24: 4BFFFE7D  bl 0x8315e8a0
	ctx.lr = 0x8315EA28;
	sub_8315E8A0(ctx, base);
	// 8315EA28: 5469043E  clrlwi r9, r3, 0x10
	ctx.r[9].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315EA2C: 7D1EE850  subf r8, r30, r29
	ctx.r[8].s64 = ctx.r[29].s64 - ctx.r[30].s64;
	// 8315EA30: 995C000D  stb r10, 0xd(r28)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[28].u32.wrapping_add(13 as u32), ctx.r[10].u8 ) };
	// 8315EA34: B15C0010  sth r10, 0x10(r28)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[28].u32.wrapping_add(16 as u32), ctx.r[10].u16 ) };
	// 8315EA38: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315EA3C: 7D694050  subf r11, r9, r8
	ctx.r[11].s64 = ctx.r[8].s64 - ctx.r[9].s64;
	// 8315EA40: 38EBFFE8  addi r7, r11, -0x18
	ctx.r[7].s64 = ctx.r[11].s64 + -24;
	// 8315EA44: 90FC0008  stw r7, 8(r28)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[28].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 8315EA48: 4BFFFEF9  bl 0x8315e940
	ctx.lr = 0x8315EA4C;
	sub_8315E940(ctx, base);
	// 8315EA4C: 397E0018  addi r11, r30, 0x18
	ctx.r[11].s64 = ctx.r[30].s64 + 24;
	// 8315EA50: 939F0010  stw r28, 0x10(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[28].u32 ) };
	// 8315EA54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EA58: 939F0014  stw r28, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[28].u32 ) };
	// 8315EA5C: 917F000C  stw r11, 0xc(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u32 ) };
	// 8315EA60: 917F0008  stw r11, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8315EA64: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315EA68: 48049750  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EA70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315EA70 size=60
    let mut pc: u32 = 0x8315EA70;
    'dispatch: loop {
        match pc {
            0x8315EA70 => {
    //   block [0x8315EA70..0x8315EAAC)
	// 8315EA70: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315EA74: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315EA78: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315EA7C: 5484043E  clrlwi r4, r4, 0x10
	ctx.r[4].u64 = ctx.r[4].u32 as u64 & 0x0000FFFFu64;
	// 8315EA80: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8315EA84: 4BFFFF1D  bl 0x8315e9a0
	ctx.lr = 0x8315EA88;
	sub_8315E9A0(ctx, base);
	// 8315EA88: A0C7000E  lhz r6, 0xe(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[7].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315EA8C: 5465043E  clrlwi r5, r3, 0x10
	ctx.r[5].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315EA90: 7C862850  subf r4, r6, r5
	ctx.r[4].s64 = ctx.r[5].s64 - ctx.r[6].s64;
	// 8315EA94: 7C830034  cntlzw r3, r4
	ctx.r[3].u64 = if ctx.r[4].u32 == 0 { 32 } else { ctx.r[4].u32.leading_zeros() as u64 };
	// 8315EA98: 5463DFFE  rlwinm r3, r3, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[3].u32 as u64 & 0x0000001Fu64;
	// 8315EA9C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315EAA0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315EAA4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315EAA8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EAB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315EAB0 size=88
    let mut pc: u32 = 0x8315EAB0;
    'dispatch: loop {
        match pc {
            0x8315EAB0 => {
    //   block [0x8315EAB0..0x8315EB08)
	// 8315EAB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315EAB4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315EAB8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315EABC: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 8315EAC0: 54A4043E  clrlwi r4, r5, 0x10
	ctx.r[4].u64 = ctx.r[5].u32 as u64 & 0x0000FFFFu64;
	// 8315EAC4: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8315EAC8: 4BFFFED9  bl 0x8315e9a0
	ctx.lr = 0x8315EACC;
	sub_8315E9A0(ctx, base);
	// 8315EACC: A1060010  lhz r8, 0x10(r6)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[6].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315EAD0: A166000E  lhz r11, 0xe(r6)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[6].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315EAD4: 5469043E  clrlwi r9, r3, 0x10
	ctx.r[9].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315EAD8: 81460008  lwz r10, 8(r6)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[6].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EADC: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315EAE0: 7D685A14  add r11, r8, r11
	ctx.r[11].u64 = ctx.r[8].u64 + ctx.r[11].u64;
	// 8315EAE4: 7CA93A14  add r5, r9, r7
	ctx.r[5].u64 = ctx.r[9].u64 + ctx.r[7].u64;
	// 8315EAE8: 7C8B5214  add r4, r11, r10
	ctx.r[4].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315EAEC: 7F052000  cmpw cr6, r5, r4
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[4].s32, &mut ctx.xer);
	// 8315EAF0: 40990008  ble cr6, 0x8315eaf8
	if !ctx.cr[6].gt {
	pc = 0x8315EAF8; continue 'dispatch;
	}
	// 8315EAF4: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315EAF8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315EAFC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315EB00: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315EB04: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EB08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315EB08 size=116
    let mut pc: u32 = 0x8315EB08;
    'dispatch: loop {
        match pc {
            0x8315EB08 => {
    //   block [0x8315EB08..0x8315EB7C)
	// 8315EB08: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315EB0C: 48049661  bl 0x831a816c
	ctx.lr = 0x8315EB10;
	sub_831A8130(ctx, base);
	// 8315EB10: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315EB14: 83E30010  lwz r31, 0x10(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315EB18: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315EB1C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315EB20: 897F000C  lbz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EB24: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EB28: 409A0030  bne cr6, 0x8315eb58
	if !ctx.cr[6].eq {
	pc = 0x8315EB58; continue 'dispatch;
	}
	// 8315EB2C: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EB30: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315EB34: 409A0018  bne cr6, 0x8315eb4c
	if !ctx.cr[6].eq {
	pc = 0x8315EB4C; continue 'dispatch;
	}
	// 8315EB38: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315EB3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EB40: 4BFFFF31  bl 0x8315ea70
	ctx.lr = 0x8315EB44;
	sub_8315EA70(ctx, base);
	// 8315EB44: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315EB48: 419A0028  beq cr6, 0x8315eb70
	if ctx.cr[6].eq {
	pc = 0x8315EB70; continue 'dispatch;
	}
	// 8315EB4C: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315EB50: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EB54: 419A001C  beq cr6, 0x8315eb70
	if ctx.cr[6].eq {
	pc = 0x8315EB70; continue 'dispatch;
	}
	// 8315EB58: 83FF0004  lwz r31, 4(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315EB5C: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315EB60: 409AFFC0  bne cr6, 0x8315eb20
	if !ctx.cr[6].eq {
	pc = 0x8315EB20; continue 'dispatch;
	}
	// 8315EB64: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315EB68: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315EB6C: 48049650  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315EB70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EB74: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315EB78: 48049644  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EB80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315EB80 size=160
    let mut pc: u32 = 0x8315EB80;
    'dispatch: loop {
        match pc {
            0x8315EB80 => {
    //   block [0x8315EB80..0x8315EC20)
	// 8315EB80: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315EB84: 480495E9  bl 0x831a816c
	ctx.lr = 0x8315EB88;
	sub_831A8130(ctx, base);
	// 8315EB88: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315EB8C: 83E30014  lwz r31, 0x14(r3)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315EB90: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315EB94: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315EB98: 897F000C  lbz r11, 0xc(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EB9C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EBA0: 409A005C  bne cr6, 0x8315ebfc
	if !ctx.cr[6].eq {
	pc = 0x8315EBFC; continue 'dispatch;
	}
	// 8315EBA4: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315EBA8: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315EBAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EBB0: 4BFFFF01  bl 0x8315eab0
	ctx.lr = 0x8315EBB4;
	sub_8315EAB0(ctx, base);
	// 8315EBB4: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315EBB8: 409A0018  bne cr6, 0x8315ebd0
	if !ctx.cr[6].eq {
	pc = 0x8315EBD0; continue 'dispatch;
	}
	// 8315EBBC: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315EBC0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EBC4: 419A0050  beq cr6, 0x8315ec14
	if ctx.cr[6].eq {
	pc = 0x8315EC14; continue 'dispatch;
	}
	// 8315EBC8: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 8315EBCC: 419A0048  beq cr6, 0x8315ec14
	if ctx.cr[6].eq {
	pc = 0x8315EC14; continue 'dispatch;
	}
	// 8315EBD0: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EBD4: 7F0BF000  cmpw cr6, r11, r30
	ctx.cr[6].compare_i32(ctx.r[11].s32, ctx.r[30].s32, &mut ctx.xer);
	// 8315EBD8: 409A0024  bne cr6, 0x8315ebfc
	if !ctx.cr[6].eq {
	pc = 0x8315EBFC; continue 'dispatch;
	}
	// 8315EBDC: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315EBE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EBE4: 4BFFFE8D  bl 0x8315ea70
	ctx.lr = 0x8315EBE8;
	sub_8315EA70(ctx, base);
	// 8315EBE8: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315EBEC: 409A0010  bne cr6, 0x8315ebfc
	if !ctx.cr[6].eq {
	pc = 0x8315EBFC; continue 'dispatch;
	}
	// 8315EBF0: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315EBF4: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 8315EBF8: 419A001C  beq cr6, 0x8315ec14
	if ctx.cr[6].eq {
	pc = 0x8315EC14; continue 'dispatch;
	}
	// 8315EBFC: 83FF0000  lwz r31, 0(r31)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315EC00: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315EC04: 409AFF94  bne cr6, 0x8315eb98
	if !ctx.cr[6].eq {
	pc = 0x8315EB98; continue 'dispatch;
	}
	// 8315EC08: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315EC0C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315EC10: 480495AC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315EC14: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EC18: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315EC1C: 480495A0  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC20 size=44
    let mut pc: u32 = 0x8315EC20;
    'dispatch: loop {
        match pc {
            0x8315EC20 => {
    //   block [0x8315EC20..0x8315EC4C)
	// 8315EC20: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315EC24: 7CA42B78  mr r4, r5
	ctx.r[4].u64 = ctx.r[5].u64;
	// 8315EC28: 7CC53378  mr r5, r6
	ctx.r[5].u64 = ctx.r[6].u64;
	// 8315EC2C: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315EC30: 2F0B0001  cmpwi cr6, r11, 1
	ctx.cr[6].compare_i32(ctx.r[11].s32, 1, &mut ctx.xer);
	// 8315EC34: 419A001C  beq cr6, 0x8315ec50
	if ctx.cr[6].eq {
		sub_8315EC50(ctx, base);
		return;
	}
	// 8315EC38: 2F0B0002  cmpwi cr6, r11, 2
	ctx.cr[6].compare_i32(ctx.r[11].s32, 2, &mut ctx.xer);
	// 8315EC3C: 419A0010  beq cr6, 0x8315ec4c
	if ctx.cr[6].eq {
		sub_8315EC4C(ctx, base);
		return;
	}
	// 8315EC40: 2F0B0003  cmpwi cr6, r11, 3
	ctx.cr[6].compare_i32(ctx.r[11].s32, 3, &mut ctx.xer);
	// 8315EC44: 419A0010  beq cr6, 0x8315ec54
	if ctx.cr[6].eq {
		sub_8315EC54(ctx, base);
		return;
	}
	// 8315EC48: 48000000  b 0x8315ec48
	pc = 0x8315EC48; continue 'dispatch;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC4C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC4C size=4
    let mut pc: u32 = 0x8315EC4C;
    'dispatch: loop {
        match pc {
            0x8315EC4C => {
    //   block [0x8315EC4C..0x8315EC50)
	// 8315EC4C: 4BFFFF34  b 0x8315eb80
	sub_8315EB80(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC50(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC50 size=4
    let mut pc: u32 = 0x8315EC50;
    'dispatch: loop {
        match pc {
            0x8315EC50 => {
    //   block [0x8315EC50..0x8315EC54)
	// 8315EC50: 4BFFFEB8  b 0x8315eb08
	sub_8315EB08(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC54(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC54 size=8
    let mut pc: u32 = 0x8315EC54;
    'dispatch: loop {
        match pc {
            0x8315EC54 => {
    //   block [0x8315EC54..0x8315EC5C)
	// 8315EC54: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 8315EC58: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC60(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC60 size=16
    let mut pc: u32 = 0x8315EC60;
    'dispatch: loop {
        match pc {
            0x8315EC60 => {
    //   block [0x8315EC60..0x8315EC70)
	// 8315EC60: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EC64: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EC68: 7F0A5800  cmpw cr6, r10, r11
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315EC6C: 4C980020  bgelr cr6
	if !ctx.cr[6].lt { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC70(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC70 size=8
    let mut pc: u32 = 0x8315EC70;
    'dispatch: loop {
        match pc {
            0x8315EC70 => {
    //   block [0x8315EC70..0x8315EC78)
	// 8315EC70: 91630008  stw r11, 8(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(8 as u32), ctx.r[11].u32 ) };
	// 8315EC74: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC78(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC78 size=16
    let mut pc: u32 = 0x8315EC78;
    'dispatch: loop {
        match pc {
            0x8315EC78 => {
    //   block [0x8315EC78..0x8315EC88)
	// 8315EC78: A163000E  lhz r11, 0xe(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315EC7C: 7D6B1A14  add r11, r11, r3
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[3].u64;
	// 8315EC80: 386B001C  addi r3, r11, 0x1c
	ctx.r[3].s64 = ctx.r[11].s64 + 28;
	// 8315EC84: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EC88(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315EC88 size=28
    let mut pc: u32 = 0x8315EC88;
    'dispatch: loop {
        match pc {
            0x8315EC88 => {
    //   block [0x8315EC88..0x8315ECA4)
	// 8315EC88: A1630010  lhz r11, 0x10(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315EC8C: A123000E  lhz r9, 0xe(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315EC90: 81430008  lwz r10, 8(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EC94: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315EC98: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315EC9C: 386B001C  addi r3, r11, 0x1c
	ctx.r[3].s64 = ctx.r[11].s64 + 28;
	// 8315ECA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315ECA8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315ECA8 size=92
    let mut pc: u32 = 0x8315ECA8;
    'dispatch: loop {
        match pc {
            0x8315ECA8 => {
    //   block [0x8315ECA8..0x8315ED04)
	// 8315ECA8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315ECAC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315ECB0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315ECB4: 54AB043E  clrlwi r11, r5, 0x10
	ctx.r[11].u64 = ctx.r[5].u32 as u64 & 0x0000FFFFu64;
	// 8315ECB8: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8315ECBC: 7D6B2214  add r11, r11, r4
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[4].u64;
	// 8315ECC0: 38EB001C  addi r7, r11, 0x1c
	ctx.r[7].s64 = ctx.r[11].s64 + 28;
	// 8315ECC4: 7C673214  add r3, r7, r6
	ctx.r[3].u64 = ctx.r[7].u64 + ctx.r[6].u64;
	// 8315ECC8: 4BFFFBC9  bl 0x8315e890
	ctx.lr = 0x8315ECCC;
	sub_8315E890(ctx, base);
	// 8315ECCC: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315ECD0: 4BFFFCD1  bl 0x8315e9a0
	ctx.lr = 0x8315ECD4;
	sub_8315E9A0(ctx, base);
	// 8315ECD4: 7D633A14  add r11, r3, r7
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[7].u64;
	// 8315ECD8: 7CC33378  mr r3, r6
	ctx.r[3].u64 = ctx.r[6].u64;
	// 8315ECDC: 390B001C  addi r8, r11, 0x1c
	ctx.r[8].s64 = ctx.r[11].s64 + 28;
	// 8315ECE0: 4BFFFFA9  bl 0x8315ec88
	ctx.lr = 0x8315ECE4;
	sub_8315EC88(ctx, base);
	// 8315ECE4: 7F034000  cmpw cr6, r3, r8
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[8].s32, &mut ctx.xer);
	// 8315ECE8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315ECEC: 41980008  blt cr6, 0x8315ecf4
	if ctx.cr[6].lt {
	pc = 0x8315ECF4; continue 'dispatch;
	}
	// 8315ECF0: 38600001  li r3, 1
	ctx.r[3].s64 = 1;
	// 8315ECF4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315ECF8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315ECFC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315ED00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315ED08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315ED08 size=16
    let mut pc: u32 = 0x8315ED08;
    'dispatch: loop {
        match pc {
            0x8315ED08 => {
    //   block [0x8315ED08..0x8315ED18)
	// 8315ED08: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8315ED0C: 80640004  lwz r3, 4(r4)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315ED10: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315ED14: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315ED18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315ED18 size=12
    let mut pc: u32 = 0x8315ED18;
    'dispatch: loop {
        match pc {
            0x8315ED18 => {
    //   block [0x8315ED18..0x8315ED24)
	// 8315ED18: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315ED1C: 7C6A5A14  add r3, r10, r11
	ctx.r[3].u64 = ctx.r[10].u64 + ctx.r[11].u64;
	// 8315ED20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315ED28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315ED28 size=392
    let mut pc: u32 = 0x8315ED28;
    'dispatch: loop {
        match pc {
            0x8315ED28 => {
    //   block [0x8315ED28..0x8315EEB0)
	// 8315ED28: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315ED2C: 48049429  bl 0x831a8154
	ctx.lr = 0x8315ED30;
	sub_831A8130(ctx, base);
	// 8315ED30: 9421FF60  stwu r1, -0xa0(r1)
	ea = ctx.r[1].u32.wrapping_add(-160 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315ED34: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8315ED38: 7C7A1B78  mr r26, r3
	ctx.r[26].u64 = ctx.r[3].u64;
	// 8315ED3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315ED40: 7CBC2B78  mr r28, r5
	ctx.r[28].u64 = ctx.r[5].u64;
	// 8315ED44: 7CD93378  mr r25, r6
	ctx.r[25].u64 = ctx.r[6].u64;
	// 8315ED48: 4BFFFF41  bl 0x8315ec88
	ctx.lr = 0x8315ED4C;
	sub_8315EC88(ctx, base);
	// 8315ED4C: 7C781B78  mr r24, r3
	ctx.r[24].u64 = ctx.r[3].u64;
	// 8315ED50: 7CE43B78  mr r4, r7
	ctx.r[4].u64 = ctx.r[7].u64;
	// 8315ED54: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315ED58: 4BFFFC49  bl 0x8315e9a0
	ctx.lr = 0x8315ED5C;
	sub_8315E9A0(ctx, base);
	// 8315ED5C: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315ED60: 547B043E  clrlwi r27, r3, 0x10
	ctx.r[27].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315ED64: 7F1C5800  cmpw cr6, r28, r11
	ctx.cr[6].compare_i32(ctx.r[28].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315ED68: 409A0064  bne cr6, 0x8315edcc
	if !ctx.cr[6].eq {
	pc = 0x8315EDCC; continue 'dispatch;
	}
	// 8315ED6C: A17F000E  lhz r11, 0xe(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315ED70: 576A043E  clrlwi r10, r27, 0x10
	ctx.r[10].u64 = ctx.r[27].u32 as u64 & 0x0000FFFFu64;
	// 8315ED74: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8315ED78: 409A0054  bne cr6, 0x8315edcc
	if !ctx.cr[6].eq {
	pc = 0x8315EDCC; continue 'dispatch;
	}
	// 8315ED7C: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315ED80: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315ED84: 409A0010  bne cr6, 0x8315ed94
	if !ctx.cr[6].eq {
	pc = 0x8315ED94; continue 'dispatch;
	}
	// 8315ED88: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315ED8C: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8315ED90: 48049414  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 8315ED94: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315ED98: 933F0014  stw r25, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[25].u32 ) };
	// 8315ED9C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EDA0: 997F000D  stb r11, 0xd(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(13 as u32), ctx.r[11].u8 ) };
	// 8315EDA4: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8315EDA8: 4BFFFB99  bl 0x8315e940
	ctx.lr = 0x8315EDAC;
	sub_8315E940(ctx, base);
	// 8315EDAC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EDB0: 4BFFFED9  bl 0x8315ec88
	ctx.lr = 0x8315EDB4;
	sub_8315EC88(ctx, base);
	// 8315EDB4: 817A000C  lwz r11, 0xc(r26)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EDB8: 7D435A14  add r10, r3, r11
	ctx.r[10].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 8315EDBC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EDC0: 915A000C  stw r10, 0xc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8315EDC4: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8315EDC8: 480493DC  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 8315EDCC: 7F65DB78  mr r5, r27
	ctx.r[5].u64 = ctx.r[27].u64;
	// 8315EDD0: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8315EDD4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EDD8: 4BFFFED1  bl 0x8315eca8
	ctx.lr = 0x8315EDDC;
	sub_8315ECA8(ctx, base);
	// 8315EDDC: 2F030000  cmpwi cr6, r3, 0
	ctx.cr[6].compare_i32(ctx.r[3].s32, 0, &mut ctx.xer);
	// 8315EDE0: 419AFFA8  beq cr6, 0x8315ed88
	if ctx.cr[6].eq {
	pc = 0x8315ED88; continue 'dispatch;
	}
	// 8315EDE4: 576B043E  clrlwi r11, r27, 0x10
	ctx.r[11].u64 = ctx.r[27].u32 as u64 & 0x0000FFFFu64;
	// 8315EDE8: 7D6BE214  add r11, r11, r28
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[28].u64;
	// 8315EDEC: 3BAB001C  addi r29, r11, 0x1c
	ctx.r[29].s64 = ctx.r[11].s64 + 28;
	// 8315EDF0: 7D5DFA14  add r10, r29, r31
	ctx.r[10].u64 = ctx.r[29].u64 + ctx.r[31].u64;
	// 8315EDF4: 7D435378  mr r3, r10
	ctx.r[3].u64 = ctx.r[10].u64;
	// 8315EDF8: 4BFFFA99  bl 0x8315e890
	ctx.lr = 0x8315EDFC;
	sub_8315E890(ctx, base);
	// 8315EDFC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315EE00: 38A00018  li r5, 0x18
	ctx.r[5].s64 = 24;
	// 8315EE04: 7D6AF050  subf r11, r10, r30
	ctx.r[11].s64 = ctx.r[30].s64 - ctx.r[10].s64;
	// 8315EE08: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315EE0C: 5577043E  clrlwi r23, r11, 0x10
	ctx.r[23].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8315EE10: 480493D1  bl 0x831a81e0
	ctx.lr = 0x8315EE14;
	sub_831A81E0(ctx, base);
	// 8315EE14: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315EE18: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315EE1C: 4BFFFB85  bl 0x8315e9a0
	ctx.lr = 0x8315EE20;
	sub_8315E9A0(ctx, base);
	// 8315EE20: 546A043E  clrlwi r10, r3, 0x10
	ctx.r[10].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315EE24: 93FE0000  stw r31, 0(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8315EE28: 39600001  li r11, 1
	ctx.r[11].s64 = 1;
	// 8315EE2C: 7D2AC050  subf r9, r10, r24
	ctx.r[9].s64 = ctx.r[24].s64 - ctx.r[10].s64;
	// 8315EE30: B15E000E  sth r10, 0xe(r30)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[30].u32.wrapping_add(14 as u32), ctx.r[10].u16 ) };
	// 8315EE34: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EE38: 7D174850  subf r8, r23, r9
	ctx.r[8].s64 = ctx.r[9].s64 - ctx.r[23].s64;
	// 8315EE3C: 7D5D4050  subf r10, r29, r8
	ctx.r[10].s64 = ctx.r[8].s64 - ctx.r[29].s64;
	// 8315EE40: 38EAFFE4  addi r7, r10, -0x1c
	ctx.r[7].s64 = ctx.r[10].s64 + -28;
	// 8315EE44: 90FE0008  stw r7, 8(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(8 as u32), ctx.r[7].u32 ) };
	// 8315EE48: 80DF0004  lwz r6, 4(r31)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315EE4C: 90DE0004  stw r6, 4(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(4 as u32), ctx.r[6].u32 ) };
	// 8315EE50: B37F000E  sth r27, 0xe(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(14 as u32), ctx.r[27].u16 ) };
	// 8315EE54: 93DF0004  stw r30, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8315EE58: 939F0008  stw r28, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[28].u32 ) };
	// 8315EE5C: 997F000D  stb r11, 0xd(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(13 as u32), ctx.r[11].u8 ) };
	// 8315EE60: 933F0014  stw r25, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[25].u32 ) };
	// 8315EE64: B2FF0010  sth r23, 0x10(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[23].u16 ) };
	// 8315EE68: 997F000C  stb r11, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[11].u8 ) };
	// 8315EE6C: 4BFFFAD5  bl 0x8315e940
	ctx.lr = 0x8315EE70;
	sub_8315E940(ctx, base);
	// 8315EE70: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EE74: 4BFFFE15  bl 0x8315ec88
	ctx.lr = 0x8315EE78;
	sub_8315EC88(ctx, base);
	// 8315EE78: 80BA000C  lwz r5, 0xc(r26)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[26].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EE7C: 7C832A14  add r4, r3, r5
	ctx.r[4].u64 = ctx.r[3].u64 + ctx.r[5].u64;
	// 8315EE80: 909A000C  stw r4, 0xc(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(12 as u32), ctx.r[4].u32 ) };
	// 8315EE84: 817E0004  lwz r11, 4(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315EE88: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EE8C: 409A0014  bne cr6, 0x8315eea0
	if !ctx.cr[6].eq {
	pc = 0x8315EEA0; continue 'dispatch;
	}
	// 8315EE90: 93DA0014  stw r30, 0x14(r26)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[26].u32.wrapping_add(20 as u32), ctx.r[30].u32 ) };
	// 8315EE94: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EE98: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8315EE9C: 48049308  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
	// 8315EEA0: 93CB0000  stw r30, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[30].u32 ) };
	// 8315EEA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EEA8: 382100A0  addi r1, r1, 0xa0
	ctx.r[1].s64 = ctx.r[1].s64 + 160;
	// 8315EEAC: 480492F8  b 0x831a81a4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315EEB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315EEB0 size=488
    let mut pc: u32 = 0x8315EEB0;
    'dispatch: loop {
        match pc {
            0x8315EEB0 => {
    //   block [0x8315EEB0..0x8315F098)
	// 8315EEB0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315EEB4: 480492B5  bl 0x831a8168
	ctx.lr = 0x8315EEB8;
	sub_831A8130(ctx, base);
	// 8315EEB8: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315EEBC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315EEC0: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8315EEC4: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8315EEC8: 4BFFFE41  bl 0x8315ed08
	ctx.lr = 0x8315EECC;
	sub_8315ED08(ctx, base);
	// 8315EECC: 817F0008  lwz r11, 8(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315EED0: 7C661B78  mr r6, r3
	ctx.r[6].u64 = ctx.r[3].u64;
	// 8315EED4: 7F055800  cmpw cr6, r5, r11
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315EED8: 409A0074  bne cr6, 0x8315ef4c
	if !ctx.cr[6].eq {
	pc = 0x8315EF4C; continue 'dispatch;
	}
	// 8315EEDC: 7CE43B78  mr r4, r7
	ctx.r[4].u64 = ctx.r[7].u64;
	// 8315EEE0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EEE4: 4BFFFABD  bl 0x8315e9a0
	ctx.lr = 0x8315EEE8;
	sub_8315E9A0(ctx, base);
	// 8315EEE8: A17F000E  lhz r11, 0xe(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[31].u32.wrapping_add(14 as u32) ) } as u64;
	// 8315EEEC: 546A043E  clrlwi r10, r3, 0x10
	ctx.r[10].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315EEF0: 7F0A5840  cmplw cr6, r10, r11
	ctx.cr[6].compare_u32(ctx.r[10].u32, ctx.r[11].u32, &mut ctx.xer);
	// 8315EEF4: 409A0058  bne cr6, 0x8315ef4c
	if !ctx.cr[6].eq {
	pc = 0x8315EF4C; continue 'dispatch;
	}
	// 8315EEF8: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315EEFC: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EF00: 409A0010  bne cr6, 0x8315ef10
	if !ctx.cr[6].eq {
	pc = 0x8315EF10; continue 'dispatch;
	}
	// 8315EF04: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315EF08: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315EF0C: 480492AC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315EF10: 39600002  li r11, 2
	ctx.r[11].s64 = 2;
	// 8315EF14: 93BF0014  stw r29, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u32 ) };
	// 8315EF18: 39400001  li r10, 1
	ctx.r[10].s64 = 1;
	// 8315EF1C: 997F000D  stb r11, 0xd(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(13 as u32), ctx.r[11].u8 ) };
	// 8315EF20: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EF24: 995F000C  stb r10, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[10].u8 ) };
	// 8315EF28: 4BFFFA19  bl 0x8315e940
	ctx.lr = 0x8315EF2C;
	sub_8315E940(ctx, base);
	// 8315EF2C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EF30: 4BFFFD59  bl 0x8315ec88
	ctx.lr = 0x8315EF34;
	sub_8315EC88(ctx, base);
	// 8315EF34: 813E000C  lwz r9, 0xc(r30)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EF38: 7D034A14  add r8, r3, r9
	ctx.r[8].u64 = ctx.r[3].u64 + ctx.r[9].u64;
	// 8315EF3C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EF40: 911E000C  stw r8, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[8].u32 ) };
	// 8315EF44: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315EF48: 48049270  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315EF4C: 7F853050  subf r28, r5, r6
	ctx.r[28].s64 = ctx.r[6].s64 - ctx.r[5].s64;
	// 8315EF50: 7CE43B78  mr r4, r7
	ctx.r[4].u64 = ctx.r[7].u64;
	// 8315EF54: 7F83E378  mr r3, r28
	ctx.r[3].u64 = ctx.r[28].u64;
	// 8315EF58: 4BFFF999  bl 0x8315e8f0
	ctx.lr = 0x8315EF5C;
	sub_8315E8F0(ctx, base);
	// 8315EF5C: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315EF60: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EF64: 7D6AE050  subf r11, r10, r28
	ctx.r[11].s64 = ctx.r[28].s64 - ctx.r[10].s64;
	// 8315EF68: 390AFFE4  addi r8, r10, -0x1c
	ctx.r[8].s64 = ctx.r[10].s64 + -28;
	// 8315EF6C: 5569043E  clrlwi r9, r11, 0x10
	ctx.r[9].u64 = ctx.r[11].u32 as u64 & 0x0000FFFFu64;
	// 8315EF70: 55070038  rlwinm r7, r8, 0, 0, 0x1c
	ctx.r[7].u64 = ctx.r[8].u32 as u64 & 0xFFFFFFFFu64;
	// 8315EF74: 4BFFFD05  bl 0x8315ec78
	ctx.lr = 0x8315EF78;
	sub_8315EC78(ctx, base);
	// 8315EF78: 7F071840  cmplw cr6, r7, r3
	ctx.cr[6].compare_u32(ctx.r[7].u32, ctx.r[3].u32, &mut ctx.xer);
	// 8315EF7C: 40980064  bge cr6, 0x8315efe0
	if !ctx.cr[6].lt {
	pc = 0x8315EFE0; continue 'dispatch;
	}
	// 8315EF80: 897F000D  lbz r11, 0xd(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[31].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315EF84: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315EF88: 419AFF7C  beq cr6, 0x8315ef04
	if ctx.cr[6].eq {
	pc = 0x8315EF04; continue 'dispatch;
	}
	// 8315EF8C: 7D7F5050  subf r11, r31, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[31].s64;
	// 8315EF90: B13F0010  sth r9, 0x10(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[9].u16 ) };
	// 8315EF94: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8315EF98: 90BF0008  stw r5, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 8315EF9C: 3D2B0001  addis r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 65536;
	// 8315EFA0: 93BF0014  stw r29, 0x14(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(20 as u32), ctx.r[29].u32 ) };
	// 8315EFA4: 39000001  li r8, 1
	ctx.r[8].s64 = 1;
	// 8315EFA8: 995F000D  stb r10, 0xd(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(13 as u32), ctx.r[10].u8 ) };
	// 8315EFAC: 3929FFE4  addi r9, r9, -0x1c
	ctx.r[9].s64 = ctx.r[9].s64 + -28;
	// 8315EFB0: 991F000C  stb r8, 0xc(r31)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[31].u32.wrapping_add(12 as u32), ctx.r[8].u8 ) };
	// 8315EFB4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EFB8: B13F000E  sth r9, 0xe(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(14 as u32), ctx.r[9].u16 ) };
	// 8315EFBC: 4BFFF985  bl 0x8315e940
	ctx.lr = 0x8315EFC0;
	sub_8315E940(ctx, base);
	// 8315EFC0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EFC4: 4BFFFCC5  bl 0x8315ec88
	ctx.lr = 0x8315EFC8;
	sub_8315EC88(ctx, base);
	// 8315EFC8: 80DE000C  lwz r6, 0xc(r30)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315EFCC: 7CA33214  add r5, r3, r6
	ctx.r[5].u64 = ctx.r[3].u64 + ctx.r[6].u64;
	// 8315EFD0: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315EFD4: 90BE000C  stw r5, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[5].u32 ) };
	// 8315EFD8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315EFDC: 480491DC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315EFE0: 7D675050  subf r11, r7, r10
	ctx.r[11].s64 = ctx.r[10].s64 - ctx.r[7].s64;
	// 8315EFE4: 90A70008  stw r5, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[5].u32 ) };
	// 8315EFE8: 39400002  li r10, 2
	ctx.r[10].s64 = 2;
	// 8315EFEC: 3D0B0001  addis r8, r11, 1
	ctx.r[8].s64 = ctx.r[11].s64 + 65536;
	// 8315EFF0: 38C00001  li r6, 1
	ctx.r[6].s64 = 1;
	// 8315EFF4: 9947000D  stb r10, 0xd(r7)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[7].u32.wrapping_add(13 as u32), ctx.r[10].u8 ) };
	// 8315EFF8: 3908FFE4  addi r8, r8, -0x1c
	ctx.r[8].s64 = ctx.r[8].s64 + -28;
	// 8315EFFC: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F000: B107000E  sth r8, 0xe(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(14 as u32), ctx.r[8].u16 ) };
	// 8315F004: 809F0004  lwz r4, 4(r31)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F008: 90870004  stw r4, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[4].u32 ) };
	// 8315F00C: 93E70000  stw r31, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[31].u32 ) };
	// 8315F010: B1270010  sth r9, 0x10(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(16 as u32), ctx.r[9].u16 ) };
	// 8315F014: 93A70014  stw r29, 0x14(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), ctx.r[29].u32 ) };
	// 8315F018: 98C7000C  stb r6, 0xc(r7)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[6].u8 ) };
	// 8315F01C: 4BFFF925  bl 0x8315e940
	ctx.lr = 0x8315F020;
	sub_8315E940(ctx, base);
	// 8315F020: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F024: 4BFFFC65  bl 0x8315ec88
	ctx.lr = 0x8315F028;
	sub_8315EC88(ctx, base);
	// 8315F028: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F02C: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315F030: 7D435A14  add r10, r3, r11
	ctx.r[10].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 8315F034: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F038: 915E000C  stw r10, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8315F03C: 4BFFF965  bl 0x8315e9a0
	ctx.lr = 0x8315F040;
	sub_8315E9A0(ctx, base);
	// 8315F040: 817F0004  lwz r11, 4(r31)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[31].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F044: B07F000E  sth r3, 0xe(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(14 as u32), ctx.r[3].u16 ) };
	// 8315F048: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F04C: 419A0008  beq cr6, 0x8315f054
	if ctx.cr[6].eq {
	pc = 0x8315F054; continue 'dispatch;
	}
	// 8315F050: 90EB0000  stw r7, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 8315F054: 90FF0004  stw r7, 4(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 8315F058: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F05C: 4BFFF845  bl 0x8315e8a0
	ctx.lr = 0x8315F060;
	sub_8315E8A0(ctx, base);
	// 8315F060: 546B043E  clrlwi r11, r3, 0x10
	ctx.r[11].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315F064: 7D5F3850  subf r10, r31, r7
	ctx.r[10].s64 = ctx.r[7].s64 - ctx.r[31].s64;
	// 8315F068: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8315F06C: 7D0B5050  subf r8, r11, r10
	ctx.r[8].s64 = ctx.r[10].s64 - ctx.r[11].s64;
	// 8315F070: B13F0010  sth r9, 0x10(r31)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[31].u32.wrapping_add(16 as u32), ctx.r[9].u16 ) };
	// 8315F074: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F078: 911F0008  stw r8, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8315F07C: 4BFFF865  bl 0x8315e8e0
	ctx.lr = 0x8315F080;
	sub_8315E8E0(ctx, base);
	// 8315F080: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315F084: 409A0008  bne cr6, 0x8315f08c
	if !ctx.cr[6].eq {
	pc = 0x8315F08C; continue 'dispatch;
	}
	// 8315F088: 90FE0014  stw r7, 0x14(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), ctx.r[7].u32 ) };
	// 8315F08C: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F090: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F094: 48049124  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F098(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F098 size=188
    let mut pc: u32 = 0x8315F098;
    'dispatch: loop {
        match pc {
            0x8315F098 => {
    //   block [0x8315F098..0x8315F154)
	// 8315F098: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F09C: 480490C9  bl 0x831a8164
	ctx.lr = 0x8315F0A0;
	sub_831A8130(ctx, base);
	// 8315F0A0: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F0A4: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 8315F0A8: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315F0AC: 7C9C2378  mr r28, r4
	ctx.r[28].u64 = ctx.r[4].u64;
	// 8315F0B0: 7CDB3378  mr r27, r6
	ctx.r[27].u64 = ctx.r[6].u64;
	// 8315F0B4: 7CFD3B78  mr r29, r7
	ctx.r[29].u64 = ctx.r[7].u64;
	// 8315F0B8: 2F1F0000  cmpwi cr6, r31, 0
	ctx.cr[6].compare_i32(ctx.r[31].s32, 0, &mut ctx.xer);
	// 8315F0BC: 40980010  bge cr6, 0x8315f0cc
	if !ctx.cr[6].lt {
	pc = 0x8315F0CC; continue 'dispatch;
	}
	// 8315F0C0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F0C4: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F0C8: 480490EC  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
	// 8315F0CC: 57A6043E  clrlwi r6, r29, 0x10
	ctx.r[6].u64 = ctx.r[29].u32 as u64 & 0x0000FFFFu64;
	// 8315F0D0: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8315F0D4: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8315F0D8: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315F0DC: 4BFFFB45  bl 0x8315ec20
	ctx.lr = 0x8315F0E0;
	sub_8315EC20(ctx, base);
	// 8315F0E0: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8315F0E4: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315F0E8: 419AFFD8  beq cr6, 0x8315f0c0
	if ctx.cr[6].eq {
	pc = 0x8315F0C0; continue 'dispatch;
	}
	// 8315F0EC: 2F1C0001  cmpwi cr6, r28, 1
	ctx.cr[6].compare_i32(ctx.r[28].s32, 1, &mut ctx.xer);
	// 8315F0F0: 419A002C  beq cr6, 0x8315f11c
	if ctx.cr[6].eq {
	pc = 0x8315F11C; continue 'dispatch;
	}
	// 8315F0F4: 2F1C0002  cmpwi cr6, r28, 2
	ctx.cr[6].compare_i32(ctx.r[28].s32, 2, &mut ctx.xer);
	// 8315F0F8: 419A000C  beq cr6, 0x8315f104
	if ctx.cr[6].eq {
	pc = 0x8315F104; continue 'dispatch;
	}
	// 8315F0FC: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8315F100: 48000034  b 0x8315f134
	pc = 0x8315F134; continue 'dispatch;
	// 8315F104: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 8315F108: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 8315F10C: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8315F110: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315F114: 4BFFFD9D  bl 0x8315eeb0
	ctx.lr = 0x8315F118;
	sub_8315EEB0(ctx, base);
	// 8315F118: 48000018  b 0x8315f130
	pc = 0x8315F130; continue 'dispatch;
	// 8315F11C: 7FA7EB78  mr r7, r29
	ctx.r[7].u64 = ctx.r[29].u64;
	// 8315F120: 7F66DB78  mr r6, r27
	ctx.r[6].u64 = ctx.r[27].u64;
	// 8315F124: 7FE5FB78  mr r5, r31
	ctx.r[5].u64 = ctx.r[31].u64;
	// 8315F128: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315F12C: 4BFFFBFD  bl 0x8315ed28
	ctx.lr = 0x8315F130;
	sub_8315ED28(ctx, base);
	// 8315F130: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 8315F134: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315F138: 4BFFFB29  bl 0x8315ec60
	ctx.lr = 0x8315F13C;
	sub_8315EC60(ctx, base);
	// 8315F13C: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8315F140: 419AFF80  beq cr6, 0x8315f0c0
	if ctx.cr[6].eq {
	pc = 0x8315F0C0; continue 'dispatch;
	}
	// 8315F144: 7D234B78  mr r3, r9
	ctx.r[3].u64 = ctx.r[9].u64;
	// 8315F148: 4BFFFB31  bl 0x8315ec78
	ctx.lr = 0x8315F14C;
	sub_8315EC78(ctx, base);
	// 8315F14C: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F150: 48049064  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F158(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F158 size=20
    let mut pc: u32 = 0x8315F158;
    'dispatch: loop {
        match pc {
            0x8315F158 => {
    //   block [0x8315F158..0x8315F16C)
	// 8315F158: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 8315F15C: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 8315F160: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 8315F164: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315F168: 4BFFFF30  b 0x8315f098
	sub_8315F098(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F170(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F170 size=20
    let mut pc: u32 = 0x8315F170;
    'dispatch: loop {
        match pc {
            0x8315F170 => {
    //   block [0x8315F170..0x8315F184)
	// 8315F170: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 8315F174: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 8315F178: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 8315F17C: 38800002  li r4, 2
	ctx.r[4].s64 = 2;
	// 8315F180: 4BFFFF18  b 0x8315f098
	sub_8315F098(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F188(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F188 size=20
    let mut pc: u32 = 0x8315F188;
    'dispatch: loop {
        match pc {
            0x8315F188 => {
    //   block [0x8315F188..0x8315F19C)
	// 8315F188: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 8315F18C: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 8315F190: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 8315F194: 38800003  li r4, 3
	ctx.r[4].s64 = 3;
	// 8315F198: 4BFFFF00  b 0x8315f098
	sub_8315F098(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F1A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F1A0 size=20
    let mut pc: u32 = 0x8315F1A0;
    'dispatch: loop {
        match pc {
            0x8315F1A0 => {
    //   block [0x8315F1A0..0x8315F1B4)
	// 8315F1A0: 81630004  lwz r11, 4(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F1A4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F1A8: 409A000C  bne cr6, 0x8315f1b4
	if !ctx.cr[6].eq {
		sub_8315F1B4(ctx, base);
		return;
	}
	// 8315F1AC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F1B0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F1B4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F1B4 size=16
    let mut pc: u32 = 0x8315F1B4;
    'dispatch: loop {
        match pc {
            0x8315F1B4 => {
    //   block [0x8315F1B4..0x8315F1C4)
	// 8315F1B4: 896B000D  lbz r11, 0xd(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315F1B8: 7D6A0034  cntlzw r10, r11
	ctx.r[10].u64 = if ctx.r[11].u32 == 0 { 32 } else { ctx.r[11].u32.leading_zeros() as u64 };
	// 8315F1BC: 5543DFFE  rlwinm r3, r10, 0x1b, 0x1f, 0x1f
	ctx.r[3].u64 = ctx.r[10].u32 as u64 & 0x0000001Fu64;
	// 8315F1C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F1C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F1C8 size=324
    let mut pc: u32 = 0x8315F1C8;
    'dispatch: loop {
        match pc {
            0x8315F1C8 => {
    //   block [0x8315F1C8..0x8315F30C)
	// 8315F1C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F1CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F1D0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F1D4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F1D8: 8964000C  lbz r11, 0xc(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F1DC: 7C651B78  mr r5, r3
	ctx.r[5].u64 = ctx.r[3].u64;
	// 8315F1E0: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8315F1E4: 409A0018  bne cr6, 0x8315f1fc
	if !ctx.cr[6].eq {
	pc = 0x8315F1FC; continue 'dispatch;
	}
	// 8315F1E8: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315F1EC: 4BFFFA9D  bl 0x8315ec88
	ctx.lr = 0x8315F1F0;
	sub_8315EC88(ctx, base);
	// 8315F1F0: 8165000C  lwz r11, 0xc(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F1F4: 7D435850  subf r10, r3, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 8315F1F8: 9145000C  stw r10, 0xc(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8315F1FC: 80E40004  lwz r7, 4(r4)
	ctx.r[7].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F200: 3BE00000  li r31, 0
	ctx.r[31].s64 = 0;
	// 8315F204: 81040000  lwz r8, 0(r4)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F208: 7FE6FB78  mr r6, r31
	ctx.r[6].u64 = ctx.r[31].u64;
	// 8315F20C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8315F210: 419A0008  beq cr6, 0x8315f218
	if ctx.cr[6].eq {
	pc = 0x8315F218; continue 'dispatch;
	}
	// 8315F214: 80C70004  lwz r6, 4(r7)
	ctx.r[6].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F218: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8315F21C: 9BE4000C  stb r31, 0xc(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[31].u8 ) };
	// 8315F220: 419A0048  beq cr6, 0x8315f268
	if ctx.cr[6].eq {
	pc = 0x8315F268; continue 'dispatch;
	}
	// 8315F224: 8968000C  lbz r11, 0xc(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[8].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F228: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F22C: 409A003C  bne cr6, 0x8315f268
	if !ctx.cr[6].eq {
	pc = 0x8315F268; continue 'dispatch;
	}
	// 8315F230: 90E80004  stw r7, 4(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[7].u32 ) };
	// 8315F234: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315F238: 4BFFFA51  bl 0x8315ec88
	ctx.lr = 0x8315F23C;
	sub_8315EC88(ctx, base);
	// 8315F23C: 81680008  lwz r11, 8(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315F240: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8315F244: 7D435A14  add r10, r3, r11
	ctx.r[10].u64 = ctx.r[3].u64 + ctx.r[11].u64;
	// 8315F248: 91480008  stw r10, 8(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[10].u32 ) };
	// 8315F24C: 419A0008  beq cr6, 0x8315f254
	if ctx.cr[6].eq {
	pc = 0x8315F254; continue 'dispatch;
	}
	// 8315F250: 91070000  stw r8, 0(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8315F254: 81680004  lwz r11, 4(r8)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F258: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F25C: 409A0010  bne cr6, 0x8315f26c
	if !ctx.cr[6].eq {
	pc = 0x8315F26C; continue 'dispatch;
	}
	// 8315F260: 91050014  stw r8, 0x14(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), ctx.r[8].u32 ) };
	// 8315F264: 48000008  b 0x8315f26c
	pc = 0x8315F26C; continue 'dispatch;
	// 8315F268: 7C882378  mr r8, r4
	ctx.r[8].u64 = ctx.r[4].u64;
	// 8315F26C: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8315F270: 419A0088  beq cr6, 0x8315f2f8
	if ctx.cr[6].eq {
	pc = 0x8315F2F8; continue 'dispatch;
	}
	// 8315F274: 8967000C  lbz r11, 0xc(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F278: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F27C: 409A007C  bne cr6, 0x8315f2f8
	if !ctx.cr[6].eq {
	pc = 0x8315F2F8; continue 'dispatch;
	}
	// 8315F280: 81670004  lwz r11, 4(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F284: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F288: 91680004  stw r11, 4(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315F28C: 4BFFF9FD  bl 0x8315ec88
	ctx.lr = 0x8315F290;
	sub_8315EC88(ctx, base);
	// 8315F290: 81480008  lwz r10, 8(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315F294: 7D235214  add r9, r3, r10
	ctx.r[9].u64 = ctx.r[3].u64 + ctx.r[10].u64;
	// 8315F298: 91280008  stw r9, 8(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(8 as u32), ctx.r[9].u32 ) };
	// 8315F29C: 81670004  lwz r11, 4(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F2A0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F2A4: 419A0008  beq cr6, 0x8315f2ac
	if ctx.cr[6].eq {
	pc = 0x8315F2AC; continue 'dispatch;
	}
	// 8315F2A8: 910B0000  stw r8, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8315F2AC: 7F082040  cmplw cr6, r8, r4
	ctx.cr[6].compare_u32(ctx.r[8].u32, ctx.r[4].u32, &mut ctx.xer);
	// 8315F2B0: 409A0014  bne cr6, 0x8315f2c4
	if !ctx.cr[6].eq {
	pc = 0x8315F2C4; continue 'dispatch;
	}
	// 8315F2B4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8315F2B8: 409A0018  bne cr6, 0x8315f2d0
	if !ctx.cr[6].eq {
	pc = 0x8315F2D0; continue 'dispatch;
	}
	// 8315F2BC: 90850014  stw r4, 0x14(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), ctx.r[4].u32 ) };
	// 8315F2C0: 48000010  b 0x8315f2d0
	pc = 0x8315F2D0; continue 'dispatch;
	// 8315F2C4: 2B060000  cmplwi cr6, r6, 0
	ctx.cr[6].compare_u32(ctx.r[6].u32, 0 as u32, &mut ctx.xer);
	// 8315F2C8: 409A0008  bne cr6, 0x8315f2d0
	if !ctx.cr[6].eq {
	pc = 0x8315F2D0; continue 'dispatch;
	}
	// 8315F2CC: 91050014  stw r8, 0x14(r5)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[5].u32.wrapping_add(20 as u32), ctx.r[8].u32 ) };
	// 8315F2D0: 8967000D  lbz r11, 0xd(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[7].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315F2D4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F2D8: 409A0008  bne cr6, 0x8315f2e0
	if !ctx.cr[6].eq {
	pc = 0x8315F2E0; continue 'dispatch;
	}
	// 8315F2DC: 9BE8000D  stb r31, 0xd(r8)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[8].u32.wrapping_add(13 as u32), ctx.r[31].u8 ) };
	// 8315F2E0: 81670014  lwz r11, 0x14(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(20 as u32) ) } as u64;
	// 8315F2E4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F2E8: 409A0008  bne cr6, 0x8315f2f0
	if !ctx.cr[6].eq {
	pc = 0x8315F2F0; continue 'dispatch;
	}
	// 8315F2EC: 93E80014  stw r31, 0x14(r8)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[8].u32.wrapping_add(20 as u32), ctx.r[31].u32 ) };
	// 8315F2F0: 7D034378  mr r3, r8
	ctx.r[3].u64 = ctx.r[8].u64;
	// 8315F2F4: 4BFFF64D  bl 0x8315e940
	ctx.lr = 0x8315F2F8;
	sub_8315E940(ctx, base);
	// 8315F2F8: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F2FC: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F300: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F304: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315F308: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F310(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F310 size=320
    let mut pc: u32 = 0x8315F310;
    'dispatch: loop {
        match pc {
            0x8315F310 => {
    //   block [0x8315F310..0x8315F450)
	// 8315F310: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F314: 48048E59  bl 0x831a816c
	ctx.lr = 0x8315F318;
	sub_831A8130(ctx, base);
	// 8315F318: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F31C: 8964000D  lbz r11, 0xd(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[4].u32.wrapping_add(13 as u32) ) } as u64;
	// 8315F320: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315F324: 83A40008  lwz r29, 8(r4)
	ctx.r[29].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315F328: 2B0B0002  cmplwi cr6, r11, 2
	ctx.cr[6].compare_u32(ctx.r[11].u32, 2 as u32, &mut ctx.xer);
	// 8315F32C: 409A0014  bne cr6, 0x8315f340
	if !ctx.cr[6].eq {
	pc = 0x8315F340; continue 'dispatch;
	}
	// 8315F330: 4BFFFE99  bl 0x8315f1c8
	ctx.lr = 0x8315F334;
	sub_8315F1C8(ctx, base);
	// 8315F334: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315F338: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F33C: 48048E80  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315F340: 2B0B0001  cmplwi cr6, r11, 1
	ctx.cr[6].compare_u32(ctx.r[11].u32, 1 as u32, &mut ctx.xer);
	// 8315F344: 409A0100  bne cr6, 0x8315f444
	if !ctx.cr[6].eq {
	pc = 0x8315F444; continue 'dispatch;
	}
	// 8315F348: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315F34C: 4BFFF93D  bl 0x8315ec88
	ctx.lr = 0x8315F350;
	sub_8315EC88(ctx, base);
	// 8315F350: 817E000C  lwz r11, 0xc(r30)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F354: 7D435850  subf r10, r3, r11
	ctx.r[10].s64 = ctx.r[11].s64 - ctx.r[3].s64;
	// 8315F358: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315F35C: 915E000C  stw r10, 0xc(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(12 as u32), ctx.r[10].u32 ) };
	// 8315F360: 4BFFFE41  bl 0x8315f1a0
	ctx.lr = 0x8315F364;
	sub_8315F1A0(ctx, base);
	// 8315F364: 2F030001  cmpwi cr6, r3, 1
	ctx.cr[6].compare_i32(ctx.r[3].s32, 1, &mut ctx.xer);
	// 8315F368: 409A00B4  bne cr6, 0x8315f41c
	if !ctx.cr[6].eq {
	pc = 0x8315F41C; continue 'dispatch;
	}
	// 8315F36C: 80A40004  lwz r5, 4(r4)
	ctx.r[5].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F370: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 8315F374: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8315F378: 4BFFF911  bl 0x8315ec88
	ctx.lr = 0x8315F37C;
	sub_8315EC88(ctx, base);
	// 8315F37C: 81640000  lwz r11, 0(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F380: 7FE32A14  add r31, r3, r5
	ctx.r[31].u64 = ctx.r[3].u64 + ctx.r[5].u64;
	// 8315F384: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F388: 419A0024  beq cr6, 0x8315f3ac
	if ctx.cr[6].eq {
	pc = 0x8315F3AC; continue 'dispatch;
	}
	// 8315F38C: 81670000  lwz r11, 0(r7)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[7].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F390: 894B000C  lbz r10, 0xc(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F394: 2B0A0001  cmplwi cr6, r10, 1
	ctx.cr[6].compare_u32(ctx.r[10].u32, 1 as u32, &mut ctx.xer);
	// 8315F398: 419A0014  beq cr6, 0x8315f3ac
	if ctx.cr[6].eq {
	pc = 0x8315F3AC; continue 'dispatch;
	}
	// 8315F39C: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F3A0: 7D675B78  mr r7, r11
	ctx.r[7].u64 = ctx.r[11].u64;
	// 8315F3A4: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315F3A8: 409AFFE4  bne cr6, 0x8315f38c
	if !ctx.cr[6].eq {
	pc = 0x8315F38C; continue 'dispatch;
	}
	// 8315F3AC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315F3B0: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315F3B4: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F3B8: 98C7000C  stb r6, 0xc(r7)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[7].u32.wrapping_add(12 as u32), ctx.r[6].u8 ) };
	// 8315F3BC: 98C7000D  stb r6, 0xd(r7)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[7].u32.wrapping_add(13 as u32), ctx.r[6].u8 ) };
	// 8315F3C0: 4BFFF5E1  bl 0x8315e9a0
	ctx.lr = 0x8315F3C4;
	sub_8315E9A0(ctx, base);
	// 8315F3C4: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8315F3C8: B0C70010  sth r6, 0x10(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(16 as u32), ctx.r[6].u16 ) };
	// 8315F3CC: 7CE33B78  mr r3, r7
	ctx.r[3].u64 = ctx.r[7].u64;
	// 8315F3D0: B167000E  sth r11, 0xe(r7)
	unsafe { crate::rt::store_u16( base as *mut u8, ctx.r[7].u32.wrapping_add(14 as u32), ctx.r[11].u16 ) };
	// 8315F3D4: 90C70014  stw r6, 0x14(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(20 as u32), ctx.r[6].u32 ) };
	// 8315F3D8: 4BFFF4C9  bl 0x8315e8a0
	ctx.lr = 0x8315F3DC;
	sub_8315E8A0(ctx, base);
	// 8315F3DC: 546A043E  clrlwi r10, r3, 0x10
	ctx.r[10].u64 = ctx.r[3].u32 as u64 & 0x0000FFFFu64;
	// 8315F3E0: 7D27F850  subf r9, r7, r31
	ctx.r[9].s64 = ctx.r[31].s64 - ctx.r[7].s64;
	// 8315F3E4: 7D0A4850  subf r8, r10, r9
	ctx.r[8].s64 = ctx.r[9].s64 - ctx.r[10].s64;
	// 8315F3E8: 91070008  stw r8, 8(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(8 as u32), ctx.r[8].u32 ) };
	// 8315F3EC: 81650004  lwz r11, 4(r5)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[5].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F3F0: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F3F4: 91670004  stw r11, 4(r7)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[7].u32.wrapping_add(4 as u32), ctx.r[11].u32 ) };
	// 8315F3F8: 419A0014  beq cr6, 0x8315f40c
	if ctx.cr[6].eq {
	pc = 0x8315F40C; continue 'dispatch;
	}
	// 8315F3FC: 90EB0000  stw r7, 0(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[7].u32 ) };
	// 8315F400: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315F404: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F408: 48048DB4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315F40C: 90FE0014  stw r7, 0x14(r30)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[30].u32.wrapping_add(20 as u32), ctx.r[7].u32 ) };
	// 8315F410: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315F414: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F418: 48048DA4  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315F41C: 81640004  lwz r11, 4(r4)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F420: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315F424: 98C4000C  stb r6, 0xc(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(12 as u32), ctx.r[6].u8 ) };
	// 8315F428: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F42C: 409A000C  bne cr6, 0x8315f438
	if !ctx.cr[6].eq {
	pc = 0x8315F438; continue 'dispatch;
	}
	// 8315F430: 98C4000D  stb r6, 0xd(r4)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[4].u32.wrapping_add(13 as u32), ctx.r[6].u8 ) };
	// 8315F434: 90C40014  stw r6, 0x14(r4)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[4].u32.wrapping_add(20 as u32), ctx.r[6].u32 ) };
	// 8315F438: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315F43C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F440: 48048D7C  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315F444: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315F448: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F44C: 48048D70  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F450(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F450 size=132
    let mut pc: u32 = 0x8315F450;
    'dispatch: loop {
        match pc {
            0x8315F450 => {
    //   block [0x8315F450..0x8315F4D4)
	// 8315F450: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F454: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F458: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F45C: 7C691B78  mr r9, r3
	ctx.r[9].u64 = ctx.r[3].u64;
	// 8315F460: 2B040000  cmplwi cr6, r4, 0
	ctx.cr[6].compare_u32(ctx.r[4].u32, 0 as u32, &mut ctx.xer);
	// 8315F464: 409A0010  bne cr6, 0x8315f474
	if !ctx.cr[6].eq {
	pc = 0x8315F474; continue 'dispatch;
	}
	// 8315F468: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F46C: 388B61FC  addi r4, r11, 0x61fc
	ctx.r[4].s64 = ctx.r[11].s64 + 25084;
	// 8315F470: 48000048  b 0x8315f4b8
	pc = 0x8315F4B8; continue 'dispatch;
	// 8315F474: 7F092040  cmplw cr6, r9, r4
	ctx.cr[6].compare_u32(ctx.r[9].u32, ctx.r[4].u32, &mut ctx.xer);
	// 8315F478: 41990038  bgt cr6, 0x8315f4b0
	if ctx.cr[6].gt {
	pc = 0x8315F4B0; continue 'dispatch;
	}
	// 8315F47C: 81690004  lwz r11, 4(r9)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[9].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F480: 7D6B4A14  add r11, r11, r9
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[9].u64;
	// 8315F484: 7F0B2040  cmplw cr6, r11, r4
	ctx.cr[6].compare_u32(ctx.r[11].u32, ctx.r[4].u32, &mut ctx.xer);
	// 8315F488: 41980028  blt cr6, 0x8315f4b0
	if ctx.cr[6].lt {
	pc = 0x8315F4B0; continue 'dispatch;
	}
	// 8315F48C: 7C832378  mr r3, r4
	ctx.r[3].u64 = ctx.r[4].u64;
	// 8315F490: 4BFFF4E9  bl 0x8315e978
	ctx.lr = 0x8315F494;
	sub_8315E978(ctx, base);
	// 8315F494: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8315F498: 7D234B78  mr r3, r9
	ctx.r[3].u64 = ctx.r[9].u64;
	// 8315F49C: 4BFFFE75  bl 0x8315f310
	ctx.lr = 0x8315F4A0;
	sub_8315F310(ctx, base);
	// 8315F4A0: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F4A4: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F4A8: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F4AC: 4E800020  blr
	return;
	// 8315F4B0: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F4B4: 388B61D4  addi r4, r11, 0x61d4
	ctx.r[4].s64 = ctx.r[11].s64 + 25044;
	// 8315F4B8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F4BC: 4800065D  bl 0x8315fb18
	ctx.lr = 0x8315F4C0;
	sub_8315FB18(ctx, base);
	// 8315F4C0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F4C4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F4C8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F4CC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F4D0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F4D8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F4D8 size=84
    let mut pc: u32 = 0x8315F4D8;
    'dispatch: loop {
        match pc {
            0x8315F4D8 => {
    //   block [0x8315F4D8..0x8315F52C)
	// 8315F4D8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F4DC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F4E0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F4E4: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315F4E8: 806B81A8  lwz r3, -0x7e58(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-32344 as u32) ) } as u64;
	// 8315F4EC: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315F4F0: 409A0024  bne cr6, 0x8315f514
	if !ctx.cr[6].eq {
	pc = 0x8315F514; continue 'dispatch;
	}
	// 8315F4F4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F4F8: 388B621C  addi r4, r11, 0x621c
	ctx.r[4].s64 = ctx.r[11].s64 + 25116;
	// 8315F4FC: 4800061D  bl 0x8315fb18
	ctx.lr = 0x8315F500;
	sub_8315FB18(ctx, base);
	// 8315F500: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315F504: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F508: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F50C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F510: 4E800020  blr
	return;
	// 8315F514: 480008B5  bl 0x8315fdc8
	ctx.lr = 0x8315F518;
	sub_8315FDC8(ctx, base);
	// 8315F518: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F51C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F520: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F524: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F528: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F530(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F530 size=84
    let mut pc: u32 = 0x8315F530;
    'dispatch: loop {
        match pc {
            0x8315F530 => {
    //   block [0x8315F530..0x8315F584)
	// 8315F530: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F534: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F538: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F53C: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315F540: 806B81A8  lwz r3, -0x7e58(r11)
	ctx.r[3].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(-32344 as u32) ) } as u64;
	// 8315F544: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315F548: 409A0024  bne cr6, 0x8315f56c
	if !ctx.cr[6].eq {
	pc = 0x8315F56C; continue 'dispatch;
	}
	// 8315F54C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F550: 388B6244  addi r4, r11, 0x6244
	ctx.r[4].s64 = ctx.r[11].s64 + 25156;
	// 8315F554: 480005C5  bl 0x8315fb18
	ctx.lr = 0x8315F558;
	sub_8315FB18(ctx, base);
	// 8315F558: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315F55C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F560: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F564: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F568: 4E800020  blr
	return;
	// 8315F56C: 48000875  bl 0x8315fde0
	ctx.lr = 0x8315F570;
	sub_8315FDE0(ctx, base);
	// 8315F570: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F574: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F578: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F57C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F580: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F588(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F588 size=20
    let mut pc: u32 = 0x8315F588;
    'dispatch: loop {
        match pc {
            0x8315F588 => {
    //   block [0x8315F588..0x8315F59C)
	// 8315F588: 2F030008  cmpwi cr6, r3, 8
	ctx.cr[6].compare_i32(ctx.r[3].s32, 8, &mut ctx.xer);
	// 8315F58C: 40980010  bge cr6, 0x8315f59c
	if !ctx.cr[6].lt {
		sub_8315F59C(ctx, base);
		return;
	}
	// 8315F590: 39600008  li r11, 8
	ctx.r[11].s64 = 8;
	// 8315F594: 386B0024  addi r3, r11, 0x24
	ctx.r[3].s64 = ctx.r[11].s64 + 36;
	// 8315F598: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F59C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F59C size=8
    let mut pc: u32 = 0x8315F59C;
    'dispatch: loop {
        match pc {
            0x8315F59C => {
    //   block [0x8315F59C..0x8315F5A4)
	// 8315F59C: 38630024  addi r3, r3, 0x24
	ctx.r[3].s64 = ctx.r[3].s64 + 36;
	// 8315F5A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F5A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F5A8 size=16
    let mut pc: u32 = 0x8315F5A8;
    'dispatch: loop {
        match pc {
            0x8315F5A8 => {
    //   block [0x8315F5A8..0x8315F5B8)
	// 8315F5A8: 7C671B78  mr r7, r3
	ctx.r[7].u64 = ctx.r[3].u64;
	// 8315F5AC: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315F5B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F5B4: 48000494  b 0x8315fa48
	sub_8315FA48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F5B8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F5B8 size=96
    let mut pc: u32 = 0x8315F5B8;
    'dispatch: loop {
        match pc {
            0x8315F5B8 => {
    //   block [0x8315F5B8..0x8315F618)
	// 8315F5B8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F5BC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F5C0: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F5C4: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F5C8: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315F5CC: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 8315F5D0: 3BEB81A0  addi r31, r11, -0x7e60
	ctx.r[31].s64 = ctx.r[11].s64 + -32352;
	// 8315F5D4: 392A6180  addi r9, r10, 0x6180
	ctx.r[9].s64 = ctx.r[10].s64 + 24960;
	// 8315F5D8: 912B81A0  stw r9, -0x7e60(r11)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[11].u32.wrapping_add(-32352 as u32), ctx.r[9].u32 ) };
	// 8315F5DC: 48004245  bl 0x83163820
	ctx.lr = 0x8315F5E0;
	sub_83163820(ctx, base);
	// 8315F5E0: 387F0010  addi r3, r31, 0x10
	ctx.r[3].s64 = ctx.r[31].s64 + 16;
	// 8315F5E4: 38800040  li r4, 0x40
	ctx.r[4].s64 = 64;
	// 8315F5E8: 480007B9  bl 0x8315fda0
	ctx.lr = 0x8315F5EC;
	sub_8315FDA0(ctx, base);
	// 8315F5EC: 907F0008  stw r3, 8(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(8 as u32), ctx.r[3].u32 ) };
	// 8315F5F0: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315F5F4: 409A0010  bne cr6, 0x8315f604
	if !ctx.cr[6].eq {
	pc = 0x8315F604; continue 'dispatch;
	}
	// 8315F5F8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F5FC: 388B626C  addi r4, r11, 0x626c
	ctx.r[4].s64 = ctx.r[11].s64 + 25196;
	// 8315F600: 48000519  bl 0x8315fb18
	ctx.lr = 0x8315F604;
	sub_8315FB18(ctx, base);
	// 8315F604: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F608: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F60C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F610: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315F614: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F618(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F618 size=28
    let mut pc: u32 = 0x8315F618;
    'dispatch: loop {
        match pc {
            0x8315F618 => {
    //   block [0x8315F618..0x8315F634)
	// 8315F618: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315F61C: 816A81A4  lwz r11, -0x7e5c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-32348 as u32) ) } as u64;
	// 8315F620: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 8315F624: 912A81A4  stw r9, -0x7e5c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-32348 as u32), ctx.r[9].u32 ) };
	// 8315F628: 810A81A4  lwz r8, -0x7e5c(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-32348 as u32) ) } as u64;
	// 8315F62C: 2F080000  cmpwi cr6, r8, 0
	ctx.cr[6].compare_i32(ctx.r[8].s32, 0, &mut ctx.xer);
	// 8315F630: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F634(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315F634 size=8
    let mut pc: u32 = 0x8315F634;
    'dispatch: loop {
        match pc {
            0x8315F634 => {
    //   block [0x8315F634..0x8315F63C)
	// 8315F634: 4BFFF21C  b 0x8315e850
	sub_8315E850(ctx, base);
	return;
	// 8315F638: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F640(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F640 size=96
    let mut pc: u32 = 0x8315F640;
    'dispatch: loop {
        match pc {
            0x8315F640 => {
    //   block [0x8315F640..0x8315F6A0)
	// 8315F640: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F644: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F648: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F64C: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F650: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F654: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315F658: 419A0020  beq cr6, 0x8315f678
	if ctx.cr[6].eq {
	pc = 0x8315F678; continue 'dispatch;
	}
	// 8315F65C: 554B003E  slwi r11, r10, 0
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315F660: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315F664: 4E800421  bctrl
	ctx.lr = 0x8315F668;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315F668: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F66C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F670: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F674: 4E800020  blr
	return;
	// 8315F678: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F67C: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315F680: 388B5ECC  addi r4, r11, 0x5ecc
	ctx.r[4].s64 = ctx.r[11].s64 + 24268;
	// 8315F684: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F688: 4BFFFF21  bl 0x8315f5a8
	ctx.lr = 0x8315F68C;
	sub_8315F5A8(ctx, base);
	// 8315F68C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F690: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F694: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F698: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F69C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F6A0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F6A0 size=92
    let mut pc: u32 = 0x8315F6A0;
    'dispatch: loop {
        match pc {
            0x8315F6A0 => {
    //   block [0x8315F6A0..0x8315F6FC)
	// 8315F6A0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F6A4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F6A8: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F6AC: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F6B0: 816B0004  lwz r11, 4(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F6B4: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F6B8: 419A001C  beq cr6, 0x8315f6d4
	if ctx.cr[6].eq {
	pc = 0x8315F6D4; continue 'dispatch;
	}
	// 8315F6BC: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315F6C0: 4E800421  bctrl
	ctx.lr = 0x8315F6C4;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315F6C4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F6C8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F6CC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F6D0: 4E800020  blr
	return;
	// 8315F6D4: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F6D8: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315F6DC: 388B5E98  addi r4, r11, 0x5e98
	ctx.r[4].s64 = ctx.r[11].s64 + 24216;
	// 8315F6E0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F6E4: 4BFFFEC5  bl 0x8315f5a8
	ctx.lr = 0x8315F6E8;
	sub_8315F5A8(ctx, base);
	// 8315F6E8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F6EC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F6F0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F6F4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F6F8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F700(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F700 size=104
    let mut pc: u32 = 0x8315F700;
    'dispatch: loop {
        match pc {
            0x8315F700 => {
    //   block [0x8315F700..0x8315F768)
	// 8315F700: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F704: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F708: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F70C: 2F070001  cmpwi cr6, r7, 1
	ctx.cr[6].compare_i32(ctx.r[7].s32, 1, &mut ctx.xer);
	// 8315F710: 409A0018  bne cr6, 0x8315f728
	if !ctx.cr[6].eq {
	pc = 0x8315F728; continue 'dispatch;
	}
	// 8315F714: 4BFFFF2D  bl 0x8315f640
	ctx.lr = 0x8315F718;
	sub_8315F640(ctx, base);
	// 8315F718: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F71C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F720: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F724: 4E800020  blr
	return;
	// 8315F728: 2F070002  cmpwi cr6, r7, 2
	ctx.cr[6].compare_i32(ctx.r[7].s32, 2, &mut ctx.xer);
	// 8315F72C: 409A0018  bne cr6, 0x8315f744
	if !ctx.cr[6].eq {
	pc = 0x8315F744; continue 'dispatch;
	}
	// 8315F730: 4BFFFF71  bl 0x8315f6a0
	ctx.lr = 0x8315F734;
	sub_8315F6A0(ctx, base);
	// 8315F734: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F738: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F73C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F740: 4E800020  blr
	return;
	// 8315F744: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F748: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F74C: 388B629C  addi r4, r11, 0x629c
	ctx.r[4].s64 = ctx.r[11].s64 + 25244;
	// 8315F750: 480003C9  bl 0x8315fb18
	ctx.lr = 0x8315F754;
	sub_8315FB18(ctx, base);
	// 8315F754: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F758: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F75C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F760: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F764: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F768(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F768 size=92
    let mut pc: u32 = 0x8315F768;
    'dispatch: loop {
        match pc {
            0x8315F768 => {
    //   block [0x8315F768..0x8315F7C4)
	// 8315F768: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F76C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F770: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F774: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315F778: 816B000C  lwz r11, 0xc(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315F77C: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315F780: 419A001C  beq cr6, 0x8315f79c
	if ctx.cr[6].eq {
	pc = 0x8315F79C; continue 'dispatch;
	}
	// 8315F784: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315F788: 4E800421  bctrl
	ctx.lr = 0x8315F78C;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315F78C: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F790: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F794: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F798: 4E800020  blr
	return;
	// 8315F79C: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315F7A0: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315F7A4: 388B5E24  addi r4, r11, 0x5e24
	ctx.r[4].s64 = ctx.r[11].s64 + 24100;
	// 8315F7A8: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F7AC: 4BFFFDFD  bl 0x8315f5a8
	ctx.lr = 0x8315F7B0;
	sub_8315F5A8(ctx, base);
	// 8315F7B0: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F7B4: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315F7B8: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F7BC: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F7C0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F7C8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F7C8 size=108
    let mut pc: u32 = 0x8315F7C8;
    'dispatch: loop {
        match pc {
            0x8315F7C8 => {
    //   block [0x8315F7C8..0x8315F834)
	// 8315F7C8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F7CC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F7D0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315F7D4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F7D8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F7DC: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F7E0: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F7E4: 2F1E0018  cmpwi cr6, r30, 0x18
	ctx.cr[6].compare_i32(ctx.r[30].s32, 24, &mut ctx.xer);
	// 8315F7E8: 4199000C  bgt cr6, 0x8315f7f4
	if ctx.cr[6].gt {
	pc = 0x8315F7F4; continue 'dispatch;
	}
	// 8315F7EC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F7F0: 4800002C  b 0x8315f81c
	pc = 0x8315F81C; continue 'dispatch;
	// 8315F7F4: 38A00018  li r5, 0x18
	ctx.r[5].s64 = 24;
	// 8315F7F8: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315F7FC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F800: 480489E1  bl 0x831a81e0
	ctx.lr = 0x8315F804;
	sub_831A81E0(ctx, base);
	// 8315F804: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F808: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F80C: 4BFFF1C5  bl 0x8315e9d0
	ctx.lr = 0x8315F810;
	sub_8315E9D0(ctx, base);
	// 8315F810: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315F814: 394BBC40  addi r10, r11, -0x43c0
	ctx.r[10].s64 = ctx.r[11].s64 + -17344;
	// 8315F818: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315F81C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F820: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F824: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F828: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315F82C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315F830: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F838(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F838 size=108
    let mut pc: u32 = 0x8315F838;
    'dispatch: loop {
        match pc {
            0x8315F838 => {
    //   block [0x8315F838..0x8315F8A4)
	// 8315F838: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F83C: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F840: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315F844: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F848: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F84C: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F850: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F854: 2F1E0018  cmpwi cr6, r30, 0x18
	ctx.cr[6].compare_i32(ctx.r[30].s32, 24, &mut ctx.xer);
	// 8315F858: 4199000C  bgt cr6, 0x8315f864
	if ctx.cr[6].gt {
	pc = 0x8315F864; continue 'dispatch;
	}
	// 8315F85C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315F860: 4800002C  b 0x8315f88c
	pc = 0x8315F88C; continue 'dispatch;
	// 8315F864: 38A00018  li r5, 0x18
	ctx.r[5].s64 = 24;
	// 8315F868: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315F86C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F870: 48048971  bl 0x831a81e0
	ctx.lr = 0x8315F874;
	sub_831A81E0(ctx, base);
	// 8315F874: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F878: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F87C: 4BFFF155  bl 0x8315e9d0
	ctx.lr = 0x8315F880;
	sub_8315E9D0(ctx, base);
	// 8315F880: 3D608335  lis r11, -0x7ccb
	ctx.r[11].s64 = -2093678592;
	// 8315F884: 394BBC50  addi r10, r11, -0x43b0
	ctx.r[10].s64 = ctx.r[11].s64 + -17328;
	// 8315F888: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315F88C: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F890: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F894: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F898: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315F89C: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315F8A0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F8A8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F8A8 size=76
    let mut pc: u32 = 0x8315F8A8;
    'dispatch: loop {
        match pc {
            0x8315F8A8 => {
    //   block [0x8315F8A8..0x8315F8F4)
	// 8315F8A8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F8AC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F8B0: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315F8B4: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F8B8: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F8BC: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315F8C0: 809E0010  lwz r4, 0x10(r30)
	ctx.r[4].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[30].u32.wrapping_add(16 as u32) ) } as u64;
	// 8315F8C4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315F8C8: 83E40004  lwz r31, 4(r4)
	ctx.r[31].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[4].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315F8CC: 4BFFF8FD  bl 0x8315f1c8
	ctx.lr = 0x8315F8D0;
	sub_8315F1C8(ctx, base);
	// 8315F8D0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8315F8D4: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315F8D8: 409AFFEC  bne cr6, 0x8315f8c4
	if !ctx.cr[6].eq {
	pc = 0x8315F8C4; continue 'dispatch;
	}
	// 8315F8DC: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315F8E0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315F8E4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315F8E8: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315F8EC: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315F8F0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F8F8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F8F8 size=72
    let mut pc: u32 = 0x8315F8F8;
    'dispatch: loop {
        match pc {
            0x8315F8F8 => {
    //   block [0x8315F8F8..0x8315F940)
	// 8315F8F8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F8FC: 4804886D  bl 0x831a8168
	ctx.lr = 0x8315F900;
	sub_831A8130(ctx, base);
	// 8315F900: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F904: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F908: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F90C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315F910: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 8315F914: 4BFFFBC5  bl 0x8315f4d8
	ctx.lr = 0x8315F918;
	sub_8315F4D8(ctx, base);
	// 8315F918: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8315F91C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315F920: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F924: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F928: 4BFFF831  bl 0x8315f158
	ctx.lr = 0x8315F92C;
	sub_8315F158(ctx, base);
	// 8315F92C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F930: 4BFFFC01  bl 0x8315f530
	ctx.lr = 0x8315F934;
	sub_8315F530(ctx, base);
	// 8315F934: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F938: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F93C: 4804887C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F940(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F940 size=72
    let mut pc: u32 = 0x8315F940;
    'dispatch: loop {
        match pc {
            0x8315F940 => {
    //   block [0x8315F940..0x8315F988)
	// 8315F940: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F944: 48048825  bl 0x831a8168
	ctx.lr = 0x8315F948;
	sub_831A8130(ctx, base);
	// 8315F948: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F94C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F950: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F954: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315F958: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 8315F95C: 4BFFFB7D  bl 0x8315f4d8
	ctx.lr = 0x8315F960;
	sub_8315F4D8(ctx, base);
	// 8315F960: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8315F964: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315F968: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F96C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F970: 4BFFF801  bl 0x8315f170
	ctx.lr = 0x8315F974;
	sub_8315F170(ctx, base);
	// 8315F974: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F978: 4BFFFBB9  bl 0x8315f530
	ctx.lr = 0x8315F97C;
	sub_8315F530(ctx, base);
	// 8315F97C: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F980: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F984: 48048834  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F988(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F988 size=72
    let mut pc: u32 = 0x8315F988;
    'dispatch: loop {
        match pc {
            0x8315F988 => {
    //   block [0x8315F988..0x8315F9D0)
	// 8315F988: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F98C: 480487DD  bl 0x831a8168
	ctx.lr = 0x8315F990;
	sub_831A8130(ctx, base);
	// 8315F990: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F994: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F998: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F99C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315F9A0: 7CDC3378  mr r28, r6
	ctx.r[28].u64 = ctx.r[6].u64;
	// 8315F9A4: 4BFFFB35  bl 0x8315f4d8
	ctx.lr = 0x8315F9A8;
	sub_8315F4D8(ctx, base);
	// 8315F9A8: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8315F9AC: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315F9B0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F9B4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F9B8: 4BFFF7D1  bl 0x8315f188
	ctx.lr = 0x8315F9BC;
	sub_8315F188(ctx, base);
	// 8315F9BC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F9C0: 4BFFFB71  bl 0x8315f530
	ctx.lr = 0x8315F9C4;
	sub_8315F530(ctx, base);
	// 8315F9C4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F9C8: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315F9CC: 480487EC  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315F9D0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315F9D0 size=80
    let mut pc: u32 = 0x8315F9D0;
    'dispatch: loop {
        match pc {
            0x8315F9D0 => {
    //   block [0x8315F9D0..0x8315FA20)
	// 8315F9D0: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315F9D4: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315F9D8: FBC1FFE8  std r30, -0x18(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-24 as u32), ctx.r[30].u64 ) };
	// 8315F9DC: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315F9E0: 9421FF90  stwu r1, -0x70(r1)
	ea = ctx.r[1].u32.wrapping_add(-112 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315F9E4: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315F9E8: 7C9E2378  mr r30, r4
	ctx.r[30].u64 = ctx.r[4].u64;
	// 8315F9EC: 4BFFFAED  bl 0x8315f4d8
	ctx.lr = 0x8315F9F0;
	sub_8315F4D8(ctx, base);
	// 8315F9F0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315F9F4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315F9F8: 4BFFFA59  bl 0x8315f450
	ctx.lr = 0x8315F9FC;
	sub_8315F450(ctx, base);
	// 8315F9FC: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315FA00: 4BFFFB31  bl 0x8315f530
	ctx.lr = 0x8315FA04;
	sub_8315F530(ctx, base);
	// 8315FA04: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FA08: 38210070  addi r1, r1, 0x70
	ctx.r[1].s64 = ctx.r[1].s64 + 112;
	// 8315FA0C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315FA10: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315FA14: EBC1FFE8  ld r30, -0x18(r1)
	ctx.r[30].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-24 as u32) ) };
	// 8315FA18: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315FA1C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FA20(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FA20 size=28
    let mut pc: u32 = 0x8315FA20;
    'dispatch: loop {
        match pc {
            0x8315FA20 => {
    //   block [0x8315FA20..0x8315FA3C)
	// 8315FA20: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315FA24: 816A81A4  lwz r11, -0x7e5c(r10)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-32348 as u32) ) } as u64;
	// 8315FA28: 392B0001  addi r9, r11, 1
	ctx.r[9].s64 = ctx.r[11].s64 + 1;
	// 8315FA2C: 912A81A4  stw r9, -0x7e5c(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-32348 as u32), ctx.r[9].u32 ) };
	// 8315FA30: 810A81A4  lwz r8, -0x7e5c(r10)
	ctx.r[8].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[10].u32.wrapping_add(-32348 as u32) ) } as u64;
	// 8315FA34: 2F080001  cmpwi cr6, r8, 1
	ctx.cr[6].compare_i32(ctx.r[8].s32, 1, &mut ctx.xer);
	// 8315FA38: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FA3C(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FA3C size=8
    let mut pc: u32 = 0x8315FA3C;
    'dispatch: loop {
        match pc {
            0x8315FA3C => {
    //   block [0x8315FA3C..0x8315FA44)
	// 8315FA3C: 4BFFFB7C  b 0x8315f5b8
	sub_8315F5B8(ctx, base);
	return;
	// 8315FA40: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FA48(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FA48 size=112
    let mut pc: u32 = 0x8315FA48;
    'dispatch: loop {
        match pc {
            0x8315FA48 => {
    //   block [0x8315FA48..0x8315FAB8)
	// 8315FA48: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FA4C: 48048719  bl 0x831a8164
	ctx.lr = 0x8315FA50;
	sub_831A8130(ctx, base);
	// 8315FA50: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FA54: 7C7B1B78  mr r27, r3
	ctx.r[27].u64 = ctx.r[3].u64;
	// 8315FA58: 7C9F2378  mr r31, r4
	ctx.r[31].u64 = ctx.r[4].u64;
	// 8315FA5C: 7CBE2B78  mr r30, r5
	ctx.r[30].u64 = ctx.r[5].u64;
	// 8315FA60: 7CDD3378  mr r29, r6
	ctx.r[29].u64 = ctx.r[6].u64;
	// 8315FA64: 7CFC3B78  mr r28, r7
	ctx.r[28].u64 = ctx.r[7].u64;
	// 8315FA68: 48003DB9  bl 0x83163820
	ctx.lr = 0x8315FA6C;
	sub_83163820(ctx, base);
	// 8315FA6C: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315FA70: 396B81F4  addi r11, r11, -0x7e0c
	ctx.r[11].s64 = ctx.r[11].s64 + -32268;
	// 8315FA74: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315FA78: 2F0A0001  cmpwi cr6, r10, 1
	ctx.cr[6].compare_i32(ctx.r[10].s32, 1, &mut ctx.xer);
	// 8315FA7C: 409A000C  bne cr6, 0x8315fa88
	if !ctx.cr[6].eq {
	pc = 0x8315FA88; continue 'dispatch;
	}
	// 8315FA80: 2F1B0001  cmpwi cr6, r27, 1
	ctx.cr[6].compare_i32(ctx.r[27].s32, 1, &mut ctx.xer);
	// 8315FA84: 419A002C  beq cr6, 0x8315fab0
	if ctx.cr[6].eq {
	pc = 0x8315FAB0; continue 'dispatch;
	}
	// 8315FA88: 814B0000  lwz r10, 0(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FA8C: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315FA90: 419A0020  beq cr6, 0x8315fab0
	if ctx.cr[6].eq {
	pc = 0x8315FAB0; continue 'dispatch;
	}
	// 8315FA94: 554B003E  slwi r11, r10, 0
	ctx.r[11].u32 = ctx.r[10].u32.wrapping_shl(0);
	ctx.r[11].u64 = ctx.r[11].u32 as u64;
	// 8315FA98: 7F86E378  mr r6, r28
	ctx.r[6].u64 = ctx.r[28].u64;
	// 8315FA9C: 7FA5EB78  mr r5, r29
	ctx.r[5].u64 = ctx.r[29].u64;
	// 8315FAA0: 7FC4F378  mr r4, r30
	ctx.r[4].u64 = ctx.r[30].u64;
	// 8315FAA4: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FAA8: 7D6903A6  mtctr r11
	ctx.ctr.u64 = ctx.r[11].u64;
	// 8315FAAC: 4E800421  bctrl
	ctx.lr = 0x8315FAB0;
	crate::rt::call_indirect(ctx.ctr.u32);
	// 8315FAB0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FAB4: 48048700  b 0x831a81b4
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FAB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FAB8 size=76
    let mut pc: u32 = 0x8315FAB8;
    'dispatch: loop {
        match pc {
            0x8315FAB8 => {
    //   block [0x8315FAB8..0x8315FB04)
	// 8315FAB8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FABC: 39200000  li r9, 0
	ctx.r[9].s64 = 0;
	// 8315FAC0: 396B6324  addi r11, r11, 0x6324
	ctx.r[11].s64 = ctx.r[11].s64 + 25380;
	// 8315FAC4: 814B0004  lwz r10, 4(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315FAC8: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315FACC: 419A002C  beq cr6, 0x8315faf8
	if ctx.cr[6].eq {
	pc = 0x8315FAF8; continue 'dispatch;
	}
	// 8315FAD0: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315FAD4: 7D4A582E  lwzx r10, r10, r11
	ctx.r[10].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8315FAD8: 7F0A1800  cmpw cr6, r10, r3
	ctx.cr[6].compare_i32(ctx.r[10].s32, ctx.r[3].s32, &mut ctx.xer);
	// 8315FADC: 419A0028  beq cr6, 0x8315fb04
	if ctx.cr[6].eq {
		sub_8315FB04(ctx, base);
		return;
	}
	// 8315FAE0: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8315FAE4: 390B0004  addi r8, r11, 4
	ctx.r[8].s64 = ctx.r[11].s64 + 4;
	// 8315FAE8: 552A1838  slwi r10, r9, 3
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315FAEC: 7CEA402E  lwzx r7, r10, r8
	ctx.r[7].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[8].u32)) } as u64;
	// 8315FAF0: 2B070000  cmplwi cr6, r7, 0
	ctx.cr[6].compare_u32(ctx.r[7].u32, 0 as u32, &mut ctx.xer);
	// 8315FAF4: 409AFFE0  bne cr6, 0x8315fad4
	if !ctx.cr[6].eq {
	pc = 0x8315FAD4; continue 'dispatch;
	}
	// 8315FAF8: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FAFC: 386B6310  addi r3, r11, 0x6310
	ctx.r[3].s64 = ctx.r[11].s64 + 25360;
	// 8315FB00: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FB04(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FB04 size=16
    let mut pc: u32 = 0x8315FB04;
    'dispatch: loop {
        match pc {
            0x8315FB04 => {
    //   block [0x8315FB04..0x8315FB14)
	// 8315FB04: 552A1838  slwi r10, r9, 3
	ctx.r[10].u32 = ctx.r[9].u32.wrapping_shl(3);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315FB08: 392B0004  addi r9, r11, 4
	ctx.r[9].s64 = ctx.r[11].s64 + 4;
	// 8315FB0C: 7C6A482E  lwzx r3, r10, r9
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[10].u32.wrapping_add(ctx.r[9].u32)) } as u64;
	// 8315FB10: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FB18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FB18 size=16
    let mut pc: u32 = 0x8315FB18;
    'dispatch: loop {
        match pc {
            0x8315FB18 => {
    //   block [0x8315FB18..0x8315FB28)
	// 8315FB18: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8315FB1C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315FB20: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315FB24: 4BFFFF24  b 0x8315fa48
	sub_8315FA48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FB28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FB28 size=12
    let mut pc: u32 = 0x8315FB28;
    'dispatch: loop {
        match pc {
            0x8315FB28 => {
    //   block [0x8315FB28..0x8315FB34)
	// 8315FB28: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8315FB2C: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315FB30: 4BFFFF18  b 0x8315fa48
	sub_8315FA48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FB38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FB38 size=8
    let mut pc: u32 = 0x8315FB38;
    'dispatch: loop {
        match pc {
            0x8315FB38 => {
    //   block [0x8315FB38..0x8315FB40)
	// 8315FB38: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8315FB3C: 4BFFFF0C  b 0x8315fa48
	sub_8315FA48(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FB40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FB40 size=216
    let mut pc: u32 = 0x8315FB40;
    'dispatch: loop {
        match pc {
            0x8315FB40 => {
    //   block [0x8315FB40..0x8315FC18)
	// 8315FB40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FB44: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315FB48: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315FB4C: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FB50: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315FB54: 7CA32B78  mr r3, r5
	ctx.r[3].u64 = ctx.r[5].u64;
	// 8315FB58: 7C862378  mr r6, r4
	ctx.r[6].u64 = ctx.r[4].u64;
	// 8315FB5C: 4BFFFF5D  bl 0x8315fab8
	ctx.lr = 0x8315FB60;
	sub_8315FAB8(ctx, base);
	// 8315FB60: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315FB64: 7C6A1B78  mr r10, r3
	ctx.r[10].u64 = ctx.r[3].u64;
	// 8315FB68: 388B8200  addi r4, r11, -0x7e00
	ctx.r[4].s64 = ctx.r[11].s64 + -32256;
	// 8315FB6C: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 8315FB70: 7D262050  subf r9, r6, r4
	ctx.r[9].s64 = ctx.r[4].s64 - ctx.r[6].s64;
	// 8315FB74: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FB78: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8315FB7C: 7D0959AE  stbx r8, r9, r11
	unsafe { crate::rt::store_u8(base as *mut u8, ctx.r[9].u32.wrapping_add(ctx.r[11].u32), ctx.r[8].u8) };
	// 8315FB80: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FB84: 409AFFF0  bne cr6, 0x8315fb74
	if !ctx.cr[6].eq {
	pc = 0x8315FB74; continue 'dispatch;
	}
	// 8315FB88: 3D20820C  lis r9, -0x7df4
	ctx.r[9].s64 = -2113142784;
	// 8315FB8C: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315FB90: 39292298  addi r9, r9, 0x2298
	ctx.r[9].s64 = ctx.r[9].s64 + 8856;
	// 8315FB94: 890B0000  lbz r8, 0(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FB98: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FB9C: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8315FBA0: 409AFFF4  bne cr6, 0x8315fb94
	if !ctx.cr[6].eq {
	pc = 0x8315FB94; continue 'dispatch;
	}
	// 8315FBA4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315FBA8: 89090000  lbz r8, 0(r9)
	ctx.r[8].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[9].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FBAC: 39290001  addi r9, r9, 1
	ctx.r[9].s64 = ctx.r[9].s64 + 1;
	// 8315FBB0: 2B080000  cmplwi cr6, r8, 0
	ctx.cr[6].compare_u32(ctx.r[8].u32, 0 as u32, &mut ctx.xer);
	// 8315FBB4: 990B0000  stb r8, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[8].u8 ) };
	// 8315FBB8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FBBC: 409AFFEC  bne cr6, 0x8315fba8
	if !ctx.cr[6].eq {
	pc = 0x8315FBA8; continue 'dispatch;
	}
	// 8315FBC0: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315FBC4: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FBC8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FBCC: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8315FBD0: 409AFFF4  bne cr6, 0x8315fbc4
	if !ctx.cr[6].eq {
	pc = 0x8315FBC4; continue 'dispatch;
	}
	// 8315FBD4: 396BFFFF  addi r11, r11, -1
	ctx.r[11].s64 = ctx.r[11].s64 + -1;
	// 8315FBD8: 892A0000  lbz r9, 0(r10)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FBDC: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8315FBE0: 2B090000  cmplwi cr6, r9, 0
	ctx.cr[6].compare_u32(ctx.r[9].u32, 0 as u32, &mut ctx.xer);
	// 8315FBE4: 992B0000  stb r9, 0(r11)
	unsafe { crate::rt::store_u8( base as *mut u8, ctx.r[11].u32.wrapping_add(0 as u32), ctx.r[9].u8 ) };
	// 8315FBE8: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FBEC: 409AFFEC  bne cr6, 0x8315fbd8
	if !ctx.cr[6].eq {
	pc = 0x8315FBD8; continue 'dispatch;
	}
	// 8315FBF0: 38E00000  li r7, 0
	ctx.r[7].s64 = 0;
	// 8315FBF4: 38C00000  li r6, 0
	ctx.r[6].s64 = 0;
	// 8315FBF8: 38A00000  li r5, 0
	ctx.r[5].s64 = 0;
	// 8315FBFC: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FC00: 4BFFFE49  bl 0x8315fa48
	ctx.lr = 0x8315FC04;
	sub_8315FA48(ctx, base);
	// 8315FC04: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315FC08: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315FC0C: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315FC10: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315FC14: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FC18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FC18 size=104
    let mut pc: u32 = 0x8315FC18;
    'dispatch: loop {
        match pc {
            0x8315FC18 => {
    //   block [0x8315FC18..0x8315FC80)
	// 8315FC18: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FC1C: 4804854D  bl 0x831a8168
	ctx.lr = 0x8315FC20;
	sub_831A8130(ctx, base);
	// 8315FC20: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FC24: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315FC28: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315FC2C: 7CCB3378  mr r11, r6
	ctx.r[11].u64 = ctx.r[6].u64;
	// 8315FC30: 3B9E0004  addi r28, r30, 4
	ctx.r[28].s64 = ctx.r[30].s64 + 4;
	// 8315FC34: 7CE63B78  mr r6, r7
	ctx.r[6].u64 = ctx.r[7].u64;
	// 8315FC38: 7CA72B78  mr r7, r5
	ctx.r[7].u64 = ctx.r[5].u64;
	// 8315FC3C: 7D655B78  mr r5, r11
	ctx.r[5].u64 = ctx.r[11].u64;
	// 8315FC40: 7F84E378  mr r4, r28
	ctx.r[4].u64 = ctx.r[28].u64;
	// 8315FC44: 7FA3EB78  mr r3, r29
	ctx.r[3].u64 = ctx.r[29].u64;
	// 8315FC48: 4BFFFAB9  bl 0x8315f700
	ctx.lr = 0x8315FC4C;
	sub_8315F700(ctx, base);
	// 8315FC4C: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315FC50: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315FC54: 409A000C  bne cr6, 0x8315fc60
	if !ctx.cr[6].eq {
	pc = 0x8315FC60; continue 'dispatch;
	}
	// 8315FC58: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FC5C: 4804855C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
	// 8315FC60: 7F85E378  mr r5, r28
	ctx.r[5].u64 = ctx.r[28].u64;
	// 8315FC64: 38800000  li r4, 0
	ctx.r[4].s64 = 0;
	// 8315FC68: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FC6C: 48048575  bl 0x831a81e0
	ctx.lr = 0x8315FC70;
	sub_831A81E0(ctx, base);
	// 8315FC70: 7FBFF12E  stwx r29, r31, r30
	unsafe { crate::rt::store_u32(base as *mut u8, ctx.r[31].u32.wrapping_add(ctx.r[30].u32), ctx.r[29].u32) };
	// 8315FC74: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FC78: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FC7C: 4804853C  b 0x831a81b8
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FC80(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FC80 size=16
    let mut pc: u32 = 0x8315FC80;
    'dispatch: loop {
        match pc {
            0x8315FC80 => {
    //   block [0x8315FC80..0x8315FC90)
	// 8315FC80: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315FC84: 7C641B78  mr r4, r3
	ctx.r[4].u64 = ctx.r[3].u64;
	// 8315FC88: 7C63582E  lwzx r3, r3, r11
	ctx.r[3].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[3].u32.wrapping_add(ctx.r[11].u32)) } as u64;
	// 8315FC8C: 4BFFFADC  b 0x8315f768
	sub_8315F768(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FC90(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FC90 size=20
    let mut pc: u32 = 0x8315FC90;
    'dispatch: loop {
        match pc {
            0x8315FC90 => {
    //   block [0x8315FC90..0x8315FCA4)
	// 8315FC90: 7D633214  add r11, r3, r6
	ctx.r[11].u64 = ctx.r[3].u64 + ctx.r[6].u64;
	// 8315FC94: 7F055800  cmpw cr6, r5, r11
	ctx.cr[6].compare_i32(ctx.r[5].s32, ctx.r[11].s32, &mut ctx.xer);
	// 8315FC98: 4098000C  bge cr6, 0x8315fca4
	if !ctx.cr[6].lt {
		sub_8315FCA4(ctx, base);
		return;
	}
	// 8315FC9C: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315FCA0: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FCA4(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FCA4 size=20
    let mut pc: u32 = 0x8315FCA4;
    'dispatch: loop {
        match pc {
            0x8315FCA4 => {
    //   block [0x8315FCA4..0x8315FCB8)
	// 8315FCA4: 7D643214  add r11, r4, r6
	ctx.r[11].u64 = ctx.r[4].u64 + ctx.r[6].u64;
	// 8315FCA8: 7D4600D0  neg r10, r6
	ctx.r[10].s64 = -ctx.r[6].s64;
	// 8315FCAC: 392BFFFF  addi r9, r11, -1
	ctx.r[9].s64 = ctx.r[11].s64 + -1;
	// 8315FCB0: 7D235038  and r3, r9, r10
	ctx.r[3].u64 = ctx.r[9].u64 & ctx.r[10].u64;
	// 8315FCB4: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FCB8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FCB8 size=36
    let mut pc: u32 = 0x8315FCB8;
    'dispatch: loop {
        match pc {
            0x8315FCB8 => {
    //   block [0x8315FCB8..0x8315FCDC)
	// 8315FCB8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FCBC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315FCC0: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FCC4: 4BFFF8C5  bl 0x8315f588
	ctx.lr = 0x8315FCC8;
	sub_8315F588(ctx, base);
	// 8315FCC8: 38630004  addi r3, r3, 4
	ctx.r[3].s64 = ctx.r[3].s64 + 4;
	// 8315FCCC: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315FCD0: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315FCD4: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315FCD8: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FCE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FCE0 size=20
    let mut pc: u32 = 0x8315FCE0;
    'dispatch: loop {
        match pc {
            0x8315FCE0 => {
    //   block [0x8315FCE0..0x8315FCF4)
	// 8315FCE0: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FCE4: 38E00010  li r7, 0x10
	ctx.r[7].s64 = 16;
	// 8315FCE8: 38CB634C  addi r6, r11, 0x634c
	ctx.r[6].s64 = ctx.r[11].s64 + 25420;
	// 8315FCEC: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8315FCF0: 4BFFFF28  b 0x8315fc18
	sub_8315FC18(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FCF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FCF8 size=16
    let mut pc: u32 = 0x8315FCF8;
    'dispatch: loop {
        match pc {
            0x8315FCF8 => {
    //   block [0x8315FCF8..0x8315FD08)
	// 8315FCF8: 7CC73378  mr r7, r6
	ctx.r[7].u64 = ctx.r[6].u64;
	// 8315FCFC: 7CA62B78  mr r6, r5
	ctx.r[6].u64 = ctx.r[5].u64;
	// 8315FD00: 38A00001  li r5, 1
	ctx.r[5].s64 = 1;
	// 8315FD04: 4BFFFF14  b 0x8315fc18
	sub_8315FC18(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FD08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FD08 size=8
    let mut pc: u32 = 0x8315FD08;
    'dispatch: loop {
        match pc {
            0x8315FD08 => {
    //   block [0x8315FD08..0x8315FD10)
	// 8315FD08: 38C00008  li r6, 8
	ctx.r[6].s64 = 8;
	// 8315FD0C: 4BFFFF84  b 0x8315fc90
	sub_8315FC90(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FD10(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FD10 size=24
    let mut pc: u32 = 0x8315FD10;
    'dispatch: loop {
        match pc {
            0x8315FD10 => {
    //   block [0x8315FD10..0x8315FD28)
	// 8315FD10: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FD14: 39400000  li r10, 0
	ctx.r[10].s64 = 0;
	// 8315FD18: 392B63B8  addi r9, r11, 0x63b8
	ctx.r[9].s64 = ctx.r[11].s64 + 25528;
	// 8315FD1C: 91430004  stw r10, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[10].u32 ) };
	// 8315FD20: 91230000  stw r9, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[9].u32 ) };
	// 8315FD24: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FD28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FD28 size=16
    let mut pc: u32 = 0x8315FD28;
    'dispatch: loop {
        match pc {
            0x8315FD28 => {
    //   block [0x8315FD28..0x8315FD38)
	// 8315FD28: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FD2C: 394B63B8  addi r10, r11, 0x63b8
	ctx.r[10].s64 = ctx.r[11].s64 + 25528;
	// 8315FD30: 91430000  stw r10, 0(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315FD34: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FD38(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FD38 size=104
    let mut pc: u32 = 0x8315FD38;
    'dispatch: loop {
        match pc {
            0x8315FD38 => {
    //   block [0x8315FD38..0x8315FDA0)
	// 8315FD38: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FD3C: 48048431  bl 0x831a816c
	ctx.lr = 0x8315FD40;
	sub_831A8130(ctx, base);
	// 8315FD40: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FD44: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FD48: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315FD4C: 392B6358  addi r9, r11, 0x6358
	ctx.r[9].s64 = ctx.r[11].s64 + 25432;
	// 8315FD50: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315FD54: 7C9D2378  mr r29, r4
	ctx.r[29].u64 = ctx.r[4].u64;
	// 8315FD58: 7CBF2B78  mr r31, r5
	ctx.r[31].u64 = ctx.r[5].u64;
	// 8315FD5C: 912A8300  stw r9, -0x7d00(r10)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[10].u32.wrapping_add(-32000 as u32), ctx.r[9].u32 ) };
	// 8315FD60: 48003AC1  bl 0x83163820
	ctx.lr = 0x8315FD64;
	sub_83163820(ctx, base);
	// 8315FD64: 39000000  li r8, 0
	ctx.r[8].s64 = 0;
	// 8315FD68: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315FD6C: 911F0000  stw r8, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[8].u32 ) };
	// 8315FD70: 7FA4EB78  mr r4, r29
	ctx.r[4].u64 = ctx.r[29].u64;
	// 8315FD74: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315FD78: 48003D71  bl 0x83163ae8
	ctx.lr = 0x8315FD7C;
	sub_83163AE8(ctx, base);
	// 8315FD7C: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315FD80: 2B030000  cmplwi cr6, r3, 0
	ctx.cr[6].compare_u32(ctx.r[3].u32, 0 as u32, &mut ctx.xer);
	// 8315FD84: 419A000C  beq cr6, 0x8315fd90
	if ctx.cr[6].eq {
	pc = 0x8315FD90; continue 'dispatch;
	}
	// 8315FD88: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315FD8C: 419A000C  beq cr6, 0x8315fd98
	if ctx.cr[6].eq {
	pc = 0x8315FD98; continue 'dispatch;
	}
	// 8315FD90: 917F0000  stw r11, 0(r31)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[31].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315FD94: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315FD98: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FD9C: 48048420  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FDA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FDA0 size=12
    let mut pc: u32 = 0x8315FDA0;
    'dispatch: loop {
        match pc {
            0x8315FDA0 => {
    //   block [0x8315FDA0..0x8315FDAC)
	// 8315FDA0: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315FDA4: 38AB81F0  addi r5, r11, -0x7e10
	ctx.r[5].s64 = ctx.r[11].s64 + -32272;
	// 8315FDA8: 4BFFFF90  b 0x8315fd38
	sub_8315FD38(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FDB0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FDB0 size=24
    let mut pc: u32 = 0x8315FDB0;
    'dispatch: loop {
        match pc {
            0x8315FDB0 => {
    //   block [0x8315FDB0..0x8315FDC8)
	// 8315FDB0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FDB4: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315FDB8: 388A81F0  addi r4, r10, -0x7e10
	ctx.r[4].s64 = ctx.r[10].s64 + -32272;
	// 8315FDBC: 812B0000  lwz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FDC0: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315FDC4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FDC8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FDC8 size=24
    let mut pc: u32 = 0x8315FDC8;
    'dispatch: loop {
        match pc {
            0x8315FDC8 => {
    //   block [0x8315FDC8..0x8315FDE0)
	// 8315FDC8: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FDCC: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315FDD0: 388A81F0  addi r4, r10, -0x7e10
	ctx.r[4].s64 = ctx.r[10].s64 + -32272;
	// 8315FDD4: 812B0004  lwz r9, 4(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(4 as u32) ) } as u64;
	// 8315FDD8: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315FDDC: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FDE0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FDE0 size=24
    let mut pc: u32 = 0x8315FDE0;
    'dispatch: loop {
        match pc {
            0x8315FDE0 => {
    //   block [0x8315FDE0..0x8315FDF8)
	// 8315FDE0: 81630000  lwz r11, 0(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FDE4: 3D40833A  lis r10, -0x7cc6
	ctx.r[10].s64 = -2093350912;
	// 8315FDE8: 388A81F0  addi r4, r10, -0x7e10
	ctx.r[4].s64 = ctx.r[10].s64 + -32272;
	// 8315FDEC: 812B0008  lwz r9, 8(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(8 as u32) ) } as u64;
	// 8315FDF0: 7D2903A6  mtctr r9
	ctx.ctr.u64 = ctx.r[9].u64;
	// 8315FDF4: 4E800420  bctr
	crate::rt::call_indirect(ctx.ctr.u32);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FDF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FDF8 size=68
    let mut pc: u32 = 0x8315FDF8;
    'dispatch: loop {
        match pc {
            0x8315FDF8 => {
    //   block [0x8315FDF8..0x8315FE3C)
	// 8315FDF8: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FDFC: 9181FFF8  stw r12, -8(r1)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[1].u32.wrapping_add(-8 as u32), ctx.r[12].u32 ) };
	// 8315FE00: FBE1FFF0  std r31, -0x10(r1)
	unsafe { crate::rt::store_u64( base as *mut u8, ctx.r[1].u32.wrapping_add(-16 as u32), ctx.r[31].u64 ) };
	// 8315FE04: 9421FFA0  stwu r1, -0x60(r1)
	ea = ctx.r[1].u32.wrapping_add(-96 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FE08: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315FE0C: 4BFFFF1D  bl 0x8315fd28
	ctx.lr = 0x8315FE10;
	sub_8315FD28(ctx, base);
	// 8315FE10: 548B07FE  clrlwi r11, r4, 0x1f
	ctx.r[11].u64 = ctx.r[4].u32 as u64 & 0x00000001u64;
	// 8315FE14: 2B0B0000  cmplwi cr6, r11, 0
	ctx.cr[6].compare_u32(ctx.r[11].u32, 0 as u32, &mut ctx.xer);
	// 8315FE18: 419A0010  beq cr6, 0x8315fe28
	if ctx.cr[6].eq {
	pc = 0x8315FE28; continue 'dispatch;
	}
	// 8315FE1C: 38800008  li r4, 8
	ctx.r[4].s64 = 8;
	// 8315FE20: 4BFFFE61  bl 0x8315fc80
	ctx.lr = 0x8315FE24;
	sub_8315FC80(ctx, base);
	// 8315FE24: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FE28: 38210060  addi r1, r1, 0x60
	ctx.r[1].s64 = ctx.r[1].s64 + 96;
	// 8315FE2C: 8181FFF8  lwz r12, -8(r1)
	ctx.r[12].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(-8 as u32) ) } as u64;
	// 8315FE30: 7D8803A6  mtlr r12
	ctx.lr = ctx.r[12].u64;
	// 8315FE34: EBE1FFF0  ld r31, -0x10(r1)
	ctx.r[31].u64 = unsafe { crate::rt::load_u64( base as *const u8, ctx.r[1].u32.wrapping_add(-16 as u32) ) };
	// 8315FE38: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FE40(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    let mut ea: u32 = 0;
    // ---- function 0x8315FE40 size=164
    let mut pc: u32 = 0x8315FE40;
    'dispatch: loop {
        match pc {
            0x8315FE40 => {
    //   block [0x8315FE40..0x8315FEE4)
	// 8315FE40: 7D8802A6  mflr r12
	ctx.r[12].u64 = ctx.lr;
	// 8315FE44: 48048329  bl 0x831a816c
	ctx.lr = 0x8315FE48;
	sub_831A8130(ctx, base);
	// 8315FE48: 9421FF80  stwu r1, -0x80(r1)
	ea = ctx.r[1].u32.wrapping_add(-128 as u32);
	unsafe { crate::rt::store_u32(base as *mut u8, ea, ctx.r[1].u32) };
	ctx.r[1].u32 = ea;
	// 8315FE4C: 7CBD2B78  mr r29, r5
	ctx.r[29].u64 = ctx.r[5].u64;
	// 8315FE50: 39600000  li r11, 0
	ctx.r[11].s64 = 0;
	// 8315FE54: 3D408219  lis r10, -0x7de7
	ctx.r[10].s64 = -2112290816;
	// 8315FE58: 7C872378  mr r7, r4
	ctx.r[7].u64 = ctx.r[4].u64;
	// 8315FE5C: 38AA63F0  addi r5, r10, 0x63f0
	ctx.r[5].s64 = ctx.r[10].s64 + 25584;
	// 8315FE60: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315FE64: 38C00004  li r6, 4
	ctx.r[6].s64 = 4;
	// 8315FE68: 38800034  li r4, 0x34
	ctx.r[4].s64 = 52;
	// 8315FE6C: 7C7E1B78  mr r30, r3
	ctx.r[30].u64 = ctx.r[3].u64;
	// 8315FE70: 4BFFF891  bl 0x8315f700
	ctx.lr = 0x8315FE74;
	sub_8315F700(ctx, base);
	// 8315FE74: 7C7F1B78  mr r31, r3
	ctx.r[31].u64 = ctx.r[3].u64;
	// 8315FE78: 2B1F0000  cmplwi cr6, r31, 0
	ctx.cr[6].compare_u32(ctx.r[31].u32, 0 as u32, &mut ctx.xer);
	// 8315FE7C: 409A0024  bne cr6, 0x8315fea0
	if !ctx.cr[6].eq {
	pc = 0x8315FEA0; continue 'dispatch;
	}
	// 8315FE80: 3D608219  lis r11, -0x7de7
	ctx.r[11].s64 = -2112290816;
	// 8315FE84: 388B63C8  addi r4, r11, 0x63c8
	ctx.r[4].s64 = ctx.r[11].s64 + 25544;
	// 8315FE88: 4BFFFC91  bl 0x8315fb18
	ctx.lr = 0x8315FE8C;
	sub_8315FB18(ctx, base);
	// 8315FE8C: 3940FFFD  li r10, -3
	ctx.r[10].s64 = -3;
	// 8315FE90: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315FE94: 915D0000  stw r10, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[10].u32 ) };
	// 8315FE98: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FE9C: 48048320  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315FEA0: 38A10050  addi r5, r1, 0x50
	ctx.r[5].s64 = ctx.r[1].s64 + 80;
	// 8315FEA4: 38800034  li r4, 0x34
	ctx.r[4].s64 = 52;
	// 8315FEA8: 7FE3FB78  mr r3, r31
	ctx.r[3].u64 = ctx.r[31].u64;
	// 8315FEAC: 4BFFFE8D  bl 0x8315fd38
	ctx.lr = 0x8315FEB0;
	sub_8315FD38(ctx, base);
	// 8315FEB0: 81610050  lwz r11, 0x50(r1)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[1].u32.wrapping_add(80 as u32) ) } as u64;
	// 8315FEB4: 2F0B0000  cmpwi cr6, r11, 0
	ctx.cr[6].compare_i32(ctx.r[11].s32, 0, &mut ctx.xer);
	// 8315FEB8: 419A0020  beq cr6, 0x8315fed8
	if ctx.cr[6].eq {
	pc = 0x8315FED8; continue 'dispatch;
	}
	// 8315FEBC: 917D0000  stw r11, 0(r29)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[29].u32.wrapping_add(0 as u32), ctx.r[11].u32 ) };
	// 8315FEC0: 7FE4FB78  mr r4, r31
	ctx.r[4].u64 = ctx.r[31].u64;
	// 8315FEC4: 7FC3F378  mr r3, r30
	ctx.r[3].u64 = ctx.r[30].u64;
	// 8315FEC8: 4BFFF8A1  bl 0x8315f768
	ctx.lr = 0x8315FECC;
	sub_8315F768(ctx, base);
	// 8315FECC: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315FED0: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FED4: 480482E8  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
	// 8315FED8: 93C30004  stw r30, 4(r3)
	unsafe { crate::rt::store_u32( base as *mut u8, ctx.r[3].u32.wrapping_add(4 as u32), ctx.r[30].u32 ) };
	// 8315FEDC: 38210080  addi r1, r1, 0x80
	ctx.r[1].s64 = ctx.r[1].s64 + 128;
	// 8315FEE0: 480482DC  b 0x831a81bc
	sub_831A8180(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FEE8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FEE8 size=12
    let mut pc: u32 = 0x8315FEE8;
    'dispatch: loop {
        match pc {
            0x8315FEE8 => {
    //   block [0x8315FEE8..0x8315FEF4)
	// 8315FEE8: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315FEEC: 38AB81F0  addi r5, r11, -0x7e10
	ctx.r[5].s64 = ctx.r[11].s64 + -32272;
	// 8315FEF0: 4BFFFF50  b 0x8315fe40
	sub_8315FE40(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FEF8(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FEF8 size=12
    let mut pc: u32 = 0x8315FEF8;
    'dispatch: loop {
        match pc {
            0x8315FEF8 => {
    //   block [0x8315FEF8..0x8315FF04)
	// 8315FEF8: 7C852378  mr r5, r4
	ctx.r[5].u64 = ctx.r[4].u64;
	// 8315FEFC: 38800001  li r4, 1
	ctx.r[4].s64 = 1;
	// 8315FF00: 4BFFFF40  b 0x8315fe40
	sub_8315FE40(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FF08(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FF08 size=12
    let mut pc: u32 = 0x8315FF08;
    'dispatch: loop {
        match pc {
            0x8315FF08 => {
    //   block [0x8315FF08..0x8315FF14)
	// 8315FF08: 3D60833A  lis r11, -0x7cc6
	ctx.r[11].s64 = -2093350912;
	// 8315FF0C: 388B81F0  addi r4, r11, -0x7e10
	ctx.r[4].s64 = ctx.r[11].s64 + -32272;
	// 8315FF10: 4BFFFFE8  b 0x8315fef8
	sub_8315FEF8(ctx, base);
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FF18(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FF18 size=12
    let mut pc: u32 = 0x8315FF18;
    'dispatch: loop {
        match pc {
            0x8315FF18 => {
    //   block [0x8315FF18..0x8315FF24)
	// 8315FF18: 8163000C  lwz r11, 0xc(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(12 as u32) ) } as u64;
	// 8315FF1C: 386B0008  addi r3, r11, 8
	ctx.r[3].s64 = ctx.r[11].s64 + 8;
	// 8315FF20: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FF28(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FF28 size=8
    let mut pc: u32 = 0x8315FF28;
    'dispatch: loop {
        match pc {
            0x8315FF28 => {
    //   block [0x8315FF28..0x8315FF30)
	// 8315FF28: A0630020  lhz r3, 0x20(r3)
	ctx.r[3].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315FF2C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FF30(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FF30 size=104
    let mut pc: u32 = 0x8315FF30;
    'dispatch: loop {
        match pc {
            0x8315FF30 => {
    //   block [0x8315FF30..0x8315FF98)
	// 8315FF30: 7C6B1B78  mr r11, r3
	ctx.r[11].u64 = ctx.r[3].u64;
	// 8315FF34: 38600000  li r3, 0
	ctx.r[3].s64 = 0;
	// 8315FF38: A0EB0020  lhz r7, 0x20(r11)
	ctx.r[7].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(32 as u32) ) } as u64;
	// 8315FF3C: 2F070000  cmpwi cr6, r7, 0
	ctx.cr[6].compare_i32(ctx.r[7].s32, 0, &mut ctx.xer);
	// 8315FF40: 40990050  ble cr6, 0x8315ff90
	if !ctx.cr[6].gt {
	pc = 0x8315FF90; continue 'dispatch;
	}
	// 8315FF44: 816B0028  lwz r11, 0x28(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315FF48: 390B0004  addi r8, r11, 4
	ctx.r[8].s64 = ctx.r[11].s64 + 4;
	// 8315FF4C: 81480000  lwz r10, 0(r8)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[8].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FF50: 7C8B2378  mr r11, r4
	ctx.r[11].u64 = ctx.r[4].u64;
	// 8315FF54: 892B0000  lbz r9, 0(r11)
	ctx.r[9].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FF58: 88CA0000  lbz r6, 0(r10)
	ctx.r[6].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FF5C: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315FF60: 7D264850  subf r9, r6, r9
	ctx.r[9].s64 = ctx.r[9].s64 - ctx.r[6].s64;
	// 8315FF64: 419A0014  beq cr6, 0x8315ff78
	if ctx.cr[6].eq {
	pc = 0x8315FF78; continue 'dispatch;
	}
	// 8315FF68: 396B0001  addi r11, r11, 1
	ctx.r[11].s64 = ctx.r[11].s64 + 1;
	// 8315FF6C: 394A0001  addi r10, r10, 1
	ctx.r[10].s64 = ctx.r[10].s64 + 1;
	// 8315FF70: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315FF74: 419AFFE0  beq cr6, 0x8315ff54
	if ctx.cr[6].eq {
	pc = 0x8315FF54; continue 'dispatch;
	}
	// 8315FF78: 2F090000  cmpwi cr6, r9, 0
	ctx.cr[6].compare_i32(ctx.r[9].s32, 0, &mut ctx.xer);
	// 8315FF7C: 419A0014  beq cr6, 0x8315ff90
	if ctx.cr[6].eq {
	pc = 0x8315FF90; continue 'dispatch;
	}
	// 8315FF80: 38630001  addi r3, r3, 1
	ctx.r[3].s64 = ctx.r[3].s64 + 1;
	// 8315FF84: 39080020  addi r8, r8, 0x20
	ctx.r[8].s64 = ctx.r[8].s64 + 32;
	// 8315FF88: 7F033800  cmpw cr6, r3, r7
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8315FF8C: 4198FFC0  blt cr6, 0x8315ff4c
	if ctx.cr[6].lt {
	pc = 0x8315FF4C; continue 'dispatch;
	}
	// 8315FF90: 7F033800  cmpw cr6, r3, r7
	ctx.cr[6].compare_i32(ctx.r[3].s32, ctx.r[7].s32, &mut ctx.xer);
	// 8315FF94: 4C9A0020  bnelr cr6
	if !ctx.cr[6].eq { return; }
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FF98(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FF98 size=8
    let mut pc: u32 = 0x8315FF98;
    'dispatch: loop {
        match pc {
            0x8315FF98 => {
    //   block [0x8315FF98..0x8315FFA0)
	// 8315FF98: 3860FFFF  li r3, -1
	ctx.r[3].s64 = -1;
	// 8315FF9C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_8315FFA0(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x8315FFA0 size=96
    let mut pc: u32 = 0x8315FFA0;
    'dispatch: loop {
        match pc {
            0x8315FFA0 => {
    //   block [0x8315FFA0..0x83160000)
	// 8315FFA0: 81630028  lwz r11, 0x28(r3)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(40 as u32) ) } as u64;
	// 8315FFA4: 54AA2834  slwi r10, r5, 5
	ctx.r[10].u32 = ctx.r[5].u32.wrapping_shl(5);
	ctx.r[10].u64 = ctx.r[10].u32 as u64;
	// 8315FFA8: 7D6B5214  add r11, r11, r10
	ctx.r[11].u64 = ctx.r[11].u64 + ctx.r[10].u64;
	// 8315FFAC: 894B0009  lbz r10, 9(r11)
	ctx.r[10].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[11].u32.wrapping_add(9 as u32) ) } as u64;
	// 8315FFB0: 2B0A0000  cmplwi cr6, r10, 0
	ctx.cr[6].compare_u32(ctx.r[10].u32, 0 as u32, &mut ctx.xer);
	// 8315FFB4: 419A007C  beq cr6, 0x83160030
	if ctx.cr[6].eq {
		sub_83160030(ctx, base);
		return;
	}
	// 8315FFB8: 81430024  lwz r10, 0x24(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(36 as u32) ) } as u64;
	// 8315FFBC: 7F045040  cmplw cr6, r4, r10
	ctx.cr[6].compare_u32(ctx.r[4].u32, ctx.r[10].u32, &mut ctx.xer);
	// 8315FFC0: 40980070  bge cr6, 0x83160030
	if !ctx.cr[6].lt {
		sub_83160030(ctx, base);
		return;
	}
	// 8315FFC4: A1430022  lhz r10, 0x22(r3)
	ctx.r[10].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[3].u32.wrapping_add(34 as u32) ) } as u64;
	// 8315FFC8: A10B000A  lhz r8, 0xa(r11)
	ctx.r[8].u64 = unsafe { crate::rt::load_u16( base as *const u8, ctx.r[11].u32.wrapping_add(10 as u32) ) } as u64;
	// 8315FFCC: 7D4A21D6  mullw r10, r10, r4
	ctx.r[10].s64 = (ctx.r[10].s32 as i64) * (ctx.r[4].s32 as i64);
	// 8315FFD0: 81230018  lwz r9, 0x18(r3)
	ctx.r[9].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[3].u32.wrapping_add(24 as u32) ) } as u64;
	// 8315FFD4: 816B0000  lwz r11, 0(r11)
	ctx.r[11].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[11].u32.wrapping_add(0 as u32) ) } as u64;
	// 8315FFD8: 7D4A4214  add r10, r10, r8
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[8].u64;
	// 8315FFDC: 2B0B0005  cmplwi cr6, r11, 5
	ctx.cr[6].compare_u32(ctx.r[11].u32, 5 as u32, &mut ctx.xer);
	// 8315FFE0: 7D4A4A14  add r10, r10, r9
	ctx.r[10].u64 = ctx.r[10].u64 + ctx.r[9].u64;
	// 8315FFE4: 419900B4  bgt cr6, 0x83160098
	if ctx.cr[6].gt {
		sub_83160098(ctx, base);
		return;
	}
	// 8315FFE8: 3D808316  lis r12, -0x7cea
	ctx.r[12].s64 = -2095710208;
	// 8315FFEC: 398C0000  addi r12, r12, 0
	ctx.r[12].s64 = ctx.r[12].s64 + 0;
	// 8315FFF0: 5560103A  slwi r0, r11, 2
	ctx.r[0].u32 = ctx.r[11].u32.wrapping_shl(2);
	ctx.r[0].u64 = ctx.r[0].u32 as u64;
	// 8315FFF4: 7C0C002E  lwzx r0, r12, r0
	ctx.r[0].u64 = unsafe { crate::rt::load_u32(base as *const u8, ctx.r[12].u32.wrapping_add(ctx.r[0].u32)) } as u64;
	// 8315FFF8: 7C0903A6  mtctr r0
	ctx.ctr.u64 = ctx.r[0].u64;
	// 8315FFFC: 4E800420  bctr
	match ctx.r[11].u64 {
		0 => {
			// ERROR: 0x83160018
			return;
		},
		1 => {
			// ERROR: 0x83160018
			return;
		},
		2 => {
			// ERROR: 0x83160020
			return;
		},
		3 => {
			// ERROR: 0x83160020
			return;
		},
		4 => {
			// ERROR: 0x83160028
			return;
		},
		5 => {
			// ERROR: 0x83160028
			return;
		},
		_ => unsafe { core::hint::unreachable_unchecked() },
	}
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83160000(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83160000 size=32
    let mut pc: u32 = 0x83160000;
    'dispatch: loop {
        match pc {
            0x83160000 => {
    //   block [0x83160000..0x83160020)
	// 83160000: 83160018  lwz r24, 0x18(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(24 as u32) ) } as u64;
	// 83160004: 83160018  lwz r24, 0x18(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(24 as u32) ) } as u64;
	// 83160008: 83160020  lwz r24, 0x20(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(32 as u32) ) } as u64;
	// 8316000C: 83160020  lwz r24, 0x20(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(32 as u32) ) } as u64;
	// 83160010: 83160028  lwz r24, 0x28(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(40 as u32) ) } as u64;
	// 83160014: 83160028  lwz r24, 0x28(r22)
	ctx.r[24].u64 = unsafe { crate::rt::load_u32( base as *const u8, ctx.r[22].u32.wrapping_add(40 as u32) ) } as u64;
	// 83160018: 886A0000  lbz r3, 0(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(0 as u32) ) } as u64;
	// 8316001C: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


pub fn sub_83160020(ctx: &mut crate::recompiler::ppc_context::PPCContext, base: *mut u8) {
    // ---- function 0x83160020 size=8
    let mut pc: u32 = 0x83160020;
    'dispatch: loop {
        match pc {
            0x83160020 => {
    //   block [0x83160020..0x83160028)
	// 83160020: 886A0001  lbz r3, 1(r10)
	ctx.r[3].u64 = unsafe { crate::rt::load_u8( base as *const u8, ctx.r[10].u32.wrapping_add(1 as u32) ) } as u64;
	// 83160024: 4E800020  blr
	return;
            }
            _ => unsafe { core::hint::unreachable_unchecked() },
        }
    }
}


